<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="46b8f9361fae73f13467cd1aaff186ba" category="summary">NetApp 솔루션 자료에 대한 최근 변경 사항 로그</block>
  <block id="679ce0aa9d3d54bfddd37e1b78b802de" category="doc">NetApp 솔루션 변경 로그</block>
  <block id="aceacf14369d872e8cb00f62613f52c6" category="paragraph">NetApp 솔루션 자료에 대한 최근 변경 사항. 가장 최근의 변경 사항이 먼저 나열됩니다.</block>
  <block id="e63695c4dea40eefb2ef481c7b242192" category="open-title">모든 변경 사항</block>
  <block id="5edbe8c55546db896b55871b44a39263" category="cell">* 날짜 *</block>
  <block id="12cd1425f32ad289dba28e35ae9096fb" category="cell">* 솔루션 영역 *</block>
  <block id="b96941ac46daa357b1782f017746a57b" category="cell">* 변경에 대한 설명 *</block>
  <block id="7d131526ee2a04107bbc50d52a29a7d7" category="cell">2021년 12월 21일</block>
  <block id="0db377921f4ce762c62526131097968f" category="cell">일반</block>
  <block id="ceba75f5c6f0a0eed497aaa1cc4f30ad" category="cell">가상화 및 엔터프라이즈 하이브리드 클라우드에 대한 콘텐츠를 보다 효율적으로 구성하기 위한 랜딩 페이지를 만들었습니다</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="cell">컨테이너</block>
  <block id="c65463900a520919b522c30b6256e475" category="cell">새로운 비디오 데모 추가: NetApp Astra Control을 활용하여 사후 분석 수행 및 NVA-1160에 애플리케이션 복원</block>
  <block id="f63616bb6a8255ed08089231c746f285" category="cell">2021년 12월 6일</block>
  <block id="3f2c1d118f7bc861eb20da58f81a2d0d" category="cell">하이브리드 클라우드/가상화</block>
  <block id="040fc8ca9c1b1eb9d408c7ae5e202acb" category="cell">가상화 환경 및 게스트 연결 스토리지 옵션을 위한 EHC(Enterprise Hybrid Cloud) 컨텐츠 생성</block>
  <block id="16784caec2e047ddf59bd5a51bd35a73" category="cell">2021년 11월 15일</block>
  <block id="1c20ad7a11d1c2856906d55171b50126" category="cell">새 비디오 데모 추가: Astra Control을 사용하여 CI/CD 파이프라인에서 데이터 보호 NVA-1160에 추가</block>
  <block id="b0ac6120dada9135114784db22a59940" category="cell">최신 데이터 분석</block>
  <block id="5cdb842b21b9f980df2b3ab63ee9a9e6" category="cell">새로운 내용: Confluent Kafka 모범 사례</block>
  <block id="38562890365e144b467ec2813a6377f2" category="cell">2021년 11월 2일</block>
  <block id="caea8340e2d186a540518d08602aa065" category="cell">자동화</block>
  <block id="fb0ad99371abb3d02d60add8160c6dd9" category="cell">NetApp Cloud Manager를 사용하여 CVO 및 Connector의 AWS 인증 요구사항</block>
  <block id="dfd39862c9cc158ad7b0e4e1e9a3024a" category="cell">2021년 10월 29일</block>
  <block id="e7c456cd85cc15bd3faf7b65c0833d3e" category="cell">새로운 콘텐츠: TR-4657 - NetApp 하이브리드 클라우드 데이터 솔루션: Spark 및 Hadoop</block>
  <block id="4549cdf15178a5f0535be7f0f86cdb4d" category="cell">엔터프라이즈 데이터베이스</block>
  <block id="63c0320f73b5f4e528bbe1488acc5103" category="cell">Oracle 데이터베이스용 자동화된 데이터 보호</block>
  <block id="815425a7766095190649a3f9ecbc1828" category="cell">2021년 10월 26일</block>
  <block id="7a81532ad3c2274f22bc7665e02f162f" category="cell">NetApp 솔루션 타일에 엔터프라이즈 애플리케이션 및 데이터베이스용 블로그 섹션이 추가되었습니다. 엔터프라이즈 데이터베이스 블로그에 두 개의 블로그를 추가했습니다.</block>
  <block id="8493c4f1797303a6de2524a60adcf058" category="cell">2021년 10월 18일</block>
  <block id="ade15f89ccc27958a743a992cea8c574" category="cell">TR-4908 - SnapCenter를 사용한 하이브리드 클라우드 데이터베이스 솔루션</block>
  <block id="622eda32248f1c4d1fc31dd78ec74c4a" category="cell">2021년 10월 14일</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="cell">포함되었습니다</block>
  <block id="f6ecd264493db5fac4b21f19be4eb69d" category="cell">VMware VCF 블로그 시리즈를 통해 NetApp의 1-4부 추가</block>
  <block id="83a11da06ed8a3e338b5e8d2991cae0c" category="cell">2021년 4월 10일</block>
  <block id="c95696f6146a5b8b56c74d4349687ec6" category="cell">새로운 비디오 데모 추가: NVA-1160에 Astra Control Center를 사용한 워크로드 마이그레이션</block>
  <block id="4f41bdb2ec81835b66ffbbd18feea656" category="cell">2021년 9월 23일</block>
  <block id="9b699c59be5ba510cd9c430a31843b23" category="cell">데이터 마이그레이션</block>
  <block id="32ff1e0d02ec482c64fdac1af2a49372" category="cell">새로운 콘텐츠: NetApp XCP 모범 사례</block>
  <block id="42246d8ef9280d19cf1326197310630a" category="cell">2021년 9월 21일</block>
  <block id="10c87c454d38afc0644c8c1fb75fa524" category="cell">VMware vSphere 관리자를 위한 새로운 컨텐츠 또는 ONTAP, VMware vSphere 자동화</block>
  <block id="faaef04f2f0bb7bed9504fc3d357ba59" category="cell">2021년 9월 9일</block>
  <block id="80245b1f322b07a9fcd385bb375d8182" category="cell">F5 BIG-IP 로드 밸런서와 OpenShift와의 통합 NVA-1160을 추가했습니다</block>
  <block id="023cd4d7ed373df0d803d414e2e452bf" category="cell">2021년 8월 5일</block>
  <block id="afb6b7f715f1bf6492efb8f3c279ddd7" category="cell">Red Hat OpenShift에 NVA-1160-NetApp Astra Control Center에 새로운 기술 통합 추가</block>
  <block id="2cd99fd0d69d62395a72dc7d4684299c" category="cell">2021년 7월 21일</block>
  <block id="13d13fda6fbfbd83ab30f9a5bee17b08" category="cell">NFS에서 ONTAP용 Oracle19c의 자동 배포</block>
  <block id="e88b179e97a156d13d1c9c4163513205" category="cell">2021년 7월 2일</block>
  <block id="9f99e3ea14c0a44dde0fd7db13fa3bef" category="cell">TR-4897 - Azure NetApp Files의 SQL Server: 실제 배포 보기</block>
  <block id="83d39ff0c36403ca3e183af9ca091a71" category="cell">2021년 6월 16일</block>
  <block id="2891cb0fe31606ff172d0be4ec81732f" category="cell">OpenShift Virtualization 설치: NetApp과 함께 Red Hat OpenShift 라는 새 비디오 데모 추가</block>
  <block id="77d29c989f99997794df55b2d9053ae8" category="cell">OpenShift 가상화를 통한 가상 머신 구축 이라는 새로운 비디오 데모 추가: NetAppp의 Red Hat OpenShift</block>
  <block id="fab25e19f7e186358ed7f1268e7af3b4" category="cell">2021년 6월 14일</block>
  <block id="96da300b5faf4ae3a5ca09afabba4273" category="cell">Azure NetApp Files 기반 Microsoft SQL Server 솔루션 추가</block>
  <block id="67c877d4abd9acdbb0fa62c3720b6d60" category="cell">2021년 6월 11일</block>
  <block id="a14851e0e2cb4c8e9176cdea01500288" category="cell">새로운 비디오 데모 추가: NVA-1160에 Astra Trident 및 SnapMirror를 사용한 워크로드 마이그레이션</block>
  <block id="c5d2015481e39976c67e40778a449a2d" category="cell">2021년 6월 9일</block>
  <block id="c4aad26d0bd9fb92610a1b5b3390bd46" category="cell">NetApp OpenShift에서 NVA-1160-Advanced Cluster Management for Kubernetes에 새로운 사용 사례를 추가했습니다</block>
  <block id="53977250e4a69cab3688fcbede8fb73a" category="cell">2021년 5월 28일</block>
  <block id="9c23aa040a3dc51dbbf59463247f4fec" category="cell">NetApp ONTAP를 사용한 NVA-1160-OpenShift Virtualization에 새로운 사용 사례 추가</block>
  <block id="c02e5ac689072495b8af780302105253" category="cell">2021년 5월 27일</block>
  <block id="f5abcac882b8caa17d3af1c14144f503" category="cell">NetApp ONTAP 기반 OpenShift에서 NVA-1160-Multitenancy에 새 사용 사례를 추가했습니다</block>
  <block id="3202abe9084b2d9ec5b0b162721978e7" category="cell">2021년 5월 26일</block>
  <block id="d58aa75910c54a80c6ba4de7e7f6949f" category="cell">NetApp과 함께 NVA-1160-Red Hat OpenShift 추가</block>
  <block id="a0be3ecb819e8e7215f946964346f547" category="cell">2021년 5월 25일</block>
  <block id="95a74db23b085df59ef6412199e9e791" category="cell">블로그 추가: Red Hat OpenShift에 NetApp Trident 설치 – Docker 'toomanyrequest' 문제를 해결하는 방법!</block>
  <block id="2dec0489948dbe7f63f68743a085e98c" category="cell">2021년 5월 19일</block>
  <block id="9045bfbeff51b83f9752fe549021a181" category="cell">FlexPod 솔루션 링크가 추가되었습니다</block>
  <block id="0a40e3c91a3a55c9a37428c6d194d0e5" category="cell">AI</block>
  <block id="af3192eaae3cb09641db4adcc45ed625" category="cell">AI Control Plane 솔루션을 PDF에서 HTML로 변환했습니다</block>
  <block id="8ff5be8d16e86e5284f8ba8a3428459a" category="cell">2021년 5월 17일</block>
  <block id="a88789a4f83f213b256b57eb0884fd1d" category="cell">기본 페이지에 솔루션 피드백 타일을 추가했습니다</block>
  <block id="027fb9451c491d9dcfb7db05f552788d" category="cell">2021년 5월 11일</block>
  <block id="3e62d5f1a7f1b6907ad1ecaf11282dac" category="cell">NFS에서 Oracle 19c for ONTAP의 자동 구축을 추가했습니다</block>
  <block id="d2422eca0ff6f19afb6e1206b15fbe01" category="cell">2021년 5월 10일</block>
  <block id="85c96a5f13e6dea61e003704f8d456e2" category="cell">새로운 비디오: NetApp 및 VMware Tanzu Basic에서 VVol 사용 방법, 3부</block>
  <block id="29e9b684dbbdf5cc1828da82a146781d" category="cell">2021년 5월 6일</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="cell">Oracle 데이터베이스</block>
  <block id="508db167da7d74fc86c3f8024ce04558" category="cell">FC를 통해 Cisco UCS 및 NetApp AFF A800을 사용하여 FlexPod 데이터 센터의 Oracle 19c RAC 데이터베이스에 대한 링크가 추가되었습니다</block>
  <block id="85fbf94a3ecf9a3af4a93f80a3681fe1" category="cell">2021년 5월 5일</block>
  <block id="608f33919f16e9a23bd532ad6bcf480a" category="cell">FlexPod Oracle NVA(1155) 및 자동화 비디오 추가</block>
  <block id="4dc6e14d2ad9dafd2cd72f8c77d22bea" category="cell">2021년 5월 3일</block>
  <block id="3d21a9c32818fc58b044121ce91e053c" category="cell">데스크톱 가상화</block>
  <block id="4174d4c17e4b11e07d8dd581e16ba56c" category="cell">FlexPod 데스크톱 가상화 솔루션 링크가 추가되었습니다</block>
  <block id="b3cae16f1f895f4f9ceae98617a3bf0d" category="cell">2021년 4월 30일</block>
  <block id="2764512d2fc00264d149a6142151aa1a" category="cell">비디오: NetApp 및 VMware Tanzu Basic에서 VVol 사용 방법, 2부</block>
  <block id="4996fa0acf5cc54e889a50e9bdd2e56b" category="cell">2021년 4월 26일</block>
  <block id="9c5316849ca2429400f8979f0ee0d963" category="cell">블로그 추가: ONTAP와 함께 VMware Tanzu를 사용하여 Kubernetes 여정을 가속화하십시오</block>
  <block id="911da11d01e00e9aa94c5b03b2e6e2cc" category="cell">2021년 4월 6일</block>
  <block id="06cfdb63e0660d09f203a21e28520a1e" category="cell">"이 리포지토리 정보" 추가</block>
  <block id="32edd80de3642c58e1a05df5f3e458e1" category="cell">2021년 3월 31일</block>
  <block id="bbb1c8f8182403001f2e1f69085ca2ad" category="cell">Edge에 TR-4886-AI 추론 추가: Lenovo ThinkSystem Solution Design이 포함된 NetApp ONTAP</block>
  <block id="d61c9a3748e1dd56535fbdaaa3e39eab" category="cell">2021년 3월 29일</block>
  <block id="8575a367028bec3e86e25b102a8dced1" category="cell">NetApp 스토리지 솔루션을 사용한 NVA-1157-Apache Spark 워크로드 추가</block>
  <block id="8f10e64b04f6cc56cf66fd4f4eb0f4d9" category="cell">2021년 3월 23일</block>
  <block id="7998f8ad3cabe02af607385cae780ce1" category="cell">비디오: NetApp 및 VMware Tanzu Basic에서 VVol 사용 방법, 1부</block>
  <block id="f86fe8ec70f2003923e4000589747208" category="cell">2021년 3월 9일</block>
  <block id="eea51e9c0dffabdea48ada8f53bbf0f5" category="cell">E-Series 콘텐츠 추가, AI 콘텐츠 분류</block>
  <block id="0b218fa381bfd1c86fff15d165ab23a0" category="cell">2021년 4월 3일</block>
  <block id="932af944058a758da919ca59d1af640b" category="cell">새로운 콘텐츠: NetApp 솔루션 자동화 시작하기</block>
  <block id="4be9c930c1a8a198115d499cb3223d9e" category="cell">2021년 2월 18일</block>
  <block id="0c560038af98c5401dd10202e7937acd" category="cell">ONTAP용 TR-4597-VMware vSphere 추가</block>
  <block id="aa1c3ec5e6dcfb94555ff987f061f1a0" category="cell">2021년 2월 16일</block>
  <block id="3ecf1285a084b58473a7873e3f33e74a" category="cell">AI 에지 추론을 위한 자동화된 배포 단계 추가</block>
  <block id="8138d0c3e613508050b6fec12c4322c7" category="cell">2021년 2월 3일</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="cell">제공합니다</block>
  <block id="91171755730ad15e6d79b5cb6682a8f1" category="cell">모든 SAP 및 SAP HANA 콘텐츠에 대한 랜딩 페이지 추가</block>
  <block id="e5099bd65458f8a8556c830ac4759296" category="cell">2021년 2월 1일</block>
  <block id="09689218a7f330554f4e28a18e9e14a6" category="cell">NetApp VDS가 포함된 VDI, GPU 노드의 콘텐츠 추가</block>
  <block id="c487c48f1528e49e3cb129fdbdd79990" category="cell">2021년 6월 1일</block>
  <block id="868f7f9e78f90bcf0597030ffefd449b" category="cell">새로운 솔루션: NVIDIA DGX A100 시스템과 Mellanox Spectrum 이더넷 스위치(설계 및 구축)가 포함된 NetApp ONTAP AI</block>
  <block id="0663765430d1ca93138f13429aef7c37" category="cell">2020년 12월 22일</block>
  <block id="a4aae8f8849c453c6c67080c5d013301" category="cell">NetApp Solutions 저장소의 초기 릴리즈</block>
  <block id="b0522aa84a7257c47dd4b765cf173db9" category="open-title">AI/데이터 분석</block>
  <block id="f27edcc7a209983dc37cbcdb0df49ce7" category="open-title">가상 데스크톱</block>
  <block id="6fb2815b4c371ee082a84cc14539d4cb" category="open-title">엔터프라이즈 애플리케이션</block>
  <block id="18a2eb3f7faf7c44e3062e78cbeff089" category="inline-link-macro">SAP 솔루션 저장소</block>
  <block id="412b2ee09f2fbaf8cddb69ee6fe43a2e" category="admonition">SAP 및 SAP HANA 업데이트에 대한 자세한 내용은 의 각 솔루션에 대해 나와 있는 "업데이트 기록" 콘텐츠를 참조하십시오 <block ref="c4ed54a973fb1aa472c2443732d93c13" category="inline-link-macro-rx"></block>.</block>
  <block id="19751bc7a2f01e4ee4762945c90c0130" category="open-title">데이터 보호 및 AMP, 마이그레이션</block>
  <block id="408649df4ac74ae19e47eef7d060c5cb" category="open-title">솔루션 자동화</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">결론</block>
  <block id="7c0ea3e86521674f72e056d148d4f2ce" category="paragraph">NetApp 및 Run: AI는 이 기술 보고서에서 AI 워크로드 오케스트레이션을 단순화하기 위한 Run:AI 플랫폼과 함께 NetApp ONTAP AI 솔루션의 고유한 기능을 시연했습니다. 이전 단계에서는 딥 러닝을 위한 데이터 파이프라인 및 워크로드 오케스트레이션의 프로세스를 간소화하는 참조 아키텍처를 제공합니다. 이러한 솔루션을 구현하려는 고객은 NetApp 및 Run:AI에 자세한 내용을 문의하도록 권장합니다.</block>
  <block id="f797637684ff1290d12e5495dac050a6" category="inline-link-macro">다음: 섹션 4.8의 테스트 세부 정보</block>
  <block id="bbe251d46ac2a6899a2a4d5d0e331a43" category="paragraph"><block ref="bbe251d46ac2a6899a2a4d5d0e331a43" category="inline-link-macro-rx"></block></block>
  <block id="34d54070f7d06f04159ffbc3d9a3e082" category="doc">작업 환경을 구성합니다</block>
  <block id="8302b607de31151e5500de556070d9b9" category="paragraph">'노트북'의 et_env-example.ipynb를 'et_env.ipynb'로 복사합니다. 'et_env.ipynb'를 열고 편집합니다. 이 노트북은 자격 증명, 파일 위치 및 실행 드라이버에 대한 변수를 설정합니다.</block>
  <block id="3dc3cffc26096b89061a452cc7d16b6a" category="paragraph">위의 지침을 따르면 다음 단계만 변경할 수 있습니다.</block>
  <block id="26448fec50e405fb230427686eeb11f4" category="list-text">이과지오 서비스 대시보드에서 이 값을 'docker_registry'로 얻습니다</block>
  <block id="837784ac15c5cac463a4d016bac63db1" category="paragraph">예: dddocker-registry.default-tenant.app.clusterq.iguaziodev.com:80`</block>
  <block id="04dca9f72f7dfc6f87034c574f821a12" category="list-text">'admin'을 Iguazio 사용자 이름으로 변경합니다.</block>
  <block id="b2dea33f1195135f6905b7dd0ee58713" category="paragraph">''IGZ_container_path='/users/admin''</block>
  <block id="0ddaf8f981ee966dc3533de490c7ee4e" category="paragraph">다음은 ONTAP 시스템 연결 세부 정보입니다. Trident를 설치할 때 생성한 볼륨 이름을 포함합니다. 다음은 온-프레미스 ONTAP 클러스터에 대한 설정입니다.</block>
  <block id="dada97be0cb81e6518d92aa7112fa356" category="paragraph">Cloud Volumes ONTAP에 대한 설정은 다음과 같습니다.</block>
  <block id="586d20125924bc57624aaacc07973d5a" category="section-title">기본 Docker 이미지를 생성합니다</block>
  <block id="0ab24923db4855b821917446711104c9" category="paragraph">ML 파이프라인을 구축하는 데 필요한 모든 것이 Iguazio 플랫폼에 포함되어 있습니다. 개발자는 파이프라인을 실행하고 Jupyter Notebook에서 이미지 생성을 실행하는 데 필요한 Docker 이미지의 사양을 정의할 수 있습니다. 노트북 'create-images.ipynb'를 열고 모든 셀을 실행합니다.</block>
  <block id="3dc4e8abb0e99c6cf29451a16a891524" category="paragraph">이 노트북은 파이프라인에서 사용하는 두 개의 이미지를 만듭니다.</block>
  <block id="5446cc82e4c165e2700af830f8428d63" category="list-text">"iguazio/NetApp. ML 작업을 처리하는 데 사용됩니다.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">오류: 그래픽 이미지가 없습니다</block>
  <block id="61145f9d17e187b69bc41525b10aafe6" category="paragraph"><block ref="61145f9d17e187b69bc41525b10aafe6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62e9956426227f62abc9692954a5ad39" category="list-text">'NetApp/파이프라인' NetApp Snapshot 복사본을 처리하는 유틸리티를 포함합니다.</block>
  <block id="4050f795a12d7f83a545999c8a0d1905" category="paragraph"><block ref="4050f795a12d7f83a545999c8a0d1905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6677daf583d4c0cf5860927a024f278d" category="section-title">개별 Jupyter Notebooks를 검토합니다</block>
  <block id="6414e1c23e017075a375d3a531eab90c" category="paragraph">다음 표에는 이 작업을 만드는 데 사용한 라이브러리와 프레임워크가 나와 있습니다. 이러한 모든 구성 요소는 Iguazio의 역할 기반 액세스 및 보안 제어와 완벽하게 통합되어 있습니다.</block>
  <block id="da292beca00e0b352eade7a070855fd3" category="cell">라이브러리/프레임워크</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">설명</block>
  <block id="124d604ba0d3fd8e3d31c821b2a332f5" category="cell">MLRun</block>
  <block id="1c1491d01d96c08951ae2ac55fadf443" category="cell">머신 러닝/AI 파이프라인을 조립, 실행 및 모니터링할 수 있도록 Iguazio에서 관리합니다.</block>
  <block id="a2580bd6e044f86f4e39be2f59ee91da" category="cell">뉴클레오</block>
  <block id="2d753cbb7762fe25d15a2cda2ff84790" category="cell">서버를 사용하지 않는 함수 프레임워크가 Iguazio와 통합되었습니다. 이과지오(Iguazio)에서 관리하는 오픈 소스 프로젝트로도 사용할 수 있습니다.</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">Kubeflow</block>
  <block id="0bbee378f2697a1d0c184e76d2b206c6" category="cell">파이프라인을 구축하는 Kubernetes 기반 프레임워크 이과지오가 기여하는 오픈 소스 프로젝트이기도 합니다. 이과지오와 통합되어 나머지 인프라와의 보안 및 통합을 강화합니다.</block>
  <block id="c5fd214cdd0d2b3b4272e73b022ba5c2" category="cell">Docker 를 참조하십시오</block>
  <block id="849efb47ec760eb7c3c6b5848e740c3b" category="cell">Docker 레지스트리는 Iguazio 플랫폼에서 서비스로 실행됩니다. 이 설정을 변경하여 레지스트리에 연결할 수도 있습니다.</block>
  <block id="a38f73277b7341a709cf0cb57ebc4434" category="cell">NetApp Cloud Volumes를 참조하십시오</block>
  <block id="7279bb663993b77e219b4ca813326d77" category="cell">AWS에서 실행되는 Cloud Volumes를 통해 대량의 데이터에 액세스하고 Snapshot 복사본을 교육에 사용되는 데이터 세트의 버전으로 만들 수 있습니다.</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="cell">트라이던트</block>
  <block id="9953e13b783f3ad45d99187c955cb9f9" category="cell">Trident는 NetApp에서 관리하는 오픈 소스 프로젝트입니다. Kubernetes에서 스토리지 및 컴퓨팅 리소스와 통합할 수 있도록 지원합니다.</block>
  <block id="5fa4506d691373039fd2834939e582b3" category="paragraph">우리는 여러 노트북을 사용하여 ML 파이프라인을 구성하였습니다. 각 노트북은 파이프라인에 함께 들어가기 전에 개별적으로 테스트할 수 있습니다. 이 데모 애플리케이션의 배포 흐름에 따라 각 노트북을 개별적으로 다룹니다.</block>
  <block id="06a86c2506db8ef5fdac675c1352e3cf" category="paragraph">원하는 결과는 데이터의 스냅샷 복사본을 기반으로 모델을 교육하고 추론을 위해 모델을 구축하는 파이프라인입니다. 완료된 MLRun 파이프라인에 대한 블록 다이어그램이 다음 이미지에 나와 있습니다.</block>
  <block id="1d79eb753e06f2122a118408a14d6c51" category="paragraph"><block ref="1d79eb753e06f2122a118408a14d6c51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51b666fe429f998144ea4f2ce818cd60" category="section-title">데이터 생성 기능 구축</block>
  <block id="034015442bf8bf34c0e7e8149d35dae6" category="paragraph">이 섹션에서는 Nuclio 서버리스 기능을 사용하여 네트워크 장치 데이터를 생성하는 방법에 대해 설명합니다. 이 활용 사례는 파이프라인을 구축한 이과지오 클라이언트에서 수정되었으며 이과지오 서비스를 사용하여 네트워크 디바이스 장애를 모니터링하고 예측합니다.</block>
  <block id="2d024dd4dc0601ff2e4d0b81fcaec60a" category="inline-link">Nuclio 웹 사이트</block>
  <block id="59009d367371847f2042c59338282f4b" category="paragraph">네트워크 장치에서 오는 데이터를 시뮬레이션했습니다. Jupyter Notebook data-generator.ipynb를 실행하면 10분마다 실행되는 서버리스 기능이 생성되고 새 데이터가 있는 Parquet 파일이 생성됩니다. 함수를 배포하려면 이 전자 필기장의 모든 셀을 실행합니다. 를 참조하십시오<block ref="a9d48e85369982160b96d90770d878d1" category="inline-link-rx"></block> 이 노트북에서 잘 모르는 구성 요소를 검토합니다.</block>
  <block id="fa0c06ebcd647f13ce81472307615ee3" category="paragraph">함수를 생성할 때 다음 주석이 있는 셀은 무시됩니다. 노트북의 모든 셀은 기능의 일부로 간주됩니다. '%nuclio magic'을(를) 활성화하려면 Nuclio 모듈을 가져옵니다.</block>
  <block id="c2b253a6bc491b37027772dba5f0b4e7" category="paragraph">기능에 대한 사양에서는 함수가 실행되는 환경, 함수가 트리거되는 방식 및 사용되는 리소스를 정의했습니다.</block>
  <block id="95b0eb5f892f7b0bcb3ec7dbb9058c02" category="paragraph">INIT_CONTEXT 함수는 함수 초기화 시 Nuclio Framework에 의해 호출됩니다.</block>
  <block id="1aab9637db54631d95ec5901bfda0947" category="paragraph">함수에 없는 코드는 함수가 초기화될 때 호출됩니다. 이 함수를 호출하면 처리기 함수가 실행됩니다. 처리기의 이름을 변경하고 함수 사양에서 지정할 수 있습니다.</block>
  <block id="94be7a657ecb54ef7337030d9dd78b70" category="paragraph">배포 전에 노트북에서 기능을 테스트할 수 있습니다.</block>
  <block id="01237c05459839293bfcd5a3beb1364f" category="paragraph">이 기능은 노트북에서 배포하거나 CI/CD 파이프라인에서 배포할 수 있습니다(이 코드 조정).</block>
  <block id="c697561ec27606d29683f7fc5fb3846d" category="section-title">파이프라인 노트북</block>
  <block id="83041c5547fb0ad965936febfc41508d" category="paragraph">이 노트북은 이 설정을 위해 개별적으로 실행할 수 없습니다. 이 내용은 각 전자 필기장에 대한 검토일 뿐입니다. 파이프라인을 구성하는 요소로 호출한 것입니다. 개별적으로 실행하려면 MLRun 설명서를 검토하여 Kubernetes 작업으로 실행합니다.</block>
  <block id="c16b208e4ffb938f4008373dea5fb4ec" category="section-title">SNAP_CV.iynb</block>
  <block id="eeb06194a969eee5616e56b449a99306" category="paragraph">이 노트북은 파이프라인의 시작 부분에 있는 Cloud Volume Snapshot 복사본을 처리합니다. 볼륨의 이름을 파이프라인 컨텍스트로 전달합니다. 이 노트북은 스냅샷 복사본을 처리하기 위해 셸 스크립트를 호출합니다. 파이프라인에서 실행되는 동안 실행 컨텍스트에는 실행에 필요한 모든 파일을 찾는 데 도움이 되는 변수가 포함되어 있습니다. 이 코드를 작성하는 동안 개발자는 이 코드를 실행하는 컨테이너의 파일 위치에 대해 걱정할 필요가 없습니다. 나중에 설명했듯이 이 응용 프로그램은 모든 종속성을 포함하여 배포되며 실행 컨텍스트를 제공하는 파이프라인 매개 변수의 정의입니다.</block>
  <block id="dc82b570ec10aa261c20bf4828af24c1" category="paragraph">생성된 스냅샷 복사본 위치는 파이프라인의 단계에서 사용할 MLRun 컨텍스트에 배치됩니다.</block>
  <block id="7f609b3599e86a8f1b83bde97709ba37" category="paragraph">다음 세 개의 노트북은 병렬로 실행됩니다.</block>
  <block id="d1839287f93e09936af234173d03d6b7" category="section-title">데이터 준비 .ipynb</block>
  <block id="dbe6ca7c47e3dc8cbd3a4956e684b761" category="paragraph">원시 메트릭을 기능으로 전환하여 모델 교육을 활성화해야 합니다. 이 노트북은 Snapshot 디렉토리에서 원시 메트릭을 읽고 모델 훈련을 위한 기능을 NetApp 볼륨에 씁니다.</block>
  <block id="dab65fbdf0ed5ce626558d99e83c618f" category="paragraph">파이프라인 컨텍스트에서 실행되는 경우 입력 DATA_DIR에 스냅샷 복사 위치가 포함됩니다.</block>
  <block id="4636df8c7ba383c5f135c7ae8f2ef772" category="section-title">ipynb 설명</block>
  <block id="43099d46867c7c0cc922fdd3e026d029" category="paragraph">수신 메트릭을 시각화하기 위해 Kubeflow 및 MLRun UI를 통해 사용할 수 있는 플롯 및 그래프를 제공하는 파이프라인 단계를 배포합니다. 각 실행에는 이 시각화 도구의 고유 버전이 있습니다.</block>
  <block id="7fd47125b80c0e6241052a47dcb41b98" category="section-title">Deploy-feature-function.ipynb</block>
  <block id="684eb641c7a322c328f8ea91cd482b0d" category="paragraph">NetApp은 이상 징후를 찾기 위한 메트릭을 지속적으로 모니터링합니다. 이 노트북은 들어오는 메트릭에 대한 예측을 실행하는 데 필요한 기능을 생성하는 서버리스 기능을 생성합니다. 이 노트북은 함수 생성을 호출합니다. 기능 코드는 노트북 data-prep.ipynb에 있다. 이러한 목적을 위해 파이프라인에서 한 단계씩 동일한 전자 필기장을 사용합니다.</block>
  <block id="1c475141d16ada0e53ddb14047963024" category="section-title">훈련.iynb</block>
  <block id="43b6984a9b2a7863061833c96be2b851" category="paragraph">피처를 작성한 후 모델 교육을 시작합니다. 이 단계의 출력은 추론을 위해 사용할 모델입니다. 또한 각 실행(실험)을 추적하기 위해 통계를 수집합니다.</block>
  <block id="a6858cae929a8eed6e9c9d6cfa9befac" category="paragraph">예를 들어 다음 명령은 해당 실험의 컨텍스트에 정확도 점수를 입력합니다. 이 값은 Kubeflow 및 MLRun에서 볼 수 있습니다.</block>
  <block id="9d1126b5d7690c0eb46dd7713822680e" category="section-title">deploy-추론-function.ipynb입니다</block>
  <block id="827ebf8bb3ee1798b5394ecd2a8bb3ae" category="paragraph">파이프라인의 마지막 단계는 모델을 서버리스 기능으로 구축하여 연속 추론을 수행하는 것입니다. 이 노트북은 'nuclio-추론-function.ipynb'에 정의된 서버리스 기능의 생성을 호출합니다.</block>
  <block id="4d2c908b5247626d682903dc9527bd05" category="section-title">파이프라인 검토 및 구축</block>
  <block id="6c8673acfb6249793bed69954ca16a9b" category="paragraph">파이프라인에서 모든 노트북을 함께 실행할 경우 실험을 지속적으로 실행하여 새로운 측정 지표를 기준으로 모델의 정확성을 재평가할 수 있습니다. 먼저 파이프라인 iptynb 노트북을 엽니다. NetApp과 Iguazio가 이 ML 파이프라인 구축을 단순화하는 방법을 자세히 설명 드리겠습니다.</block>
  <block id="50d4decae4f0f08e83a1bd8342bd6ef1" category="paragraph">MLRun을 사용하여 컨텍스트를 제공하고 파이프라인의 각 단계에 대한 리소스 할당을 처리합니다. MLRun API 서비스는 Iguazio 플랫폼에서 실행되며 Kubernetes 리소스와 상호 작용하는 지점입니다. 각 개발자는 리소스를 직접 요청할 수 없습니다. API는 요청을 처리하고 액세스 제어를 활성화합니다.</block>
  <block id="c7c5ccf69a87e301b134dcfdf46ab307" category="paragraph">파이프라인은 NetApp Cloud Volumes 및 온프레미스 볼륨과 함께 사용할 수 있습니다. Cloud Volumes를 사용하기 위해 이 데모를 구축했지만 코드에서 온프레미스 실행 옵션을 확인할 수 있습니다.</block>
  <block id="ce16d064e13fffda0ff2a07c50276f33" category="paragraph">Jupyter 노트북을 Kubeflow 단계로 전환하는 데 필요한 첫 번째 작업은 코드를 함수로 전환하는 것입니다. 기능에는 해당 노트북을 실행하는 데 필요한 모든 사양이 있습니다. 전자 필기장을 아래로 스크롤하면 파이프라인의 모든 단계에 대한 기능을 정의하는 것을 볼 수 있습니다.</block>
  <block id="8bbbd384e919f705f071525a96cdfaec" category="cell">노트북의 일부입니다</block>
  <block id="5d75cd50687084d681964f5c6ee8a73a" category="cell">code_to_function&gt; (MLRun 모듈의 일부)</block>
  <block id="eef456f018469b2d403742d05e33a5dd" category="cell">함수 이름: 프로젝트 이름. 모든 프로젝트 아티팩트를 구성하는 데 사용됩니다. 이것은 MLRun UI에서 볼 수 있습니다. 있습니다. 이 경우에는 Kubernetes 작업입니다. 이는 Dask, MPI, 스파크k8s 등이 될 수 있습니다. 자세한 내용은 MLRun 설명서를 참조하십시오. 파일. 전자 필기장의 이름입니다. Git(HTTP)의 위치일 수도 있습니다.</block>
  <block id="78805a221a988e79ef3f42d7c5bfd418" category="cell">이미지</block>
  <block id="d0161cbbc56081c803c919679b76b846" category="cell">이 단계에서 사용 중인 Docker 이미지의 이름입니다. 앞에서 create-image.ipynb 전자 필기장으로 이 기능을 만들었습니다.</block>
  <block id="28bb8862d962b462f621d9098de311cd" category="cell">volume_mounts 및 volume</block>
  <block id="a6841da965bfb59838d367b9fdc30a8c" category="cell">런타임에 NetApp Cloud Volume을 마운트하기 위한 세부 정보</block>
  <block id="5d9261bc63dfeef8d26c807e36a9daa4" category="paragraph">단계에 대한 매개 변수도 정의합니다.</block>
  <block id="fcd242cd0d87d4de3be34f843180bdb0" category="paragraph">모든 단계에 대한 함수 정의가 있으면 파이프라인을 구성할 수 있습니다. 우리는 이 정의를 만들기 위해 'kfp' 모듈을 사용합니다. MLRun을 사용하는 것과 자체적으로 구축하는 것의 차이점은 코딩의 단순화 및 단축입니다.</block>
  <block id="f02b57d2fbd61d7629e76438ba68f7a1" category="paragraph">정의한 기능은 MLRun의 AS_STEP 기능을 이용하여 STEP 부품으로 변한다.</block>
  <block id="8859e75c5bfd3a8ea5a783296d71b795" category="section-title">스냅샷 단계 정의</block>
  <block id="dabb827ac33da3a8d8a2384874221aab" category="paragraph">스냅샷 기능을 시작하고 v3io를 소스로 출력 및 마운트합니다.</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">매개 변수</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">세부 정보</block>
  <block id="422ac26927e8ad3d6b30617226e26c2a" category="cell">새 작업</block>
  <block id="b954691c9a06ef7281bf4c836e7684f1" category="cell">NewTask 는 함수 실행의 정의입니다.</block>
  <block id="7871261404e7a8d93339696184b243b9" category="cell">(MLRun 모듈)</block>
  <block id="4522319a8fbbe0a85c82e604047dfe6c" category="cell">핸들러. 호출할 Python 함수의 이름입니다. 전자 필기장에서 이름 처리기를 사용했지만 필수 사항은 아닙니다. 매개 변수 실행에 전달된 매개 변수. 코드 안에서 context.get_param('parameter')을 사용하여 값을 가져옵니다.</block>
  <block id="6cebb60f71d9de65143ade7a8388e27a" category="cell">AS_STEP</block>
  <block id="070faabab806ce863279f5bd38452cc4" category="cell">이름. Kubeflow 파이프라인 단계의 이름입니다. 출력. 이 값은 완료 시 단계에서 사전에 추가하는 값입니다. SNAP_CV.iynb 노트북을 살펴보십시오. mount_v3io(). 이를 통해 파이프라인을 실행하는 사용자에 대해 /User를 마운트하는 단계를 구성합니다.</block>
  <block id="a8aff967e1649a1c82ea607c881e8091" category="cell">입력</block>
  <block id="6f1ba99c8ee685047e0fa3c32349a01f" category="cell">이전 단계의 출력을 단계별로 전달할 수 있습니다. 이 경우 snap.outputs ['sapVolumeDetails']는 스냅 단계에서 생성한 스냅샷 복사본의 이름입니다.</block>
  <block id="a399d9e54dd5dc35c6b455d995702175" category="cell">아웃_경로</block>
  <block id="026446ea82508e4c9f41609b3484b4cb" category="cell">MLRun 모듈 log_artifacts를 사용하여 생성하는 아티팩트를 배치할 위치입니다.</block>
  <block id="2fe8889e7fb9545ea383ff3c0451cabf" category="paragraph">pipeline.ipynb는 위에서 아래로 실행할 수 있다. 그런 다음 Iguazio 대시보드에서 Pipelines 탭으로 이동하여 Iguazio 대시보드 파이프라인 탭에 표시된 진행 상황을 모니터링할 수 있습니다.</block>
  <block id="74dec5a93e3c1ccb06f26ebc6f9401fb" category="paragraph"><block ref="74dec5a93e3c1ccb06f26ebc6f9401fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f47db69a9e60b47a1c8f7800753f6b57" category="paragraph">모든 러닝에서 훈련 단계의 정확성을 기록했기 때문에 훈련 정확도 기록에서도 볼 수 있듯이 각 실험마다 정확한 기록을 가지고 있습니다.</block>
  <block id="5bb7a1a5b810ce843cd4d41a7137ce26" category="paragraph"><block ref="5bb7a1a5b810ce843cd4d41a7137ce26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9ebd260b4ed60a239b8228fe68b2dbc" category="paragraph">스냅샷 단계를 선택하면 이 실험을 실행하는 데 사용된 스냅샷 복사본의 이름을 볼 수 있습니다.</block>
  <block id="1d231b2e1da6122607105ce52f87a763" category="paragraph"><block ref="1d231b2e1da6122607105ce52f87a763" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc578a2d3b019d646da18c9172282dc" category="paragraph">설명된 단계에는 우리가 사용한 지표를 탐색할 수 있는 시각적 인공물이 있습니다. 다음 이미지와 같이 전체 플롯을 보기 위해 확장할 수 있습니다.</block>
  <block id="ffb599ed438d33d337e7cca9a1fbaf07" category="paragraph"><block ref="ffb599ed438d33d337e7cca9a1fbaf07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89238f00748675db057567546f67c2c5" category="paragraph">또한 MLRun API 데이터베이스는 프로젝트별로 구성된 각 실행의 입력, 출력 및 아티팩트를 추적합니다. 각 시리즈의 입력, 출력 및 아티팩트의 예는 다음 영상에서 확인할 수 있습니다.</block>
  <block id="a8baa83f88edfb0fceafeda75819cb5f" category="paragraph"><block ref="a8baa83f88edfb0fceafeda75819cb5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c6050fe85d7b5528bc8356c88eab725" category="paragraph">각 직무마다 추가 세부 정보를 저장합니다.</block>
  <block id="8683624a37c6626765321b5cc2f60954" category="paragraph"><block ref="8683624a37c6626765321b5cc2f60954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f02f72c9470e67a8b3c5f9054b0a32c" category="inline-link">MLRun GitHub 사이트</block>
  <block id="01661b1e0825da7434573266df1672e0" category="paragraph">MLRun에 대한 자세한 내용은 이 문서에서 다룰 수 있는 것보다 많습니다. 단계와 함수의 정의를 비롯한 Al 아티팩트는 API 데이터베이스에 저장하고 버전을 지정한 후 개별 또는 전체 프로젝트로 호출할 수 있습니다. 프로젝트를 저장하고 나중에 사용할 수 있도록 Git에 푸시할 수도 있습니다. 자세한 내용은 에서 확인하시기 바랍니다<block ref="92ae596fd8e402850e22f59a73ed3a44" category="inline-link-rx"></block>.</block>
  <block id="43486dfb907f148e40f3719f314caeb4" category="inline-link-macro">다음: Grafana 대시보드 배포</block>
  <block id="0670d6ac4e77f5862afcc2fde43bcc72" category="paragraph"><block ref="0670d6ac4e77f5862afcc2fde43bcc72" category="inline-link-macro-rx"></block></block>
  <block id="4b737f96f31f513a87adcf43b83ec3a1" category="summary">이 페이지에서는 AKS 클러스터를 설정하는 데 필요한 단계를 설명합니다.</block>
  <block id="a81532d943508d42466c22d8d87bb4b8" category="doc">AKS 클러스터를 설치하고 설정합니다</block>
  <block id="ce3e1770b7ff86cfbc3a30a3e3ea87da" category="inline-link-macro">이전: 클릭률 예측 사용 사례 요약</block>
  <block id="80bf56f9bff31f7459309b983fbf8116" category="paragraph"><block ref="80bf56f9bff31f7459309b983fbf8116" category="inline-link-macro-rx"></block></block>
  <block id="50f7d8213ee52350926ec407074e68f1" category="inline-link">AKS 클러스터를 생성합니다</block>
  <block id="40e1cc9f8d9321cbe9c1ef090f926a2b" category="paragraph">AKS 클러스터를 설치 및 설정하려면 웹 페이지를 참조하십시오<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block> 그런 다음 다음 다음 단계를 완료합니다.</block>
  <block id="ad4af0825dd4979b7f48ae5ba031b23a" category="list-text">노드 유형(시스템 [CPU] 또는 작업자 [GPU] 노드)을 선택할 때 다음을 선택합니다.</block>
  <block id="5a244a81080ee9fc08696fcbd45284e5" category="list-text">기본 시스템 노드는 표준 DS2v2('agentpool' 기본 3개 노드)여야 합니다.</block>
  <block id="f3449ebebbf547282aa0562015bd360d" category="list-text">그런 다음 이름이 "gpupool"인 사용자 그룹(GPU 노드의 경우)에 대해 작업자 노드 Standard_NC6s_v3 풀(최소 3개 노드)을 추가합니다.</block>
  <block id="d3d648c68589ef99efb6ad3ec15d1beb" category="paragraph"><block ref="d3d648c68589ef99efb6ad3ec15d1beb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2efc2b95642d4bcc76c710a3826225c" category="list-text">배포에는 5~10분이 소요됩니다. 완료되면 Connect to Cluster를 클릭합니다.</block>
  <block id="31797d7013400422e5d589ae3d91c79a" category="list-text">새로 생성된 AKS 클러스터에 연결하려면 로컬 환경(랩톱/PC)에서 다음을 설치합니다.</block>
  <block id="87e009e80a344ecb598be4c4bbe01c79" category="inline-link">특정 OS에 대한 지침이 제공됩니다</block>
  <block id="13a6d4f4230d0a1569b719c15884d447" category="list-text">를 사용하는 Kubernetes 명령줄 툴입니다<block ref="ad2337a31b7d16867fc954b03de661bd" category="inline-link-rx"></block></block>
  <block id="24a109d7bba4f8808eeb0bcf64d4357b" category="inline-link">Azure CLI를 설치합니다</block>
  <block id="7feed8a8a6c680e7beeca052b9fc9ed0" category="list-text">문서에 설명된 대로 Azure CLI를 사용할 수 있습니다.<block ref="8e2043d81b680dba324c5a2abbee7b3f" category="inline-link-rx"></block></block>
  <block id="d33a4b8acf4001a4b35a2186fd020432" category="list-text">터미널에서 AKS 클러스터에 액세스하려면 'az login'을 입력하고 자격 증명을 입력합니다.</block>
  <block id="3394029cd334ed00686c86c088d73c24" category="list-text">다음 두 명령을 실행합니다.</block>
  <block id="402ff6cff3671c1f49dc4af765835c14" category="list-text">Azure CLI:kubeck get nodes를 입력합니다.</block>
  <block id="4e5d89028ffbf65df6693ef1affd6573" category="list-text">다음 예와 같이 6개 노드가 모두 가동되어 실행 중인 경우 AKS 클러스터가 로컬 환경에 준비 및 연결됩니다</block>
  <block id="6b935f22371497abfe5378d4446df0da" category="paragraph"><block ref="6b935f22371497abfe5378d4446df0da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e57b7e32f49f0297d6c7524d1da1b3c0" category="inline-link-macro">다음: Azure NetApp Files에 대해 위임된 서브넷을 만듭니다.</block>
  <block id="46b5942a33ef6a130ca5fee3f6017bec" category="paragraph"><block ref="46b5942a33ef6a130ca5fee3f6017bec" category="inline-link-macro-rx"></block></block>
  <block id="ecb81ab37e1d2a7ed6dfce3807622e3d" category="summary">이 섹션에서는 RUN AI Orchestrator를 사용하여 규모에 따라 차선 감지 분산 교육을 수행할 수 있는 플랫폼을 설정하는 방법에 대해 자세히 설명합니다.</block>
  <block id="0714a752696f8feed939bbf52a6214f7" category="doc">차선 감지 – AI를 통한 분산 훈련</block>
  <block id="dbf10b854b8b7fc90297279e7ad0f745" category="paragraph">이 섹션에서는 RUN:AI Orchestrator를 사용하여 규모에 따라 차선 감지 분산 교육을 수행할 수 있는 플랫폼을 설정하는 방법에 대해 자세히 설명합니다. 모든 솔루션 요소의 설치와 해당 플랫폼에서 분산된 교육 작업을 실행하는 방법에 대해 설명합니다. ML 버전 관리는 데이터 및 모델 재현성을 달성하기 위한 Run:AI 실험과 연결된 NetApp SnapshotTM을 사용하여 완료됩니다. ML 버전 관리는 모델 추적, 팀 구성원 간 작업 공유, 결과 재현성, 새로운 모델 버전을 운영 환경에 롤링하며 데이터 관리에 중요한 역할을 합니다. NetApp ML 버전 제어(Snapshot)는 각 실험과 관련된 데이터, 훈련된 모델 및 로그의 시점 버전을 캡처할 수 있습니다. 풍부한 API 지원을 통해 run:AI 플랫폼과 쉽게 통합할 수 있습니다. 교육 상태에 따라 이벤트를 트리거하기만 하면 됩니다. 또한, Kubernetes(K8s) 상에서 실행 중인 코드나 컨테이너의 아무 것도 변경하지 않고 전체 실험의 상태를 포착해야 합니다.</block>
  <block id="25d19977e35c6d286c5b051982ae3f3c" category="paragraph">마지막으로, 이 기술 보고서에서는 AKS의 여러 GPU 지원 노드에 대한 성능 평가를 마무리합니다.</block>
  <block id="1987a7039dccb848f2e8ce693ba3faff" category="section-title">TuSimple 데이터 세트를 사용하여 차선 감지 사용 사례에 대한 분산 교육</block>
  <block id="f75a7cb3d80e7be148c1ce86a4347011" category="paragraph">이 기술 보고서에서 분산된 교육은 차선 감지를 위한 TuSimple 데이터 세트에 대해 수행됩니다. Horovod는 AKS를 통해 Kubernetes 클러스터의 여러 GPU 노드에 대해 동시에 데이터 분산 교육을 수행하기 위한 교육 코드에 사용됩니다. 코드는 TuSimple 데이터 다운로드 및 처리를 위한 컨테이너 이미지로 패키징됩니다. 처리된 데이터는 NetApp Trident 플러그인에서 할당한 영구 볼륨에 저장됩니다. 교육에서는 하나 이상의 컨테이너 이미지가 생성되고 데이터를 다운로드하는 동안 생성된 영구 볼륨에 저장된 데이터를 사용합니다.</block>
  <block id="58b4798157820b4e4415d8136cf60fe9" category="paragraph">데이터 및 교육 작업을 제출하려면 RUN:AI를 사용하여 리소스 할당 및 관리를 오케스트레이션하십시오. Run: AI를 사용하면 Horovod에 필요한 MPI(Message Passing Interface) 작업을 수행할 수 있습니다. 이 레이아웃을 통해 여러 GPU 노드가 서로 통신하여 각 교육 미니 일괄 처리 후 교육 가중치를 업데이트할 수 있습니다. 또한 UI 및 CLI를 통해 교육을 모니터링할 수 있으므로 실험 진행 상황을 쉽게 모니터링할 수 있습니다.</block>
  <block id="ecbeff08f5ec15c6952355b518d4ae02" category="paragraph">NetApp Snapshot은 교육 코드 내에 통합되어 모든 실험에 대한 데이터 상태 및 훈련 모델을 캡처합니다. 이 기능을 사용하면 사용된 데이터 및 코드의 버전과 생성된 관련 교육 모델을 추적할 수 있습니다.</block>
  <block id="63addc90b28c066bd235c900fed65314" category="section-title">AKS 설정 및 설치</block>
  <block id="55b295c729173e8c0c745bb036b03270" category="paragraph">AKS 클러스터의 설정 및 설치는 로 이동하십시오<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block>. 그런 다음 다음 다음 일련의 단계를 수행합니다.</block>
  <block id="8f9d847fad9782b080de76b0161b1c45" category="list-text">노드 유형(시스템(CPU) 또는 작업자(GPU) 노드인지 여부)을 선택할 때 다음을 선택합니다.</block>
  <block id="957d1a35f975177c3fd161490f3e2d83" category="list-text">S tandard_DS2_v2 크기의 1차 시스템 노드 agentpool을 추가합니다. 기본 3개 노드를 사용합니다.</block>
  <block id="8853a13db2e2a03cb5b2f1186fbcd0a6" category="list-text">Standard_NC6s_v3 풀 크기로 작업자 노드 'gpupool'을 추가합니다. GPU 노드에 대해 최소 3개의 노드를 사용합니다.</block>
  <block id="5085043d6dea89934a2e516fc46f891a" category="paragraph"><block ref="5085043d6dea89934a2e516fc46f891a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633b880bff72a9f1c1114df31dec55bf" category="admonition">배포에는 5~10분이 소요됩니다.</block>
  <block id="f55bb34768c41f91318fb57b85c1def9" category="inline-link">도구를 설치합니다</block>
  <block id="6369fc9d36c9d56cbebefdeccda5fbff" category="list-text">구축이 완료되면 Connect to Cluster를 클릭합니다. 새로 생성한 AKS 클러스터에 연결하려면 로컬 환경(랩톱/PC)에서 Kubernetes 명령줄 도구를 설치하십시오. 를 방문하십시오<block ref="bcd577f96ff7023ec6fd5c904f040896" category="inline-link-rx"></block> OS에 따라 설치합니다.</block>
  <block id="811c47e56617f97db3579bc32a9085c9" category="inline-link">로컬 환경에 Azure CLI를 설치합니다</block>
  <block id="ea5d45554a3e9cb9cbc0ddea4c228b28" category="list-text"><block ref="2db79c584144175dd0bb69b6c7045fc9" category="inline-link-rx"></block>.</block>
  <block id="825ca3bff78c42ec87920dfbce105fae" category="list-text">터미널에서 AKS 클러스터에 액세스하려면 먼저 'az login'을 입력하고 자격 증명을 입력하십시오.</block>
  <block id="193937b265ce655417f00a79334d3937" category="list-text">Azure CLI에서 다음 명령을 입력합니다.</block>
  <block id="cbf78d8bb0be543834c56e61560773b0" category="admonition">여기에 표시된 대로 6개 노드가 모두 가동되어 실행 중이면 AKS 클러스터가 로컬 환경에 연결되고 준비됩니다.</block>
  <block id="e8085ec7505cfe6f3cfbe2c2628386dc" category="paragraph"><block ref="e8085ec7505cfe6f3cfbe2c2628386dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0143a2caee1b9ab090de587206b65fe6" category="section-title">Azure NetApp Files에 대해 위임된 서브넷을 생성합니다</block>
  <block id="450cf7e7f8262fdaa3454c2e11aad687" category="paragraph">Azure NetApp Files에 대해 위임된 서브넷을 만들려면 다음 단계를 수행하십시오.</block>
  <block id="0ca30ab1eb5e523356720465eb7439c8" category="list-text">Azure 포털 내의 가상 네트워크로 이동합니다. 새로 생성한 가상 네트워크를 찾습니다. 여기에 표시된 대로 AKS-VNET와 같은 접두사가 있어야 합니다. 가상 네트워크의 이름을 클릭합니다.</block>
  <block id="ce0c628aca3577055043c7f8364600d9" category="paragraph"><block ref="ce0c628aca3577055043c7f8364600d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25157709e5a253560f5ec68b8262563c" category="list-text">서브넷 을 클릭하고 상단 도구 모음에서 + 서브넷 을 선택합니다.</block>
  <block id="d9bf5876b80dbf558587f06630e3915c" category="paragraph"><block ref="d9bf5876b80dbf558587f06630e3915c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a07ef5dbc59d5ba150de82d519fb4f8" category="list-text">서브넷에 ANF.SN과 같은 이름을 입력하고 Subnet Delegation 제목에서 Microsoft.NetApp/volumes 을 선택합니다. 다른 어떤 것도 변경하지 마십시오. 확인 을 클릭합니다.</block>
  <block id="a8ccea52e17d54aea1295a99ab4d5c2e" category="paragraph"><block ref="a8ccea52e17d54aea1295a99ab4d5c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d182b62071ada1a29e4f9c26487c1121" category="paragraph">Azure NetApp Files 볼륨은 애플리케이션 클러스터에 할당되며 Kubernetes에서 영구 볼륨 청구(PVC)로 사용됩니다. 또한, 이러한 할당을 통해 볼륨을 Jupyter 노트북, 서버리스 기능 등과 같은 다양한 서비스에 유연하게 매핑할 수 있습니다</block>
  <block id="a74ff852d3b3b8447b0306018a76c4f1" category="paragraph">서비스 사용자는 다양한 방법으로 플랫폼의 스토리지를 사용할 수 있습니다. Azure NetApp Files의 주요 이점은 다음과 같습니다.</block>
  <block id="a7c5a83cc4ccf14374e496bcbb4363f5" category="list-text">사용자에게 스냅샷을 사용할 수 있는 기능을 제공합니다.</block>
  <block id="ea437fe76a4bba5bf335daccbbd24b50" category="list-text">사용자가 Azure NetApp Files 볼륨에 대량의 데이터를 저장할 수 있도록 지원</block>
  <block id="cedebf66380d43f58c07dfb1d4d686a6" category="list-text">대규모 파일 세트에서 모델을 실행할 때 Azure NetApp Files 볼륨의 성능 이점을 확보</block>
  <block id="75ab13308585f62c3cd57a246d0e0c64" category="section-title">Azure NetApp Files 설정</block>
  <block id="8c060d9ae24c7bc4518e54cd5ed13098" category="inline-link">QuickStart: Azure NetApp Files를 설정하고 NFS 볼륨을 생성합니다</block>
  <block id="fd01c32c80d631ed4bebff78fa83b23e" category="paragraph">Azure NetApp Files 설정을 완료하려면 먼저 에 설명된 대로 구성해야 합니다<block ref="2f4e63e538c7dd311b18db058621cef8" category="inline-link-rx"></block>.</block>
  <block id="e26f032bd6f7f5636860d6b94ac84859" category="paragraph">하지만 Trident를 통해 볼륨을 생성하므로 Azure NetApp Files용 NFS 볼륨을 생성하는 단계를 생략할 수 있습니다. 계속하기 전에 다음 사항을 확인하십시오.</block>
  <block id="e953b5e281d40c5db3cc047889eec4f2" category="inline-link">Azure NetApp Files 및 NetApp 리소스 공급자에 등록(Azure 클라우드 셸 이용)</block>
  <block id="3b46d13fb20fe6a92456f742b5732774" category="list-text"><block ref="527fb205c939c551ed93f597562513fb" category="inline-link-rx"></block>.</block>
  <block id="d0652e942d3d4b469179248d72ccaa5c" category="inline-link">Azure NetApp Files에서 계정을 생성했습니다</block>
  <block id="82a51bbfec23ca7366c216813caeacc8" category="list-text"><block ref="874637dbfce24ba5a63adadd91968dc9" category="inline-link-rx"></block>.</block>
  <block id="02209b9e3a221b39bf0ce87641e7afc6" category="inline-link">용량 풀을 설정합니다</block>
  <block id="7b4cb99ad8c150ff95b1a65d0f0524cc" category="list-text"><block ref="0fa33cef09dfad4c8795f42dd9dd5248" category="inline-link-rx"></block> (요구사항에 따라 최소 4TiB 표준 또는 프리미엄).</block>
  <block id="1c7c9057bf4f7aee40c5a117c160c0fd" category="section-title">AKS 가상 네트워크 및 Azure NetApp Files 가상 네트워크 피어링</block>
  <block id="998069ab494c49ade2cc77591c02d9fa" category="paragraph">다음으로 다음 단계를 수행하여 Azure NetApp Files VNET를 사용하여 AKS 가상 네트워크(VNET)를 수행하십시오.</block>
  <block id="bf12dce8dcc6febfeddec5ed2570e7d7" category="list-text">Azure 포털 맨 위의 검색 상자에 가상 네트워크를 입력합니다.</block>
  <block id="3f961f79effdf0aa37042e1733ee53ef" category="list-text">VNET AKS-VNET-NAME을 클릭한 다음 검색 필드에 Pebsearch를 입력합니다.</block>
  <block id="0249aa06ef3e10e8754106189b542be4" category="list-text">추가 를 클릭하고 아래 표에 제공된 정보를 입력합니다.</block>
  <block id="6f16a5f8ff5d75ab84c018adacdfcbb7" category="cell">필드에 입력합니다</block>
  <block id="88645c17102d75583e93db9aa716b012" category="cell">값 또는 설명입니다</block>
  <block id="f80824cb9ab9f704542dec0c71c5f38b" category="cell">피어링 링크 이름</block>
  <block id="5d43607a5a0ebb50f3ea9348485daa15" category="cell">AKS-VNET-NAME_to_anf</block>
  <block id="62912b52e584278e26870d9e5092e723" category="cell">SubscriptionID(하위 스크립트 ID)</block>
  <block id="7d97336a164d9ce685e88a121141b189" category="cell">피어링을 사용하는 Azure NetApp Files VNET의 구독</block>
  <block id="82a60e720574cf435dda0a03976e8323" category="cell">VNET 피어링 파트너</block>
  <block id="d2ade9376eb8b87db099330d20c4f180" category="cell">Azure NetApp Files VNET</block>
  <block id="5b92ad691782a9e4cc701e479c90997f" category="admonition">모든 별표 이외의 섹션은 기본적으로 그대로 둡니다</block>
  <block id="0e5883528161213f3edc02dd718e1693" category="list-text">추가 또는 확인 을 클릭하여 가상 네트워크에 피어링을 추가합니다.</block>
  <block id="12eee9bf8836d675f26602260016f7da" category="inline-link">가상 네트워크 피어링을 생성, 변경 또는 삭제합니다</block>
  <block id="fa1f15d2aebd0592f338ea9f49e06377" category="paragraph">자세한 내용은 를 참조하십시오<block ref="610fa6db13a2eefe4a391b16732fbbf0" category="inline-link-rx"></block>.</block>
  <block id="91d2f55da5f23abbcf1a0656897d101b" category="paragraph">Trident는 NetApp에서 애플리케이션 컨테이너 영구 스토리지를 위해 유지하는 오픈 소스 프로젝트입니다. Trident는 Pod 자체로 실행되는 외부 공급자 컨트롤러로 구축되어 볼륨을 모니터링하고 프로비저닝 프로세스를 완전히 자동화했습니다.</block>
  <block id="4088b2a65b2a3182209479dced5e78c5" category="paragraph">NetApp Trident를 사용하면 교육 데이터 세트 및 교육 받은 모델을 저장하기 위한 영구 볼륨을 생성하여 K8s와 원활하게 통합할 수 있습니다. 이 기능을 사용하면 데이터 과학자와 데이터 엔지니어가 데이터 세트를 수동으로 저장하고 관리해야 하는 번거로움 없이 K8s를 더 쉽게 사용할 수 있습니다. 또한 Trident는 논리적 API 통합을 통해 데이터 관리 관련 작업을 통합하므로 데이터 과학자가 새로운 데이터 플랫폼 관리에 대해 배울 필요가 없습니다.</block>
  <block id="b8b9eab8c1ed7b79387652490f5724ec" category="section-title">Trident를 설치합니다</block>
  <block id="77dc68d199719a4b8f5eba742ecb7056" category="paragraph">Trident 소프트웨어를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="2f2e9ef9449e2f31756b1d3683a207b3" category="inline-link">첫 번째 설치 Helm</block>
  <block id="089f0e488d4e2b1a4b02d6d6b638c9d3" category="list-text"><block ref="b3c10ddb3b7f0e3e121ce123f60cc497" category="inline-link-rx"></block>.</block>
  <block id="e12559703ec38e80de7b94fecc84a043" category="list-text">Trident 21.01.1 설치 프로그램을 다운로드하고 압축을 풉니다.</block>
  <block id="7ee913d1a8b01e1a461f9eb99b0bba74" category="list-text">디렉터리를 '트리덴트 - 설치자'로 변경합니다.</block>
  <block id="8ad5650fb94bff45b328581838d836fd" category="list-text">tridentctl을 시스템 '$path'의 디렉토리에 복사합니다</block>
  <block id="6da8d48465deb31425595b33a9172acf" category="list-text">Helm을 사용하여 K8s 클러스터에 Trident 설치:</block>
  <block id="7b09729551ddb1a7445f559eb1186978" category="list-text">디렉터리를 Helm 디렉토리로 변경합니다.</block>
  <block id="27b4c36cae8d1c4fd515d289942c87cc" category="list-text">Trident를 설치합니다.</block>
  <block id="cea04f1ceb2ba2472ec50de3a03a689c" category="list-text">Trident Pod의 상태를 확인합니다. 일반적인 K8s 방식:</block>
  <block id="6ac3c5fc780260af91dd10523188e6fd" category="list-text">모든 Pod가 가동되어 실행 중이면 Trident가 설치되어 앞으로 이동하기에 좋습니다.</block>
  <block id="7862dabe13bf66a99fcfd3a6b1af4d94" category="section-title">Azure NetApp Files 백엔드 및 스토리지 클래스 설정</block>
  <block id="7e98dce86779e84763b71398d851f7bb" category="paragraph">Azure NetApp Files 백엔드 및 스토리지 클래스를 설정하려면 다음 단계를 수행하십시오.</block>
  <block id="dadab4bead78e450739c0f56bad40cda" category="list-text">홈 디렉토리로 다시 전환합니다.</block>
  <block id="65b8f7db2e9a3793e76d2ec3787f71fa" category="inline-link">프로젝트 리포지토리</block>
  <block id="03636accad716972f761628ea21e43f6" category="list-text">의 클론을 생성합니다<block ref="2b240ffa21ddbdc99d1706dee4302f7e" category="inline-link-rx"></block> 차선 감지 SCNN-horovod.</block>
  <block id="0ea725833b806058fe7810e6be91f9c0" category="list-text">트리덴트-구성 디렉토리로 이동합니다.</block>
  <block id="c51fa2034e7d5d97ec8c31248fc18e98" category="list-text">Azure 서비스 원칙 생성(서비스 원칙은 Trident가 Azure와 통신하여 Azure NetApp Files 리소스에 액세스하는 방법입니다.)</block>
  <block id="7c794fc1e683a6843753158bb92cab75" category="paragraph">출력은 다음 예와 같이 표시되어야 합니다.</block>
  <block id="203565dfd87ac32927ce5a828d45babd" category="list-text">Trident의 백엔드 json 파일을 생성합니다.</block>
  <block id="d7e47f31bf1c921dd5e28ee7e6f5cd34" category="list-text">원하는 텍스트 편집기를 사용하여 아래 표의 "anf-backend.json" 파일 안에 있는 다음 필드를 작성합니다.</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">값</block>
  <block id="8c443e170595ba0feac007ffb92cb49a" category="cell">구독 ID</block>
  <block id="deb6a9aaa10be6bb24feea6a3540128c" category="cell">Azure 구독 ID입니다</block>
  <block id="bc54592d6183695b841c6d1880ec0bf8" category="cell">텐antID</block>
  <block id="b147f00fa948b22faa89aa8044904495" category="cell">Azure 테넌트 ID(이전 단계의 az ad SP 출력에서)</block>
  <block id="93c5bebdea9c94a0740fe6fd9bb250f0" category="cell">클라이언트 ID입니다</block>
  <block id="5760e6800c58c7dc9ee68efdc6db38de" category="cell">appID(이전 단계의 az ad SP 출력에서)</block>
  <block id="2b53761249254ce6b502f521e5cc0683" category="cell">clientSecret</block>
  <block id="0571f76a94493cb2020d6c3b7453a367" category="cell">암호(이전 단계의 az ad SP 출력에서)</block>
  <block id="25e6b7ea847b31b4f88b60acd65052db" category="paragraph">파일은 다음 예제와 같습니다.</block>
  <block id="49356331b94221561b7751ae1f5343a9" category="list-text">다음과 같이 구성 파일로 anf-backend.json을 사용하여 trident 네임스페이스에 Azure NetApp Files 백엔드를 생성하도록 Trident에 지시합니다.</block>
  <block id="bd9c5e9bd5f130a6fbdbcaeb04656652" category="list-text">스토리지 클래스를 생성합니다.</block>
  <block id="a9fa0a3d8bf1bce76ef654f0a047b8fe" category="list-text">K8 사용자는 이름별로 저장소 클래스를 지정하는 PVC를 사용하여 체적을 프로비저닝합니다. K8s에게 다음을 사용하여 이전 단계에서 생성한 Azure NetApp Files 백엔드를 참조하는 스토리지 클래스 "azurenetappfiles"를 생성하도록 지시합니다.</block>
  <block id="5e121b263b32950e629eaf774c12da78" category="list-text">다음 명령을 사용하여 스토리지 클래스가 생성되었는지 확인합니다.</block>
  <block id="202ed88f7ec48eda708f6c062786f474" category="paragraph"><block ref="202ed88f7ec48eda708f6c062786f474" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72611a189b0331f709788d99912a1bd7" category="section-title">AKS에 볼륨 스냅샷 구성 요소를 구축하고 설정합니다</block>
  <block id="3ea90db69187da57e9739e033add6801" category="paragraph">클러스터에서 올바른 볼륨 스냅샷 구성 요소가 사전 설치되지 않은 경우 다음 단계를 실행하여 이러한 구성 요소를 수동으로 설치할 수 있습니다.</block>
  <block id="c3987ca9f11aad20ef5d2ae0dd30f9cb" category="admonition">AKS 1.18.14에는 Snapshot Controller가 사전 설치되어 있지 않습니다.</block>
  <block id="312e34d756f6ef39f0bd74e2f844773f" category="list-text">다음 명령을 사용하여 스냅샷 베타 CRD를 설치합니다.</block>
  <block id="529616f838a47cade6e5fac6f879ce5a" category="list-text">GitHub에서 다음 문서를 사용하여 Snapshot Controller를 설치합니다.</block>
  <block id="90a2427d3a3145723cd2a130c5372865" category="inline-link">볼륨 스냅샷 클래스입니다</block>
  <block id="8f2838f14b6a64dd466dc23bcf7e3c01" category="list-text">K8s 'volumesnapshotclass'를 설정합니다. 볼륨 스냅샷을 생성하기 전에<block ref="cba124de563550c68e57cf9a6641a5d1" category="inline-link-rx"></block> 설정해야 합니다. Azure NetApp Files용 볼륨 스냅샷 클래스를 생성하고 NetApp Snapshot 기술을 사용하여 ML 버전 관리를 달성하는 데 사용합니다. volumesapshotclass NetApp-CSI-snapclass를 생성하고 다음과 같이 기본 'volumesnapshotclass'로 설정합니다.</block>
  <block id="adc3a39a071327998da9cc6708ef4fe8" category="paragraph"><block ref="adc3a39a071327998da9cc6708ef4fe8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="770bec683fa99c1a917babb074d95e66" category="list-text">다음 명령을 사용하여 볼륨 스냅샷 복사본 클래스가 생성되었는지 확인합니다.</block>
  <block id="99b5a364457d91999df6ca6488b800f2" category="paragraph"><block ref="99b5a364457d91999df6ca6488b800f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d9a6cca62c9095cbae70692ef82741c" category="section-title">AI 설치 를 실행하십시오</block>
  <block id="d1d2b81816d977b7a9d3480a495beda5" category="paragraph">run:AI를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="7899a1a12ecf76a5676a6d5ddb64842f" category="inline-link">설치 실행: AKS에 AI 클러스터</block>
  <block id="54437101a8cdfe297499d517331ced60" category="list-text"><block ref="400679f1b873ae4a832f018613d486cc" category="inline-link-rx"></block>.</block>
  <block id="5f854e827ba37f66f45f8e47643e23ea" category="list-text">app.runai.ai 으로 이동하여 새 프로젝트 만들기 를 클릭하고 이름을 차선 감지 로 지정합니다. 이렇게 하면 runai로 시작하는 K8s 클러스터의 이름 뒤에 프로젝트 이름이 붙습니다. 이 경우 생성된 네임스페이스는 runai-lane-detection입니다.</block>
  <block id="e699d582d1b58a9a23ebd74cab11d5bc" category="paragraph"><block ref="e699d582d1b58a9a23ebd74cab11d5bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="546524b2c8ed6fd083c9286159ebd55a" category="inline-link">설치 실행: AI CLI</block>
  <block id="f3a9807f54199fd5dbad651af2ea853a" category="list-text"><block ref="6291ffcd5a23a3d0b996bc90930ef0b3" category="inline-link-rx"></block>.</block>
  <block id="08d1d73b27232763a82ef46a413779ce" category="list-text">터미널에서 다음 명령을 사용하여 레인 감지를 기본 run:AI 프로젝트로 설정합니다.</block>
  <block id="0ca589f93fd9565aa5fc097fd66437ae" category="paragraph"><block ref="0ca589f93fd9565aa5fc097fd66437ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cd1a85dd18a7a0b8f1d07b4240fafcf" category="list-text">프로젝트 네임스페이스(예: lane-detection)에 대해 ClusterRole 및 ClusterRoleBinding을 만들어 runai-lane-detection 네임스페이스에 속한 기본 서비스 계정은 작업 실행 중에 'volumesnapshot' 작업을 수행할 수 있는 권한을 갖습니다.</block>
  <block id="351495b134e625df33dfb5230d6eab7b" category="list-text">다음 명령을 사용하여 'runai-lane-detection'이 존재하는지 확인하기 위한 네임스페이스를 나열합니다.</block>
  <block id="bd546162071f28fd50f8c977ac61149e" category="paragraph">출력은 다음 예와 같이 나타나야 합니다.</block>
  <block id="8c33c9910dfecb6260489cd05f43b275" category="paragraph"><block ref="8c33c9910dfecb6260489cd05f43b275" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f23930532ba19f8970c6dcb4b6ad778f" category="list-text">다음 명령을 사용하여 ClusterRole의 "netaprosnapshot" 및 ClusterRoleBinding" netappsnapshot을 생성합니다.</block>
  <block id="7e3ec6f763cd8a13380162aba60c47e0" category="section-title">실행:AI 작업으로 TuSimple 데이터 세트를 다운로드하고 처리합니다</block>
  <block id="c0cc307d9f63d0a096f8d6e3193cd561" category="paragraph">실행 시 TuSimple 데이터 세트를 다운로드하고 처리하는 프로세스는 선택 사항입니다. AI 작업은 선택 사항입니다. 여기에는 다음 단계가 포함됩니다.</block>
  <block id="52eeaf7bac6d3e2111d129a11d0bafed" category="list-text">기존 Docker 이미지(예: muneer7589/download-tusimple:1.0)를 사용하려면 Docker 이미지를 빌드하고 푸시하거나 이 단계를 생략합니다</block>
  <block id="0d5647db76048e129c1146a822abbdd8" category="list-text">홈 디렉토리로 이동합니다.</block>
  <block id="02c403c221afbdccdc4f7182e2eb5cb7" category="list-text">'lane-detection-SCNN-horovod' 프로젝트의 데이터 디렉토리로 이동합니다.</block>
  <block id="eed104c2f8af7c3526ec55b8cc69dde7" category="list-text">build_image.sh 쉘 스크립트를 수정하고 Docker 리포지토리를 사용자 위치로 변경합니다. 예를 들어, 'muneer7589'를 Docker 리포지토리 이름으로 바꿉니다. Docker 이미지 이름과 태그(예: dowload-tusimple, 1.0)를 변경할 수도 있습니다.</block>
  <block id="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="paragraph"><block ref="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed49e04589e6c9071bbd1af307f83a0" category="list-text">스크립트를 실행하여 Docker 이미지를 구축하고 다음 명령을 사용하여 Docker 저장소로 푸시합니다.</block>
  <block id="8ebf5e70d0ed304519c7c9b525d80af1" category="list-text">Run:AI 작업을 제출하여 NetApp Trident가 동적으로 생성한 'PVC'에 TuSimple 레인 감지 데이터 세트를 다운로드, 추출, 전처리 및 저장합니다.</block>
  <block id="050d58b165aef32cad86839521b721b2" category="list-text">다음 명령을 사용하여 run:AI 작업을 제출하십시오.</block>
  <block id="83b4fb868b7505e293871c3e5accc98c" category="list-text">실행:AI 작업을 제출하려면 아래 표의 정보를 입력하십시오.</block>
  <block id="e50d72d773874b2be58530daec43900c" category="cell">-이름</block>
  <block id="37e9bb74490b0ac510effff5a546f11d" category="cell">작업의 이름입니다</block>
  <block id="5503ed8f71ae365eb6f5e8221562a0eb" category="cell">-PVC</block>
  <block id="626299ff067d1e6a178beced1631ab43" category="cell">[StorageClassName]:Size:ContainerMountPath 형식의 PVC 위의 작업 제출에서 스토리지 클래스 azurenetappfiles가 있는 Trident를 사용하여 필요 시 PVC를 만듭니다. 여기서 영구 볼륨 용량은 100Gi 이며 경로 /mnt에 마운트됩니다.</block>
  <block id="0247d7fb481075907b9eb467cfe90e3a" category="cell">?곸긽</block>
  <block id="b30f1ca8b35fd6ccab829a959f414a51" category="cell">이 작업에 대한 컨테이너를 생성할 때 사용할 Docker 이미지입니다</block>
  <block id="22a55ba6c8590fa98f1b3234141f2848" category="paragraph"><block ref="22a55ba6c8590fa98f1b3234141f2848" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af270e479cd849e4a9cb6d17b76585ef" category="list-text">제출된 RUN:AI 작업을 나열합니다.</block>
  <block id="f740410b6ea33d3ffc740140cc23a0e2" category="paragraph"><block ref="f740410b6ea33d3ffc740140cc23a0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51869a860c4af748ec2815d406929a17" category="list-text">제출된 작업 로그를 확인하십시오.</block>
  <block id="ab353387b0e5276e03aecae4cc95d150" category="paragraph"><block ref="ab353387b0e5276e03aecae4cc95d150" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84dd51baa0cf15db0a639dbb6d5d8ee" category="list-text">만든 PVC를 나열합니다. 다음 단계에서 이 'PVC' 명령을 사용하여 훈련하십시오.</block>
  <block id="cc2e05fe54a847aee415a2deb0b7f13e" category="paragraph"><block ref="cc2e05fe54a847aee415a2deb0b7f13e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20e4749f78095f0b9adf5c3cad36f81" category="list-text">실행 중인 작업 확인: AI UI (또는 'app.run.ai`).</block>
  <block id="ced39410c19f3968638fc81e16743f32" category="paragraph"><block ref="ced39410c19f3968638fc81e16743f32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dee54cb181d3bfde644600fb15bbac4" category="section-title">Horovod를 사용하여 분산 차선 감지 교육을 수행합니다</block>
  <block id="645e2c981858a720c673c6a782efd9ea" category="paragraph">Horovod를 사용하여 분산 차선 감지 교육을 수행하는 것은 선택적 프로세스입니다. 그러나 다음과 같은 단계가 있습니다.</block>
  <block id="04e568eec6dda4a0cfb1fc6680509d35" category="list-text">기존 Docker 이미지(예: 'muneer7589/dist-lane-detection: 3.1):'를 사용하려면 Docker 이미지를 빌드하고 푸시하거나 이 단계를 건너뜁니다</block>
  <block id="b01fdc5088b4a04549ed5e7cc71f898b" category="list-text">홈 디렉토리로 이동합니다.</block>
  <block id="14e21ef8495bc1dd543db0aebbe06c5b" category="list-text">프로젝트 디렉터리 레인 감지 SCNN-horovod로 이동합니다</block>
  <block id="0a27aa824e245e7b31f5f8d990636ead" category="list-text">'build_image.sh' 쉘 스크립트를 수정하고 Docker 리포지토리를 사용자 이름으로 변경합니다(예: 'muneer7589'를 Docker 리포지토리 이름으로 대체). Docker 이미지 이름과 태그(dist-lane-detection, 3.1 등)도 변경할 수 있습니다.</block>
  <block id="c9ce95c3d4cf96d5e894e4a834754cb6" category="paragraph"><block ref="c9ce95c3d4cf96d5e894e4a834754cb6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2776d43d1e635424496622f14cfd745c" category="list-text">스크립트를 실행하여 Docker 이미지를 구축하고 Docker 저장소로 이동합니다.</block>
  <block id="b9bcfd06c5cdfc67a00ffe8a0c846318" category="list-text">배포 교육(MPI)을 수행하기 위한 AI 작업 제출:</block>
  <block id="f3b76b64a9761cfb85f0ddc37d910fef" category="list-text">러닝 제출 사용: 이전 단계에서 PVC를 자동으로 생성하기 위한 AI(데이터 다운로드용)만 RWO 액세스를 허용할 수 있습니다. 이 경우 여러 Pod 또는 노드가 동일한 PVC에 대한 분산 교육 액세스를 허용하지 않습니다. 액세스 모드를 ReadWriteMany로 업데이트하고 Kubernetes 패치를 사용하여 업데이트합니다.</block>
  <block id="2874172b683ddc4047fd63f29baf543d" category="list-text">먼저 다음 명령을 실행하여 PVC의 볼륨 이름을 가져옵니다.</block>
  <block id="bcc0952c2970bfd6c85cd65050e00533" category="paragraph"><block ref="bcc0952c2970bfd6c85cd65050e00533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64ac0e4e6343f4593e210b98f9c91de" category="list-text">볼륨을 패치하고 ReadWriteMany에 대한 액세스 모드를 업데이트합니다(다음 명령에서 볼륨 이름을 사용자 이름으로 바꾸기).</block>
  <block id="7a9d347cf2f324e82478a9cf243448f7" category="list-text">아래 표의 정보를 사용하여 배포된 교육 작업을 실행하기 위한 AI MPI 작업 제출:</block>
  <block id="b068931cc450442b63f5b3d276ea4297" category="cell">이름</block>
  <block id="e4580c1854231c935f0cf2eb4609d97a" category="cell">분산된 교육 작업의 이름입니다</block>
  <block id="384dd16a327b7f16278642f008c27fab" category="cell">대형 shm</block>
  <block id="fc9fed4d0a3cb207102499ba041f2603" category="cell">대용량 /dev/shm 디바이스 마운트 RAM에 마운트된 공유 파일 시스템이며 여러 CPU 작업자가 CPU RAM에 배치를 처리 및 로드할 수 있을 만큼 충분한 크기의 공유 메모리를 제공합니다.</block>
  <block id="530968b205d33b3869aa32e2933fbfad" category="cell">프로세스</block>
  <block id="403e4aa48fedb1c5777ee913b2f2bedb" category="cell">분산된 교육 프로세스 수</block>
  <block id="0aa0be2a866411d9ff03515227454947" category="cell">GPU</block>
  <block id="031492a2d708ca774bd08c099eb4dd79" category="cell">이 작업에서 작업에 할당할 GPU/프로세스 수, GPU 작업자 프로세스 3개(--프로세스=3)가 있으며, 각각 단일 GPU(--GPU 1)로 할당됩니다.</block>
  <block id="642542e40351edbd731ebad352b31317" category="cell">PVC</block>
  <block id="c50723a53a74a682495f8c3810ce4a65" category="cell">이전 작업(download-tusimple-data-0)에서 생성한 기존 영구 볼륨(PVC-download-tusimple-data-0)을 사용하고 path /mnt에 마운트됩니다</block>
  <block id="8c236f63f205a50942b609a6d45734a7" category="cell">컨테이너에 설정할 환경 변수를 정의합니다</block>
  <block id="61dcf83940f915d0c5fe5b985eed7be8" category="cell">작업자 사용</block>
  <block id="f84e120605e14d9755a1ed2e8e03cea6" category="cell">인수를 true로 설정하면 다중 프로세스 데이터 로드가 설정됩니다</block>
  <block id="90b186f5d2a6890e77373c8aa60461e7" category="cell">작업자 수</block>
  <block id="a10574eb8e119b847fb5ab95b788e723" category="cell">데이터 로더 작업자 프로세스의 수입니다</block>
  <block id="61c67ea819106ff81c08249014791d3b" category="cell">batch_size를 선택합니다</block>
  <block id="243f7fe32e2dbb7748c1a018fe60016e" category="cell">교육 배치 크기</block>
  <block id="d07f4474a5e5996da9b6e57abb250331" category="cell">VAL을 사용합니다</block>
  <block id="919bc92a851c1d3e2c467e844398b751" category="cell">인수를 TRUE로 설정하면 유효성 검사가 허용됩니다</block>
  <block id="c4407b612c3b5e2c00c1b5522c686c84" category="cell">Val_batch_size를 선택합니다</block>
  <block id="597765782da042e86019b4c919a86248" category="cell">검증 배치 크기</block>
  <block id="18e0d33045db50bb37e6f2fcd5c0b842" category="cell">snapshot을 설정합니다</block>
  <block id="67c5deea68dff022b0f807ffb3bf56e2" category="cell">인수를 TRUE로 설정하면 ML 버전 관리를 위해 데이터 및 훈련된 모델 스냅샷을 생성할 수 있습니다</block>
  <block id="cdd7dd1603420ef6c3efe7b264205137" category="cell">PVC_이름</block>
  <block id="d95926771c9100db9ba3e3247c86a192" category="cell">스냅샷을 생성할 PVC의 이름입니다. 위의 작업 제출에서 데이터 세트 및 교육 모델로 구성된 PVC-download-tusimple-data-0의 스냅샷을 촬영하고 있습니다</block>
  <block id="b302d66ab7f3f0c94236ff26c8ead4d9" category="inline-image-macro">오류: 그래픽 이미지가 없습니다</block>
  <block id="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="paragraph"><block ref="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3299ed00d03beff0cc2ebaf178a91786" category="list-text">제출된 작업을 나열합니다.</block>
  <block id="2e593aa2ccf62807184e56a543d23e97" category="paragraph"><block ref="2e593aa2ccf62807184e56a543d23e97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82abe908a319245230ef0f3ec84c263f" category="list-text">제출된 작업 로그:</block>
  <block id="dab56217fc48a1919fee48434a7c7204" category="paragraph"><block ref="dab56217fc48a1919fee48434a7c7204" category="inline-image-macro-rx" type="image"></block></block>
  <block id="981528b0e4cd4a19c56310c6b9c915ce" category="list-text">아래 그림과 같이 RUN TO/RUN TO/AI GUI(또는 app.runai.ai): RUN:AI 대시보드 에서 교육 작업을 확인하십시오. 첫 번째 그림에서는 분산 훈련 작업에 할당된 3개의 GPU를 AKS의 3개 노드에 분산시키고, 두 번째 실행인 AI 작업에 대해 자세히 설명합니다.</block>
  <block id="d8cbd4299e4baf5de5572bf6af32dd52" category="paragraph"><block ref="d8cbd4299e4baf5de5572bf6af32dd52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fdc4068f0b660d1d6b102946986bd1" category="paragraph"><block ref="90fdc4068f0b660d1d6b102946986bd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e8bb0b427c33dd6cf63d1a3a37c7022" category="list-text">교육이 완료되면 RUN:AI 작업과 연결되고 생성된 NetApp Snapshot 복사본이 있는지 확인하십시오.</block>
  <block id="6c94f812a836696605e3e2b6bd5ca768" category="paragraph"><block ref="6c94f812a836696605e3e2b6bd5ca768" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4c0a1395081fc81855e465c493f4967" category="section-title">NetApp 스냅샷 복사본에서 데이터를 복원합니다</block>
  <block id="ec8de1dcfce51c9d877901e2f6f5971e" category="paragraph">NetApp Snapshot 복사본에서 데이터를 복원하려면 다음 단계를 수행하십시오.</block>
  <block id="5adc4d7860e7ad0f78ada0bb1f0eaca6" category="list-text">프로젝트 디렉터리 'lane-detection-SCNN-horovod'로 이동합니다.</block>
  <block id="6344772f26907403fed713060f33b8f4" category="list-text">restore-snaphot-vc.yaML을 수정하고 데이터 복원을 원하는 스냅샷 사본으로 dataSource의 이름 필드를 업데이트합니다. 이 예제에서는 데이터 복원 위치를 PVC 이름으로 변경할 수도 있습니다.</block>
  <block id="b3b5448c329ac882bc890a1be1a1b369" category="paragraph"><block ref="b3b5448c329ac882bc890a1be1a1b369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f8efb3d1b86c88cfab193291776b6ad" category="list-text">restore-snapshot-pvc.yAML을 사용하여 새로운 PVC를 생성한다.</block>
  <block id="34c7c2e95019754701182fe2ab194499" category="paragraph"><block ref="34c7c2e95019754701182fe2ab194499" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070856555a817dbf9a4061542b2098ca" category="list-text">방금 복원한 데이터를 교육에 사용하려는 경우, 작업 제출은 이전과 동일하게 유지되며, 교육 작업을 제출할 때 다음 명령에 표시된 것처럼 'PVC_NAME'만 복원된 'PVC_NAME'으로 교체합니다.</block>
  <block id="e945ddc4d35a9c49a17bd00c53db05a6" category="section-title">성능 평가</block>
  <block id="3451b157ef07ae84bfaba5fb6639c1ba" category="paragraph">솔루션의 선형 확장성을 보여주기 위해 GPU 1개와 GPU 3개 등 두 가지 시나리오에서 성능 테스트를 수행했습니다. TuSimple 레인 감지 데이터 세트에 대한 교육 중에 GPU 할당, GPU 및 메모리 사용률, 다양한 단일 및 3노드 메트릭이 캡처되었습니다. 교육 프로세스 중 리소스 활용도를 분석하기 위해 데이터가 5배 증가합니다.</block>
  <block id="b8077d533d2f9918c47d330cbac4392d" category="inline-link-macro">Azure NetApp Files 서비스 레벨</block>
  <block id="da9b7dc2993c3c848d5d9a9a15806d8c" category="paragraph">이 솔루션을 통해 고객은 작은 데이터 세트와 몇 개의 GPU로 시작할 수 있습니다. 데이터의 양과 GPU 수요가 증가하면 고객은 표준 계층의 테라바이트를 동적으로 확장하고 프리미엄 계층까지 신속하게 확장하여 데이터 이동 없이 테라바이트당 처리량의 4배를 얻을 수 있습니다. 이 프로세스는 섹션, <block ref="bdbab4daa7de478307acc7147c869853" category="inline-link-macro-rx"></block>.</block>
  <block id="090a231c840a0cb23aa29c8d1afc7832" category="paragraph">GPU 1개의 처리 시간은 12시간 45분이었습니다. 3개 노드에서 3개의 GPU를 처리하는 데 약 4시간 30분이 소요되었습니다.</block>
  <block id="49eca64b9f03702167beb48ebd38587b" category="paragraph">이 문서의 나머지 부분에서는 개별 비즈니스 요구 사항에 따른 성능 및 확장성의 예를 보여 줍니다.</block>
  <block id="abfc10c2bc00a990735e6d27797295a8" category="paragraph">아래 그림은 1 GPU 할당 및 메모리 활용률을 보여 줍니다.</block>
  <block id="8d7e3abab70510c3f4636ff7bf953250" category="paragraph"><block ref="8d7e3abab70510c3f4636ff7bf953250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31a3d2def4927574922946c38f043c0b" category="paragraph">아래 그림은 단일 노드 GPU 활용률을 보여 줍니다.</block>
  <block id="58cf0f270760f08ac96254402d0696dc" category="paragraph"><block ref="58cf0f270760f08ac96254402d0696dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dcca9cfd87d9f2087d720ef187655cea" category="paragraph">아래 그림은 단일 노드 메모리 크기(16GB)를 보여줍니다.</block>
  <block id="e22d39f2830d0f3e3944644d0f605d41" category="paragraph"><block ref="e22d39f2830d0f3e3944644d0f605d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="576c0843e21d5ee884a067aa7b6a1a40" category="paragraph">아래 그림은 단일 노드 GPU 수(1)를 보여줍니다.</block>
  <block id="ef855771be83c072ebaafc60d2d1933f" category="paragraph"><block ref="ef855771be83c072ebaafc60d2d1933f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2c50f1b8fc86c36cc0df94dd14b46b9" category="paragraph">아래 그림은 단일 노드 GPU 할당(%)을 보여줍니다.</block>
  <block id="e295f84458327d01315b814d8deb2aea" category="paragraph"><block ref="e295f84458327d01315b814d8deb2aea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b2b7f256373eac14419bfec5b84b21" category="paragraph">아래 그림은 3개 노드에서 GPU 할당 및 메모리인 3개의 GPU를 보여줍니다.</block>
  <block id="e763ef0e4b7cb9d022bf6db49319c570" category="paragraph"><block ref="e763ef0e4b7cb9d022bf6db49319c570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94ab4242b167972f7a9f0513ca772555" category="paragraph">아래 그림은 3개 노드의 사용률(%)에서 3개의 GPU를 보여줍니다.</block>
  <block id="d786146ae56597413fa5be548126cda9" category="paragraph"><block ref="d786146ae56597413fa5be548126cda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c31ecb239228cac5e96860d42f9a4d" category="paragraph">아래 그림은 3개 노드의 메모리 사용률(%)에서 3개의 GPU를 보여줍니다.</block>
  <block id="2224958fd5113068ac8a3b55a336661b" category="paragraph"><block ref="2224958fd5113068ac8a3b55a336661b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79f05e8f99917560625d1cf3f2d4fc5d" category="inline-link">서비스 레벨</block>
  <block id="07c1fda2408980b5d53ea06ad3cc5ed1" category="paragraph">볼륨을 를 사용하는 다른 용량 풀로 이동하여 기존 볼륨의 서비스 수준을 변경할 수 있습니다<block ref="bc9fbd5fd43d884f02abe6a6f9b51339" category="inline-link-rx"></block> 볼륨에 대한 을 선택합니다. 볼륨에 대한 이 기존 서비스 수준 변경 사항은 데이터를 마이그레이션할 필요가 없습니다. 볼륨에 대한 액세스에도 영향을 주지 않습니다.</block>
  <block id="5e2ff0b5dc3206032a81aa3aecb7c462" category="section-title">볼륨의 서비스 수준을 동적으로 변경합니다</block>
  <block id="58e691ddc6184f73e5d6b513ca5a3c49" category="paragraph">볼륨의 서비스 수준을 변경하려면 다음 단계를 수행하십시오.</block>
  <block id="3f19b438418ed162387a3050b304c89b" category="list-text">볼륨 페이지에서 서비스 수준을 변경할 볼륨을 마우스 오른쪽 단추로 클릭합니다. 풀 변경 을 선택합니다.</block>
  <block id="5acf521dbc5099b2ec33a64efac89595" category="paragraph"><block ref="5acf521dbc5099b2ec33a64efac89595" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6533c4186062235d8b7f47e232e92597" category="list-text">Change Pool 창에서 볼륨을 이동할 용량 풀을 선택합니다. 그런 다음 확인을 클릭합니다.</block>
  <block id="3f0874d07ce6ae728a6dcdda7903f9cd" category="paragraph"><block ref="3f0874d07ce6ae728a6dcdda7903f9cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb935c59f24539e0966b7ab5c761e862" category="section-title">서비스 수준 변경 자동화</block>
  <block id="1391028ed384c93fd59fd5a0097f9181" category="paragraph">동적 서비스 수준 변경은 현재 공개 미리 보기에 있지만 기본적으로 활성화되어 있지 않습니다. Azure 구독에서 이 기능을 활성화하려면 “ 문서에 제공된 다음 단계를 수행하십시오<block ref="5c3671452d40598396b030d5c9c6dc27" category="inline-link-rx"></block>.”</block>
  <block id="407443b5508c517acd825fbcddb7ab4c" category="inline-link">AZ NetApp 파일 볼륨: ANF(Azure NetApp Files) 볼륨 리소스 관리</block>
  <block id="1d3afb31c5d2a81fca940ae760671a1c" category="list-text">Azure:CLI에 대해 다음 명령을 사용할 수도 있습니다. Azure NetApp Files의 풀 크기 변경에 대한 자세한 내용은 를 참조하십시오<block ref="8b45caafcc8d758d5c37edb19f8a2761" category="inline-link-rx"></block>.</block>
  <block id="ebd5b070cb8457b94f1916baa92c3c7d" category="inline-link">Azure NetApp Files 볼륨의 풀을 변경합니다</block>
  <block id="d5460fd5fbfbf643b9a4bc1d1de279d0" category="list-text">여기에 표시된 'et-aznetapfilesvolumepool' cmdlet은 Azure NetApp Files 볼륨의 풀을 변경할 수 있습니다. 볼륨 풀 크기 및 Azure PowerShell 변경에 대한 자세한 내용은 을 참조하십시오<block ref="70c8d95cde8b63eae0d37a8b81a31482" category="inline-link-rx"></block>.</block>
  <block id="3ad0505876550699ce505845f96683a7" category="doc">NetApp Cloud Sync를 사용하여 대화 내용 아카이빙</block>
  <block id="5b7a8a379330d9d43907b47a6d7ee306" category="inline-link-macro">Nemo Training을 사용하여 Intent 모델을 확장합니다</block>
  <block id="a7e4c14a726c28e6cb4b935701ac2899" category="paragraph">하루에 한 번 대화 기록을 CSV 파일로 덤프하면 Cloud Sync를 활용하여 로그 파일을 로컬 저장소에 다운로드할 수 있습니다. 다음 그림에서는 Cloud Sync를 사용하여 Nemo 교육을 위한 대화 기록을 전송하는 동안 Jarvis를 온프레미스 및 퍼블릭 클라우드에 구축하는 아키텍처를 보여 줍니다. Nemo 교육에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="14a0a4dd1a1c18cba42b2036fe4dfc33" category="inline-link-macro-rx"></block>.</block>
  <block id="e60c4461b2b4dcf3aa8535e3aab780b3" category="paragraph"><block ref="e60c4461b2b4dcf3aa8535e3aab780b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00717575e300ae9f18fa0a24d97bcca5" category="inline-link-macro">다음: Nemo Training을 사용하여 Intent Models를 확장합니다</block>
  <block id="7ee8a10f8da0d566f0c5cccb9528b186" category="paragraph"><block ref="7ee8a10f8da0d566f0c5cccb9528b186" category="inline-link-macro-rx"></block></block>
  <block id="00a9f41b5383bf6bcb5b7f6540d427b4" category="summary">NVIDIA, AWS, Google 등에서 제공하는 최신 기술 및 사전 교육 모델링 툴을 사용하여 복잡한 모델을 가진 엔드 투 엔드 파이프라인을 상대적으로 쉽게 구축 및 사용자 정의할 수 있습니다.</block>
  <block id="2a3b399798aa16ecfbc1425cc560bfad" category="doc">사용 사례</block>
  <block id="14e5cae1e8e56eca8add5bdcedfe2335" category="inline-link-macro">이전: 지원 센터 분석.</block>
  <block id="d39a6e05d58eb4f71cae7257dc52a1d0" category="paragraph"><block ref="d39a6e05d58eb4f71cae7257dc52a1d0" category="inline-link-macro-rx"></block></block>
  <block id="710217ef02bea8d1d76bc6fc0e7bc056" category="paragraph">이러한 지원 센터에서 처리하는 통화 수 때문에 수동으로 수행할 경우 통화 성능 평가에 상당한 시간이 걸릴 수 있습니다. 단어 개수 계산 및 기타 방법과 같은 기존 방법은 일부 자동화를 달성할 수 있지만 이러한 방법은 동적 언어의 보다 미묘한 측면과 의미 컨텍스트를 캡처하지 않습니다. AI 모델링 기법을 사용하면 이러한 고급 분석 중 일부를 자동화된 방식으로 수행할 수 있습니다. 또한, NVIDIA, AWS, Google 등에서 제공하는 최신 기술 및 사전 교육 모델링 툴을 사용하여 복잡한 모델을 가진 엔드 투 엔드 파이프라인을 상대적으로 쉽게 구축 및 사용자 지정할 수 있습니다.</block>
  <block id="dd4541bcdb4728a1a380e825494f08e2" category="paragraph">지원 센터 정서 분석을 위한 엔드 투 엔드 파이프라인은 직원들이 통화자와 대화하면서 실시간으로 오디오 파일을 수집합니다. 그런 다음 이러한 오디오 파일을 텍스트 형식으로 변환하는 텍스트 음성 변환 구성 요소에서 사용할 수 있도록 처리됩니다. 대화의 각 문구에는 정서(긍정적, 부정적 또는 중립적)를 나타내는 레이블이 표시됩니다.</block>
  <block id="cfc9b6a29659e2208f66d876bd355200" category="paragraph">감정 분석은 통화 성과를 평가하기 위한 대화의 필수 요소를 제공할 수 있습니다. 이러한 감정은 직원과 통화자 간의 상호 작용에 대한 심도 있는 수준을 더하고 있습니다. AI 지원 정서 대시보드는 관리자가 대화 내에서 감정을 실시간으로 추적할 수 있도록 하며 직원의 과거 통화 내역을 후향적 분석합니다.</block>
  <block id="2357d01362feabb1716e49b27d23f9cf" category="inline-link">NVIDIA Maxine</block>
  <block id="a2415fcdba82ba111e08286b17d98943" category="paragraph">사전 구축된 툴을 강력한 방법으로 결합하여 이 문제를 해결하기 위한 엔드 투 엔드 AI 파이프라인을 빠르게 구축할 수 있습니다. 이 경우 NVIDIA Riva 라이브러리를 사용하여 두 개의 직렬 내 작업(오디오 전사 및 정서 분석)을 수행할 수 있습니다. 첫 번째는 감시 방식 학습 신호 처리 알고리즘이고 두 번째는 감시 방식 학습 NLP 분류 알고리즘입니다. NVIDIA TAO 툴킷을 사용하여 비즈니스 관련 데이터와 관련된 모든 사용 사례에 맞게 즉시 사용 가능한 알고리즘을 미세 조정할 수 있습니다. 따라서 훨씬 적은 비용과 리소스로 더 정확하고 강력한 솔루션을 구축할 수 있습니다. 고객은 을 통합할 수 있습니다<block ref="2aa9e1b3ec0ddf7f0bf09cdb2976222a" category="inline-link-rx"></block> 지원 센터 설계의 GPU 가속 비디오 회의 응용 프로그램용 프레임워크</block>
  <block id="076dd41fe8ba902e5439b5ba07f330ee" category="paragraph">다음 사용 사례가 이 솔루션의 핵심입니다. 두 사용 사례 모두 모델 세부 조정에는 TAO Toolkit을 사용하고 모델 배포에는 Riva를 사용합니다.</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="list-text">텍스트 음성 변환</block>
  <block id="7cb906d40b2e5bad2205a60ef8b6a019" category="list-text">정서 분석</block>
  <block id="bc176e8f914533ec222bba678e13955f" category="paragraph">직원과 고객 간의 지원 센터 상호 작용을 분석하기 위해 오디오 통화 형식으로 각 고객 대화를 파이프라인을 통해 실행하여 문장별 감정을 추출할 수 있습니다. 그런 다음, 그 감정은 인간이 검증하여 정서를 정당화하거나 필요에 따라 조정할 수 있다. 그런 다음 레이블이 지정된 데이터가 미세 조정 단계로 전달되어 감정의 예측을 개선합니다. 레이블이 지정된 감정 데이터가 이미 있으면 모델 세부 조정을 신속하게 처리할 수 있습니다. 어느 경우든 파이프라인은 오디오를 수집하여 문장을 분류해야 하는 다른 솔루션에 일반화할 수 있습니다.</block>
  <block id="91fa9ce0e0cb723f35d6cc55f796be7e" category="paragraph"><block ref="91fa9ce0e0cb723f35d6cc55f796be7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8836d456396ee0865c317994c018a24b" category="paragraph">AI 정서 출력은 외부 클라우드 데이터베이스 또는 회사에서 관리하는 스토리지 시스템에 업로드됩니다. 감성 출력은 관리자의 정서 분석을 표시하는 대시보드 내에서 사용할 수 있도록 이 큰 데이터베이스에서 로컬 스토리지로 전송됩니다. 대시보드의 주요 기능은 고객 서비스 직원과 실시간으로 상호 작용하는 것입니다. 관리자는 통화 중에 각 문장의 감정을 실시간으로 업데이트하고 직원의 과거 성과 또는 고객 반응에 대한 과거의 평가를 통해 직원에 대한 피드백을 평가 및 제공할 수 있습니다.</block>
  <block id="586779135ffb596b1f1844ada64164b6" category="paragraph"><block ref="586779135ffb596b1f1844ada64164b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link-macro">NetApp DataOps 툴킷</block>
  <block id="539788a6fdaffc74393f282739bdd3e2" category="paragraph">를 클릭합니다 <block ref="95472f01c3cd86dddef6619dbb9af815" category="inline-link-macro-rx"></block> 는 Riva 추론 파이프라인에서 정서 레이블을 생성한 후에도 데이터 스토리지 시스템을 계속 관리할 수 있습니다. 이러한 AI 결과는 NetApp DataOps 툴킷에서 관리하는 데이터 스토리지 시스템에 업로드할 수 있습니다. 데이터 스토리지 시스템은 수백 개의 인서트를 관리할 수 있어야 하며 매 분마다 선택해야 합니다. 로컬 디바이스 스토리지 시스템은 더 큰 데이터 스토리지를 실시간으로 쿼리하여 압축을 풉니다. 또한 대규모 데이터 스토리지 인스턴스를 쿼리하여 기간별 데이터를 쿼리하면 대시보드 환경을 더욱 향상시킬 수 있습니다. NetApp DataOps 툴킷은 데이터를 빠르게 복제하고 이를 사용하는 모든 대시보드에 배포하여 이러한 두 용도 모두를 촉진합니다.</block>
  <block id="3190a811a89bc9da4384152bc43d1b94" category="section-title">대상</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">이 솔루션의 대상 고객은 다음과 같은 그룹을 포함합니다.</block>
  <block id="679db67ee98260ef471da732862ed356" category="list-text">직원 관리자</block>
  <block id="7e6beec614d536589c47de8f77fa1b1a" category="list-text">데이터 엔지니어/데이터 과학자</block>
  <block id="a2ce7e25564bee3c78076bcff87d1329" category="list-text">IT 관리자(사내, 클라우드 또는 하이브리드)</block>
  <block id="8dcd09ac05ad9012a6ff01f7b5fc337b" category="paragraph">대화 전반에 걸쳐 감정을 추적하는 것은 직원의 성과를 평가할 수 있는 귀중한 도구입니다. 관리자는 AI 대시보드를 사용하여 직원과 발신자가 어떻게 자신의 감정을 실시간으로 변화시킵니다．이를 통해 실시간 평가와 안내 세션을 진행할 수 있습니다． 또한, 기업은 음성 대화, 텍스트 챗봇 및 화상 회의에 참여하는 고객으로부터 중요한 고객 통찰력을 얻을 수 있습니다. 이러한 고객 분석은 최신 최첨단 AI 모델 및 워크플로우와 함께 규모에 따른 다중 모드 처리 기능을 사용합니다.</block>
  <block id="b7c29e65097b6ed45e464f6492ff670d" category="paragraph">데이터 측면에서 많은 수의 오디오 파일이 지원 센터에 의해 매일 처리됩니다. NetApp DataOps 툴킷은 모델 및 정서 분석 대시보드의 주기적인 미세 조정을 위해 이 데이터 처리 작업을 용이하게 합니다.</block>
  <block id="1da289b166db713f9283c5be78ef5b96" category="paragraph">IT 관리자는 NetApp DataOps 툴킷을 사용하여 구축 환경과 운영 환경 간에 데이터를 빠르게 이동할 수 있습니다. 또한, 실시간 추론을 위해 NVIDIA 환경과 서버를 관리하고 분산해야 합니다.</block>
  <block id="d463f48696e58e286e9c0d594169b395" category="inline-link-macro">다음: 아키텍처.</block>
  <block id="7179915e029316714169ac136027ef31" category="paragraph"><block ref="7179915e029316714169ac136027ef31" category="inline-link-macro-rx"></block></block>
  <block id="27d597678185c0988ffb2dbb0c1b941d" category="doc">ImageNet 데이터 세트 벤치마크 요약을 통한 ResNet-50</block>
  <block id="3c97b4929008c9f4091a8070f570ccd4" category="paragraph">산업 표준 벤치마크 도구 TensorFlow 벤치마크를 사용하여 이 시스템의 운영 및 성능을 검증했습니다. 이미지 분류를 위해 유명한 CNN(Convolutional Neural Network) DL 모델인 ResNet-50을 교육하기 위해 ImageNet 데이터 세트를 사용합니다. ResNet-50은 더욱 빠른 처리 시간으로 정확한 교육 결과를 제공하므로 스토리지에서 충분한 수요를 창출할 수 있습니다.</block>
  <block id="a89cd2a9c8244dab756ec04aeb8247e9" category="inline-link-macro">다음: AI 설치를 실행합니다</block>
  <block id="123704fec3ddad892d7c2ae5c4de301b" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block></block>
  <block id="1a17b23dd49d997677e18c9b9fe29935" category="summary">이 페이지에서는 기본 작업 스트림 대시보드를 사용하여 Dask를 모니터링하는 방법에 대해 설명합니다.</block>
  <block id="3268570ddd540695f3e92ff79d8f4684" category="doc">기본 작업 스트림 대시보드를 사용하여 Dask를 모니터링합니다</block>
  <block id="1e80a6d70a902d1dae25d26917a5b490" category="inline-link-macro">이전: Dask에서 Day 15를 로드하여 Dask cuML 무작위 포리스트 모델을 교육합니다.</block>
  <block id="3898f5ae37dfd830af10cdc128236b50" category="paragraph"><block ref="3898f5ae37dfd830af10cdc128236b50" category="inline-link-macro-rx"></block></block>
  <block id="9eeb55820f49a600fa229f23cfe9e5b5" category="inline-link">Dask 분산 스케줄러입니다</block>
  <block id="99b248c7005783fe2682ad82217e9a24" category="paragraph">를 클릭합니다<block ref="7df0d90bf997a373bfe85bbe10a2d2c8" category="inline-link-rx"></block> 다음과 같은 두 가지 형태로 실시간 피드백을 제공합니다.</block>
  <block id="d8516bf5d94a38a1fa1d7a8c3b92dee7" category="list-text">실시간 정보가 포함된 여러 플롯과 테이블이 포함된 대화형 대시보드</block>
  <block id="d22ebe91c5dc1499387785da997fbe7d" category="list-text">콘솔 또는 노트북에서 대화형 사용에 적합한 진행률 표시줄</block>
  <block id="6e35e4c1cc9332ebc8028df451bc4f06" category="paragraph">이 경우 다음 그림은 저장된 바이트, 스트림 수에 대한 자세한 분석 결과가 있는 작업 스트림, 실행된 관련 함수와 함께 작업 이름별 진행 상황 등을 포함하여 작업 진행 상황을 모니터링하는 방법을 보여 줍니다. 이 경우 작업자 노드가 3개이므로 스트림의 기본 청크가 3개 있고 색상 코드는 각 스트림 내의 서로 다른 작업을 나타냅니다.</block>
  <block id="5743e70224503025dacaa77fae253c4f" category="paragraph"><block ref="5743e70224503025dacaa77fae253c4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a5c7a858f05434bf6637c3995959f49" category="paragraph">개별 작업을 분석하고 실행 시간을 밀리초 단위로 점검하거나 장애물이나 장애물을 식별할 수 있는 옵션이 있습니다. 예를 들어 다음 그림에서는 랜덤 포리스트 모델 피팅 단계에 대한 작업 스트림을 보여 줍니다. DataFrame 프로세싱을 위한 고유한 청크, 랜덤 포리스트에 맞는 _Construct_RF 등 훨씬 더 많은 함수가 실행되고 있습니다. Criteo Click Logs에서 하루 동안 수집한 데이터의 크기가 45GB로 인해 대부분의 시간이 DataFrame 작업에 소비되었습니다.</block>
  <block id="816ff133aaa3d2f46ca0c7842f5fdaab" category="paragraph"><block ref="816ff133aaa3d2f46ca0c7842f5fdaab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5eca1492a19a4c24071ed91262666cf" category="inline-link-macro">다음: 교육 시간 비교.</block>
  <block id="d5d929f175d4a2062c661e45b9656f32" category="paragraph"><block ref="d5d929f175d4a2062c661e45b9656f32" category="inline-link-macro-rx"></block></block>
  <block id="17a9b27c376a8a5f5e184b2ebce41164" category="summary">모든 것이 배포된 후 새 데이터에 대한 추론을 실행합니다. 이 모델은 사용자가 검색 활동을 기반으로 광고를 클릭하는지 여부를 예측합니다. 예측 결과는 Dask cuDF에 저장됩니다. Prometheus를 사용하여 결과를 모니터링하고 Grafana 대시보드에서 시각화할 수 있습니다.</block>
  <block id="af4d0cbb3c6dcf4f3a5e831b08e40ace" category="doc">Prometheus 및 Grafana로 Dask 및 RAPIDS를 모니터링합니다</block>
  <block id="a5d741c60ca9280a87382bcc2667207c" category="inline-link-macro">이전: 교육 시간 비교.</block>
  <block id="8162cd02e2793715a1b14265f2bfb54b" category="paragraph"><block ref="8162cd02e2793715a1b14265f2bfb54b" category="inline-link-macro-rx"></block></block>
  <block id="23c1612202d19b502b3701f893fb2557" category="inline-link">RAPIDS AI 중간 포스트</block>
  <block id="9fed5c9f0dab5b88ba96d45cf450079f" category="paragraph">자세한 내용은 다음을 참조하십시오<block ref="47200b727ab2088d205d11a973529202" category="inline-link-rx"></block>.</block>
  <block id="a5705f3e27851573a7eafd2a00a523b5" category="inline-link-macro">다음: NetApp DataOps 툴킷을 사용하여 데이터 세트 및 모델 버전 관리</block>
  <block id="db75fb5c1fef47405a8df61e726e3c66" category="paragraph"><block ref="db75fb5c1fef47405a8df61e726e3c66" category="inline-link-macro-rx"></block></block>
  <block id="729d72c073b607d370c067152cc53a10" category="doc">검증 결과</block>
  <block id="25edd21a28cb2fca00ab6f30e47c6d79" category="paragraph">샘플 추론 요청을 실행하려면 다음 단계를 수행하십시오.</block>
  <block id="cb11a85322b32a7615367d2523718b49" category="list-text">클라이언트 컨테이너/포드에 셸을 가져옵니다.</block>
  <block id="b489ec265fd981ff7aa78a7721bd3101" category="list-text">샘플 추론 요청을 실행합니다.</block>
  <block id="15c5e1ffe753f0365f39e7b508ce5ae0" category="paragraph"><block ref="15c5e1ffe753f0365f39e7b508ce5ae0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5bf2ae3a2d0d1dd1e0740744c9ebb1b" category="paragraph">이 추론 요청은 이미지 인식에 사용되는 resnet50_netdef 모델을 호출합니다. 다른 클라이언트는 유사한 접근 방식을 따르고 적절한 모델을 호출하여 추론 요청을 동시에 보낼 수도 있습니다.</block>
  <block id="b872d0389acf826cc7cf1939cd17a05d" category="inline-link-macro">다음: 추가 정보를 찾을 위치</block>
  <block id="a301641e2c9595a0c9c39ee7986f7ca8" category="paragraph"><block ref="a301641e2c9595a0c9c39ee7986f7ca8" category="inline-link-macro-rx"></block></block>
  <block id="bd3114e9e2000f42e265a067e98b0d25" category="doc">타사 API에 이행 엔진으로 연결합니다</block>
  <block id="1aea646cd3c044dd0758af18e73cfef3" category="paragraph">다음 타사 API를 이행 엔진으로 연결하여 질문에 답변했습니다.</block>
  <block id="94c494471216991658782a32f1e3ef37" category="inline-link">WeatherStack API를 참조하십시오</block>
  <block id="f7eb24e530470f21243c27770bd2c549" category="list-text"><block ref="c8600f69e922164a09610e481537b92d" category="inline-link-rx"></block>: 지정된 위치에 날씨, 온도, 강우량 및 눈을 반환합니다.</block>
  <block id="1c96228fa1453bf3f691d5081cbd6adb" category="inline-link">Yelp Fusion API를 참조하십시오</block>
  <block id="55a3b552be8202b066ea237b831186f4" category="list-text"><block ref="8af0de0530d799485b6d6a2d146ab784" category="inline-link-rx"></block>: 지정된 위치에서 가장 가까운 매장 정보를 반환합니다.</block>
  <block id="114e8180b93cb1b21cd00067e446e5f0" category="inline-link">eBay Python SDK</block>
  <block id="da6816adc86546982065d9aef78845e5" category="list-text"><block ref="3d046b40b6d382ee41dd02d3b6ab007c" category="inline-link-rx"></block>: 지정된 항목의 가격을 반환합니다.</block>
  <block id="3f7ba19f5b656e6cf8db9c69330a6d6e" category="inline-link-macro">다음: NetApp Retail Assistant 데모</block>
  <block id="23e96dc8693037c8fa1d7c0587a2d5eb" category="paragraph"><block ref="23e96dc8693037c8fa1d7c0587a2d5eb" category="inline-link-macro-rx"></block></block>
  <block id="48c4dc7fbfa1197490124f13eb565bd2" category="doc">ONTAP AI 배포</block>
  <block id="70d5c23ad68d59b2546133efdd1c3267" category="inline-link">NVA-1121-deploy: NetApp ONTAP AI, NVIDIA 구현</block>
  <block id="b393f072bc6b17085b75486a2abbcf97" category="paragraph">ONTAP AI를 배포하려면 네트워킹, 컴퓨팅 및 스토리지 하드웨어를 설치하고 구성해야 합니다. ONTAP AI 인프라 구축에 대한 구체적인 지침은 이 문서의 범위를 벗어납니다. 자세한 배포 정보는 를 참조하십시오<block ref="8c03c9c25bc6aba17e86c510148a3423" category="inline-link-rx"></block>.</block>
  <block id="03e335ae74b1356b294af55e07eb6b70" category="paragraph">이 솔루션 검증에서 단일 볼륨이 생성되어 DGX-1 시스템에 마운트되었습니다. 그런 다음 이 마운트 지점을 컨테이너에 마운트하여 데이터를 교육에 액세스할 수 있도록 했습니다. 대규모 배포의 경우 NetApp Trident는 볼륨의 생성 및 마운트를 자동화하여 관리 오버헤드를 제거하고 최종 사용자 리소스 관리를 지원합니다.</block>
  <block id="328d9c8854162b6d9dae70c57baa7505" category="inline-link-macro">다음: Kubernetes 배포</block>
  <block id="5102c02ef61bdeaa79904c17f58ca7e3" category="paragraph"><block ref="5102c02ef61bdeaa79904c17f58ca7e3" category="inline-link-macro-rx"></block></block>
  <block id="3bb420314fa4b29837c4b0528524000f" category="doc">NetApp ONTAP AI 및 AI 제어 플레인</block>
  <block id="1b85c0e7f381bd6f8c3150cafe56a9f0" category="paragraph">NetApp ONTAP AI 아키텍처는 NVIDIA DGX 시스템과 NetApp 클라우드 연결형 스토리지 시스템을 기반으로 합니다. 이 참조 아키텍처는 IT 조직이 다음과 같은 이점을 얻을 수 있도록 해 줍니다.</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">설계 복잡성 제거</block>
  <block id="5116c5071beb9f4f5b673c988c417c71" category="list-text">컴퓨팅과 스토리지의 독립적인 확장 지원</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">고객이 작은 규모로 시작한 후 원활하게 확장할 수 있도록 지원</block>
  <block id="bae698d3cdcc290d6a0048c7b786446c" category="list-text">다양한 성능 및 비용 관련 다양한 스토리지 옵션을 제공합니다.NetApp ONTAP AI는 DGX 시스템과 NetApp AFF A800 스토리지 시스템을 최첨단 네트워킹과 긴밀하게 통합합니다. NetApp ONTAP AI 및 DGX 시스템은 설계 복잡성과 추측을 제거함으로써 AI 배포를 단순화합니다. 고객은 작은 규모로 시작한 후 에지에서 코어 및 클라우드까지 포괄하여 데이터를 지능적으로 관리하면서 중단 없이 시스템을 확장할 수 있습니다.</block>
  <block id="c729dcbcad9e1c72ae15d4b823e9f311" category="paragraph">NetApp AI Control Plane은 데이터 과학자 및 데이터 엔지니어를 위한 전체 스택 AI, ML 및 딥 러닝(DL) 데이터 및 실험 관리 솔루션입니다. 조직이 AI를 더 많이 사용함에 따라 워크로드 확장성 및 데이터 가용성을 비롯한 여러 과제에 직면하게 됩니다. NetApp AI Control Plane은 GIT 보고에서와 같이 데이터 네임스페이스를 신속하게 클론 복제하여 추적 및 버전 관리를 위한 데이터 및 모델 기준선의 거의 즉각적인 생성을 통합하는 AI 교육 워크플로우를 정의 및 구현하는 등의 기능을 통해 이러한 문제를 해결합니다. NetApp AI Control Plane을 사용하면 사이트 및 지역 간에 데이터를 원활하게 복제하고 대규모 데이터 세트에 액세스할 수 있는 Jupyter Notebook 작업 공간을 신속하게 프로비저닝할 수 있습니다.</block>
  <block id="42cac0fcbbddfc99b31ff898d7902c83" category="inline-link-macro">다음: AI 워크로드 오케스트레이션에 대해 AI 플랫폼 실행</block>
  <block id="e3683938a3c34e6a7cf5b3896258e91e" category="paragraph"><block ref="a8dcbc617641d20db42fd66f3a42caae" category="inline-link-macro-rx"></block>.</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">이 섹션에서는 AI 솔루션의 기술 기반에 대해 설명합니다.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">기술 개요</block>
  <block id="5231f9fa4d08024f4620b759f83d0e97" category="inline-link-macro">이전: 소개.</block>
  <block id="42b507999e258502c07acce91c03de9f" category="paragraph"><block ref="42b507999e258502c07acce91c03de9f" category="inline-link-macro-rx"></block></block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">NetApp AFF 시스템</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">최첨단 NetApp AFF 스토리지 시스템을 사용하면 AI 추론 구축을 통해 에지에서 업계 최고 수준의 성능, 탁월한 유연성, 클라우드 통합, 동급 최고의 데이터 관리로 엔터프라이즈 스토리지 요구사항을 충족할 수 있습니다. 플래시 전용으로 설계된 NetApp AFF 시스템은 비즈니스 크리티컬 데이터를 더 빠르게 처리하고 관리, 보호할 수 있도록 지원합니다.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">엔트리 레벨 NetApp AFF 스토리지 시스템은 FAS2750 하드웨어 및 SSD 플래시 미디어를 기반으로 합니다</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">HA 구성의 컨트롤러 2개</block>
  <block id="7df12cd193e8452ed6fc45ca8bcd3771" category="paragraph"><block ref="7df12cd193e8452ed6fc45ca8bcd3771" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">NetApp 엔트리 레벨 AFF C190 스토리지 시스템은 다음 기능을 지원합니다.</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">최대 드라이브 수는 24x 960GB SSD입니다</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">두 가지 가능한 구성:</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">이더넷(10GbE): 10GBASE-T(RJ-45) 포트 4개</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">유니파이드(16Gb FC 또는 10GbE): 4x UTA2(Unified Target Adapter 2) 포트</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">최대 50.5TB의 유효 용량</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">NAS 워크로드의 경우, 단일 엔트리 레벨 AFF C190 시스템은 연속 읽기의 경우 4.4GBps의 처리량과 작은 랜덤 읽기의 경우 1ms 이하의 지연 시간으로 230K IOPS를 지원합니다.</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220을 참조하십시오</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">또한, NetApp은 대규모 구축을 위해 더 뛰어난 성능과 확장성을 제공하는 다른 엔트리급 스토리지 시스템을 제공합니다. NAS 워크로드의 경우 단일 엔트리 레벨 AFF A220 시스템이 다음을 지원합니다.</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">순차적 읽기의 경우 6.2GBps의 처리량</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375K IOPS, 1ms 미만의 지연 시간으로 소규모 랜덤 읽기 지원</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">최대 드라이브 수는 144x 960GB, 3.8TB 또는 7.6TB SSD입니다</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220은 1PB 이상의 실제 용량으로 확장됩니다</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">최대 실제 용량은 35PB이며 최대 스케일아웃 2-24개 노드(HA 쌍 12개)를 지원하는 경우</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">AFF A220보다 45% 이상 높은 성능 향상을 제공합니다</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440k IOPS 랜덤 읽기 @ 1ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">최신 NetApp ONTAP 릴리스 ONTAP 9.8을 기반으로 구축</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">HA 및 클러스터 인터커넥트에 2개의 25GB 이더넷을 활용합니다</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">NetApp E-Series EF 시스템</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF-Series는 엔트리 레벨 및 미드레인지 All-Flash SAN 스토리지 어레이 제품군으로, NetApp SANtricity 소프트웨어를 사용하여 데이터에 더 빠르게 액세스하고 가치를 더 빠르게 창출할 수 있습니다. 이러한 시스템은 SAS 및 NVMe 플래시 스토리지를 모두 제공하며 경제적인 가격으로 최고 수준의 IOPS, 100마이크로초 미만의 응답 시간, 최대 44GBps의 대역폭을 제공하므로 AI 추론 및 고성능 컴퓨팅(HPC)과 같은 까다로운 애플리케이션과 혼합 워크로드에 적합합니다.</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">다음 그림에서는 NetApp EF280 스토리지 시스템을 보여 줍니다.</block>
  <block id="51ffc2dfd09bb521be00106f197d1009" category="paragraph"><block ref="51ffc2dfd09bb521be00106f197d1009" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">32Gb/16Gb FC, 25Gb/10Gb iSCSI 및 12Gb SAS 지원</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">최대 실제 용량은 총 1.5PB의 96개 드라이브입니다</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">10GBps 처리량(순차적 읽기)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300K IOPS(랜덤 읽기)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280은 NetApp 포트폴리오에서 가장 경제적인 All-Flash 어레이(AFA)입니다</block>
  <block id="44114b1635cead15f56735bad0467251" category="section-title">NetApp EF300</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24x NVMe SSD 드라이브로 총 367TB 용량 지원</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">총 240x NL-SAS HDD, 96x SAS SSD 또는 그 조합 확장 옵션</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100Gb NVMe/IB, NVMe/RoCE, iSER/IB 및 SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32Gb NVMe/FC, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25GB iSCSI</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20GBps(순차적 읽기)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOPS(랜덤 읽기)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EF-Series NetApp EF-Series All-Flash 어레이 EF600, F300, EF570, EF280 데이터시트</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">자세한 내용은 를 참조하십시오<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>.</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">NetApp의 최신 세대 스토리지 관리 소프트웨어인 ONTAP 9.8.1을 통해 기업은 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다. ONTAP는 업계 최고 수준의 데이터 관리 기능을 활용하여 데이터가 상주하는 위치와 상관없이 단일 툴셋으로 데이터를 관리하고 보호할 수 있습니다. 필요에 따라 에지, 코어, 클라우드 등 어느 위치로도 데이터를 자유롭게 이동할 수 있습니다. ONTAP 9.8.1에는 데이터 관리를 단순화하고, 중요 데이터를 더 빨리 처리하고 보호하고, 하이브리드 클라우드 아키텍처 전반에서 차세대 인프라 기능을 지원하는 다양한 기능이 포함되어 있습니다.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">데이터 관리를 단순화하십시오</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">애플리케이션 및 데이터 세트에 적절한 리소스가 사용될 수 있도록 데이터 관리는 엔터프라이즈 IT 운영에 매우 중요합니다. ONTAP에는 운영을 간소화 및 단순화하고 총 운영 비용을 절감할 수 있는 다음과 같은 기능이 포함되어 있습니다.</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">* 인라인 데이터 컴팩션 및 확대된 중복제거. * 데이터 컴팩션은 스토리지 블록 내부의 낭비되는 공간을 줄이고, 중복제거는 실제 용량을 크게 증가시킵니다. 이는 로컬에 저장된 데이터와 클라우드로 계층화된 데이터에 적용됩니다.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">* 최소, 최대 및 적응형 서비스 품질(AQoS). * 세분화된 서비스 품질(QoS) 제어는 공유 수준이 높은 환경에서 중요 애플리케이션의 성능 수준을 유지하는 데 도움이 됩니다.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool. * 이 기능은 콜드 데이터를 AWS(Amazon Web Services), Azure, NetApp StorageGRID 스토리지 솔루션을 포함한 퍼블릭 및 프라이빗 클라우드 스토리지 옵션으로 자동 계층화합니다. FabricPool에 대한 자세한 내용은 를 참조하십시오 <block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">데이터 가속화 및 보호</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9은 탁월한 수준의 성능과 데이터 보호를 제공하며 다음과 같은 방법으로 이러한 기능을 확장합니다.</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">* 성능 및 낮은 지연 시간 * ONTAP는 가장 짧은 지연 시간으로 가장 높은 처리량을 제공합니다.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">* 데이터 보호. * ONTAP는 모든 플랫폼에서 공통 관리를 지원하는 내장 데이터 보호 기능을 제공합니다.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* NVE(NetApp 볼륨 암호화). * ONTAP는 온보드 및 외부 키 관리를 모두 지원하여 네이티브 볼륨 레벨 암호화를 제공합니다.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">* 멀티테넌시 및 다단계 인증 * ONTAP를 통해 인프라 리소스를 최고 수준의 보안으로 공유할 수 있습니다.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">미래 지향형 인프라</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9은 다음과 같은 기능을 통해 지속적으로 변화하는 까다로운 비즈니스 요구사항을 충족할 수 있도록 지원합니다.</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">* 원활한 확장 및 무중단 운영 * ONTAP은 기존 컨트롤러 및 스케일아웃 클러스터에 무중단으로 용량을 추가할 수 있도록 지원합니다. 고객은 고비용이 따르는 데이터 마이그레이션이나 운영 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="0cee26e8172666a9085f957269fc4b64" category="list-text">* 클라우드 연결. * ONTAP은 클라우드에 가장 많이 연결되는 스토리지 관리 소프트웨어로, 모든 퍼블릭 클라우드에서 소프트웨어 정의 스토리지(ONTAP Select) 및 클라우드 네이티브 인스턴스(NetApp Cloud Volumes Service) 옵션이 제공됩니다.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">새로운 애플리케이션과의 통합 * ONTAP는 기존 엔터프라이즈 앱을 지원하는 인프라와 동일한 인프라를 사용하여 자율주행 차량, 스마트 시티, Industry 4.0과 같은 차세대 플랫폼 및 애플리케이션을 위한 엔터프라이즈급 데이터 서비스를 제공합니다.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity를 참조하십시오</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">NetApp E-Series SANtricity 소프트웨어 데이터시트 를 참조하십시오</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity는 E-Series 하이브리드 플래시 및 EF-Series All-Flash 어레이에 업계 최고의 성능, 안정성, 단순성을 제공하도록 설계되었습니다. 데이터 분석, 비디오 감시, 백업 및 복구 등 워크로드가 많은 애플리케이션에서 E-Series 하이브리드 플래시 및 EF-Series All-Flash 어레이의 성능과 활용률을 극대화합니다. SANtricity를 사용하면 스토리지를 온라인 상태로 유지하면서 구성 조정, 유지 관리, 용량 확장 및 기타 작업을 완료할 수 있습니다. 또한 SANtricity는 사용하기 쉬운 온박스형 시스템 관리자 인터페이스를 통해 뛰어난 데이터 보호, 사전 예방 모니터링 및 인증 보안을 제공합니다. 자세한 내용은 를 참조하십시오<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>.</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">최적의 성능</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">성능에 최적화된 SANtricity 소프트웨어는 모든 데이터 분석, 비디오 감시 및 백업 앱에 높은 IOPS 및 처리량과 짧은 지연 시간으로 데이터를 제공합니다. IOPS가 높고 지연 시간이 짧은 애플리케이션과 대역폭과 처리량이 높은 애플리케이션의 성능을 더욱 높이십시오.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">가동 시간 극대화</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">스토리지가 온라인 상태일 때 모든 관리 작업을 완료하십시오. I/O를 중단하지 않고 구성을 변경하거나, 유지보수를 수행하거나, 용량을 확장할 수 있습니다 자동화된 기능, 온라인 구성, 최첨단 DPP(Dynamic Disk Pool) 기술 등을 통해 동급 최고의 안정성을 실현합니다.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">편안한 휴식</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">SANtricity 소프트웨어는 사용이 간편한 온박스형 시스템 관리자 인터페이스를 통해 뛰어난 데이터 보호, 사전 예방 모니터링 및 인증 보안을 제공합니다. 스토리지 관리 업무를 간소화합니다. 모든 E-Series 스토리지 시스템의 고급 튜닝에 필요한 유연성 확보 언제 어디서나 NetApp E-Series 시스템을 관리할 수 있습니다. NetApp의 온박스 웹 기반 인터페이스는 관리 워크플로우를 간소화합니다.</block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="section-title">NetApp 트라이던트</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block> NetApp은 Docker 및 Kubernetes용 오픈 소스 동적 스토리지 오케스트레이터로서 영구 스토리지의 생성, 관리 및 사용을 단순화합니다. Kubernetes 네이티브 애플리케이션인 Trident는 Kubernetes 클러스터 내에서 직접 실행됩니다. Trident를 사용하면 고객이 DL 컨테이너 이미지를 NetApp 스토리지에 원활하게 배포하고 AI 컨테이너 배포를 위한 엔터프라이즈급 경험을 제공할 수 있습니다. Kubernetes 사용자(예: ML 개발자 및 데이터 과학자)는 오케스트레이션 및 클론 복제를 생성, 관리 및 자동화하여 NetApp 기술이 제공하는 NetApp 고급 데이터 관리 기능을 활용할 수 있습니다.</block>
  <block id="dc188738e6cc2e9f8314e1b95f18ebfd" category="section-title">NetApp Cloud Sync를 참조하십시오</block>
  <block id="e367efbc26bd12c0d6ae37dd6a55ef9b" category="inline-link">Cloud Sync</block>
  <block id="2d76806bea2175a1c575d37015a3621b" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> 는 빠르고 안전한 데이터 동기화를 제공하는 NetApp 서비스입니다. 온프레미스 NFS 또는 SMB 파일 공유, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, Amazon S3(Amazon Simple Storage Service), Amazon Elastic File System(Amazon EFS), Azure Blob, Google Cloud Storage 간에 파일을 전송해야 하는 경우 또는 IBM 클라우드 오브젝트 스토리지인 Cloud Sync를 사용하면 파일을 필요한 곳으로 빠르고 안전하게 이동할 수 있습니다. 데이터가 전송되면 소스와 타겟 모두에서 사용할 수 있습니다. Cloud Sync는 미리 정의된 일정에 따라 데이터를 지속적으로 동기화하여 변경된 부분만 이동하므로 데이터 복제에 소비되는 시간과 비용이 최소화됩니다. Cloud Sync는 매우 간편한 설정 및 사용이 가능한 SaaS(Software as a Service) 툴입니다. Cloud Sync에 의해 트리거되는 데이터 전송은 데이터 브로커가 수행합니다. AWS, Azure, Google Cloud Platform 또는 온프레미스에서 Cloud Sync 데이터 브로커를 구축할 수 있습니다.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="section-title">Lenovo ThinkSystem 서버</block>
  <block id="e76fa728781968dd4a707e2d3b1d8108" category="paragraph">Lenovo ThinkSystem 서버는 현재 고객의 과제를 해결하고 미래의 과제를 해결할 수 있는 혁신적인 모듈식 설계 접근 방식을 제공하는 혁신적인 하드웨어, 소프트웨어 및 서비스를 갖추고 있습니다. 이러한 서버는 동급 최강의 업계 표준 기술과 차별화된 Lenovo의 혁신적인 기술을 결합하여 x86 서버에서 최대한의 유연성을 제공합니다.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Lenovo ThinkSystem 서버 배포의 주요 이점은 다음과 같습니다.</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">비즈니스 성장에 맞춰 확장할 수 있는 모듈식 설계</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">업계 최고 수준의 복원력으로 예기치 못한 가동 중지의 비용이 많이 드는 시간을 절약할 수 있습니다</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">빠른 플래시 기술을 통해 지연 시간을 단축하고, 응답 시간을 단축하며, 데이터 관리를 실시간으로 수행할 수 있습니다</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">AI 분야에서 Lenovo는 기업들이 워크로드에 대한 ML 및 AI의 이점을 이해하고 적용할 수 있도록 실질적인 접근 방식을 취하고 있습니다. Lenovo 고객은 Lenovo AI Innovation Center의 Lenovo AI 제품을 살펴보고 평가하여 해당 사용 사례의 가치를 완벽하게 파악할 수 있습니다. 가치 창출 시간을 단축하기 위해 이 고객 중심 접근 방식은 AI에 사용하고 최적화할 수 있는 솔루션 개발 플랫폼에 대한 개념 증명을 고객에게 제공합니다.</block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="section-title">Lenovo ThinkSystem SE350 Edge 서버</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">에지 컴퓨팅을 사용하면 데이터 센터 또는 클라우드로 전송되기 전에 네트워크 에지에서 IoT 장치의 데이터를 분석할 수 있습니다. 아래 그림과 같이 Lenovo ThinkSystem SE350은 견고하며 환경 친화적인 소형 폼 팩터에서 유연성, 연결, 보안 및 원격 관리 기능에 중점을 두고 엣지에서의 배포를 위한 고유한 요구 사항을 충족하도록 설계되었습니다.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">에지 AI 워크로드에 대한 가속화를 지원할 수 있는 유연성을 갖춘 인텔 제온 D 프로세서를 장착한 SE350은 데이터 센터 외부의 다양한 환경에서 서버 배포의 과제를 해결하기 위해 특별히 제작되었습니다.</block>
  <block id="b739a166d96ffd72ac4d456012bfbe21" category="paragraph"><block ref="b739a166d96ffd72ac4d456012bfbe21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="paragraph"><block ref="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="section-title">MLPerf</block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf Inference v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf는 AI 성능 평가를 위한 업계 최고의 벤치마크 제품군입니다. 여기에는 영상 분류, 물체 감지, 의료 영상 및 NLP(자연어 처리)를 비롯한 다양한 적용 AI 영역을 다룹니다. 이 검증에서는 이 검증이 완료될 때 MLPerf 추론의 최신 반복인 Inference v0.7 워크로드를 사용했습니다. 를 클릭합니다<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> 데이터 센터 및 에지 시스템을 위한 새로운 벤치마크 4개가 포함된 제품군:</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">* BERT. * Transformers(BERT)의 양방향 Encoder Representation은 Squad 데이터 세트를 사용하여 질문 답변에 맞게 미세 조정되었습니다.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">* DLRM. * DLRM(Deep Learning Recommendation Model)은 CTR(Click-Through Rates)을 최적화하도록 교육받은 개인 설정 및 권장 모델입니다.</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">* 3D U-Net. * 3D U-Net 아키텍처는 Brain Tumor Segmentation(뇌종양 분할) 데이터 세트에 대한 교육을 받습니다.</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">* RNN-T * Recurrent Neural Network Transducer(RNN-T)는 LibriSpeech의 하위 집합에 대한 교육을 받은 자동 음성 인식(ASR) 모델입니다. MLPerf Inference 결과 및 코드는 공개적으로 사용할 수 있으며 Apache 라이센스에 따라 릴리스됩니다. MLPerf Inference에는 다음과 같은 시나리오를 지원하는 Edge 분산이 있습니다.</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">* 단일 스트림. * 이 시나리오는 스마트폰에서 실행되는 오프라인 AI 쿼리와 같이 응답성이 중요한 요소인 시스템을 모방합니다. 개별 쿼리가 시스템으로 전송되고 응답 시간이 기록됩니다. 모든 응답의 90번째 백분위수 지연 시간이 결과로 보고됩니다.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">* 멀티스트림. * 이 벤치마크는 여러 센서의 입력을 처리하는 시스템을 위한 것입니다. 테스트 중에 쿼리는 고정된 시간 간격으로 전송됩니다. QoS 제약(허용되는 최대 지연 시간)이 적용됩니다. QoS 제한을 충족하는 동안 시스템에서 처리할 수 있는 스트림의 수를 보고합니다.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">* Offline. * 배치 처리 응용 프로그램을 다루는 가장 간단한 시나리오이며 메트릭은 초당 샘플 처리량입니다. 모든 데이터를 시스템에서 사용할 수 있으며 벤치마크는 모든 샘플을 처리하는 데 걸리는 시간을 측정합니다.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="c953c121914b99f83398f20ab2160ed1" category="paragraph">Lenovo는 이 문서에 사용된 서버인 T4가 포함된 SE350에 대한 MLPerf Inference 점수를 게시했습니다. 의 결과를 참조하십시오<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> 입력 #0.7-145의 "Edge, Closed Division" 섹션에 있습니다.</block>
  <block id="26cb2cd90a9e0e03f63323eab13f117d" category="inline-link-macro">다음: 테스트 계획.</block>
  <block id="91666b8460dc62d134fe80c31f05d28b" category="paragraph"><block ref="91666b8460dc62d134fe80c31f05d28b" category="inline-link-macro-rx"></block></block>
  <block id="f521e3eae9fd2145ce8aeede6602641d" category="summary">이 섹션에서는 이 솔루션의 다양한 구성 요소에 대한 설계 고려 사항에 대해 설명합니다.</block>
  <block id="648bdcd0b9a0f83d7b068dbed3c21c07" category="doc">설계 고려 사항</block>
  <block id="5b1c62f1e35074e19185d9341b492c54" category="inline-link-macro">이전: 아키텍처.</block>
  <block id="b180067c966e23ba80c92f3bb1bf6745" category="paragraph"><block ref="b180067c966e23ba80c92f3bb1bf6745" category="inline-link-macro-rx"></block></block>
  <block id="35ff22a5291df56d5075c29d8dc65044" category="section-title">네트워크 및 컴퓨팅 설계</block>
  <block id="49d41bdb2234e0a4330f0c9d7d03853a" category="paragraph">데이터 보안 제한에 따라 모든 데이터는 고객의 인프라 또는 보안 환경 내에 있어야 합니다.</block>
  <block id="5a20c2b759137410d60f5ce368ca45d2" category="paragraph"><block ref="5a20c2b759137410d60f5ce368ca45d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d6e133bd239a98d559f693ee2ff5ecc" category="section-title">스토리지 설계</block>
  <block id="3051d856c7b26f6d385279d67a8a532b" category="paragraph">NetApp DataOps 툴킷은 스토리지 시스템 관리를 위한 1차 서비스 역할을 합니다. DataOps Toolkit은 개발자, 데이터 과학자, DevOps 엔지니어 및 데이터 엔지니어가 새로운 데이터 볼륨의 거의 즉각적인 프로비저닝 또는 JupyterLab 작업 공간, 데이터 볼륨의 거의 즉각적인 클론 복제 또는 JupyterLab 작업 공간과 같은 다양한 데이터 관리 작업을 간단하게 수행할 수 있는 Python 라이브러리입니다. 추적 기능 또는 베이스라인 기능을 위한 데이터 볼륨 또는 JupyterLab 작업 공간의 거의 즉각적인 스냅샷 기능을 제공합니다. 이 Python 라이브러리는 명령줄 유틸리티 또는 모든 Python 프로그램 또는 Jupyter Notebook로 가져올 수 있는 기능 라이브러리 중 하나로 작동할 수 있습니다.</block>
  <block id="6f9e8585e5f750b8ceb149639b1e25e6" category="section-title">Riva 모범 사례</block>
  <block id="7ecab6bd65c2f169e987be2f59219357" category="inline-link">모범 데이터 사례</block>
  <block id="f51b8fa6c731ea53318149e50e826ddb" category="paragraph">NVIDIA는 몇 가지 일반적인 기능을 제공합니다<block ref="f6aee1daf7f2fd9cd207fcd26f08d8be" category="inline-link-rx"></block> Riva 사용:</block>
  <block id="20430e77ba2ecbe15261761c8f4fa2c4" category="list-text">* 가능한 경우 무손실 오디오 형식을 사용합니다. * MP3와 같은 손실 코덱을 사용하면 품질이 저하될 수 있습니다.</block>
  <block id="8b3e389f067f32da1e1ab7df2b8d8155" category="list-text">* 교육 데이터를 보강합니다. * 오디오 교육 데이터에 배경 잡음을 추가하면 처음에는 정확도가 떨어되지만 견고성이 향상됩니다.</block>
  <block id="b37d69a795b4d7bb6e0f28a42c3ef8ae" category="list-text">* 스크레핑된 텍스트를 사용할 경우 어휘 크기를 제한합니다. * 많은 온라인 출처에는 오타 또는 부수적인 대명사 및 일반적이지 않은 단어가 포함되어 있습니다. 이러한 언어를 제거하면 언어 모델이 개선될 수 있습니다.</block>
  <block id="6afe4c71ada39a70da349380efbad345" category="list-text">* 가능한 경우 최소 16kHz의 샘플링 속도를 사용하십시오. * 그러나 리샘플링을 시도하지 마십시오. 리샘플링을 하면 오디오 품질이 저하됩니다.</block>
  <block id="cab3977e4ad163e19ab6245a9b09f541" category="paragraph">이러한 모범 사례 외에도 고객은 파이프라인의 각 단계에 대해 정확한 레이블이 있는 대표적인 샘플 데이터 세트를 우선적으로 수집해야 합니다. 즉, 샘플 데이터 세트는 타겟 데이터 세트에 예시된 지정된 특성을 비율에 맞게 반영해야 합니다. 마찬가지로 데이터 세트의 주석 역시 데이터의 품질과 양을 모두 최대화하도록 정확도와 레이블 지정 속도를 조율할 책임이 있습니다. 예를 들어, 이 지원 센터 솔루션에는 오디오 파일, 텍스트 레이블 및 정서 레이블이 필요합니다. 이 솔루션의 순차적 특성은 파이프라인 시작 부분의 오류가 끝까지 전파된다는 것을 의미합니다 오디오 파일의 품질이 좋지 않으면 텍스트 사본과 정서 레이블도 함께 표시됩니다.</block>
  <block id="0b6b65c9613285433178682e3550355c" category="paragraph">이 오류 전파는 이 데이터에 대한 교육을 받은 모델에도 비슷하게 적용됩니다. 감정의 예측이 100% 정확하지만 텍스트 음성 변환 모델이 제대로 작동하지 않는 경우, 최종 파이프라인은 초기 오디오-텍스트 사본으로 제한됩니다. 개발자는 각 모델의 성능을 개별적으로, 대규모 파이프라인의 구성 요소로 고려하는 것이 중요합니다. 이 경우 최종 목표는 감정을 정확하게 예측할 수 있는 파이프라인을 개발하는 것입니다. 따라서 파이프라인을 평가하는 전반적인 지표는 음성-텍스트 전사가 직접적으로 영향을 미치는 정서 정확도입니다.</block>
  <block id="f3b552e561f520013398b3be885a4420" category="paragraph"><block ref="f3b552e561f520013398b3be885a4420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1ce31a9f2a1a3a478bb69589e180bd" category="paragraph">NetApp DataOps 툴킷은 즉각적인 데이터 클론 복제 기술을 사용하여 데이터 품질 점검 파이프라인을 보완합니다. 레이블이 지정된 각 파일을 평가하고 기존의 레이블 파일과 비교해야 합니다. 이러한 품질 검사를 다양한 데이터 스토리지 시스템에 분산하면 이러한 검사가 빠르고 효율적으로 실행됩니다.</block>
  <block id="6d61a746e66a6545c5c9faf68668e013" category="inline-link-macro">다음: 지원 센터 정서 분석 구축</block>
  <block id="58a113e09ecc7941870d9bcc2d2ee3df" category="paragraph"><block ref="58a113e09ecc7941870d9bcc2d2ee3df" category="inline-link-macro-rx"></block></block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">추가 정보를 찾을 수 있는 위치</block>
  <block id="c701c7fe143bef79cc6eebc32606262e" category="paragraph">이 문서에 설명된 정보에 대한 자세한 내용은 다음 리소스를 참조하십시오.</block>
  <block id="b682eee68510f6de72c9f48b832fba3c" category="inline-link"><block ref="b682eee68510f6de72c9f48b832fba3c" category="inline-link-rx"></block></block>
  <block id="3e5d8230d86c09995fcd8e9ccf335813" category="list-text">cnvrg.io(<block ref="0691e14f48847a7f13eaf800c0f5813a" category="inline-link-rx"></block>):</block>
  <block id="6536b07bf755c64528073e655a567c32" category="list-text">cnvrg 코어(무료 ML 플랫폼)</block>
  <block id="0a16af2994c8e10c6c5976d774430a92" category="paragraph"><block ref="0a16af2994c8e10c6c5976d774430a92" category="inline-link-rx"></block></block>
  <block id="1b21ae34f592a7f2ca92d4a44122475d" category="list-text">cnvrg 문서</block>
  <block id="0730c44e9dc233c7fce5d95816294f52" category="inline-link"><block ref="0730c44e9dc233c7fce5d95816294f52" category="inline-link-rx"></block></block>
  <block id="f3a2f110576ed38849e70a6bb9794ae8" category="paragraph"><block ref="f3a2f110576ed38849e70a6bb9794ae8" category="inline-link-rx"></block></block>
  <block id="c7c082299876892b4274ecfb3c3f7bcd" category="list-text">NVIDIA DGX-1 서버:</block>
  <block id="d2647f7d8e79758eea27c6cdcf636638" category="list-text">NVIDIA DGX-1 서버</block>
  <block id="45a310b0e4b087b75cb073303044f6f9" category="paragraph"><block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="65d1be94e9f29dc4af77bef169d5be14" category="list-text">NVIDIA Tesla V100 Tensor 코어 GPU</block>
  <block id="fad8218d69ce01748faed5492aa5d3ef" category="paragraph"><block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="list-text">NGC(NVIDIA GPU Cloud)</block>
  <block id="5c75bfead88762783d54deaaa3d62735" category="paragraph"><block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="64ba1593b4427fb62b53b007d4a1c26e" category="list-text">NetApp AFF 시스템:</block>
  <block id="584122d1d5e8c2c4232e029a6896ba40" category="list-text">AFF 데이터시트 를 참조하십시오</block>
  <block id="092940c9deac7c0f10a0ed36613c28c2" category="paragraph"><block ref="092940c9deac7c0f10a0ed36613c28c2" category="inline-link-rx"></block></block>
  <block id="b4199ce9c494dec10c6ee051ddb413e2" category="list-text">AFF를 위한 NetApp FlashAdvantage</block>
  <block id="9dcd8a7bfc88cf6bbca4b422861950bf" category="paragraph"><block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="30df7f622635480ab538fb3016f9c36a" category="list-text">ONTAP 9.x 설명서</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="paragraph"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="35d8efcf211e40a836698bff14ed0ff6" category="list-text">NetApp FlexGroup 기술 보고서</block>
  <block id="1ab29fc7fde3319a82a477ec308cf820" category="paragraph"><block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="de1e4a3a0cae539a34678546eb6e91b3" category="list-text">컨테이너용 NetApp 영구 스토리지:</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="paragraph"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="1cb9a8619999ebc0a2d9c07624d76166" category="list-text">NetApp 상호 운용성 매트릭스:</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="list-text">NetApp 상호 운용성 매트릭스 툴</block>
  <block id="d51c982ce98a1e197c234ea0b9a5e7d9" category="paragraph"><block ref="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link-rx"></block></block>
  <block id="7a211d267d46c5b44662098f9234fcd0" category="list-text">ONTAP AI 네트워킹:</block>
  <block id="b8a60c56690ddfc62bd735d0b212c396" category="list-text">Cisco Nexus 3232C 스위치</block>
  <block id="bb31172f259c591005fd4cbcdbfadd11" category="paragraph"><block ref="bb31172f259c591005fd4cbcdbfadd11" category="inline-link-rx"></block></block>
  <block id="926dc08a3a3a3946402bb1beab6545cc" category="list-text">Mellanox Spectrum 2000 시리즈 스위치</block>
  <block id="492f548658890a1d2495b8af5cebef8c" category="paragraph"><block ref="11ff6f8fb3928ea5c0863401e5e79d17" category="inline-link-rx"></block></block>
  <block id="193721fbb9ea3851cafcea43a4d95f73" category="list-text">ML 프레임워크 및 도구:</block>
  <block id="edb7d6728a9813b505cb306367d453e3" category="list-text">달리</block>
  <block id="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="paragraph"><block ref="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link-rx"></block></block>
  <block id="1b2766572fa1896116e3c218eb697113" category="list-text">TensorFlow: 모두를 위한 오픈 소스 머신 러닝 프레임워크</block>
  <block id="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="paragraph"><block ref="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link-rx"></block></block>
  <block id="26909d0380bdba02e2fcf7f7157cd78b" category="list-text">Horovod: Uber의 TensorFlow용 오픈 소스 분산 딥 러닝 프레임워크</block>
  <block id="3ffa9619031400d374ed5c0860d434ab" category="paragraph"><block ref="3ffa9619031400d374ed5c0860d434ab" category="inline-link-rx"></block></block>
  <block id="c9cbaff7c173f4b7bc923573ca753577" category="list-text">컨테이너 런타임 에코시스템에서 GPU 지원</block>
  <block id="b3a776c1e64d267ebe62a7bf45c6c1b7" category="paragraph"><block ref="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link-rx"></block></block>
  <block id="4c3db4ae25b5f5aaa206a7fedd201322" category="paragraph"><block ref="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link-rx"></block></block>
  <block id="30136395f01879792198317c11831ea4" category="list-text">쿠버네티스</block>
  <block id="9b4643ea7f05b216a0cf56ceddb43241" category="paragraph"><block ref="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link-rx"></block></block>
  <block id="142f782bb2b326679982208fe40cec31" category="list-text">NVIDIA DeepOps</block>
  <block id="ccd09fd9430cf2df88a137dbec97676b" category="paragraph"><block ref="ccd09fd9430cf2df88a137dbec97676b" category="inline-link-rx"></block></block>
  <block id="a33d91971f7757996ab0eb8eb0362814" category="paragraph"><block ref="a33d91971f7757996ab0eb8eb0362814" category="inline-link-rx"></block></block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="list-text">Jupyter 노트북 서버</block>
  <block id="c90a0598d42425e6ec2dfb3058534b35" category="paragraph"><block ref="c90a0598d42425e6ec2dfb3058534b35" category="inline-link-rx"></block></block>
  <block id="22d149e351657eac5bd1db4934498bbe" category="list-text">데이터 세트 및 벤치마크</block>
  <block id="717108fd0999828c4a6d8290d419733b" category="list-text">NIH 흉부 X선 데이터 세트</block>
  <block id="4eb7427d14327fa86230f324870dc6b8" category="paragraph"><block ref="4eb7427d14327fa86230f324870dc6b8" category="inline-link-rx"></block></block>
  <block id="f249b6ce18772b83efb8a6e58ac09d47" category="list-text">Xiaosong Wang, Yifan Peng, Le Lu, Zhivyong Lu, Mohammadadadhadi Bagheri, Ronald Summers, ChestX-ray8: 병원 스케일 흉부 X선 데이터베이스 및 약한 감독 하에 Common Thorax 질환의 분류 및 국소화에 대한 벤치마크, IEEE CVPR, pp. 3462-3471, 2017TR-4841-0620</block>
  <block id="2732cb29fe3befd83c06e7c220b5456d" category="doc">섹션 4.10에 대한 테스트 세부 정보</block>
  <block id="6b4330df9a37bcfef1faecd1e8973464" category="inline-link-macro">할당량 초과 공정성</block>
  <block id="273936fc522fd7dbe4473de8a0b2a985" category="paragraph">이 섹션에서는 섹션에 대한 테스트 세부 정보를 다룹니다 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>.</block>
  <block id="cf46f9264bb33ef7576cf671194a0275" category="paragraph">팀-A, 팀-b, 팀-c의 순서로 작업을 제출합니다.</block>
  <block id="9e727fdd3aec8274f46685441900280d" category="cell">프로젝트</block>
  <block id="b3428404a5be1cf95d4e53b2ddc8288a" category="cell">GPU 수</block>
  <block id="96b0141273eabab320119c467cdcaf17" category="cell">합계</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">설명</block>
  <block id="9320270de4ff6824ae7a21f729fb7d44" category="cell">팀-A</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="36d2df43ead992a1e3c86acd0cec69f9" category="cell">4월 4일</block>
  <block id="fac80c1054e849e1ec88244c017978e7" category="cell">1개의 워크로드가 대기열에 있습니다</block>
  <block id="eefc99cd833e14811fb22b758cbc62e5" category="cell">2개의 작업 부하가 대기 중입니다</block>
  <block id="238ff8d9192e9c01e50a8d6d21f1607b" category="cell">팀-b</block>
  <block id="867c7d7d65c50ae3679fabce2eab87a3" category="cell">2월 2일</block>
  <block id="3b40d1328b825dda4b761a8e534669b7" category="cell">팀 - c</block>
  <block id="be46ffa9e65cb964fc3236de02c41e4e" category="paragraph">다음 실행된 명령 시퀀스를 참조하십시오.</block>
  <block id="3bf38f884fd74f6e6f1ec3d80018edd8" category="paragraph">이때 다음과 같은 상태가 있어야 합니다.</block>
  <block id="e55f05703a3e04fbd9e10f76ae925cc9" category="cell">GPU가 할당되었습니다</block>
  <block id="26cc9c6ccae01f319282379c339cd90b" category="cell">작업 로드 대기 중</block>
  <block id="001f9003205f670658ffc60b1e4d62d8" category="cell">각각 GPU를 묻는 2개의 워크로드</block>
  <block id="f0f10ddbe8f00433aad17626c8d96a73" category="cell">각각 2개의 GPU를 요구하는 2개의 워크로드</block>
  <block id="ae7ccf7b1a6a1a023f611a294572a900" category="cell">팀 d</block>
  <block id="f82056dbbe3376b10ac622b0bdaae914" category="cell">8월 8일</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="cell">없음</block>
  <block id="61b8291124bff8ee36a1c799e35395e9" category="paragraph">그런 다음 'team-d'에 대한 모든 워크로드를 삭제합니다.</block>
  <block id="ed9cf33d84548b5953f8b042c72faef4" category="paragraph">섹션을 참조하십시오 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>를 참조하십시오.</block>
  <block id="543cdcd352596e4ad69b4597a2188c02" category="paragraph"><block ref="543cdcd352596e4ad69b4597a2188c02" category="inline-link-macro-rx"></block></block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">제안된 아키텍처의 성능을 평가하기 위해 다수의 테스트를 실행했습니다. 6가지 워크로드(영상 분류, 물체 감지[소형], 물체 감지[대형], 의료 영상, 텍스트 음성 변환, 및 NLP(자연어 처리))를 사용하여 오프라인, 단일 스트림 및 멀티스트림 등 세 가지 시나리오에서 실행할 수 있습니다.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">테스트 결과</block>
  <block id="5e2777e1d5ba6adfeabc55064de508f5" category="inline-link-macro">이전: 테스트 절차</block>
  <block id="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="paragraph"><block ref="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="inline-link-macro-rx"></block></block>
  <block id="507b481f4f0fb36b82f97222c73fb91d" category="section-title">AFF에 대한 테스트 결과</block>
  <block id="817fbb6103e6cb6855c19a5c1b25f817" category="paragraph">제안된 아키텍처의 성능을 평가하기 위해 다수의 테스트를 실행했습니다. 6가지 워크로드(영상 분류, 물체 감지[소형], 물체 감지[대형], 의료 영상, 텍스트 음성 변환, 및 NLP(Natural Language Processing))를 사용하여 오프라인, 단일 스트림 및 멀티스트림의 세 가지 시나리오에서 실행할 수 있습니다.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">마지막 시나리오는 영상 분류 및 물체 감지에 대해서만 구현됩니다.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">이렇게 하면 다음과 같은 세 가지 다른 설정 하에서 모두 테스트한 15가지 가능한 워크로드가 제공됩니다.</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">단일 서버/로컬 스토리지</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">단일 서버/네트워크 스토리지</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">멀티 서버/네트워크 스토리지</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">결과는 다음 섹션에 설명되어 있습니다.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">AFF의 오프라인 시나리오에서 AI 추론을 사용합니다</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">이 시나리오에서는 서버에서 모든 데이터를 사용할 수 있었고 모든 샘플을 처리하는 데 걸린 시간이 측정되었습니다. 테스트 결과로 초당 샘플에 대역폭이 보고됩니다. 두 개 이상의 컴퓨팅 서버를 사용한 경우 모든 서버에 대한 총 대역폭을 합산한 것으로 보고합니다. 아래 그림에서는 세 가지 사용 사례 모두의 결과를 보여 줍니다. 2서버 사례에서는 두 서버의 결합된 대역폭을 보고합니다.</block>
  <block id="d39bc80b598327ae50c15f64c44bb6ea" category="paragraph"><block ref="d39bc80b598327ae50c15f64c44bb6ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">결과에 따르면 네트워크 스토리지는 성능에 부정적인 영향을 주지 않습니다. 변경 사항은 최소이며 일부 작업의 경우 아무것도 발견되지 않습니다. 두 번째 서버를 추가할 때 총 대역폭이 정확히 두 배 또는 최악의 경우 변경률이 1% 미만입니다.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">AFF의 단일 스트림 시나리오에서 AI 추론을 사용합니다</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">이 벤치마크는 지연 시간을 측정합니다. 여러 계산 서버 사례에서는 평균 지연 시간을 보고합니다. 작업 세트의 결과는 아래 그림에 나와 있습니다. 2서버 사례에서는 두 서버 모두의 평균 지연 시간을 보고합니다.</block>
  <block id="01f3906715186988e276bc34ebc661c0" category="paragraph"><block ref="01f3906715186988e276bc34ebc661c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">결과는 네트워크 스토리지가 작업을 처리하기에 충분하다는 것을 다시 한 번 보여 줍니다. 한 서버 케이스에서 로컬 스토리지와 네트워크 스토리지의 차이는 최소 또는 없음입니다. 마찬가지로 두 서버가 동일한 스토리지를 사용하는 경우 두 서버의 지연 시간은 동일하게 유지되거나 매우 적은 양의 변경 사항이 적용됩니다.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">AFF의 다중 스트림 시나리오에서 AI 추론을 사용합니다</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">이 경우 결과적으로 QoS 제약 조건을 만족하면서 시스템에서 처리할 수 있는 스트림의 수가 됩니다. 따라서 결과는 항상 정수입니다. 둘 이상의 서버에 대해 모든 서버에 대해 집계된 총 스트림 수를 보고합니다. 모든 워크로드가 이 시나리오를 지원하는 것은 아니지만 이를 실행했습니다. 테스트 결과는 아래 그림에 요약되어 있습니다. 2서버 사례에서는 두 서버 모두에서 스트림 수가 결합된 것으로 보고합니다.</block>
  <block id="758b60f43cbc650fded1dcf9be428fa5" category="paragraph"><block ref="758b60f43cbc650fded1dcf9be428fa5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">결과는 설정의 완벽한 성능을 보여줍니다. 로컬 및 네트워킹 스토리지는 동일한 결과를 제공하며 두 번째 서버를 추가하면 제안된 설정에서 처리할 수 있는 스트림 수가 두 배가 됩니다.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">EF 테스트 결과</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">제안된 아키텍처의 성능을 평가하기 위해 다수의 테스트를 실행했습니다. 6가지 워크로드(영상 분류, 물체 감지[소형], 물체 감지[대형], 의료 영상, 텍스트 음성 변환, 두 가지 시나리오(오프라인 및 단일 스트림)에서 실행된 자연어 처리[NLP])를 들 수 있습니다. 결과는 다음 섹션에 설명되어 있습니다.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">EF의 오프라인 시나리오에서 AI 추론을 사용합니다</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">이 시나리오에서는 서버에서 모든 데이터를 사용할 수 있었고 모든 샘플을 처리하는 데 걸린 시간이 측정되었습니다. 테스트 결과로 초당 샘플에 대역폭이 보고됩니다. 단일 노드 실행의 경우 두 서버 모두에서 평균을 보고하며, 두 서버 실행 시 모든 서버에 대해 총 대역폭을 집계합니다. 사용 사례에 대한 결과는 아래 그림에 나와 있습니다.</block>
  <block id="8e793f971410e2b57df427d1305ee0a2" category="paragraph"><block ref="8e793f971410e2b57df427d1305ee0a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">EF의 단일 스트림 시나리오에서 AI 추론을 사용합니다</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">이 벤치마크는 지연 시간을 측정합니다. 모든 경우에 대해 실행에 관련된 모든 서버의 평균 지연 시간을 보고합니다. 작업 세트의 결과가 제공됩니다.</block>
  <block id="5656e3a262dfb3d6e1cba96551717de0" category="paragraph"><block ref="5656e3a262dfb3d6e1cba96551717de0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">결과는 네트워크 스토리지가 작업을 처리하기에 충분하다는 것을 다시 보여줍니다. 한 서버 케이스에서 로컬 스토리지와 네트워크 스토리지의 차이는 Minimal(최소) 또는 None(없음)입니다. 마찬가지로 두 서버가 동일한 스토리지를 사용하는 경우 두 서버의 지연 시간은 동일하게 유지되거나 매우 적은 양의 변경 사항이 적용됩니다.</block>
  <block id="516a608926718d1a912cf9404f1a63ac" category="inline-link-macro">다음으로 아키텍처 사이징 옵션을 살펴보겠습니다.</block>
  <block id="9cedf0fb8faddf365d88f523ae482015" category="paragraph"><block ref="9cedf0fb8faddf365d88f523ae482015" category="inline-link-macro-rx"></block></block>
  <block id="290612199861c31d1036b185b4e69b75" category="doc">요약</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">ADAS(Advanced Driver Assistance Systems), Industry 4.0, 스마트 시티 및 IoT(Internet of Things)와 같은 몇 가지 새로운 애플리케이션 시나리오에서는 지연 시간이 거의 없이 지속적인 데이터 스트림을 처리해야 합니다. 이 문서에서는 이러한 요구사항을 충족하는 에지 환경에서 NetApp 스토리지 컨트롤러 및 Lenovo ThinkSystem 서버에 GPU 기반 인공 지능(AI) 추론을 배포하기 위한 컴퓨팅 및 스토리지 아키텍처에 대해 설명합니다. 또한, NVIDIA T4 GPU가 장착된 에지 서버에서 다양한 추론 작업을 평가하여 업계 표준 MLPerf Inference 벤치마크의 성능 데이터도 제공합니다. 오프라인, 단일 스트림 및 다중 스트림 추론 시나리오의 성능을 조사한 결과, 비용 효율적인 공유 네트워크 스토리지 시스템이 포함된 아키텍처의 성능이 매우 뛰어나며 여러 에지 서버에 대한 데이터 및 모델 관리의 중앙 지점을 제공하는 것으로 나타났습니다.</block>
  <block id="e88a70d67e9de42d391fd019f2d06484" category="summary">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및 웹 사이트를 검토하십시오.</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="doc">추가 정보</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹 사이트를 검토하십시오.</block>
  <block id="b49efd5b259d6a3bceda1ebb8e34064a" category="list-text">데이터 세트: TuSimple</block>
  <block id="61554b11b65c50bf7a094a86d699c8d5" category="inline-link"><block ref="61554b11b65c50bf7a094a86d699c8d5" category="inline-link-rx"></block></block>
  <block id="b150fd9c1d7740c871626031a398c8a3" category="paragraph"><block ref="b150fd9c1d7740c871626031a398c8a3" category="inline-link-rx"></block></block>
  <block id="a3a3504f7b11916e352125a598e15797" category="list-text">딥 러닝 네트워크 아키텍처: 공간 컨볼루ional 신경망</block>
  <block id="6467a460cb421335f9f5b0523c38c9a6" category="inline-link"><block ref="6467a460cb421335f9f5b0523c38c9a6" category="inline-link-rx"></block></block>
  <block id="35527148b08f99f1d85797af833430dc" category="paragraph"><block ref="35527148b08f99f1d85797af833430dc" category="inline-link-rx"></block></block>
  <block id="cc1881adebe7ddf5b873966741a32ef1" category="list-text">분산형 딥 러닝 교육 프레임워크: Horovod</block>
  <block id="732f85d0d5eaa9222831dd5290518ff2" category="inline-link"><block ref="732f85d0d5eaa9222831dd5290518ff2" category="inline-link-rx"></block></block>
  <block id="655c281079d0281fcf4b8f2f08634c16" category="paragraph"><block ref="655c281079d0281fcf4b8f2f08634c16" category="inline-link-rx"></block></block>
  <block id="934b1fbd011b584c4878284f454f812e" category="list-text">실행: AI 컨테이너 오케스트레이션 솔루션: 실행: AI 제품 소개</block>
  <block id="64b899832bfcad18bb426fb355a0d03b" category="inline-link"><block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="b78ec84f003a4d277e318031a163e191" category="paragraph"><block ref="b78ec84f003a4d277e318031a163e191" category="inline-link-rx"></block></block>
  <block id="275dbaaa3169640f82917075918df905" category="list-text">AI 설치 설명서를 실행하십시오</block>
  <block id="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link"><block ref="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link-rx"></block></block>
  <block id="517046a8acf2e7fa61798debc5b6e25e" category="inline-link"><block ref="517046a8acf2e7fa61798debc5b6e25e" category="inline-link-rx"></block></block>
  <block id="b8b2e04f115b148d49a8cb477ed86af9" category="paragraph"><block ref="f03e58e4917966d9b82995c8ce69643b" category="inline-link-rx"></block><block ref="3530112fad5ba376549c9e0750df83f3" category="inline-link-rx"></block></block>
  <block id="8787c0bfc5af7ce34db56c9a5739f788" category="list-text">실행 중인 작업 제출: AI CLI</block>
  <block id="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link"><block ref="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link-rx"></block></block>
  <block id="ca4ef6cf830a9de78ea71279d0d5417c" category="paragraph"><block ref="ca4ef6cf830a9de78ea71279d0d5417c" category="inline-link-rx"></block></block>
  <block id="984fd97f526f8afe9d2472b0894b84c2" category="inline-link"><block ref="984fd97f526f8afe9d2472b0894b84c2" category="inline-link-rx"></block></block>
  <block id="65640a241681656a4410cd7184278c9b" category="paragraph"><block ref="65640a241681656a4410cd7184278c9b" category="inline-link-rx"></block></block>
  <block id="33a756969a35b0a9029bf2a2c10e6d67" category="list-text">Azure 클라우드 리소스: Azure NetApp Files</block>
  <block id="99ac98f589f6b551211f31e86cb9a212" category="inline-link"><block ref="99ac98f589f6b551211f31e86cb9a212" category="inline-link-rx"></block></block>
  <block id="3085d4407b575d4a8938814c7db17d92" category="paragraph"><block ref="3085d4407b575d4a8938814c7db17d92" category="inline-link-rx"></block></block>
  <block id="f938809a358080d4c7a941e59abfca40" category="list-text">Azure Kubernetes 서비스</block>
  <block id="21d0acc34f6416d6ebd8074617c57439" category="inline-link"><block ref="21d0acc34f6416d6ebd8074617c57439" category="inline-link-rx"></block></block>
  <block id="91c4b230ded9b13564b447ba71304aeb" category="paragraph"><block ref="91c4b230ded9b13564b447ba71304aeb" category="inline-link-rx"></block></block>
  <block id="d9d650693b25d0540fbb606b1d1fbe4e" category="list-text">Azure VM SKU</block>
  <block id="08318cbecd61665ab1824d118c1029a5" category="inline-link"><block ref="08318cbecd61665ab1824d118c1029a5" category="inline-link-rx"></block></block>
  <block id="3e05fd8f7e2e0ac6116dd746a8823eaa" category="paragraph"><block ref="3e05fd8f7e2e0ac6116dd746a8823eaa" category="inline-link-rx"></block></block>
  <block id="b9a1a7c8f2194407b24183f7826d2e44" category="list-text">GPU SKU가 포함된 Azure VM</block>
  <block id="6046df9266bb79e1d99f9c232c1835e3" category="inline-link"><block ref="6046df9266bb79e1d99f9c232c1835e3" category="inline-link-rx"></block></block>
  <block id="d0bf246853f6f35070f6a8231d468c87" category="paragraph"><block ref="d0bf246853f6f35070f6a8231d468c87" category="inline-link-rx"></block></block>
  <block id="43a545df8285ba2aba289a52824f250d" category="inline-link"><block ref="43a545df8285ba2aba289a52824f250d" category="inline-link-rx"></block></block>
  <block id="944823ac69152177e369bd5d9a61a02f" category="paragraph"><block ref="944823ac69152177e369bd5d9a61a02f" category="inline-link-rx"></block></block>
  <block id="a9359a0f51034e1b1972f7690fe03f71" category="list-text">NetApp 구현 Data Fabric</block>
  <block id="781262103885a96ffc9275431a7ef132" category="inline-link"><block ref="781262103885a96ffc9275431a7ef132" category="inline-link-rx"></block></block>
  <block id="93e35e3e458c1d81846aa83c346e240e" category="paragraph"><block ref="93e35e3e458c1d81846aa83c346e240e" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">NetApp 제품 설명서</block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="677b450634b1a6a563206526cb4d9075" category="doc">TR-4858: 실행 시 NetApp 오케스트레이션 솔루션: AI</block>
  <block id="0959ee1db60e15d1e8e42d1206ca6a19" category="paragraph">Rick Huang, David Arnette, Sung-Han Lin, NetApp Yaron Goldberg, Run: AI</block>
  <block id="c87cafeb37457343ef978bbf8cad88b5" category="paragraph">NetApp AFF 스토리지 시스템은 탁월한 성능과 업계 최고 수준의 하이브리드 클라우드 데이터 관리 기능을 제공합니다. NetApp 및 Run: AI는 엔터프라이즈급 성능, 안정성 및 지원을 제공하는 인공 지능(AI) 및 머신 러닝(ML) 워크로드용 NetApp ONTAP AI 솔루션의 고유한 기능을 시연하기 위해 파트너 계약을 체결했습니다. 실행: AI 워크로드 오케스트레이션에서 Kubernetes 기반 스케줄링 및 리소스 활용률 플랫폼을 추가하여 연구원이 GPU 활용률을 관리하고 최적화할 수 있도록 지원합니다. NVIDIA DGX 시스템과 NetApp, NVIDIA, Run의 통합 솔루션: AI는 엔터프라이즈 AI 워크로드를 위해 특별 제작된 인프라 스택을 제공합니다. 이 기술 보고서는 다양한 사용 사례와 산업 수직 분야를 지원하기 위해 대화형 AI 시스템을 구축하는 고객에게 직접적인 지침을 제공합니다. 이 이니셔티브에는 Run:AI 및 NetApp AFF A800 스토리지 시스템 구축에 대한 정보가 포함되며, AI 이니셔티브를 빠르고 성공적으로 구현하는 가장 간단한 방법을 위한 참조 아키텍처 역할을 합니다.</block>
  <block id="cae36004793b7131e0fc2323f598e7bb" category="list-text">컨테이너 마이크로서비스와 같은 Kubernetes 기반 사용 사례에 대한 AI 모델 및 소프트웨어 개발을 위한 솔루션을 설계하는 엔터프라이즈 설계자</block>
  <block id="5d138e1f42e31fb645a3e3f5a8d37929" category="list-text">여러 팀 및 프로젝트가 있는 클러스터 환경에서 효율적인 모델 개발 목표를 달성할 수 있는 방법을 찾는 데이터 과학자</block>
  <block id="0d43a0c7aeec219a746e836746c0b208" category="list-text">운영 모델의 유지 관리 및 실행을 담당하는 데이터 엔지니어</block>
  <block id="00d764d2e91381a99d6f2c7b108e7c8e" category="list-text">최적의 Kubernetes 클러스터 리소스 활용률 경험을 만들고 AI 이니셔티브를 통한 시장 출시 기간을 단축하려는 경영진 및 IT 의사 결정자 및 비즈니스 리더</block>
  <block id="7a83f363d45e73d7915a600e1bbc92ba" category="inline-link-macro">다음: 솔루션 개요</block>
  <block id="29d90e44a805022079f5ad8bc748f89f" category="paragraph"><block ref="29d90e44a805022079f5ad8bc748f89f" category="inline-link-macro-rx"></block></block>
  <block id="7580f940c2b73a449943bf14cfdb743e" category="summary">이 페이지에서는 Azure NetApp Files에 대한 클라우드 리소스 구성에 대해 설명합니다.</block>
  <block id="9ab9ef31301ca94d2090a6ac7e5141f0" category="doc">클라우드 리소스 요구사항</block>
  <block id="1cee510209f529b7ddd8911bbc6e3ee2" category="inline-link-macro">이전: 소프트웨어 요구 사항.</block>
  <block id="abab2b04b3822b72d0eeb7b61dd84730" category="paragraph"><block ref="abab2b04b3822b72d0eeb7b61dd84730" category="inline-link-macro-rx"></block></block>
  <block id="00130c4c20e30be7264c0ff0d085261b" category="section-title">Azure NetApp Files를 구성합니다</block>
  <block id="d696f60435e09b1c41d1db77b458999b" category="inline-link">QuickStart: Azure NetApp Files를 설정하고 NFS 볼륨을 생성합니다</block>
  <block id="b955f251da04c8c868b22cbe7663a4f5" category="paragraph">에 설명된 대로 Azure NetApp Files를 구성합니다<block ref="f8525997ced72f3cfd70e1aecf287af9" category="inline-link-rx"></block>.</block>
  <block id="4ee734214d7dd4e522f2aab3d8e3d349" category="paragraph">Trident를 통해 볼륨을 생성하므로 "Azure NetApp Files용 NFS 볼륨 생성" 섹션을 계속 진행할 수 있습니다. 계속하기 전에 다음 단계를 완료하십시오.</block>
  <block id="2a304a1348456ccd2234cd71a81bd338" category="inline-link">링크</block>
  <block id="b1d13ce152415787185b9f596f9635e1" category="list-text">Azure Shell을 통해 Azure NetApp Files 및 NetApp 리소스 공급자 에 등록(<block ref="7a85c4f09a460b2978e2b516b5474576" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="4c21364a09ae3c9dab758e383fcae62d" category="list-text">Azure NetApp Files(<block ref="27e1abf4e17aeb1c0d418f5fee2f2b5f" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="97f203356061531d1acaf022df0d4c3c" category="list-text">용량 풀 설정(필요에 따라 최소 4TB Standard 또는 Premium)(<block ref="16f1daa909eef5f1fe1f552d6b28d086" category="inline-link-rx"></block>). 다음 표에는 클라우드에서 설정을 위한 네트워크 구성 요구 사항이 나와 있습니다. Dask 클러스터와 Azure NetApp Files는 동일한 Azure VNet(Virtual Network) 또는 피어링된 VNET에 있어야 합니다.</block>
  <block id="ddcf50c29294d4414f3f7c1bbc892cb5" category="cell">리소스</block>
  <block id="3e19b1ddc4033d0c6c439dad720f730d" category="cell">유형/버전</block>
  <block id="f2d1dd8f39098da402272f7606fd2638" category="cell">1.18.14</block>
  <block id="21b6b0c072968b7235d21d8ec72be5dc" category="cell">에이전트 노드</block>
  <block id="e5262abb96ddec17ecbca3557e70ea26" category="cell">3x Standard_DS2_v2</block>
  <block id="c64f4eaffc33134095fd3105b3d63832" category="cell">GPU 노드</block>
  <block id="11fed615c3da90add7abe544e965fa14" category="cell">표준 _NC6s_v3 3개</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="cell">Azure NetApp Files</block>
  <block id="238f4027146f2469c7d1209e594471e4" category="cell">표준 용량 풀</block>
  <block id="9163995275052e5abd777ae389b15dfd" category="cell">용량(TB</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="a6a0cae93cb8ecdef629c6de5f05989c" category="inline-link-macro">다음: 클릭률 예측 사용 사례 요약</block>
  <block id="a5efee0d52d97830d344cded6ac0bf5c" category="paragraph"><block ref="a5efee0d52d97830d344cded6ac0bf5c" category="inline-link-macro-rx"></block></block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">기술 개요</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">NetApp 개요</block>
  <block id="d30aa8861afaf98888c2367f107a8bc6" category="paragraph">NetApp은 하이브리드 클라우드 환경에서 데이터 관련 최고의 권위자입니다. NetApp은 클라우드와 온프레미스 환경에서 애플리케이션 및 데이터의 관리를 간소화하여 디지털 혁신을 앞당기는 다양한 하이브리드 클라우드 데이터 서비스를 제공합니다. NetApp은 파트너와 함께 글로벌 조직이 데이터의 잠재력을 극대화하여 고객과의 접점을 확대하고 혁신을 촉진하며 운영을 최적화할 수 있도록 돕고 있습니다.</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP AI를 참조하십시오</block>
  <block id="ee86473f0dbd191846077276ce455778" category="paragraph">NVIDIA DGX 시스템과 NetApp 클라우드 연결형 All-Flash 스토리지를 기반으로 하는 NetApp ONTAP AI를 사용하면 데이터 흐름을 안정적으로 간소화하고 에지에서 코어 및 클라우드에 이르는 Data Fabric을 사용하여 분석, 훈련, 추론의 속도를 높일 수 있습니다. 이 아키텍처는 IT 조직에 다음과 같은 이점을 제공하는 아키텍처를 제공합니다.</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">컴퓨팅과 스토리지를 독립적으로 확장할 수 있습니다</block>
  <block id="6cb062d50ca0d4a2bfa0caec33fea16f" category="list-text">다양한 성능 및 비용 포인트를 위한 다양한 스토리지 옵션을 제공합니다.NetApp ONTAP AI는 NVIDIA DGX-1, 페타플롭 확장 AI 시스템, NVIDIA Mellanox 고성능 이더넷 스위치를 통합한 통합 인프라 스택을 제공하여 AI 워크로드를 통합하고 구축을 간소화하고 ROI를 가속합니다. NetApp은 이 기술 보고서를 위해 하나의 DGX-1 및 NetApp AFF A800 스토리지 시스템과 함께 ONTAP AI를 활용했습니다. 다음 이미지는 이 검증에 사용된 DGX-1 시스템과 ONTAP AI의 토폴로지를 보여줍니다.</block>
  <block id="3eedc2d7451e7ff0440f17c9e61227dc" category="paragraph"><block ref="3eedc2d7451e7ff0440f17c9e61227dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="section-title">NetApp AI Control Plane</block>
  <block id="e1fc355cf7f97dbf25407695f8852241" category="paragraph">NetApp AI Control Plane을 사용하면 최고의 확장성, 간소화된 구축, 무중단 데이터 가용성을 제공하는 솔루션을 통해 AI 및 ML을 활용할 수 있습니다. AI Control Plane 솔루션은 Kubernetes 및 Kubeflow를 NetApp 구현 Data Fabric과 통합합니다. 클라우드 네이티브 구현을 위한 업계 표준 컨테이너 오케스트레이션 플랫폼인 Kubernetes는 워크로드 확장성 및 이동성을 지원합니다. Kubeflow는 관리 및 구현을 간소화하여 개발자가 더 많은 데이터 과학을 더 빠르게 수행할 수 있도록 지원하는 오픈 소스 머신 러닝 플랫폼입니다. NetApp 구현 Data Fabric은 최고의 데이터 가용성 및 이동성을 제공하여 에지, 코어, 클라우드에 이르는 파이프라인 전반에서 데이터에 액세스할 수 있도록 합니다. 이 기술 보고서에서는 MLRun 파이프라인에서 NetApp AI Control Plane을 사용합니다. 다음 이미지는 각 클러스터에 대해 서로 다른 엔드포인트를 가질 수 있는 Kubernetes 클러스터 관리 페이지를 보여줍니다. NFS 영구 볼륨을 Kubernetes 클러스터에 연결했고 다음 이미지에는 클러스터에 연결된 영구 볼륨이 표시됩니다. 여기서<block ref="33155b45dbdad2f412212744fbe6f8dc" category="inline-link-rx"></block> 영구 스토리지 지원 및 데이터 관리 기능을 제공합니다.</block>
  <block id="b058638c35435549e77a90b91abd3305" category="paragraph"><block ref="b058638c35435549e77a90b91abd3305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eee185b539f0e52d8b64916066463222" category="paragraph"><block ref="eee185b539f0e52d8b64916066463222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d371ade9f9702601a7e2f8f57c8b013" category="paragraph"><block ref="7d371ade9f9702601a7e2f8f57c8b013" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1dc271f7d3ae88e2a019314b7e4fd8e" category="section-title">Iguazio 개요</block>
  <block id="0c9fe13fe6a660070e99a54151edd7c3" category="paragraph">Iguazio Data Science Platform은 완전히 통합되고 안전한 PaaS(Data Science Platform as a Service)로서 개발을 간소화하고, 성능을 가속화하고, 협업을 촉진하며, 운영 문제를 해결합니다. 이 플랫폼에는 다음과 같은 구성 요소가 통합되어 있으며 이과지오 데이터 과학 플랫폼이 다음 이미지에 나와 있습니다.</block>
  <block id="2137518d79f0a3dfe335e8c02312cf96" category="list-text">Jupyter Notebooks, 통합 분석 엔진 및 Python 패키지를 포함하는 데이터 과학 워크벤치입니다</block>
  <block id="68ed19bfa85e4c4677e50979864e169b" category="list-text">실험 추적 및 자동화된 파이프라인 기능을 사용하여 관리 모델링</block>
  <block id="37a28d84cd653345f1f2c036cb732f2d" category="list-text">확장 가능한 Kubernetes 클러스터를 통해 데이터 및 ML 서비스를 관리했습니다</block>
  <block id="77fdda1a79199ac02cde44b4249cb509" category="list-text">Nuclio는 실시간 서버리스 기능 프레임워크입니다</block>
  <block id="96a6f4a99a7526e82a294d44ed005701" category="list-text">SQL, NoSQL, 시계열 데이터베이스, 파일(단순한 개체), 스트리밍을 지원하는 매우 빠르고 안전한 데이터 계층입니다</block>
  <block id="00a48f02675717eaf6082c4ba536a366" category="list-text">NetApp, Amazon S3, HDFS, SQL 데이터베이스, 스트리밍 또는 메시징 프로토콜 등의 타사 데이터 소스와 통합</block>
  <block id="901630ad39a688431a68dc119f5378a3" category="list-text">Grafana 기반의 실시간 대시보드</block>
  <block id="887fce38ef8ddd8546748bb746ed7e5a" category="paragraph"><block ref="887fce38ef8ddd8546748bb746ed7e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="961027a0ac9a1d9515fa54a5d5372c79" category="inline-link-macro">다음: 소프트웨어 및 하드웨어 요구 사항</block>
  <block id="a10e3ee0949323f601d4c9624980eb47" category="paragraph"><block ref="a10e3ee0949323f601d4c9624980eb47" category="inline-link-macro-rx"></block></block>
  <block id="7661400c51b9fc184bdec46eb5577ff9" category="doc">GitHub에서 코드를 가져옵니다</block>
  <block id="1a3652d661d6b73b6aa57aff1fa5e4d4" category="paragraph">이제 Iguazio 클러스터와 개발자 환경에서 NetApp Cloud Volume 또는 NetApp Trident 볼륨을 사용할 수 있으므로 애플리케이션 검토를 시작할 수 있습니다.</block>
  <block id="ae53ae826cc9a587fbaee0e834dd75ca" category="paragraph">사용자는 고유한 작업 공간(디렉터리)을 가지고 있습니다. 모든 노트북에서 사용자 디렉토리 경로는 "/User"입니다. Iguazio 플랫폼은 디렉토리를 관리합니다. 위의 지침을 따르면 NetApp Cloud 볼륨은 '/NetApp' 디렉토리에 있습니다.</block>
  <block id="754e85a9ea7f4fbb718080a73790abdb" category="paragraph">Jupyter 터미널을 사용하여 GitHub에서 코드를 가져옵니다.</block>
  <block id="1d706cc291efb1d79274befd6f9dd64c" category="paragraph"><block ref="1d706cc291efb1d79274befd6f9dd64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12d0e4b8ba8db4e6a7aa1dda942a1ed4" category="paragraph">Jupyter 터미널 프롬프트에서 프로젝트를 복제합니다.</block>
  <block id="d4095d9e0ab52b6d683ace00b5cbea55" category="paragraph">이제 Jupyter 작업 공간의 파일 트리에 'netops-netapp' 폴더가 표시됩니다.</block>
  <block id="f8161ff446bbd6f76b0d99d6f34a1d7f" category="inline-link-macro">다음: 작업 환경 구성</block>
  <block id="48dd929a2f5f248856ce2768950aff4e" category="paragraph"><block ref="48dd929a2f5f248856ce2768950aff4e" category="inline-link-macro-rx"></block></block>
  <block id="1703cadf8e847114fb353feaaf03beb9" category="summary">이 섹션에는 Kubernetes를 ONTAP AI Pod에 구축할 때 실행할 수 있는 다양한 고성능 작업의 예가 포함되어 있습니다.</block>
  <block id="639ce1b23959b4470d67802f0e5e412a" category="doc">ONTAP AI 배포에 대한 고성능 작업 예</block>
  <block id="b7cd12d2dd9ac8e3414514a02e5df6f4" category="inline-link-macro">다음: 단일 노드 AI 워크로드 실행</block>
  <block id="6ee8519e7493385361c9afcfd675c8d0" category="paragraph"><block ref="6ee8519e7493385361c9afcfd675c8d0" category="inline-link-macro-rx"></block></block>
  <block id="0a1bc6b4024485ff9b55c99c1237e175" category="doc">실행 시 클러스터 및 GPU 활용률 최적화: AI</block>
  <block id="612edeb05f6d237e20f3d843d6e7eba4" category="paragraph">다음 섹션에서는 AI 설치, 테스트 시나리오, 그리고 이 검증에서 수행된 결과에 대해 자세히 설명합니다.</block>
  <block id="2df14da3d7db15550e8eafc892e89d8e" category="paragraph">TensorFlow 벤치마크를 비롯하여 업계 표준 벤치마크 툴을 사용하여 이 시스템의 운영 및 성능을 검증했습니다. ImageNet 데이터 세트는 이미지 분류를 위해 유명한 CNN(Convolutional Neural Network) DL 모델인 ResNet-50을 교육하는 데 사용되었습니다. ResNet-50은 더욱 빠른 처리 시간으로 정확한 교육 결과를 제공하므로 스토리지에서 충분한 수요를 창출할 수 있습니다.</block>
  <block id="13bb3aa52565b3e3f517764c0e88c324" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block>.</block>
  <block id="d577549f9b3a229c338e203a433489f6" category="summary">이 섹션에서는 AKS VNET를 Azure NetApp Files VNET와 피어로 사용하는 방법을 설명합니다.</block>
  <block id="e61e6d340ad05dc2e1ad0982f6857d7d" category="doc">피어 AKS VNET 및 Azure NetApp Files VNET</block>
  <block id="1c45d541f316a23589217be5991b1545" category="inline-link-macro">이전: Azure NetApp Files에 대해 위임된 서브넷을 만듭니다.</block>
  <block id="786730f8769009abf0bf6400157dd16b" category="paragraph"><block ref="786730f8769009abf0bf6400157dd16b" category="inline-link-macro-rx"></block></block>
  <block id="e6ef5f0946a89d073a8f360de1038061" category="paragraph">AKS VNET를 Azure NetApp Files VNET와 상호 운용하려면 다음 단계를 수행하십시오.</block>
  <block id="87c2d6c506d0bf65d2c5d773474f9c0f" category="list-text">검색 필드에 가상 네트워크를 입력합니다.</block>
  <block id="7680f3bc49a836c67a8b0e7d2d9ccb44" category="list-text">VNET AKS-VNET-NAME을 선택합니다 이 버튼을 클릭하고 검색 필드에 '북경'을 입력합니다.</block>
  <block id="fc3bb6a018a8f599cab21678959f92b0" category="list-text">추가 를 클릭합니다.</block>
  <block id="1991ef5bd8e165e42c56ccaefa2f640f" category="list-text">다음 설명을 입력합니다.</block>
  <block id="51e5b9c0a583a9afbc2f998e622fd30d" category="list-text">피어링 링크명은 AKS-VNET-NAME_to_anf입니다.</block>
  <block id="14ac6521e2758ba95fe7be9ca6a82cd1" category="list-text">VNET 피어링 파트너로 구독하는 Azure NetApp Files VNET와 가입자 ID입니다.</block>
  <block id="70b58cb057d859d4da9f17e43ffd238c" category="list-text">별표가 아닌 모든 섹션은 기본값을 사용하여 남겨 둡니다.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">추가 를 클릭합니다.</block>
  <block id="50e3209c871e4867931ef51a9344a921" category="paragraph">자세한 내용은 을 참조하십시오<block ref="f81943721c88f7efe9b8252470f9ea43" category="inline-link-rx"></block>.</block>
  <block id="fd3c95528aa9718948de8d4e38b2fa2c" category="inline-link-macro">다음: Trident를 설치합니다.</block>
  <block id="18337fe57049583a9c04a79f64a2088f" category="paragraph"><block ref="18337fe57049583a9c04a79f64a2088f" category="inline-link-macro-rx"></block></block>
  <block id="2e52c56d063752bbfeda9c8f9d2fee41" category="summary">이 페이지에서는 Kubernetes 클러스터에서 NetApp Trident를 설치 및 구성하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="7c4090c7fa7a91e8c7fed182401dbf6b" category="doc">NetApp Trident 구축 및 구성</block>
  <block id="e539ec743b02403b5ba74b884d117a5a" category="paragraph">이 섹션에서는 Kubernetes 클러스터에 NetApp Trident를 설치 및 구성하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">필수 구성 요소</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">이 섹션에 요약된 배포 연습을 수행하기 전에 이미 다음 작업을 수행했다고 가정합니다.</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link">Trident 문서</block>
  <block id="d6c3cdbd20fe8752d1f443bdb84038e3" category="list-text">Kubernetes 작업 클러스터가 이미 있으며, Trident에서 지원하는 Kubernetes 버전을 실행 중입니다. 지원되는 버전 목록은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="14ede02439184c7c75e53410ffa40370" category="list-text">Trident에서 지원하는 작업 중인 NetApp 스토리지 어플라이언스, 소프트웨어 정의 인스턴스 또는 클라우드 스토리지 서비스가 이미 있습니다.</block>
  <block id="984b69562391cb8032fd50ded03a29a6" category="paragraph">Kubernetes 클러스터에 NetApp Trident를 설치 및 구성하려면 배포 점프 호스트에서 다음 작업을 수행하십시오.</block>
  <block id="07d8795f785e6495307106596d07402e" category="list-text">다음 방법 중 하나를 사용하여 Trident를 배포합니다.</block>
  <block id="040d3466a6f1c45ca2e523c9354dfdc7" category="inline-link">Trident 배포 지침</block>
  <block id="bb6989644edf59b8c5e0de0c25b6f8b6" category="list-text">NVIDIA DeepOps를 사용하여 Kubernetes 클러스터를 구축한 경우, NVIDIA DeepOps를 사용하여 Kubernetes 클러스터에 Trident를 구축할 수도 있습니다. DeepOps를 사용하여 Trident를 배포하려면 을 따릅니다<block ref="77e542aaaac8c5d2482c94ca2d79c997" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">배포 지침</block>
  <block id="b6463ef77c88b4c74dd6c4b1479d1bae" category="list-text">NVIDIA DeepOps를 사용하여 Kubernetes 클러스터를 배포하지 않았거나 Trident를 수동으로 배포하려는 경우 에 따라 Trident를 배포할 수 있습니다<block ref="73e6be38c8ff1e0c58865c34876a2e98" category="inline-link-rx"></block> Trident 문서 Trident 백엔드를 하나 이상 생성하고 Kubernetes StorageClass를 하나 이상 생성해야 합니다. 백엔드 및 StorageClasses에 대한 자세한 내용은 을 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="f363c1a10e150fdee0f4f310a06acb5e" category="inline-link-macro">ONTAP AI 배포에 대한 Trident 백엔드 예</block>
  <block id="7cfdcb466d040b6c8f9c85e9981b9652" category="inline-link-macro">ONTAP AI 배포를 위한 Kubernetes Storagecles의 예</block>
  <block id="180b707bbdd9c2fc8001a966c6c7d029" category="admonition">ONTAP AI Pod에 NetApp AI Control Plane 솔루션을 구축하는 경우 를 참조하십시오 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block> 및 를 생성할 수 있는 다른 Trident 백엔드의 몇 가지 예를 확인하십시오 <block ref="d495c2f5a68f6923824470c0096419c8" category="inline-link-macro-rx"></block> 생성할 수 있는 여러 Kubernetes StorageClasses의 몇 가지 예를 확인하십시오.</block>
  <block id="4fe6ae61b2ccf0bd553bc2c0f15cf803" category="inline-link-macro">다음: ONTAP AI 배포에 대한 Trident 백엔드 예</block>
  <block id="8de05380035e6d3c48105e0b80ca2e32" category="paragraph"><block ref="8de05380035e6d3c48105e0b80ca2e32" category="inline-link-macro-rx"></block></block>
  <block id="ca6d5ad374e3cf268dec341c0c398442" category="summary">이 아키텍처에서 초점은 AI 또는 머신 러닝(ML) 분산 훈련 프로세스 중 가장 컴퓨팅 집약적인 레인 감지 프로세스에 있습니다.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">솔루션 개요</block>
  <block id="8cb13336dc020a2fb7bca9d4e940cc64" category="paragraph">이 아키텍처에서 초점은 AI 또는 머신 러닝(ML) 분산 훈련 프로세스 중 가장 컴퓨팅 집약적인 레인 감지 프로세스에 있습니다. 차선 감지는 자동 주행에서 가장 중요한 작업 중 하나로서, 차선 표시를 현지화함으로써 차량을 인도하는 데 도움이 됩니다. 차선 표시와 같은 정적 구성 요소는 차량이 고속도로를 대화식으로 안전하게 주행하도록 안내합니다.</block>
  <block id="0721542454dcaa77c97cd9c545d9063f" category="paragraph">합성신경망(CNN) 기반 접근 방식은 장면에 대한 이해와 세그멘테이션을 새로운 차원으로 끌어올려 왔습니다. 폐쇄될 수 있는 긴 구조 및 영역(예: 폴, 차선의 음영 등)이 있는 물체에는 이 기능이 제대로 작동하지 않습니다. 공간 컨벌루ional Neural Network(SCNN)는 CNN을 풍부한 공간 수준으로 일반화합니다. 동일한 레이어에서 뉴런 간에 정보를 전달할 수 있으므로 폐색이 있는 레인, 폴 또는 트럭과 같은 구조적 개체에 가장 적합합니다. 이러한 호환성은 공간 정보를 보강할 수 있고 매끄러움과 지속성을 유지하기 때문입니다.</block>
  <block id="df38a65c87631c9530cc3a6832ea7a7d" category="paragraph">모델이 데이터세트의 다양한 구성 요소를 학습하고 구분할 수 있도록 시스템에 수천 개의 화면 이미지를 삽입해야 합니다. 이러한 이미지에는 날씨, 주간 또는 야간, 다차선 고속도로 도로 및 기타 교통 상황이 포함됩니다.</block>
  <block id="f7759f002b4a60b5c837abb7f8936037" category="paragraph">교육에는 양질의 데이터와 많은 양의 데이터가 필요합니다. 단일 GPU 또는 여러 GPU를 사용하여 교육을 완료하는 데 며칠~몇 주가 걸릴 수 있습니다. 데이터 분산 교육을 통해 여러 노드 및 GPU를 사용하여 프로세스를 가속화할 수 있습니다. Horovod는 분산 교육을 제공하지만 GPU 클러스터 간에 데이터를 읽는 것이 방해가 될 수 있는 프레임워크 중 하나입니다. Azure NetApp Files은 컴퓨팅 용량의 최고에 GPU를 활용할 수 있도록 초고속, 높은 처리량, 지속적으로 짧은 지연 시간을 제공합니다. 이번 실험에서 클러스터 전체의 모든 GPU가 SCNN을 사용하여 차선 감지를 교육하기 위해 평균 96% 이상 사용되고 있다는 것을 확인했습니다.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="section-title">대상</block>
  <block id="0ca450eccdc7141b5e85e9e691a7f16b" category="paragraph">데이터 과학은 IT 및 비즈니스 분야의 여러 분야를 통합하므로 여러 페르소나가 대상 고객을 대상으로 합니다.</block>
  <block id="8acb1f50d0ada4e1149c01a5aa15b9ce" category="list-text">데이터 과학자는 자신이 선택한 도구와 라이브러리를 사용할 수 있는 유연성이 필요합니다.</block>
  <block id="d0ba3808090644db73caeb23fcc2b17c" category="list-text">데이터 엔지니어는 데이터 흐름과 데이터 위치를 알아야 합니다.</block>
  <block id="22a8c99419dee54a28ed1e2355a6706b" category="list-text">자율 주행 사용 사례 전문가</block>
  <block id="18f66c4bad233033dabddf6ff1289eeb" category="list-text">클라우드 관리자 및 설계자는 Azure(클라우드) 리소스를 설정하고 관리합니다.</block>
  <block id="4c9b6067f04f945e9247ecd00c22e328" category="list-text">DevOps 엔지니어는 새로운 AI/ML 애플리케이션을 CI/CD(Continuous Integration and Continuous Deployment) 파이프라인에 통합하는 툴을 필요로 합니다.</block>
  <block id="53720cf6403ac6b8a2402cce66c79d4f" category="list-text">비즈니스 사용자는 AI/ML 애플리케이션에 액세스할 수 있기를 원합니다.</block>
  <block id="68dcdc6243e54c14b4c41c129d574c43" category="paragraph">이 문서에서는 Azure NetApp Files, RUN:AI 및 Microsoft Azure가 각 역할이 비즈니스에 제공하는 데 어떤 도움이 되는지 설명합니다.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="section-title">솔루션 기술</block>
  <block id="8017303b9b2c96742151083f089fc51f" category="paragraph">이 섹션에서는 Azure 클라우드에서 완벽하게 실행되는 분산 교육 솔루션을 구현하여 레인 감지 사용 사례에 대한 기술 요구 사항을 다룹니다. 아래 그림은 솔루션 아키텍처를 간략하게 보여 줍니다.</block>
  <block id="f17291da16ed3dd7b705548f16706120" category="paragraph">이 솔루션에 사용되는 요소는 다음과 같습니다.</block>
  <block id="f28c5620810ae2a6961a1811277a7ff8" category="list-text">Azure Kubernetes 서비스(AKS)</block>
  <block id="03023f4a63d3d8f8ff86ff8246f75b9a" category="list-text">NVIDIA GPU를 사용하는 Azure Compute SKU</block>
  <block id="ae5ba69294a1b9feb03e6dd75395092c" category="list-text">실행: AI</block>
  <block id="951370659c41a55ac9f80ff19c2f4b26" category="paragraph">여기에 언급된 모든 요소에 대한 링크는 에 나와 있습니다 <block ref="c8b73068ae16e202922904f7ed452f8e" category="inline-link-macro-rx"></block> 섹션을 참조하십시오.</block>
  <block id="00d9279819736707d2b224ec427a8aae" category="paragraph"><block ref="00d9279819736707d2b224ec427a8aae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6a2faff353ad4e74bf3ee92e5d8b9c6" category="section-title">클라우드 리소스 및 서비스 요구사항</block>
  <block id="5b691a1a00c6c03be70e559f55ae4fef" category="paragraph">다음 표에는 솔루션을 구현하는 데 필요한 하드웨어 구성요소가 나와 있습니다. 솔루션 구현에 사용되는 클라우드 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="c8e2277ecfb1427838c488c217f99466" category="cell">클라우드</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">수량</block>
  <block id="5f3bc5eb45e6b472bf3345d1036945e9" category="cell">AKS</block>
  <block id="55b8660903ebaaed924e945432fe269e" category="cell">최소 3개의 시스템 노드 및 3개의 GPU 작업자 노드</block>
  <block id="3580a6b3e7ba0d55af17daee07244cbd" category="cell">가상 머신(VM) SKU 시스템 노드입니다</block>
  <block id="8f75b0af54b5e672a660f4f1f1557f18" category="cell">Standard_DS2_v2 3개</block>
  <block id="a6066b29e1c4603af2c5c46cf549f764" category="cell">VM SKU GPU 작업자 노드입니다</block>
  <block id="6aa4bab72f83c0b68587ee208f2c9ab0" category="cell">표준 _NC6s_v3 3개</block>
  <block id="3468e131592d70a22139936f3fb21403" category="cell">4TB 표준 계층</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">소프트웨어 요구 사항</block>
  <block id="d9ae1ecd6158beb6acd24c9f59d0498e" category="paragraph">다음 표에는 솔루션을 구현하는 데 필요한 소프트웨어 구성요소가 나와 있습니다. 솔루션 구현에 사용되는 소프트웨어 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">소프트웨어</block>
  <block id="cb251883efe045266871b7dd15229644" category="cell">버전 또는 기타 정보</block>
  <block id="bb451ae1fa5a629a0307949d38a60e2d" category="cell">AKS - Kubernetes 버전</block>
  <block id="13c5eaa211a3778d391d5c8f65b80234" category="cell">실행: AI CLI</block>
  <block id="89633b9d6f401377b6ece0682b92530a" category="cell">v2.2.25</block>
  <block id="4b138e2d1492b1e550d42348c65cbf82" category="cell">실행: AI Orchestration Kubernetes Operator version</block>
  <block id="6db851ff24c4b893a85242e63bbea119" category="cell">1.0.109</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">호로브</block>
  <block id="4a7724061c17f8cf5be61a8adf4c170f" category="cell">0.21.2</block>
  <block id="44adee2c140fc723412bae93732e5993" category="cell">20.01.1</block>
  <block id="152090ff5e9a05ea7e1cf0c248449638" category="cell">헬름</block>
  <block id="272f0a04b740763e0a29316bc4af89a4" category="cell">3.0.0</block>
  <block id="cff4cbb413623685c446a2632974cf62" category="summary">이 페이지에서는 기존 Pandas를 이용한 모델 교육 시간을 DASK와 비교합니다. Pandas의 경우, 메모리 오버플로를 방지하기 위해 처리 시간이 느려지기 때문에 더 적은 양의 데이터를 로드했습니다. 따라서 공정한 비교를 제공하기 위해 결과를 보간했습니다.</block>
  <block id="014020acc8f97c1da58961d44b6301eb" category="doc">교육 시간 비교</block>
  <block id="76c5145913d13d6c3105c4265a78047e" category="inline-link-macro">이전: 기본 작업 스트림 대시보드를 사용하여 Dask를 모니터링합니다.</block>
  <block id="a871e4d194e2df9c65b061a5fc7cb154" category="paragraph"><block ref="a871e4d194e2df9c65b061a5fc7cb154" category="inline-link-macro-rx"></block></block>
  <block id="c8ed0bb49061765f5f30ba006ea7c5c0" category="paragraph">이 섹션에서는 기존 Pandas를 사용한 모델 교육 시간을 DASK와 비교합니다. Pandas의 경우, 메모리 오버플로를 방지하기 위해 처리 시간이 느려지기 때문에 더 적은 양의 데이터를 로드했습니다. 따라서 공정한 비교를 제공하기 위해 결과를 보간했습니다.</block>
  <block id="5b5214524edbd74fb721da08e61c8a41" category="paragraph">다음 표에서는 Pandas 무작위 포리스트 모델에 사용되는 데이터(데이터 세트의 15일 당 20억 개 중 5천만 개 행)가 상당히 적은 경우의 원시 교육 시간 비교를 보여 줍니다. 이 샘플은 사용 가능한 모든 데이터의 0.25% 이하만을 사용합니다. Dask-cuML의 경우 사용 가능한 모든 20억 행에 대해 무작위 포리스트 모델을 교육했습니다. 두 가지 접근 방식은 비슷한 훈련 시간을 낳았습니다.</block>
  <block id="40a68b5da4b9b224764558bb02ecd028" category="cell">접근 방식</block>
  <block id="0e90ab0d7d04d2a878961f8d40071c83" category="cell">교육 시간</block>
  <block id="24cc88af022e13431f8005b38f74e0fd" category="cell">Scikit-learn: 15일째에 50M 행만 교육 데이터로 사용합니다</block>
  <block id="26e394f0b8009246698f4844db682015" category="cell">47분 21초</block>
  <block id="ed536b2798ed9f16a79fb8f772601548" category="cell">RAPIDS-DASK: 15일 안에 20B 행을 모두 훈련 데이터로 사용</block>
  <block id="8809f6d1a4b5cbd872b52f83e378e527" category="cell">1시간, 12분, 11초</block>
  <block id="57093fade268287629c2720356ecac57" category="paragraph">다음 표와 같이 교육 시간 결과를 선형적으로 보간할 경우 Dask와 함께 분산 훈련을 사용하면 큰 이점이 있습니다. 기존의 Pandas scikit-learn 접근 방식을 통해 클릭 로그를 하루에 45GB의 데이터를 처리하고 교육하는 데 13일이 걸리는 반면, RAPIDS-Dask 방식을 사용하면 같은 양의 데이터를 262.39배 더 빠르게 처리할 수 있습니다.</block>
  <block id="36ebc33745cb5ac06238c615c8aaebdc" category="cell">Scikit-learn: 15일째에 20B 행을 모두 훈련 데이터로 사용합니다</block>
  <block id="b2ab615236e8c7812b0ab7dff59c552f" category="cell">13일, 3시간, 40분, 11초</block>
  <block id="0d7cda3e89555f27bf26cf0c0c4f4fed" category="paragraph">이전 표에서 RAPIDS와 DASK를 사용하여 여러 GPU 인스턴스에 데이터 처리 및 모델 훈련을 분산하면, Scikit-learn 모델 훈련을 통해 기존 PandDataFrame 처리에 비해 실행 시간이 상당히 짧아진다는 것을 알 수 있습니다. 이 프레임워크를 통해 다중 노드, 다중 GPU 클러스터의 온프레미스뿐만 아니라 클라우드에서 스케일업 및 스케일아웃이 가능합니다.</block>
  <block id="fbd52cffa97d6ec5e0230516fc61f14c" category="inline-link-macro">다음: Prometheus 및 Grafana를 사용하여 Dask 및 RAPIDS를 모니터링합니다.</block>
  <block id="78117011d88a8971f2eadbeee6ac6474" category="paragraph"><block ref="78117011d88a8971f2eadbeee6ac6474" category="inline-link-macro-rx"></block></block>
  <block id="84860cc77161e23e44eccd05430c00ea" category="doc">실행 중인 작업 제출: AI CLI</block>
  <block id="68c9d249f35c91dfcc4a11e209ccbdba" category="paragraph">이 섹션에서는 Kubernetes 작업 실행에 사용할 수 있는 기본 Run:AI 명령에 대한 자세한 정보를 제공합니다. 워크로드 유형에 따라 3개 부분으로 나뉩니다. AI/ML/DL 워크로드는 다음과 같은 두 가지 일반 유형으로 나눌 수 있습니다.</block>
  <block id="754edd5bae16b4a2ed8e6673821d3339" category="list-text">* 무인 교육 세션 *. 이러한 유형의 워크로드를 사용하여 데이터 과학자는 자체 실행 워크로드를 준비하여 실행을 위해 보냅니다. 실행 중에 고객은 결과를 검토할 수 있습니다. 이러한 유형의 워크로드는 생산 또는 인물 개발에 사람의 개입이 필요 없는 단계에 있을 때 주로 사용됩니다.</block>
  <block id="fdfda155b7c1021ae5e73d2ab01c0129" category="list-text">* 대화형 빌드 세션 *. 이러한 유형의 워크로드를 사용하여 데이터 과학자는 Bash, Jupyter Notebook, remote PyCharm 또는 유사한 IDE를 사용한 대화형 세션을 열고 GPU 리소스에 직접 액세스합니다. 연결된 포트를 사용하여 대화형 워크로드를 실행하는 세 번째 시나리오가 포함되어 컨테이너 사용자에게 내부 포트를 제공합니다.</block>
  <block id="6ec08732676824c58d76b0ecdc2aed24" category="section-title">무인 교육 워크로드</block>
  <block id="18cb2734d0533ff093ddcb1b3005e216" category="paragraph">프로젝트를 설정하고 GPU를 지정한 후 명령줄에서 다음 명령을 사용하여 모든 Kubernetes 워크로드를 실행할 수 있습니다.</block>
  <block id="68e667063c4711033bbf6b7f8b312e1f" category="paragraph">이 명령은 단일 GPU를 할당하여 팀 A의 무인 교육 작업을 시작합니다. 이 작업은 샘플 Docker 이미지 'GCR.IO/RUN-AI-DEMO/QuickStart'를 기반으로 합니다. 우리는 그 일을 하이퍼1이라고 명명했다. 그런 다음 다음 다음 명령을 실행하여 작업의 진행률을 모니터링할 수 있습니다.</block>
  <block id="cbae10285b6d282e740369a59fd25aaf" category="paragraph">다음 그림은 루나이 리스트 명령의 결과를 보여준다. 표시되는 일반적인 상태는 다음과 같습니다.</block>
  <block id="e749e4e3bf7ed6d5368f336ba6ceeead" category="list-text">'ContainerCreating' Docker 컨테이너를 클라우드 저장소에서 다운로드하고 있습니다.</block>
  <block id="f5231f23820da3ad520bb16a9dfe97a7" category="list-text">'보류 중'. 작업이 예약될 때까지 대기 중입니다.</block>
  <block id="411497b40a902afd2813d3c7af137ffb" category="list-text">'러닝'입니다. 작업이 실행 중입니다.</block>
  <block id="c0801feb8216aa6b36a769e14c3bc138" category="paragraph"><block ref="c0801feb8216aa6b36a769e14c3bc138" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4f5f0c8fb5ec5bccf18cfd167b1d3bc5" category="paragraph">작업에 대한 추가 상태를 가져오려면 다음 명령을 실행합니다.</block>
  <block id="db0b192c9c9b9885b435e466b9ac861c" category="paragraph">작업의 로그를 보려면 "runai logs &lt;job-name&gt;" 명령을 실행합니다.</block>
  <block id="280782f59c990a941b600c998427a52c" category="paragraph">이 예에서는 각 단계에 대해 현재 교육 Epoch, ETA, 손실 함수 값, 정확도 및 경과 시간을 포함하여 실행 중인 DL 세션의 로그를 확인해야 합니다.</block>
  <block id="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link"><block ref="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link-rx"></block></block>
  <block id="848ad760ae00e3eca33445cd09cfdf34" category="paragraph">의 Run:AI UI에서 클러스터 상태를 볼 수 있습니다<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>. 대시보드 &gt; 개요 에서 GPU 사용률을 모니터링할 수 있습니다.</block>
  <block id="f899123d07ffe99c3d97952ae96017ed" category="paragraph">이 워크로드를 중지하려면 다음 명령을 실행합니다.</block>
  <block id="1f979b6140776c287d458036805ad8aa" category="inline-link">무인 교육 워크로드 실행</block>
  <block id="637552715214e8c0c87022bac459e824" category="paragraph">이 명령은 교육 워크로드를 중지합니다. 이 작업은 'runai list'를 다시 실행하여 확인할 수 있습니다. 자세한 내용은 을 참조하십시오<block ref="e5fbbc266c1fd3a9a029581f5747622d" category="inline-link-rx"></block>.</block>
  <block id="7afece97948db40e546138d81dd343e1" category="section-title">대화형 빌드 워크로드</block>
  <block id="30330792601ba24e9ad5f4f5ee0d5151" category="paragraph">프로젝트를 설정하고 GPU를 할당하면 명령줄에서 다음 명령을 사용하여 대화형 빌드 워크로드를 실행할 수 있습니다.</block>
  <block id="ca57038d87e3f48eb98329e6fd449824" category="paragraph">이 작업은 샘플 Docker 이미지 Python을 기반으로 합니다. 우리는 작업 구축1이라는 이름을 붙였습니다.</block>
  <block id="39fd96ce47a2aa757eb5cc98cd910730" category="admonition">인터액티브 플래그는 작업이 시작이나 끝이 없다는 뜻입니다 이 일을 마무리하는 것은 연구자의 책임입니다. 관리자는 시스템에 의해 종료된 후 대화형 작업에 대한 시간 제한을 정의할 수 있습니다.</block>
  <block id="d39d9c693980c2af510d4a58be6f2620" category="paragraph">이 작업에는 '--g 1' 플래그가 GPU를 하나만 할당합니다. 명령어와 논리는 '--명령 슬립--args 무한대'입니다. 명령을 제공해야 합니다. 그렇지 않고 컨테이너가 시작되고 즉시 종료됩니다.</block>
  <block id="aedc6bf8e3cb52af4a660584c69353ca" category="paragraph">다음 명령은 에 설명된 명령과 유사하게 작동합니다 <block ref="a09c3ced87a580a4004dfa2429aba9c7" category="inline-xref-macro-rx"></block>:</block>
  <block id="1d2bac5ee25c12c0ee793df98c1b4d49" category="list-text">'runai list': 이름, 상태, 나이, 노드, 이미지, 작업을 위해 프로젝트, 사용자 및 GPU를 지원합니다.</block>
  <block id="6b5b5fdb13c8b8af02a41b296af91a2e" category="list-text">runai get build1: 작업 build1에 추가 상태를 표시합니다.</block>
  <block id="9c1e129aa488b11d05275f016f42dda5" category="list-text">'runai delete build1': 대화형 워크로드 빌드 중지1. bash 셸을 컨테이너에 가져오려면 다음 명령을 사용합니다.</block>
  <block id="ac97b61bdc50cfc22ffd507de190d00c" category="paragraph">그러면 컴퓨터에 직접 셸이 제공됩니다. 그런 다음 데이터 과학자는 컨테이너 내에서 모델을 개발 또는 미세 조정할 수 있습니다.</block>
  <block id="5051a9eb1fad38f876a260ba0a4850af" category="inline-link"><block ref="5051a9eb1fad38f876a260ba0a4850af" category="inline-link-rx"></block></block>
  <block id="c7fdd5fcf033fb9395c27ecbf2e54fc9" category="inline-link">대화형 빌드 워크로드 시작 및 사용</block>
  <block id="ff53dc42327d97c7410a6ac241222ffe" category="paragraph">의 Run:AI UI에서 클러스터 상태를 볼 수 있습니다<block ref="29f2b88109b12c4db8e875d3f5ba7aae" category="inline-link-rx"></block>. 자세한 내용은 을 참조하십시오<block ref="f3d6ab8050b43c83f452779c7622ab1d" category="inline-link-rx"></block>.</block>
  <block id="1028c65994f7201e0f43b3bf5d3c6b41" category="section-title">연결된 포트를 사용하는 대화형 작업 부하</block>
  <block id="7d05c708b92b4809bfe9bf66edf8f765" category="inline-link">침투</block>
  <block id="34274fcc13408f06acfe43c4065c3f3b" category="paragraph">대화형 빌드 워크로드의 확장으로 Run:AI CLI로 컨테이너를 시작할 때 컨테이너 사용자에게 내부 포트를 표시할 수 있습니다. 이 기능은 Jupyter Notebooks와 함께 작업하거나 다른 마이크로서비스에 연결하는 클라우드 환경에 유용합니다.<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Kubernetes 클러스터 외부에서 Kubernetes 서비스에 액세스할 수 있습니다. 어떤 인바운드 연결이 어떤 서비스에 연결할지 정의하는 규칙 모음을 만들어 액세스를 구성할 수 있습니다.</block>
  <block id="e7f72a2c9a0cb7337eb00a3093f846da" category="paragraph">클러스터의 서비스에 대한 외부 액세스를 보다 효율적으로 관리하기 위해 클러스터 관리자를 설치하는 것이 좋습니다<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> 및 로드 밸런서를 구성합니다.</block>
  <block id="16d79943625573d5b80809fe2a7ddbdd" category="paragraph">서비스 유형으로 수신을 사용하려면 다음 명령을 실행하여 워크로드를 제출할 때 메서드 유형과 포트를 설정합니다.</block>
  <block id="79fcc0299f1a85ebab053926e2222bca" category="paragraph">컨테이너가 성공적으로 시작된 후 runai list를 실행하여 Jupyter Notebook에 액세스할 수 있는 Service URL(S)을 확인합니다. URL은 수신 엔드포인트, 작업 이름 및 포트로 구성됩니다. 예를 들어 를 참조하십시오<block ref="0309fbe8f364c8f6dfe6f383da8c46c2" category="inline-link-rx"></block>.</block>
  <block id="451b08ed1bf6f7f0a8931cff52c4c45e" category="inline-link">연결된 포트를 사용하여 대화형 빌드 워크로드 시작</block>
  <block id="b524842923f8cb1e38064fadc680893f" category="paragraph">자세한 내용은 을 참조하십시오<block ref="414875add8a18a03ddddfb14fb1c47f4" category="inline-link-rx"></block>.</block>
  <block id="5bb97c2dd089da990a792356c72a6128" category="inline-link-macro">다음: 높은 클러스터 사용률 달성</block>
  <block id="8f87de13e6ff3dd2fc164bdb930759bb" category="paragraph"><block ref="8f87de13e6ff3dd2fc164bdb930759bb" category="inline-link-macro-rx"></block></block>
  <block id="3ff1a758f526c5ceb434059efe27020a" category="summary">Apache Airflow 워크플로의 예</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">Kubernetes용 NetApp 데이터 과학 툴킷</block>
  <block id="c5da96d7204df28dd9fdc33139c8a776" category="paragraph">를 클릭합니다<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> 공기 흐름과 함께 사용할 수 있습니다. 공기 흐름이 원활한 NetApp 데이터 과학 툴킷을 사용하면 NetApp 데이터 관리 작업을 공기 흐름으로 조율되는 자동화된 워크플로우에 통합할 수 있습니다.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">공기 흐름의 예</block>
  <block id="9fc322b3a5bb56d2d6ac18c15773d1c2" category="paragraph">을 참조하십시오<block ref="c50bba54faf39c027cd571674d44a9c0" category="inline-link-rx"></block> NetApp Data Science Toolkit GitHub 리포지토리 내의 섹션에서 공기 흐름이 포함된 툴킷 사용에 대한 자세한 내용을 확인하십시오.</block>
  <block id="64b0abe7a29610e134041ed793101fce" category="inline-link-macro">다음: Trident 작업의 예</block>
  <block id="f6c488122d476f1d213cf78dc2ee84d2" category="paragraph"><block ref="f6c488122d476f1d213cf78dc2ee84d2" category="inline-link-macro-rx"></block></block>
  <block id="65f63f96295566cd4278775eef1b4c8c" category="doc">덜 까다로운 워크로드 또는 대화형 워크로드에 대한 부분 GPU 할당</block>
  <block id="1b3d285072ee60a98cde2f66b6e47fde" category="paragraph">연구자와 개발자가 개발, 고매개 변수 조정 또는 디버깅 단계에서 자신의 모델을 작업할 때 이러한 워크로드는 일반적으로 컴퓨팅 리소스를 적게 사용합니다. 따라서 동일한 GPU를 다른 워크로드에 동시에 할당할 수 있도록 소수점 GPU 및 메모리를 프로비저닝하는 것이 더 효율적입니다. 실행: AI의 오케스트레이션 솔루션은 Kubernetes에서 컨테이너화된 워크로드를 위한 분할 GPU 공유 시스템을 제공합니다. 이 시스템은 CUDA 프로그램을 실행하는 워크로드를 지원하며 추론과 모델 구축과 같은 가벼운 AI 작업에 특히 적합합니다. 소수점 GPU 시스템은 데이터 과학과 AI 엔지니어링 팀에게 단일 GPU에서 동시에 여러 워크로드를 실행할 수 있는 기능을 투명하게 제공합니다. 이를 통해 기업은 컴퓨터 비전, 음성 인식 및 자연어 처리와 같은 더 많은 워크로드를 동일한 하드웨어에서 실행할 수 있으므로 비용이 절감됩니다.</block>
  <block id="5db1fcd5bb529fa2475aaf893414d2e4" category="paragraph">실행: AI의 분할 GPU 시스템은 컨테이너가 자급식 프로세서인 것처럼 사용하고 액세스할 수 있는 자체 메모리 및 컴퓨팅 공간을 사용하여 가상화된 논리 GPU를 효과적으로 생성합니다. 따라서 여러 워크로드가 서로 간섭하지 않고 동일한 GPU의 컨테이너에서 나란히 실행될 수 있습니다. 이 솔루션은 투명하고 단순하며 이식 가능하며 컨테이너 자체를 변경할 필요가 없습니다.</block>
  <block id="71cdf780e37cc9571b5fcd0bf89958b1" category="paragraph">일반적인 UseCase는 동일한 GPU에서 실행되는 작업을 2~8개 볼 수 있으며, 이는 동일한 하드웨어에서 8배 더 많은 작업을 수행할 수 있음을 의미합니다.</block>
  <block id="0a1f69603a47f75f701f92ad7d94e3c5" category="paragraph">다음 그림에서 PROJECT 팀 d에 속한 Frac05 작업에 대해 할당된 GPU 수가 0.50인 것을 알 수 있다. 이는 컨테이너에 사용 가능한 GPU 메모리가 DGX-1 노드의 V100 GPU당 32GB의 절반 인 16,255MB임을 보여 주는 'NVIDIA-SMI' 명령으로 더욱 검증되었습니다.</block>
  <block id="e6d9743072cdc6867ea2980c7db7e7fd" category="paragraph"><block ref="e6d9743072cdc6867ea2980c7db7e7fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9afb11deef37d75cf56adc6e1a2f4020" category="inline-link-macro">다음으로, 초과 할당 GPU 할당을 사용하여 높은 클러스터 사용률을 달성하십시오</block>
  <block id="15968f671ef08561726e3064358c707b" category="paragraph"><block ref="15968f671ef08561726e3064358c707b" category="inline-link-macro-rx"></block></block>
  <block id="431db7b0dc79bb29f07c20c6060c3338" category="summary">이 섹션에서는 Jupyter Notebooks와 이 솔루션에 유용한 기타 리소스를 소개합니다.</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="doc">비디오 및 데모</block>
  <block id="eeb22c31d24f52a9b8225da48c32dd15" category="inline-link-macro">이전: 확인 결과.</block>
  <block id="234bbb7420397102b6a782bcaafff71a" category="paragraph"><block ref="234bbb7420397102b6a782bcaafff71a" category="inline-link-macro-rx"></block></block>
  <block id="4b8db041d93aa27fd0cc94a261e224ca" category="inline-link-macro">“지원 센터-정서-분석-파이프라인.iynb”</block>
  <block id="4e336784d7218f9fd7024470cba6b522" category="inline-link">“Support-Center-Model-Transfer-Learning-and-fine-Tuning.ipynb”</block>
  <block id="46e3dcdd2c6c30a1d9fcf40d37f0deb3" category="paragraph">감정 분석 파이프라인이 포함된 두 개의 노트북이 있습니다.<block ref="8ed620ac9482ce00db4c0f6de7250148" category="inline-link-rx"></block> 및 <block ref="ff8619e3bd3fbeea07c38337a7b773f7" category="inline-link-macro-rx"></block>. 이 노트북은 함께 지원 센터 데이터를 수집하고 사용자 데이터에 맞게 조정된 최첨단 딥 러닝 모델을 사용하여 각 문장에서 감정을 추출하는 파이프라인을 개발하는 방법을 보여줍니다.</block>
  <block id="fa8c0b2056c13341c1455ad44cc91889" category="section-title">지원 센터 - 정서 분석 파이프라인. ipynb</block>
  <block id="6b3450c2b921c398bbf90a1aee0b016c" category="paragraph">이 노트북에는 오디오 인제스트, 텍스트로 변환, 외부 대시보드에서 사용할 정서 추출용 추론 Riva 파이프라인이 포함되어 있습니다. 아직 완료되지 않은 경우 데이터 세트가 자동으로 다운로드되고 처리됩니다. 전자 필기장의 첫 번째 섹션은 오디오 파일을 텍스트로 변환하는 작업을 처리하는 텍스트 음성 변환 섹션입니다. 그 다음에는 각 텍스트 문장에 대한 감정을 추출하고 제안된 대시보드와 유사한 형식으로 결과를 표시하는 감정 분석 섹션이 이어집니다.</block>
  <block id="63abda3d2c420172da9a3a20c7f64dda" category="admonition">이 노트북은 모델 훈련 및 미세 조정 전에 실행해야 합니다. MP3 데이터 세트를 다운로드하여 올바른 형식으로 변환해야 하기 때문입니다.</block>
  <block id="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="paragraph"><block ref="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="295c2feb943bbe2efca238849828084e" category="section-title">Support Center - 모델 교육 및 미세 조정. ipynb</block>
  <block id="6efbeb8cfc7e387edbf91bad41170349" category="paragraph">TAO 툴킷 가상 환경은 노트북을 실행하기 전에 설정해야 합니다(설치 지침은 명령 개요 의 TAO 툴킷 섹션 참조).</block>
  <block id="a9d805c9ddfdf62e60632a9754e29404" category="paragraph">이 노트북은 TAO 툴킷을 사용하여 고객 데이터에 대한 딥 러닝 모델을 미세 조정합니다. 이전 전자 필기장과 마찬가지로 이 섹션은 텍스트 음성 대 텍스트 및 감정 분석 구성 요소에 대한 두 섹션으로 구분됩니다. 각 섹션은 데이터 처리, 모델 교육 및 세부 조정, 결과 평가 및 모델 내보내기를 거치게 됩니다. 마지막으로, Riva에서 사용할 미세 조정된 모델을 모두 배포하기 위한 마지막 섹션이 있습니다.</block>
  <block id="b40454c57dd60f999f3243514cd90ede" category="paragraph"><block ref="b40454c57dd60f999f3243514cd90ede" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b774a4819b60036fd16dae7b1618fe7" category="inline-link-macro">다음: 결론.</block>
  <block id="f89bf51287609a0c0cf7563b31265c06" category="paragraph"><block ref="f89bf51287609a0c0cf7563b31265c06" category="inline-link-macro-rx"></block></block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="doc">감사의 말</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">NetApp 기술 마케팅 엔지니어 Mike Olesby</block>
  <block id="94a8512f59eafd68b470105fc3269fd4" category="list-text">NetApp 선임 기술 담당 이사 Santosh Rao</block>
  <block id="17e1dd6389643aeecf567ba08bf1df2c" category="paragraph"><block ref="17e1dd6389643aeecf567ba08bf1df2c" category="inline-link-macro-rx"></block></block>
  <block id="74c071ff3c1d6d6fc39b72d617aefdf8" category="doc">솔루션 배포 및 검증 세부 정보</block>
  <block id="b122830b8b8edd9e76690ea23b0c4cbd" category="paragraph">다음 섹션에서는 솔루션 구축 및 검증에 대한 세부 정보를 다룹니다.</block>
  <block id="ebe48d794d8ada5d4e067cd5993bdd3e" category="inline-link-macro">다음: ONTAP AI 배포</block>
  <block id="3b103491115e62f2388d69086a2eff9d" category="paragraph"><block ref="3b103491115e62f2388d69086a2eff9d" category="inline-link-macro-rx"></block></block>
  <block id="8b6327b93d10679b1f412976af9d3bba" category="summary">Docker, Kubernetes 등의 오케스트레이션 툴과 통합된 Azure NetApp Files, RAPIDS, DASK를 사용하면 대규모 ML 처리 및 훈련 구축을 더 빠르게 처리하고 간소화할 수 있습니다. 이 솔루션은 엔드 투 엔드 데이터 파이프라인을 통합함으로써 수많은 고급 컴퓨팅 워크로드에서 발생하는 지연 시간과 복잡성을 줄여 개발과 운영 간의 격차를 효과적으로 해소합니다.</block>
  <block id="53ffd6a9e0049c8cbf7f940c2b8bc793" category="inline-link-macro">이전: NetApp DataOps 툴킷을 사용하여 데이터 세트 및 모델 버전 관리</block>
  <block id="01643859d7e5dff013d2acd6a02af35e" category="paragraph"><block ref="01643859d7e5dff013d2acd6a02af35e" category="inline-link-macro-rx"></block></block>
  <block id="7527b11aa1f9aa169a9d6103e9c4c417" category="paragraph">Azure NetApp Files, RAPIDS 및 DASK는 Docker, Kubernetes 등의 오케스트레이션 툴과 통합하여 대규모 ML 처리 및 훈련 구축을 간소화하고 있습니다. 이 솔루션은 엔드 투 엔드 데이터 파이프라인을 통합함으로써 수많은 고급 컴퓨팅 워크로드에서 발생하는 지연 시간과 복잡성을 줄여 개발과 운영 간의 격차를 효과적으로 해소합니다. 데이터 과학자는 대규모 데이터 세트에서 쿼리를 실행하고 교육 단계 동안 다른 사용자와 데이터 및 알고리즘 모델을 안전하게 공유할 수 있습니다.</block>
  <block id="bd9091c7320e4b1069eed28f04839354" category="paragraph">자체 AI/ML 파이프라인을 구축할 때는 아키텍처 구성 요소의 통합, 관리, 보안 및 접근성을 구성하는 것이 매우 어렵습니다. 개발자가 자신의 환경에 액세스하고 제어하도록 하는 것은 또 다른 도전 과제입니다.</block>
  <block id="a93fc9ba708498e20819f22e22ecfa5c" category="paragraph">클라우드에 엔드 투 엔드 분산 교육 모델 및 데이터 파이프라인을 구축하여 총 워크플로우 완료 시간을 GPU 가속 데이터 처리 및 컴퓨팅 프레임워크를 활용하지 않는 기존의 오픈 소스 접근 방식에 비해 크게 두 배나 단축한 것으로 입증되었습니다.</block>
  <block id="fcceee9f9e65e4b0d089c6c433f6c191" category="paragraph">NetApp, Microsoft, 오픈 소스 오케스트레이션 프레임워크 및 NVIDIA가 결합되어 최신 기술을 유연한 관리 서비스로 통합하여 기술 채택을 가속화하고 새로운 AI/ML 애플리케이션의 출시 시기를 앞당길 수 있습니다. 이러한 고급 서비스는 사내 및 하이브리드 구축 아키텍처용으로 쉽게 포팅할 수 있는 클라우드 네이티브 환경에서 제공됩니다.</block>
  <block id="40a15e6807b47955e7b7a9b1bd330b01" category="inline-link-macro">다음: 추가 정보를 찾을 위치.</block>
  <block id="eee817389517c17ec810d52f22a8222d" category="paragraph"><block ref="eee817389517c17ec810d52f22a8222d" category="inline-link-macro-rx"></block></block>
  <block id="7a879e305f90568b91e8623ce5f9ee39" category="summary">2019년 5월부터 Microsoft는 NetApp ONTAP 기술을 기반으로 엔터프라이즈 NFS 및 SMB 파일 서비스를 위한 Azure 네이티브 자사 포털 서비스를 제공합니다.</block>
  <block id="0bf51d984b6a6d3fddc0e24f62eb1a14" category="doc">TR-4896: Azure에서 분산된 교육: 차선 감지 - 솔루션 설계</block>
  <block id="0ab5aa2896d8eed7732e69be5e5782b4" category="paragraph">Muneer Ahmad and Verron Martina, NetApp Ronden Dar, run:AI</block>
  <block id="a89ade32996e322edf837476febbc9bd" category="paragraph">2019년 5월부터 Microsoft는 NetApp ONTAP 기술을 기반으로 엔터프라이즈 NFS 및 SMB 파일 서비스를 위한 Azure 네이티브 자사 포털 서비스를 제공합니다. 이러한 개발을 위해 Microsoft와 NetApp의 전략적 파트너십을 활용하고 세계적인 수준의 ONTAP 데이터 서비스를 Azure로 확장합니다.</block>
  <block id="d6312cb01ee08559dbaa35c308e72268" category="paragraph">업계 최고의 클라우드 데이터 서비스 공급자인 NetApp이 Run:AI와 팀을 이루어 AI 인프라를 가상화하여 AI의 전체 GPU 활용률을 더욱 빠르게 실험할 수 있도록 했습니다. 이 파트너십을 통해 팀에서는 데이터를 빠르게 활용하고 컴퓨팅 리소스를 무제한으로 활용하여 여러 실험을 병렬로 실행하여 AI 속도를 높일 수 있습니다. 실행: AI는 리소스 할당을 자동화하여 전체 GPU 활용률을 지원하며, 검증된 Azure NetApp Files 아키텍처를 통해 데이터 파이프라인의 장애물을 제거하여 모든 실험을 최대 속도로 실행할 수 있습니다.</block>
  <block id="5234f8ee670afed8c398940a707f25df" category="paragraph">NetApp과 RUN TO NETAPP: AI는 고객에게 Azure에서의 AI 전환을 위한 미래 지향형 플랫폼을 제공하기 위해 힘을 합했습니다. 분석 및 고성능 컴퓨팅(HPC)에서 자율적 결정(고객이 필요한 시점에 필요한 비용만 지불하여 IT 투자를 최적화할 수 있음)에 이르기까지, NetApp과 실행 시 AI는 Azure Cloud에서 통합된 단일 경험을 제공합니다.</block>
  <block id="67d45a00257105f21f4427f31e0c9fa1" category="summary">이 기술 보고서에서는 이전 학습 및 대화형 AI를 사용하는 NVIDIA 소프트웨어 프레임워크와 NetApp 데이터 관리 기술을 함께 사용하여 엔터프라이즈 수준의 글로벌 지원 센터에서 NetApp 데이터 관리 기술을 수행하는 고객에 대한 감정 분석을 수행할 수 있는 설계 지침을 제공합니다.</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="doc">TR-4910: NetApp AI를 통한 고객 커뮤니케이션의 감정 분석</block>
  <block id="22268d4ee4f32cda2f20141957aac961" category="paragraph">Rick Huang, Sathish Thyagarajan, David Arnette, NetApp Diego Sosa-Coba, SFL Scientific</block>
  <block id="0c450c48691e7a55b657f2cb7d18a0dd" category="paragraph">이 기술 보고서에서는 이전 학습 및 대화형 AI를 사용하는 NVIDIA 소프트웨어 프레임워크와 NetApp 데이터 관리 기술을 함께 사용하여 엔터프라이즈 수준의 글로벌 지원 센터에서 NetApp 데이터 관리 기술을 수행하는 고객에 대한 감정 분석을 수행할 수 있는 설계 지침을 제공합니다. 이 솔루션은 채팅 로그, 이메일 및 기타 텍스트 또는 오디오 통신을 나타내는 녹음된 음성 또는 텍스트 파일을 통해 고객 통찰력을 얻고자 하는 모든 산업에 적용됩니다. NetApp은 NetApp 클라우드 연결 All-Flash 스토리지를 통해 GPU 가속 컴퓨팅 클러스터에서 자동 음성 인식, 실시간 감정 분석, 딥 러닝 자연어 처리 모델 재교육 기능을 시연하기 위해 엔드 투 엔드 파이프라인을 구축했습니다. 방대한 최신 언어 모델을 훈련 및 최적화하여 글로벌 지원 센터와 신속하게 추론을 수행하여 탁월한 고객 경험과 객관적이고 장기적인 직원 성과 평가를 생성할 수 있습니다.</block>
  <block id="549c85ede9b39be6ef0eec80db7e098c" category="paragraph">정서 분석은 자연어 처리(NLP) 내 연구 분야로서 텍스트에서 긍정적, 부정적 또는 중립적 감정을 도출합니다. 점점 더 많은 사람들이 대화하는 AI 시스템은 거의 세계적인 수준의 통합으로 부상했습니다. 감정 분석은 지원 센터 직원의 통화 성과를 확인하고 적절한 자동 챗봇 응답을 제공하는 등 다양한 활용 사례를 통해 분기별 수익 통화 시 기업 담당자와 대상 간의 상호 작용을 기반으로 회사의 주식 가격을 예측해 볼 수 있습니다. 또한, 감정 분석을 사용하여 브랜드가 제공하는 제품, 서비스 또는 지원에 대한 고객의 관점을 결정할 수 있습니다.</block>
  <block id="5855677156d63ad3c93a7b5382098060" category="paragraph">이 엔드 투 엔드 솔루션은 NLP 모델을 사용하여 지원 센터 분석 프레임워크를 지원하는 고수준 정서 분석을 수행합니다. 오디오 녹음은 서면 텍스트로 처리되며 대화의 각 문장에서 감정은 추출됩니다. 대시보드로 집계된 결과는 역사적, 실시간으로 대화 감정을 분석하기 위해 만들 수 있습니다. 이 솔루션은 유사한 데이터 양식 및 출력 요구가 있는 다른 솔루션으로 일반화할 수 있습니다. 적절한 데이터를 사용하여 다른 사용 사례를 수행할 수 있습니다. 예를 들어 동일한 종단간 파이프라인을 사용하여 기업 수익 통화를 분석하여 감정을 분석할 수 있습니다. 또한 파이프라인의 유연한 특성 때문에 주제 모델링 및 NER(명명된 엔티티 인식)과 같은 다른 형태의 NLP 분석이 가능합니다.</block>
  <block id="ea4f750fd9fd89aeff4ca8d4162fb673" category="paragraph">이러한 AI 구현은 NVIDIA Riva, NVIDIA TAO 툴킷 및 NetApp DataOps 툴킷을 함께 사용하여 가능했습니다. NVIDIA의 툴은 사전 구축된 모델 및 파이프라인을 사용하여 고성능 AI 솔루션을 신속하게 배포하는 데 사용됩니다. NetApp DataOps 툴킷은 다양한 데이터 관리 작업을 단순화하여 개발 속도를 높여줍니다.</block>
  <block id="7a7e97f7fcf4e2974d9a6feee2b056f8" category="section-title">고객 가치</block>
  <block id="3815ef30c3d6c6bdc3862cc9530d091e" category="paragraph">기업은 감성 분석을 위해 텍스트, 오디오 및 비디오 대화를 위한 직원 평가 및 고객 반응 도구를 통해 가치를 확인합니다. 관리자는 대시보드에 표시되는 정보를 활용하여 대화 양쪽을 기준으로 직원 및 고객 만족도를 평가할 수 있습니다.</block>
  <block id="da210ea22d819ca26070a3795f9a14d4" category="paragraph">또한 NetApp DataOps 툴킷은 고객 인프라 내에서 데이터의 버전 관리 및 할당을 관리합니다. 따라서 복잡하지 않은 데이터 스토리지 비용을 발생시키지 않고 대시보드 내에 제공되는 분석 내용이 자주 업데이트됩니다.</block>
  <block id="e5fcadecc4515efec9267b8ad57b28a5" category="inline-link-macro">다음으로, 사용 사례를 살펴보겠습니다.</block>
  <block id="93b7bce28e36a4eebec23c8fd4be315d" category="paragraph"><block ref="93b7bce28e36a4eebec23c8fd4be315d" category="inline-link-macro-rx"></block></block>
  <block id="c4e7b8572218b2c9421122c7ab76be25" category="paragraph">NetApp과 cnvrg.io는 파트너십을 통해 고객에게 ML 및 DL 소프트웨어 개발을 위한 완벽한 데이터 관리 솔루션을 제공합니다. ONTAP AI는 모든 규모의 운영에 고성능 컴퓨팅 및 스토리지를 제공하며 cnvrg.io 소프트웨어는 데이터 과학 워크플로우를 간소화하고 리소스 활용률을 향상합니다.</block>
  <block id="c6a4d485e7c4cefa4c121ce6c59b28dc" category="inline-link-macro">다음은 감사의 말</block>
  <block id="0c8a89e4d7937b03d3adc0f1d6530b08" category="paragraph"><block ref="0c8a89e4d7937b03d3adc0f1d6530b08" category="inline-link-macro-rx"></block></block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">다른 사용 사례에 맞게 검증에 사용된 설정을 조정할 수 있습니다.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">아키텍처 사이징 옵션</block>
  <block id="ac0ec60d36dfa69ed9c33bff90080b23" category="inline-link-macro">이전: 테스트 결과.</block>
  <block id="389a3124af7d4b9dc7165b05fd96a378" category="paragraph"><block ref="389a3124af7d4b9dc7165b05fd96a378" category="inline-link-macro-rx"></block></block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">컴퓨팅 서버</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">우리는 SE350에서 지원되는 최저 수준의 CPU인 Intel Xeon D-2123IT CPU를 4개의 물리적 코어와 60W TDP로 사용했습니다. 서버는 CPU 교체를 지원하지 않지만 보다 강력한 CPU로 주문할 수 있습니다. 지원되는 최상위 CPU는 16개의 코어가 있는 Intel Xeon D-2183IT, 2.20GHz에서 실행되는 100W입니다. 이렇게 하면 CPU 계산 기능이 크게 향상됩니다. CPU는 추론 워크로드 자체를 실행하는 데 병목 지점이 되지 않지만, 데이터 처리와 추론과 관련된 다른 작업에 도움이 됩니다. 현재 NVIDIA T4는 에지 사용 사례에 사용할 수 있는 유일한 GPU이므로, 현재는 GPU를 업그레이드하거나 다운그레이드할 수 없습니다.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">공유 스토리지</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">테스트 및 검증을 위해 최대 스토리지 용량이 50.5TB, 순차적 읽기의 경우 처리량 4.4GBps, 소규모 랜덤 읽기의 경우 230K IOPS를 지원하는 NetApp AFF C190 시스템이 이 문서의 목적에 사용되었으며 에지 추론 워크로드에 적합한 것으로 입증되었습니다.</block>
  <block id="bb33c803e43b816786d862bbbbf2c824" category="paragraph">그러나 스토리지 용량 또는 더 빠른 네트워킹 속도가 필요한 경우 NetApp AFF A220 또는 을 사용해야 합니다<block ref="03f94a30ec5c979321fdd9a1ba99a1c6" category="inline-link-rx"></block> 기술을 자세히 소개합니다. 또한 최대 1.5PB의 용량을 가진 NetApp EF280 시스템도 이 솔루션 검증을 위해 10Gbps 대역폭 사용이 사용되었습니다. 더 높은 대역폭으로 더 많은 스토리지 용량을 원하는 경우,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> 사용할 수 있습니다.</block>
  <block id="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="paragraph"><block ref="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="inline-link-macro-rx"></block></block>
  <block id="19075a93ccd90f3ea7019f0572778b2a" category="summary">이 페이지에는 이 솔루션에 필요한 소프트웨어 요구 사항이 나열되어 있습니다.</block>
  <block id="b0167c15bc26c48af07aea36aba706fa" category="inline-link-macro">이전: 기술 개요</block>
  <block id="440b940924209e1d417ef7c4ef9bce34" category="paragraph"><block ref="440b940924209e1d417ef7c4ef9bce34" category="inline-link-macro-rx"></block></block>
  <block id="793d18702a236e0e3b768917638f0ba2" category="paragraph">다음 표에는 이 솔루션에 필요한 소프트웨어 요구 사항이 나열되어 있습니다.</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">버전</block>
  <block id="8ab697a4168b5fb33603a98d6bc9a436" category="cell">RAPIDS 및 Dask 컨테이너 이미지입니다</block>
  <block id="9ab6289633c326d69a377cbb29bd81a3" category="cell">리포지토리: "rapidsai/rapidsai" 태그: 0.17-ca11.0-runtime-uubuntu18.04</block>
  <block id="6e1b77cc3b83d87aaee751e2eaed5044" category="inline-link-macro">다음으로, 클라우드 리소스 요구사항을 살펴보겠습니다.</block>
  <block id="58bc7690a5a3a5a1aa5dc70739fd0b53" category="paragraph"><block ref="58bc7690a5a3a5a1aa5dc70739fd0b53" category="inline-link-macro-rx"></block></block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">솔루션 개요</block>
  <block id="fbe29309a183681bc26203d4c65853a2" category="paragraph">이 섹션에서는 기존의 데이터 과학 파이프라인과 그 단점을 검토합니다. 또한, 제안된 데이터 세트 캐싱 솔루션의 아키텍처도 제공합니다.</block>
  <block id="1f14aecc1193f646e0005e27fbc6e63d" category="section-title">기존의 데이터 과학 파이프라인 및 결점</block>
  <block id="17fb7d0ba5495199d3e18fe23dff7b59" category="paragraph">ML 모델 개발 및 배포의 일반적인 시퀀스에는 다음을 포함하는 반복 단계가 포함됩니다.</block>
  <block id="63e1ded7e3ae73253b5c287bc9bdef02" category="list-text">데이터 수집 중</block>
  <block id="52e028dc7ac82e9d4b7b1ae588fecc9a" category="list-text">데이터 사전 처리(여러 버전의 데이터 세트 생성)</block>
  <block id="33cd0fcdd9ee7e650043133b12516155" category="list-text">하이퍼파라미터 최적화, 다른 모델 등과 관련된 여러 실험 실행</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="list-text">구축</block>
  <block id="b85c416c94e0c5314a1e6fcc21d4139e" category="list-text">Monitoringcnvrg.io는 연구부터 배포에 이르는 모든 작업을 자동화하는 포괄적인 플랫폼을 개발했습니다. 다음 그림에서는 파이프라인과 관련된 대시보드 스크린샷의 작은 샘플을 보여 줍니다.</block>
  <block id="5a5ade85e7f7478bcba59e8c3891c914" category="paragraph"><block ref="5a5ade85e7f7478bcba59e8c3891c914" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26d6a4638ffd0b7779f1353f5fe54f0d" category="paragraph">퍼블릭 저장소 및 프라이빗 데이터에서 여러 데이터 세트를 재생하는 것이 일반적입니다. 또한 각 데이터 세트에는 데이터 세트 정리 또는 기능 엔지니어링으로 인해 여러 버전이 있을 수 있습니다. 다음 그림과 같이 팀에서 공동 작업 및 일관성 도구를 사용할 수 있도록 데이터 세트 허브와 버전 허브를 제공하는 대시보드가 필요합니다.</block>
  <block id="e884d73b6a4214bea010ec3bbfdad8b6" category="paragraph"><block ref="e884d73b6a4214bea010ec3bbfdad8b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93661dde7027bf31b3d007740a3d4648" category="paragraph">파이프라인의 다음 단계에서는 각각 데이터 세트 및 특정 컴퓨팅 인스턴스와 관련된 교육 모델의 여러 병렬 인스턴스가 필요합니다. 특정 컴퓨팅 인스턴스를 사용하여 특정 실험으로 데이터 세트를 바인딩하는 것은 쉽지 않습니다. AWS(Amazon Web Services)의 GPU 인스턴스에서 일부 실험을 수행하는 동시에, DGX-1 또는 DGX-2 온프레미스 인스턴스에서 다른 실험을 수행할 수 있기 때문입니다. GCP의 CPU 서버에서 다른 실험을 실행할 수도 있지만 데이터 세트 위치가 교육을 수행하는 컴퓨팅 리소스 가까이에 있지 않습니다. 데이터 세트 스토리지에서 컴퓨팅 인스턴스까지 지연 시간이 짧은 10GbE 또는 더 많은 연결이 끊어지려면 어느 정도의 근접성이 있어야 합니다.</block>
  <block id="ba4f5ee1b0d01d3416723cfc3ec296ec" category="paragraph">데이터 과학자는 훈련을 수행하고 실험을 실행하는 컴퓨팅 인스턴스에 데이터 세트를 다운로드하는 것이 일반적입니다. 그러나 이 접근 방식에는 몇 가지 잠재적 문제가 있습니다.</block>
  <block id="90b6a1c5b483f6c6b399bc17c5e1af9a" category="list-text">데이터 과학자가 데이터 세트를 컴퓨팅 인스턴스로 다운로드할 때 통합 컴퓨팅 스토리지가 고성능을 보장하는 것은 아닙니다(고성능 시스템의 예로는 ONTAP AFF A800 NVMe 솔루션이 있음).</block>
  <block id="5713a88504bb65e3808faac627a6a0fc" category="list-text">다운로드한 데이터 세트가 하나의 컴퓨팅 노드에 상주하면 NetApp ONTAP 고성능 분산 스토리지와 달리 여러 노드에서 분산 모델을 실행하면 스토리지 병목 현상이 발생할 수 있습니다.</block>
  <block id="299b9ae5439d32ed932f51f3b3aa92d6" category="list-text">대기열 충돌 또는 우선순위 때문에 훈련 실험의 다음 반복을 다른 컴퓨팅 인스턴스에서 수행할 수 있으며, 데이터 세트에서 컴퓨팅 위치까지의 거리가 크게 멀어지거나</block>
  <block id="30e37003024e85518a26760a7ab58f4e" category="list-text">동일한 컴퓨팅 클러스터에서 교육 실험을 실행하는 다른 팀 구성원은 이 데이터 세트를 공유할 수 없으며, 각 팀원이 임의의 위치에서 데이터 세트의 (값비싼) 다운로드를 수행합니다.</block>
  <block id="9e5d53150336efb0446a063309805f01" category="list-text">후속 훈련 작업에 동일한 데이터 세트의 다른 데이터 세트 또는 버전이 필요한 경우 데이터 과학자는 training.NetApp 및 cnvrg.io를 수행하는 컴퓨팅 인스턴스에 데이터 세트의 (값비싼) 다운로드를 다시 수행해야 합니다. 그 결과, 이러한 장애 요소를 제거하는 새로운 데이터 세트 캐싱 솔루션이 만들어졌습니다. 이 솔루션은 ONTAP 고성능 스토리지 시스템에서 핫 데이터 세트를 캐싱하여 ML 파이프라인의 실행을 가속합니다. ONTAP NFS를 사용하면 NetApp에서 제공하는 Data Fabric(예: AFF A800)에서 데이터 세트를 한 번만 캐싱할 수 있으며, 이 데이터는 컴퓨팅과 함께 배치됩니다. NetApp ONTAP NFS 고속 스토리지가 여러 ML 컴퓨팅 노드를 지원할 수 있으므로 교육 모델의 성능이 최적화되어 비용 절감, 생산성 및 운영 효율성이 조직에 제공됩니다.</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">솔루션 아키텍처</block>
  <block id="a63af1f206939a3c956a2e8b6ab53103" category="paragraph">다음 그림과 같이 NetApp 및 cnvrg.io의 이 솔루션은 데이터 세트 캐싱을 제공합니다. 데이터 세트 캐싱을 사용하면 데이터 과학자가 원하는 데이터 세트 또는 데이터 세트 버전을 선택하여 ML 컴퓨팅 클러스터 근처에 있는 ONTAP NFS 캐시로 이동할 수 있습니다. 이제 데이터 과학자는 지연 또는 다운로드를 유발하지 않고 여러 실험을 실행할 수 있습니다. 또한 모든 공동 작업 엔지니어는 데이터 레이크에서 추가로 다운로드할 필요 없이 연결된 컴퓨팅 클러스터(노드를 선택할 수 있는 자유로이)에서 동일한 데이터 세트를 사용할 수 있습니다. 데이터 과학자는 모든 데이터 세트 및 버전을 추적 및 모니터링하고 캐시된 데이터 세트를 확인하는 대시보드를 제공합니다.</block>
  <block id="612eaee91b23ecc385c1b402d44c081f" category="paragraph">cnvrg.io 플랫폼은 특정 시간 동안 사용되지 않은 오래된 데이터 세트를 자동으로 감지하여 캐시에서 데이터를 제거하므로 자주 사용하는 데이터 세트에 대해 사용 가능한 NFS 캐시 공간을 유지합니다. ONTAP의 데이터 세트 캐싱은 클라우드와 사내에서 이루어지므로 최대한의 유연성을 제공하는 것이 중요합니다.</block>
  <block id="0cb5e14601fcf39745352a9556939aa3" category="paragraph"><block ref="0cb5e14601fcf39745352a9556939aa3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="810aceabf729ffa8c2dfd61a3aaeafaa" category="inline-link-macro">다음: 개념 및 구성 요소</block>
  <block id="0a01ff9defa9120e928e7e306e3e3234" category="paragraph"><block ref="0a01ff9defa9120e928e7e306e3e3234" category="inline-link-macro-rx"></block></block>
  <block id="dcfa517bb68d187d11e580baf2ecf588" category="summary">이 페이지에서는 제어(Helm)를 사용하여 AKS에서 RAPIDS를 사용하여 Dask를 설정하는 방법에 대해 설명합니다.</block>
  <block id="fd22fb1626b987fa7b72743fa9698ec6" category="doc">Helm을 사용하여 AKS에서 RAPIDS를 사용하여 Dask를 설정합니다</block>
  <block id="d74bb88aa6e4b1c540be703fda33923e" category="inline-link-macro">이전: Trident를 설치합니다.</block>
  <block id="6020c64d2124fc0caa426123bfc5ba38" category="paragraph"><block ref="6020c64d2124fc0caa426123bfc5ba38" category="inline-link-macro-rx"></block></block>
  <block id="d81f517b6ad0d9702be81a8199a2246f" category="paragraph">Hrom을 사용하여 AKS에서 RAPIDS를 사용하여 Dask를 설정하려면 다음 단계를 수행하십시오.</block>
  <block id="549c839f491ec7099a895dd1cfea7534" category="list-text">RAPIDS를 사용하여 Dask를 설치하기 위한 네임스페이스를 생성합니다.</block>
  <block id="74d041e68ac2a21a636ab14ae78f279d" category="list-text">PVC를 생성하여 클릭률 데이터 세트를 저장합니다.</block>
  <block id="f5008aa6b27cdcaadbe27960383c8ff6" category="list-text">다음 YAML 콘텐츠를 파일에 저장하여 PVC를 생성합니다.</block>
  <block id="67d464c36bcc48173c964a780459dbfd" category="list-text">Kubernetes 클러스터에 YAML 파일을 적용하십시오.</block>
  <block id="be0ca76aafd92c18792693b8f05d01ce" category="inline-link"><block ref="be0ca76aafd92c18792693b8f05d01ce" category="inline-link-rx"></block></block>
  <block id="dc7ba914646428512334728c1f0ebd7d" category="list-text">"rapidsai git" 리포지토리 복제(<block ref="4f08c7c28c19e75f4d8607fc65d40067" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="50aef45ee39d958bc589f422bfb6d1bf" category="list-text">"Values.YAML"을 수정하고, 작업자와 Jupyter 작업공간을 위해 앞서 만든 PVC를 포함합니다.</block>
  <block id="06867e85b141bb9d17f8ed6b4b685c46" category="list-text">리포지토리의 "rapidsai" 디렉토리로 이동합니다.</block>
  <block id="1a985ac965074fab9cfcee28ef954755" category="list-text">Values.YAML 파일을 업데이트하고 PVC를 사용해 볼륨을 마운트합니다.</block>
  <block id="52076eb1fec3929530258335052328b3" category="list-text">리포지토리의 홈 디렉토리로 이동하여 H제어 를 사용하여 AKS에 작업자 노드 3개가 있는 Dask를 배포합니다.</block>
  <block id="bd4e74749939dd3c9f80ff138c18af53" category="inline-link-macro">다음: Azure NetApp Files 성능 계층</block>
  <block id="52d5e0adb69809963ce4f94104a75b5e" category="paragraph"><block ref="52d5e0adb69809963ce4f94104a75b5e" category="inline-link-macro-rx"></block></block>
  <block id="e40030fd64108859627c7a126638f0e6" category="list-text">NetApp AI 컨트롤 플레인:</block>
  <block id="63178726ae501745b3914ec3aa50969e" category="list-text">NetApp AI Control Plane 기술 보고서</block>
  <block id="3ce56c027572d1908d65b63056be024f" category="inline-link"><block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="445a4d3400bdde832e8898d8349696c0" category="paragraph"><block ref="445a4d3400bdde832e8898d8349696c0" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="9a8ec45d909b996af4c042e44b5c5f29" category="list-text">TensorFlow: 모두를 위한 오픈 소스 머신 러닝 프레임워크<block ref="db3465122fd83ad1dc4cff7e67d794df" category="inline-link-rx"></block></block>
  <block id="60ea9e9ecbf839c413c5e977002eabf4" category="paragraph"><block ref="60ea9e9ecbf839c413c5e977002eabf4" category="inline-link-rx"></block></block>
  <block id="6bd14be39aedfe96ceacec2caaac0532" category="paragraph"><block ref="6bd14be39aedfe96ceacec2caaac0532" category="inline-link-rx"></block></block>
  <block id="6771540ad76dbed724cb9025978b8510" category="paragraph"><block ref="6771540ad76dbed724cb9025978b8510" category="inline-link-rx"></block></block>
  <block id="ef9e62eeb81c0987fbe61de48635886a" category="paragraph"><block ref="ef9e62eeb81c0987fbe61de48635886a" category="inline-link-rx"></block></block>
  <block id="3bc4d41311862190a8fd0d6c8f661971" category="list-text">Iguazio 데이터 과학 플랫폼</block>
  <block id="737d4d1e81ff236001338f46d1623aaa" category="list-text">Iguazio 데이터 과학 플랫폼 문서</block>
  <block id="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link"><block ref="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link-rx"></block></block>
  <block id="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="paragraph"><block ref="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="inline-link-rx"></block></block>
  <block id="4f0f362becf6baf6e08f490115d76d98" category="list-text">Nuclio 서버리스 기능</block>
  <block id="89aa84cdf5db1bece2993801c78914de" category="inline-link"><block ref="89aa84cdf5db1bece2993801c78914de" category="inline-link-rx"></block></block>
  <block id="93eac034cc1c1aaedaf6ed41063825ee" category="paragraph"><block ref="93eac034cc1c1aaedaf6ed41063825ee" category="inline-link-rx"></block></block>
  <block id="b5266d58998338015b5e02ee7e84a833" category="list-text">MLRun OpenSource 파이프라인 오케스트레이션 프레임워크</block>
  <block id="b96a861dccea968edc0b7a9ff96203e9" category="inline-link"><block ref="b96a861dccea968edc0b7a9ff96203e9" category="inline-link-rx"></block></block>
  <block id="70a8a001358e056f435199da7e17e427" category="paragraph"><block ref="70a8a001358e056f435199da7e17e427" category="inline-link-rx"></block></block>
  <block id="b3f90aaddad391963c2090db8f1b727e" category="list-text">NVIDIA DGX-1 시스템</block>
  <block id="af828c56c03364ebbde4c582adeb8de3" category="paragraph"><block ref="af828c56c03364ebbde4c582adeb8de3" category="inline-link-rx"></block></block>
  <block id="d6a377b23d0f4dbe3f5bf91d5f6abf74" category="list-text">NVIDIA Tesla V100 Tensor 코어 GPU</block>
  <block id="a724832176ce84a9d4be5c34e44891d3" category="paragraph"><block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="0df7621d860637a2e6e462c56322edab" category="list-text">NVIDIA GPU 클라우드</block>
  <block id="839d9b8469a8d9554891a7515a2b9be7" category="paragraph"><block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="9a84c14d2692222552174943486e7136" category="inline-link"><block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="0d9d8991a05834f0e52a99b37ce360b8" category="paragraph"><block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="5f662f6dc276dd5a2a83440d0fe63e9b" category="list-text">AFF용 NetApp 플래시의 이점</block>
  <block id="72cf25e9f1e13167cd0dde6f285552ea" category="paragraph"><block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link"><block ref="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link-rx"></block></block>
  <block id="a5d59e86f09bafae4247836d5135b6a3" category="paragraph"><block ref="a5d59e86f09bafae4247836d5135b6a3" category="inline-link-rx"></block></block>
  <block id="7a26d62dac2be507dcc3e5b9da0ed765" category="paragraph"><block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="47c991332229e0cbfe947beaa428ea61" category="list-text">DGX-1 및 Cisco 네트워킹 기반 ONTAP AI 설계 가이드</block>
  <block id="b141781260425e95eee945147e2f0d99" category="inline-link"><block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="9fbee18519e76388280bc1f8e3fd6c7e" category="paragraph"><block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="0be3b0697a0ffdfe9065df24ec1d3e16" category="list-text">DGX-1 및 Cisco 네트워킹 지원 ONTAP AI 배포 가이드</block>
  <block id="921f17c41dea89b0a711f380e9864e09" category="inline-link"><block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="aef3d0752148699921f8a251537d5ff3" category="paragraph"><block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="205a4f16a51f3acd6dbba76dbeb10818" category="list-text">DGX-1 및 Mellanox 네트워킹 설계 가이드를 지원하는 ONTAP AI</block>
  <block id="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link"><block ref="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link-rx"></block></block>
  <block id="0a9e1455c4a5a9965867a5efd6b8cc9b" category="paragraph"><block ref="0a9e1455c4a5a9965867a5efd6b8cc9b" category="inline-link-rx"></block></block>
  <block id="913c29df09bcb5715ed7a48c12f3a0da" category="list-text">ONTAP AI 네트워킹</block>
  <block id="ae2703e9b1dff6da048c786142c2e7db" category="list-text">Cisco Nexus 3232C 시리즈 스위치</block>
  <block id="96eb8aa0e86d101fdf87284d7d6f1bc7" category="paragraph"><block ref="96eb8aa0e86d101fdf87284d7d6f1bc7" category="inline-link-rx"></block></block>
  <block id="8a27a2062df55e0aa73964ea8ec2ab55" category="list-text">Mellanox 스케일 아웃 SN2000 이더넷 스위치 시리즈</block>
  <block id="87a849c2f3c412a491f97674d5e27ed1" category="inline-link"><block ref="fd77c1cd25d650110f7047fa02f8327d" category="inline-link-rx"></block></block>
  <block id="a6c16c720941d75800533dedd69929cc" category="paragraph"><block ref="ad90d1952f7d0f85370461937e4484b7" category="inline-link-rx"></block></block>
  <block id="9e40fd8f5f0e113c758dfa63adc1221d" category="summary">Kubeflow는 새로운 Jupyter Notebook 서버를 신속하게 프로비저닝하여 데이터 과학자 작업 공간 역할을 할 수 있습니다. Kubeflow와 함께 새로운 Jupyter Notebook 서버를 프로비저닝하려면 이 페이지에 나열된 작업을 수행합니다.</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">데이터 과학자 또는 개발자 사용을 위한 Jupyter Notebook Workspace를 제공합니다</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Kubeflow 공식 문서</block>
  <block id="52d84951381eb0ab7a285dd32b31702c" category="paragraph">Kubeflow는 새로운 Jupyter Notebook 서버를 신속하게 프로비저닝하여 데이터 과학자 작업 공간 역할을 할 수 있습니다. Kubeflow와 함께 새로운 Jupyter Notebook 서버를 프로비저닝하려면 다음 작업을 수행합니다. Kubeflow 컨텍스트 내의 Jupyter Notebooks에 대한 자세한 내용은 를 참조하십시오<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>.</block>
  <block id="5e82e4aa94a53b3b50acf347914be197" category="list-text">Kubeflow 중앙 대시보드에서 기본 메뉴의 Notebook Servers를 클릭하여 Jupyter Notebook 서버 관리 페이지로 이동합니다.</block>
  <block id="358d18b5a42ec1d80b04e767298ea372" category="paragraph"><block ref="358d18b5a42ec1d80b04e767298ea372" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208feb7a4d57f0afc49e53fe1fe8b978" category="list-text">New Server를 클릭하여 새 Jupyter Notebook 서버를 프로비저닝합니다.</block>
  <block id="3541a3b25823fa3b302c686b6fe2a212" category="paragraph"><block ref="3541a3b25823fa3b302c686b6fe2a212" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f95069a2e81949b101427e1fa4afddf" category="list-text">새 서버의 이름을 지정하고, 서버를 기반으로 할 Docker 이미지를 선택한 다음, 서버에서 예약할 CPU와 RAM의 양을 지정합니다. 네임스페이스 필드가 비어 있는 경우 페이지 머리글의 네임스페이스 선택 메뉴를 사용하여 네임스페이스를 선택합니다. 그러면 Namespace 필드가 선택한 네임스페이스로 자동 채워집니다.</block>
  <block id="4fbbbc4aaa49d653f486738eed12357a" category="paragraph">다음 예에서는 kubeflow-anonymous 네임스페이스가 선택됩니다. 또한 Docker 이미지, CPU 및 RAM에 대한 기본값을 사용할 수 있습니다.</block>
  <block id="69bc8b3ae7667985c27ce3ef5de0e6ca" category="paragraph"><block ref="69bc8b3ae7667985c27ce3ef5de0e6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Kubeflow 구축</block>
  <block id="095efbb867f01094d56c633d3337a412" category="list-text">작업 공간 볼륨 세부 정보를 지정합니다. 새 볼륨을 생성하기로 선택한 경우 기본 StorageClass를 사용하여 해당 볼륨 또는 PVC가 프로비저닝됩니다. Trident를 사용하는 StorageClass가 섹션에서 기본 StorageClass로 지정되었기 때문입니다 <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>, 볼륨 또는 PVC는 Trident를 사용하여 프로비저닝됩니다. 이 볼륨은 Jupyter Notebook Server 컨테이너 내의 기본 작업 공간으로 자동으로 마운트됩니다. 사용자가 서버에서 별도의 데이터 볼륨에 저장되지 않은 전자 필기장은 이 작업 영역 볼륨에 자동으로 저장됩니다. 따라서 재부팅 시에도 노트북이 유지됩니다.</block>
  <block id="c44927b0124469511a724e179c80bfb5" category="paragraph"><block ref="c44927b0124469511a724e179c80bfb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="555e44b3745904843417371073338d08" category="list-text">데이터 볼륨을 추가합니다. 다음 예에서는 'PB-FG-ALL'이라는 기존 PVC를 지정하고 기본 마운트 지점을 적용합니다.</block>
  <block id="0c73069b282d8e99ecbd8feb39164d40" category="paragraph"><block ref="0c73069b282d8e99ecbd8feb39164d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b120f9006af3d27ef70eb256c99c6617" category="list-text">* 선택 사항: * 원하는 수의 GPU를 노트북 서버에 할당하도록 요청합니다. 다음 예에서는 GPU 1개가 요청됩니다.</block>
  <block id="c969e6364e4561a959d1ce20f7187723" category="paragraph"><block ref="c969e6364e4561a959d1ce20f7187723" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8da2142543d647576288d71dddabb01" category="list-text">시작 을 클릭하여 새 노트북 서버를 프로비저닝합니다.</block>
  <block id="37a742c47c216725dd178d8c3c7a3f31" category="list-text">노트북 서버가 완전히 준비될 때까지 기다립니다. 지정한 Docker 이미지를 사용하여 서버를 프로비저닝하지 않은 경우 이미지를 다운로드해야 하므로 몇 분 정도 걸릴 수 있습니다. 서버가 완전히 프로비저닝되면 Jupyter Notebook 서버 관리 페이지의 상태 열에 녹색 확인 표시가 나타납니다.</block>
  <block id="417a2eafac6842560d3900cf9d12b5bb" category="paragraph"><block ref="417a2eafac6842560d3900cf9d12b5bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0463a63e8059055e703ecd9ffa72e106" category="list-text">연결을 클릭하여 새 서버 웹 인터페이스에 연결합니다.</block>
  <block id="4fbf21602f4888216386998d62f1defd" category="list-text">6단계에서 지정한 데이터 세트 볼륨이 서버에 마운트되었는지 확인합니다. 이 볼륨은 기본적으로 기본 작업 공간 내에 마운트됩니다. 사용자의 관점에서 이것은 작업 영역 내의 다른 폴더일 뿐입니다. 인프라 전문가가 아닌 데이터 과학자인 사용자는 이 볼륨을 사용하기 위해 스토리지 전문 지식을 보유할 필요가 없습니다.</block>
  <block id="c4b6acc44505864a5dccae2571b74f6a" category="paragraph"><block ref="c4b6acc44505864a5dccae2571b74f6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7d375154397ce9358d2234ec578ff7e" category="paragraph"><block ref="a7d375154397ce9358d2234ec578ff7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="479d03862d87da58784e60e5cfcec977" category="list-text">터미널을 열고 5단계에서 새 볼륨이 요청되었다고 가정하고 df -h를 실행하여 새로운 Trident 제공 영구 볼륨이 기본 작업 공간으로 마운트되었는지 확인합니다.</block>
  <block id="68f39a4f77e618e6617c3830fb47de7c" category="paragraph">기본 작업 공간 디렉터리는 서버의 웹 인터페이스에 처음 액세스할 때 표시되는 기본 디렉터리입니다. 따라서 웹 인터페이스를 사용하여 생성한 아티팩트는 Trident가 제공하는 영구 볼륨에 저장됩니다.</block>
  <block id="d3e91c75db0cb717734224e6eb72e201" category="paragraph"><block ref="d3e91c75db0cb717734224e6eb72e201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d739fe0e421e9cb4d6315f0021cc5eb" category="paragraph"><block ref="1d739fe0e421e9cb4d6315f0021cc5eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8c20de15cf5efa2297f9d40d899450e" category="list-text">터미널을 사용하여 NVIDIA-SMI를 실행하여 올바른 개수의 GPU가 노트북 서버에 할당되었는지 확인합니다. 다음 예에서는 7단계에서 요청했던 대로 하나의 GPU가 노트북 서버에 할당되었습니다.</block>
  <block id="ed4e7225349e5c6cd33dfd15ad878438" category="paragraph"><block ref="ed4e7225349e5c6cd33dfd15ad878438" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c64f80d07d5c1623b7b2f34e40d7b46c" category="inline-link-macro">다음: 노트북 및 파이프라인 예제</block>
  <block id="c3714374d558db5573b4ecd4261e206e" category="paragraph"><block ref="c3714374d558db5573b4ecd4261e206e" category="inline-link-macro-rx"></block></block>
  <block id="4b022a47bb6a38cb1b05a5cbec618ccd" category="inline-link-macro">이전: 피어 AKS VNET 및 Azure NetApp Files VNET</block>
  <block id="fec5fee1adce318e5e2f9ce6a66ccc02" category="paragraph"><block ref="fec5fee1adce318e5e2f9ce6a66ccc02" category="inline-link-macro-rx"></block></block>
  <block id="999aa3cd55c654beafcfa7653b65d339" category="paragraph">Hrom을 사용하여 Trident를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="36cd38f49b9afa08222c0dc9ebfe35eb" category="inline-link">출처</block>
  <block id="9c5f8711af47a869d4ef82db9e55eda5" category="list-text">Helm을 설치합니다(설치 지침은 를 참조하십시오<block ref="adf15389dc6d5fe4bd9024075437080f" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="f7c078ec85c617d77dfa95c309e4df1b" category="list-text">Trident 20.01.1 설치 프로그램을 다운로드하고 압축을 풉니다.</block>
  <block id="5729bb69ffc852a2e2757d743b7cb833" category="list-text">시스템 '$path'의 디렉토리에 tridentctl을 복사합니다.</block>
  <block id="d7fc4d1537e4623fdcebe9b8ba333cbb" category="list-text">Kubernetes(K8s) 클러스터에 Trident를 설치하고 H제어(<block ref="cbc920955683fc4acb62f9ea7099333f" category="inline-link-rx"></block>):</block>
  <block id="f515d7de4d597c284ba8042f699a0eab" category="list-text">디렉터리를 'helm' 디렉토리로 변경합니다.</block>
  <block id="6ee4094e2c3617e3e298ec79f9dc2898" category="list-text">Trident Pod의 상태를 확인합니다.</block>
  <block id="30f93734da9765d3bc7d49ca89932736" category="paragraph">모든 Pod가 가동되어 실행 중이면 Trident가 설치되어 앞으로 이동할 수 있습니다.</block>
  <block id="cde865911fa15995bc83db30d852300b" category="list-text">AKS에 대한 Azure NetApp Files 백엔드 및 스토리지 클래스를 설정합니다.</block>
  <block id="476fdb61358f28988640245a33bd9199" category="list-text">Azure 서비스 원칙을 만듭니다.</block>
  <block id="5cdfb88cd634d9d0eb47237e3251d4bd" category="paragraph">서비스 보안 주체는 Trident가 Azure와 통신하여 Azure NetApp Files 리소스를 조작하는 방법입니다.</block>
  <block id="253a9ccb0f0696ed79c174b388867829" category="list-text">Trident 백엔드 json 파일(예: "anf-backend.json")을 생성합니다.</block>
  <block id="c17b83e07524acc467ac01e42fa0ebdb" category="list-text">원하는 텍스트 편집기를 사용하여 'anf-backend.json' 파일 안에 다음 필드를 입력합니다.</block>
  <block id="1197f8dc56b70115d87008dd2ecd3fca" category="list-text">다음 필드로 대체합니다.</block>
  <block id="b0b2134849d44712e969d6872e7245e5" category="list-text">'스크립트 ID'입니다. Azure 구독 ID입니다.</block>
  <block id="7b42dbe86adeab0d66f36221b33bb0f4" category="list-text">텐antID. 이전 단계에서 'az ad sp'의 출력에서 Azure 테넌트 ID입니다.</block>
  <block id="5a8bb8e509b4a424a1df50ef0bb41d89" category="list-text">'클라이언트 ID'. 이전 단계에서 'az ad sp'의 출력에서 귀하의 appID.</block>
  <block id="6334b606a5807346a083767eaab3934f" category="list-text">'clientSecret' 이전 단계에서 사용한 'az ad sp' 출력의 암호입니다.</block>
  <block id="12104fe8975b3ce95324ec3cab160ffc" category="list-text">구성 파일로 anf-backend.json을 사용하여 trident 네임스페이스에 Azure NetApp Files 백엔드를 생성하도록 Trident에 지시합니다.</block>
  <block id="d6d34c355bcd6b2efe2795a2aeedd247" category="paragraph"><block ref="d6d34c355bcd6b2efe2795a2aeedd247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="004530c3d3b3f442f56243625372db1d" category="list-text">스토리지 클래스를 생성합니다. Kubernetes 사용자는 이름으로 스토리지 클래스를 지정하는 PVC를 사용하여 볼륨을 프로비저닝합니다. K8s에게 이전 단계에서 만든 Trident 백엔드를 참조하는 스토리지 클래스 "azurenetappfiles"를 생성하도록 지시합니다.</block>
  <block id="e777b114d6f12bc1190a60eaf8498e37" category="list-text">스토리지 클래스 및 복사본을 위한 YAML('anf-storage-class.yAML') 파일을 생성합니다.</block>
  <block id="01d45e8c6af153b1a477537e02466b5c" category="list-text">스토리지 클래스가 생성되었는지 확인합니다.</block>
  <block id="445895be8456b7de5e864fc09994551a" category="paragraph"><block ref="445895be8456b7de5e864fc09994551a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d3fec4cfe088bc80c2c2930f051b60b" category="inline-link-macro">다음: 헬름으로 AKS에서 RAPIDS를 사용하여 Dask를 설정합니다.</block>
  <block id="f2d1f2f412dd744c26a147e39bfa708f" category="paragraph"><block ref="f2d1f2f412dd744c26a147e39bfa708f" category="inline-link-macro-rx"></block></block>
  <block id="2fb227f90ebf269423fe0cf1a15b8111" category="doc">영구 볼륨 클레임을 정의합니다</block>
  <block id="8f5da11015f2baf835f0e8b421c1cfe9" category="list-text">다음 YAML을 파일에 저장하여 기본 유형의 PVC를 생성합니다.</block>
  <block id="04c58cdb1d0c073dd558caf87f2b8ed1" category="list-text">Iguazio Kubernetes 클러스터에 YAML 파일을 적용하십시오.</block>
  <block id="f685fdfcc5aedb3ccc237a4020b69cd8" category="section-title">Jupyter Notebook에 NetApp Volume을 연결합니다</block>
  <block id="dc4b8e255a77b2c73f89b702dbb7acc5" category="inline-link">Iguazio 응용 프로그램 서비스 및 도구 개요</block>
  <block id="11eb1e24a14c1d15ee5e287b4338b764" category="paragraph">Iguazio는 데이터 과학자에게 AI/ML 애플리케이션의 개발 및 배포를 위한 완벽한 종단 간 스택을 제공하기 위해 여러 가지 관리 서비스를 제공합니다. 에서 이러한 구성 요소에 대해 자세히 알아볼 수 있습니다<block ref="2cf4dcc22fda31f66959754df93d6196" category="inline-link-rx"></block>.</block>
  <block id="3591be3d07a4f8a37d218b9e92bea432" category="paragraph">관리 서비스 중 하나는 Jupyter Notebook입니다. 각 개발자는 개발에 필요한 리소스와 함께 노트북 컨테이너를 직접 배포할 수 있습니다. NetApp Cloud Volume에 대한 액세스 권한을 부여하려면 볼륨을 해당 컨테이너에 할당하고 리소스 할당, 실행 중인 사용자 및 영구 볼륨 청구에 대한 환경 변수 설정을 다음 이미지에 표시할 수 있습니다.</block>
  <block id="31bbf80f0649d07d3e8340123f1a6963" category="inline-link">TR-4798</block>
  <block id="e0d870d503aeb797f7626b14c9acb4ae" category="paragraph">온-프레미스 구성의 경우 를 참조할 수 있습니다<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> 버전 관리를 위한 데이터 또는 모델의 스냅샷 복사본 생성 등 NetApp ONTAP 데이터 관리 기능을 지원하는 Trident 설정에서 Trident 백엔드 구성 파일에 다음 줄을 추가하여 스냅샷 디렉토리를 표시합니다.</block>
  <block id="12ce9751e0e6d2a7d593d46e19211984" category="inline-link">Trident 명령</block>
  <block id="71f8fa2d01d0c5a2d9af72f90f65e379" category="paragraph">JSON 형식으로 Trident 백 엔드 구성 파일을 생성한 후 다음을 실행해야 합니다<block ref="1dce3ee9e9ff2b59caf27104be259d37" category="inline-link-rx"></block> 이를 참조하려면:</block>
  <block id="2842c07cfacaf614e63dc1f2afef93b2" category="paragraph"><block ref="2842c07cfacaf614e63dc1f2afef93b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d47cd04a0ddb5c3e6a2d9b9bc5c6a120" category="inline-link-macro">다음: 응용 프로그램 배포</block>
  <block id="fafac2eb9a7c4fcf46778865a22a00d2" category="paragraph"><block ref="fafac2eb9a7c4fcf46778865a22a00d2" category="inline-link-macro-rx"></block></block>
  <block id="fb1290be14b9bc3c64a2c3c9ace6c065" category="doc">사용 사례 개요 및 문제 설명</block>
  <block id="aa04a8198c7c60df7adcd6cd49bec6f8" category="paragraph">데이터 세트 및 데이터 세트 버전은 일반적으로 비용을 줄이고 기타 운영 이점을 제공하는 NetApp StorageGRID 오브젝트 기반 스토리지와 같은 데이터 레이크에 있습니다. 데이터 과학자는 이러한 데이터 세트를 가져와 다양한 단계로 엔지니어링하여 특정 모델을 사용하여 교육 준비를 합니다. 종종 여러 버전을 만들어냅니다. 다음 단계로 데이터 과학자는 모델을 실행하기 위해 최적화된 컴퓨팅 리소스(GPU, 하이엔드 CPU 인스턴스, 온프레미스 클러스터 등)를 선택해야 합니다. 다음 그림에서는 ML 컴퓨팅 환경에서 데이터 세트의 근접 위치 부족을 보여 줍니다.</block>
  <block id="cc054601488581e80cc1d19c227126f6" category="paragraph"><block ref="cc054601488581e80cc1d19c227126f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88515fca547c502286d6f2a9081fc734" category="paragraph">하지만 다양한 컴퓨팅 환경에서 여러 개의 교육 실험을 병렬로 실행해야 합니다. 각 환경에서는 데이터 레이크에서 데이터 세트를 다운로드해야 하며, 이 프로세스는 비용과 시간이 많이 소요됩니다. 데이터 세트와 컴퓨팅 환경(특히 하이브리드 클라우드의 경우)의 근접성이 보장되지는 않습니다. 또한 동일한 데이터 세트를 사용하여 자체 실험을 수행하는 다른 팀 구성원은 동일한 극한 용도의 프로세스를 거쳐야 합니다. 분명한 느린 데이터 액세스 외에도 데이터 세트 버전 추적, 데이터 세트 공유, 협업 및 재현성의 어려움 등의 문제가 있습니다.</block>
  <block id="30b64502c0cb2f8a9bf951993e0abbac" category="section-title">고객 요구 사항</block>
  <block id="5243f720d7e440d7746f03df97ef885f" category="paragraph">리소스를 효율적으로 사용하면서 고성능 ML 실행을 구현하기 위해 고객 요구사항이 달라질 수 있습니다. 예를 들어, 고객은 다음과 같은 요구사항을 충족해야 할 수 있습니다.</block>
  <block id="1735cf11ce0034dbb80c297fb204bc21" category="list-text">많은 비용이 드는 다운로드 및 데이터 액세스 복잡성을 발생시키지 않으면서 교육 모델을 실행하는 각 컴퓨팅 인스턴스에서 데이터 세트에 빠르게 액세스할 수 있습니다</block>
  <block id="80085a846f90523080cf086e66561d52" category="list-text">데이터 세트의 위치에 관계없이 클라우드 또는 온프레미스에서 컴퓨팅 인스턴스(GPU 또는 CPU)를 사용합니다</block>
  <block id="de79912b1ab8764406a232888aab85e5" category="list-text">불필요한 지연 시간 및 데이터 지연 시간 없이 동일한 데이터 세트에서 여러 컴퓨팅 리소스와 동시에 여러 교육 실험을 실행하여 효율성 및 생산성 향상</block>
  <block id="5211203793a223f02322b88b2e698a82" category="list-text">컴퓨팅 인스턴스 비용 최소화</block>
  <block id="6a6fcee71b4e22ac6a4afdfdb5940b67" category="list-text">데이터 세트, 계열, 버전 및 기타 메타데이터 세부 정보를 기록할 수 있는 도구를 통해 재현성이 향상되었습니다</block>
  <block id="930d18875813298018f8364069441eee" category="list-text">공유 및 협업이 향상되어 권한이 있는 팀원 중 한 명이 데이터 세트에 액세스하여 실험을 실행할 수 있습니다</block>
  <block id="5f700d00ad72470694a5aa06cd515c8b" category="paragraph">NetApp ONTAP 데이터 관리 소프트웨어를 사용하여 데이터 세트 캐싱을 구축하려면 다음과 같은 작업을 수행해야 합니다.</block>
  <block id="41fac0272180c0141b5cd7ad6ad85a44" category="list-text">컴퓨팅 리소스에 가장 가까운 NFS 스토리지를 구성하고 설정합니다.</block>
  <block id="25a3a7ee3cfbb4afc291cd5b94dec000" category="list-text">캐시할 데이터 세트 및 버전을 결정합니다.</block>
  <block id="dbffd2a20c35c06fbb6ba0cd17e54ef6" category="list-text">캐시된 데이터 세트에 커밋된 총 메모리 용량과 추가 캐시 커밋에 사용할 수 있는 NFS 스토리지 용량(예: 캐시 관리)을 모니터링합니다.</block>
  <block id="61d5e7050cbe037ad5adeaf246e6be19" category="list-text">특정 시간에 사용하지 않은 데이터 세트가 캐시에서 노후화되었습니다. 기본값은 1일입니다. 다른 구성 옵션을 사용할 수 있습니다.</block>
  <block id="36691dc48fac4774974c970e3bfa1a7d" category="paragraph"><block ref="36691dc48fac4774974c970e3bfa1a7d" category="inline-link-macro-rx"></block></block>
  <block id="57a499fcdd85136edfd1ee55dedd9675" category="summary">이 솔루션은 AI/ML 애플리케이션의 라이프사이클 뒤에 있습니다. 먼저 데이터 과학자의 작업을 통해 데이터를 준비하고 모델을 교육하는 데 필요한 다양한 단계를 정의합니다. DASK에서 RAPIDS를 활용하여 Azure Kubernetes Service(AKS) 클러스터 전반에 걸쳐 분산 교육을 수행하여 기존 Python 좌식 키트 학습 접근법과 비교하여 교육 시간을 크게 줄였습니다. 전체 주기를 완료하기 위해 Azure NetApp Files과 파이프라인을 통합합니다.</block>
  <block id="0359d40b3d1a900a1841f1e8bd783cd5" category="doc">TR-4904: Azure에서 제공되는 분산 교육 - 클릭 비율 예측</block>
  <block id="e6fab630e7da86a500e1e3c51fa61a00" category="paragraph">Rick Huang, Verron Martina, Muneer Ahmad, NetApp</block>
  <block id="4c3816ce69205bc811aa89dbe9d09a1a" category="paragraph">데이터 과학자의 작업은 머신 러닝(ML) 및 인공 지능(AI) 모델의 훈련 및 튜닝에 중점을 두어야 합니다. 그러나 구글의 조사에 따르면, 데이터 과학자들은 약 80%의 시간을 들여 모델을 엔터프라이즈 애플리케이션과 연동하고 대규모로 실행하는 방법을 찾아내고 있습니다.</block>
  <block id="a1451f6988178ae140f8da836d63a157" category="paragraph">엔드 투 엔드 AI/ML 프로젝트를 관리하려면 엔터프라이즈 구성 요소를 더 잘 이해해야 합니다. DevOps가 정의, 통합 및 구축을 인수했지만, 이러한 유형의 구성요소는 AI/ML 프로젝트를 포함하는 유사한 흐름을 타겟으로 합니다. 엔터프라이즈에서 엔드 투 엔드 AI/ML 파이프라인이 어떤 영향을 받는지 알아보려면 다음 필수 구성요소 목록을 참조하십시오.</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="list-text">스토리지</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="list-text">네트워킹</block>
  <block id="ea2ef9b0d095bf991f4973633b485340" category="list-text">데이터베이스를 지원합니다</block>
  <block id="3b18b13f059019d19211f8a9f36f7e4e" category="list-text">파일 시스템</block>
  <block id="d6c823008f20bbfce5f39b30ec9fa918" category="list-text">CI/CD(Continuous Integration and Continuous Deployment) 파이프라인</block>
  <block id="24bea3d677b34d6aea9ff01417fd9d06" category="list-text">IDE(통합 개발 환경)</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="list-text">보안</block>
  <block id="bd0992d43bb2d0ca676184502e14754e" category="list-text">데이터 액세스 정책</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="list-text">하드웨어</block>
  <block id="a9353b1bd1eeedb788a74090b5f8d0bc" category="list-text">데이터 과학 도구 세트 및 라이브러리</block>
  <block id="e6a53478c3fc5682c6f851672b3e7bc9" category="paragraph">데이터 과학의 세계는 IT와 비즈니스의 여러 분야를 아우릅니다.</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">데이터 과학자는 자신이 선택한 도구와 라이브러리를 사용할 수 있는 유연성이 필요합니다.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">데이터 엔지니어는 데이터 흐름과 데이터 위치를 알아야 합니다.</block>
  <block id="c12281f5ea7b17e370414efbf3f26c30" category="list-text">DevOps 엔지니어는 새로운 AI/ML 애플리케이션을 CI/CD 파이프라인에 통합하는 툴을 필요로 합니다.</block>
  <block id="9ca78187997ba2a23a73c094256ae63f" category="list-text">클라우드 관리자와 설계자는 Azure 리소스를 설정하고 관리할 수 있어야 합니다.</block>
  <block id="060bc2911862b1ab8f6b4b77542434a2" category="paragraph">이 기술 보고서에서는 Azure NetApp Files, RAPIDS AI, DASK, Azure가 이러한 각 역할이 비즈니스에 어떤 가치를 제공하는지 설명합니다.</block>
  <block id="ed8b6e047f5d4e844fe3e870c3fda4a3" category="paragraph">Azure NetApp Files는 다양한 성능 계층을 제공합니다. 고객은 표준 계층으로 시작하여 데이터를 이동하지 않고도 고성능 계층으로 스케일아웃 및 스케일업할 수 있습니다. 이 기능을 통해 데이터 과학자는 성능 문제 없이 규모에 맞게 모델을 교육할 수 있으므로 아래 그림과 같이 클러스터 전체에서 데이터 사일로를 피할 수 있습니다.</block>
  <block id="d4dc9019b6000fd12d9dc6b091fe3e26" category="paragraph"><block ref="d4dc9019b6000fd12d9dc6b091fe3e26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b320345f652aacf7148c76dff24e2f68" category="inline-link-macro">다음: 기술 개요</block>
  <block id="a20978df09e58f39953eb81f9368c2f2" category="paragraph"><block ref="a20978df09e58f39953eb81f9368c2f2" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">AI 기반 자동화 및 에지 컴퓨팅은 비즈니스 조직이 디지털 혁신을 달성하고 운영 효율성과 안전을 극대화할 수 있도록 지원하는 선도적인 접근 방식입니다. 에지 컴퓨팅은 데이터 센터와 데이터를 전송할 필요가 없기 때문에 훨씬 더 빠르게 처리됩니다. 따라서 데이터를 데이터 센터 또는 클라우드로 전송하는 데 따른 비용이 절감됩니다.</block>
  <block id="1490b4526090ba1052ae7d989d2f44df" category="inline-link-macro">이전: 아키텍처 사이징 옵션</block>
  <block id="9d58af74dd11a7bf0a907e66af94ae03" category="paragraph"><block ref="9d58af74dd11a7bf0a907e66af94ae03" category="inline-link-macro-rx"></block></block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">AI 기반 자동화 및 에지 컴퓨팅은 비즈니스 조직이 디지털 혁신을 달성하고 운영 효율성과 안전을 극대화할 수 있도록 지원하는 선도적인 접근 방식입니다. 에지 컴퓨팅은 데이터 센터와 데이터를 전송할 필요가 없기 때문에 훨씬 더 빠르게 처리됩니다. 따라서 데이터를 데이터 센터 또는 클라우드로 전송하는 데 따른 비용이 절감됩니다. 에지에 구축된 AI 추론 모델을 사용하여 거의 실시간으로 의사 결정을 내려야 하는 경우 지연 시간이 단축되고 속도가 빨라질 수 있습니다.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">NetApp 스토리지 시스템은 로컬 SSD 스토리지와 동일하거나 더 우수한 성능을 제공하여 데이터 과학자, 데이터 엔지니어, AI/ML 개발자 및 비즈니스 또는 IT 의사 결정자에게 다음과 같은 이점을 제공합니다.</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">AI 시스템, 분석 및 기타 중요한 비즈니스 시스템 간에 데이터를 손쉽게 공유 이러한 데이터 공유는 인프라 오버헤드를 줄이고 성능을 향상하며 기업 전체에서 데이터 관리를 간소화합니다.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">컴퓨팅과 스토리지를 독립적으로 확장하므로 비용을 최소화하고 리소스 사용량을 높일 수 있습니다.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">즉각적이고 공간 효율적인 사용자 작업 공간, 통합 버전 제어 및 자동화된 구축을 위해 통합 Snapshot 복사본과 클론을 사용하여 개발 및 구축 워크플로우를 간소화했습니다.</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">재해 복구 및 비즈니스 연속성을 위한 엔터프라이즈급 데이터 보호 기능 이 문서에 제공된 NetApp 및 Lenovo 솔루션은 에지에서 엔터프라이즈급 AI 추론 배포에 이상적인 유연한 스케일아웃 아키텍처입니다.</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">J.J. Falkanger, 선임 Lenovo, HPC 및 AI 솔루션 매니저</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, NetApp 기술 마케팅 엔지니어</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, 기술 팀장 E-Series AI 솔루션, NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, NetApp QA 엔지니어</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="section-title">추가 정보를 찾을 수 있는 위치</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">이 문서에 설명된 정보에 대한 자세한 내용은 다음 문서 및/또는 웹 사이트를 참조하십시오.</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">NetApp AFF A-Series 어레이 제품 페이지 를 참조하십시오</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAP 데이터 관리 소프트웨어 - ONTAP 9 정보 라이브러리</block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: NetApp EF-Series 소개</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">NetApp E-Series SANtricity 소프트웨어 데이터시트 를 참조하십시오</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">컨테이너용 NetApp 영구 스토리지 - NetApp Trident</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlow 벤치마크</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Lenovo ThinkSystem DM5100F 유니파이드 플래시 스토리지 어레이</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="f8287e56c1a5982e49b792d1116aa372" category="paragraph"><block ref="f8287e56c1a5982e49b792d1116aa372" category="inline-link-rx"></block></block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">버전 기록</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">날짜</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">문서 버전 기록</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">버전 1.0</block>
  <block id="5e79a20254a28ffdb604f6cba5216c75" category="cell">2021년 3월</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">최초 릴리스</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">버전 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">2021년 10월</block>
  <block id="71b3f2dc39aa770e58cd3fad98b76c37" category="cell">EF 및 MLPerf Inference v1.1로 업데이트되었습니다</block>
  <block id="232abf87aa3028a990e94f6bb51fe8bd" category="summary">Kubernetes 클러스터에서 단일 노드 AI 및 ML 작업을 실행하려면 배포 점프 호스트에서 이 페이지의 작업을 수행하십시오.</block>
  <block id="46300fa439cc237919f854816fc89fc2" category="doc">단일 노드 AI 워크로드 실행</block>
  <block id="ebbcd572ece7625ba24f2c3ecda6d5b5" category="paragraph">Kubernetes 클러스터에서 단일 노드 AI 및 ML 작업을 실행하려면 배포 점프 호스트에서 다음 작업을 수행하십시오. Trident를 사용하면 페타바이트에 이를 수 있는 데이터 볼륨을 빠르고 쉽게 만들어 Kubernetes 워크로드에 액세스할 수 있습니다. Kubernetes Pod에서 데이터 볼륨에 액세스할 수 있도록 하려면 POD 정의에 PVC를 지정하기만 하면 됩니다. 이 단계는 Kubernetes 네이티브 운영이므로 NetApp의 전문성이 필요하지 않습니다.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">이 섹션에서는 Kubernetes 클러스터에서 실행하려고 하는 특정 AI 및 ML 워크로드를 이미 컨테이너화(Docker 컨테이너 형식)했다고 가정합니다.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNet 웹 사이트</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">다음 명령 예는 ImageNet 데이터 세트를 사용하는 TensorFlow 벤치마크 워크로드에 대한 Kubernetes 작업 생성을 보여줍니다. ImageNet 데이터 세트에 대한 자세한 내용은 를 참조하십시오<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>.</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">이 예시 작업은 8개의 GPU를 요청하므로 8개 이상의 GPU를 갖춘 단일 GPU 작업자 노드에서 실행할 수 있습니다. 이 예시 작업은 8개 이상의 GPU를 갖춘 작업자 노드가 없거나 현재 다른 워크로드를 사용 중인 클러스터에 제출할 수 있습니다. 이 경우 해당 작업자 노드를 사용할 수 있을 때까지 작업은 보류 중 상태로 유지됩니다.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Kubernetes 공식 문서</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">또한 스토리지 대역폭을 최대화하기 위해 필요한 교육 데이터가 들어 있는 볼륨이 이 작업에서 생성되는 POD 내에 두 번 마운트됩니다. 포드에도 다른 볼륨이 마운트됩니다. 이 두 번째 볼륨은 결과 및 메트릭을 저장하는 데 사용됩니다. 이러한 용적은 PVC 이름을 사용하여 작업 정의에서 참조됩니다. Kubernetes 작업에 대한 자세한 내용은 를 참조하십시오<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>.</block>
  <block id="225e66547943a27f429558dce4e639e2" category="paragraph">이 예시 작업이 생성하는 포드의 /dev/shm에 Memory의 midium 값을 가진 emptyDir 볼륨이 실장된다. Docker 컨테이너 런타임을 통해 자동으로 생성되는 '/dev/shm' 가상 볼륨의 기본 크기는 TensorFlow의 요구 사항에 비해 부족할 수 있습니다. 다음 예제와 같이 "emptyDir" 볼륨을 마운트하면 충분히 큰 "/dev/shm" 가상 볼륨이 제공됩니다. 'emptyDir' 볼륨에 대한 자세한 내용은 를 참조하십시오<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>.</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">이 예제 작업 정의에 지정된 단일 컨테이너에는 'ecurityContext &gt; privileged' 값이 'true'로 지정됩니다. 이 값은 컨테이너가 호스트에 대한 루트 액세스 권한을 효과적으로 가지고 있음을 의미합니다. 이 경우 실행되는 특정 워크로드에 루트 액세스가 필요하므로 이 주석이 사용됩니다. 특히, 워크로드가 수행하는 명확한 캐시 작업에서는 루트 액세스가 필요합니다. 이 "특권" 주석이 필요한지 여부는 실행 중인 특정 워크로드의 요구 사항에 따라 달라집니다.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">1단계에서 만든 작업이 올바르게 실행 중인지 확인합니다. 다음 명령 예에서는 작업 정의에 지정된 대로 작업에 대해 단일 POD가 생성되었으며 이 POD가 현재 GPU 작업자 노드 중 하나에서 실행되고 있음을 확인합니다.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">1단계에서 생성한 작업이 성공적으로 완료되었는지 확인합니다. 다음 명령 예에서는 작업이 성공적으로 완료되었음을 확인합니다.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">* 선택 사항: * 작업 아티팩트 정리. 다음 예제 명령은 1단계에서 만든 작업 오브젝트의 삭제를 보여 줍니다.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">작업 개체를 삭제하면 Kubernetes에서 연결된 포드를 자동으로 삭제합니다.</block>
  <block id="7af76512b5f0f470c6a7a6db368a9818" category="inline-link-macro">다음: 동기 분산 AI 워크로드 실행</block>
  <block id="e79dd849e38d01ac3faa7090e83320b2" category="paragraph"><block ref="e79dd849e38d01ac3faa7090e83320b2" category="inline-link-macro-rx"></block></block>
  <block id="a7fbadb37067070a61a3da62b548ba3c" category="paragraph">NVIDIA Nemo는 NVIDIA에서 대화형 AI 애플리케이션을 만들기 위해 만든 툴킷입니다. 이 툴킷에는 ASR, NLP 및 TTS에 대한 사전 교육 모듈 모음이 포함되어 있어 연구자와 데이터 과학자가 복잡한 신경망 아키텍처를 쉽게 구성하고 자체 애플리케이션을 설계하는 데 더 많은 노력을 집중할 수 있습니다.</block>
  <block id="1a56a4858eeec63d31bc890d38325b84" category="paragraph">앞의 예에서와 같이 나라에서는 제한된 질문 유형만 처리할 수 있습니다. 사전 교육 받은 NLP 모델은 이러한 유형의 질문에만 교육을 제공하기 때문입니다. Nara가 보다 광범위한 질문을 처리하도록 하려면 자체 데이터세트를 사용하여 재교육해야 합니다. 따라서 여기서는 Nemo를 사용하여 NLP 모델을 확장하여 요구 사항을 충족하는 방법을 보여 줍니다. 우선 Nara에서 수집한 로그를 Nemo 형식으로 변환한 다음 NLP 모델을 향상시키기 위해 데이터 세트를 사용하여 훈련합니다.</block>
  <block id="a559b87068921eec05086ce5485e9784" category="section-title">모델</block>
  <block id="4e19d1e300ea3cd63472939c24caf65d" category="paragraph">우리의 목표는 Nara가 사용자 선호도에 따라 항목을 정렬할 수 있도록 하는 것입니다. 예를 들어, 나라에게 최고 등급의 스시 레스토랑을 추천하거나 나라(Nara)가 가장 낮은 가격으로 청바지를 찾아보길 원할 수도 있습니다. 이를 위해 Nemo에 제공된 intent detection 및 slot filling 모델을 실습 모델로 사용한다. 이 모델을 통해 Nara는 선호하는 검색의 의도를 이해할 수 있습니다.</block>
  <block id="5cb83e5ef3cd25eb53fa55d635a7758f" category="section-title">데이터 준비</block>
  <block id="807cace7b07fcded06b9d106c4dd4d2d" category="paragraph">모델을 학습하기 위해 이 유형의 질문에 대한 데이터 세트를 수집하고 이를 Nemo 형식으로 변환합니다. 여기서는 모델을 훈련하는 데 사용하는 파일을 나열했습니다.</block>
  <block id="dc1d3747ed1059f234cbe4a104700abd" category="section-title">dict.intents.csv</block>
  <block id="e803005a5c3a99889733e9c8e8bba406" category="paragraph">이 파일에는 Nemo가 이해할 수 있는 모든 인텐트가 나열되어 있습니다. 여기서는 일차 연고 2개와 일차 연고 중 하나에 적합하지 않은 질문을 분류하는 데만 사용되는 의도로 1개를 사용합니다.</block>
  <block id="ce2440c5074ba6a1e30fa2ec906dafb4" category="section-title">dict.slots.csv</block>
  <block id="a3fc542c51797c85b30365ba9b2d12c5" category="paragraph">이 파일에는 교육 질문에 표시할 수 있는 모든 슬롯이 나열되어 있습니다.</block>
  <block id="795cab38744084526a62914e47789fbe" category="section-title">훈련.TSV</block>
  <block id="8a5ae45ea3762f79d1a520bcf61275d5" category="paragraph">이 데이터 세트는 주요 교육 데이터 세트입니다. 각 줄은 dict.intent.csv 파일의 의도 범주 목록에 따라 질문으로 시작합니다. 레이블은 0부터 열거됩니다.</block>
  <block id="db487d8daea13e36203f660d46b3cdfc" category="section-title">기차_슬롯.TSV</block>
  <block id="73ade6fc5004174d2abe822c85cdfbef" category="section-title">모델 훈련</block>
  <block id="c764142480a5daa39ac98125503352e8" category="paragraph">그런 다음 다음 다음 다음 명령을 사용하여 컨테이너를 시작합니다. 이 명령은 간단한 교육 연습이므로 컨테이너가 단일 GPU(GPU ID=1)를 사용하도록 제한합니다. 또한 로컬 작업 공간/작업 공간/Nemo/를 컨테이너/Nemo 내부의 폴더에 매핑합니다.</block>
  <block id="a712c52af847db1e143ca43fdd44bd39" category="paragraph">컨테이너 내부에서 사전 훈련된 원래 BERT 모델에서 시작하려면 다음 명령을 사용하여 교육 절차를 시작할 수 있습니다. data_dir은 교육 데이터의 경로를 설정하기 위한 인수입니다. Work_dir 체크포인트 파일을 저장할 위치를 구성할 수 있습니다.</block>
  <block id="9e654b2215e90d20951b3ddd67a15bc6" category="paragraph">새로운 교육 데이터 세트가 있고 이전 모델을 개선하려는 경우 다음 명령을 사용하여 중지한 시점부터 계속 진행할 수 있습니다. checkpoint_dir 은 경로를 이전 체크포인트 폴더로 가져갑니다.</block>
  <block id="87eea49f703666c49da2d7987ba093b2" category="section-title">모델을 추론합니다</block>
  <block id="484c4e9e4a0a20bf41551f65663fa9d2" category="paragraph">특정 수의 Epoch 후에 교육 이수 모델의 성능을 검증해야 합니다. 다음 명령을 사용하여 쿼리를 하나씩 테스트할 수 있습니다. 예를 들어, 이 명령에서 모델이 '최고의 파스타를 어디서 얻을 수 있는지'라는 질의의 의도를 제대로 파악할 수 있는지 확인해야 합니다.</block>
  <block id="de558a28e6333ac9f453a42631f44c12" category="paragraph">그런 다음, 추론의 출력입니다. 출력물에서는 숙련된 모델이 find_the_store의 의도를 적절히 예측하고 관심 있는 키워드를 반환할 수 있습니다. 이러한 키워드를 사용하여 Nara는 사용자가 원하는 것을 검색하고 보다 정확한 검색을 수행할 수 있습니다.</block>
  <block id="254a4a0ddc892d6a01d7e7ef286fbb71" category="inline-link-macro">다음: 결론</block>
  <block id="5b7f09a1d5da38512130330f4d38fd32" category="paragraph"><block ref="5b7f09a1d5da38512130330f4d38fd32" category="inline-link-macro-rx"></block></block>
  <block id="3993b517d983222c5b766976180367f0" category="inline-link-macro">Previous(이전): 추가 정보를 찾을 위치.</block>
  <block id="7d5fc90090e6ef28f1b090f458e3bb91" category="paragraph"><block ref="7d5fc90090e6ef28f1b090f458e3bb91" category="inline-link-macro-rx"></block></block>
  <block id="248f830b158797f9c038ea35ea266b89" category="cell">2021년 8월</block>
  <block id="ea9349a37bfee247df0f87cbcacca796" category="cell">최초 릴리스.</block>
  <block id="86608a0b346f307c76f8ae00c9f6bcb9" category="summary">이 보고서는 데이터 네임스페이스를 빠르게 클론 복제하는 방법을 보여 줍니다. 추적 및 버전 관리를 위해 거의 즉각적인 데이터 생성 및 모델 기준선을 통합하는 AI 교육 워크플로우를 정의하고 구현하는 방법을 보여줍니다. 또한, 사이트 및 지역 전반에서 데이터를 원활하게 복제하고 대규모 데이터 세트에 액세스할 수 있는 Jupyter Notebook 작업 공간을 신속하게 프로비저닝하는 방법도 보여 줍니다.</block>
  <block id="fffa1b56750a0334993c90d5adc9912a" category="doc">TR-4798: NetApp AI Control Plane</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp에서 직접 지원합니다</block>
  <block id="27114500e25aba7a27847b772d396575" category="paragraph">모든 규모와 업종에 상관없이 모든 기업과 조직은 실제 문제를 해결하고 혁신적인 제품과 서비스를 제공하며 경쟁이 갈수록 치열해지는 시장에서 경쟁 우위를 확보하기 위해 인공 지능(AI), 머신 러닝(ML), 딥 러닝(DL)으로 눈을 돌리고 있습니다. AI, ML 및 DL의 사용이 증가함에 따라 워크로드 확장성 및 데이터 가용성을 비롯한 많은 과제에 직면하게 됩니다. 이 문서에서는 NetApp 데이터 관리 기능을 널리 사용되는 오픈 소스 툴 및 프레임워크와 결합하여 제공하는 솔루션인 NetApp AI Control Plane을 사용하여 이러한 과제를 해결하는 방법을 보여줍니다.</block>
  <block id="98300151efa6f504dee4866e49cf2078" category="paragraph">이 보고서는 데이터 네임스페이스를 빠르게 클론 복제하는 방법을 보여 줍니다. 또한, 사이트 및 지역 전반에서 데이터를 원활하게 복제하여 결합형 통합 AI/ML/DL 데이터 파이프라인을 생성하는 방법을 보여줍니다. 또한 추적 가능성 및 버전 관리를 위한 데이터 및 모델 기준선의 거의 즉각적인 생성을 통합하는 AI, ML 및 DL 교육 워크플로우를 정의하고 구현하는 방법을 안내합니다. 이 솔루션을 사용하면 모든 모델 훈련을 다시 모델을 훈련 및/또는 검증하는 데 사용된 정확한 데이터 세트로 추적할 수 있습니다. 마지막으로, 이 문서에서는 방대한 데이터 세트에 액세스하여 Jupyter Notebook 작업 공간을 신속하게 프로비저닝하는 방법을 설명합니다.</block>
  <block id="3a8a3991c7ef251983bda0fd052b9b10" category="inline-link-macro">TR-4890</block>
  <block id="3cbee33bcafaf0315e821a3331b91eb5" category="inline-link-macro">NetApp의 완벽하게 지원되는 병렬 파일 시스템 솔루션인 BeeGFS</block>
  <block id="63de7cb3a054a3754335c60a0c8ba878" category="paragraph">참고: 동일한 데이터 세트에 대한 공유 액세스가 필요한 다수의 GPU 서버가 포함된 대규모 HPC 스타일 분산 교육이거나 병렬 파일 시스템이 필요하거나 선호한다면, 확인해 보십시오 <block ref="f82f3a4db7a848244fd5070f378c86fb" category="inline-link-macro-rx"></block>. 이 기술 보고서에서는 을 포함하는 방법을 설명합니다 <block ref="99c493838dffa23aa6d1149e33e3edf0" category="inline-link-macro-rx"></block> NetApp AI Control Plane의 일부로, 이 솔루션은 소수의 NVIDIA DGX A100 시스템에서 완전한 140개 노드 SuperPOD까지 확장하도록 설계되었습니다.</block>
  <block id="9f1cc947f3e0236f8d5bc32d8d33509a" category="inline-link">cloud.netapp.com</block>
  <block id="9d50c340b35848862ab6ecbdadc401ed" category="paragraph">NetApp AI Control Plane은 데이터 과학자 및 데이터 엔지니어를 대상으로 하므로 최소한의 NetApp 또는 NetApp ONTAP ® 전문 지식이 필요합니다. 이 솔루션에서는 단순하고 친숙한 툴과 인터페이스를 사용하여 데이터 관리 기능을 실행할 수 있습니다. 귀사 환경에 NetApp 스토리지가 이미 구축되어 있다면 지금 바로 NetApp AI Control Plane을 시험 구동할 수 있습니다. 솔루션을 시험하고 싶지만 NetApp 스토리지가 없는 경우, 를 방문하십시오<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>클라우드 기반 NetApp 스토리지 솔루션을 사용하여 몇 분 이내에 시스템을 구축하고 실행할 수 있습니다. 다음 그림은 솔루션을 시각적으로 보여 줍니다.</block>
  <block id="1f39acb56ba2a8669371819a64348c74" category="paragraph"><block ref="1f39acb56ba2a8669371819a64348c74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6dd86945b1681007efc06cd445661f24" category="inline-link-macro">다음: 개념 및 구성 요소.</block>
  <block id="742ed784bbf61aca3af793407a42b1f5" category="paragraph"><block ref="742ed784bbf61aca3af793407a42b1f5" category="inline-link-macro-rx"></block></block>
  <block id="dfcb1d1644aa3be367d0ca7761be62ad" category="summary">이 페이지에서는 Azure NetApp Files에 대해 위임된 서브넷을 생성하는 데 필요한 단계를 설명합니다.</block>
  <block id="d991c79e9311d59d4e38f3115d9c5b24" category="inline-link-macro">이전: AKS 클러스터를 설치하고 설정합니다.</block>
  <block id="5dd65debe44935eb5866a15b9a62237e" category="paragraph"><block ref="5dd65debe44935eb5866a15b9a62237e" category="inline-link-macro-rx"></block></block>
  <block id="8bffe528b31ee595be868b5a4af3d25a" category="paragraph">Azure NetApp Files에 대해 위임된 서브넷을 만들려면 다음 단계를 수행하십시오.</block>
  <block id="1aa0034de6393efa24703b8a479a5aa6" category="list-text">Azure 포털에서 가상 네트워크로 이동합니다. 새로 생성한 가상 네트워크를 찾습니다. AKS-VNET와 같은 접두사가 있어야 합니다.</block>
  <block id="f1621549bc319674bb9e859babb2a671" category="list-text">VNET의 이름을 클릭합니다.</block>
  <block id="c536871a8fac3a4390226f6e485cf662" category="paragraph"><block ref="c536871a8fac3a4390226f6e485cf662" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5025fbb3995af8640cab85f4f91126b" category="list-text">서브넷 을 클릭하고 상단 도구 모음에서 + 서브넷 을 클릭합니다.</block>
  <block id="22307856839205c5209cc8ce1f4ed0df" category="paragraph"><block ref="22307856839205c5209cc8ce1f4ed0df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e45b350630c9a3b31bf0c1a1f03dffb0" category="list-text">서브넷에는 ANF.SN과 같은 이름을 입력하고 Subnet Delegation 제목 아래에서 microsoft.Netapp/volumes` 을 선택합니다. 다른 어떤 것도 변경하지 마십시오. 확인 을 클릭합니다.</block>
  <block id="3621b1bf0075cb659f152966504dfc0d" category="paragraph"><block ref="3621b1bf0075cb659f152966504dfc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8034fc216ae23edc69bb75430f3de2f" category="paragraph">Azure NetApp Files 볼륨은 애플리케이션 클러스터에 할당되며 Kubernetes에서 영구 볼륨 청구(PVC)로 사용됩니다. 또한 이 프로세스를 통해 Jupyter 노트북, 서버리스 기능 등과 같은 다양한 서비스에 유연하게 매핑할 수 있습니다.</block>
  <block id="ac3654eb11c3b0cfc94c6c1abdc6767a" category="paragraph">서비스 사용자는 다양한 방법으로 플랫폼의 스토리지를 사용할 수 있습니다. 이 기술 보고서에서 NFS에 대해 설명함에 따라 Azure NetApp Files의 주요 이점은 다음과 같습니다.</block>
  <block id="42ba8b77b788a422a7e4ba2d8bb2d45e" category="list-text">사용자에게 스냅샷 복사본 사용 기능 제공</block>
  <block id="a51448debe1bbe5bb229b849d4057e09" category="list-text">사용자가 Azure NetApp Files 볼륨에 대량의 데이터를 저장할 수 있도록 지원</block>
  <block id="b7c10d399d058ef3538882e444459ba5" category="list-text">대규모 파일 세트에서 모델을 실행할 때 Azure NetApp Files 볼륨의 성능 이점을 사용합니다.</block>
  <block id="4b15c9979e20dd7eb0c0263e9d5ab1db" category="inline-link-macro">다음: 피어 AKS VNET 및 Azure NetApp Files VNET</block>
  <block id="a9f725be439e4752193d45f7e7f41851" category="paragraph"><block ref="a9f725be439e4752193d45f7e7f41851" category="inline-link-macro-rx"></block></block>
  <block id="e1490a61359279998443f8eab1c0483e" category="summary">이 페이지에는 분산형 또는 대규모 교육에서 Azure NetApp Files의 이점이 요약되어 있습니다.</block>
  <block id="b0de8e85db65da6381bb71646929daa6" category="doc">클릭률 예측 사용 사례 요약</block>
  <block id="d7550d336c660c27c3f1aa9ffdbc1e08" category="inline-link-macro">이전: 클라우드 리소스 요구사항</block>
  <block id="6a4fb77bb2a725598588e7db128b749b" category="paragraph"><block ref="6a4fb77bb2a725598588e7db128b749b" category="inline-link-macro-rx"></block></block>
  <block id="3f504d5ee520c44b83e5875afd3f2831" category="inline-link">테라바이트 로그를 클릭합니다</block>
  <block id="ce2803fd5e9b90b62d0792d13e715d11" category="inline-link">Criteo AI Lab을 참조하십시오</block>
  <block id="b622f3d3bde9c5202a2be0c23982e0b2" category="paragraph">이 사용 사례는 공개적으로 제공되는 를 기반으로 합니다<block ref="f00b4c49198828625540594bcd2c0e57" category="inline-link-rx"></block> 데이터 세트 시작<block ref="3ba217c046bd683ab55f300076736b4a" category="inline-link-rx"></block>. 최근 ML 플랫폼 및 애플리케이션의 발전으로 이제 대규모 학습에 많은 관심이 집중되고 있습니다. 클릭 비율(CTR)은 온라인 광고 노출 100회 당 평균 클릭 수(백분율로 표시)로 정의됩니다. 디지털 마케팅, 소매, 전자 상거래 및 서비스 공급자를 포함한 다양한 산업 및 사용 사례에서 핵심 메트릭으로 널리 채택되고 있습니다. CTR을 잠재적인 고객 트래픽에 대한 중요한 메트릭으로 사용하는 예는 다음과 같습니다.</block>
  <block id="d86cf69a8b82547a94ca3f6a307cf9a6" category="inline-link">Google 웹로그 분석</block>
  <block id="fe123d76ac9bec74ba2056b6a34fbf5d" category="inline-link">광고 순위</block>
  <block id="747d705222dc64c89cfadd75a9792b30" category="list-text">* 디지털 마케팅: * in<block ref="6c9e2e85af2f8f35c64de5000ebda91e" category="inline-link-rx"></block>, CTR은 광고주 또는 상인의 키워드, 광고 및 무료 리스팅이 얼마나 잘 수행되고 있는지 측정하는 데 사용할 수 있습니다. 높은 CTR은 사용자가 귀하의 광고 및 리스팅을 유용하고 관련성 있는 것으로 찾도록 하는 좋은 지표입니다. 또한 CTR은 의 구성 요소인 키워드의 예상 CTR에 기여합니다<block ref="428c3403a03510f9dc338448b285e764" category="inline-link-rx"></block>.</block>
  <block id="8a2e97f5a0cefdd4b76863bdd3773fb2" category="list-text">* 전자 상거래: * 활용은 물론<block ref="8785133d6074d4ab5f5345c36bc35a21" category="inline-link-rx"></block>전자 상거래 백엔드에는 최소 일부 방문자 통계가 있습니다. 이러한 통계는 한 눈에 유용하지 않을 수 있지만 일반적으로 읽기 쉽고 다른 정보보다 정확할 수 있습니다. 이러한 통계로 구성된 타사 데이터 세트는 독점 데이터이므로 전자 상거래 셀러, 구매자 및 플랫폼과 가장 관련이 있습니다. 이러한 데이터 세트는 추가 분석을 위해 시계시리즈를 구성하여 결과를 작년도와 어제와 비교하여 벤치마크 설정에 사용할 수 있습니다.</block>
  <block id="5737cd832bf93fd33459cf0a04787441" category="list-text">* 소매: * 오프라인 유통업체는 방문자 수와 고객 수를 CTR과 연관시킬 수 있습니다. 고객 수는 POS(Point of Sale) 기록에서 확인할 수 있습니다. 소매업체의 웹 사이트 또는 광고 트래픽에서 CTR을 사용하면 앞서 언급한 판매량이 발생할 수 있습니다. 로열티 프로그램은 온라인 광고나 다른 웹 사이트에서 리디렉션된 고객이 보상을 받기 위해 참여할 수 있기 때문에 또 다른 활용 사례입니다. 소매업체는 로열티 프로그램을 통해 고객을 확보하고 판매 기록에서 고객 행동을 기록하여 다양한 범주의 소비자 구매 행동을 예측할 뿐만 아니라 쿠폰을 개인화하고 이탈을 줄이는 추천 시스템을 구축할 수 있습니다.</block>
  <block id="32c14bcab423a033bf540425e236d3e6" category="list-text">* 서비스 공급자: * 통신 회사 및 인터넷 서비스 공급자는 통찰력 있는 AI, ML 및 분석 사용 사례를 위한 수많은 제3자 사용자 원격 측정 데이터를 보유하고 있습니다. 예를 들어, 통신 회사는 모바일 가입자의 웹 브라우징 최상위 도메인 기록 로그를 매일 활용하여 기존 모델을 세부 조정하여 최신 사용자 세분화, 고객 행동 예측, 온라인 경험 개선을 위한 실시간 광고 제작을 위해 광고업체와 협업할 수 있습니다. 이러한 데이터 중심 마케팅 워크플로에서 CTR은 변환을 반영하는 중요한 지표입니다.</block>
  <block id="78ae79f63f58a3ac75e77e3a075fd19e" category="inline-link">Criteo Terabyte 클릭 로그</block>
  <block id="deb698cbe7918324e2e1564708266732" category="paragraph">디지털 마케팅의 맥락에서<block ref="cc065865c19a3af4babfdf02c1c6b55d" category="inline-link-rx"></block> 이제 ML 플랫폼 및 알고리즘의 확장성을 평가하는 데 필요한 참조 데이터세트가 되었습니다. 광고주는 클릭 비율을 예측함으로써 광고에 반응할 가능성이 가장 높은 방문자를 선택하고, 검색 기록을 분석하고, 사용자의 관심사에 따라 가장 관련성이 높은 광고를 표시할 수 있습니다.</block>
  <block id="5f326be91a09bc93ca87444e834df2a6" category="paragraph">이 기술 보고서에 제공된 솔루션은 다음과 같은 이점을 제공합니다.</block>
  <block id="67ccf3c7c1e67c90000dfee83bab38ec" category="list-text">Azure NetApp Files는 분산 또는 대규모 교육에서 이점을 제공합니다</block>
  <block id="e15bc9f9b7a013d672cb689660ab9f9f" category="list-text">RAPIDS CUDA 지원 데이터 처리(cuDF, cuPy 등) 및 ML 알고리즘(cuML)</block>
  <block id="e150c8d445e71cda899957943e39b75f" category="list-text">분산 교육을 위한 Dask 병렬 컴퓨팅 프레임워크입니다</block>
  <block id="ec61531814ab09c5338813eecc764692" category="paragraph">RAPIDS AI 및 Azure NetApp Files를 기반으로 하는 엔드 투 엔드 워크플로우에서 랜덤 포리스트 모델 훈련 시간을 크게 두 배나 단축한 것으로 입증되었습니다. 이러한 개선은 매일 45GB의 구조화된 표 형식 데이터(평균)를 사용하여 실제 클릭 로그를 처리할 때 기존의 Pandas 접근 방식과 비교했을 때 매우 중요합니다. 이는 약 20억 개의 행이 포함된 DataFrame과 같습니다. 클러스터 환경 설정, 프레임워크 및 라이브러리 설치, 데이터 로드 및 처리, 기존 교육과 분산 교육 비교, 시각화 및 모니터링, 이 기술 보고서의 중요한 엔드 투 엔드 런타임 결과를 비교합니다.</block>
  <block id="3876b7e4b6a608a0b9001ae2e65c91b1" category="inline-link-macro">다음: AKS 클러스터를 설치하고 설정합니다.</block>
  <block id="2f0a1a89887d5c4f057724084bfdb718" category="paragraph"><block ref="2f0a1a89887d5c4f057724084bfdb718" category="inline-link-macro-rx"></block></block>
  <block id="0b7e964d1176d21b9ba3eceec8ed95ac" category="doc">개념 및 구성 요소</block>
  <block id="56dfbb2acffcc994819cbad5ec450617" category="paragraph">이 섹션에서는 ML 워크플로우에서 데이터 캐싱과 관련된 개념 및 구성 요소에 대해 설명합니다.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="section-title">머신 러닝</block>
  <block id="d3f18dede1775f82df24232095090253" category="paragraph">ML은 전 세계 많은 기업과 조직에 빠르게 필수 요소가 되고 있습니다. 따라서, IT 및 DevOps 팀은 ML 워크로드 및 프로비저닝 클라우드, 온프레미스, 하이브리드 컴퓨팅 리소스를 표준화하여 ML 작업 및 파이프라인에 필요한 동적이고 집약적인 워크플로우를 지원해야 하는 과제에 직면해 있습니다.</block>
  <block id="f71dfff263d05c18171dcf4b8c538ebf" category="section-title">컨테이너 기반 머신 러닝 및 Kubernetes</block>
  <block id="002f314c3c41ffb741f8c91d2274af9a" category="paragraph">컨테이너는 공유 호스트 운영 체제 커널 위에서 실행되는 격리된 사용자 공간 인스턴스입니다. 컨테이너 채택이 빠르게 증가하고 있습니다. 컨테이너는 가상 머신(VM)이 제공하는 것과 동일한 애플리케이션 샌드박스(sandbox)의 많은 이점을 제공합니다. 하지만 VM이 사용하는 하이퍼바이저 및 게스트 운영 체제 계층이 없어졌기 때문에 컨테이너는 훨씬 더 가볍습니다.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Docker 웹 사이트</block>
  <block id="ce8bb3a31abf8bfcdcdacb34d96b010a" category="paragraph">또한 컨테이너를 사용하면 애플리케이션 종속성, 실행 시간 등을 애플리케이션과 직접 효율적으로 패키징할 수 있습니다. 가장 일반적으로 사용되는 컨테이너 패키징 형식은 Docker 컨테이너입니다. Docker 컨테이너 형식으로 컨테이너화된 애플리케이션은 Docker 컨테이너를 실행할 수 있는 모든 시스템에서 실행할 수 있습니다. 모든 종속성이 컨테이너 자체에 패키지되어 있기 때문에 응용 프로그램의 종속성이 컴퓨터에 없는 경우에도 마찬가지입니다. 자세한 내용은 를 참조하십시오<block ref="5b5112034c22f544bc19c7a568afbfcb" category="inline-link-rx"></block>.</block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Kubernetes 웹 사이트</block>
  <block id="cfbe31a3e8ac3348240670510232ed8f" category="paragraph">데이터 과학자는 널리 사용되는 컨테이너 오케스트레이터인 Kubernetes를 사용하여 유연한 컨테이너 기반 작업 및 파이프라인을 시작할 수 있습니다. 또한 인프라 팀이 단일 관리형 클라우드 네이티브 환경에서 ML 워크로드를 관리하고 모니터링할 수 있습니다. 자세한 내용은 를 참조하십시오<block ref="45556eaecf73275e38fa694031a104a3" category="inline-link-rx"></block>.</block>
  <block id="e5e8ab661917b89b4161959c7dc28442" category="section-title">cnvrg.io</block>
  <block id="371ac536e4099ad82f6080b713ce9647" category="paragraph">cnvrg.io는 AI 및 데이터 과학 개발의 관리, 확장 및 속도를 연구에서 운영으로 전환하는 AI 운영 체제입니다. 데이터 과학자가 코드 우선 플랫폼을 구축하고 사내 또는 클라우드에서 유연하게 실행할 수 있습니다. 모델 관리, MLOps 및 지속적인 ML 솔루션을 통해 cnvrg.IO는 데이터 과학 팀에 최고의 기술을 제공하므로 DevOps에 더 적은 시간을 할애하고 진정한 마법인 알고리즘에 집중할 수 있습니다. cnvrg.io를 사용한 이후, 여러 산업 분야의 팀들이 생산 모델에 더 많은 모델을 투입하여 비즈니스 가치를 증대하고 있습니다.</block>
  <block id="ffb1d184fa3790eda48f1fc2d9c2f821" category="section-title">cnvrg.io 메타 스케줄러</block>
  <block id="55fdc117823776b1ebb2170b4adfadf6" category="paragraph">cnvrg IO는 IT와 엔지니어가 서로 다른 컴퓨팅 리소스를 동일한 제어 평면에 연결하고 cnvrg.io를 사용하여 모든 리소스에 걸쳐 ML 작업을 관리할 수 있는 고유한 아키텍처를 가지고 있습니다. 즉, 다음 그림과 같이 여러 온프레미스 Kubernetes 클러스터, VM 서버 및 클라우드 계정을 연결하고 모든 리소스에서 ML 워크로드를 실행할 수 있습니다.</block>
  <block id="3c7fcf7e73eda18d7277b14914857f38" category="paragraph"><block ref="3c7fcf7e73eda18d7277b14914857f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cfff0196a077e92a8fe9326f97cb7fc5" category="section-title">cnvrg.io 데이터 캐싱</block>
  <block id="ad693e5ee82f0e0486a136821d0a0779" category="paragraph">데이터 과학자는 cnvrg.io를 사용하여 데이터 캐싱 기술을 통해 핫 데이터 세트 및 콜드 데이터 세트 버전을 정의할 수 있습니다. 기본적으로 데이터 세트는 중앙 집중식 오브젝트 스토리지 데이터베이스에 저장됩니다. 그런 다음 데이터 과학자는 선택한 컴퓨팅 리소스에 특정 데이터 버전을 캐시하여 다운로드 시간을 줄이고 ML 개발 및 생산성을 향상시킬 수 있습니다. 캐싱되고 며칠 동안 사용되지 않는 데이터 세트는 선택한 NFS에서 자동으로 지워집니다. 한 번의 클릭으로 캐시 캐싱 및 지우기를 수행할 수 있으며 코딩, IT 또는 DevOps 작업이 필요하지 않습니다.</block>
  <block id="42cf1b27f88752e1e98918981aa76e41" category="section-title">cnvrg.io는 플로우 및 ML 파이프라인</block>
  <block id="1bc2ab6c98ec5b23a8a384861da1c6ca" category="paragraph">cnvrg.IO Flows는 생산 ML 파이프라인을 구축하기 위한 도구입니다. 플로우의 각 구성 요소는 기본 Docker 이미지를 사용하여 선택한 컴퓨팅에서 실행되는 스크립트/코드입니다. 이 설계를 통해 데이터 과학자와 엔지니어가 사내 및 클라우드에서 모두 실행할 수 있는 단일 파이프라인을 구축할 수 있습니다. cnvrg.io는 데이터, 매개 변수 및 아티팩트가 서로 다른 구성 요소 간에 이동하고 있는지 확인합니다. 또한 각 흐름을 모니터링하고 추적하여 100% 재현성 있는 데이터 과학을 제공합니다.</block>
  <block id="87cd11047488d3aa87eb2829eeb02305" category="section-title">cnvrg.io 코어</block>
  <block id="526c8ebff3057ce85f47160f32e15556" category="paragraph">cnvrg.io core는 데이터 과학자가 DevOps에 초점을 맞추는 데 도움을 주기 위해 데이터 과학 커뮤니티를 위한 무료 플랫폼입니다. Core의 유연한 인프라를 통해 데이터 과학자는 온프레미스 또는 클라우드 등 어떤 언어, AI 프레임워크 또는 컴퓨팅 환경이라도 사용할 수 있으므로 가장 잘하는 일을 하고 알고리즘을 구축할 수 있습니다. cnvrg.io 코어는 모든 Kubernetes 클러스터에서 단일 명령으로 간편하게 설치할 수 있습니다.</block>
  <block id="f92894a2a2633c488de71d74ace474d7" category="paragraph">ONTAP AI는 NetApp AFF 스토리지 시스템 및 NVIDIA DGX 시스템과 Tesla V100 GPU를 사용하는 ML 및 딥 러닝(DL) 워크로드를 위한 데이터 센터 참조 아키텍처입니다. ONTAP AI는 100Gb 이더넷을 통한 산업 표준 NFS 파일 프로토콜을 기반으로 하며, 표준 데이터 센터 기술을 사용하여 구현 및 관리 오버헤드를 줄이는 고성능 ML/DL 인프라를 고객에게 제공합니다. 표준화된 네트워크 및 프로토콜을 사용하여 ONTAP AI를 하이브리드 클라우드 환경에 통합하는 동시에 운영 일관성과 단순성을 유지할 수 있습니다. 사전 검증된 인프라 솔루션인 ONTAP AI를 사용하면 구축 시간과 위험을 줄이고 관리 오버헤드를 크게 줄여 고객이 투자 회수 시간을 단축할 수 있습니다.</block>
  <block id="47bbe104ad41e6af2ee0dba5dc76d74d" category="inline-link">DeepOps 웹 사이트</block>
  <block id="b1c5aef0d1e7ec0339ca5caa48c1b3e3" category="paragraph">DeepOps는 NVIDIA의 오픈 소스 프로젝트로, Ansible을 사용하여 GPU 서버 클러스터를 모범 사례에 따라 자동으로 구축합니다. DeepOps는 모듈식이며 다양한 배포 작업에 사용할 수 있습니다. 이 문서와 이 문서에서 설명하는 검증 연습에서는 GPU 서버 작업자 노드로 구성된 Kubernetes 클러스터를 배포하는 데 DeepOps를 사용합니다. 자세한 내용은 를 참조하십시오<block ref="640792bfd91bad987ba8fd5d776a2824" category="inline-link-rx"></block>.</block>
  <block id="6ea70a0ecace7daa9dfbbc8ff3282de1" category="inline-link">Trident 웹 사이트</block>
  <block id="c2148c4c14a795b271b67f662900da4e" category="paragraph">Trident는 NetApp에서 개발 및 유지 관리하는 오픈 소스 스토리지 오케스트레이터로서 Kubernetes 워크로드를 위한 영구 스토리지의 생성, 관리 및 사용을 크게 단순화합니다. Trident 자체 Kubernetes 네이티브 애플리케이션 - Kubernetes 클러스터 내에서 직접 실행됩니다. Trident를 사용하면 Kubernetes 사용자(개발자, 데이터 과학자, Kubernetes 관리자 등)가 이미 익숙한 표준 Kubernetes 형식으로 영구 스토리지 볼륨을 생성, 관리 및 상호 작용할 수 있습니다. 이와 동시에 NetApp 기술에서 제공하는 NetApp 고급 데이터 관리 기능과 Data Fabric을 활용할 수 있습니다. Trident는 영구 스토리지의 복잡성을 추상화하여 사용이 간편합니다. 자세한 내용은 를 참조하십시오<block ref="c98bfcab9052a99136f8752a5ac8ed0b" category="inline-link-rx"></block>.</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID를 참조하십시오</block>
  <block id="ecfefbd82f34239e668be7aac3762226" category="paragraph">NetApp StorageGRID는 사용자가 S3 프로토콜을 통해 액세스할 수 있는 간단하고 클라우드식 스토리지를 제공하여 이러한 요구를 충족하도록 설계된 소프트웨어 정의 오브젝트 스토리지 플랫폼입니다. StorageGRID는 인터넷에 연결된 사이트에서 거리에 관계없이 여러 노드를 지원하도록 설계된 스케일아웃 시스템입니다. StorageGRID의 지능형 정책 엔진을 사용하여 지리적 복원력을 위해 사이트 전체에서 오브젝트를 삭제 코딩하거나 원격 사이트 간에 오브젝트 복제를 선택하여 WAN 액세스 지연 시간을 최소화할 수 있습니다. StorageGRID은 이 솔루션에서 탁월한 프라이빗 클라우드 1차 오브젝트 스토리지 데이터 레이크를 제공합니다.</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="section-title">NetApp Cloud Volumes ONTAP를 참조하십시오</block>
  <block id="c060a6548f860aa739b76c0178ac7c5c" category="paragraph">NetApp Cloud Volumes ONTAP 데이터 관리 소프트웨어는 AWS, Google Cloud Platform 및 Microsoft Azure를 비롯한 퍼블릭 클라우드 공급자의 유연성을 통해 사용자 데이터에 제어, 보호 및 효율성을 제공합니다. Cloud Volumes ONTAP은 NetApp ONTAP 스토리지 소프트웨어를 기반으로 하는 클라우드 네이티브 데이터 관리 소프트웨어로, 클라우드 데이터 요구사항을 해결하는 뛰어난 범용 스토리지 플랫폼을 제공합니다. 클라우드와 사내에서 동일한 스토리지 소프트웨어를 사용하는 사용자는 새로운 데이터 관리 방법을 통해 IT 직원을 교육하지 않고도 Data Fabric의 가치를 실현할 수 있습니다.</block>
  <block id="e16f1943a363dfa46a958bd450c2ecf8" category="paragraph">하이브리드 클라우드 구현 모델에 관심 있는 고객을 위해 Cloud Volumes ONTAP은 대부분의 퍼블릭 클라우드에서 동일한 기능과 동급 최고의 성능을 제공하여 어떠한 환경에도 일관되고 원활한 사용자 경험을 제공할 수 있습니다.</block>
  <block id="2d52bcd2e896c32a66c9fe10fed38e0f" category="inline-link-macro">다음: 하드웨어 및 소프트웨어 요구 사항</block>
  <block id="82ac5cdab15b3954389238dddbc12168" category="paragraph"><block ref="82ac5cdab15b3954389238dddbc12168" category="inline-link-macro-rx"></block></block>
  <block id="0dff6955889d5634f0212efb574ef815" category="doc">클릭률 예측 데이터 처리 및 모델 교육을 통해</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="summary">Trident 작업의 예</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">이 섹션에는 Trident를 사용하여 수행할 수 있는 다양한 작업의 예가 포함되어 있습니다.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">기존 볼륨을 가져옵니다</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Kubernetes 클러스터 내의 컨테이너에 마운트할 NetApp 스토리지 시스템/플랫폼에 기존 볼륨이 있지만, 클러스터의 PVC와 연결되지 않은 경우 이러한 볼륨을 가져와야 합니다. Trident 볼륨 가져오기 기능을 사용하여 이러한 볼륨을 가져올 수 있습니다.</block>
  <block id="4330c34147b36030c50afe1d04ec2213" category="paragraph">다음 예제 명령은 섹션의 예에서 생성된 각 Trident 백엔드에 대해 동일한 볼륨("PB_FG_ALL"이라는 이름)을 두 번 가져오는 것을 보여 줍니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 1단계. 같은 볼륨을 이러한 방식으로 두 번 가져오면 섹션에 설명된 대로 여러 LIF에서 볼륨(기존 FlexGroup 볼륨)을 여러 번 마운트할 수 있습니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 1단계. PVC에 대한 자세한 내용은 를 참조하십시오<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>. 볼륨 가져오기 기능에 대한 자세한 내용은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">예제 PVC 규격 파일에는 'ReadOnlyMany'의 'accessModes' 값이 지정되어 있습니다. 'accessMode' 필드에 대한 자세한 내용은 를 참조하십시오<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="6631bf64346739a9880a9789a941a8d6" category="inline-link-macro">ONTAP AI 구축을 위한 Kubernetes StorageClasses의 예</block>
  <block id="e6d82e60d43fe02e01930addfe670e8f" category="admonition">다음 가져오기 명령에 지정된 백엔드 이름은 섹션의 예제에서 생성한 백엔드에 해당합니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 1단계. 다음 예제 PVC 정의 파일에 지정된 StorageClass 이름은 섹션의 예제에서 만든 StorageClasses에 해당합니다 <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, 1단계.</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">새 볼륨을 프로비저닝합니다</block>
  <block id="e149d2e1fdb31ad28f79dd3d2c7ee8ff" category="paragraph">Trident를 사용하여 NetApp 스토리지 시스템 또는 플랫폼에서 새 볼륨을 프로비저닝할 수 있습니다. 다음 명령 예에서는 새 FlexVol 볼륨의 프로비저닝을 보여 줍니다. 이 예제에서는 섹션의 예제에서 만든 StorageClass 를 사용하여 볼륨을 프로비저닝합니다 <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, 2단계.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">다음 PVC 정의 파일에는 ReadWriteMany 의 accessModes 값이 지정되어 있습니다. 'accessMode' 필드에 대한 자세한 내용은 를 참조하십시오<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="c515da31cebf8cf63b394c59f3f5f2c0" category="inline-link-macro">다음: ONTAP AI 배포에 대한 고성능 작업 예 개요</block>
  <block id="5c11e6d83807487f2c41bd48dc524734" category="paragraph"><block ref="5c11e6d83807487f2c41bd48dc524734" category="inline-link-macro-rx"></block></block>
  <block id="60f89129c6220bfb3de5a84b4f6471ca" category="summary">이 페이지에서는 Pandas 및 Dask DataFrames를 사용하여 Criteo Terabyte 데이터 세트에서 Click Logs 데이터를 로드하는 방법을 설명합니다. 이 사용 사례는 광고 교환을 위한 디지털 광고에서 광고 클릭 여부를 예측하여 사용자의 프로필을 작성하는 데 사용됩니다. 또한 교환에서 자동화된 파이프라인에서 정확한 모델을 사용하지 않는 경우도 해당됩니다.</block>
  <block id="efdbc2f24f0a87c559175250c645b26b" category="doc">Pandas에서 Logs day 15를 로드하여 좌골키트을 훈련합니다. 무작위 포리스트 모델을 학습하십시오</block>
  <block id="2979440f06f7cfcab78b9a92ca964f28" category="inline-link-macro">이전: 데이터 처리 및 모델 훈련을 위한 라이브러리.</block>
  <block id="f2982e3861753bd206faa379a769d904" category="paragraph"><block ref="f2982e3861753bd206faa379a769d904" category="inline-link-macro-rx"></block></block>
  <block id="f82859e215621220b9aae984f796ef24" category="paragraph">이 섹션에서는 Pandas 및 Dask DataFrames를 사용하여 Criteo Terabyte 데이터 세트에서 Click Logs 데이터를 로드하는 방법을 설명합니다. 이 사용 사례는 광고 교환을 위한 디지털 광고에서 광고 클릭 여부를 예측하여 사용자의 프로필을 작성하는 데 사용됩니다. 또한 교환에서 자동화된 파이프라인에서 정확한 모델을 사용하지 않는 경우도 해당됩니다.</block>
  <block id="f08833dbbe310e84a1ba564838776db2" category="paragraph">Click Logs 데이터 세트에서 15일차 데이터를 로드하여 총 45GB를 기록했습니다. Jupyter Notebook CTR-PandasRF-Collated에서 다음 셀을 실행하면 처음 5000만 개의 행이 포함된 Pandas DataFrame을 생성하고 좌골키트학습 무작위 포리스트 모델을 생성합니다.</block>
  <block id="f9964b2f8f54a1422ac46bab70fd1216" category="inline-link">공식 좌골 키트 - 학습 문서</block>
  <block id="5646953e1414498e1ddf2eb3ab488e27" category="paragraph">훈련된 무작위 포리스트 모델을 사용하여 예측을 수행하려면 이 전자 필기장에서 다음 단락을 실행하십시오. 중복을 피하기 위해 15일째부터 마지막 100만 행을 테스트 세트로 테스트했습니다. 또한 이 셀은 예측의 정확도를 계산하고, 사용자가 광고를 클릭하는지 여부를 모델이 정확하게 예측한 발생 비율로 정의됩니다. 이 노트북에서 잘 모르는 구성 요소를 검토하려면 을 참조하십시오<block ref="27e4d9ca2442a6439517a3ec2c7a4e73" category="inline-link-rx"></block>.</block>
  <block id="4e5653c75e720212b79703e8083de2a8" category="inline-link-macro">다음: Dask에서 Day 15를 로드하여 Dask cuML 무작위 포리스트 모델을 교육합니다.</block>
  <block id="8c9976282cff1b15934d937349911c30" category="paragraph"><block ref="8c9976282cff1b15934d937349911c30" category="inline-link-macro-rx"></block></block>
  <block id="1e48409a293254dced52407be3dbb722" category="doc">Jarvis, Cloud Sync 및 Nemo를 사용하여 가상 도우미를 빌드합니다</block>
  <block id="68dc442228015e015ca6272edb5994e4" category="inline-link-macro">다음: Jarvis, Cloud Sync 및 Nemo 개요를 사용하여 가상 도우미를 만듭니다</block>
  <block id="f308b9afc8e29196ebb4fe535e29fc51" category="paragraph"><block ref="f308b9afc8e29196ebb4fe535e29fc51" category="inline-link-macro-rx"></block></block>
  <block id="ccc33823c0dc5e9ee0838a5eaa86f076" category="doc">섹션 4.9의 테스트 세부 정보</block>
  <block id="c83553858a60514501e9751c0747dea0" category="inline-link-macro">기본 자원 할당 공정성</block>
  <block id="ed8e4613850a4014b0e6ef830982caf2" category="paragraph">이 섹션에서는 섹션에 대한 테스트 세부 정보를 다룹니다 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>.</block>
  <block id="f354c9a7a0a52e7a5a3514252ea5f8b7" category="paragraph">다음 순서로 작업을 제출합니다.</block>
  <block id="17b3673d5c28fb72e7cc48549f489dd4" category="cell">6/8</block>
  <block id="ffe090618e54b7916fa47cf8881019b1" category="cell">팀-b/c 워크로드가 일시 중지되고 "보류 중"으로 이동합니다.</block>
  <block id="bccfe4ac65004fb31c146d17003d00e8" category="cell">다른 팀(b/c)의 워크로드는 일시 중지되고 "보류 중"으로 이동합니다.</block>
  <block id="3b099141b6a7e4e8804c3fda5ed4f440" category="paragraph">섹션을 참조하십시오 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block> 진행 중인 테스트 시나리오에 대한 논의.</block>
  <block id="5d52789e4f8028aca21d5650bed8273b" category="inline-link-macro">다음: 섹션 4.10의 테스트 세부 정보</block>
  <block id="61a1556247485f1d0fbb34dbe36d1503" category="paragraph"><block ref="61a1556247485f1d0fbb34dbe36d1503" category="inline-link-macro-rx"></block></block>
  <block id="7fd01fa95033c040ddfe882c5258bda9" category="paragraph">=:hardwaturs::nofooter::icons:linkattrs::imagesdir:./../media/</block>
  <block id="01360221b637a04fa184dc6b9355fa46" category="summary">우리는 이 솔루션 작성의 일부로 간단한 성능 비교를 수행했습니다. Kubernetes를 사용하여 몇 가지 표준 NetApp 벤치마킹 작업을 실행했고, 단순한 Docker 실행 명령을 사용하여 수행한 실행과 벤치마크 결과를 비교했습니다.</block>
  <block id="0e2f0f77407bfd956f621e13b8c1be34" category="doc">성능 테스트</block>
  <block id="467941822b3a557a8db7197e12285f14" category="paragraph">우리는 이 솔루션 작성의 일부로 간단한 성능 비교를 수행했습니다. Kubernetes를 사용하여 몇 가지 표준 NetApp AI 벤치마킹 작업을 실행했으며, 단순한 Docker 실행 명령을 사용하여 수행한 실행과 벤치마크 결과를 비교했습니다. 뚜렷한 성능 차이는 없었습니다. 따라서, 컨테이너화된 AI 교육 작업을 오케스트레이션하기 위해 Kubernetes를 사용할 경우 성능에 부정적인 영향을 미치지 않는다는 결론을 내렸습니다. 성능 비교 결과는 다음 표를 참조하십시오.</block>
  <block id="74575b23d5305310e904f87eb02ff980" category="cell">벤치마크</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">데이터 세트</block>
  <block id="c269688995d2959579fca276425898b8" category="cell">Docker 실행(이미지/초)</block>
  <block id="b3acbf223e2bb7a3a796e3b698a7748d" category="cell">Kubernetes(이미지/초)</block>
  <block id="6de4dbc350a60fb9d5ea80ac7854681d" category="cell">단일 노드 TensorFlow</block>
  <block id="2ec7cdace40d8a092e842288dfe854f7" category="cell">합성 데이터</block>
  <block id="a5ee9f5535788c17b947b7f2d8354351" category="cell">6,667.2475</block>
  <block id="b573d76a35b8d44de29524f11e873c60" category="cell">6,661.93125</block>
  <block id="b318879f822314efe94c2f096d06465c" category="cell">ImageNet</block>
  <block id="f9622443c76d58838af97acd4f0c12ed" category="cell">6,570.2025</block>
  <block id="f93ed9c22230ae6e2ed85323e8d3dff7" category="cell">6,530.59125</block>
  <block id="83817408eae44458daefc1a9516ad170" category="cell">동기식 분산 2노드 TensorFlow</block>
  <block id="d4b63997154f30598f823403bb4df7ba" category="cell">13,213.70625</block>
  <block id="a328a929a422e4b69be5bbe94694282e" category="cell">13,218.288125</block>
  <block id="209f721713f475a9a0f4ba2743b40853" category="cell">12,941.69125</block>
  <block id="1f07dab13107a813c6d35bb76648ec48" category="cell">12,881.33875</block>
  <block id="68cba59815f152ec72363e2495bab8d2" category="paragraph"><block ref="68cba59815f152ec72363e2495bab8d2" category="inline-link-macro-rx"></block></block>
  <block id="0de039e647bc53dcce6e7bceb8605cbf" category="paragraph">모든 규모와 업종에 상관없이 모든 기업과 조직은 실제 문제를 해결하고 혁신적인 제품과 서비스를 제공하며 경쟁이 갈수록 치열해지는 시장에서 경쟁 우위를 확보하기 위해 인공 지능(AI), 머신 러닝(ML), 딥 러닝(DL)으로 눈을 돌리고 있습니다. AI, ML 및 DL의 사용이 증가함에 따라 워크로드 확장성 및 데이터 가용성을 비롯한 많은 과제에 직면하게 됩니다. 이러한 문제는 NetApp AI Control Plane 솔루션을 사용하여 해결할 수 있습니다.</block>
  <block id="cae02473f4798da0fdd40f4f598b1d96" category="paragraph">이 솔루션을 사용하면 데이터 네임스페이스를 빠르게 클론 복제할 수 있습니다. 또한 추적 가능성 및 버전 관리를 위한 데이터 및 모델 기준선의 거의 즉각적인 생성을 통합하는 AI, ML 및 DL 교육 워크플로우를 정의하고 구현할 수 있습니다. 이 솔루션을 사용하면 모든 단일 모델 교육을 모델이 훈련 및/또는 검증을 거친 정확한 데이터 세트로 추적할 수 있습니다. 끝으로, 이 솔루션을 사용하면 방대한 데이터 세트에 액세스할 수 있는 Jupyter Notebook 작업 공간을 신속하게 프로비저닝할 수 있습니다.</block>
  <block id="696dba9a093d4ac7b67234745dd57835" category="paragraph">이 솔루션은 데이터 과학자 및 데이터 엔지니어들을 대상으로 하기 때문에 최소한의 NetApp 또는 NetApp ONTAP 전문 지식이 필요합니다. 이 솔루션에서는 단순하고 친숙한 툴과 인터페이스를 사용하여 데이터 관리 기능을 실행할 수 있습니다. 또한 이 솔루션은 완전한 오픈 소스 및 무료 구성 요소를 활용합니다. 따라서 환경에 NetApp 스토리지가 이미 있는 경우 지금 이 솔루션을 구현할 수 있습니다. 이 솔루션을 시험하고 싶지만 NetApp 스토리지가 없는 경우 를 방문하십시오<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>또한 클라우드 기반 NetApp 스토리지 솔루션을 사용하여 시스템을 신속하게 가동할 수 있습니다.</block>
  <block id="0a37acabf89826767b5a5fcb8dacffa3" category="summary">이 페이지에서는 Kubernetes 클러스터에 Kubeflow를 구축하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">이 섹션에서는 Kubernetes 클러스터에 Kubeflow를 구축하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="f48269a81318d4bd2dd9e57a8239fe56" category="list-text">Kubernetes 작업 클러스터가 이미 있으며, Kubeflow에서 지원하는 Kubernetes 버전을 실행하고 있습니다. 지원되는 버전 목록은 를 참조하십시오<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>.</block>
  <block id="3429b7e0331de8d2f8d377b034ca6855" category="inline-link-macro">Trident 구축 및 구성</block>
  <block id="9fc644d78f21555decceeddf5b691fa4" category="list-text">에 설명된 대로 Kubernetes 클러스터에 NetApp Trident를 이미 설치 및 구성했습니다 <block ref="ec7700e2b8d95edf2f2700b590eab273" category="inline-link-macro-rx"></block>.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">기본 Kubernetes StorageClass를 설정합니다</block>
  <block id="e1be30d98edccc10974d5d339832197c" category="paragraph">Kubeflow를 구현하기 전에 Kubernetes 클러스터 내에서 기본 StorageClass를 지정해야 합니다. Kubeflow 배포 프로세스에서는 기본 StorageClass를 사용하여 새 영구 볼륨의 프로비저닝을 시도합니다. 기본 StorageClass로 지정된 StorageClass가 없으면 배포가 실패합니다. 클러스터 내에서 기본 StorageClass를 지정하려면 배포 점프 호스트에서 다음 작업을 수행합니다. 클러스터 내에서 기본 StorageClass를 이미 지정한 경우에는 이 단계를 건너뛸 수 있습니다.</block>
  <block id="e3e4fbe325df2b20670ca04ad0c2a517" category="list-text">기존 StorageClasses 중 하나를 기본 StorageClass로 지정합니다. 다음 명령을 실행하면 기본 StorageClass로 ONTAP-ai-FlexVols-Retain이라는 StorageClass가 지정됩니다.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">ONTAP-NAS-Flexgroup Trident 백엔드 유형은 PVC 크기가 매우 큽니다. 기본적으로 Kubeflow는 크기가 몇 GB인 PVC를 프로비저닝하려고 시도합니다. 따라서 Kubeflow 구축을 위해 "ONTAP-NAS-flexgroup" 백엔드 유형을 기본 StorageClass로 사용하는 StorageClass를 지정할 수 없습니다.</block>
  <block id="f12aad36b1ab9194dd8bc67542366bff" category="section-title">NVIDIA DeepOps를 사용하여 Kubeflow를 배포합니다</block>
  <block id="3e1922d78dd7bdb1e8d7e7bd8f5aa92c" category="paragraph">NVIDIA DeepOps에서 제공하는 Kubeflow 구현 툴을 사용할 것을 권장합니다. DeepOps 구축 툴을 사용하여 Kubernetes 클러스터에 Kubeflow를 배포하려면 배포 점프 호스트에서 다음 작업을 수행합니다.</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">설치 지침</block>
  <block id="3ede8bc1f55c95b9a16b2429e0b9bbcc" category="admonition">또는 에 따라 Kubeflow를 수동으로 배포할 수도 있습니다<block ref="c75d7e23bc80ca81cea11fe427173cb3" category="inline-link-rx"></block> 공식 Kubeflow 문서에서 제공됩니다</block>
  <block id="a73d6d865f72179145299c720c53d39c" category="inline-link">Kubeflow 구축 지침</block>
  <block id="04e3c704baa1b4c23cd48a18c10fcf39" category="list-text">에 따라 클러스터에 Kubeflow를 구현합니다<block ref="5e7f04c1dfa70dd058d2720be031c44b" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="2efdbab31c5d41a149e5092f4b8d7e48" category="list-text">DeepOps Kubeflow 구현 도구에서 출력하는 Kubeflow 대시보드 URL을 기록합니다.</block>
  <block id="b714a06d49f16f8b7f988d95734d177f" category="list-text">Kubeflow 네임스페이스 내에 배포된 모든 Pod에 'Running'이라는 'Status'가 표시되는지 확인하고 네임스페이스 내에 배포된 구성 요소가 오류 상태에 있지 않은지 확인합니다. 모든 Pod를 시작하는 데 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="d6049afd6b1943d1e98ca6347dd907c5" category="list-text">웹 브라우저에서 2단계에서 기록해 둔 URL로 이동하여 Kubeflow 중앙 대시보드에 액세스합니다.</block>
  <block id="64f559cf2e77f73aca6bd3dc9649f62c" category="paragraph">기본 사용자 이름은 admin@kubeflow.org, 기본 암호는 12341234입니다. 추가 사용자를 생성하려면 의 지침을 따르십시오<block ref="f529217f090b2c9cc3764f14abdec5f7" category="inline-link-rx"></block>.</block>
  <block id="2d84920115f9dc91fe2d35c4dc07eaf0" category="paragraph"><block ref="2d84920115f9dc91fe2d35c4dc07eaf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="defd49beb1345ee37b446e866e8b3420" category="inline-link-macro">다음: Kubeflow 작업 및 작업 예</block>
  <block id="2ecf31480279823ef2aed30a0fc061f2" category="paragraph"><block ref="2ecf31480279823ef2aed30a0fc061f2" category="inline-link-macro-rx"></block></block>
  <block id="e1196fc000d661461f32bcaab7319c6a" category="doc">소매 사용 사례에 대한 상태 및 흐름을 사용자 지정합니다</block>
  <block id="1e3ecab57c1572b4a25412b1e395562a" category="paragraph">특정 사용 사례에 맞게 Dialog Manager의 상태 및 흐름을 사용자 지정할 수 있습니다. 당사의 소매 예시에서 다음과 같은 네 가지 YAML 파일이 다양한 인도에 따라 대화를 유도합니다.</block>
  <block id="608f6d7dfd7bc98630446f0c601cc730" category="paragraph">다음 파일 이름 목록과 각 파일에 대한 설명을 따르십시오.</block>
  <block id="77d10e2958e3d21f89adae8647e8d0d2" category="list-text">main_flow.yml: 주요 대화의 흐름과 상태를 정의하고 필요에 따라 다른 3개의 YAML 파일로 흐름을 안내합니다.</block>
  <block id="96b445ea5c6b049dfc1250466b6bdf2e" category="list-text">RETail_flow.yml: 소매 또는 관심 지점 질문과 관련된 주가 포함되어 있습니다. 시스템은 가장 가까운 매장의 정보 또는 지정된 품목의 가격을 제공합니다.</block>
  <block id="17a0ea5055e6be908d7e2f6f983aa471" category="list-text">날씨 흐름.yml: 날씨 문제와 관련된 주가 포함되어 있습니다. 위치를 확인할 수 없는 경우 시스템은 추가 질문을 통해 명확히 합니다.</block>
  <block id="ade7d8cc2b23f24add45c4096dd41795" category="list-text">error_flow.yml: 위의 3가지 YAML 파일에 포함되지 않는 경우를 처리합니다. 오류 메시지를 표시한 후 시스템은 사용자 질문 수락으로 다시 라우팅합니다. 다음 섹션에는 이러한 YAML 파일에 대한 자세한 정의가 나와 있습니다.</block>
  <block id="ef7c28f5093b59a07761555c8914df26" category="section-title">Main_flow.yml</block>
  <block id="dfc9a806326d590aa4ccf49aa6909cda" category="section-title">retail_flow.yml</block>
  <block id="6e08d9d65c68d5f447f4fd239052c12e" category="section-title">WATEER_flow.yml</block>
  <block id="b7dc1d2ced2caa9352158983c5ffeda1" category="section-title">ERROR_flow.yml</block>
  <block id="c6496825f1a87696b60935af9416283a" category="inline-link-macro">다음: 타사 API에 Fulfillment Engine으로 연결합니다</block>
  <block id="3a9d38bca913120b9d3638cb194cd7e6" category="paragraph"><block ref="3a9d38bca913120b9d3638cb194cd7e6" category="inline-link-macro-rx"></block></block>
  <block id="bf8b135ff3c775c5b9bbba1b2f7a61ce" category="doc">이 솔루션에 사용된 하드웨어</block>
  <block id="3b31e2e4387e938056251a113831e6da" category="inline-link">NVA-1121</block>
  <block id="a4ec49885c617f2b2500789af7e6eebf" category="paragraph">이 솔루션은 ONTAP AI 참조 아키텍처 2개의 DGX-1 노드 및 1개의 AFF A800 스토리지 시스템을 사용하여 검증되었습니다. 을 참조하십시오<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> 이 검증에 사용된 인프라에 대한 자세한 내용은 를 참조하십시오.</block>
  <block id="6c4fbfa85e86ba1acd8a66b367a3b2c4" category="paragraph">다음 표에는 솔루션을 테스트하는 데 필요한 하드웨어 구성요소가 나와 있습니다.</block>
  <block id="fe59cdcdefd7c53625e1e745b9c5be09" category="cell">DGX-1 시스템</block>
  <block id="53270fbfda62583949b287e08ae3d063" category="cell">AFF A800</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="6da64488bfb7f3216610e30ced34ff23" category="cell">Nexus 3232C 스위치</block>
  <block id="4c2db3e48f4f33a355c8e493453b53c2" category="inline-link-macro">다음: 소프트웨어 요구 사항</block>
  <block id="54870296c311c566be3a76b4a4df8e8c" category="paragraph"><block ref="43a6574de87222e6a8a22c8138fc4c45" category="inline-link-macro-rx"></block>.</block>
  <block id="638c2d891d4e85bcfae409499fba817c" category="doc">할당량 초과 GPU 할당을 통한 높은 클러스터 사용률 달성</block>
  <block id="5648f06cc2dff861e557e088190ccbe2" category="paragraph">섹션을 참조하십시오 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, 및 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>복잡한 워크로드 관리, 자동 사전 예방 예약 및 초과 할당량 GPU 프로비저닝을 위한 Run:AI 조정 기능을 시연하기 위해 고급 테스트 시나리오를 고안했습니다. 이를 통해 ONTAP AI 환경에서 클러스터 리소스를 많이 사용하고 엔터프라이즈급 데이터 과학 팀 생산성을 최적화할 수 있었습니다.</block>
  <block id="fed09193953a2a2d15bfba4063981f8c" category="paragraph">이 세 섹션에서는 다음 프로젝트 및 할당량을 설정합니다.</block>
  <block id="d2d5c3e087f684e56b5b81d6212d7ccb" category="cell">할당량</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="207b738b6cd0e1cf6ac4a405dc72102f" category="paragraph">또한 다음 세 개의 단원에 다음과 같은 컨테이너를 사용합니다.</block>
  <block id="cc6f12794ea24a191cb4f699f1b95036" category="list-text">Jupyter Notebook: jupyter/base-notebook</block>
  <block id="b8d0bb7e356bfdd7e018a7c62f9343fa" category="list-text">Run:AI QuickStart:'GCR.IO/RUN-AI-DEMO/QuickStart'를 실행하십시오</block>
  <block id="c9582d103b2fe8050364d3e629c4e80e" category="paragraph">이 테스트 시나리오에 대해 다음과 같은 목표를 설정했습니다.</block>
  <block id="c2d51205301247cd0aa0eca284d3889b" category="list-text">리소스 프로비저닝의 간편성 및 리소스를 사용자로부터 추상화한 방법을 보여줍니다</block>
  <block id="dfd4af458e74e30246827532e692dca7" category="list-text">GPU의 분수와 GPU의 정수 수를 간편하게 프로비저닝하는 방법을 보여줍니다</block>
  <block id="d7bf7c7f0d7884bd8fe07da4f6a8aba3" category="list-text">클러스터에 무료 GPU가 있을 경우 팀 또는 사용자가 리소스 할당량을 처리할 수 있으므로 시스템에서 컴퓨팅 병목 현상이 해소되는 방법을 보여줍니다</block>
  <block id="f93609e9c7f7c826e6c83bb1f8416207" category="list-text">NetApp 컨테이너와 같은 컴퓨팅 집약적인 작업을 실행할 때 NetApp 솔루션을 사용하여 데이터 파이프라인의 병목 현상을 제거하는 방법을 보여줍니다</block>
  <block id="8ac218f5a62c8021756a192ac737a7f2" category="list-text">시스템을 사용하여 여러 유형의 컨테이너를 실행하는 방법을 보여 줍니다</block>
  <block id="802125395813e0bec35472d0403ab94e" category="list-text">Jupyter 노트북</block>
  <block id="91c4a4ef606f959264719f8d084aab0e" category="list-text">실행: AI 컨테이너</block>
  <block id="23edbe937c996eb973ab4c69f9648893" category="list-text">클러스터가 가득 찼을 때 높은 사용률을 표시합니다</block>
  <block id="37e875b843ef9539c02d09d3bbee6668" category="inline-link-macro">섹션 4.8의 테스트 세부 사항</block>
  <block id="815a27a2c38741e36d920cbea5587384" category="paragraph">테스트 중에 실행된 실제 명령 시퀀스에 대한 자세한 내용은 을 참조하십시오 <block ref="3a65193f11bb9f699d19b0e9a996cd93" category="inline-link-macro-rx"></block>.</block>
  <block id="9d020ce52f8e9ff0d2f2defe3942d660" category="paragraph">13개의 워크로드를 모두 제출하면 다음 그림과 같이 할당된 컨테이너 이름 및 GPU 목록을 볼 수 있습니다. NetApp은 7개의 교육 및 6개의 대화식 작업을 통해 4개의 데이터 과학 팀을 시뮬레이션하며 각 팀은 개발 또는 자체 모델을 실행하고 있습니다. 대화형 작업의 경우, 개별 개발자는 Jupyter Notebooks를 사용하여 코드를 작성하거나 디버깅합니다. 따라서 클러스터 리소스를 너무 많이 사용하지 않고 GPU 분할을 프로비저닝하는 것이 좋습니다.</block>
  <block id="5deafc9e56279ca519f1e3c351856aa8" category="paragraph"><block ref="5deafc9e56279ca519f1e3c351856aa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa04853a58b1b9ab0033c7e24b9d929" category="paragraph">이 테스트 시나리오의 결과는 다음과 같습니다.</block>
  <block id="dbaf41fcdcf0aa8cd93bfdf0e7f916f2" category="list-text">클러스터가 꽉 찼어야 합니다. 16/16개의 GPU를 사용했습니다.</block>
  <block id="25421e793bda820f3023762c547a2495" category="list-text">높은 클러스터 사용률.</block>
  <block id="fdf3de6e0502b5404d2e0b379421f759" category="list-text">부분 할당으로 인해 GPU보다 더 많은 실험</block>
  <block id="68cf93a70e0f0fe62bc0428ce8a8b348" category="list-text">팀 d는 쿼터를 모두 사용하지 않으므로 팀 b와 팀 c는 실험에 추가 GPU를 사용할 수 있어 혁신의 시간을 단축할 수 있습니다.</block>
  <block id="9083e59932e59a6f85524ab956fcf772" category="inline-link-macro">다음: 기본 자원 할당 공정성</block>
  <block id="654c44d69d64b0a5a656dd7b1375ac03" category="paragraph"><block ref="654c44d69d64b0a5a656dd7b1375ac03" category="inline-link-macro-rx"></block></block>
  <block id="28b9eb1a9ba550cf23239eb33610203e" category="doc">소프트웨어 및 하드웨어 요구 사항</block>
  <block id="dce011ea921230b4e3061bb70569c598" category="section-title">네트워크 구성</block>
  <block id="5c56d5a342310a4d1ead67adc85adcab" category="paragraph">다음은 클라우드에서 설정하기 위한 네트워크 구성 요구 사항입니다.</block>
  <block id="df97d4ea35e2febbb06b9bd1ba29b50e" category="list-text">Iguazio 클러스터와 NetApp Cloud Volumes는 동일한 가상 프라이빗 클라우드에 있어야 합니다.</block>
  <block id="a8f3c1a7fc956bcddef483bc8797e742" category="list-text">클라우드 관리자는 Iguazio 앱 노드의 포트 6443에 액세스할 수 있어야 합니다.</block>
  <block id="0d1562d43d3c0d4c52eef4a841896eba" category="list-text">이 기술 보고서에서는 Amazon Web Services를 사용했습니다. 그러나 사용자는 모든 클라우드 공급자에 솔루션을 배포할 수 있습니다.NVIDIA DGX-1을 사용하는 ONTAP AI에서의 온프레미스 테스트를 위해 이과지오에서 호스팅하는 DNS 서비스를 편리하게 사용했습니다.</block>
  <block id="820de5e74a90f4dbc17e37b78258c35b" category="paragraph">클라이언트는 동적으로 생성된 DNS 도메인에 액세스할 수 있어야 합니다. 고객은 원하는 경우 자체 DNS를 사용할 수 있습니다.</block>
  <block id="930dd6e7cbd550494f96b487d9d38ec8" category="section-title">하드웨어 요구 사항</block>
  <block id="43ad77bf4f253415b4e90ea4aa41a2d7" category="paragraph">Iguazio는 자체 클러스터에 설치할 수 있습니다. NetApp은 NVIDIA DGX-1 시스템을 통해 NetApp ONTAP AI의 솔루션을 검증했습니다. 다음 표에는 이 솔루션을 테스트하는 데 사용되는 하드웨어가 정리되어 있습니다.</block>
  <block id="7b6f2acc1b4489fd971965be635ea987" category="cell">NetApp AFF A800 시스템</block>
  <block id="55552614d2dd18f2d6c40759f2de9e22" category="cell">1개의 고가용성(HA) 2노드에 컨트롤러 2개와 NVMe SSD 48개(3.8TB 이상) 포함</block>
  <block id="413400218c4c262991ad8483b3be0a04" category="cell">Cisco Nexus 3232C 네트워크 스위치</block>
  <block id="72f23e74ab545a9064f74aca4d904bf4" category="paragraph">다음 표에는 사내 테스트에 필요한 소프트웨어 구성 요소가 나열되어 있습니다.</block>
  <block id="5acec1d6c6e07042eb0c19bc926d2633" category="cell">버전 또는 기타 정보</block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="cell">NetApp ONTAP 데이터 관리 소프트웨어</block>
  <block id="f82f50748d06cc9643330a4a8297ba43" category="cell">9.7</block>
  <block id="efdec37786e687a58664ebd4ef6bdba4" category="cell">Cisco NX-OS 스위치 펌웨어</block>
  <block id="976d6c35e21478ef03ca2cec2a74dc71" category="cell">7.0(3) I6(1)</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">NVIDIA DGX OS</block>
  <block id="751601035b4077a9c6f7280ab1d3369c" category="cell">4.4-Ubuntu 18.04 LTS</block>
  <block id="44769dc982b2126503d2d014bcf7c15a" category="cell">Docker 컨테이너 플랫폼</block>
  <block id="bb3121464976ef0c6b6b2b81fc75f3c5" category="cell">19.03.5</block>
  <block id="2a820a07d05055e147221622557f34b9" category="cell">컨테이너 버전입니다</block>
  <block id="6f3d0f773f6be20d70e6bbbafca93de9" category="cell">20.01-tF1-py2</block>
  <block id="46b6cc5d90605df4689002387db99128" category="cell">머신 러닝 프레임워크</block>
  <block id="f060e908e90b13cff9447e18fbb6bb20" category="cell">TensorFlow 1.15.0</block>
  <block id="4ec1f03a0b910370451392d8af8cd05a" category="cell">이과시오</block>
  <block id="80b1aaf85493db4117fca57135bec077" category="cell">버전 2.8 이상</block>
  <block id="20de768bd6142b858c4e99c64e19f37b" category="cell">ESX Server를 선택합니다</block>
  <block id="f884cc5c56f9c9a8d4d61568ff64db9c" category="cell">6.5</block>
  <block id="95b4a53c1023a65c982b077b13be4b96" category="paragraph">이 솔루션은 Iguazio 버전 2.5 및 NetApp Cloud Volumes ONTAP for AWS로 완전히 테스트되었습니다. Iguazio 클러스터와 NetApp 소프트웨어가 모두 AWS에서 실행되고 있습니다.</block>
  <block id="efbef76fea5d52b17e66f66b7fbdb1be" category="cell">버전 또는 유형</block>
  <block id="1f2c90c0f9931b94eab6d9d2d3a640c9" category="cell">앱 노드</block>
  <block id="8f33b30dd333b320c87f038f61e17523" category="cell">M5.4xLarge</block>
  <block id="b8f3b98512c841c7f30ce704570ac0b6" category="cell">데이터 노드</block>
  <block id="ea93f0324aaeaa177497ea41b52cb9ff" category="cell">I3.4xLarge</block>
  <block id="870032d2d605939c0c8a813ac8534e80" category="inline-link-macro">다음: 네트워크 장치 오류 예측 사용 사례 요약</block>
  <block id="6b90a2e4861b0a6faf4f640ece131282" category="paragraph"><block ref="6b90a2e4861b0a6faf4f640ece131282" category="inline-link-macro-rx"></block></block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="summary">이 섹션에서는 Kubernetes 클러스터에 공기 흐름을 구축하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow Deployment</block>
  <block id="f23c532f744716d23270b963c3eca570" category="paragraph">Kubernetes에서 Apache Airflow를 실행하는 것이 좋습니다. 이 섹션에서는 Kubernetes 클러스터에 공기 흐름을 구축하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Kubernetes 이외의 플랫폼에 공기 흐름을 배포할 수 있습니다. Kubernetes가 아닌 다른 플랫폼에 공기 흐름을 배포하는 것은 이 솔루션의 범위를 벗어납니다.</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Kubernetes 클러스터 작업이 이미 진행 중입니다.</block>
  <block id="e59b39fd5c122dde3747561247eb2888" category="list-text">"NetApp Trident 배포 및 구성" 섹션에 설명된 대로 Kubernetes 클러스터에 NetApp Trident를 이미 설치 및 구성했습니다.</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">제어 장치를 설치합니다</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Kubernetes의 유명 패키지 매니저인 Helm을 사용하여 공기 흐름을 구축합니다. 공기 흐름을 배치하기 전에 배포 점프 호스트에 Helm을 설치해야 합니다. 배포 점프 호스트에 Helm을 설치하려면 에 따르십시오<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> 공식 Helm 문서.</block>
  <block id="678c0949a1824bf54eba73ab0a2609d8" category="paragraph">공기 흐름을 구축하기 전에 Kubernetes 클러스터 내에서 기본 StorageClass를 지정해야 합니다. Airflow 배포 프로세스는 기본 StorageClass를 사용하여 새 영구 볼륨의 프로비저닝을 시도합니다. 기본 StorageClass로 지정된 StorageClass가 없으면 배포가 실패합니다. 클러스터 내에서 기본 StorageClass를 지정하려면 섹션에 설명된 지침을 따르십시오 <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>. 클러스터 내에서 기본 StorageClass를 이미 지정한 경우에는 이 단계를 건너뛸 수 있습니다.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Helm을 사용하여 공기 흐름을 전개하십시오</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Helm을 사용하여 Kubernetes 클러스터에 공기 흐름을 배포하려면 배포 점프 호스트에서 다음 작업을 수행하십시오.</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">에 따라 헬름으로 공기 흐름을 전개하십시오<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> Artifact Hub의 공식 공기 흐름 도표입니다. 다음 명령 예는 Helm을 사용한 공기 흐름의 배치를 보여줍니다. 환경과 원하는 구성에 따라 필요에 따라 'custom-values.yAML' 파일에서 값을 수정, 추가 및/또는 제거합니다.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">모든 공기 흐름 포드가 실행 중인지 확인합니다. 모든 Pod를 시작하는 데 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">1단계에서 제어 장치를 사용하여 공기 흐름을 배포할 때 콘솔에 인쇄된 지침에 따라 공기 흐름 웹 서비스 URL을 얻습니다.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Airflow 웹 서비스에 액세스할 수 있는지 확인합니다.</block>
  <block id="6a8e19652a540e359304ba812d39ea8e" category="paragraph"><block ref="6a8e19652a540e359304ba812d39ea8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99c61a2c4480337fdf852f9dbe8a8863" category="inline-link-macro">다음: Apache Airflow 워크플로우의 예</block>
  <block id="d719776b249ed9e7109b922484d474a2" category="paragraph"><block ref="d719776b249ed9e7109b922484d474a2" category="inline-link-macro-rx"></block></block>
  <block id="74b3e84bf9817092a6f26ddf10a2f3f8" category="summary">이 페이지에서는 이 솔루션에 사용된 기술에 대해 간략하게 설명합니다.</block>
  <block id="dd5a70c15c985f455edb59eebf8d3eaa" category="paragraph"><block ref="dd5a70c15c985f455edb59eebf8d3eaa" category="inline-link-macro-rx"></block></block>
  <block id="4b2eedb67d8fb9da01af759e6e722a13" category="section-title">Microsoft 및 NetApp</block>
  <block id="09e4ef7b38fea4a7bdf4341b588176d6" category="paragraph">2019년 5월부터 Microsoft는 NetApp ONTAP 기술을 기반으로 엔터프라이즈 NFS 및 SMB 파일 서비스를 위한 Azure 네이티브 자사 포털 서비스를 제공해 왔습니다. 이러한 개발을 위해 Microsoft와 NetApp의 전략적 파트너십을 활용하고 세계적인 수준의 ONTAP 데이터 서비스를 Azure로 확장합니다.</block>
  <block id="851e5baafa3bd23201e65e29f2fdf06a" category="paragraph">Azure NetApp Files 서비스는 엔터프라이즈급 고성능 용량제 파일 스토리지 서비스입니다. Azure NetApp Files은 모든 워크로드 유형을 지원하며 기본적으로 고가용성을 제공합니다. 서비스를 통해 서비스 및 성능 수준을 선택하고 스냅샷 복사본을 설정할 수 있습니다. Azure NetApp Files은 코드 변경 없이 데이터베이스, SAP, 고성능 컴퓨팅 애플리케이션 등 클라우드에서 가장 까다로운 엔터프라이즈 파일 워크로드를 마이그레이션 및 실행하기 위한 Azure 퍼스트 파티 서비스입니다.</block>
  <block id="f014a6e06480ef33e3f1ab027f7065ca" category="paragraph">이 참조 아키텍처는 IT 조직이 다음과 같은 이점을 얻을 수 있도록 해 줍니다.</block>
  <block id="5e6e9a1ee378cf26b50e61d8bd46d54d" category="list-text">다양한 성능 및 비용 요소에 부합하는 폭넓은 스토리지 계층을 제공합니다</block>
  <block id="295f4f6daaf50c87d2639d407c47f357" category="section-title">Dask 및 NVIDIA RAPIDS 개요</block>
  <block id="a9dcf931a9aad845de3c5b908d562955" category="paragraph">Dask는 여러 시스템에서 Python 라이브러리를 확장하고 대용량 데이터의 처리 속도를 높이는 오픈 소스 병렬 컴퓨팅 도구입니다. Pandas, Numpy 및 scikit-learn과 같은 단일 스레드 기존 Python 라이브러리와 유사한 API를 제공합니다. 따라서 기본 Python 사용자는 클러스터 전체에서 리소스를 사용하기 위해 기존 코드의 많은 부분을 변경하지 않아도 됩니다.</block>
  <block id="955647f3573b932f8596ba04ed80b7b6" category="paragraph">NVIDIA RAPIDS는 전체 GPU에서 엔드 투 엔드 ML 및 데이터 분석 워크플로우를 실행하도록 지원하는 오픈 소스 라이브러리 제품군입니다. DASK와 함께 사용하면 GPU 워크스테이션(스케일업)에서 다중 노드, 다중 GPU 클러스터(스케일아웃)까지 쉽게 확장할 수 있습니다.</block>
  <block id="7a9ece70a2d60d73203e927718fd8454" category="paragraph">클러스터에서 Dask를 구축할 경우 Kubernetes를 리소스 오케스트레이션에 사용할 수 있습니다. 다음 그림과 같이 프로세스 요구 사항에 따라 작업자 노드를 확장하거나 축소할 수도 있습니다. 그러면 클러스터 리소스 소비를 최적화할 수 있습니다.</block>
  <block id="b3951b803e4010ed575c9238d2803949" category="paragraph"><block ref="b3951b803e4010ed575c9238d2803949" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2e194dd3ce5b4d001a02991ef567211" category="inline-link-macro">다음: 소프트웨어 요구 사항.</block>
  <block id="23704e1baeed350311b18c3583ad89e9" category="paragraph"><block ref="23704e1baeed350311b18c3583ad89e9" category="inline-link-macro-rx"></block></block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">추상화</block>
  <block id="1d91c2c04b7f73cb59edb799d095c75c" category="paragraph">이 백서에서는 NVIDIA Jarvis 프레임워크를 사용하여 인공 지능(AI) 대화형 솔루션을 구축하는 고객을 위한 지침과 소매 및 기타 사용 사례를 위한 NetApp ONTAP AI 및 Cloud Sync를 제공합니다. 여기에는 가상 보조자를 위한 NLP(자연어 처리) 모델 개발, 검증된 테스트 사례 및 결과에 사용되는 고급 워크플로에 대한 정보가 포함되어 있습니다.</block>
  <block id="52c7321ea4e3d5b264fdc8639a65e280" category="doc">Grafana 대시보드 배포</block>
  <block id="c843fc0ceca9c58b409cab519799c125" category="paragraph">모든 것이 배포되면 새 데이터에 대한 추론을 실행합니다. 이 모델은 네트워크 장치 장비의 고장을 예측합니다. 예측 결과는 Iguazio 시간 계열 테이블에 저장됩니다. Iguazio의 보안 및 데이터 액세스 정책과 통합된 플랫폼을 통해 Grafana로 결과를 시각화할 수 있습니다.</block>
  <block id="ae93e86067cc1d0e7bb1ec8fdca6fbc3" category="paragraph">제공된 JSON 파일을 클러스터의 Grafana 인터페이스로 가져와 대시보드를 구축할 수 있습니다.</block>
  <block id="213977705fe35a4cb0cfc9365088fc87" category="list-text">Grafana 서비스가 실행 중인지 확인하려면 서비스 아래를 살펴보십시오.</block>
  <block id="b426c25dbb35de6b9c6bff0b10b8bef9" category="paragraph"><block ref="b426c25dbb35de6b9c6bff0b10b8bef9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b6e0cc0a098260878a0e8fa4eb7766" category="list-text">이 인스턴스가 없으면 서비스 섹션에서 인스턴스를 배포합니다.</block>
  <block id="cd40a7a2e0a86f4a0283af5999a050db" category="list-text">새 서비스를 클릭합니다.</block>
  <block id="59c4bcb990174489660974167376a50a" category="list-text">목록에서 Grafana를 선택합니다.</block>
  <block id="7e280ecf88737f34a1972ac94f9ae2a1" category="list-text">기본값을 그대로 사용합니다.</block>
  <block id="9e47b36567e5001dea59ffee81456737" category="list-text">다음 단계를 클릭합니다.</block>
  <block id="4fa350b43dd079673b6fca4852841147" category="list-text">사용자 ID를 입력합니다.</block>
  <block id="af81385be6cef15b54f8c8c126c0eab0" category="list-text">서비스 저장 을 클릭합니다.</block>
  <block id="568c8b6f668936384414e470f9ddd939" category="list-text">맨 위에 있는 변경 내용 적용을 클릭합니다.</block>
  <block id="b5be50b376063d6c3ffaa3be10d4a9d3" category="list-text">대시보드를 배포하려면 Jupyter 인터페이스를 통해 NetopsPredictions-Dashboard.json 파일을 다운로드합니다.</block>
  <block id="587b311a501585c3a1d9260d4f147990" category="paragraph"><block ref="587b311a501585c3a1d9260d4f147990" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ad16c6527a3abd13b6864b8b078586b" category="list-text">서비스 섹션에서 Grafana를 열고 대시보드를 가져옵니다.</block>
  <block id="0b78dd574d02d72071845d040fdde57c" category="paragraph"><block ref="0b78dd574d02d72071845d040fdde57c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3ce0bca8ff75db7ff2bbc3e76532b2" category="list-text">Upload(*.json) File을 클릭하고 앞서 다운로드한 파일('NetopsPredictions - Dashboard.json')을 선택한다. 업로드가 완료되면 대시보드가 표시됩니다.</block>
  <block id="7cd4d06091771aa3f16d2759a067e18c" category="paragraph"><block ref="7cd4d06091771aa3f16d2759a067e18c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0258dc4515b0e18ecd4b55651e27671" category="section-title">정리 기능을 배포합니다</block>
  <block id="ff4bdefb3ddd7532393d08c8df14d786" category="paragraph">많은 데이터를 생성할 때 정리 및 정리하는 것이 중요합니다. 이를 위해 정리 기능을 정리 iynb 공책에 배치한다.</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="section-title">이점</block>
  <block id="6d0f7ccc9b17bcabb743cabdfb56e0da" category="paragraph">NetApp과 Iguazio는 Docker, Kubernetes와 같은 오케스트레이션 툴과 함께 Kubeflow, Apache Spark 및 TensorFlow 등의 필수 프레임워크를 구축하여 AI 및 ML 애플리케이션의 구축 속도를 높이고 단순화합니다. NetApp과 Iguazio는 엔드 투 엔드 데이터 파이프라인을 통합함으로써 수많은 고급 컴퓨팅 워크로드에서 발생하는 지연 시간과 복잡성을 줄이고 개발 및 운영 간의 격차를 효과적으로 좁혀줍니다. 데이터 과학자는 대규모 데이터 세트에서 쿼리를 실행하고 교육 단계 동안 권한 있는 사용자와 데이터 및 알고리즘 모델을 안전하게 공유할 수 있습니다. 컨테이너식 모델이 운영 환경에 준비되면 개발 환경에서 운영 환경으로 쉽게 이동할 수 있습니다.</block>
  <block id="daee7e425c63dff416cde0a8932a8483" category="paragraph"><block ref="daee7e425c63dff416cde0a8932a8483" category="inline-link-macro-rx"></block></block>
  <block id="3b878279a04dc47d60932cb294d96259" category="doc">개요</block>
  <block id="f68b67869778246b8f0d8a98ed043512" category="paragraph">이 섹션에서는 Virtual Retail Assistant 구현에 대해 자세히 설명합니다.</block>
  <block id="02216530e0245f79b0b7448e14bffbce" category="inline-link-macro">다음: Jarvis 배포</block>
  <block id="a9ca2532d8607b5827969961f314249e" category="paragraph"><block ref="a9ca2532d8607b5827969961f314249e" category="inline-link-macro-rx"></block></block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">설정</block>
  <block id="9783bbad26249ed7f40d89e12ba42020" category="doc">실행: AI 워크로드 오케스트레이션에 AI 플랫폼 사용</block>
  <block id="cb39fb629a91fdf37928a15d38e05318" category="list-text">더 빠르게 혁신을 이룩할 수 있습니다. 연구원들은 NetApp 스토리지 시스템과 함께 AI 리소스 풀링, 큐 처리 및 우선순위 지정 메커니즘을 사용하여 인프라 관리 문제에서 제거되며 데이터 과학에만 집중할 수 있습니다. 실행: AI 및 NetApp 고객은 컴퓨팅 또는 데이터 파이프라인 병목 현상 없이 필요한 만큼 워크로드를 실행하여 생산성을 향상할 수 있습니다.</block>
  <block id="8df86cf2931aab70fd9ad1f919f40449" category="list-text">팀 생산성 향상. Run:AI Fairness 알고리즘은 모든 사용자와 팀이 리소스의 페어공유를 확보할 수 있도록 보장합니다. 우선 순위 프로젝트와 관련된 정책을 미리 설정할 수 있으며, 플랫폼을 통해 사용자 팀 간에 리소스를 동적으로 할당할 수 있으므로 사용자가 원하는 GPU 리소스에 적시에 액세스할 수 있습니다.</block>
  <block id="c835378d4be1896f62ef5d2760340909" category="list-text">GPU 활용률이 향상되었습니다. Run:AI Scheduler를 사용하면 Kubernetes에서 분산된 훈련을 위해 소수점 GPU, 정수 GPU 및 여러 GPU 노드를 쉽게 사용할 수 있습니다. 이런 식으로 AI 워크로드는 용량이 아닌 요구사항에 따라 실행됩니다. 데이터 과학 팀은 동일한 인프라에서 더 많은 AI 실험을 실행할 수 있습니다.</block>
  <block id="5960deb1522a82336a7a31213acea4b0" category="inline-link-macro">다음: 솔루션 기술</block>
  <block id="dde440f8f7c47863e65c2d82a820b8a5" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block>.</block>
  <block id="2e240897109c5037e05afe0bf035d177" category="inline-link-macro">이전: 결론.</block>
  <block id="9c08a0abcced906f3225e86f61dd598c" category="paragraph"><block ref="9c08a0abcced906f3225e86f61dd598c" category="inline-link-macro-rx"></block></block>
  <block id="c5648cc9e6e76ab4aa041d71661d0288" category="list-text">3D 대화형 데모</block>
  <block id="26e071d5769be8e940617a0c8dd5c22d" category="inline-link">www.netapp.com/ai</block>
  <block id="9e22db1b830d668e86d5dc1b5c204555" category="paragraph"><block ref="9e22db1b830d668e86d5dc1b5c204555" category="inline-link-rx"></block></block>
  <block id="1fa584a3d1190f1a7fdded0c91412cac" category="list-text">NetApp AI 전문가와의 직접 연결</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="488d7301e5d1a52040c33186d7e11657" category="paragraph"><block ref="488d7301e5d1a52040c33186d7e11657" category="inline-link-rx"></block></block>
  <block id="787dd83fbbc162f0279e320ada1f7c0b" category="list-text">NVDIA Base Command Platform with NetApp 솔루션 개요</block>
  <block id="5541299dd0999c42fcd24fd754001e38" category="inline-link"><block ref="5541299dd0999c42fcd24fd754001e38" category="inline-link-rx"></block></block>
  <block id="ac527e3c2b2d8a080840aa28c13b127b" category="paragraph"><block ref="ac527e3c2b2d8a080840aa28c13b127b" category="inline-link-rx"></block></block>
  <block id="465b9c508fba1d27d188eb21e0655293" category="list-text">AI를 위한 NetApp 10가지 이유 인포그래픽</block>
  <block id="75048e22ffd1c45ce07e6cae3170780a" category="inline-link"><block ref="75048e22ffd1c45ce07e6cae3170780a" category="inline-link-rx"></block></block>
  <block id="e2435a6f01dee5a11f6cd698a292183d" category="paragraph"><block ref="e2435a6f01dee5a11f6cd698a292183d" category="inline-link-rx"></block></block>
  <block id="66d4373905c5c7c0a3f51e5480d443b2" category="list-text">의료 부문의 AI: 폐 CT 스캔에서 COVID-19 병변을 식별하는 딥 러닝 백서</block>
  <block id="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link"><block ref="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link-rx"></block></block>
  <block id="d1e9d43080e6c2364ee86ac930ae1341" category="paragraph"><block ref="d1e9d43080e6c2364ee86ac930ae1341" category="inline-link-rx"></block></block>
  <block id="2ece031fbb30496ba2ec244a07557107" category="list-text">의료 부문의 AI: 의료 설정에서 안면 마스크 사용 모니터링 백서</block>
  <block id="aa895997d9bc7e84d90779885cb936b7" category="inline-link"><block ref="aa895997d9bc7e84d90779885cb936b7" category="inline-link-rx"></block></block>
  <block id="4ac3d75f4e132824f0fe3a418d42a9f9" category="paragraph"><block ref="4ac3d75f4e132824f0fe3a418d42a9f9" category="inline-link-rx"></block></block>
  <block id="ff11da2c36a9883c6eb658395f3de353" category="list-text">의료 부문의 AI: 진단 이미징 기술 보고서</block>
  <block id="41575d740e0d837694e2fa66ce618124" category="inline-link"><block ref="41575d740e0d837694e2fa66ce618124" category="inline-link-rx"></block></block>
  <block id="61a15cd6b61d637fb54ae6ae99ae39d5" category="paragraph"><block ref="61a15cd6b61d637fb54ae6ae99ae39d5" category="inline-link-rx"></block></block>
  <block id="1527888e6b729290296c51cf9c3aeeec" category="list-text">소매 분야 AI: NVIDIA Riva를 통한 NetApp의 대화형 AI</block>
  <block id="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link"><block ref="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link-rx"></block></block>
  <block id="dc1f6c62d8de3b68ec946b66d053f5a7" category="paragraph"><block ref="dc1f6c62d8de3b68ec946b66d053f5a7" category="inline-link-rx"></block></block>
  <block id="2281741ceb773b1efc91b48b4e5e04fe" category="list-text">NetApp ONTAP AI 솔루션 개요</block>
  <block id="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link"><block ref="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link-rx"></block></block>
  <block id="a32cc63ad53dc74caf680b96a921ad3b" category="paragraph"><block ref="a32cc63ad53dc74caf680b96a921ad3b" category="inline-link-rx"></block></block>
  <block id="c6b4ec978259e83d537f6a179912448a" category="list-text">NetApp DataOps 툴킷 솔루션 요약 정보</block>
  <block id="c50b3ec30c711b6233dd7753f12165d4" category="inline-link"><block ref="c50b3ec30c711b6233dd7753f12165d4" category="inline-link-rx"></block></block>
  <block id="a045bf4eb32fbbf6c351d4c3cbd5932c" category="paragraph"><block ref="a045bf4eb32fbbf6c351d4c3cbd5932c" category="inline-link-rx"></block></block>
  <block id="9399af78c2a9b2a197612e42bf8b8f79" category="list-text">NetApp AI Control Plane 솔루션 요약</block>
  <block id="c771257beb97f479ebb6d342d91b61bd" category="inline-link"><block ref="c771257beb97f479ebb6d342d91b61bd" category="inline-link-rx"></block></block>
  <block id="ce6060d7bc79a57fdb337f6364f0e8a9" category="paragraph"><block ref="ce6060d7bc79a57fdb337f6364f0e8a9" category="inline-link-rx"></block></block>
  <block id="b6e1af8dc83073dfa46f061507b15586" category="list-text">데이터 드라이브를 통한 산업 혁신 AI eBook</block>
  <block id="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link"><block ref="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link-rx"></block></block>
  <block id="195010aa6331d4b94de36f6aa5cf3fc7" category="paragraph"><block ref="195010aa6331d4b94de36f6aa5cf3fc7" category="inline-link-rx"></block></block>
  <block id="4dcaafba5ac7511b65c0f3a3688f8d81" category="list-text">NetApp EF-Series AI 솔루션 개요</block>
  <block id="385bae1ac9580238d4ef22dad99878c3" category="inline-link"><block ref="385bae1ac9580238d4ef22dad99878c3" category="inline-link-rx"></block></block>
  <block id="5bbcd3b785c7ecb740b1302ea68fb4ff" category="paragraph"><block ref="5bbcd3b785c7ecb740b1302ea68fb4ff" category="inline-link-rx"></block></block>
  <block id="e72de1f0850154df8bf93fae76b2276d" category="list-text">NetApp AI 및 Lenovo ThinkSystem for AI Inferencing 솔루션 개요</block>
  <block id="883d1d69b62bc20ea26446649b6c95b0" category="inline-link"><block ref="883d1d69b62bc20ea26446649b6c95b0" category="inline-link-rx"></block></block>
  <block id="74686a12110c0c39ad22ac2252bcb1a1" category="paragraph"><block ref="74686a12110c0c39ad22ac2252bcb1a1" category="inline-link-rx"></block></block>
  <block id="8954bee2812529847e7f3108185fc57d" category="list-text">엔터프라이즈 AI 및 ML용 NetApp AI 및 Lenovo ThinkSystem 솔루션 개요</block>
  <block id="f877ccffca68b901c2c61513c04dbf37" category="inline-link"><block ref="f877ccffca68b901c2c61513c04dbf37" category="inline-link-rx"></block></block>
  <block id="214ebd5c8513ce31087d4bf0cd12af76" category="paragraph"><block ref="214ebd5c8513ce31087d4bf0cd12af76" category="inline-link-rx"></block></block>
  <block id="7cbca96fc14ecadf4054303e98a81787" category="list-text">NetApp과 NVIDIA – AI 비디오를 통해 가능한 것을 새롭게 정의합니다</block>
  <block id="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link"><block ref="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link-rx"></block></block>
  <block id="c7531fbb829ae07f04aab76de6fad46c" category="paragraph"><block ref="c7531fbb829ae07f04aab76de6fad46c" category="inline-link-rx"></block></block>
  <block id="3cfbc3bac23f6bb9e7ebdc6deefeaf1d" category="paragraph">NetApp과 NVIDIA가 개발 및 검증한 NetApp ONTAP AI 아키텍처는 NVIDIA DGX 시스템과 NetApp 클라우드 연결형 스토리지 시스템을 기반으로 합니다. 이 참조 아키텍처는 IT 조직이 다음과 같은 이점을 얻을 수 있도록 해 줍니다.</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">다양한 성능 및 비용 요소에 부합하는 폭넓은 스토리지 옵션을 제공합니다</block>
  <block id="6fa0f6cc1d5d12069641e73217a17be2" category="paragraph">NetApp ONTAP AI는 DGX 시스템과 NetApp AFF A800 스토리지 시스템을 최첨단 네트워킹과 긴밀하게 통합합니다. NetApp ONTAP AI 및 DGX 시스템은 설계 복잡성과 추측을 제거함으로써 AI 배포를 단순화합니다. 고객은 작은 규모로 시작한 후 에지에서 코어 및 클라우드까지 포괄하여 데이터를 지능적으로 관리하면서 중단 없이 시스템을 확장할 수 있습니다.</block>
  <block id="bdc094a519f73076386a8bf2948832a6" category="paragraph">NetApp AI Control Plane은 데이터 과학자 및 데이터 엔지니어를 위한 전체 스택 AI, ML 및 딥 러닝(DL) 데이터 및 실험 관리 솔루션입니다. 조직이 AI를 더 많이 사용함에 따라 워크로드 확장성 및 데이터 가용성을 비롯한 여러 과제에 직면하게 됩니다. NetApp AI Control Plane은 Git repo와 마찬가지로 데이터 네임스페이스를 신속하게 클론 복제하여 추적 및 버전 관리를 위한 데이터 및 모델 기준을 거의 즉각적으로 생성하는 AI 교육 워크플로우를 정의 및 구현하는 등의 기능을 통해 이러한 문제를 해결합니다. NetApp AI Control Plane을 사용하면 사이트 및 지역 간에 데이터를 원활하게 복제하고 대규모 데이터 세트에 액세스할 수 있는 Jupyter Notebook 작업 공간을 신속하게 프로비저닝할 수 있습니다.</block>
  <block id="22101b8498dea1c2e2e35bd4868847a4" category="paragraph">실행: AI는 AI 인프라를 위한 세계 최초의 오케스트레이션 및 가상화 플랫폼을 구축했습니다. 실행: AI는 기본 하드웨어에서 워크로드를 추상화하여 동적으로 프로비저닝할 수 있는 GPU 리소스 공유 풀을 만들어 AI 워크로드를 효율적으로 조정하고 GPU를 최적화된 상태로 사용할 수 있도록 지원합니다. 데이터 과학자는 대용량 GPU 전력을 원활하게 소비하여 연구 결과를 개선하고 가속화하는 동시에, IT 팀이 리소스 프로비저닝, 대기 및 활용률에 대한 중앙 집중식 교차 사이트 제어 및 실시간 가시성을 유지할 수 있습니다. 실행: AI 플랫폼은 Kubernetes를 기반으로 구축되므로 기존 IT 및 데이터 과학 워크플로우와의 간편한 통합이 가능합니다.</block>
  <block id="ae00256db8d45ecdaf9c364a96821417" category="paragraph">Run:AI 플랫폼은 다음과 같은 이점을 제공합니다.</block>
  <block id="d472807c15e94ef6053e95521ff7e838" category="list-text">* 혁신을 위한 더 빠른 시간. * Run을 사용하면 AI 리소스 풀링, 큐 처리 및 우선순위 지정 메커니즘을 NetApp 스토리지 시스템과 함께 사용하여 연구원들은 인프라 관리 문제와 관련된 문제를 해결할 수 있으며 데이터 과학에만 집중할 수 있습니다. 실행: AI 및 NetApp 고객은 컴퓨팅 또는 데이터 파이프라인 병목 현상 없이 필요한 만큼 워크로드를 실행하여 생산성을 향상할 수 있습니다.</block>
  <block id="2707d068deb9b46967615c70c806e0d8" category="list-text">* 팀 생산성 향상. * 실행: AI 공정성 알고리즘은 모든 사용자와 팀이 적절한 리소스 공유를 확보할 수 있도록 보장합니다. 우선 순위 프로젝트와 관련된 정책을 미리 설정할 수 있으며, 플랫폼을 통해 사용자 또는 팀 간에 리소스를 동적으로 할당할 수 있으므로 사용자가 원하는 GPU 리소스에 적시에 액세스할 수 있습니다.</block>
  <block id="faa5854c7e84507b88cba1c0ec1a9aaf" category="list-text">* GPU 사용률이 개선되었습니다. * 실행: AI 스케줄러를 사용하면 Kubernetes에서 분산된 훈련을 위해 소수점 GPU, 정수 GPU 및 여러 GPU 노드를 쉽게 사용할 수 있습니다. 이런 식으로 AI 워크로드는 용량이 아닌 사용자의 요구사항을 기반으로 실행됩니다. 데이터 과학 팀은 동일한 인프라에서 더 많은 AI 실험을 실행할 수 있습니다.</block>
  <block id="d9533ea5c6cb975dff314dace88f2aa4" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block></block>
  <block id="5328ed3b5c6e4726166e04c16c2e5581" category="summary">이 섹션에서는 Pandas에서 Criteo Click Logs day 15를 로드하고 좌골키트학습 무작위 포리스트 모델을 훈련하는 방법에 대해 설명합니다. 이 예에서는 Dask cuDF를 사용하여 DataFrame 로드를 수행하고 Dask cuML에서 임의의 포리스트 모델을 교육했습니다.</block>
  <block id="a0432b74d7d4d2ad68e93e947654c865" category="doc">Dask에서 Day 15를 로드하고 Dask cuML 무작위 포리스트 모델을 교육합니다</block>
  <block id="7c784438423fe1bee9ab4f91a8fd7559" category="inline-link-macro">이전: Pandas에서 Logs day 15를 Load Critio 클릭하여 좌골 키트 교육 - Learn random forest model.</block>
  <block id="5d5b75a952d74a7d4520c521956b9d7e" category="paragraph"><block ref="5d5b75a952d74a7d4520c521956b9d7e" category="inline-link-macro-rx"></block></block>
  <block id="78dc33cd9d496e2466a0c1e2ba09ab3f" category="inline-link-macro">“교육 시간 비교.”</block>
  <block id="4a2764258721dd882c9ec28454963797" category="paragraph">이전 섹션과 비슷한 방식으로, Pandas에서 Criteo Click Logs day 15 를 로드하고 좌골키트학습 무작위 포리스트 모델을 훈련합니다. 이 예에서는 Dask cuDF를 사용하여 DataFrame 로드를 수행하고 Dask cuML에서 임의의 포리스트 모델을 교육했습니다. 이 섹션에서는 교육 시간과 규모의 차이를 비교했습니다 <block ref="8d6c01ed5b9db5301efeb6183c858b76" category="inline-link-macro-rx"></block></block>
  <block id="356d8553da3749641cb731d318c85b0c" category="section-title">criteo_dask_rf.ipynb입니다</block>
  <block id="2f4f1a139be92d2b17647025ff8630ab" category="paragraph">이 노트북은 다음 예와 같이 'numpy', 'cuml', 필요한 'dask' 라이브러리를 가져옵니다.</block>
  <block id="7b871613dade772ae668d694698383bf" category="paragraph">Dask 클라이언트()를 시작합니다.</block>
  <block id="3e9277d3d0f0519292426b933e52f232" category="paragraph">클러스터가 올바르게 구성된 경우 작업자 노드의 상태를 확인할 수 있습니다.</block>
  <block id="d6b257c355ced1525e4967c96b62b83e" category="paragraph">AKS 클러스터에서 다음 상태가 표시됩니다.</block>
  <block id="d94a77691c281e8bf418635fea6ca580" category="paragraph"><block ref="d94a77691c281e8bf418635fea6ca580" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073b2194006d8da73b5f74f3d7224d76" category="paragraph">DASK는 처리 코드를 즉시 실행하는 대신 실행 대신 실행 대신 대상 지정 DAG(Acyclic Graph)를 생성합니다. DAG에는 각 작업자가 실행해야 하는 일련의 작업과 상호 작용이 포함되어 있습니다. 이 레이아웃은 사용자가 Dask에서 한 가지 방식 또는 다른 방식으로 작업을 실행하도록 지시할 때까지 작업이 실행되지 않음을 의미합니다. Dask를 사용하면 다음과 같은 세 가지 주요 옵션을 사용할 수 있습니다.</block>
  <block id="a40049c3d7270ce955d2023f8e2015dc" category="list-text">* DataFrame의 컴퓨팅()을 호출합니다. * 이 호출은 모든 파티션을 처리한 다음 결과를 스케줄러에 반환하여 최종 집계 및 cuDF DataFrame으로 변환합니다. 이 옵션은 스케줄러 노드의 메모리가 부족하지 않는 한 적은 결과에만 사용해야 합니다.</block>
  <block id="30e170dbe1dd223491e1a822605da52d" category="list-text">* Call persist() on a DataFrame. * 이 호출은 그래프를 실행하지만 결과를 스케줄러 노드로 반환하는 대신 클러스터의 전체 노드를 메모리에 유지하여 사용자가 이러한 중간 결과를 다시 사용하지 않고도 파이프라인에서 재사용할 수 있도록 합니다.</block>
  <block id="ca013764f3f6faeab137d2d529dba598" category="list-text">* DataFrame의 Call head(). * cuDF와 마찬가지로 이 호출은 10개의 레코드를 스케줄러 노드로 다시 반환합니다. 이 옵션을 사용하면 DataFrame 에 원하는 출력 형식이 포함되어 있는지 또는 레코드 자체가 타당한지 여부를 처리 및 계산에 따라 빠르게 확인할 수 있습니다.</block>
  <block id="7ac60f98a199ceae63010c7802a9aefa" category="paragraph">따라서 사용자가 이러한 작업을 호출하지 않는 한 작업자는 스케줄러가 처리를 시작할 때까지 유휴 상태로 있습니다. 이러한 게으른 실행 패러다임은 Apache Spark와 같은 오늘날의 병렬적이고 분산된 컴퓨팅 프레임워크에서 흔히 볼 수 있습니다.</block>
  <block id="d887d6a29f39f14cec0f83c5b02c42f8" category="paragraph">다음 단락에서는 분산 GPU 가속 컴퓨팅에 Dask cuML을 사용하여 임의 포리스트 모델을 교육하고 모델 예측 정확도를 계산합니다.</block>
  <block id="de76ff3258bd3001f89804efae30da38" category="inline-link-macro">다음: 기본 작업 스트림 대시보드를 사용하여 Dask를 모니터링합니다.</block>
  <block id="5db30f2a693de098d03dec622875beec" category="paragraph"><block ref="5db30f2a693de098d03dec622875beec" category="inline-link-macro-rx"></block></block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">이 문서는 MLPerf Inference v0.7 코드, MLPerf Inference v1.1 코드 및 규칙을 따릅니다. 이 단원에 나와 있는 표에 정의된 대로 모서리에서 추론을 위해 설계된 벤치마크를 실행했습니다.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">테스트 계획</block>
  <block id="35e08a3e7b357a4284ef29b287063ae5" category="paragraph"><block ref="35e08a3e7b357a4284ef29b287063ae5" category="inline-link-macro-rx"></block></block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">코드</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">규칙</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">이 문서는 MLPerf Inference v0.7을 따릅니다<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>, MLPerf Inference v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>, 및<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>. 아래 표에 정의된 대로 에지에서 추론을 위해 설계된 MLPerf 벤치마크를 실행했습니다.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">영역</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">작업</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSL 크기</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">품질</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">멀티스트림 지연 제한</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">비전</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">영상 분류</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet(224x224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">FP32의 99%</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">물체 감지(대형)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD-ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">코코(1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">물체 감지(소형)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD - MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">코코(300x300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">의료 영상 분할</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">2019 (224x224x160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">FP32의 99% 및 99.9%</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">해당 없음</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">음성</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">텍스트 음성 변환</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">리브리스페흐(LiBrispeech) 개발 - 청소</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">언어</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">언어 처리</block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="cell">베르</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">스쿼드 v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">다음 표에는 Edge 벤치마크 시나리오가 나와 있습니다.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">시나리오</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">영상 분류</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">단일 스트림, 오프라인, 멀티스트림</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">단일 스트림, 오프라인</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">이 검증에서 개발된 네트워크 스토리지 아키텍처를 사용하여 이러한 벤치마크를 수행한 결과 및 이전에 MLPerf에 제출한 에지 서버에서 로컬 실행의 결과를 비교했습니다. 이와 비교하여 공유 스토리지가 추론 성능에 미치는 영향을 확인합니다.</block>
  <block id="a53c037982ff4e0cd4a61ba90c4c21d3" category="inline-link-macro">다음: 구성을 테스트합니다.</block>
  <block id="50cbf9a915ce97c432035077add8a92f" category="paragraph"><block ref="50cbf9a915ce97c432035077add8a92f" category="inline-link-macro-rx"></block></block>
  <block id="1cf7e301510c711b73d2b182b9dcf084" category="doc">사용 사례</block>
  <block id="4c2588a1e3dbf6824a4f05095df75f83" category="paragraph">오늘날의 모든 애플리케이션은 AI가 지원하지 않지만, AI의 탁월한 이점을 활용할 수 있도록 하는 새로운 기능도 필요합니다. AI의 채택을 지원하려면 최적의 상태로 기능하고 지속적인 혁신을 지원하는 데 필요한 리소스를 제공하는 인프라가 필요합니다.</block>
  <block id="31965de7c735983bb41a0b7e70361db2" category="paragraph">AI 기반 애플리케이션의 경우 에지 위치가 데이터의 주요 소스 역할을 합니다. 사용 가능한 데이터는 일정 기간 동안 여러 에지 위치에서 수집된 교육에 사용하여 교육 데이터 세트를 구성할 수 있습니다. 그런 다음, 훈련된 모델을 데이터가 수집된 에지 위치로 다시 구축하여 운영 데이터를 전용 추론 플랫폼으로 반복적으로 전송할 필요 없이 더 빠른 추론을 사용할 수 있습니다.</block>
  <block id="9e53c147a93fed13d4349cba2a35e36b" category="paragraph">NetApp H615c 컴퓨팅 노드에서 지원하는 NetApp HCI AI 추론 솔루션은 NVIDIA T4 GPU 및 NetApp 클라우드 연결 스토리지 시스템을 통해 NetApp 및 NVIDIA를 통해 개발 및 검증되었습니다. NetApp HCI은 애매모호한 영역을 해결하여 설계 상의 복잡성을 제거하고 추측을 말하여 에지 데이터 센터에서 AI 추론 솔루션 구축을 단순화합니다. 이 솔루션은 다음과 같은 특징을 갖춘 규범적 아키텍처를 IT 조직에 제공합니다.</block>
  <block id="9c4a53996590c74a0de3bba81f878254" category="list-text">에지 데이터 센터에서 AI 추론을 사용할 수 있습니다</block>
  <block id="20c3f996d396cc8c92788bb3585a6e86" category="list-text">GPU 리소스 소비를 최적화합니다</block>
  <block id="06e81c54cb9157aa59541289f1163daf" category="list-text">유연성 및 확장성을 위해 Kubernetes 기반 추론 플랫폼을 제공합니다</block>
  <block id="ba37c372c4a9119e45c7f525f4743cfc" category="paragraph">에지 데이터 센터는 거의 생성 지점에 있는 위치에서 데이터를 관리 및 처리합니다. 이러한 근접성으로 인해 효율성이 증가하고 데이터 처리와 관련된 지연 시간이 줄어듭니다. 많은 업종별 시장에서 에지 데이터 센터의 이점을 인식하고 있으며 이러한 분산 데이터 처리 방식을 적극적으로 채택하고 있습니다.</block>
  <block id="b501a0f0a3e7d559cecfad08c330227e" category="paragraph">다음 표에는 엣지 수직 시장과 애플리케이션이 나열되어 있습니다.</block>
  <block id="06ce2a25e5d12c166a36f654dbea6012" category="cell">수직</block>
  <block id="1ddf333c6654f7f89c739dddfb4cc429" category="cell">응용 프로그램</block>
  <block id="077262cc53a1fb1b5f651d31b6bf81ba" category="cell">의료</block>
  <block id="9da98fbc1c3d290fefb743a2df8914b4" category="cell">컴퓨터 보조 진단 기능은 의료진이 조기 질병 감지에 도움이 됩니다</block>
  <block id="fa0a7aa1622ad105e9cdf5a706058333" category="cell">석유 및 가스</block>
  <block id="55dae4e2e7f267e43e5768e66c7c3771" category="cell">원격 생산 시설, 비디오 및 이미지 분석에 대한 자동 검사</block>
  <block id="252ddb15657f2c60bddc73633a7bf8c0" category="cell">항공</block>
  <block id="7a84f6faf76fd3533ae6ca65d28c53eb" category="cell">항공 교통 제어 지원 및 실시간 비디오 피드 분석</block>
  <block id="81ea9456adf225bcf11b668b427fd4f2" category="cell">미디어 및 엔터테인먼트</block>
  <block id="5015819e58d425b19f8acc93866e76fa" category="cell">오디오/비디오 콘텐츠 필터링을 통해 가족 친화적인 콘텐츠를 제공합니다</block>
  <block id="616e90f12cb95950bc1c75396902393a" category="cell">비즈니스 분석</block>
  <block id="3e4c06851690089d4952320e9df36dc2" category="cell">브랜드 인지도를 통해 라이브 스트리밍 TV 행사에서 브랜드 이미지를 분석할 수 있습니다</block>
  <block id="a9f7ecebb493e129aafb4cbfd73e85df" category="cell">전자 상거래</block>
  <block id="5df4fc692c9317012855d6935bf10310" category="cell">이상적인 가맹점과 창고 조합을 찾기 위한 공급업체 제공의 스마트 번들</block>
  <block id="053e0bc8b9627b28e2ed8029a34b35bd" category="cell">소매</block>
  <block id="7cf7816e39e6e0c259a79dc29c5a5e7c" category="cell">고객이 장바구니에 넣은 품목을 인식하고 디지털 결제를 용이하게 하기 위한 자동 체크 아웃</block>
  <block id="165f5687ea9050fba239731810d0abe8" category="cell">스마트 시티</block>
  <block id="a47b360ffbe39c5a39c7e12e2ae8fdf5" category="cell">교통 흐름을 개선하고, 주차 상황을 최적화하고, 보행자 및 자전거 운전자 안전을 강화합니다</block>
  <block id="e86883c7cfc07afcf1e5ad8dffd7e1cc" category="cell">제조</block>
  <block id="f4d790a35097fa97c2687ac573b25338" category="cell">품질 관리, 조립 라인 모니터링 및 결함 식별</block>
  <block id="2273d1167a6212812d95dc8fadbae78e" category="cell">고객 서비스</block>
  <block id="bf4948e47ea0d77a86e639979879262d" category="cell">고객 서비스 자동화 - 전화, 이메일 및 소셜 미디어 등의 질문 분석 및 분류</block>
  <block id="8e54e9aa508ea37f7fe734e86ba9da27" category="cell">농업</block>
  <block id="7fb956270d49b22c3226bc1db2b0269f" category="cell">비료 및 살균제 사용을 최적화하기 위한 지능형 농장 운영 및 활동 계획</block>
  <block id="134481f7bea652a34fa2ada120d250e5" category="list-text">데이터 과학자</block>
  <block id="8d26f0555c7ace3d4b297da8c12fb31b" category="list-text">IT 설계자</block>
  <block id="c114d2813b0041352b49187ebc28b62b" category="list-text">현장 컨설턴트</block>
  <block id="2d6d0cc18609f97853f883c1891397d2" category="list-text">구축</block>
  <block id="467f739adb5605167109d76676b44696" category="list-text">IT 관리자</block>
  <block id="dcfa1c08d3b0126217af0b8690305c08" category="list-text">에지 위치에서 IT 혁신과 강력한 데이터 및 애플리케이션 서비스를 제공하는 인프라가 필요한 모든 고객</block>
  <block id="ad54e6f7d665098e981d7e41732ce4c2" category="inline-link-macro">다음: 아키텍처</block>
  <block id="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="paragraph"><block ref="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="inline-link-macro-rx"></block></block>
  <block id="8383a1cf96c028a0986b7371049c8495" category="doc">네트워크 장치 오류 예측 사용 사례 요약</block>
  <block id="dea416ff04e558b0d76cce896b618880" category="paragraph">이 사용 사례는 아시아 통신 분야의 이과지오 고객을 기반으로 합니다. 매년 100K 기업 고객 및 125k 네트워크 중단 이벤트가 발생하면서 네트워크 장애가 고객에게 영향을 미치지 않도록 사전에 조치를 취하고 예측해야 했습니다. 이 솔루션은 다음과 같은 이점을 제공합니다.</block>
  <block id="feb68271e6d14db0b1ff524f3eb47a27" category="list-text">네트워크 장애에 대한 예측 분석</block>
  <block id="70e00676492bea584fb8e7d551515eb5" category="list-text">발권 시스템과 통합</block>
  <block id="6de8d1444549249c0161228a7b7c1d27" category="list-text">네트워크 장애를 방지하기 위한 사전 예방 조치 이과지오(Iguazio)의 구현 결과, 60%의 장애를 사전에 예방했습니다.</block>
  <block id="fd80dbb606385d62c59605ec96147d3f" category="inline-link-macro">다음: 설정 개요</block>
  <block id="d31627f0c8fea1236773b2420ab9cd39" category="paragraph"><block ref="d31627f0c8fea1236773b2420ab9cd39" category="inline-link-macro-rx"></block></block>
  <block id="1d22ea3c852f35081a408a42b1caa719" category="doc">cnvrg.io 배포</block>
  <block id="e1d91df1cfd0e5839c45e06d0504c9d6" category="section-title">제어 장치를 사용하여 cnvrg 코어를 배포합니다</block>
  <block id="7e9e2a4317009b27ebfc0b4cd222ba30" category="paragraph">Helm은 모든 클러스터, 온프레미스, Minikube 또는 모든 클라우드 클러스터(예: AKS, EKS, GKE)를 사용하여 cnvrg를 신속하게 배포하는 가장 쉬운 방법입니다. 이 섹션에서는 Kubernetes가 설치된 사내(DGX-1) 인스턴스에 cnvrg를 설치한 방법을 설명합니다.</block>
  <block id="ea6de3fdf29035cd2d521949527c2a44" category="paragraph">설치를 완료하려면 먼저 로컬 컴퓨터에 다음 종속 항목을 설치하고 준비해야 합니다.</block>
  <block id="6f49e891fdb1bb11823492f4d315b2fd" category="list-text">쿠베틀입니다</block>
  <block id="5e6cef7c129d4703b20be420ac32145c" category="list-text">Helm 3.x</block>
  <block id="93fafc2be5db6c259030d6d8dc989752" category="list-text">Kubernetes 클러스터 1.15 이상</block>
  <block id="116efea8faeef9714de76fe9f81d9b82" category="section-title">헬름으로 배포</block>
  <block id="237800170a9b824a7de8c08766ea114e" category="list-text">최신 cnvrg Helm 차트를 다운로드하려면 다음 명령을 실행합니다.</block>
  <block id="9b821098b02043dada6b07b924f4ef5f" category="list-text">cnvrg를 구축하기 전에 클러스터의 외부 IP 주소와 cnvrg를 배포할 노드의 이름이 필요합니다. 사내 Kubernetes 클러스터에 cnvrg를 배포하려면 다음 명령을 실행합니다.</block>
  <block id="1d1eb4e0da8bac1b4eaa79c1f0be9e04" category="list-text">helm install 명령을 실행합니다. 모든 서비스 및 시스템이 클러스터에 자동으로 설치됩니다. 이 프로세스는 최대 15분 정도 소요될 수 있습니다.</block>
  <block id="e269e5751f8883222b6d2f55da7ed811" category="list-text">헬름 설치 명령은 10분 정도 걸릴 수 있습니다. 배포가 완료되면 새로 배포된 cnvrg의 URL로 이동하거나 새 클러스터를 조직 내의 리소스로 추가합니다. 'helm' 명령은 올바른 URL을 알려줍니다.</block>
  <block id="ac0cc75e8d4f0df818dd93a00041897a" category="list-text">모든 컨테이너의 상태가 실행 중 또는 완료됨이면 cnvrg가 성공적으로 배포된 것입니다. 이 결과는 다음 예제 출력과 유사해야 합니다.</block>
  <block id="3e82668da957bceb0d0c7024273ab624" category="section-title">ResNet50 및 Chest X-ray 데이터 집합을 사용한 컴퓨터 비전 모델 교육</block>
  <block id="c9c734dfca60f137a58e1a5cb9c89b62" category="inline-link">NIH 다운로드 사이트</block>
  <block id="0c7f26c15912f9f5d0e0473bb21cb9a2" category="paragraph">cnvrg.io AI OS는 NVIDIA DGX 시스템을 기반으로 하는 NetApp ONTAP AI 아키텍처를 기반으로 Kubernetes 설정에 구축했습니다. 검증을 위해 흉부 X-레이의 식별 불가 영상으로 구성된 NIH Chest X-ray 데이터 세트를 사용했습니다. 이미지는 PNG 형식이었습니다. 이 데이터는 NIH 임상 센터에서 제공했으며 을 통해 확인할 수 있습니다<block ref="4e3f11b94ad47864cbd9c6049036ac93" category="inline-link-rx"></block>. 15개 클래스에서 627, 615의 이미지를 사용하여 250GB 데이터 샘플을 사용했습니다.</block>
  <block id="de53b795a18176edb91a88632f621868" category="paragraph">데이터 세트가 cnvrg 플랫폼으로 업로드되었으며 NetApp AFF A800 스토리지 시스템에서 NFS 엑스포트에 캐싱되었습니다.</block>
  <block id="ec948f075c372d4beb7d19a5266f22d5" category="section-title">컴퓨팅 리소스 설정</block>
  <block id="42af2f71dc8561eb9cfe43d45664ecb3" category="paragraph">엔지니어 및 IT 전문가는 cnvrg 아키텍처 및 메타 스케줄링 기능을 사용하여 서로 다른 컴퓨팅 리소스를 단일 플랫폼에 연결할 수 있습니다. 설정에서 딥 러닝 워크로드를 실행하기 위해 배포된 것과 동일한 클러스터 cnvrg를 사용했습니다. 추가 클러스터를 연결해야 하는 경우 다음 스크린샷과 같이 GUI를 사용합니다.</block>
  <block id="df25fca4c07e68ed339b0e1974a9d59f" category="paragraph"><block ref="df25fca4c07e68ed339b0e1974a9d59f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f541774a08fc687f6e2016c77a6ebca5" category="section-title">데이터 로드</block>
  <block id="564bfd33ed32c02158989dfcee59ae89" category="paragraph">cnvrg 플랫폼에 데이터를 업로드하려면 GUI 또는 cnvrg CLI를 사용할 수 있습니다. 대규모 데이터 세트의 경우 많은 파일을 처리할 수 있는 강력하고 확장 가능하며 안정적인 툴이므로 CLI를 사용하는 것이 좋습니다.</block>
  <block id="41ad6001e0d3c17bd4a7957e18bd8bab" category="paragraph">데이터를 업로드하려면 다음 단계를 완료하십시오.</block>
  <block id="192b006166881688d04f398db712aaeb" category="inline-link">cnvrg CLI를 참조하십시오</block>
  <block id="8e9fbcfb57e26d7a14f0292c11fae122" category="list-text">를 다운로드합니다<block ref="d3ae4cf97b77cb5805c16205cd459ce4" category="inline-link-rx"></block>.</block>
  <block id="5cea56fcf2481a021f3d93843a22c319" category="list-text">X-ray 디렉토리로 이동합니다.</block>
  <block id="1c5a650f398227a4f97ed81accfbbb4b" category="list-text">'cnvrg data init' 명령으로 플랫폼 내 데이터세트를 초기화한다.</block>
  <block id="5c48f13a3d988e0d618145098a829e3a" category="list-text">중앙 오브젝트 저장소(StorageGRID, S3 등)에 데이터를 업로드한 후 GUI로 검색할 수 있습니다. 다음 그림은 로드된 흉부 X선 섬유증 영상 PNG 파일을 보여줍니다. 또한, cnvrg는 데이터를 버전화하므로 빌드하는 모든 모델을 데이터 버전으로 복제할 수 있습니다.</block>
  <block id="935b6e25167b65d839bc1487ebb2fa6e" category="paragraph"><block ref="935b6e25167b65d839bc1487ebb2fa6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="308e9394a715dc64aa4e48e0054775ed" category="section-title">Cach 데이터</block>
  <block id="556cde11a66a789acb7e62b934c1a88c" category="paragraph">각 모델의 교육 및 실험을 위해 600k+ 파일을 다운로드하지 않고 더 빠르게 교육을 제공하기 위해 데이터를 중앙 데이터 레이크 오브젝트 저장소에 처음 업로드한 후 데이터 캐싱 기능을 사용했습니다.</block>
  <block id="3d163413cac9b6cc4726a9c83d37fed3" category="paragraph"><block ref="3d163413cac9b6cc4726a9c83d37fed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d006c100d76e7d21d64055ce3cfe6a24" category="paragraph">사용자가 캐시를 클릭하면 cnvrg는 원격 오브젝트 저장소에서 특정 커밋에 있는 데이터를 다운로드하여 ONTAP NFS 볼륨에 캐시합니다. 완료되면 데이터를 즉시 교육에 사용할 수 있습니다. 또한 데이터가 며칠 동안 사용되지 않으면(예: 모델 교육 또는 탐색) cnvrg가 자동으로 캐시를 지웁니다.</block>
  <block id="53ad459d9bb7a65de3d1cc839b75c19f" category="section-title">캐시된 데이터로 ML 파이프라인을 구축합니다</block>
  <block id="db226c80bcb6098ce2f47dd3982cca26" category="paragraph">cnvrg 흐름으로 생산 ML 파이프라인을 쉽게 구축할 수 있습니다. 흐름은 유연하며 모든 종류의 ML 사용 사례에 사용할 수 있으며 GUI 또는 코드를 통해 생성할 수 있습니다. 플로우의 각 구성 요소는 다른 Docker 이미지를 사용하여 다른 컴퓨팅 리소스에서 실행될 수 있으므로 하이브리드 클라우드와 최적화된 ML 파이프라인을 구축할 수 있습니다.</block>
  <block id="6b0eae96748d48b032362774a6467411" category="paragraph"><block ref="6b0eae96748d48b032362774a6467411" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1f18dfff2566b35d7d0e528565c43aa" category="section-title">흉부 X선 흐름 구축:데이터 설정</block>
  <block id="adec555cb8cd4de3f288baed510d1163" category="paragraph">새로 생성된 흐름에 데이터 세트를 추가했습니다. 데이터 집합을 추가할 때 특정 버전(커밋)을 선택하고 캐시된 버전을 사용할지 여부를 지정할 수 있습니다. 이 예에서는 캐시된 커밋을 선택했습니다.</block>
  <block id="6dd780034ed574b328dbc16a6b485b79" category="paragraph"><block ref="6dd780034ed574b328dbc16a6b485b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e0789c536fc18ddcdc32b4ca598b58" category="section-title">흉부 X선 흐름 구축:교육 모델 설정:ResNet50</block>
  <block id="fa3c48d58d8e9fd17365fd986906dd52" category="paragraph">파이프라인에서는 원하는 모든 종류의 사용자 지정 코드를 추가할 수 있습니다. cnvrg에는 재사용 가능한 ML 구성 요소 컬렉션인 AI 라이브러리도 있습니다. AI 라이브러리에는 모든 ML 또는 딥 러닝 플로우에 사용할 수 있는 알고리즘, 스크립트, 데이터 소스 및 기타 솔루션이 있습니다. 이 예에서는 사전 구축된 ResNet50 모듈을 선택했습니다. batch_size:128, epoch:10 등과 같은 기본 매개 변수를 사용했습니다. 이러한 매개 변수는 AI 라이브러리 문서에서 확인할 수 있습니다. 다음 스크린샷은 ResNet50에 연결된 X선 데이터 세트의 새로운 흐름을 보여줍니다.</block>
  <block id="defe5cc08faaa501eeb5fc5500664d29" category="paragraph"><block ref="defe5cc08faaa501eeb5fc5500664d29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf9bb479506589dfd719446fe3e054c7" category="section-title">ResNet50의 컴퓨팅 리소스를 정의합니다</block>
  <block id="943cb3f5c7789c68e811b0accdb6c5d9" category="paragraph">cnvrg 플로우의 각 알고리즘 또는 구성 요소는 다른 Docker 이미지와 함께 다른 컴퓨팅 인스턴스에서 실행될 수 있습니다. 저희 셋업에서는 NetApp ONTAP AI 아키텍처를 사용하여 NVIDIA DGX 시스템에 대한 훈련 알고리즘을 실행하려고 했습니다. 다음 그림에서는 사내 클러스터의 컴퓨팅 템플릿과 사양인 GPU-Real을 선택했습니다. 또한 템플릿 큐와 여러 템플릿을 선택했습니다. 이렇게 하면 'GPU-실제' 리소스를 할당할 수 없는 경우(예: 다른 데이터 과학자가 사용 중인 경우) 클라우드 공급자 템플릿을 추가하여 자동 클라우드 증가를 지원할 수 있습니다. 다음 스크린샷에서는 ResNet50의 컴퓨팅 노드로 GPU-real을 사용하는 방법을 보여 줍니다.</block>
  <block id="27c8450e6f62877ec794262ae4c5a713" category="paragraph"><block ref="27c8450e6f62877ec794262ae4c5a713" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bee38713f37ae72239f6bda08384dfbb" category="section-title">추적 및 모니터링 결과</block>
  <block id="546b7da7049f1d7fdf35cdb57fa96c7c" category="paragraph">흐름이 실행된 후 cnvrg가 추적 및 모니터링 엔진을 트리거합니다. 각 흐름 실행은 자동으로 문서화되고 실시간으로 업데이트됩니다. Hyperparameters, 메트릭, 리소스 사용량(GPU 활용률 등), 코드 버전, 아티팩트, 로그, 다음 두 스크린샷과 같이 실험 섹션에서 자동으로 사용할 수 있습니다.</block>
  <block id="8fabeb8b8d143d509bb92087cbbf953c" category="paragraph"><block ref="8fabeb8b8d143d509bb92087cbbf953c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbd22304f732000189e44de22498da1" category="paragraph"><block ref="fdbd22304f732000189e44de22498da1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="debe391efc3dc12a7d87720a4cf068a5" category="paragraph"><block ref="debe391efc3dc12a7d87720a4cf068a5" category="inline-link-macro-rx"></block></block>
  <block id="efbb4ade01a09771413f4c09880e800a" category="paragraph">이 섹션에서는 여러 팀에서 워크로드를 제출하고 할당량을 초과하는 시나리오를 확장합니다. 이 방법으로 Run:AI의 Fairness 알고리즘이 사전 설정된 할당량의 비율에 따라 클러스터 리소스를 할당하는 방법을 보여 줍니다.</block>
  <block id="3bd5af2e3a75651c4b9c45d26400fbaa" category="paragraph">이 테스트 시나리오의 목표:</block>
  <block id="cc9e23eb4fe1626d97a5dfeab7cf0d25" category="list-text">여러 팀에서 할당량을 통해 GPU를 요청할 때 큐 메커니즘을 표시합니다.</block>
  <block id="050060785f2852b203c9e82254f2946a" category="list-text">할당량 비율에 따라 할당량이 초과된 여러 팀 간에 클러스터가 공평하게 분배되어 할당량이 더 큰 팀이 여유 용량을 더 많이 점유하도록 하는 방법을 보여 줍니다.</block>
  <block id="9e06f625a31670e60f0a8a09917c3ba0" category="paragraph">의 끝에 있습니다 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>팀-b, 팀-c의 두 가지 워크로드가 대기 중입니다. 이 섹션에서는 추가 워크로드를 전담합니다.</block>
  <block id="286cda6cf9e9438a2cff2827773cfe7a" category="inline-link-macro">섹션 4.10의 테스트 세부 정보</block>
  <block id="0e7a9992269080ceaf2b90c188cbb861" category="paragraph">작업 제출, 사용된 컨테이너 이미지 및 실행된 명령 시퀀스를 포함한 자세한 내용은 을 참조하십시오 <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>.</block>
  <block id="b1df8ade330dd8e3c0962d87a58c1ba9" category="paragraph">섹션에 따라 모든 작업이 제출되는 경우 <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>시스템 대시보드에는 팀-A, 팀-b, 팀-c가 모두 미리 설정된 할당량보다 더 많은 GPU를 가지고 있는 것으로 표시됩니다. 팀 A는 미리 설정된 소프트 쿼터보다 4개의 GPU를 더 점유하고, 팀 b와 팀 c는 각각 소프트 할당량(2개)보다 2개의 GPU를 더 점유합니다. 할당된 초과 할당량 GPU의 비율은 사전 설정된 할당량의 비율과 동일합니다. 이는 시스템이 사전 설정 할당량을 우선 순위에 따라 사용하고 여러 팀에서 더 많은 GPU를 요청하고 할당량을 초과할 경우 적절히 프로비저닝하기 때문입니다. 이러한 자동 로드 밸런싱은 엔터프라이즈 데이터 과학 팀이 AI 모델 개발 및 생산에 적극적으로 참여할 때 공정성과 우선순위를 제공합니다.</block>
  <block id="6effcb49094093af4699b050b9994a58" category="paragraph"><block ref="6effcb49094093af4699b050b9994a58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3be1869ca88e0b5881bc6d1da583426" category="list-text">시스템이 다른 팀의 작업 부하를 취소하기 시작합니다.</block>
  <block id="d2325970b5cec6b47eb2c10267e3a599" category="list-text">대기열은 공정성 알고리즘에 따라 결정되며, 팀-b와 팀-c는 할당량 초과 GPU(할당량이 비슷하므로)와 동일한 양을 할당받습니다. 또 팀-A는 쿼터보다 2배 많은 양의 GPU를 갖게 된다. 팀-b, 팀-c의 쿼터보다 쿼터량이 2배 더 높기 때문이다.</block>
  <block id="e2cc28c61aaa6ca7e38bd7ed9de398f1" category="list-text">모든 할당이 자동으로 수행됩니다.</block>
  <block id="c21d5f3e7c1336258c406bddcde6e0f8" category="paragraph">따라서 시스템은 다음 상태에서 안정되어야 합니다.</block>
  <block id="8f2185cd998019e76038f11669cfbfb0" category="cell">GPU가 할당되었습니다</block>
  <block id="3b55c08436be9e1008bb19488c139c88" category="cell">8월 4일</block>
  <block id="f532ced5959572a93091758c821d7ff1" category="cell">할당량에 4개의 GPU가 사용됩니다. 대기열이 비어 있습니다.</block>
  <block id="c3a4885d143dc5b306446fb380c6cfda" category="cell">4월 2일</block>
  <block id="b0713292a73176f9754bd528cecde2d1" category="cell">할당량을 통해 2개의 GPU가 제공됩니다. 하나의 워크로드가 대기 중입니다.</block>
  <block id="1f0189591d8d7dc1d3db367398fb49c5" category="cell">0/8</block>
  <block id="7c0de9de98eb6577a96694238e533915" category="cell">GPU를 전혀 사용하지 않고, 대기 중인 워크로드가 없습니다.</block>
  <block id="948c32bf5f56f7dd6f3b2baab5f6d89d" category="paragraph">다음 그림에서는 섹션에 대한 Run:AI Analytics 대시보드의 시간별 프로젝트당 GPU 할당을 보여 줍니다 <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>, <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, 및 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>. 그림의 각 줄은 언제든지 특정 데이터 과학 팀에 프로비저닝된 GPU 수를 나타냅니다. 시스템이 제출된 워크로드에 따라 GPU를 동적으로 할당하는지 확인할 수 있습니다. 따라서 클러스터에 사용 가능한 GPU가 있을 때 팀은 할당량을 초과하고, 공정성에 따라 작업을 사전에 미분하여 4팀 모두에 대해 안정적인 상태가 될 수 있습니다.</block>
  <block id="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="paragraph"><block ref="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e94097f9836d70dc64016728992696a0" category="inline-link-macro">다음: Trident에서 프로비저닝한 PersistentVolume에 데이터 저장</block>
  <block id="14718f3c808034f0e3239dbaf832a478" category="paragraph"><block ref="14718f3c808034f0e3239dbaf832a478" category="inline-link-macro-rx"></block></block>
  <block id="2034cc978abb3057c4cf27e92b16ee74" category="doc">Kubernetes 구축</block>
  <block id="47302a7393e0a038a150e679c9b3e80d" category="paragraph">NVIDIA DeepOps를 사용하여 Kubernetes 클러스터를 구축하고 구성하려면 배포 점프 호스트에서 다음 작업을 수행하십시오.</block>
  <block id="5c51dc3fcfdd9653809e90fa3948c2f4" category="inline-link">시작 페이지</block>
  <block id="21f937997adb0cac073e2458491f2c2f" category="list-text">의 지침에 따라 NVIDIA DeepOps를 다운로드합니다<block ref="a94c3c17b923443c927cfa8fe7a2482a" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="76ada3ea43b0e44772967793fe69b1bd" category="inline-link">Kubernetes 구축 가이드</block>
  <block id="03628142cdc704dd6ffe5d7d13573999" category="list-text">의 지침에 따라 클러스터에 Kubernetes를 배포합니다<block ref="cdf0a6d71dcbe898357c0e37010d30de" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="2dfe8bb84d94f23030d91e315d7899bc" category="admonition">DeepOps Kubernetes 구축이 작동하려면 모든 Kubernetes 마스터 및 작업자 노드에 동일한 사용자가 있어야 합니다.</block>
  <block id="c6fff1434177c1b95244b5300314f730" category="paragraph">배포가 실패하면 depops/config/group_vars/k8s-cluster.yml에서 kubctl_localhost의 값을 false로 변경하고 2단계를 반복합니다. kubeck_localhost의 값이 true인 경우에만 실행되는 Ansible 호스트에 kubbeck 바이너리 복사 작업은 알려진 메모리 사용 문제가 있는 Ansible 모듈 가져오기를 사용합니다. 이러한 메모리 사용 문제로 인해 작업이 실패할 수 있습니다. 메모리 문제로 인해 작업이 실패하면 나머지 배포 작업이 성공적으로 완료되지 않습니다.</block>
  <block id="24e1fa4c913dcdc975e022f921d4d603" category="paragraph">kubbctl_localhost의 값을 false로 변경한 후 배포가 성공적으로 완료되면 Kubernetes 마스터 노드에서 배포 점프 호스트로 kubbectl 바이너리를 수동으로 복사해야 합니다. 특정 마스터 노드에서 kudctl 명령을 직접 실행하여 kubctl 바이너리의 위치를 찾을 수 있습니다.</block>
  <block id="a185054da23018c3578742c41141312b" category="inline-link-macro">다음: cnvrg.io 배포</block>
  <block id="c18b567a6a5397941715c30a00a97395" category="paragraph"><block ref="c18b567a6a5397941715c30a00a97395" category="inline-link-macro-rx"></block></block>
  <block id="337f05fad2de58e4a8b74cb25536b52d" category="doc">설정 개요</block>
  <block id="666f45aef7a28ef5ba6e4bfb2f71bcee" category="section-title">Iguazio 설치</block>
  <block id="b681b0e4b3576aa1cd854e2b66c16dcd" category="paragraph">Iguazio는 온프레미스 또는 클라우드 공급자에 설치할 수 있습니다. 프로비저닝은 서비스로 수행하고 Iguazio 또는 고객이 관리할 수 있습니다. 두 경우 모두 Iguazio는 클러스터를 배포 및 관리하기 위한 배포 애플리케이션(Provazio)을 제공합니다.</block>
  <block id="8334797b9b3383d4f48d98178b8845ea" category="inline-link">이 페이지</block>
  <block id="ade8a7efee71036d2ca57676a54b31e3" category="paragraph">온-프레미스 설치의 경우 을 참조하십시오<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> 컴퓨팅, 네트워크 및 스토리지 설정을 위해 사용할 수 있습니다. Iguazio는 고객의 추가 비용 없이 구내 배치 서비스를 제공합니다. 을 참조하십시오<block ref="d273dd0a16e6003b56381a70823807f7" category="inline-link-rx"></block> DNS 및 SMTP 서버 구성의 경우 Provazio 설치 페이지는 다음과 같다.</block>
  <block id="8e72dced5918c4009ff80044ba6f44db" category="paragraph"><block ref="8e72dced5918c4009ff80044ba6f44db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c16d8d5e717cd029389f76abddf769b7" category="inline-link-macro">다음: Kubernetes 클러스터 구성</block>
  <block id="1d42e0b2a8893ff00a35554162554936" category="paragraph"><block ref="1d42e0b2a8893ff00a35554162554936" category="inline-link-macro-rx"></block></block>
  <block id="1f9a7430deed674d394796eaea14138f" category="paragraph">이 기술 보고서에서는 Run:AI CLI 및 NetApp ONTAP AI의 시스템 대시보드를 사용하여 Kubernetes 클러스터 및 GPU 사용을 최적화할 수 있는 중소기업과 대형 데이터 과학/엔지니어링 팀을 보유한 고객을 위한 지침을 제공합니다. 또한 검증된 테스트 사례를 위한 Run:AI 플랫폼 설치 정보, 테스트 시나리오, 세부 명령도 포함되어 있습니다. Run:AI 오케스트레이션 솔루션과 NetApp AI Control Plane은 최적의 리소스 활용을 통해 개발자 생산성을 향상하여 혁신을 위한 시간을 단축합니다.</block>
  <block id="892726726d592ee18c9ee8ad25a088ae" category="inline-link-macro">다음: 핵심 요약</block>
  <block id="e6c479abab08e982bd2f0efd6e3e405a" category="paragraph"><block ref="e6c479abab08e982bd2f0efd6e3e405a" category="inline-link-macro-rx"></block></block>
  <block id="0e85d8fd0ce7acdba87f57325a14b3fb" category="summary">이전 섹션에서 언급한 바와 같이, 두 개 이상의 기계 학습 모델이 순서대로 실행될 때마다 오류가 파이프라인 전체에 전파됩니다. 이 솔루션을 위해, 이 회사의 주식 리스크 수준을 측정하는 데 있어 가장 중요한 요소는 문장의 감정입니다. 파이프라인에 필수적인 스피치-텍스트 모델은 정서를 예측할 수 있는 전처리부 역할을 합니다.</block>
  <block id="6700d3710d10e74d6e48f994b760d48b" category="doc">검증 결과</block>
  <block id="ee4eec78ae095f539af53c130e976afa" category="inline-link-macro">이전: 지원 센터 감정 분석 구축</block>
  <block id="ac96c8f3af95b93c2683c2124998e668" category="paragraph"><block ref="ac96c8f3af95b93c2683c2124998e668" category="inline-link-macro-rx"></block></block>
  <block id="2e10a4ae90aad11c07592a14fbf8c5c6" category="paragraph">이전 섹션에서 언급한 바와 같이, 두 개 이상의 기계 학습 모델이 순서대로 실행될 때마다 오류가 파이프라인 전체에 전파됩니다. 이 솔루션을 위해, 이 회사의 주식 리스크 수준을 측정하는 데 있어 가장 중요한 요소는 문장의 감정입니다. 파이프라인에 필수적인 스피치-텍스트 모델은 정서를 예측할 수 있는 전처리부 역할을 합니다. 진짜 중요한 것은 근거 있는 진실과 예측된 문장 사이의 감정의 차이이다. 이는 WER(Error Rate)의 프록시 역할을 합니다. 음성-텍스트 정확도는 중요하지만 WER은 최종 파이프라인 메트릭에 직접 사용되지 않습니다.</block>
  <block id="0fc4c7871adf5db8dd2b13fc4c381da8" category="paragraph">이러한 정서 메트릭은 각 문장의 F1 점수, 리콜 및 정밀도에 대해 계산할 수 있습니다. 그런 다음 결과를 집계하여 각 메트릭의 신뢰 간격과 함께 혼란 매트릭스 내에 표시할 수 있습니다.</block>
  <block id="66554c8f1474c5658d17e23710901f98" category="paragraph">전송 학습 기능을 사용하면 적은 데이터 요구사항, 교육 시간 및 비용으로 모델 성능을 향상할 수 있습니다. 또한 세부 조정된 모델을 기준 버전과 비교하여 전송 학습이 페어링되지 않고 성능을 향상시키도록 해야 합니다. 다시 말해, 세부 조정된 모델은 사전 교육 모델보다 지원 센터 데이터의 성능이 더 우수해야 합니다.</block>
  <block id="6e979ee914c9401fddd049d16cdef66a" category="section-title">파이프라인 평가</block>
  <block id="7f109f66c71a1fd15436d1c413354c41" category="cell">테스트 케이스</block>
  <block id="e7f1ec3a5f35af805407a8a531eefb79" category="cell">테스트 번호</block>
  <block id="6bf1af9a7f1b6dd6cca4b7434097ad94" category="cell">파이프라인 정서 지표</block>
  <block id="beed3529b961c63b785104d7a17cf5f4" category="cell">테스트 필수 구성 요소</block>
  <block id="c7320b1f70fd8a9831e530d17a82f34d" category="cell">음성-텍스트 및 정서 분석 모델을 위해 미세 조정된 모델</block>
  <block id="9d5b1bc6dcdedf0c8750e543fab75738" category="cell">예상 결과</block>
  <block id="74015a89b882f01e94433a9c1f1c904c" category="cell">미세 조정된 모델의 정서 측정 기준은 원래 사전 교육 모델보다 성능이 뛰어납니다.</block>
  <block id="68d279a19e31962e0ab0b648f25c07ee" category="list-text">기준 모델의 정서 메트릭을 계산합니다.</block>
  <block id="b6168629c9e5a47b0637aa362112642d" category="list-text">미세 조정된 모델의 정서 메트릭을 계산합니다.</block>
  <block id="97ae5da5f745d90cf815a206b3549e0a" category="list-text">이러한 메트릭 간의 차이를 계산합니다.</block>
  <block id="fc997f472d1b5e66aadb364e10c29f4f" category="list-text">모든 문장에 걸친 평균 차이입니다.</block>
  <block id="c6b3b1378b2e31169a4a1cd4c20691c8" category="inline-link-macro">다음: 비디오 및 데모</block>
  <block id="6016219a0b0ad0bb3594f964b5e6396d" category="paragraph"><block ref="6016219a0b0ad0bb3594f964b5e6396d" category="inline-link-macro-rx"></block></block>
  <block id="9d273bd32c1fceb91b7d6a4d40e98bdd" category="doc">소프트웨어 요구 사항</block>
  <block id="8e926487edd9348114ada5fa88a732df" category="paragraph">이 솔루션은 Run:AI 운영자가 설치된 기본 Kubernetes 구축을 사용하여 검증되었습니다. Kubernetes는 를 사용하여 구축했습니다<block ref="1c894f7463797b81796e78efc8345fb0" category="inline-link-rx"></block> 구축 엔진: 즉시 프로덕션할 수 있는 환경에 필요한 모든 구성 요소를 배포합니다. DeepOps가 자동으로 배포됩니다<block ref="ca1c90879f9a0e8dc4ff805fb398f7ff" category="inline-link-rx"></block> 스토리지를 K8s 환경과 지속적으로 통합하고 기본 스토리지 클래스를 만들어 컨테이너가 AFF A800 스토리지 시스템에서 스토리지를 활용하도록 했습니다. ONTAP AI 기반 Kubernetes를 사용하는 Trident에 대한 자세한 내용은 를 참조하십시오<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block>.</block>
  <block id="a2525584dd9d2a9522ddea95841c06b3" category="cell">9.6p4</block>
  <block id="4a5be8fea83a32ad5c7fc31b02ef1028" category="cell">4.0.4 - Ubuntu 18.04 LTS</block>
  <block id="80afba45eb055fc9bdc48c90d1debd06" category="cell">Kubernetes 버전</block>
  <block id="4bbe90408850f459864a71c8054732f1" category="cell">1.17</block>
  <block id="f1112223b41fddc71fd6a626582dfb78" category="cell">Trident 버전</block>
  <block id="43d66966083b0e0feac8fb9be14ba5b8" category="cell">20.04.0</block>
  <block id="e993176eed424766bc6bd4758eaf2cb6" category="cell">실행: AI CLI</block>
  <block id="5e6305186adf6e7dcf03f5cbfc802c49" category="cell">v2.1.13</block>
  <block id="f3eeed8e4b2791f80e2f123c4720aef5" category="cell">실행: AI Orchestration Kubernetes Operator version</block>
  <block id="bf8c2933a2f54ce25fe986f66d3bffa3" category="cell">1.0.39</block>
  <block id="0cc9a8e76e0a79d0e0072e0a0d675fe5" category="cell">18.06.1-CE[e68fc7a]</block>
  <block id="076ca75e2fc5b6ea85d72b0a9adc8844" category="inline-link">AI GPU 클러스터의 사전 요구사항 을 실행하십시오</block>
  <block id="eaec7f01752b17abf6125d8f29a8543c" category="paragraph">Run:AI에 대한 추가 소프트웨어 요구사항은 에서 확인할 수 있습니다<block ref="98bb21d82bcd499a183c82dcfc9b02f3" category="inline-link-rx"></block>.</block>
  <block id="cc352f05f03c970b081b8afa29693b60" category="inline-link-macro">다음: AI 실행을 통한 최적의 클러스터 및 GPU 활용률</block>
  <block id="f7235eb2146d800446cbbbac3a57548c" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block>.</block>
  <block id="9a50201aa3bf66a7a0337ccf29d20c90" category="doc">솔루션 기술</block>
  <block id="ed4a202c34987f40d5e245e76a65a243" category="paragraph">다음 그림에서는 제안한 대화형 AI 시스템 아키텍처를 보여 줍니다. 음성 신호 또는 텍스트 입력으로 시스템과 상호 작용할 수 있습니다. 음성 입력이 감지되면 Jarvis AIaaS(AI-as-service)가 ASR을 수행하여 Dialog Manager에 대한 텍스트를 생성합니다. 대화 관리자는 대화 상태를 기억하고, 텍스트를 해당 서비스로 라우팅하고, 명령을 이행 엔진에 전달합니다. Jarvis NLP 서비스는 텍스트를 가져와 인텐트와 엔터티를 인식하고 이러한 인텐트와 엔터티 슬롯을 다시 대화 상자 매니저로 출력한 다음 작업을 이행 엔진에 보냅니다. 이행 엔진은 사용자 쿼리에 응답하는 타사 API 또는 SQL 데이터베이스로 구성됩니다. 이행 엔진에서 결과를 수신한 후 대화 상자 관리자는 텍스트를 Jarvis TTS AIaaS로 라우팅하여 최종 사용자에 대한 오디오 응답을 생성합니다. 대화 기록을 보관하고, intents와 nemo 교육 슬롯을 사용해 문장에 주석을 달 수 있습니다. 그러면 NLP 서비스가 시스템과 상호 작용하는 사용자가 많아질수록 성능이 향상됩니다.</block>
  <block id="308a0722262fbc3adde5d5d900ad0c36" category="paragraph"><block ref="308a0722262fbc3adde5d5d900ad0c36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="863eef2617ffc374c485389aabdd8a24" category="paragraph">이 솔루션은 하나의 DGX Station과 하나의 AFF A220 스토리지 시스템을 사용하여 검증되었습니다. Jarvis는 딥 신경 네트워크 계산을 수행하려면 T4 또는 V100 GPU가 필요합니다.</block>
  <block id="71c9e70899509bff35197ba9da10dafc" category="cell">T4 또는 V100 GPU</block>
  <block id="8f452959667e7665cddf2484ddca1724" category="cell">NVIDIA DGX 스테이션</block>
  <block id="f7a05af899e536cde0a9c8476c2da0a1" category="paragraph">다음 표에는 테스트를 통해 솔루션을 구현하는 데 필요한 소프트웨어 구성요소가 나와 있습니다.</block>
  <block id="eaf2f97729e8d5e4d205672da8afc9a5" category="cell">9.6</block>
  <block id="0664d9eb73230b2a0b514b0facae8ade" category="cell">NVIDIA Jarvis 프레임워크</block>
  <block id="cc5f21cb121669006a19c9fde049f048" category="cell">EA v0.2</block>
  <block id="dfcc0491fc5a6e738ca8b5ef3a258093" category="cell">NVIDIA 니모</block>
  <block id="317fe32bf712dffb43ddc0ee8dde8c3c" category="cell">nvcr.io/nvidia/nemo:v0.10</block>
  <block id="3032d0de2852f0bb1e13142c2c47cd5b" category="inline-link-macro">다음: Jarvis, Cloud Sync 및 Nemo 개요를 사용하여 가상 도우미를 만듭니다</block>
  <block id="5cefb81f0324c44ec13c02fa7700924b" category="paragraph"><block ref="5cefb81f0324c44ec13c02fa7700924b" category="inline-link-macro-rx"></block></block>
  <block id="b831e128b8fd177e9c80396ed741b7c1" category="doc">하드웨어 및 소프트웨어 요구 사항</block>
  <block id="afee48a46dd68b9618cec81a8ee5ba86" category="paragraph">이 섹션에서는 ONTAP AI 솔루션의 기술 요구사항을 다룹니다.</block>
  <block id="e96b7604f8b75ae786c6c0e1016e46fd" category="inline-link">ONTAP AI 웹 사이트</block>
  <block id="929f5f13d86d1be55b96dba26e773c6f" category="paragraph">하드웨어 요구사항은 특정 고객 워크로드에 따라 다르지만, ONTAP AI는 대규모 ML/DL 작업을 위해 단일 GPU에서 랙 확장 구성까지 데이터 엔지니어링, 모델 훈련, 운영 추론을 위해 어떤 확장하고 구축할 수 있습니다. ONTAP AI에 대한 자세한 내용은 를 참조하십시오<block ref="7ec9b089c41da1b986bad97e1099df1c" category="inline-link-rx"></block>.</block>
  <block id="41e840b508d9e839f95d16dd582af8d6" category="paragraph">이 솔루션은 컴퓨팅, NetApp AFF A800 스토리지 시스템 및 Cisco Nexus 3232C 네트워크 연결을 위해 DGX-1 시스템을 사용하여 검증되었습니다. 이 검증에 사용된 AFF A800은 대부분의 ML/DL 워크로드에 대해 최대 10개의 DGX-1 시스템을 지원할 수 있습니다. 다음 그림은 이 검증에서 모델 훈련에 사용되는 ONTAP AI 토폴로지를 보여줍니다.</block>
  <block id="bc2eb92d1e1797a759b677c38f619a8f" category="paragraph"><block ref="bc2eb92d1e1797a759b677c38f619a8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d98e5c43e7b3be89fe8a9076f89f1e99" category="paragraph">이 솔루션을 퍼블릭 클라우드로 확장하려면 Cloud Volumes ONTAP을 클라우드 GPU 컴퓨팅 리소스와 함께 구축하고 하이브리드 클라우드 데이터 패브릭에 통합하면 모든 워크로드에 적합한 리소스를 사용할 수 있습니다.</block>
  <block id="4dc70b997a39a64b2def3ef74a96fdb4" category="paragraph">다음 표는 이 솔루션 검증에 사용된 특정 소프트웨어 버전을 보여줍니다.</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">구성 요소</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">우분투</block>
  <block id="d173e10eb6a0fc7969fe540c987e0c7d" category="cell">18.04.4 LTS</block>
  <block id="9b4bffa460105781f82b1d463bde8200" category="cell">4.4.0</block>
  <block id="3c1d47ba5c1ada327abd4532ff9f4437" category="cell">20.02.1</block>
  <block id="0083e57a258edd18b949d3afbf6cfc2a" category="cell">1.15</block>
  <block id="232de5556d4148d75b55012e1230616c" category="cell">3.1.0</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="cell">NetApp ONTAP를 참조하십시오</block>
  <block id="d8a31094f88724af6834c47a6697dc56" category="cell">9.6P4</block>
  <block id="9909115a4f9fe32731077286c367501c" category="paragraph">이 솔루션 검증에서 Kubernetes는 DGX-1 시스템에서 단일 노드 클러스터로 구축되었습니다. 대규모 배포의 경우 관리 서비스의 고가용성을 제공하고 ML 및 DL 워크로드에 대한 중요한 DGX 리소스를 예약하려면 독립 Kubernetes 마스터 노드를 구축해야 합니다.</block>
  <block id="1c428dd76324aae91879799ae73fbc37" category="inline-link-macro">다음: 솔루션 배포 및 검증 세부 정보</block>
  <block id="5e5761a91dc25c881f4ca86678634b1b" category="paragraph"><block ref="5e5761a91dc25c881f4ca86678634b1b" category="inline-link-macro-rx"></block></block>
  <block id="d7cd7846436814deb26b0df06d7a4b2a" category="summary">Kubernetes 클러스터에서 동기식 다중 노드 AI 및 ML 작업을 실행하려면 배포 점프 호스트에서 이 페이지에 나열된 작업을 수행하십시오. 이 프로세스를 통해 NetApp 볼륨에 저장된 데이터를 활용하고 단일 작업자 노드가 제공할 수 있는 것보다 더 많은 GPU를 사용할 수 있습니다.</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">동기식 분산 AI 워크로드 실행</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Kubernetes 클러스터에서 동기식 다중 노드 AI 및 ML 작업을 실행하려면 배포 점프 호스트에서 다음 작업을 수행하십시오. 이 프로세스를 통해 NetApp 볼륨에 저장된 데이터를 활용하고 단일 작업자 노드가 제공할 수 있는 것보다 더 많은 GPU를 사용할 수 있습니다. 동기식 분산 AI 작업을 설명하는 방법은 다음 그림을 참조하십시오.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">동기 분산 작업은 비동기 분산 작업에 비해 성능 및 교육 정확도를 높일 수 있습니다. 동기 작업과 비동기 작업의 장단점을 논하는 것은 이 문서의 범위를 벗어납니다.</block>
  <block id="262523fcbe6eb0ec96ea58299e58f65c" category="paragraph"><block ref="262523fcbe6eb0ec96ea58299e58f65c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a9af10e4883efa64de927027b5b0ffa" category="list-text">다음 명령 예는 섹션의 예에서 단일 노드에서 실행된 동일한 TensorFlow 벤치마크 작업의 동기식 분산 실행에 참여하는 작업자 1명의 생성을 보여 줍니다 <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>. 이 특정 예제에서는 작업이 두 작업자 노드에 걸쳐 실행되므로 한 명의 작업자만 배포됩니다.</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">이 작업자 배포는 8개의 GPU를 요청하므로 8개 이상의 GPU를 갖춘 단일 GPU 작업자 노드에서 실행할 수 있습니다. GPU 작업자 노드에서 8개 이상의 GPU를 사용하여 성능을 극대화한 경우, 이 숫자를 작업자 노드가 갖춘 GPU 수와 같게 늘리고 싶을 수 있습니다. Kubernetes 구축에 대한 자세한 내용은 를 참조하십시오<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>.</block>
  <block id="bfe89db11adc9a38165e670f3062d398" category="paragraph">이 예에서는 특정 컨테이너형 작업자가 자체적으로 완료되지 않기 때문에 Kubernetes 구축이 생성됩니다. 따라서 Kubernetes 작업 구성을 사용하여 구축하는 것은 타당하지 않습니다. 작업자가 혼자서 완료되도록 설계되거나 작성된 경우 작업 구성을 사용하여 작업자를 배포하는 것이 합리일 수 있습니다.</block>
  <block id="05bdf5435b916b7b205f448788324f2b" category="paragraph">이 예제 배포 사양에 지정된 POD에 "true"의 "hostNetwork" 값이 제공됩니다. 이 값은 이 Pod가 일반적으로 Kubernetes에서 각 Pod에 생성하는 가상 네트워킹 스택 대신 호스트 작업자 노드의 네트워킹 스택을 사용한다는 것을 의미합니다. 이 경우 특정 워크로드는 개방형 MPI, NCCL 및 Horovod를 통해 동기식 분산 방식으로 워크로드를 실행하기 때문에 이 주석이 사용됩니다. 따라서 호스트 네트워킹 스택에 액세스해야 합니다. 공개 MPI, NCCL 및 Horovod에 대한 논의는 이 문서의 범위를 벗어납니다. 이 "hostNetwork: true" 주석이 필요한지 여부는 실행 중인 특정 워크로드의 요구 사항에 따라 달라집니다. hostNetwork 필드에 대한 자세한 내용은 를 참조하십시오<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>.</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">1단계에서 만든 작업자 배포가 성공적으로 시작되었는지 확인합니다. 다음 예제 명령은 배포 정의에 나와 있는 것처럼 단일 작업자 POD가 배포용으로 생성되었으며 이 POD가 현재 GPU 작업자 노드 중 하나에서 실행되고 있음을 확인합니다.</block>
  <block id="3ba975f6a7389af18602f0e938bcc37b" category="list-text">동기 다중 노드 작업의 실행을 종료, 참여 및 추적하는 마스터에 대한 Kubernetes 작업을 생성합니다. 다음 명령 예에서는 이 섹션의 예제에서 단일 노드에서 실행된 것과 동일한 TensorFlow 벤치마크 작업의 동기식 분산 실행을 시작, 참여 및 추적하는 하나의 마스터를 생성합니다 <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>.</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">이 마스터 작업에서는 8개의 GPU를 요청하므로 8개 이상의 GPU를 갖춘 단일 GPU 작업자 노드에서 실행할 수 있습니다. GPU 작업자 노드에서 8개 이상의 GPU를 사용하여 성능을 극대화한 경우, 이 숫자를 작업자 노드가 갖춘 GPU 수와 같게 늘리고 싶을 수 있습니다.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">이 예에서 지정한 마스터 포드는 1단계에서 작업자 포드가 hostNetwork 값이 true인 것처럼 true의 hostNetwork 값이 지정됩니다. 이 값이 필요한 이유에 대한 자세한 내용은 1단계를 참조하십시오.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">3단계에서 만든 마스터 작업이 올바르게 실행되고 있는지 확인합니다. 다음 예제 명령은 작업 정의에 나와 있는 것처럼 작업에 대해 단일 마스터 포드가 생성되었으며 이 포드가 현재 GPU 작업자 노드 중 하나에서 실행되고 있음을 확인합니다. 또한 1단계에서 처음 보았던 작업자 포드가 여전히 실행 중이고 마스터 포드와 작업자 포드가 다른 노드에서 실행되고 있음을 확인해야 합니다.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">3단계에서 만든 마스터 작업이 성공적으로 완료되었는지 확인합니다. 다음 명령 예에서는 작업이 성공적으로 완료되었음을 확인합니다.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">작업자 배포가 더 이상 필요하지 않으면 삭제합니다. 다음 예제 명령은 1단계에서 만든 작업자 배포 개체를 삭제하는 방법을 보여 줍니다.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">작업자 배포 개체를 삭제하면 Kubernetes에서 연결된 작업자 포드를 자동으로 삭제합니다.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">* 선택 사항: * 마스터 작업 아티팩트를 정리하십시오. 다음 예제 명령은 3단계에서 만든 마스터 작업 오브젝트의 삭제를 보여 줍니다.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">마스터 작업 개체를 삭제하면 연결된 마스터 포드가 자동으로 삭제됩니다.</block>
  <block id="256fbc599203bd1bd63bfe25b7a5b9ad" category="inline-link-macro">다음: 성능 테스트.</block>
  <block id="35bb3345a07dfa439dd6936ea8f69faf" category="paragraph"><block ref="35bb3345a07dfa439dd6936ea8f69faf" category="inline-link-macro-rx"></block></block>
  <block id="e7446d382d8184be0a342a2fc45d4394" category="doc">WP-7328: NVIDIA Jarvis를 사용하는 NetApp 대화형 AI</block>
  <block id="5dabc617366db74ce2a9fa3915f6af5a" category="paragraph">Rick Huang, Sung-Han Lin, NetApp Davide Onfrio, NVIDIA</block>
  <block id="018aacc6ea95e20996bf57b319fd037a" category="paragraph">NVIDIA DGX 시스템 제품군은 엔터프라이즈 AI용으로 특별 제작된 세계 최초의 통합 인공 지능(AI) 기반 시스템으로 구성되어 있습니다. NetApp AFF 스토리지 시스템은 탁월한 성능과 업계 최고 수준의 하이브리드 클라우드 데이터 관리 기능을 제공합니다. NetApp과 NVIDIA는 협력 관계를 맺고 엔터프라이즈급 성능, 안정성 및 지원을 제공하는 AI 및 머신 러닝(ML) 워크로드를 위한 턴키 솔루션인 NetApp ONTAP AI 참조 아키텍처를 구축했습니다.</block>
  <block id="1a76c739ce37834495a22c5db663d24b" category="paragraph">이 백서에서는 다양한 산업 분야의 다양한 사용 사례를 지원하는 대화 AI 시스템을 구축하는 고객에게 직접 지침을 제공합니다. NVIDIA Jarvis를 사용하는 시스템 구축에 대한 정보를 제공합니다. 테스트는 NVIDIA DGX Station 및 NetApp AFF A220 스토리지 시스템을 사용하여 수행되었습니다.</block>
  <block id="f813bd56d696cb8de386a53a37eed6f6" category="list-text">가상 소매 비서 등의 대화형 AI 사용 사례를 위한 AI 모델 및 소프트웨어 개발을 위한 솔루션을 설계하는 엔터프라이즈 설계자</block>
  <block id="0497dfe9ff978e87977c978d3443e206" category="list-text">언어 모델링 개발 목표를 달성하기 위한 효율적인 방법을 찾고 있는 데이터 과학자</block>
  <block id="e84c345e30f668aa19a041e2e12bc9fe" category="list-text">고객 질문 및 대화 내용 등 텍스트 데이터의 유지 관리 및 처리를 담당하는 데이터 엔지니어</block>
  <block id="00101e6b2bf526b1ee79d39389f461fa" category="list-text">대화형 AI 경험을 바꾸고 AI 이니셔티브를 통해 출시 시기를 앞당기고자 하는 경영진 및 IT 의사 결정자 및 비즈니스 리더</block>
  <block id="88851610d9d91a7b78ab814276bebba7" category="paragraph"><block ref="88851610d9d91a7b78ab814276bebba7" category="inline-link-macro-rx"></block></block>
  <block id="1a7fa7cc4c79d5163f691ff60e6fc34d" category="doc">실행: AI 대시보드 및 뷰</block>
  <block id="3473dab452c5446b1a01a923e9879461" category="paragraph">Run:AI를 Kubernetes 클러스터에 설치하고 컨테이너를 올바르게 구성하면 에 다음과 같은 대시보드와 뷰가 표시됩니다<block ref="2af90fde6f4d8ae5947b005d1208e742" category="inline-link-rx"></block> 다음 그림과 같이 브라우저에서</block>
  <block id="f977554b7762214959db36c20484c697" category="paragraph"><block ref="f977554b7762214959db36c20484c697" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dfd99441ce89d4be896e4fc9757f7d2" category="paragraph">2개의 DGX-1 노드에서 제공하는 클러스터에 총 16개의 GPU가 있습니다. 노드 수, 총 사용 가능한 GPU, 워크로드와 할당된 할당된 할당된 GPU, 총 실행 중인 작업 수, 보류 중인 작업 및 유휴 할당 GPU를 볼 수 있습니다. 오른쪽의 막대 다이어그램에서는 프로젝트당 GPU를 보여 주며, 각 팀이 클러스터 리소스를 사용하는 방법을 요약합니다. 가운데는 작업 이름, 프로젝트, 사용자, 작업 유형, 각 작업이 실행 중인 노드, 해당 작업에 할당된 GPU 수, 작업의 현재 실행 시간, 작업의 작업 진행 상태, 해당 작업의 GPU 사용률 단일 팀('team-A')이 제출한 실행 중인 작업이 3개뿐이므로 클러스터 사용률이 낮은 상태(GPU 사용률이 23%)입니다.</block>
  <block id="67545e2efac33412706ff883eff2e1c4" category="paragraph">다음 섹션에서는 프로젝트 탭에서 여러 팀을 생성하고 각 팀에 GPU를 할당하여 클러스터당 사용자가 많을 때 클러스터 사용을 최대화하고 리소스를 관리하는 방법을 보여줍니다. 테스트 시나리오는 훈련, 추론 및 대화형 워크로드 간에 메모리 및 GPU 리소스가 공유되는 엔터프라이즈 환경을 모방합니다.</block>
  <block id="73eea118e4762640a7f60136f3e5c1a0" category="inline-link-macro">다음으로, 데이터 과학 팀을 위한 프로젝트 생성 및 GPU 할당</block>
  <block id="7c2c470385b4f61a9e9b5b0881d2f061" category="paragraph"><block ref="7c2c470385b4f61a9e9b5b0881d2f061" category="inline-link-macro-rx"></block></block>
  <block id="ae6f5747bf29f889c1d28208afab2a1a" category="doc">응용 프로그램 배포</block>
  <block id="cef52206f11ced919c8d0dd4b2c791a4" category="paragraph">다음 섹션에서는 응용 프로그램을 설치하고 배포하는 방법에 대해 설명합니다.</block>
  <block id="d0954433c0b62861850b87d9cba7599f" category="inline-link-macro">다음: GitHub에서 코드를 가져옵니다</block>
  <block id="255a6bf7e1d34563f76daaf2b6cd6184" category="paragraph"><block ref="26e27ac56fb4c03c9632ab9bd4fc068b" category="inline-link-macro-rx"></block>.</block>
  <block id="39cf3ca3e5dbe56d6eade7cbe3cc40e6" category="doc">Kubeflow 작업 및 작업 예</block>
  <block id="368c8f521d74a015b7a3e1a46c8847b1" category="paragraph">이 섹션에서는 Kubeflow를 사용하여 수행할 수 있는 다양한 작업 및 작업의 예를 제공합니다.</block>
  <block id="bdbf5a5e65f2cf7435dfcea294400b35" category="inline-link-macro">다음: 데이터 과학자 또는 개발자 사용을 위해 Jupyter Notebook Workspace를 프로비저닝합니다.</block>
  <block id="86e512bbf34bd396dd043a14ff2027ec" category="paragraph"><block ref="86e512bbf34bd396dd043a14ff2027ec" category="inline-link-macro-rx"></block></block>
  <block id="820423ca1ad0e872ef04cbb366b6e3de" category="paragraph">NetApp과 Iguazio는 이러한 기술을 관리형 서비스로 결합하여 기술 채택을 가속하고 새로운 AI/ML 애플리케이션의 출시 시기를 앞지였습니다.</block>
  <block id="b0a9c7dc36cb18f93679b833533b9936" category="paragraph"><block ref="b0a9c7dc36cb18f93679b833533b9936" category="inline-link-macro-rx"></block></block>
  <block id="d3202b7eec66185e032fcad76b4c2aa3" category="paragraph"><block ref="d3202b7eec66185e032fcad76b4c2aa3" category="inline-link-macro-rx"></block></block>
  <block id="27a5a0a02525fbb66788e119b829fe28" category="list-text">Azure NetApp Files:</block>
  <block id="45bd81d391ee3bd9831a237bff32b2c1" category="list-text">Azure NetApp Files용 솔루션 아키텍처 페이지</block>
  <block id="57b815cb2da0c842a09d5ef586792c0a" category="inline-link"><block ref="57b815cb2da0c842a09d5ef586792c0a" category="inline-link-rx"></block></block>
  <block id="02508d077a7c6fbe1035568c37610d22" category="paragraph"><block ref="02508d077a7c6fbe1035568c37610d22" category="inline-link-rx"></block></block>
  <block id="f42fced7b7a9bfef49a209632add6f80" category="list-text">컨테이너용 Trident 영구 스토리지:</block>
  <block id="158e66cfa121c58b072656402170ca60" category="list-text">Azure NetApp Files 및 Trident</block>
  <block id="d9fe72ef646d82c8372b45ff009726a2" category="inline-link"><block ref="d9fe72ef646d82c8372b45ff009726a2" category="inline-link-rx"></block></block>
  <block id="e3c781df174a80c19c70a938b96db93a" category="paragraph"><block ref="e3c781df174a80c19c70a938b96db93a" category="inline-link-rx"></block></block>
  <block id="145f2a04d99fdbd7a450ef83e82d471b" category="list-text">Dask 및 RAPIDS:</block>
  <block id="df5eb1591e808e358e02221e1e0111e6" category="list-text">Dask(질문)</block>
  <block id="7db6639777894f081a3d7c055b97900a" category="inline-link"><block ref="7db6639777894f081a3d7c055b97900a" category="inline-link-rx"></block></block>
  <block id="4846c68fb34aec3b1b7b7de96d27e71f" category="paragraph"><block ref="4846c68fb34aec3b1b7b7de96d27e71f" category="inline-link-rx"></block></block>
  <block id="41563f9620e92fbfd1e105e32ac297e4" category="list-text">Dask를 설치합니다</block>
  <block id="8659b02378fc9b47aac4428f69411abc" category="inline-link"><block ref="8659b02378fc9b47aac4428f69411abc" category="inline-link-rx"></block></block>
  <block id="972dffc891589785367dd3581a5abcef" category="paragraph"><block ref="972dffc891589785367dd3581a5abcef" category="inline-link-rx"></block></block>
  <block id="3ba7abeba4fd0f5d5ca9072155319afd" category="list-text">Dask API</block>
  <block id="f7673aa4f6b36ba9952cef7c98115776" category="inline-link"><block ref="f7673aa4f6b36ba9952cef7c98115776" category="inline-link-rx"></block></block>
  <block id="d43a23bd530cae7ba37a2e0ed6513bad" category="paragraph"><block ref="d43a23bd530cae7ba37a2e0ed6513bad" category="inline-link-rx"></block></block>
  <block id="1bfabf7fb7bf05567331dfc3d20c4921" category="list-text">Dask 기계 학습</block>
  <block id="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link"><block ref="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link-rx"></block></block>
  <block id="d05f63d77306100c615132f350f3fafe" category="paragraph"><block ref="d05f63d77306100c615132f350f3fafe" category="inline-link-rx"></block></block>
  <block id="90223e93e145939c9954970520e1767a" category="list-text">Dask 분산 진단</block>
  <block id="e7252fe9d67234e05be7dc251c48cf74" category="inline-link"><block ref="e7252fe9d67234e05be7dc251c48cf74" category="inline-link-rx"></block></block>
  <block id="925c8b588cf5ae5fc486494a21fba8ac" category="paragraph"><block ref="925c8b588cf5ae5fc486494a21fba8ac" category="inline-link-rx"></block></block>
  <block id="d97adf46c9b097cad5eff54e3b65a21f" category="paragraph"><block ref="d97adf46c9b097cad5eff54e3b65a21f" category="inline-link-rx"></block></block>
  <block id="528d52adf23d34a248f0b9bf684c1832" category="paragraph"><block ref="528d52adf23d34a248f0b9bf684c1832" category="inline-link-rx"></block></block>
  <block id="a43c7ca8f7e6a4a034f6a940ec7566f5" category="inline-link-macro">다음: 버전 기록.</block>
  <block id="5f751f93279ebf35ea83b9aa80ef02df" category="paragraph"><block ref="5f751f93279ebf35ea83b9aa80ef02df" category="inline-link-macro-rx"></block></block>
  <block id="1e92efa8f46c28a3c3a1c03ababfa7be" category="doc">NetApp Retail Assistant 데모</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">이 링크</block>
  <block id="bb07f1ff94c6f99bf48a403706bea4ca" category="paragraph">NetApp Retail Assistant(Nara)의 데모 비디오를 녹화했습니다. 을 클릭합니다<block ref="c1305d6e7f2e06345748f63e36abba33" category="inline-link-rx"></block> 다음 그림을 열고 비디오 데모를 재생합니다.</block>
  <block id="088070f65f454d6b38e8e40e332e70a8" category="paragraph"><block ref="088070f65f454d6b38e8e40e332e70a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d81ccbd202a60c621000abca3f6f3de" category="inline-link-macro">다음: NetApp Cloud Sync를 사용하여 대화 내용 아카이빙</block>
  <block id="a165baa9089720dc90e8baf16267821f" category="paragraph"><block ref="a165baa9089720dc90e8baf16267821f" category="inline-link-macro-rx"></block></block>
  <block id="45ce76bfe721ca13d37ca15fdbebd391" category="paragraph">저자는 NVIDIA의 존경받는 동료 Davide Onofrio, Alex Qi, Sicong Ji, Marty Jain 및 Robert Sohigian이 이 백서에 기여한 바를 진심으로 인정합니다. 또한 NetApp의 주요 팀원 중 Santosh Rao, David Arnette, Michael Oglesby, Brent Davis, Andy Sayare의 기여에 대해 인정하고자 합니다. Erik Mulder와 Mike McNamara가 함께 합니다.</block>
  <block id="81fbc4247f2c3a990b090cef6b9ebe03" category="paragraph">본 문서를 작성하는 데 큰 도움이 되는 통찰과 전문 지식을 제공해주신 모든 분에게 진심으로 감사합니다.</block>
  <block id="bc2f62a5c14dc9d16f38cc32c304164c" category="paragraph"><block ref="bc2f62a5c14dc9d16f38cc32c304164c" category="inline-link-macro-rx"></block></block>
  <block id="6f7f6c0b1054487e622896990b1d6d55" category="doc">TR-4841: 데이터 캐싱을 지원하는 하이브리드 클라우드 AI 운영 체제</block>
  <block id="1b55e21d5b19a6ba57ae9bbd6f3a0630" category="paragraph">Rick Huang, David Arnette, NetApp Yochay Ettun, cnvrg.io</block>
  <block id="28d9fd6fa10254fdcc59aa182ae32dc9" category="paragraph">데이터의 폭발적인 증가와 ML 및 AI의 기하급수적인 성장으로 인해 고유한 개발 및 구현 과제를 가진 제타바이트 경제성이 창출되었습니다.</block>
  <block id="eb35f773ff882afb6d6d67613a4701ee" category="paragraph">머신 러닝 모델은 데이터를 많이 필요로 하며 컴퓨팅 리소스 가까이에 고성능 데이터 스토리지가 필요한 것으로 널리 알려져 있지만, 실제로 하이브리드 클라우드 및 탄력적인 컴퓨팅 인스턴스 구축을 위해 이러한 모델을 구현하는 것은 그리 간단하지 않습니다. 일반적으로 대량의 데이터가 GPU와 같은 고성능 AI 컴퓨팅 리소스가 효율적으로 액세스할 수 없는 저비용 데이터 레이크에 저장됩니다. 일부 워크로드가 클라우드에서 작동하고 일부는 사내 또는 다른 HPC 환경에 완전히 있는 하이브리드 클라우드 인프라에서는 이 문제가 더욱 가중됩니다.</block>
  <block id="2b8ab86ccf473cca225e50ddb8c47e25" category="paragraph">이 문서에서는 IT 전문가와 데이터 엔지니어가 토폴로지 인식 데이터 허브로 진정한 하이브리드 클라우드 AI 플랫폼을 구축하여 데이터 과학자가 컴퓨팅 리소스 가까이에 있는 데이터 세트의 캐시를 즉시 자동으로 생성할 수 있는 새로운 솔루션을 소개합니다. 있습니다. 그 결과, 고성능 모델 훈련을 수행할 수 있을 뿐만 아니라 데이터 세트 버전 허브 내에서 데이터 세트 캐시, 버전 및 계모델에 즉시 액세스할 수 있는 여러 AI 전문가의 협업을 비롯한 추가 이점을 얻을 수 있습니다.</block>
  <block id="3bc3b194b0ef70e2e6ce113f819619c4" category="inline-link-macro">다음: 사용 사례 개요 및 문제 설명</block>
  <block id="3eb8a6b81400ec3a497fb59a7e6f4360" category="paragraph"><block ref="3eb8a6b81400ec3a497fb59a7e6f4360" category="inline-link-macro-rx"></block></block>
  <block id="dbb4dd9a11f48db13d63eedaae717fe5" category="doc">데이터 과학 팀을 위한 프로젝트 생성 및 GPU 할당</block>
  <block id="22d09d229a06f294b0f45804f8e639d3" category="paragraph">연구원들은 Run:AI CLI, Kubeflow 또는 유사한 프로세스를 통해 워크로드를 제출할 수 있습니다. 리소스 할당을 간소화하고 우선 순위를 만들기 위해 Run:AI에는 프로젝트의 개념이 도입되었습니다. 프로젝트는 프로젝트 이름을 GPU 할당 및 기본 설정과 연결하는 할당량 요소입니다. 여러 데이터 과학 팀을 관리할 수 있는 간단하고 편리한 방법입니다.</block>
  <block id="c0bd05e9d88cf015eac684873bfd14c7" category="paragraph">워크로드를 제출하는 연구원은 프로젝트를 워크로드 요청과 연계해야 합니다. Run:AI 스케줄러는 요청을 현재 할당 및 프로젝트와 비교하여 워크로드에 리소스를 할당할 수 있는지 또는 보류 중 상태를 유지해야 하는지 여부를 결정합니다.</block>
  <block id="800f40fa67f69116bf6f38cd07456608" category="paragraph">시스템 관리자는 실행: AI 프로젝트 탭에서 다음 매개 변수를 설정할 수 있습니다.</block>
  <block id="9c429f2284a95aaa299c7d85ccb16734" category="list-text">* 모델 프로젝트 * 사용자별 프로젝트를 설정하고, 사용자 팀별로 프로젝트를 설정하고, 실제 조직 프로젝트별로 프로젝트를 설정합니다.</block>
  <block id="b2f1422cf0d082a495bbf865b9a5621d" category="list-text">* 프로젝트 할당량 * 각 프로젝트는 이 프로젝트에 동시에 할당할 수 있는 GPU 할당량과 연관됩니다. 이 프로젝트는 클러스터의 상태에 관계없이 이 프로젝트를 사용하는 연구원이 GPU 수를 확보할 수 있다는 점에서 보장된 할당량입니다. 일반적으로 프로젝트 할당의 합계는 클러스터에 있는 GPU 수와 같아야 합니다. 이 외에도 이 프로젝트의 사용자는 초과 할당량을 받을 수 있습니다. GPU를 사용하지 않는 한, 이 프로젝트를 사용하는 연구자는 더 많은 GPU를 얻을 수 있습니다. 에서는 할당량 초과 테스트 시나리오와 공정성 고려 사항을 보여 줍니다<block ref="9563fd9ab6978412dc97d80a70e51786" category="inline-link-rx"></block>,<block ref="a8ad108feafc827856baa28b0b9070ed" category="inline-link-rx"></block>, 및<block ref="be867f64efefe193012b1dfc6c82f783" category="inline-link-rx"></block>.</block>
  <block id="20a3a45fbbd9502add12fd216350d569" category="list-text">새 프로젝트를 만들고, 기존 프로젝트를 업데이트하고, 기존 프로젝트를 삭제합니다.</block>
  <block id="3bf13b237342258b6ddb3f167d679a3b" category="inline-link">AI 문서 를 실행하십시오</block>
  <block id="77332641abf52ec5dc1af8b23b2339f3" category="list-text">* 특정 노드 그룹에서 실행할 작업 제한 *. 특정 노드에서만 실행되도록 특정 프로젝트를 할당할 수 있습니다. 이 기능은 프로젝트 팀이 충분한 메모리를 갖춘 특수 하드웨어가 필요한 경우에 유용합니다. 또는 프로젝트 팀은 전문 예산으로 구입한 특정 하드웨어의 소유자가 되거나, 더 약한 하드웨어에서 작동하고 더 긴 훈련이나 무인 워크로드를 더 빠른 노드로 직접 처리하기 위해 직접 빌드하거나 대화형 워크로드를 실행해야 할 수도 있습니다. 노드를 그룹화하고 특정 프로젝트에 대한 선호도를 설정하는 명령은 을 참조하십시오 <block ref="eae60ce89b8727160634b52e7654bf73" category="inline-link-rx"></block>.</block>
  <block id="2bd802cca9bf193b441123437f5d39ca" category="list-text">* 대화형 작업 기간 제한 *. 연구자들은 종종 대화식 작업을 종결하는 것을 잊어버립니다. 이로 인해 리소스가 낭비될 수 있습니다. 일부 조직에서는 대화형 작업의 기간을 제한하고 자동으로 작업을 종결하는 것을 선호합니다.</block>
  <block id="10c2495ded559d79de96be22751712dc" category="paragraph">다음 그림에서는 네 개의 팀이 생성된 프로젝트 보기를 보여 줍니다. 각 팀에는 서로 다른 워크로드를 처리할 수 있는 서로 다른 수의 GPU가 할당되며, 총 GPU 수는 2개의 DGX-1로 구성된 클러스터에서 사용 가능한 총 GPU 수와 같습니다.</block>
  <block id="9ba047faa1d241a6153be986be27097f" category="paragraph"><block ref="9ba047faa1d241a6153be986be27097f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4804b15e4766599ceade052b5ca8af9" category="inline-link-macro">다음: AI CLI 실행 에서 작업 제출</block>
  <block id="9c6088fad9917e07026030c1d3eaad09" category="paragraph"><block ref="9c6088fad9917e07026030c1d3eaad09" category="inline-link-macro-rx"></block></block>
  <block id="33204bfa9ee287508f03782fd7ad512e" category="summary">Trident를 사용하여 Kubernetes 클러스터 내에서 스토리지 리소스를 동적으로 프로비저닝하려면 먼저 하나 이상의 Kubernetes StorageClasses를 생성해야 합니다. 이 페이지의 예제는 ONTAP AI POD에 NetApp AI Control Plane 솔루션을 구축할 경우 생성할 수 있는 여러 가지 유형의 StorageClasses를 보여줍니다.</block>
  <block id="d9206a5144976221af82df78ad3d7977" category="paragraph">Trident를 사용하여 Kubernetes 클러스터 내에서 스토리지 리소스를 동적으로 프로비저닝하려면 먼저 하나 이상의 Kubernetes StorageClasses를 생성해야 합니다. 다음 예제는 ONTAP AI POD에 NetApp AI Control Plane 솔루션을 구축할 경우 생성할 수 있는 다양한 유형의 StorageClasses를 보여줍니다. StorageClasses에 대한 자세한 내용은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="993143e7434e63409a07cf3e8c422505" category="list-text">NetApp은 섹션에 생성한 각 FlexGroup 지원 Trident 백엔드에 대해 별도의 StorageClass를 생성할 것을 권장합니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 1단계. 이러한 세분화된 StorageClasses를 사용하면 특정 LIF(Trident 백엔드를 생성할 때 지정한 LIF)에 해당하는 NFS 마운트를 StorageClass 사양 파일에 지정된 특정 백엔드에서 추가할 수 있습니다. 다음 예제 명령은 섹션에 생성된 두 예제 백엔드에 해당하는 두 개의 StorageClasses를 생성하는 방법을 보여 줍니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 1단계. StorageClasses에 대한 자세한 내용은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Kubernetes 문서</block>
  <block id="a596fcc71d1c43e3ba86b1557ac7af81" category="paragraph">영구 볼륨은 해당 PersistentVolumeClaim(PVC)이 삭제되어도 삭제되지 않도록 다음 예에서는 "Retain"의 "reclaimPolicy" 값을 사용합니다. '청구 정책' 필드에 대한 자세한 내용은 공식 을 참조하십시오<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>.</block>
  <block id="f053cb3a491d2bc48d41230b10a9b164" category="list-text">또한 섹션에서 생성한 FlexVol 지원 Trident 백엔드에 해당하는 StorageClass를 생성하는 것이 좋습니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 2단계. 다음 명령 예에서는 FlexVol 볼륨에 대한 단일 StorageClass를 생성하는 것을 보여 줍니다.</block>
  <block id="99608a01905f0e69895bbb864a0deba3" category="paragraph">다음 예에서는 FlexVol 지원 Trident 백엔드가 하나만 생성되었기 때문에 StorageClass 정의 파일에 특정 백엔드가 지정되지 않습니다. Kubernetes를 사용하여 이 StorageClass를 사용하는 볼륨을 관리할 경우 Trident는 'ONTAP-NAS' 드라이버를 사용하는 사용 가능한 백엔드를 사용하려고 합니다.</block>
  <block id="ee1d27a4ae3e30ff30ef72e305b029e7" category="list-text">또한 FlexGroup 볼륨에 대한 일반 StorageClass를 생성하는 것이 좋습니다. 다음 예제 명령은 FlexGroup 볼륨에 대한 단일 일반 StorageClass 를 생성하는 방법을 보여 줍니다.</block>
  <block id="d4a43a35c5d5a5ce3aefe77ceaa73a5c" category="paragraph">StorageClass 정의 파일에 특정 백엔드가 지정되지 않았습니다. 따라서 Kubernetes를 사용하여 이 StorageClass를 사용하는 볼륨을 관리할 때 Trident는 'ONTAP-NAS-Flexgroup' 드라이버를 사용하는 사용 가능한 백엔드를 사용하려고 합니다.</block>
  <block id="b569e24403ad128c09e2d0dbd0116463" category="inline-link-macro">다음은 Kubeflow 구축 개요입니다.</block>
  <block id="66f5564ed29f37f0b81d2dde741b9c8f" category="paragraph"><block ref="66f5564ed29f37f0b81d2dde741b9c8f" category="inline-link-macro-rx"></block></block>
  <block id="8fcbbd73e86fa0b56d72d6127c318c85" category="paragraph">데이터의 폭발적인 증가와 머신 러닝(ML)과 인공 지능(AI)의 기하급수적인 성장으로 인해 고유한 개발 및 구현 과제와 함께 새로운 경제를 창조했습니다. 일반적으로 대량의 데이터는 GPU와 같은 고성능 AI 컴퓨팅 리소스가 효율적으로 액세스할 수 없는 저렴한 데이터 레이크에 저장됩니다. 이 보고서에서는 데이터 과학 전문가가 데이터 허브를 구현하고, 한 번의 클릭으로 위치와 관계없이 컴퓨팅 리소스 가까이에 데이터 세트 캐시를 생성할 수 있는 새로운 솔루션을 제공합니다. 따라서 AI 실무자는 새로운 데이터 세트 버전 허브를 통해 향상된 협업을 통해 고성능 모델 훈련을 더 쉽게 수행할 수 있습니다.</block>
  <block id="13e8f52d7e19f83d3e64003c58ea220b" category="doc">NDE를 사용하여 NetApp HCI에 VMware 가상 인프라 구축(자동화된 구축)</block>
  <block id="2635318d9bf1ea76c73bfab7f3eeafb7" category="section-title">NDE 배포 필수 구성 요소</block>
  <block id="f6ec2c1aa5118cb19e89af5a10ecb65c" category="inline-link">NetApp HCI 필수 구성 요소 체크리스트</block>
  <block id="2187fc20798cda55150d8c067fac10be" category="paragraph">을 참조하십시오<block ref="c760383d1767df51ab118e6ffc289894" category="inline-link-rx"></block> 배포를 시작하기 전에 NetApp HCI에 대한 요구 사항 및 권장 사항을 확인하십시오.</block>
  <block id="cd02d0868a7414dd1e76924b30b82b52" category="list-text">네트워크 및 스위치 요구 사항 및 구성</block>
  <block id="1d8b6c167080876dff9ad2e74e70fecf" category="list-text">필요한 VLAN ID를 준비합니다</block>
  <block id="17cec09f14c225b5f27dc73542e9077a" category="list-text">스위치 구성</block>
  <block id="4d40082ed807aa2fb7e1d2f03921e4d4" category="list-text">NetApp HCI 및 VMware의 IP 주소 요구 사항</block>
  <block id="2e8e4792043f43cb4b34a84b8dcd909b" category="list-text">DNS 및 시간 유지 요구 사항</block>
  <block id="829710d6ec2a8e59e7a69fb3537ec494" category="list-text">최종 준비</block>
  <block id="fb720b4ad7c03710e0e5771c9fb58b44" category="section-title">NDE 실행</block>
  <block id="cf50c81e30d1d64fcb4992a9792abedb" category="paragraph">NDE를 실행하기 전에 모든 구성 요소의 랙 및 스택, 네트워크 스위치 구성 및 모든 사전 요구 사항 확인을 완료해야 합니다. NDE가 모든 주소를 자동으로 구성하도록 하려면 단일 스토리지 노드의 관리 주소에 연결하여 NDE를 실행할 수 있습니다.</block>
  <block id="130c61c344b6fbf262b6f63818eab7e4" category="paragraph">NDE는 HCI 시스템을 온라인으로 전환하는 다음과 같은 작업을 수행합니다.</block>
  <block id="d89f68a2ec388fe5d72fb6fe024a0176" category="list-text">최소 2개의 스토리지 노드에 스토리지 노드(NetApp Element 소프트웨어)를 설치합니다.</block>
  <block id="f6f86c1086573c7daeb1f48535041576" category="list-text">최소 2개의 컴퓨팅 노드에 VMware 하이퍼바이저를 설치합니다.</block>
  <block id="0718265bec3e2ee6fc9d5e0773b5ff60" category="list-text">VMware vCenter를 설치하여 전체 NetApp HCI 스택을 관리합니다.</block>
  <block id="e09575b9713329ebe2480dbf404b2b1b" category="list-text">NetApp 스토리지 관리 노드(mNode) 및 NetApp 모니터링 에이전트를 설치 및 구성합니다.</block>
  <block id="dddc28f734d0bcb367638f51ef8b4dfa" category="admonition">이 검증에서는 NDE를 사용하여 모든 주소를 자동으로 구성합니다. 사용자 환경에서 DHCP를 설정하거나 각 스토리지 노드 및 컴퓨팅 노드에 대해 IP 주소를 수동으로 할당할 수도 있습니다. 이러한 단계는 본 가이드에서 다루지 않습니다.</block>
  <block id="dd9cd526f5753b79bda6de19f1a66fe9" category="paragraph">앞에서 설명한 것처럼 이 검증에서는 컴퓨팅 노드에 대해 2케이블 구성을 사용합니다.</block>
  <block id="32691d86c49e682187776e0262b732d7" category="paragraph">NDE에 대한 자세한 단계는 본 문서에서 다루지 않습니다.</block>
  <block id="968a3687be335c74374e73712c63e2e4" category="inline-link">구축 가이드</block>
  <block id="8b6e1a3a9d21ff63520793416432cd56" category="paragraph">기본 NetApp HCI 플랫폼 배포 완료에 대한 단계별 지침은 를 참조하십시오<block ref="7742239770a3accee30f01673a1a43a5" category="inline-link-rx"></block>.</block>
  <block id="61ef02ded53524d506cd714c5821cd86" category="list-text">NDE가 완료되면 vCenter에 로그인하여 ONTAP Select 및 애플리케이션에서 사용할 NFS 네트워크에 대한 분산 포트 그룹 NetApp HCI VDS 01-NFS_Network를 생성합니다.</block>
  <block id="9fb27fdce8d8c70b2c7b741958c8ac6e" category="inline-link-macro">다음: NetApp H615c 구성(수동 구축)</block>
  <block id="6623698128b1c14d8639f2404306f783" category="paragraph"><block ref="6623698128b1c14d8639f2404306f783" category="inline-link-macro-rx"></block></block>
  <block id="c755c33dca37a8aaffbf190bdf3f5fef" category="paragraph">이 솔루션은 NetApp AFF A800 시스템 1대, DGX-1 서버 2대, Cisco Nexus 3232C 100GbE 스위치 2개를 사용하여 구축했습니다. RoCE(RDMA over Converged Ethernet)를 통한 원격 직접 메모리 액세스(RDMA)를 사용하여 각 DGX-1 서버는 GPU 간 통신에 사용되는 4개의 100GbE 연결을 통해 Nexus 스위치에 연결합니다. NFS 스토리지 액세스를 위한 기존 IP 통신도 이 링크에서 발생합니다. 4개의 100GbE 링크를 사용하여 각 스토리지 컨트롤러를 네트워크 스위치에 연결합니다. 다음 그림은 모든 테스트 시나리오에 대해 이 기술 보고서에 사용된 ONTAP AI 솔루션 아키텍처를 보여줍니다.</block>
  <block id="782c9fdc3f29358987c2f5b99fe9e6b9" category="paragraph"><block ref="782c9fdc3f29358987c2f5b99fe9e6b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1b09355c9538fe149372d3728c98bb1" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block></block>
  <block id="aa364e0963e38930007df2b60bdba067" category="doc">Trident에서 프로비저닝한 PersistentVolume에 데이터 저장</block>
  <block id="ef1fb51957f2aa894de5476a9a0112a2" category="paragraph">NetApp Trident는 컨테이너화된 애플리케이션의 정교한 지속성 요구사항을 충족하도록 설계된 완전 지원되는 오픈 소스 프로젝트입니다. 데이터 계층화, 암호화, NetApp Snapshot 기술, 규정 준수 및 NetApp ONTAP 데이터 관리 소프트웨어에서 제공하는 우수한 성능의 이점을 추가로 활용하여 Trident에서 프로비저닝한 Kubernetes PersistentVolume(PV)에 데이터를 읽고 쓸 수 있습니다.</block>
  <block id="a821f368daf439d909bfed3c8e95d4b9" category="section-title">기존 네임스페이스에서 PVC 재사용</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link">NetApp Trident 문서</block>
  <block id="15040fc521e7fa5e8ef42694ca89e53d" category="paragraph">대규모 AI 프로젝트의 경우, 여러 컨테이너가 동일한 Kubernetes PV에서 데이터를 읽고 쓰는 것이 더 효율적일 수 있습니다. Kubernetes PVC(Persistent Volume Claim)를 재사용하려면 이미 PVC를 생성해야 합니다. 를 참조하십시오<block ref="5b6274adc29653ed1820027957bdb4e2" category="inline-link-rx"></block> PVC 작성에 대한 자세한 내용은. 다음은 기존 PVC를 재사용하는 예입니다.</block>
  <block id="743520c366f0d11ca817811dda85fcf1" category="paragraph">다음 명령어를 실행해 프로젝트 팀 A에 대한 작업 PVC-TEST의 상태를 확인할 수 있다.</block>
  <block id="7d4c508442c775f946e3d9318b75b1a0" category="paragraph">team-A job 'PVC-test'에 PV/tmp/pvc1mount가 마운트된 것을 볼 수 있습니다. 이렇게 하면 여러 컨테이너를 동일한 볼륨에서 읽을 수 있으므로 개발 또는 운영 중인 경쟁 모델이 여러 개 있을 때 유용합니다. 데이터 과학자는 모델의 앙상블을 만든 다음 대부분의 투표 또는 기타 기술을 통해 예측 결과를 결합할 수 있습니다.</block>
  <block id="dae81aa45b8ce281aabbd1402afe277b" category="paragraph">다음을 사용하여 컨테이너 셸에 액세스합니다.</block>
  <block id="bc63da8fa87210da818596598e359427" category="paragraph">그런 다음 마운트된 볼륨을 확인하고 컨테이너 내의 데이터에 액세스할 수 있습니다.</block>
  <block id="fc180b17e3fccb2beb46854f71d31406" category="paragraph">PVC를 재사용할 수 있는 이 기능은 NetApp FlexVol 볼륨 및 NetApp ONTAP FlexGroup 볼륨과 함께 작동하여 데이터 엔지니어가 보다 유연하고 강력한 데이터 관리 옵션을 통해 NetApp이 제공하는 Data Fabric을 활용할 수 있도록 지원합니다.</block>
  <block id="2e203cb5454e63a32bcdb87dc9cb77ad" category="paragraph"><block ref="2e203cb5454e63a32bcdb87dc9cb77ad" category="inline-link-macro-rx"></block></block>
  <block id="c1579c333c7c7a4e52136c7f58a7efc6" category="summary">이 기술 보고서에서 제안된 솔루션은 이러한 탁월한 고객 경험의 제공을 지원하는 것으로 입증되었으며, 이제 기업이 AI 인프라 및 워크플로의 현대화를 위한 조치를 취하도록 하는 것이 과제입니다.</block>
  <block id="9c5e72cb1709251063c12e4bddb1ba12" category="inline-link-macro">이전: 비디오 및 데모.</block>
  <block id="2f6461cd01fcb0c2d85704a563bd7c19" category="paragraph"><block ref="2f6461cd01fcb0c2d85704a563bd7c19" category="inline-link-macro-rx"></block></block>
  <block id="50d6e8cef34560d1d68c6688a12b1cb8" category="paragraph">고객 경험이 점점 더 경쟁이 치열해지는 주요 전장으로 간주됨에 따라, 거의 모든 산업의 기업이 간과할 수 없는 중요한 구성 요소가 AI 강화 글로벌 지원 센터가 되었습니다. 이 기술 보고서에서 제안된 솔루션은 이러한 탁월한 고객 경험의 제공을 지원하는 것으로 입증되었으며, 이제 기업이 AI 인프라 및 워크플로의 현대화를 위한 조치를 취하도록 하는 것이 과제입니다.</block>
  <block id="f6e349295b2165b25a412793116b8675" category="paragraph">고객 서비스에서 AI를 가장 잘 구현하는 것은 상담원을 대체하지 않는 것입니다. 오히려 AI를 사용하면 실시간 감정 분석, 분쟁 에스컬레이션, 다중 모달 Affective 컴퓨팅을 통해 탁월한 고객 경험을 창출하여 포괄적인 AI 모델이 규모에 따라 권장사항을 제시하고 개별 상담원의 부족한 사항을 보완할 수 있는 언어, 비언어적, 안면 신호를 감지할 수 있습니다. 또한 AI는 특정 고객과 현재 사용 가능한 에이전트 간에 더 나은 일치를 제공할 수 있습니다. AI를 사용하는 기업은 공급자의 제품, 서비스 및 브랜드 이미지에 대한 생각과 인상에 대해 귀중한 고객 감정을 끌어낼 수 있습니다.</block>
  <block id="eb5cb6f03236a80f7ddd5085afa95729" category="paragraph">이 솔루션을 사용하여 지원 상담원이 객관적인 성능 평가 메트릭으로 사용할 시계열 데이터를 구성할 수도 있습니다. 일반적인 고객 만족도 설문 조사에는 대개 충분한 응답이 없습니다. 고용주는 장기적인 직원 및 고객 감정을 수집하여 지원 상담원의 성과에 대해 충분한 정보를 바탕으로 의사 결정을 내릴 수 있습니다.</block>
  <block id="aa20fc291fbb8ceda8651d8d8ee9dba6" category="paragraph">NetApp, SFL Scientific, 오픈 소스 오케스트레이션 프레임워크 및 NVIDIA의 결합을 통해 최신 기술을 관리형 서비스로 통합하고 기술 도입을 가속하고 새로운 AI/ML 애플리케이션의 출시 시기를 앞당길 수 있습니다. 이러한 고급 서비스는 클라우드 네이티브 환경과 하이브리드 구축 아키텍처에 대해 쉽게 이식할 수 있는 온프레미스 서비스입니다.</block>
  <block id="71fd14327d5bf7e725ab97e00192b238" category="paragraph"><block ref="71fd14327d5bf7e725ab97e00192b238" category="inline-link-macro-rx"></block></block>
  <block id="9e59f01034d2c132fac901b9c14a5d88" category="summary">Kubernetes용 NetApp DataOps 툴킷은 스토리지 리소스와 Kubernetes 워크로드를 데이터 과학 작업 공간 수준까지 추상화합니다. 이러한 기능은 데이터 과학자와 데이터 엔지니어를 위해 설계된 간단하고 사용하기 쉬운 인터페이스로 패키징되어 있습니다.</block>
  <block id="7aee811c7e891ab94bb5be40b333faaf" category="doc">NetApp DataOps 툴킷을 사용하여 데이터 세트 및 모델 버전 관리</block>
  <block id="f7136197d3b16131979b9319c4acce63" category="inline-link-macro">이전: Prometheus 및 Grafana를 사용하여 Dask 및 RAPIDS를 모니터링합니다.</block>
  <block id="402dae1972461d7e7ba986ab6728df6c" category="paragraph"><block ref="402dae1972461d7e7ba986ab6728df6c" category="inline-link-macro-rx"></block></block>
  <block id="fd2d048a9ec0f96d89493b98f72cbe34" category="paragraph">Kubernetes용 NetApp DataOps 툴킷은 스토리지 리소스와 Kubernetes 워크로드를 데이터 과학 작업 공간 수준까지 추상화합니다. 이러한 기능은 데이터 과학자와 데이터 엔지니어를 위해 설계된 간단하고 사용하기 쉬운 인터페이스로 패키징되어 있습니다. 데이터 과학자와 엔지니어는 익숙한 형식의 Python 프로그램을 사용하여 JupyterLab 작업 공간을 단 몇 초 만에 프로비저닝 및 폐기할 수 있습니다. 이러한 작업 공간에는 테라바이트나 페타바이트급의 스토리지 용량이 포함될 수 있으므로 데이터 과학자는 모든 훈련 데이터 세트를 프로젝트 작업 공간에 직접 저장할 수 있습니다. 작업 영역과 데이터 볼륨을 별도로 관리하는 시대는 지났습니다.</block>
  <block id="4a6c7893abd7ef92fb09d3359e17324d" category="inline-link">GitHub 리포지토리</block>
  <block id="eb0d40310a9cc0432fac66dc97652c39" category="paragraph">자세한 내용은 툴킷 을 참조하십시오<block ref="64134ca6239d4056f34489b42f2baeed" category="inline-link-rx"></block>.</block>
  <block id="1d1983037d4fd7beac963697b84f82bd" category="paragraph"><block ref="1d1983037d4fd7beac963697b84f82bd" category="inline-link-macro-rx"></block></block>
  <block id="a6214fe1ac9a6825ffe38f3b34489c9d" category="summary">NetApp Run AI는 AI 워크로드 오케스트레이션을 단순화하기 위해 실행 AI 플랫폼과 함께 Azure NetApp Files의 고유한 기능을 시연하기 위해 이 기술 보고서를 작성하는 데 협력했습니다.</block>
  <block id="a55106260c16aab506cebfb58e07e030" category="paragraph">NetApp과 RUN: AI는 AI 워크로드 오케스트레이션을 단순화하기 위한 RUN:AI 플랫폼과 함께 Azure NetApp Files의 고유한 기능을 시연하기 위해 이 기술 보고서를 작성하는 데 협력했습니다. 이 기술 보고서는 분산 차선 감지 교육을 위한 데이터 파이프라인 및 워크로드 오케스트레이션 프로세스의 간소화를 위한 참조 아키텍처를 제공합니다.</block>
  <block id="4e51614a389f3ad4fa17e2ce7ad984e7" category="paragraph">결론적으로, 규모에 따른 분산 교육(특히 퍼블릭 클라우드 환경)과 관련하여 리소스 오케스트레이션 및 스토리지 구성요소를 솔루션의 중요한 요소로 간주하게 됩니다. 데이터를 관리하여 여러 GPU 처리를 방해해서는 안 되므로 GPU 사이클을 최적으로 활용할 수 있습니다. 따라서 대규모 분산 교육 용도로 시스템을 최대한 비용 효율적으로 만들 수 있습니다.</block>
  <block id="269c35b1959d92e9ef6665bb4c60ad5d" category="paragraph">NetApp에서 제공하는 Data Fabric을 사용하면 데이터 과학자와 데이터 엔지니어가 사내 및 클라우드에 연결하여 수동 개입 없이 동기식 데이터를 사용할 수 있으므로 문제를 극복할 수 있습니다. 다시 말해, Data Fabric은 여러 위치에 분산되어 있는 AI 워크플로우를 관리하는 프로세스를 원활하게 처리합니다. 또한, 데이터를 컴퓨팅 가까이에 두고 분석, 교육, 검증을 필요할 때 언제 어디서나 수행하여 수요 기반 데이터 가용성을 지원합니다. 이 기능을 사용하면 데이터 통합뿐만 아니라 전체 데이터 파이프라인의 보호 및 보안을 실현할 수 있습니다.</block>
  <block id="d68d11ee3f69a45d681f78c744cae498" category="summary">볼륨에 대해 원하는 서비스 수준을 사용하는 다른 용량 풀로 볼륨을 이동하여 기존 볼륨의 서비스 수준을 변경할 수 있습니다. 이 솔루션을 통해 고객은 작은 데이터 세트와 Standard Tier의 적은 수의 GPU로 시작한 후 데이터 및 GPU가 증가함에 따라 프리미엄 계층으로 스케일아웃 또는 스케일업할 수 있습니다.</block>
  <block id="2fe5665064f07acc8afc830f911c09a5" category="doc">Azure NetApp Files 성능 계층</block>
  <block id="d84e339c1d1265f11e2f217f8d04354a" category="inline-link-macro">이전: Helm을 사용하여 AKS에서 RAPIDS 배포를 사용하여 Dask를 설정합니다.</block>
  <block id="1be55e0d10ba600a3d66b1f73f978b9f" category="paragraph"><block ref="1be55e0d10ba600a3d66b1f73f978b9f" category="inline-link-macro-rx"></block></block>
  <block id="de524ca3fc83ef426bc329e1a8b712ea" category="paragraph">볼륨에 대해 원하는 서비스 수준을 사용하는 다른 용량 풀로 볼륨을 이동하여 기존 볼륨의 서비스 수준을 변경할 수 있습니다. 이 솔루션을 통해 고객은 작은 데이터 세트와 Standard Tier의 적은 수의 GPU로 시작한 후 데이터 및 GPU가 증가함에 따라 프리미엄 계층으로 스케일아웃 또는 스케일업할 수 있습니다. Premium Tier는 Standard Tier보다 테라바이트당 처리량이 4배 더 향상되었으며, 볼륨의 서비스 수준을 변경하기 위해 데이터를 이동할 필요 없이 스케일업이 가능합니다.</block>
  <block id="5f92df8a2ac38644ed8ba20e16791602" category="paragraph">볼륨의 서비스 수준을 동적으로 변경하려면 다음 단계를 수행하십시오.</block>
  <block id="8c83c4957baac2f6fea18f9d77767e3a" category="paragraph"><block ref="8c83c4957baac2f6fea18f9d77767e3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ec2eabbe87e02cad1b0d4279ea00a7" category="list-text">Change Pool 창에서 볼륨을 이동할 용량 풀을 선택합니다.</block>
  <block id="ef3a0105bad35ad4c385d92daf6496a6" category="paragraph"><block ref="ef3a0105bad35ad4c385d92daf6496a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">확인 을 클릭합니다.</block>
  <block id="32ae33eea9c6b04002778d814c344fb5" category="section-title">성능 계층 변경을 자동화합니다</block>
  <block id="1c9506694c5a6fe83d1a0389d1d24564" category="paragraph">다음 옵션을 사용하여 성능 계층 변경을 자동화할 수 있습니다.</block>
  <block id="54a3bcd89041e8f96766dcb598b15511" category="list-text">동적 서비스 수준 변경은 현재 Public Preview에 있으며 기본적으로 활성화되어 있지 않습니다. Azure 구독에서 이 기능을 활성화하려면 이 설명서에서 방법을 참조하십시오<block ref="773d4c9e90e7325c5fcf35857900af6e" category="inline-link-rx"></block>.</block>
  <block id="0b01c5f61940e864222c5b29615a7eeb" category="inline-link">볼륨 풀 변경 설명서</block>
  <block id="265eed4df59633a830c9da49505786fc" category="list-text">Azure CLI 볼륨 풀 변경 명령은 에 나와 있습니다<block ref="db78b725076ccf0203288c6620e52eb9" category="inline-link-rx"></block> 및 의 예는 다음과 같습니다.</block>
  <block id="4455e376dc005ca0a99be0491b917ce7" category="inline-link">Set-AzNetAppFilesVolumePool cmdlet</block>
  <block id="a5bce2f378011f6036711869a5e8073b" category="list-text">PowerShell<block ref="45dc9ea5ce8eabd60a14674d792889e0" category="inline-link-rx"></block> Azure NetApp Files 볼륨의 풀을 변경하며 다음 예에 표시됩니다.</block>
  <block id="b79b50d5bff47e3a668f266c7b9dbc7b" category="inline-link-macro">다음: 데이터 처리 및 모델 훈련을 위한 라이브러리.</block>
  <block id="edd770dcbb857ec8f0871955fb2f7d5d" category="paragraph"><block ref="edd770dcbb857ec8f0871955fb2f7d5d" category="inline-link-macro-rx"></block></block>
  <block id="b8b025dc1895637326d2420e912751e0" category="summary">Trident를 사용하여 Kubernetes 클러스터 내에서 스토리지 리소스를 동적으로 프로비저닝하려면 먼저 하나 이상의 Trident 백엔드를 생성해야 합니다. 이 페이지의 예는 ONTAP AI Pod에 NetApp AI Control Plane 솔루션을 구축할 경우 생성할 수 있는 다양한 유형의 백엔드를 나타냅니다.</block>
  <block id="c0fe00dd01499e23426b850b65782c77" category="paragraph">Trident를 사용하여 Kubernetes 클러스터 내에서 스토리지 리소스를 동적으로 프로비저닝하려면 먼저 하나 이상의 Trident 백엔드를 생성해야 합니다. 다음 예는 ONTAP AI 포드에 NetApp AI Control Plane 솔루션을 구축할 경우 생성할 수 있는 다양한 유형의 백엔드를 보여줍니다. 백엔드에 대한 자세한 내용은 을 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="1e698f68960fb964df99e73068c9377c" category="list-text">NetApp AFF 시스템에서 사용할 각 데이터 LIF(데이터 액세스를 제공하는 논리적 네트워크 인터페이스)에 대해 FlexGroup 지원 Trident 백엔드를 생성하는 것이 좋습니다. LIF 간 볼륨 마운트의 균형을 조정할 수 있습니다</block>
  <block id="327a3876126e4773cfcc5e30649c9483" category="paragraph">다음 명령 예는 동일한 ONTAP 스토리지 가상 시스템(SVM)과 연관된 2개의 서로 다른 데이터 LIF에 대해 2개의 FlexGroup 지원 Trident 백엔드를 생성하는 것을 보여줍니다. 이러한 백엔드는 'ONTAP-NAS-Flexgroup' 스토리지 드라이버를 사용합니다. ONTAP는 FlexVol와 FlexGroup의 두 가지 기본 데이터 볼륨 유형을 지원합니다. FlexVol 볼륨의 크기는 제한되어 있습니다(이 쓰기 작업 시 최대 크기는 특정 구축에 따라 다름). 반면 FlexGroup 볼륨은 최대 20PB 및 4천억 개 파일까지 선형적으로 확장할 수 있으므로 데이터 관리를 크게 간소화하는 단일 네임스페이스를 제공합니다. 따라서 FlexGroup 볼륨은 대량의 데이터를 사용하는 AI 및 ML 워크로드에 최적화되어 있습니다.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">소량의 데이터로 작업하고 FlexGroup 볼륨 대신 FlexVol 볼륨을 사용하려는 경우, ONTAP-NAS-Flexgroup 스토리지 드라이버 대신 'ONTAP-NAS' 스토리지 드라이버를 사용하는 Trident 백엔드를 생성할 수 있습니다.</block>
  <block id="d04adbc45ec06c05c1826745b8f4ddf2" category="list-text">또한 하나 이상의 FlexVol 지원 Trident 백엔드를 생성하는 것이 좋습니다. 데이터 세트 스토리지를 훈련하는 데 FlexGroup 볼륨을 사용하는 경우 FlexVol 볼륨을 사용하여 결과, 출력, 디버그 정보 등을 저장할 수 있습니다. FlexVol 볼륨을 사용하려면 하나 이상의 FlexVol 지원 Trident 백엔드를 생성해야 합니다. 다음 명령의 예는 단일 데이터 LIF를 사용하는 단일 FlexVol 지원 Trident 백엔드를 생성하는 것입니다.</block>
  <block id="f8bc0cf277b3c4424978d08f10f9df70" category="inline-link-macro">다음: ONTAP AI 배포를 위한 Kubernetes Storagecles의 예</block>
  <block id="a58ef634a291d01e3abec43e5619294a" category="paragraph"><block ref="a58ef634a291d01e3abec43e5619294a" category="inline-link-macro-rx"></block></block>
  <block id="fa752e98365b630341b8478c89a6757f" category="doc">Kubernetes 클러스터 구성 중</block>
  <block id="f12c340e651d989970371432778f9be2" category="paragraph">이 섹션은 클라우드 및 온프레미스 구축을 위한 두 부분으로 나누어져 있습니다.</block>
  <block id="ee06675a624f2ec74e8b71b5a57f8f9e" category="section-title">클라우드 구축 Kubernetes 구성</block>
  <block id="b513a0297a0d2efdebed8ce18e2f1715" category="paragraph">NetApp Cloud Manager를 통해 Iguazio Kubernetes 클러스터 연결을 정의할 수 있습니다. Trident를 사용하려면 클러스터의 여러 리소스에 액세스하여 볼륨을 사용할 수 있어야 합니다.</block>
  <block id="2d5bc331cc722113dd483838e908804c" category="list-text">액세스를 설정하려면 Iguazio 노드 중 하나에서 Kubernetes 구성 파일을 가져옵니다. 이 파일은 `/home/Iguazio/.kube/config.' 아래에 있습니다 이 파일을 바탕 화면에 다운로드합니다.</block>
  <block id="17c6b0de5b91c5c06a0d8173c89110d8" category="list-text">구성할 클러스터 검색 으로 이동합니다.</block>
  <block id="df37cca51036f4c5b59db211df5354bc" category="paragraph"><block ref="df37cca51036f4c5b59db211df5354bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b848e07dc3f62b4307419421d844f123" category="list-text">Kubernetes 구성 파일을 업로드합니다. 다음 이미지를 참조하십시오.</block>
  <block id="5bcc42d0a2624f1586064488c3484529" category="paragraph"><block ref="5bcc42d0a2624f1586064488c3484529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63de24a45facebf9f65cb6578847f2b4" category="list-text">Trident를 구축하고 클러스터와 볼륨을 연결합니다. Iguazio 클러스터에 영구 볼륨 정의 및 할당에 대한 다음 이미지를 참조하십시오. 이 프로세스는 Iguazio의 Kubernetes 클러스터에 영구 볼륨(PV)을 만듭니다. 이를 사용하려면 먼저 영구 볼륨 클레임(PVC)을 정의해야 합니다.</block>
  <block id="8b69025b2efa1b2ccb917bc911d30ccd" category="section-title">온프레미스 구축 Kubernetes 구성</block>
  <block id="5be8900878997a404baf02b07ff271c6" category="paragraph">NetApp Trident의 사내 설치에 대한 자세한 내용은 을 참조하십시오<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> 를 참조하십시오. Kubernetes 클러스터를 구성하고 NetApp Trident를 설치한 후 Trident를 Iguazio 클러스터에 연결하여 데이터 및 모델의 Snapshot 복사본 생성 등의 NetApp 데이터 관리 기능을 사용할 수 있습니다.</block>
  <block id="50af1dc10d66589053fc82292fe61444" category="inline-link-macro">Next(다음): 영구 볼륨 클레임을 정의합니다</block>
  <block id="bb0c0300eb362a15d2d6480d832ecfbe" category="paragraph"><block ref="bb0c0300eb362a15d2d6480d832ecfbe" category="inline-link-macro-rx"></block></block>
  <block id="a8a1e11a906a27bd156606bf4717e8e8" category="summary">이 지원 센터 솔루션의 아키텍처는 NVIDIA의 사전 구축된 툴과 NetApp DataOps 툴킷을 중심으로 돌아가고 있습니다. NVIDIA의 도구는 사전 구축된 모델 및 파이프라인을 사용하여 고성능 AI 솔루션을 신속하게 배포하는 데 사용됩니다. NetApp DataOps 툴킷은 다양한 데이터 관리 작업을 단순화하여 개발 속도를 높여줍니다.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">있습니다</block>
  <block id="d51083e81cbf0ec7828af24692206315" category="inline-link-macro">이전: 사용 사례.</block>
  <block id="beff34f173af198016bee889c9f9ed7a" category="paragraph"><block ref="beff34f173af198016bee889c9f9ed7a" category="inline-link-macro-rx"></block></block>
  <block id="c779b37f861deb44744634dea201514f" category="inline-link-macro">NVIDIA Riva</block>
  <block id="ccfdc9ae99a97b7a6b8ad83a329bcdc8" category="paragraph"><block ref="eb3a0fd60dc608626ce6d809beb18359" category="inline-link-macro-rx"></block> GPU에 실시간 성능을 제공하는 멀티모달 대화형 AI 애플리케이션을 구축하기 위한 GPU 가속 SDK NVIDIA Train, 조정 및 최적화(TAO) 툴킷은 교육을 가속화하고 매우 정확하고 성능 높은 도메인 특정 AI 모델을 빠르게 생성할 수 있는 더 빠르고 쉬운 방법을 제공합니다.</block>
  <block id="600ff5755ecd6aa4213eb806162b679e" category="paragraph">NetApp DataOps Toolkit은 개발자, 데이터 과학자, DevOps 엔지니어 및 데이터 엔지니어가 다양한 데이터 관리 작업을 수행할 수 있도록 지원하는 Python 라이브러리입니다. 여기에는 새로운 데이터 볼륨 또는 JupyterLab 작업 공간의 거의 즉각적인 프로비저닝, 데이터 볼륨 또는 JupyterLab 작업 공간의 거의 즉각적인 클론 복제, 추적 및 베이스라인 기능을 위한 데이터 볼륨 또는 JupyterLab 작업 공간의 거의 즉각적인 스냅샷 생성이 포함됩니다.</block>
  <block id="2b0d957e4ad1bdfd446155ff5bb8a9b2" category="section-title">아키텍처 다이어그램</block>
  <block id="1c8bd88c9d2cb845c6c27915f4a3fe8e" category="paragraph">다음 다이어그램에서는 솔루션 아키텍처를 보여 줍니다. 클라우드, 코어, 에지의 세 가지 주요 환경 범주가 있습니다. 각 범주는 지리적으로 분산될 수 있습니다. 예를 들어, 클라우드에는 여러 영역의 버킷에 오디오 파일이 있는 오브젝트 저장소가 포함되어 있는 반면, 코어에는 고속 네트워크 또는 NetApp Cloud Sync를 통해 연결된 데이터 센터가 포함될 수 있습니다. 에지 노드는 개별 상담원의 일상 업무 플랫폼을 나타내며, 대화형 대시보드 도구 및 마이크를 사용하여 감정을 시각화하고 고객과의 대화에서 오디오 데이터를 수집할 수 있습니다.</block>
  <block id="be5acbec67071810913f6782071a73eb" category="inline-link-macro">스토리지 설계</block>
  <block id="5d103a663d28ddc9aa2af5f7b958e52c" category="inline-link">리바</block>
  <block id="cc7a5a83afae781789c3a002465500b5" category="inline-link">Tao 툴킷</block>
  <block id="9595827147dc1170c44979ae1fcabaa6" category="paragraph">GPU 가속 데이터 센터에서 기업은 NVIDIA를 사용할 수 있습니다<block ref="cfd3aefe24e0725c1b0424dd8b503dc1" category="inline-link-rx"></block> 대화형 AI 애플리케이션을 구축하기 위한 프레임워크로, 이 애플리케이션은 에서 사용할 수 있습니다<block ref="ccdd6931e40e98163a0ae3c3c3bfb185" category="inline-link-rx"></block> TRANSFER L-Learning 기술을 사용하여 모델 마무리 및 재교육을 위한 연결 이러한 컴퓨팅 애플리케이션과 워크플로우가 에서 제공됩니다<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>ONTAP이 제공하는 최고의 데이터 관리 기능을 활용할 수 있습니다. 이 툴킷은 기업 데이터 팀이 추적 가능성, 버전 관리, A/B 테스트를 위해 스냅샷 및 클론을 통해 관련 정형 및 비정형 데이터와 함께 모델을 신속하게 프로토타입화할 수 있도록 해 줍니다. 따라서 보안, 거버넌스, 및 규정 준수: 섹션을 참조하십시오 <block ref="3f1432f6921bc0c51d34759cb0d748ab" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="816c3453eeba98af344f96d7eefe8834" category="paragraph">이 솔루션은 오디오 파일 처리, NLP 모델 교육, 전송 학습 및 데이터 관리 세부 정보 단계를 보여 줍니다. 결과적으로 전체 파이프라인은 인적 지원 상담원의 대시보드에 실시간으로 표시되는 정서 요약을 생성합니다.</block>
  <block id="b6fb1598d37d2537eed4160a485b790e" category="paragraph"><block ref="b6fb1598d37d2537eed4160a485b790e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">하드웨어 요구 사항</block>
  <block id="d993b502abe38cef7c7256291e3ffa8e" category="paragraph">다음 표에는 솔루션을 구현하는 데 필요한 하드웨어 구성요소가 나와 있습니다. 이 솔루션을 구체적으로 구축하는 데 사용되는 하드웨어 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="62519b55e4debcf57caf02c89620de61" category="cell">응답 지연 시간 테스트</block>
  <block id="b763dc0a5ffab97a986c74098214cae6" category="cell">시간(밀리초)</block>
  <block id="08fa9c0a2e18301dd14e18c393fb4280" category="cell">데이터 처리</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="08db96f19d3c99c2b42fd180d9d81580" category="cell">추론</block>
  <block id="212e6da10eee5f14935bd37b84fe9684" category="paragraph">이러한 응답 시간 테스트는 560건의 대화에서 50,000개 이상의 오디오 파일로 실행되었습니다. 각 오디오 파일의 크기는 MP3로 최대 100KB, WAV로 변환될 경우 최대 1MB였습니다. 데이터 처리 단계에서는 MP3를 WAV 파일로 변환합니다. 추론 단계에서는 오디오 파일을 텍스트로 변환하고 텍스트에서 감정을 추출합니다. 이러한 단계는 모두 서로 독립적이며 병렬화를 통해 프로세스 속도를 높일 수 있습니다.</block>
  <block id="c18e24981c583441c6975f2116288cb7" category="paragraph">매장 간의 데이터 전송 지연 시간을 고려하여 관리자는 문장의 끝 후 1초 이내에 실시간 감정 분석에 대한 업데이트를 볼 수 있어야 합니다.</block>
  <block id="1c4968697a5851a64ad0fbf1b594e919" category="section-title">NVIDIA Riva 하드웨어</block>
  <block id="5a2ebfb8baa378cfcfcba58bbb1380c2" category="cell">요구 사항</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">OS</block>
  <block id="4c8be35e5fe3d8471f378a69f74c0ab6" category="cell">Linux x86_64</block>
  <block id="4d240f00b5a82cfaaf594cdc72f552f3" category="cell">GPU 메모리(ASR)</block>
  <block id="3fa503e0bb3bf46423ef9176821a1f6c" category="cell">스트리밍 모델: ~5600 MB 비스트리밍 모델: ~3100 MB</block>
  <block id="6345afe417f42d9e0cf6a269bff00b4c" category="cell">GPU 메모리(NLP)</block>
  <block id="217941fb2e441b0bae1b5fec0b454c31" category="cell">BERT 모델당 최대 500MB</block>
  <block id="7e04ebd38c78635d1f8aa53de0dde49b" category="section-title">NVIDIA TAO 툴킷 하드웨어</block>
  <block id="03282e46abfd7449ab38bb851caf2c8d" category="cell">시스템 RAM</block>
  <block id="edaf98e5dae9931cbd74a93b3dd93849" category="cell">32GB</block>
  <block id="6ddfc451ef4f9a7613468cd288d2ab3e" category="cell">GPU RAM</block>
  <block id="2b55387dd066c5bac646ac61543d152d" category="cell">CPU</block>
  <block id="04911a799cc8712b473ed5a3cb2b8904" category="cell">8코어</block>
  <block id="52f9ec21735243ad9917cda3ca077d32" category="cell">GPU</block>
  <block id="fceec3562665d08f1dd24689f68f0f29" category="cell">NVIDIA(A100, V100 및 RTX 30x0)</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD를 지원합니다</block>
  <block id="2f9289dfcac06a2ba95650d7e24ea9e8" category="cell">100GB</block>
  <block id="19aa61315132dbea1d19c7aeeef5f5b2" category="section-title">플래시 스토리지 시스템</block>
  <block id="fd5487a1e906d6cd514dbbc16f17a489" category="paragraph">NetApp의 최신 세대 스토리지 관리 소프트웨어인 ONTAP 9.9를 통해 기업은 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다. ONTAP는 업계 최고 수준의 데이터 관리 기능을 활용하여 데이터가 상주하는 위치와 상관없이 단일 툴셋으로 데이터를 관리하고 보호할 수 있습니다. 필요에 따라 에지, 코어, 클라우드 등 어느 위치로도 데이터를 자유롭게 이동할 수 있습니다. ONTAP 9.9에는 데이터 관리를 단순화하고, 중요 데이터를 더 빨리 처리하고, 보호하며, 하이브리드 클라우드 아키텍처 전체에서 차세대 인프라 기능을 지원하는 다양한 기능이 포함되어 있습니다.</block>
  <block id="78a2efe59d4ad6ad51556ea77f5fdec3" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> 은(는) 빠르고 안전한 데이터 동기화를 제공하는 NetApp 서비스로, 사용자는 온프레미스 NFS 또는 SMB 파일 공유 간에 파일을 다음 타겟으로 전송할 수 있습니다.</block>
  <block id="df2c24964ca3e99761acc48b2c8a75c9" category="list-text">NetApp ONTAP S3</block>
  <block id="1a4c7c9b6e3157ccd0101fd0836c0bfc" category="list-text">NetApp Cloud Volumes Service를 참조하십시오</block>
  <block id="ddcf3699b41cd4c4ee5be4b9dd95c1e6" category="list-text">Amazon Simple Storage Service(Amazon S3)</block>
  <block id="8224436b00c48149c863f4b17219a19d" category="list-text">Amazon Elastic File System(Amazon EFS)</block>
  <block id="52745271323ee9ea30e3a37d0338d118" category="list-text">Azure Blob</block>
  <block id="833c2c211a541e50ad94433664e4b5c1" category="list-text">Google 클라우드 스토리지</block>
  <block id="5446a6bee3301e1f52824fc0affa6299" category="list-text">IBM 클라우드 오브젝트 스토리지</block>
  <block id="1b238365e840da0711b49e8f646e2fdf" category="paragraph">Cloud Sync는 파일을 필요한 위치로 빠르고 안전하게 이동합니다. 데이터가 전송되면 소스와 타겟 모두에서 사용할 수 있습니다. Cloud Sync는 미리 정의된 일정에 따라 데이터를 지속적으로 동기화하여 변경된 부분만 이동하여 데이터 복제에 소요되는 시간과 비용을 최소화합니다. Cloud Sync는 설정과 사용이 간편한 SaaS(Software as a Service) 툴입니다. Cloud Sync에 의해 트리거되는 데이터 전송은 데이터 브로커가 수행합니다. AWS, Azure, Google Cloud Platform 또는 온프레미스에서 Cloud Sync 데이터 브로커를 구축할 수 있습니다.</block>
  <block id="a5c952f5be43013a024d778712474fbc" category="paragraph">StorageGRID 소프트웨어 정의 오브젝트 스토리지 제품군은 퍼블릭, 프라이빗, 하이브리드 멀티 클라우드 환경에서 다양한 사용 사례를 원활하게 지원합니다. 업계 최고 수준의 혁신적인 NetApp StorageGRID은 오랫동안 자동 라이프사이클 관리를 포함하여 다목적 사용을 위해 비정형 데이터를 저장, 보안, 보호 및 보존합니다. 자세한 내용은 를 참조하십시오<block ref="7660f0463c83c682b9f091117b07c3b3" category="inline-link-rx"></block> 사이트.</block>
  <block id="6ffce2da93d4b296032f30d7b2adea01" category="paragraph">다음 표에는 이 솔루션을 구축하는 데 필요한 소프트웨어 구성요소가 나와 있습니다. 이 솔루션을 구체적으로 구축하는 데 사용되는 소프트웨어 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="d20072ce64f4d9efd57e036d2b7c30ec" category="cell">호스트 시스템</block>
  <block id="7915eebeca25d928212b5d457786a549" category="cell">Riva(이전 명칭 JARVIS)</block>
  <block id="1bf6e69c18341244d990250bf5aa3ce0" category="cell">1.4.0</block>
  <block id="7a2cd4790985cbbb0b362dfe8e59d991" category="cell">Tao 툴킷(이전 명칭: 학습 툴킷)</block>
  <block id="55c82b601deae028c1c5e87fd820923d" category="cell">3.0</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="67c6ecbcd91c613e8659b3f0c4b01510" category="cell">9.9.1</block>
  <block id="8bec4fb7fbc1430e393d3f41063748e7" category="cell">DGX OS</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="1b13fe3d4acac980a061d9efb92000d5" category="cell">생년월일</block>
  <block id="d233662f9c26d1a06118c93ef2fd1de9" category="cell">2.0.0</block>
  <block id="76e535c7d7533499b0d86f60a0d15b84" category="section-title">NVIDIA Riva 소프트웨어</block>
  <block id="5d7bf724a19463b3251c61a94a446c4c" category="cell">&gt;19.02(NVIDIA-Docker 설치 시) &gt;=19.03(DGX를 사용하지 않는 경우</block>
  <block id="3ff6010d41ffb33d6f0971a202e76ad7" category="cell">NVIDIA 드라이버</block>
  <block id="616120c1963dd46f2321dd37e823f8a0" category="cell">465.19.01 + 418.40+, 440.33+, 450.51+, 460.27+(데이터 센터 GPU용</block>
  <block id="88f8128d405513d54a3e9831c73f87a0" category="cell">컨테이너 OS</block>
  <block id="73611f9a837b7a25dad3a9c5d1a98658" category="cell">Ubuntu 20.04</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="cell">CUDA</block>
  <block id="a26b47ba45087eadbeaa7c4802b3a8c8" category="cell">11.3.0</block>
  <block id="d92ef06e9564a9db573d075b4220057e" category="cell">큐블라스</block>
  <block id="a8a364c27ce7406b7be591b4f973d5bb" category="cell">11.5.1.101</block>
  <block id="9bfd6cd63a5597c998aa2d96564f5c34" category="cell">큐드NN</block>
  <block id="15daa8f1432fd7e2b07f63097623dfab" category="cell">8.2.0.41</block>
  <block id="1ed15cc4178fd8ec4d845042a8f1ead0" category="cell">NCCL</block>
  <block id="f10585a0c5c8f535143471006baef867" category="cell">2.9.6</block>
  <block id="61918500e2bc645b2aea3f447086a8a5" category="cell">TensorRT</block>
  <block id="086934e5e95d3c797fc75f38fb3d086c" category="cell">7.2.3.4</block>
  <block id="d024876954df77538311467564f00917" category="cell">Triton Inference Server를 참조하십시오</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="2efc85a476098fde0ecbf8d81505b612" category="section-title">NVIDIA TAO 툴킷 소프트웨어</block>
  <block id="cb6c22f673a55391483c7f040d8cf637" category="cell">Ubuntu 18.04 LTS</block>
  <block id="4077fabc9a8b0e761cfd9bf752e03c8a" category="cell">18.04</block>
  <block id="23eeeb4347bdd26bfc6b7ee9a3b755dd" category="cell">파이썬</block>
  <block id="c80362c25c18981fcf433e78dda5de78" category="cell">&gt;= 3.6.9</block>
  <block id="aec7ff22e2f74b581cffbfa59e63f347" category="cell">Docker-CE 를 참조하십시오</block>
  <block id="21ca3af3ea5e6a282911a64dbf5ced7a" category="cell">&gt;19.03.5</block>
  <block id="0cf76d9b00333f4396d0424ae164dd07" category="cell">Docker-API를 지원합니다</block>
  <block id="ca2b7e7213f7ba5d4b3923e807af27df" category="cell">1.40</block>
  <block id="ad2f80b0463af47fcb7430e0e1789841" category="cell">NVIDIA - 컨테이너 - 툴킷</block>
  <block id="12b58130c1d9383cf3bf63391bd04721" category="cell">&gt;1.3.0-1</block>
  <block id="cec57b9746d41fd1c1749d591dbd7baf" category="cell">nvidia-container-runtime</block>
  <block id="68b90d96e3d934d65890ff695d37f354" category="cell">3.4.0-1</block>
  <block id="f235b98dbe494fca328354abf0b52858" category="cell">nVidia-docker2</block>
  <block id="10439f6f665bce43173e2871a0b7bfc6" category="cell">2.5.0-1</block>
  <block id="fd3811d814e856dc6a43152673bb6753" category="cell">nVidia - 드라이버</block>
  <block id="06c61cdd8c93e750b3e0d4e2537416ea" category="cell">&gt;455</block>
  <block id="b6da1806d8ccb5327c3d80bbcfea4737" category="cell">Python-PIP</block>
  <block id="7b043cb99d00fe56df3fead569b1a4de" category="cell">&gt;21.06</block>
  <block id="3bdf92e45d10e51e2bdc2b16cf33f345" category="cell">nVidia-pyindex</block>
  <block id="9ca445b9db010a99239196af5ac3a8b9" category="cell">최신 버전</block>
  <block id="cf87f69879c53ebf670ee8bd793ad7ba" category="section-title">사용 사례 세부 정보</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">이 솔루션은 다음과 같은 사용 사례에 적용됩니다.</block>
  <block id="52a38da70697d6c80e3b6a204f64263f" category="paragraph"><block ref="52a38da70697d6c80e3b6a204f64263f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8ff4a485cc084b2a4b5bb829cf18055" category="paragraph">텍스트 음성 변환 사용 사례는 지원 센터의 오디오 파일을 수집하여 시작합니다. 그런 다음 이 오디오는 Riva가 요구하는 구조에 맞게 처리됩니다. 오디오 파일이 아직 분석 단위로 분할되지 않은 경우 Riva에 오디오를 전달하기 전에 이 작업을 수행해야 합니다. 오디오 파일이 처리되면 Riva 서버에 API 호출로 전달됩니다. 서버는 호스팅 중인 여러 모델 중 하나를 사용하고 응답을 반환합니다. 이 텍스트 음성 변환(자동 음성 인식의 일부)은 오디오의 텍스트 표현을 반환합니다. 여기서 파이프라인은 감정 분석 부분으로 전환됩니다.</block>
  <block id="230007c23660d290efdea5586b1716aa" category="paragraph">감정 분석의 경우 자동 음성 인식의 텍스트 출력은 텍스트 분류에 대한 입력 역할을 합니다. 텍스트 분류는 텍스트를 다양한 범주로 분류하는 NVIDIA 구성 요소입니다. 지원 센터 대화의 경우 긍정적 범주에서 부정적 범주에 이르기까지 다양합니다. 미세 조정 단계의 성공을 결정하기 위해 홀드아웃 세트를 사용하여 모델의 성능을 평가할 수 있습니다.</block>
  <block id="3390cebd79348bc76a1e5eb5f169bedf" category="paragraph"><block ref="3390cebd79348bc76a1e5eb5f169bedf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="952b3f5758e644ef2558d59d3aace0b1" category="inline-link">NVIDIA NGC 카탈로그</block>
  <block id="4fa0a0d712258621946173068bf4f7e0" category="paragraph">TAO 툴키트의 텍스트 음성 및 정서 분석에 비슷한 파이프라인이 사용됩니다. 주요 차이점은 모델의 미세 조정에 필요한 라벨 사용입니다. TAO 툴킷 파이프라인은 데이터 파일 처리부터 시작합니다. 그런 다음 미리 훈련된 모델(에서 제공)을 사용합니다<block ref="aaddb3bb47bcb0ca6e2a55cdce808e9b" category="inline-link-rx"></block>)는 지원 센터 데이터를 사용하여 미세 조정됩니다. 미세 조정된 모델은 해당 성능 메트릭을 기준으로 평가되며, 사전 훈련된 모델보다 성능 기준에 더 적합한 경우 Riva 서버에 배포됩니다.</block>
  <block id="587796d49571c1c4d5c89993d7ed01dd" category="inline-link-macro">다음: 설계 고려 사항.</block>
  <block id="1165e49145cd3a7ebc2b75e325d8797a" category="paragraph"><block ref="1165e49145cd3a7ebc2b75e325d8797a" category="inline-link-macro-rx"></block></block>
  <block id="8537de5688b6b855ec8b5465eca4e8f6" category="list-text">NVIDIA DGX Station, V100 GPU, GPU Cloud</block>
  <block id="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link"><block ref="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link-rx"></block></block>
  <block id="432a0462f3a215c89d6067d01ac9fee8" category="list-text">NVIDIA DGX 스테이션<block ref="00e84bc2760804fd15a292583676639b" category="inline-link-rx"></block></block>
  <block id="a8135dcfdfd9c1074b55895b8d51f9be" category="list-text">NVIDIA V100 Tensor 코어 GPU<block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="f3e44b157fa7ead37042e8a6f3b14071" category="list-text">NGC<block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="45f2cdf50f8bb89b245e814009b4244c" category="list-text">NVIDIA Jarvis 다중 모드 프레임워크</block>
  <block id="944c1fe2317541350506cecb6131b857" category="inline-link"><block ref="944c1fe2317541350506cecb6131b857" category="inline-link-rx"></block></block>
  <block id="d3ceb6166da1ada512f22bc7832ec047" category="list-text">NVIDIA Jarvis<block ref="34ae4389dc7afcada801d63c08e322b9" category="inline-link-rx"></block></block>
  <block id="21ce987b6ba4d344f1427dc72d497669" category="inline-link"><block ref="21ce987b6ba4d344f1427dc72d497669" category="inline-link-rx"></block></block>
  <block id="7bf7a8db8c3809766aa2579c2eadf37d" category="list-text">NVIDIA Jarvis 조기 액세스<block ref="2daee9604c6a07f74e6776847d2ee61e" category="inline-link-rx"></block></block>
  <block id="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link"><block ref="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link-rx"></block></block>
  <block id="852c7bf0a8f3b30a5a001dbf642dbebe" category="list-text">NVIDIA 니모<block ref="fa9e246f0ef36a285adacc70507ae974" category="inline-link-rx"></block></block>
  <block id="299a4717590cda2cfe1db321802b4995" category="inline-link"><block ref="299a4717590cda2cfe1db321802b4995" category="inline-link-rx"></block></block>
  <block id="dfc2ce4fd02d20052bebaa2e6b8cd029" category="list-text">개발자 가이드 를 참조하십시오<block ref="9940ba67713949ce4f2fc05d3a37bd8c" category="inline-link-rx"></block></block>
  <block id="5467c9d1c07a7d1786936650b3c2d52a" category="list-text">NetApp AFF A 시리즈 데이터시트<block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="6bb399f406fc5ac4150ad21c6aa05ab2" category="list-text">All Flash FAS에서 NetApp 플래시의 이점<block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="9415aef2732728cc097fbbc9ab96b2fe" category="list-text">ONTAP 9 정보 라이브러리<block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="d106dc348953acc0500f03a25379282e" category="list-text">NetApp ONTAP FlexGroup 볼륨 기술 보고서<block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="05dbc5885d3bec70d2317a4b51526d96" category="list-text">DGX-1 및 Cisco 네트워킹 기반 ONTAP AI 설계 가이드<block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="af5797305db370f4f59d77bf7c73160b" category="list-text">DGX-1 및 Cisco 네트워킹 지원 ONTAP AI 배포 가이드<block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="f2345b2674d3976c091d4af042c36a8f" category="inline-link"><block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="f63c45f352478237d0d0fe7c5a26d6bf" category="list-text">DGX-1 및 Mellanox 네트워킹 설계 가이드를 지원하는 ONTAP AI<block ref="459df3a4bfb1f89f6920196001257745" category="inline-link-rx"></block></block>
  <block id="b38db7c217c396412f601b87dfc58a8c" category="inline-link"><block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="da8009e462fd2ec5eeb41b4cf3721f7a" category="list-text">DGX-2 기반 ONTAP AI 설계 가이드<block ref="86d70269673ee41c37a2673f7d3655ce" category="inline-link-rx"></block></block>
  <block id="3a607d0e3fa64fd7558e11352f751dd0" category="summary">NetApp AI Control Plane 솔루션은 이 특정 하드웨어에 종속되지 않습니다.</block>
  <block id="976cf3edd8adeff2e75cd7a9dd0dae21" category="paragraph">NetApp AI Control Plane 솔루션은 이 특정 하드웨어에 종속되지 않습니다. 이 솔루션은 Trident에서 지원하는 모든 NetApp 물리적 스토리지 어플라이언스, 소프트웨어 정의 인스턴스 또는 클라우드 서비스와 호환됩니다. 예를 들어 NetApp AFF 스토리지 시스템, Azure NetApp Files, NetApp Cloud Volumes Service, NetApp ONTAP Select 소프트웨어 정의 스토리지 인스턴스 또는 NetApp Cloud Volumes ONTAP 인스턴스가 있습니다. 또한, 사용된 Kubernetes 버전이 Kubeflow 및 NetApp Trident에서 지원하는 경우 모든 Kubernetes 클러스터에서 구현할 수 있습니다. Kubeflow에서 지원하는 Kubernetes 버전 목록은 를 참조하십시오<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Trident에서 지원하는 Kubernetes 버전 목록은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>. 솔루션을 검증하는 데 사용된 환경에 대한 자세한 내용은 다음 표를 참조하십시오.</block>
  <block id="2e4fd4a404800f52299c132a3403dc72" category="cell">인프라 구성 요소</block>
  <block id="64d354dc5879cf570ce7b4ef676e75bd" category="cell">운영 체제</block>
  <block id="4152ac69f367cb5f64dfbc247dd41db0" category="cell">배포 점프 호스트</block>
  <block id="583a65df9db4119165f5ea0abaa50281" category="cell">VM</block>
  <block id="204dd0a482d284a7fb87c908f713f9bd" category="cell">Ubuntu 20.04.2 LTS</block>
  <block id="f341fd2fe180518e152be2d6fb4ec20b" category="cell">Kubernetes 마스터 노드</block>
  <block id="a89c263b82f7c7f61c9b6c93080f8425" category="cell">Kubernetes 작업자 노드</block>
  <block id="76a7e6383604f84ace970ce86ba76a9f" category="cell">Kubernetes GPU 작업자 노드</block>
  <block id="f89b34b046a8d6e3137c95861fa3cf8a" category="cell">NVIDIA DGX-1(베어 메탈)</block>
  <block id="eba551f3f972830c55b1c9bef15b5f26" category="cell">NVIDIA DGX OS 4.0.5(Ubuntu 18.04.2 LTS 기준)</block>
  <block id="0911ffdbb76c891f964e39a07eb6b697" category="cell">1개의 HA 쌍</block>
  <block id="d1d73cf191d1afbd40e85644467cae8b" category="cell">NetApp ONTAP 9.7 P6</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">소프트웨어 구성 요소</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">아파치 기류</block>
  <block id="47354877541923135499c38a6606138a" category="cell">2.0.1</block>
  <block id="9ba69bd971d430b368ce3f0286c8e77c" category="cell">Apache Airflow Helm Chart(Apache Airflow 제어 차트</block>
  <block id="ecfa741d55b7b1a85bd61a2307877c8c" category="cell">8.0.8</block>
  <block id="fd99a7ef225418315b041ad631a5674c" category="cell">2012년 3월 19일</block>
  <block id="56765472680401499c79732468ba4340" category="cell">1.2</block>
  <block id="48d02190984e4f8526f99f9cd9550e08" category="cell">1.18.9</block>
  <block id="d58d49f83f534f5d71b20750bb7927c7" category="cell">21.01.2</block>
  <block id="7a04e1f765218bcbfc633ef331b312b8" category="inline-link-macro">61898cdfda</block>
  <block id="7855beff2fafbce2cf0df4d67f8dfed7" category="cell">커밋 시 마스터 분기의 Trident 배포 기능 <block ref="686ead03155c78694e1a59db0970fc1a" category="inline-link-macro-rx"></block>버전 21.03의 다른 모든 기능</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">지원</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">NetApp에 문의하십시오</block>
  <block id="a1773dfa99aa26853e90886d55e0d05a" category="paragraph">NetApp은 Apache Airflow, Docker, Kubeflow, Kubernetes 또는 NVIDIA DeepOps에 대한 엔터프라이즈 지원을 제공하지 않습니다. NetApp AI Control Plane 솔루션과 유사한 기능을 갖춘 완벽한 지원 솔루션을 원하는 경우, <block ref="103a4ac9affe57bb7edb7796bfdeb684" category="inline-link-macro-rx"></block> NetApp이 파트너와 공동으로 제공하는 완전 지원되는 AI/ML 솔루션 정보</block>
  <block id="26c21566450ecb01d82e6d0e3f7ef1a3" category="inline-link-macro">다음: Kubernetes 배포.</block>
  <block id="0635bed13bdc0ace58fec0264ac3d119" category="paragraph"><block ref="0635bed13bdc0ace58fec0264ac3d119" category="inline-link-macro-rx"></block></block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">이 섹션에서는 이 솔루션을 검증하는 데 사용되는 테스트 절차를 설명합니다.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">테스트 절차</block>
  <block id="e46c1f341c1cea1321f4c00d15e90b0d" category="inline-link-macro">이전: 구성을 테스트합니다.</block>
  <block id="ed760d2dffd7d011a7870619f7884005" category="paragraph"><block ref="ed760d2dffd7d011a7870619f7884005" category="inline-link-macro-rx"></block></block>
  <block id="bff816e8e8ddbe2a3b705d92abba6627" category="paragraph">이 검증에서 다음 테스트 절차를 사용했습니다.</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">운영 체제 및 AI 추론 설정</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">AFF C190의 경우 NVIDIA GPU를 지원하고 MLPerf를 사용하는 NVIDIA 드라이버 및 Docker와 함께 Ubuntu 18.04를 사용했습니다<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> MLPerf Inference v0.7에 대한 Lenovo 제출의 일부로 사용할 수 있습니다.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">EF280의 경우 NVIDIA GPU 및 MLPerf를 지원하는 Ubuntu 20.04와 NVIDIA 드라이버 및 Docker를 사용했습니다<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> MLPerf Inference v1.1에 대한 Lenovo 제출의 일부로 제공됩니다.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">AI 추론을 설정하려면 다음 단계를 수행하십시오.</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">등록이 필요한 데이터 세트, ImageNet 2012 검증 세트, Critio Terabyte 데이터 세트 및 브라츠 2019 교육 세트를 다운로드한 다음 파일의 압축을 풉니다.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">최소 1TB의 작업 디렉토리를 생성하고 디렉토리를 참조하는 환경 변수 MLPERF_Scratch_path를 정의합니다.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">네트워크 스토리지 활용 사례나 로컬 데이터로 테스트할 때 로컬 디스크에 대해 공유 스토리지에서 이 디렉토리를 공유해야 합니다.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">make "prebuild" 명령을 실행하여 필요한 추론 작업을 위해 Docker 컨테이너를 빌드하고 실행합니다.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">다음 명령은 실행 중인 Docker 컨테이너 내에서 모두 실행됩니다.</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">MLPerf Inference 태스크에 대한 사전 교육 AI 모델 'MAKE download_model'을 다운로드합니다</block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">무료로 다운로드할 수 있는 추가 데이터셋 'make download_data'를 다운로드하세요</block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">데이터 사전 처리: preprocess_data를 만든다</block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">러닝: 메이크 빌드.</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">컴퓨팅 서버의 GPU에 최적화된 추론 엔진 'make generate_gservers'를 구축합니다</block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">추론 워크로드를 실행하려면 다음 명령을 실행합니다(하나의 명령).</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">AI 추론 실행</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">세 가지 유형의 실행이 실행되었습니다.</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">로컬 스토리지를 사용하는 단일 서버 AI 추론</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">네트워크 스토리지를 사용하여 단일 서버 AI 추론</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">네트워크 스토리지를 사용하여 다중 서버 AI 추론</block>
  <block id="7dc96590f7bab3379a7a79986056d22a" category="inline-link-macro">다음: 테스트 결과.</block>
  <block id="697d202c2969580ba0434be04d39a929" category="paragraph"><block ref="697d202c2969580ba0434be04d39a929" category="inline-link-macro-rx"></block></block>
  <block id="d052a88935efadcc9eebf94684d52e19" category="doc">높은 클러스터 사용률 달성</block>
  <block id="8d46742dbd21a217f738a9ca6a31f634" category="paragraph">이 섹션에서는 GPU 리소스의 우선순위 지정 및 밸런싱을 유지하면서 높은 클러스터 사용률을 달성하는 Run:AI 오케스트레이션 솔루션을 시연하기 위해 4개의 데이터 과학 팀이 각자 고유의 워크로드를 제출하는 실제 시나리오를 에뮬레이트합니다. 먼저 섹션에 설명된 ResNet-50 벤치마크를 사용합니다 <block ref="5872a8c23866a6bf186843724ee58ad7" category="inline-link-macro-rx"></block>:</block>
  <block id="14f48338822299bdf82bb4528d3c9e07" category="paragraph">에서와 같이 ResNet-50 벤치마크를 실행했습니다<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block>. 우리는 공공 Docker 리포지토리에 없는 컨테이너에 '--local-image' 플래그를 사용했습니다. 호스트 DGX-1 노드의 /mnt와 /tmp 디렉토리를 각각 컨테이너에 `/mnt', '/tmp' 디렉토리에 마운트했습니다. 데이터 세트는 디렉토리를 가리키는 dataset_dir와 함께 NetApp AFFA800에 있습니다. '--num_devices=1'과 '-g 1'은 이 작업에 하나의 GPU를 할당한다는 것을 의미합니다. 전자는 run.py 스크립트의 주장이고 후자는 runai submit 명령의 플래그입니다.</block>
  <block id="bccb844975c2eec86eb25c0d8e2a989b" category="paragraph">다음 그림은 97%의 GPU 사용률과 16개의 사용 가능한 GPU가 할당된 시스템 개요 대시보드를 보여 줍니다. GPU/프로젝트 막대 차트에서 각 팀에 할당된 GPU 수를 쉽게 확인할 수 있습니다. 실행 중인 작업 창에는 현재 실행 중인 작업 이름, 프로젝트, 사용자, 유형, 노드, GPU 사용량, 실행 시간, 진행률 및 활용률 세부 정보 대기 시간이 있는 대기열의 워크로드 목록이 보류 중인 작업에 표시됩니다. 마지막으로, 노드 상자는 클러스터의 개별 DGX-1 노드에 대한 GPU 수와 활용률을 제공합니다.</block>
  <block id="1acc627e7c9d8002628b2e12c91ac683" category="paragraph"><block ref="1acc627e7c9d8002628b2e12c91ac683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5d3b5670d9303fddfb021e681546c0" category="inline-link-macro">다음으로, 덜 까다롭거나 대화형 워크로드에 대한 GPU 할당 분수를 지정합니다</block>
  <block id="3d9997e0f8b3b6a279c8779455e7c760" category="paragraph"><block ref="3d9997e0f8b3b6a279c8779455e7c760" category="inline-link-macro-rx"></block></block>
  <block id="66bc9494be0116470b223f2e07873f77" category="summary">이 페이지에서는 NetApp AI Control Plane 솔루션을 구현하기 위해 Kubernetes 클러스터를 구축하는 데 필요한 작업에 대해 설명합니다. Kubernetes 클러스터가 이미 있는 경우, Kubeflow 및 NetApp Trident에서 지원하는 Kubernetes 버전을 실행 중인 경우 이 섹션을 건너뛸 수 있습니다.</block>
  <block id="7c1ab988344d6a8d8cd9a30d6240955a" category="paragraph">이 섹션에서는 NetApp AI Control Plane 솔루션을 구현하기 위해 Kubernetes 클러스터를 구축하는 데 필요한 작업에 대해 설명합니다. Kubernetes 클러스터가 이미 있는 경우, Kubeflow 및 NetApp Trident에서 지원하는 Kubernetes 버전을 실행 중인 경우 이 섹션을 건너뛸 수 있습니다. Kubeflow에서 지원하는 Kubernetes 버전 목록은 를 참조하십시오<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Trident에서 지원하는 Kubernetes 버전 목록은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="ef8333b35fd982099a6ca0c7799b5618" category="paragraph">NVIDIA GPU를 탑재한 베어 메탈 노드를 포함하는 온프레미스 Kubernetes 배포의 경우 NVIDIA의 DeepOps Kubernetes 배포 도구를 사용하는 것이 좋습니다. 이 섹션에서는 DeepOps를 사용하여 Kubernetes 클러스터 구축에 대해 간략하게 설명합니다.</block>
  <block id="612cba744b0eac9a7f153d2c4b8975da" category="list-text">표준 구성 지침에 따라 베어 메탈 Kubernetes 노드(예: ONTAP AI 포드의 일부인 NVIDIA DGX 시스템)를 이미 구성했습니다.</block>
  <block id="5a881e8e37e19924ac592136b5e7cfd3" category="inline-link">DeepOps GitHub 사이트</block>
  <block id="452f5f6e8da4512f6cce223a76ae3558" category="list-text">모든 Kubernetes 마스터 및 작업자 노드와 배포 점프 호스트에 지원되는 운영 체제를 설치했습니다. DeepOps에서 지원하는 운영 체제 목록은 를 참조하십시오<block ref="253a2cf380d7db7eaadb375aa91e2221" category="inline-link-rx"></block>.</block>
  <block id="a711e4ccced882d1762a8c653be8e921" category="section-title">NVIDIA DeepOps를 사용하여 Kubernetes 설치 및 구성</block>
  <block id="0e91d2e60705ecb1730e9b96510019af" category="list-text">의 지침에 따라 NVIDIA DeepOps를 다운로드합니다<block ref="6fb71807bf6999d2aec034d498e3ebf6" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="2ed5978807d3da780c60a19b3f38a293" category="inline-link">Kubernetes 배포 가이드 페이지</block>
  <block id="5c18e4efa8c5cc9efb26e3f748b4e26d" category="list-text">의 지침에 따라 클러스터에 Kubernetes를 배포합니다<block ref="b336a8bbad16f0e8d58bf87e261f51fa" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="e76934323b48d5421aa2271f7e9fbee2" category="inline-link-macro">다음으로, NetApp Trident 구축 및 구성 개요 를 참조하십시오.</block>
  <block id="4e3ff90ed271e98a6802a9063034ea76" category="paragraph"><block ref="4e3ff90ed271e98a6802a9063034ea76" category="inline-link-macro-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">이 섹션에서는 테스트된 구성, 네트워크 인프라, SE350 서버 및 스토리지 프로비저닝 세부 정보에 대해 설명합니다.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">구성을 테스트합니다</block>
  <block id="b1ee26c1917a17c30b17d7cd6b01e2cd" category="inline-link-macro">이전: 테스트 계획.</block>
  <block id="7dffe110836fe412eac19d0f63cf5b5b" category="paragraph"><block ref="7dffe110836fe412eac19d0f63cf5b5b" category="inline-link-macro-rx"></block></block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">다음 그림은 테스트 구성을 보여 줍니다. NetApp AFF C190 스토리지 시스템과 Lenovo ThinkSystem SE350 서버 2대(각각 NVIDIA T4 가속기 1대)를 사용했습니다. 이러한 구성요소는 10GbE 네트워크 스위치를 통해 연결됩니다. 네트워크 스토리지는 검증/테스트 데이터 세트와 사전 교육 모델을 보유하고 있습니다. 서버는 컴퓨팅 기능을 제공하며 스토리지는 NFS 프로토콜을 통해 액세스됩니다.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">이 섹션에서는 테스트된 구성, 네트워크 인프라, SE350 서버 및 스토리지 프로비저닝 세부 정보에 대해 설명합니다. 다음 표에서는 솔루션 아키텍처의 기본 구성 요소를 보여 줍니다.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">솔루션 구성 요소</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">각각 NVIDIA T4 GPU 카드 1개가 장착된 SE350 서버 2대</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">각 서버에는 2.20GHz 및 128GB RAM에서 4개의 물리적 코어가 실행되는 Intel Xeon D-2123IT CPU 1개가 포함되어 있습니다</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">엔트리 레벨 NetApp AFF 스토리지 시스템(HA 쌍,</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 소프트웨어</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24x 960GB SSD</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFS 프로토콜</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">컨트롤러당 1개의 인터페이스 그룹으로, 마운트 지점에 4개의 논리 IP 주소를 사용합니다</block>
  <block id="1a538c197da3186f1eba50d82572dc34" category="paragraph"><block ref="1a538c197da3186f1eba50d82572dc34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">다음 표에는 스토리지 구성이 2RU, 24개 드라이브 슬롯이 포함된 AFF C190에 나와 있습니다.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">컨트롤러</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">집계</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroup 볼륨</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">애그리게이트 크기</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">볼륨 크기</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">운영 체제 마운트 지점</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">컨트롤러1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">집계1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_FG</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/NetApp_Lenovo_FG입니다</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">컨트롤러 2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">집계2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">/netappLenovo_AI_FG 폴더에는 모델 검증에 사용된 데이터 세트가 포함되어 있습니다.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">아래 그림은 테스트 구성을 보여 줍니다. NetApp EF280 스토리지 시스템과 두 개의 Lenovo ThinkSystem SE350 서버(각각 NVIDIA T4 가속기 1개 포함)를 사용했습니다. 이러한 구성요소는 10GbE 네트워크 스위치를 통해 연결됩니다. 네트워크 스토리지는 검증/테스트 데이터 세트와 사전 교육 모델을 보유하고 있습니다. 서버는 컴퓨팅 기능을 제공하며 스토리지는 NFS 프로토콜을 통해 액세스됩니다.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">다음 표에는 EF280에 대한 스토리지 구성이 나와 있습니다.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">볼륨 그룹</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">볼륨</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDPsize를 참조하십시오</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">연결 방법</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">볼륨 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1에서 iSCSI LUN 0으로</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">볼륨 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2를 iSCSI LUN 1로 설정합니다</block>
  <block id="43fa57e4031b0f759153c9c9fa49e6ed" category="paragraph"><block ref="43fa57e4031b0f759153c9c9fa49e6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0fccd40a3886a1e5dc539059407586a0" category="inline-link-macro">다음: 테스트 절차</block>
  <block id="3bee5237e36a9a0dc60fd351ce904544" category="paragraph"><block ref="3bee5237e36a9a0dc60fd351ce904544" category="inline-link-macro-rx"></block></block>
  <block id="9dc7cfc5bd8fb85bad9fdab5cdded288" category="doc">AI 설치 를 실행하십시오</block>
  <block id="c1b7d088e01f6ec6ec89bf69437e4bb1" category="paragraph">Run:AI를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="7ad0483bc07dbde29ffd404af83f8305" category="list-text">DeepOps를 사용하여 Kubernetes 클러스터를 설치하고 NetApp 기본 스토리지 클래스를 구성합니다.</block>
  <block id="16d20d34f759cd25fd7486bbc4046a50" category="list-text">GPU 노드 준비:</block>
  <block id="d3eff3861b26ba61222bacaa41bc0fa7" category="list-text">NVIDIA 드라이버가 GPU 노드에 설치되었는지 확인합니다.</block>
  <block id="3683aa7fe695a205b8e40e9589c94a2e" category="list-text">nVidia-docker가 기본 Docker 런타임으로 설치 및 구성되어 있는지 확인합니다.</block>
  <block id="cef990020518a58fb1e70a90b5df80fe" category="list-text">러닝 설치: AI:</block>
  <block id="e2d6778a342979b567501f951e36118a" category="inline-link">AI 관리자 UI를 실행합니다</block>
  <block id="6fc7ea9b01c6028f691aac2aeac528f1" category="list-text">에 로그인합니다<block ref="668d940d94d02be49a88c4cfd2736fa9" category="inline-link-rx"></block> 클러스터를 생성합니다.</block>
  <block id="fe8f08cfda6726e2dcc5d0b85ed2c67d" category="list-text">생성된 'runai-operator-&lt;clustername&gt;.yAML' 파일을 다운로드합니다.</block>
  <block id="b428155da5c27d208abd6c179c7669d3" category="list-text">Kubernetes 클러스터에 운영자 구성을 적용하십시오.</block>
  <block id="fac4447e0ea2e4cd1a2d9e2fefeab694" category="list-text">설치를 확인합니다.</block>
  <block id="2d14c64dc5dfa79a68cd6965fbf9e4b7" category="list-text">로 이동합니다<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>.</block>
  <block id="feb48a27d95fc7a7e0c6db496c54d2fa" category="list-text">개요 대시보드로 이동합니다.</block>
  <block id="09fa3891e2b39bb62217c6d097310577" category="inline-link">Run 설치: 사내 Kubernetes 클러스터에 AI를 설치합니다</block>
  <block id="45d7be937e1eddf966adaf68562966d4" category="inline-link">Run:AI CLI 설치</block>
  <block id="728f8fd776de1dc47f318473052286db" category="list-text">오른쪽 위에 있는 GPU 수가 예상 GPU 수를 반영하고 GPU 노드가 모두 서버 목록에 있는지 확인합니다.실행:AI 배포에 대한 자세한 내용은 을 참조하십시오<block ref="089aa48f8d7b3b135b035765dd1e17ba" category="inline-link-rx"></block> 및<block ref="f2f48a2074c9edc0c2dea174863a4f6e" category="inline-link-rx"></block>.</block>
  <block id="db9d1f740f050b1d20ab43a459bb225a" category="inline-link-macro">다음: AI 대시보드 및 보기를 실행합니다</block>
  <block id="c56b5d251d18e9b020f95696fef9f0b9" category="paragraph"><block ref="c56b5d251d18e9b020f95696fef9f0b9" category="inline-link-macro-rx"></block></block>
  <block id="ff9caff469d56a572a569942ca24c8b4" category="list-text">NVIDIA DGX 시스템</block>
  <block id="b69073c22b4269568fd577ea090ce638" category="list-text">NVIDIA DGX-1 시스템<block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="fe287c518b9b1345defadacdc6a9ecbf" category="list-text">NVIDIA V100 Tensor 코어 GPU<block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="d6a8716635a5681cde357a465953bc72" category="list-text">NGC<block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="11bdb18e1c5e7d1e4362c9d2f6956fc8" category="list-text">실행: AI 컨테이너 오케스트레이션 솔루션</block>
  <block id="5afc85c81e76f427a293dd861e0109a3" category="list-text">실행: AI 제품 소개<block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="9acfbb098f0d9b45b5897b44ae347ee9" category="list-text">AI 설치 설명서를 실행하십시오<block ref="cb05a776556ca5a25aec417185ef6863" category="inline-link-rx"></block>
<block ref="b2e8533fae57aa9047d7731db51b6dfe" category="inline-link-rx"></block></block>
  <block id="b0d8a6d0eebdc42ac243c16f9137118d" category="list-text">Run:AI CLI에서 작업 제출<block ref="97ec6c214f99d7e6a39194a167aeecc8" category="inline-link-rx"></block>
<block ref="d75350381b5fda5cc9c9a1ce34c24299" category="inline-link-rx"></block></block>
  <block id="9bd35f4f3f6faa9e9330c54fd2086967" category="list-text">실행 시 GPU 분할 할당: AI CLI<block ref="e343516de5fb56c6a0d652bcdfceaab7" category="inline-link-rx"></block></block>
  <block id="ddb27cb97146c8f5964eaf368feb4ce0" category="list-text">기술 보고서<block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="2273cd603e277bb35f96881a557b0608" category="list-text">간단한 데모<block ref="61e3673018126d9a106032d9ff691322" category="inline-link-rx"></block></block>
  <block id="45f26b752dfae88ec8c7def446162521" category="list-text">GitHub 리포지토리<block ref="f9a4909739179bedfa8ba1d225598979" category="inline-link-rx"></block></block>
  <block id="c36e36ff8b7edf8dd17781148ed57337" category="list-text">NetApp AFF A 시리즈 데이터시트<block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="ffc4c8e8bc10afc438d9c590f44e3b51" category="list-text">All Flash FAS에서 NetApp 플래시의 이점<block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="7843ce52c43038d88c2f54d85f3f764d" category="list-text">ONTAP 9 정보 라이브러리<block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="5f1b8a708e16776ca4372c71dc377653" category="list-text">NetApp ONTAP FlexGroup 볼륨 기술 보고서<block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="062d7e5979c653f33e03cb0aaeaec6e9" category="list-text">DGX-1 및 Cisco 네트워킹 기반 ONTAP AI 설계 가이드<block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="59086e50189644b7c19947dfa68f8395" category="list-text">DGX-1 및 Cisco 네트워킹 지원 ONTAP AI 배포 가이드<block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="062afad089226e62b53e77ba2af24574" category="list-text">DGX-1 및 Mellanox 네트워킹 설계 가이드를 지원하는 ONTAP AI<block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="e6b737f0513721f0a8024f538058333e" category="list-text">DGX-2 기반 ONTAP AI 설계 가이드<block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="a905494ad30a6d54678a2122c04bfd54" category="summary">Jupyter Notebooks 및 Kubeflow 파이프라인 예제</block>
  <block id="80e94617849fe0b057f3edcc76a6ac72" category="doc">예제 전자 필기장 및 파이프라인</block>
  <block id="3da57858cd6a76521b38784effc6a06f" category="paragraph">를 클릭합니다<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Kubeflow와 함께 사용할 수 있습니다. Kubeflow와 함께 NetApp Data Science Toolkit을 사용하면 다음과 같은 이점이 있습니다.</block>
  <block id="624a53dc5871ce49612a285ee2bf367e" category="list-text">데이터 과학자는 Jupyter Notebook 내에서 직접 고급 NetApp 데이터 관리 작업을 수행할 수 있습니다.</block>
  <block id="1c7d37cb415e8b7777b071784911a77a" category="list-text">고급 NetApp 데이터 관리 작업은 Kubeflow 파이프라인 프레임워크를 사용하여 자동화된 워크플로우에 통합할 수 있습니다.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflow 예</block>
  <block id="987823970c7b662272fb9e0058bf5ff1" category="paragraph">을 참조하십시오<block ref="3eb5d4ffd5360858e22dfb9799f211d7" category="inline-link-rx"></block> Kubeflow 기반 툴킷 사용에 대한 자세한 내용은 NetApp Data Science Toolkit GitHub 리포지토리 를 참조하십시오.</block>
  <block id="52a739b78342bd0cef8801d4c5c193b6" category="inline-link-macro">다음: Apache Airflow Deployment</block>
  <block id="6564dd7688129caf4acb63587998eb65" category="paragraph"><block ref="6564dd7688129caf4acb63587998eb65" category="inline-link-macro-rx"></block></block>
  <block id="dc12a1ce34c0a7a264de91bc9b933a62" category="paragraph">이 섹션에서는 'team-d'가 더 많은 GPU(할당량 아래)를 요청할 때 시스템이 'team-b'와 'team-c'의 워크로드를 일시 중지하고 공평한 분배 방식으로 보류 중인 상태로 전환한다는 것을 보여 줍니다.</block>
  <block id="86bbd55ea7850716c0c192b19c86176a" category="paragraph">작업 제출, 사용된 컨테이너 이미지 및 실행된 명령 시퀀스를 포함한 자세한 내용은 섹션을 참조하십시오 <block ref="94d73a1896276f719be59227f0e93a14" category="inline-link-macro-rx"></block>.</block>
  <block id="b6ea2a2f48a443e7d027bd652ac84762" category="paragraph">다음 그림은 자동 로드 밸런싱 및 사전 예방 예약 기능으로 인해 발생하는 클러스터 활용률, 팀당 할당된 GPU 및 보류 중인 작업을 보여줍니다. 모든 팀 작업 부하에 의해 요청된 총 GPU 수가 클러스터에서 사용 가능한 총 GPU 수를 초과할 때 Run:AI의 내부 공정성 알고리즘은 프로젝트 할당량을 충족했기 때문에 "team-b"와 "team-c"에 대해 각각 하나의 작업을 일시 중지한다는 것을 알 수 있습니다. 따라서 전반적인 높은 클러스터 활용률이 제공되지만 데이터 과학 팀은 관리자가 설정한 리소스 제약 조건에서 작업을 계속 수행할 수 있습니다.</block>
  <block id="d1a54cf8cb2a06c0715d2f042fbf44bd" category="paragraph"><block ref="d1a54cf8cb2a06c0715d2f042fbf44bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d52816ece2166f7a2e0eadf58d617df9" category="paragraph">이 테스트 시나리오의 결과는 다음과 같습니다.</block>
  <block id="bce83ec0a92a5b10380007a1643b2fd0" category="list-text">* 자동 로드 밸런싱. * 시스템은 GPU의 할당량을 자동으로 조정하여 각 팀에서 현재 할당량을 사용하고 있습니다. 일시 중지된 워크로드는 할당량이 초과된 팀에 속합니다.</block>
  <block id="f8be0d1ca354f8cb4aaa4c8aadcea80b" category="list-text">* 공정한 공유 일시 중지. * 시스템이 할당량이 초과된 팀의 작업 부하를 중지하도록 선택한 다음 다른 팀의 작업 부하를 중지시킵니다. 실행: AI에는 내부 공정성 알고리즘이 있습니다.</block>
  <block id="c088b6e407ba7f9c0274382acfa3eae0" category="inline-link-macro">다음: 할당량 초과 공정성</block>
  <block id="8e015e1b989b11d70fcb778747b8c614" category="paragraph"><block ref="8e015e1b989b11d70fcb778747b8c614" category="inline-link-macro-rx"></block></block>
  <block id="48fe531f68f98f9f6afcf79da6d3b1b3" category="doc">TR-4834: MLRun 파이프라인에 대한 NetApp과 Iguazio</block>
  <block id="a0e5bba9c75f65c1d58c6a238316bd2b" category="paragraph">Rick Huang, David Arnette, NetApp Marcelo Litovsky, Iguazio</block>
  <block id="dd9508a891c15cc4bb34f03dc870ab6c" category="paragraph">이 문서에서는 NetApp ONTAP AI, NetApp AI Control Plane, NetApp Cloud Volumes 소프트웨어 및 Iguazio 데이터 과학 플랫폼을 사용하는 MLRun 파이프라인의 세부 정보를 다룹니다. Nuclio serverless 기능, Kubernetes Persistent Volumes, NetApp Cloud Volumes, NetApp Snapshot 복사본, Grafana 대시보드를 사용했습니다. 네트워크 장애 감지 시뮬레이션을 위한 종단 간 데이터 파이프라인을 구축하기 위한 Iguazio 플랫폼의 기타 서비스. Iguazio 및 NetApp 기술을 통합하여 사내와 클라우드에서 모델 구축, 데이터 복제 및 운영 모니터링 기능을 빠르게 구현합니다.</block>
  <block id="d431a0ad3e0e99cf99c08fda529884bd" category="paragraph">데이터 과학자의 작업은 머신 러닝(ML) 및 인공 지능(AI) 모델의 훈련 및 튜닝에 중점을 두어야 합니다. 그러나 Google의 조사에 따르면 데이터 과학자는 다음 이미지에서와 같이 모델을 엔터프라이즈 애플리케이션과 연동하고 대규모로 실행하는 방법을 찾는 데 80% 정도 시간을 소비합니다. AI/ML 워크플로우에서 모델 개발을 묘사한 것으로 나타났습니다.</block>
  <block id="f08b641e59dba6d999dc1bc2085bcd2c" category="paragraph"><block ref="f08b641e59dba6d999dc1bc2085bcd2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eec0363d19df86d30ecefc2e44170fa" category="paragraph">엔드 투 엔드 AI/ML 프로젝트를 관리하려면 엔터프라이즈 구성 요소를 더 잘 이해해야 합니다. DevOps가 이러한 유형의 구성 요소를 정의, 통합 및 배포했지만 머신 러닝 작업은 AI/ML 프로젝트를 포함하는 비슷한 흐름을 목표로 합니다. 엔터프라이즈에서 엔드 투 엔드 AI/ML 파이프라인이 어떤 영향을 받는지 알아보려면 다음 필수 구성요소 목록을 참조하십시오.</block>
  <block id="52681719ec1296447ae0e357c4781415" category="list-text">개발 IDE(통합 개발 환경)</block>
  <block id="2f0ff7df4fd6fa99bbf249af2ea4c3a5" category="paragraph">이 문서에서는 NetApp과 Iguazio 간의 파트너십을 통해 엔드 투 엔드 AI/ML 파이프라인 개발을 획기적으로 단순화하는 방법을 보여줍니다. 이러한 단순화 덕분에 모든 AI/ML 애플리케이션의 출시 시기를 앞당길 수 있습니다.</block>
  <block id="253411380ba9cde08bcfafbd516ad585" category="paragraph">데이터 과학의 세계는 정보 기술 및 비즈니스의 여러 분야에 영향을 줍니다.</block>
  <block id="f1a4e0eca545ebe9e3c32f1fde407410" category="list-text">비즈니스 사용자는 AI/ML 애플리케이션에 액세스할 수 있기를 원합니다. NetApp과 Iguazio가 각 역할을 통해 당사의 플랫폼을 통해 비즈니스에서 가치를 창출하는 방법을 설명합니다.</block>
  <block id="00cc9e5c959e62a9132baca479060db3" category="paragraph">이 솔루션은 AI/ML 애플리케이션의 라이프사이클 뒤에 있습니다. 먼저 데이터 과학자의 작업을 통해 데이터를 준비하고 모델을 훈련 및 구축하는 데 필요한 다양한 단계를 정의합니다. 또한 아티팩트를 추적하고, 실행을 실험하고, Kubeflow에 배포할 수 있는 능력을 갖춘 전체 파이프라인을 생성하는 데 필요한 작업을 수행합니다. 전체 주기를 완료하기 위해 NetApp Cloud Volumes와 파이프라인을 통합하여 다음 이미지와 같이 데이터 버전 관리를 지원합니다.</block>
  <block id="ddd4a11ec23c52d3f0831809bc4d7c8f" category="paragraph"><block ref="ddd4a11ec23c52d3f0831809bc4d7c8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7c8cd7998e5c4a67923acf8580d94e2" category="inline-link-macro">다음: 기술 개요</block>
  <block id="b9023dede6231d8f57593d31db930bf6" category="paragraph"><block ref="b9023dede6231d8f57593d31db930bf6" category="inline-link-macro-rx"></block></block>
  <block id="d9ed812c8dd9083f1fb345425b8ce100" category="paragraph">이 섹션에서는 섹션의 테스트 세부 정보를 다룹니다 <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>.</block>
  <block id="be53a0541a6d36f6ecb879fa2c584b08" category="cell">이미지</block>
  <block id="c6e328a3639bc00374d81e681f89f609" category="cell">Jupyter를 선택합니다</block>
  <block id="ff8bed43ac09b1148fc7648f5845f698" category="cell">1/4</block>
  <block id="37ce74088416f28dc9bb04355c2e5a28" category="cell">–</block>
  <block id="cfaa375bf6c7f9fcc1bc04d4f30c9154" category="cell">넷엡</block>
  <block id="6408e079aefee9702aa00f77228dd941" category="cell">2월 4일</block>
  <block id="00833fac70036c049bd75443869cacb5" category="cell">실행: AI</block>
  <block id="d2313e844e73fe4a8f63d93f4df355fc" category="cell">모든 할당량을 사용합니다</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="e4275e3860ed32f489dbb6a5d4a10f5f" category="cell">0.6/2</block>
  <block id="8457d97e0a0f74a5926d1dee27e53541" category="cell">소수점 GPU</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="975ca8804565c1a569450d61090b2743" category="cell">1/2로</block>
  <block id="411472b1216ec08457e653eac42d7bbd" category="cell">2개 초과 할당량</block>
  <block id="d310cb367d993fb6fb584b198a2fd72c" category="cell">0.5</block>
  <block id="76169512ef5ca1abe70b32c0993856af" category="cell">0.5/2</block>
  <block id="e85b79abfd76b7c13b1334d8d8c194a5" category="cell">0.3</block>
  <block id="5c2b079fc9750c2995852b8fb354aae3" category="cell">2월 8일</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="00fd1da21e8b4ef31d987665dc575099" category="cell">3월 2일</block>
  <block id="0375b76ff57435094e28e94015a5f052" category="cell">1개 초과 할당</block>
  <block id="ecdb9acc2db02134680a9c49abe3e991" category="cell">8월 4일</block>
  <block id="30c006c71ada68e2273b128bc2e6831b" category="cell">할당량의 절반을 사용합니다</block>
  <block id="36cf0dc9f04c54214fa577ec66ff53fc" category="paragraph">명령 구조:</block>
  <block id="7b3a4ccf5e0cc7918cd458f7e46b9c8e" category="paragraph">테스트에 사용된 실제 명령 시퀀스:</block>
  <block id="478eb1c4e698b325048b6bccfb8974f6" category="cell">4/4(소프트 할당량/실제 할당)</block>
  <block id="2df6f557cc57e6d4044b9611b1f56439" category="inline-link-macro">Over-uota GPU 할당을 통한 높은 클러스터 활용률 달성</block>
  <block id="3667ebc7f28f59fc13bfcf314c67de05" category="paragraph">섹션을 참조하십시오 <block ref="dee5d16c649661a62d3a765af5b1a963" category="inline-link-macro-rx"></block> 진행 중인 테스트 시나리오에 대한 논의.</block>
  <block id="ac8466404b94a669f51a3d2db2401cf0" category="inline-link-macro">다음: 섹션 4.9의 테스트 세부 정보</block>
  <block id="84b7d04f598931bc149a92c543d3146f" category="paragraph"><block ref="84b7d04f598931bc149a92c543d3146f" category="inline-link-macro-rx"></block></block>
  <block id="34d110ef6b6b3684adfe9c791fce2f95" category="summary">이 섹션에서는 이 솔루션을 배포하는 데 필요한 세부 단계를 설명합니다.</block>
  <block id="e0673e67d0ae2470ff4a9a3a926792b0" category="doc">지원 센터 정서 분석 배포</block>
  <block id="0c7ee1e6d81ae421558f2979d46adb5d" category="inline-link-macro">이전: 설계 고려 사항.</block>
  <block id="2e4639bc721df1da69c19fe5c10f5764" category="paragraph"><block ref="2e4639bc721df1da69c19fe5c10f5764" category="inline-link-macro-rx"></block></block>
  <block id="b23f4e3eb5ff4f900ba54c824bf7a676" category="paragraph">솔루션 배포에는 다음 구성 요소가 포함됩니다.</block>
  <block id="1b497bff4e1d2dff7f8855237612936b" category="list-text">NGC 구성</block>
  <block id="2dcf1afb8ed1445e4b167ef91fdd8a1b" category="list-text">NVIDIA Riva 서버</block>
  <block id="6894a1e922948fc0bc9cc96291183448" category="list-text">NVIDIA TAO 툴킷</block>
  <block id="3b498dd8feee94c2dbcb419be10d3b70" category="list-text">TAO 모델을 Riva로 내보냅니다</block>
  <block id="534b37206d500ff97473ada660fb69d3" category="paragraph">배포를 수행하려면 다음 단계를 수행하십시오.</block>
  <block id="2f6c7bd50828792593b3aa4deff875cc" category="section-title">NetApp DataOps 툴킷: 지원 센터 정서 분석</block>
  <block id="3b84de14b99e2695fdfd099f56b254be" category="paragraph">를 사용합니다<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>에서 다음 단계를 완료합니다.</block>
  <block id="d19523f192f664c9e34bf949d6f084c3" category="list-text">PIP 도구 키트를 설치합니다.</block>
  <block id="1fe6ae43439f5ccecf9883686d6b3784" category="list-text">데이터 관리를 구성합니다</block>
  <block id="36b413e2c45a91e66db4aac6abd67ba1" category="section-title">NGC 구성: 지원 센터 정서 분석</block>
  <block id="e3ab64bcab09d9eb8219520405242267" category="inline-link">NGC</block>
  <block id="f526ba073cf7bc97c2b0d3bfe091e293" category="paragraph">를 눌러 설정합니다<block ref="5b4e29c9d8254a25bb1abc36cd17ca4c" category="inline-link-rx"></block>에서 다음 단계를 완료합니다.</block>
  <block id="a485a457c113aa9f2f8096ac1ca500d7" category="list-text">NGC를 다운로드합니다.</block>
  <block id="7438544460c4a4fdf0b70bb65bb03a92" category="list-text">현재 디렉터리를 경로에 추가합니다.</block>
  <block id="4f1208b2473595e5f4c3118c13de0fcc" category="list-text">명령을 실행할 수 있도록 NGC CLI를 구성해야 합니다. 메시지가 나타나면 API 키를 포함하여 다음 명령을 입력합니다.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">여기</block>
  <block id="5307692c5f99e57b8002a6a87f08c240" category="paragraph">Linux 기반이 아닌 운영 체제는 을 참조하십시오<block ref="481e32faa0c657434738f6f0a550651b" category="inline-link-rx"></block>.</block>
  <block id="326419ec6a380f68d7d15a373452bf35" category="section-title">NVIDIA Riva 서버: 지원 센터 정서 분석</block>
  <block id="92ed82a726e834b50a6863c8c4e9db4e" category="paragraph">를 눌러 설정합니다<block ref="fb85035785391c7c4b815d01de952f38" category="inline-link-rx"></block>에서 다음 단계를 완료합니다.</block>
  <block id="a4fc5fd3d1cea05f031d5adc045dc1e0" category="list-text">NGC에서 Riva 파일을 다운로드합니다.</block>
  <block id="5f2573d8cf9e274560d9a9b3eb2e1aaa" category="list-text">Riva 설정 초기화('Riva_init.sh')</block>
  <block id="3b570ac682cfeffcdb2c7243afdbf285" category="list-text">Riva 서버('Riva_start.sh')를 시작합니다.</block>
  <block id="d44d4e10378cce2928c99a4b49e45cea" category="list-text">Riva client('Riva_start_client.sh')를 시작합니다.</block>
  <block id="6846c1a17ddaf84e01f26ec51c151e78" category="inline-link">FFmpeg</block>
  <block id="22c9c751571566e0566c448194d9d64f" category="list-text">Riva 클라이언트 내에서 오디오 처리 라이브러리(<block ref="3e294dfc4ee3a49adac5a070482274ce" category="inline-link-rx"></block>)</block>
  <block id="8637711b2ee1b94fe789bb28e88c4b61" category="list-text">를 시작합니다<block ref="37a4c4b3ad3c3851ac5717bfd3104346" category="inline-link-rx"></block> 서버.</block>
  <block id="b57a5203a9fd3e877aacee6cba6bc9c8" category="list-text">Riva Inference Pipeline 노트북을 실행합니다.</block>
  <block id="5dceab25ae38dae0d7ed3167abd32377" category="section-title">NVIDIA TAO Toolkit: 지원 센터 정서 분석</block>
  <block id="2418d4c7f6be40d5c9a50e4aecab1b27" category="paragraph">NVIDIA TAO 툴킷을 설정하려면 다음 단계를 수행하십시오.</block>
  <block id="630eef78d15fd844ba4a38ea7f7a9c79" category="inline-link">가상 환경</block>
  <block id="35fb58d5f90347e4f0c445b4968db5f6" category="list-text">를 준비하고 활성화합니다<block ref="3d97a4392c0af686650645d1371fa8ef" category="inline-link-rx"></block> TAO 툴킷을 참조하십시오.</block>
  <block id="0a80b2068950d6e04f34c0142a10e719" category="inline-link">필수 패키지</block>
  <block id="40eb0bd8a87ab1b39e8f2ee5ea287a22" category="list-text">를 설치합니다<block ref="3646357cb54591ae95dd3b8f0889f0c2" category="inline-link-rx"></block>.</block>
  <block id="c0e95a7dacbc170e387c4e1a0fe41a0b" category="list-text">교육 및 미세 조정 중에 사용된 이미지를 수동으로 당깁니다.</block>
  <block id="b5a6ae7c1df936b55910309efc466f01" category="list-text">TAO 미세 조정 노트북을 실행합니다.</block>
  <block id="e6dda626093691f78b3127a8faa82b6e" category="section-title">TAO 모델을 Riva로 내보내기: 지원 센터 정서 분석</block>
  <block id="6a358d81cb24a7e408b0339062f6bb92" category="inline-link">Riva의 Tao 툴킷 모델</block>
  <block id="53ace4ba305859107cead3e5b0b53b8b" category="paragraph">사용합니다<block ref="ce50a5bf8eb35af9ad9bb322336ee3af" category="inline-link-rx"></block>에서 다음 단계를 완료합니다.</block>
  <block id="08c3be8307b7659c6ad67ee4d9659d58" category="list-text">TAO 미세 조정 노트북에 모델을 저장합니다.</block>
  <block id="ac711bb6af28947dfa8b29512acb36e8" category="list-text">TAO 교육을 받은 모델을 Riva 모델 디렉토리에 복사합니다.</block>
  <block id="1317e1d8d20d5c44c680825aba2196e6" category="section-title">구축 방해</block>
  <block id="6e3da39922ebbd1a8a1a5a7238a89168" category="paragraph">다음은 자체 솔루션을 개발할 때 고려해야 할 몇 가지 사항입니다.</block>
  <block id="47c0613abd5b97b67a94c2355692cf08" category="list-text">NetApp DataOps 툴킷은 데이터 스토리지 시스템이 최적으로 실행되도록 하기 위해 먼저 설치됩니다.</block>
  <block id="943f803f8c6b4c6508bc97536a6d7b2b" category="list-text">NVIDIA NGC는 이미지와 모델의 다운로드를 인증하기 때문에 다른 무엇보다도 먼저 설치해야 합니다.</block>
  <block id="70367b72bfd96b5608a7c72ac3f983bf" category="list-text">TAO 툴킷을 설치하기 전에 Riva를 설치해야 합니다. Riva 설치는 필요에 따라 Docker 데몬을 구성하여 이미지를 가져옵니다.</block>
  <block id="1ed7124aa68792cb6ce3049f6f1d4f7b" category="list-text">모델을 다운로드하려면 DGX 및 Docker에 인터넷 액세스 권한이 있어야 합니다.</block>
  <block id="de9b04ca3177b736c9f3cc74d62f5088" category="inline-link-macro">다음: 확인 결과.</block>
  <block id="3556370bb03d018998375ff0476db59a" category="paragraph"><block ref="3556370bb03d018998375ff0476db59a" category="inline-link-macro-rx"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">이 문서에서는 새로운 애플리케이션 시나리오를 충족하는 에지 환경에서 NetApp 스토리지 컨트롤러 및 Lenovo ThinkSystem 서버에 GPU 기반 인공 지능(AI) 추론을 배포하기 위한 컴퓨팅 및 스토리지 아키텍처에 대해 설명합니다.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: Edge-NetApp에서 Lenovo ThinkSystem - 솔루션 설계를 사용한 AI 추론</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">소개</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">기업들은 네트워크 에지에 대량의 데이터를 생성하고 있습니다. 스마트 센서 및 IoT 데이터를 활용하여 최대의 가치를 실현하기 위해 조직은 에지 컴퓨팅을 지원하는 실시간 이벤트 스트리밍 솔루션을 찾고 있습니다. 따라서 데이터 센터 외부의 에지에서는 컴퓨팅 작업이 점점 더 많이 수행됩니다. AI 추론을 이러한 트렌드에 동인으로 이끄는 요인 중 하나입니다. 에지 서버는 특히 가속기를 사용할 때 이러한 워크로드에 충분한 연산 능력을 제공하지만 제한된 스토리지는 종종 문제가 됩니다. 특히 다중 서버 환경에서는 더욱 그렇습니다. 이 문서에서는 에지 환경에서 공유 스토리지 시스템을 구축하는 방법과 성능 저하 없이 AI 추론 워크로드의 이점을 활용하는 방법을 설명합니다.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">이 문서에서는 에지의 AI 추론을 위한 참조 아키텍처에 대해 설명합니다. 여러 Lenovo ThinkSystem 에지 서버를 NetApp 스토리지 시스템과 결합하여 간편하게 구축 및 관리할 수 있는 솔루션을 구축합니다. 이 가이드는 여러 대의 카메라와 산업용 센서가 장착된 공장 바닥, 소매 거래의 POS(Point-of-Sale) 시스템 또는 자율 차량의 시각적 이상을 식별하는 FSD(Full Self-Driving) 시스템 등 다양한 상황에서 실제 배포를 위한 기본 안내서입니다.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">이 문서에서는 Lenovo ThinkSystem SE350 Edge Server와 엔트리 레벨 NetApp AFF 및 EF-Series 스토리지 시스템으로 구성된 컴퓨팅 및 스토리지 구성의 테스트 및 검증을 다룹니다. 참조 아키텍처는 AI 배포를 위한 효율적이고 비용 효율적인 솔루션을 제공하는 동시에 NetApp ONTAP 및 NetApp SANtricity 데이터 관리 소프트웨어를 통해 포괄적인 데이터 서비스, 통합 데이터 보호, 원활한 확장성 및 클라우드 연결 데이터 스토리지를 제공합니다.</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">이 문서는 다음 사용자를 대상으로 합니다.</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">에지의 AI를 제품화하려는 비즈니스 리더 및 엔터프라이즈 설계자</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">데이터 과학자, 데이터 엔지니어, AI/기계 학습(ML) 연구원 및 AI 시스템 개발자.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">AI/ML 모델 및 애플리케이션 개발을 위한 솔루션을 설계하는 엔터프라이즈 설계자</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">딥 러닝(DL) 및 ML 모델을 구축하는 효율적인 방법을 찾고 있는 데이터 과학자 및 AI 엔지니어</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">에지 장치 관리자 및 에지 서버 관리자는 에지 추론 모델의 구축과 관리를 담당합니다.</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">솔루션 아키텍처</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">이 Lenovo ThinkSystem 서버 및 NetApp ONTAP 또는 NetApp SANtricity 스토리지 솔루션은 기존 CPU와 함께 GPU의 처리 능력을 사용하여 대규모 데이터 세트에서 AI 추론을 처리하도록 설계되었습니다. 이 검증 방식은 다음 두 그림에 표시된 대로 단일 NetApp AFF 스토리지 시스템과 상호 연결된 단일 또는 다중 Lenovo SR350 에지 서버를 사용하는 아키텍처로 고성능 및 최적의 데이터 관리를 수행하는 것입니다.</block>
  <block id="5174c42549c4dd0407a40298a4d9e362" category="paragraph"><block ref="5174c42549c4dd0407a40298a4d9e362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aacb24ff7918ccc37aea66f8c9548b68" category="paragraph"><block ref="aacb24ff7918ccc37aea66f8c9548b68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">다음 그림의 논리적 아키텍처 개요에서는 이 아키텍처의 컴퓨팅 및 스토리지 요소 역할을 보여 줍니다. 특히 다음과 같은 사항이 표시됩니다.</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">에지 컴퓨팅 장치가 카메라, 센서 등의 데이터를 기반으로 추론을 수행합니다.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">다양한 용도로 사용되는 공유 스토리지 요소:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">추론 모델과 추론을 수행하는 데 필요한 다른 데이터를 위한 중심 위치를 제공합니다. 컴퓨팅 서버는 스토리지를 직접 액세스하고 로컬에서 복사할 필요 없이 네트워크 전체에서 추론 모델을 사용합니다.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">업데이트된 모델이 여기에 푸시됩니다.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">에지 서버가 나중에 분석할 수 있도록 수신하는 입력 데이터를 보관합니다. 예를 들어, 에지 장치가 카메라에 연결된 경우 저장소 요소는 카메라에서 캡처한 비디오를 유지합니다.</block>
  <block id="45d9a14c8d568ce70d22acbde8373657" category="paragraph"><block ref="45d9a14c8d568ce70d22acbde8373657" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">빨간색</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">파란색</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Lenovo 컴퓨팅 시스템</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFF 스토리지 시스템</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">카메라, 센서 등의 입력에서 추론을 수행하는 에지 장치</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">추측 모델과 에지 디바이스의 데이터를 저장하는 공유 스토리지로, 추후 분석 지원</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">이 NetApp 및 Lenovo 솔루션은 다음과 같은 주요 이점을 제공합니다.</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">소규모 지사 또는 부서에서의 GPU 가속 컴퓨팅.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">공유 스토리지에서 백업 및 관리되는 다중 에지 서버 배포</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">데이터 손실 없이 낮은 RPO(복구 시점 목표) 및 RTO(복구 시간 목표)를 충족하는 강력한 데이터 보호</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">NetApp Snapshot 복사본 및 클론을 통해 데이터 관리를 최적화하여 개발 워크플로우를 간소화합니다.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">이 아키텍처를 사용하는 방법</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">이 문서에서는 제안된 아키텍처의 설계 및 성능을 검증합니다. 하지만 NetApp은 특정 소프트웨어 수준의 컨테이너, 워크로드, 모델 관리, 클라우드 또는 온프레미스의 데이터 센터 등과 같은 특정 소프트웨어 레벨 구성 요소를 테스트하지 않았습니다. 이러한 소프트웨어 레벨 구성 요소가 배포 시나리오에 한정되어 있기 때문입니다. 여기에는 여러 개의 선택 사항이 있습니다.</block>
  <block id="080e5221e660ab18a3746fe480956ebc" category="paragraph">컨테이너 관리 수준에서 Kubernetes 컨테이너 관리는 좋은 선택이며 전체 업스트림 버전(Canonical) 또는 엔터프라이즈 배포에 적합한 수정 버전(Red Hat)에서 지원됩니다. 를 클릭합니다 <block ref="8ff9014ec7345470e1bb9286d28496e4" category="inline-link-macro-rx"></block> NetApp Trident 및 새로 추가된 Trident를 사용합니다<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> 데이터 과학자 및 데이터 엔지니어가 NetApp 스토리지와 통합할 수 있도록 추적 가능성, 데이터 관리 기능, 인터페이스 및 툴을 기본으로 제공합니다. Kubernetes용 ML 툴킷인 Kubeflow는 추가 AI 기능을 제공하는 동시에 TensorFlow Serving 또는 NVIDIA Triton Inference Server와 같은 여러 플랫폼에서 모델 버전 관리 및 KFServing을 지원합니다. 또 다른 옵션은 NVIDIA EGX 플랫폼으로, GPU 지원 AI 추론 컨테이너 카탈로그에 액세스하여 워크로드 관리를 제공합니다. 그러나 이러한 옵션을 사용하려면 운영 환경에 투입하기 위해 상당한 노력과 전문 지식이 필요할 수 있으며 타사 ISV(독립 소프트웨어 공급업체) 또는 컨설턴트의 도움이 필요할 수 있습니다.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">솔루션 영역</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">AI 추론 및 에지 컴퓨팅의 주요 이점은 지연 시간 없이 높은 수준의 품질로 데이터를 컴퓨팅, 처리 및 분석할 수 있는 장치의 기능입니다. 이 문서에서 설명하는 에지 컴퓨팅 사용 사례는 매우 많지만 다음과 같은 몇 가지 대표적인 사례가 있습니다.</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">자동차: 자율주행 차량</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">전형적인 에지 컴퓨팅 일러스트는 자율주행 차량(AV)의 첨단 운전자 지원 시스템(ADAS)에 포함되어 있습니다. 무인 자동차의 AI는 안전하고 성공적인 운전자가 되려면 카메라와 센서의 많은 데이터를 신속하게 처리해야 합니다. 물체와 사람 사이의 해석에 너무 많은 시간이 걸릴경우 생명 또는 사망이 발생할 수 있으므로 데이터를 최대한 차량과 가깝게 처리할 수 있어야 합니다. 이 경우 하나 이상의 에지 컴퓨팅 서버가 카메라, 레이더, LiDAR 및 기타 센서의 입력을 처리하는 동시에 공유 스토리지에는 추론 모델이 저장되고 센서의 입력 데이터가 저장됩니다.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">의료: 환자 모니터링</block>
  <block id="a5031cd8ea18cb91370c532194ecd58e" category="paragraph">AI 및 에지 컴퓨팅이 미치는 가장 큰 영향 중 하나는 가정 및 중환자실(ICU) 모두에서 만성 질환 환자를 지속적으로 모니터링할 수 있는 기능입니다. 인슐린 수치, 호흡, 신경학적 활동, 심장 리듬 및 위장관 기능을 모니터링하는 에지 장치에서 얻은 데이터는 다른 사람의 생명을 구하기 위한 제한된 시간이 있기 때문에 즉시 실행되어야 하는 데이터에 대한 즉각적인 분석이 필요합니다.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">소매: 계산원 없는 지불</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">에지 컴퓨팅은 유통업체가 계산 시간을 단축하고 발트 트래픽을 늘릴 수 있도록 AI 및 ML을 지원합니다. 계산원이 필요 없는 시스템은 다음과 같은 다양한 구성 요소를 지원합니다.</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">인증 및 액세스. 물리적 쇼핑객을 검증된 계정에 연결하고 소매 공간에 대한 액세스를 허용합니다.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">인벤토리 모니터링. 센서, RFID 태그 및 컴퓨터 비전 시스템을 사용하여 쇼핑객의 아이템 선택 또는 선택 취소를 확인할 수 있습니다.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">여기서 각 에지 서버는 각 계산 카운터를 처리하며 공유 스토리지 시스템은 중앙 동기화 지점으로 사용됩니다.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">금융 서비스: 키오스크의 인적 안전 및 사기 방지</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">은행 조직에서는 AI 및 에지 컴퓨팅을 사용하여 혁신을 진행하고 맞춤형 뱅킹 경험을 만들고 있습니다. 실시간 데이터 분석 및 AI 추론을 사용하는 대화형 키오스크는 이제 ATM을 통해 고객이 돈을 인출할 수 있도록 지원할 뿐만 아니라 카메라에서 캡처한 이미지를 통해 키오스크를 사전 예방적으로 모니터링하여 사람의 안전 또는 사기 행위 위험을 식별할 수 있습니다. 이 시나리오에서는 에지 컴퓨팅 서버 및 공유 스토리지 시스템이 대화형 키오스크 및 카메라에 연결되어 은행이 AI 추론 모델로 데이터를 수집하고 처리할 수 있도록 도와줍니다.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">제조: Industry 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">4차 산업혁명(Industry 4.0)은 Smart Factory 및 3D 프린팅과 같은 새로운 트렌드와 함께 시작되었습니다. 데이터 중심의 미래에 대비하기 위해 대규모 M2M(Machine-to-Machine) 통신 및 IoT가 통합되어 사람의 개입 없이 자동화 수준을 높일 수 있습니다. 제조는 이미 고도로 자동화되어 있으며 AI 기능을 추가하는 것은 장기적인 추세를 자연스럽게 이어주는 것입니다. AI를 사용하면 컴퓨터 비전 및 기타 AI 기능을 활용하여 자동화할 수 있는 운영을 자동화할 수 있습니다. 제조 공장이 안전 및 품질 관리에 필요한 ISO 표준을 충족할 수 있도록 제조 공장의 조립 라인에서 자재를 더 빠르게 분석하는 데 있어 인간의 시각이나 의사 결정에 의존하는 품질 관리 또는 작업을 자동화할 수 있습니다. 여기서 각 컴퓨팅 에지 서버는 제조 프로세스를 모니터링하는 센서 배열에 연결되고 필요에 따라 업데이트된 추론 모델이 공유 스토리지로 푸시됩니다.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">통신: Rust 감지, 타워 검사 및 네트워크 최적화</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">통신 업계에서는 컴퓨터 비전과 AI 기술을 사용하여 녹을 자동으로 탐지하고 부식된 셀 타워를 식별하는 이미지를 처리하여 추가적인 검사가 필요합니다. 드론 이미지와 AI 모델을 사용하여 타워의 특정 영역을 식별하고 녹, 표면 균열 및 부식을 분석하는 일이 최근 몇 년 사이에 증가했습니다. 통신 인프라와 셀 타워를 효율적으로 검사하고, 정기적으로 성능 저하를 평가하며, 필요할 때 신속하게 수리할 수 있는 AI 기술에 대한 수요가 지속적으로 증가하고 있습니다.</block>
  <block id="50dba7db75064ae2e0beea487226ed46" category="paragraph">또한, 데이터 트래픽 패턴을 예측하고 5G 지원 장치를 감지하고 MIMO(다중 입력 및 다중 출력) 에너지 관리를 자동화 및 보강하기 위해 AI 및 ML 알고리즘을 사용하는 것도 통신 업계의 새로운 사용 사례입니다. MIMO 하드웨어는 무선 타워에서 네트워크 용량을 늘리기 위해 사용되지만, 추가 에너지 비용이 필요합니다. 셀 사이트에 배치된 “MIMO 절전 모드”용 ML 모델은 무전기의 효율적인 사용을 예측하고 모바일 네트워크 사업자(MNO)의 에너지 소비 비용을 줄이는 데 도움이 됩니다. AI 추론 및 에지 컴퓨팅 솔루션은 MNO가 데이터 센터로 주고받는 데이터 양을 줄이고, TCO를 낮추고, 네트워크 운영을 최적화하고, 최종 사용자의 전반적인 성능을 개선하는 데 도움이 됩니다.</block>
  <block id="f45c430b02aac052aef8d958c80ff351" category="paragraph"><block ref="f45c430b02aac052aef8d958c80ff351" category="inline-link-macro-rx"></block></block>
  <block id="10dedd24e41d2fa9b5a5e681dd5b4882" category="summary">이 페이지에는 컨테이너, Kubernetes, NetApp Trident 등에 대한 정보를 비롯하여 NetApp이 AI 프로젝트를 진행하는 방법을 이해할 수 있는 배경이 포함되어 있습니다.</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">인공 지능</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">AI는 컴퓨터가 인간의 마음의 인지 기능을 모방하도록 훈련되는 컴퓨터 과학 분야입니다. AI 개발자는 컴퓨터를 교육하여 사람과 유사하거나 훨씬 뛰어난 방식으로 문제를 배우고 해결합니다. 딥 러닝 및 머신 러닝은 AI의 하위 필드입니다. 조직은 중요한 비즈니스 요구사항을 지원하기 위해 AI, ML 및 DL을 점점 더 채택하고 있습니다. 몇 가지 예는 다음과 같습니다.</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">방대한 양의 데이터를 분석하여 이전에 알려지지 않은 비즈니스 인사이트를 도출합니다</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">자연어 처리를 사용하여 고객과 직접 상호 작용</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">다양한 비즈니스 프로세스 및 기능 자동화</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">최신 AI 훈련 및 추론 워크로드에는 대규모 병렬 컴퓨팅 기능이 필요합니다. 따라서 GPU의 병렬 처리 기능이 범용 CPU보다 훨씬 뛰어나기 때문에 AI 작업을 실행하는 데 GPU가 점점 더 많이 사용되고 있습니다.</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">컨테이너는 공유 호스트 운영 체제 커널 위에서 실행되는 격리된 사용자 공간 인스턴스입니다. 컨테이너 채택이 빠르게 증가하고 있습니다. 컨테이너는 가상 머신(VM)이 제공하는 것과 동일한 애플리케이션 샌드박스(sandbox)의 많은 이점을 제공합니다. 하지만 VM이 사용하는 하이퍼바이저 및 게스트 운영 체제 계층이 없어졌기 때문에 컨테이너는 훨씬 더 가볍습니다. 다음 그림에서는 가상 시스템과 컨테이너를 보여 줍니다.</block>
  <block id="da28cd415837c7f3d1d6221ff490b84b" category="paragraph">또한 컨테이너를 사용하면 애플리케이션 종속성, 실행 시간 등을 애플리케이션과 직접 효율적으로 패키징할 수 있습니다. 가장 일반적으로 사용되는 컨테이너 패키징 형식은 Docker 컨테이너입니다. Docker 컨테이너 형식으로 컨테이너화된 애플리케이션은 Docker 컨테이너를 실행할 수 있는 모든 시스템에서 실행할 수 있습니다. 모든 종속성이 컨테이너 자체에 패키지되어 있기 때문에 응용 프로그램의 종속성이 컴퓨터에 없는 경우에도 마찬가지입니다. 자세한 내용은 를 참조하십시오<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>.</block>
  <block id="9c3d617029ed075512781527983e01e4" category="paragraph"><block ref="9c3d617029ed075512781527983e01e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a1446916a360f9c8ae3b94a97ad8c86" category="paragraph">Kubernetes는 Google에서 원래 설계한 개방형 소스, 분산형 컨테이너 오케스트레이션 플랫폼으로, 현재 CNCF(Cloud Native Computing Foundation)에서 관리하고 있습니다. Kubernetes는 컨테이너화된 애플리케이션의 구축, 관리, 확장 기능을 자동화할 수 있습니다. 최근 몇 년 동안 Kubernetes는 주요 컨테이너 오케스트레이션 플랫폼으로 부상했습니다. 다른 컨테이너 패키징 형식과 실행 시간이 지원되지만 Kubernetes는 Docker 컨테이너용 오케스트레이션 시스템으로 가장 많이 사용됩니다. 자세한 내용은 를 참조하십시오<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>.</block>
  <block id="f9b736ec48694a34e744a1a0309602bd" category="paragraph">Trident는 NetApp에서 개발 및 유지 관리하는 오픈 소스 스토리지 오케스트레이터로서 Kubernetes 워크로드를 위한 영구 스토리지의 생성, 관리 및 사용을 크게 단순화합니다. Kubernetes 네이티브 애플리케이션인 Trident는 Kubernetes 클러스터 내에서 직접 실행됩니다. Trident를 사용하면 Kubernetes 사용자(개발자, 데이터 과학자, Kubernetes 관리자 등)가 이미 익숙한 표준 Kubernetes 형식으로 영구 스토리지 볼륨을 생성, 관리 및 상호 작용할 수 있습니다. 이와 동시에 NetApp 기술에서 제공하는 NetApp 고급 데이터 관리 기능과 Data Fabric을 활용할 수 있습니다. Trident는 영구 스토리지의 복잡성을 추상화하여 사용이 간편합니다. 자세한 내용은 를 참조하십시오<block ref="ad5406ed69f3fe0de810f757310402c9" category="inline-link-rx"></block>.</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflow 웹 사이트</block>
  <block id="ea77b50ef31a778a66411b993d6cb7d1" category="paragraph">Kubeflow는 Google에서 원래 개발한 Kubernetes용 오픈 소스 AI 및 ML 툴킷입니다. Kubeflow 프로젝트를 통해 Kubernetes에서 AI 및 ML 워크플로우를 간단하게 배포, 이식 및 확장할 수 있습니다. Kubeflow는 복잡한 Kubernetes를 추상화하여 데이터 과학자가 자신이 가장 잘 알고 있는 데이터 과학에 집중할 수 있도록 지원합니다. 시각화는 다음 그림을 참조하십시오. 쿠버플로는 엔터프라이즈 IT 부서가 Kubernetes에서 점점 더 표준화되고 있으므로 상당한 주목을 받고 있습니다. 자세한 내용은 를 참조하십시오<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>.</block>
  <block id="a2b0a43dcae6386929654b652393e691" category="paragraph"><block ref="a2b0a43dcae6386929654b652393e691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow 파이프라인</block>
  <block id="384873a621d99250018cd7ce1768f8af" category="paragraph">Kubeflow 파이프라인은 Kubeflow의 핵심 구성 요소입니다. Kubeflow 파이프라인은 이식 가능하고 확장 가능한 AI 및 ML 워크플로우를 정의하고 배포하기 위한 플랫폼 및 표준입니다. 자세한 내용은 를 참조하십시오<block ref="6de5a235a0c43df48d05588e1b69b959" category="inline-link-rx"></block>.</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Jupyter 웹 사이트</block>
  <block id="3cecf3b7bbdb1a67a537c65bfd6fd529" category="paragraph">Jupyter Notebook Server는 데이터 과학자가 실시간 코드와 설명이 포함된 Jupyter Notebooks라는 위키 형식의 문서를 만들 수 있는 오픈 소스 웹 애플리케이션입니다. Jupyter Notebooks는 AI 및 ML 프로젝트를 문서화, 저장, 공유하는 수단으로 AI 및 ML 커뮤니티에서 널리 사용되고 있습니다. Kubeflow는 Kubernetes에서 Jupyter Notebook Server의 프로비저닝 및 구축을 단순화합니다. Jupyter Notebooks에 대한 자세한 내용은 를 참조하십시오<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>. Kubeflow와 관련하여 Jupyter Notebooks에 대한 자세한 내용은 를 참조하십시오<block ref="c5d2218884acd101e6deb4d8c7d39370" category="inline-link-rx"></block>.</block>
  <block id="c01fb6f699235f8c5d36bdda9e155c77" category="paragraph">Apache Airflow는 복잡한 엔터프라이즈 워크플로우를 프로그래밍 방식으로 작성, 스케줄링 및 모니터링할 수 있는 오픈 소스 워크플로우 관리 플랫폼입니다. ETL 및 데이터 파이프라인 워크플로우를 자동화하는 데 주로 사용되지만, 이러한 유형의 워크플로우에만 국한되지 않습니다. Airbnb가 공기 흐름 프로젝트를 시작했지만 그 이후 업계에서 매우 인기를 끌며 현재는 Apache Software Foundation의 후원으로 자리 잡았습니다. Python으로 공기 흐름을 작성하고 Python 스크립트를 통해 공기 흐름을 생성하고 "코드로 구성"이라는 원칙에 따라 공기 흐름을 설계할 수 있습니다. 많은 엔터프라이즈 공기 흐름 사용자가 이제 Kubernetes에서 공기 흐름을 실행합니다.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">유도된 DAG(Acclic Graphs)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">공기 흐름에서 워크플로우는 DAG(Directed Acyclic Graphs)라고 합니다. DAG는 DAG 정의에 따라 순차적으로, 병렬로 또는 둘의 조합으로 실행되는 작업으로 구성됩니다. 공기 흐름 스케줄러는 DAG 정의에 지정된 작업 수준 종속성을 준수하여 일련의 작업자에 대해 개별 작업을 실행합니다. DAG는 Python 스크립트를 통해 정의 및 생성됩니다.</block>
  <block id="0b83cba78e13ee67f3ada794b1e8edb8" category="paragraph">NetApp ONTAP 9은 NetApp의 최신 세대 스토리지 관리 소프트웨어로, 이 소프트웨어를 사용하여 귀사와 같은 기업에서 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다. 업계 최고의 데이터 관리 기능을 갖춘 ONTAP은 데이터의 위치와 상관없이 단일 툴셋으로 데이터를 관리하고 보호할 수 있도록 지원합니다. 필요에 따라 에지, 코어, 클라우드 등 어느 위치로도 데이터를 자유롭게 이동할 수 있습니다. ONTAP 9에는 데이터 관리를 단순화하고, 중요 데이터를 더 빨리 처리하고 보호하는 다수의 기능이 포함되어 있으므로 하이브리드 클라우드 아키텍처 전체에 미래 지향형 인프라를 제공합니다.</block>
  <block id="849f9e6e3176f7bb2abaf1dfdda6f4de" category="section-title">데이터 관리 단순화</block>
  <block id="5d0a72b50313f5f3615263a7d19ee676" category="paragraph">애플리케이션 및 데이터 세트에 적절한 리소스를 사용할 수 있도록 데이터 관리는 엔터프라이즈 IT 운영에 매우 중요합니다. ONTAP에는 운영을 간소화 및 단순화하고 총 운영 비용을 절감할 수 있는 다음과 같은 기능이 포함되어 있습니다.</block>
  <block id="30490e1b1bd18c329c3b28df91914ffe" category="list-text">* 인라인 데이터 컴팩션 및 확대된 중복제거. * 데이터 컴팩션은 스토리지 블록 내부의 낭비되는 공간을 줄이고, 중복제거는 실제 용량을 크게 증가시킵니다.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">* 최소, 최대 및 적응형 서비스 품질(QoS). * 세분화된 QoS 제어로 고도의 공유 환경에서 중요 애플리케이션의 성능 수준을 유지할 수 있습니다.</block>
  <block id="d9a5709ce7afa0856dd86539f75c8087" category="list-text">* ONTAP FabricPool. * 이 기능은 콜드 데이터를 AWS(Amazon Web Services), Azure, NetApp StorageGRID 오브젝트 기반 스토리지와 같은 퍼블릭 및 프라이빗 클라우드 스토리지 옵션으로 자동 계층화합니다.</block>
  <block id="ddb2f8d78c57d5743fdee9e17ae053c9" category="section-title">데이터 가속화 및 보호</block>
  <block id="4994fe58be1734616de0863809040200" category="paragraph">ONTAP는 탁월한 수준의 성능과 데이터 보호를 제공하며 다음과 같은 기능으로 이러한 기능을 확장합니다.</block>
  <block id="b109ecc7b4570bf3dbb9f8d082595075" category="list-text">* 고성능 및 낮은 지연 시간 * ONTAP는 가장 짧은 지연 시간으로 가장 높은 처리량을 제공합니다.</block>
  <block id="9e184f7b8847a390232c0163d45ab461" category="list-text">* NetApp ONTAP FlexGroup 기술. * FlexGroup 볼륨은 최대 20PB 및 4천억 개 파일까지 선형적으로 확장할 수 있는 고성능 데이터 컨테이너로, 단일 네임스페이스를 제공하여 데이터 관리를 단순화합니다.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* NetApp 볼륨 암호화. * ONTAP는 온보드 및 외부 키 관리를 모두 지원하는 기본 볼륨 레벨 암호화를 제공합니다.</block>
  <block id="0950833529b7822458a242631cce3b3b" category="section-title">미래 지향형 인프라</block>
  <block id="ba5b61620e18b71a8644dbc382c0c4f1" category="paragraph">ONTAP 9은 지속적으로 변화하는 까다로운 요구사항을 충족할 수 있도록 지원합니다.</block>
  <block id="d9d73747d25ab5e9c5de8f1f61c9ec7c" category="list-text">* 원활한 확장 및 무중단 운영 * ONTAP은 기존 컨트롤러 및 스케일아웃 클러스터에 무중단으로 용량을 추가할 수 있도록 지원합니다. 고비용이 따르는 데이터 마이그레이션이나 운영 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="512a65c054e8b5d06216e0eae55abedb" category="list-text">* 클라우드 연결. * ONTAP은 클라우드에 가장 많이 연결된 스토리지 관리 소프트웨어 중 하나로, 모든 퍼블릭 클라우드에서 소프트웨어 정의 스토리지(ONTAP Select) 및 클라우드 네이티브 인스턴스(NetApp Cloud Volumes Service) 옵션을 제공합니다.</block>
  <block id="5ca60f373401802dfa44501cfa4f5cc7" category="list-text">새로운 애플리케이션과의 통합 * 기존 엔터프라이즈 애플리케이션을 지원하는 인프라와 동일한 인프라를 사용하는 ONTAP는 OpenStack, Hadoop, MongoDB와 같은 차세대 플랫폼 및 애플리케이션을 위한 엔터프라이즈급 데이터 서비스를 제공합니다.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetApp Snapshot 복사본</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">NetApp 스냅샷 복사본은 볼륨의 읽기 전용 시점 이미지입니다. 다음 그림과 같이 이미지는 스토리지 공간을 최소한으로 사용하고, 마지막 스냅샷 복사본 생성 이후 생성된 파일의 변경사항만 기록하므로 경미한 성능 오버헤드를 발생시킵니다.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">스냅샷 복사본은 핵심 ONTAP 스토리지 가상화 기술인 WAFL(Write Anywhere File Layout)의 효율성을 높여줍니다. 데이터베이스와 마찬가지로 WAFL는 메타데이터를 사용하여 디스크의 실제 데이터 블록을 가리킵니다. 하지만 WAFL은 데이터베이스와 달리 기존 블록을 덮어쓰지 않습니다. 업데이트된 데이터를 새 블록에 쓰고 메타데이터를 변경합니다. ONTAP은 데이터 블록을 복사하는 대신 스냅샷 복사본을 생성할 때 메타데이터를 참조하므로 스냅샷 복사본이 매우 효율적입니다. 이렇게 하면 복사할 블록을 찾는 데 다른 시스템이 발생하는 탐색 시간과 복사본 자체를 만드는 비용이 제거됩니다.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">스냅샷 복사본을 사용하여 개별 파일 또는 LUN을 복구하거나 볼륨의 전체 콘텐츠를 복원할 수 있습니다. ONTAP은 스냅샷 복사본의 포인터 정보를 디스크의 데이터와 비교하여 다운타임 또는 상당한 성능 비용 없이 누락 또는 손상된 개체를 재구성합니다.</block>
  <block id="9787a3a5983c64cfaf3029a721aab4f0" category="paragraph"><block ref="9787a3a5983c64cfaf3029a721aab4f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexClone 기술</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">NetApp FlexClone 기술은 Snapshot 메타데이터를 참조하여 볼륨의 쓰기 가능한 특정 시점 복사본을 생성합니다. 복사본은 다음 그림과 같이 복사본에 변경 사항이 기록될 때까지 메타데이터에 필요한 사항을 제외하고 데이터 블록을 부모와 공유하고 스토리지를 사용하지 않습니다. FlexClone 소프트웨어를 사용하면 기존 복사본을 생성하는 데 몇 분 또는 몇 시간이 걸릴 수 있으며 최대 규모의 데이터 세트도 거의 즉시 복사할 수 있습니다. 따라서 동일한 데이터 세트의 여러 복사본(예: 개발 작업 공간)이 필요하거나 데이터 세트의 임시 복사본(운영 데이터 세트에 대해 애플리케이션 테스트)이 필요한 경우에 적합합니다.</block>
  <block id="423c2edb645c178257ba9d79bd9ac684" category="paragraph"><block ref="423c2edb645c178257ba9d79bd9ac684" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirror 데이터 복제 기술</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">NetApp SnapMirror 소프트웨어는 Data Fabric에서 사용하기 쉬운 비용 효율적인 통합 복제 솔루션입니다. LAN 또는 WAN을 통해 데이터를 고속으로 복제합니다. 가상 환경과 기존 환경 모두에서 비즈니스 크리티컬 애플리케이션을 포함한 모든 유형의 애플리케이션에 대해 높은 데이터 가용성과 빠른 데이터 복제를 제공합니다. 하나 이상의 NetApp 스토리지 시스템에 데이터를 복제하고 2차 데이터를 지속적으로 업데이트함으로써 데이터가 최신 상태로 유지되고 필요할 때마다 사용할 수 있으며 외부 복제 서버가 필요하지 않습니다. 다음 그림은 SnapMirror 기술을 활용하는 아키텍처의 예입니다.</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">SnapMirror 소프트웨어는 변경된 블록만 네트워크를 통해 전송함으로서 NetApp ONTAP 스토리지 효율성을 활용합니다. SnapMirror 소프트웨어는 또한 내장된 네트워크 압축 기능을 사용하여 데이터 전송을 더 신속하게 수행하고 네트워크 대역폭 활용률을 70%까지 줄입니다. SnapMirror 기술을 사용하면 하나의 씬 복제 데이터 스트림을 활용하여 활성 미러와 이전 시점의 복사본을 둘 다 유지 관리하는 단일 저장소를 만들 수 있으므로 네트워크 트래픽이 최대 50% 감소합니다.</block>
  <block id="423eee692f81241addaf586841d0c66a" category="paragraph"><block ref="423eee692f81241addaf586841d0c66a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e386ef1ace3f8ea71edbaa6f9cbbd00" category="paragraph">Cloud Sync는 빠르고 안전한 데이터 동기화를 제공하는 NetApp 서비스입니다. 사내 NFS 또는 SMB 파일 공유 간에 파일을 전송해야 하는 경우, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google 클라우드 스토리지 또는 IBM 클라우드 오브젝트 스토리지인 Cloud Sync는 필요한 파일을 빠르고 안전하게 이동시킵니다.</block>
  <block id="c1bea6c8c836c6911127e6fe3fde762a" category="paragraph">데이터가 전송되면 소스와 타겟 모두에서 사용할 수 있습니다. Cloud Sync는 사전 정의된 일정에 따라 업데이트가 트리거되거나 지속적으로 데이터가 동기화될 때 필요 시 데이터를 동기화할 수 있습니다. Cloud Sync는 델타만 이동하므로 데이터 복제에 소비되는 시간과 비용이 최소화됩니다.</block>
  <block id="18c24ab391d7e12f4abcfea370fb4e81" category="paragraph">Cloud Sync는 매우 간편한 설정 및 사용이 가능한 SaaS(Software as a Service) 툴입니다. Cloud Sync에 의해 트리거되는 데이터 전송은 데이터 브로커가 수행합니다. Cloud Sync 데이터 브로커는 AWS, Azure, Google Cloud Platform 또는 온프레미스에 구축할 수 있습니다.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="0e4fcaf78d0d4feda27a31ecb6944b58" category="paragraph">NetApp XCP는 모든 NetApp 및 NetApp 간 데이터 마이그레이션 및 파일 시스템 통찰력을 위한 클라이언트 기반 소프트웨어입니다. xCP는 사용 가능한 모든 시스템 리소스를 활용하여 대용량 데이터 세트 및 고성능 마이그레이션을 처리함으로써 최대한의 성능을 발휘하도록 설계되었습니다. xCP를 사용하면 보고서를 생성하는 옵션을 통해 파일 시스템에 대한 완벽한 가시성을 확보할 수 있습니다.</block>
  <block id="9a3914e340e4b09762f8231f9fd0ddaa" category="paragraph">NetApp XCP는 NFS 및 SMB 프로토콜을 지원하는 단일 패키지로 제공됩니다. xCP에는 NFS 데이터 세트용 Linux 바이너리와 SMB 데이터 세트용 Windows 실행 파일이 포함되어 있습니다.</block>
  <block id="adc911d4d2f4e0008e765523cff39824" category="paragraph">NetApp XCP File Analytics는 파일 공유를 감지하고 파일 시스템에서 스캔을 실행하며 파일 분석을 위한 대시보드를 제공하는 호스트 기반 소프트웨어입니다. XCP File Analytics는 NetApp 및 타사 시스템과 모두 호환되며 Linux 또는 Windows 호스트에서 실행되어 NFS 및 SMB에서 내보낸 파일 시스템에 대한 분석 기능을 제공합니다.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup 볼륨</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">교육 데이터 세트는 잠재적으로 수십억 개의 파일로 구성됩니다. 파일에는 텍스트, 오디오, 비디오 및 기타 형식의 비정형 데이터가 포함될 수 있으며, 이 데이터를 병렬로 읽고 저장해야 합니다. 스토리지 시스템은 수많은 작은 파일을 저장해야 하며 순차적 I/O 및 랜덤 I/O를 위해 병렬로 이들 파일을 읽어야 합니다</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">FlexGroup 볼륨은 다음 그림과 같이 여러 개의 구성 멤버 볼륨으로 구성된 단일 네임스페이스입니다. 스토리지 관리자 관점에서 FlexGroup 볼륨은 NetApp FlexVol 볼륨과 마찬가지로 관리되고 작동합니다. FlexGroup 볼륨의 파일은 개별 구성원 볼륨에 할당되며 볼륨 또는 노드에 스트라이핑되지 않습니다. 다음과 같은 기능을 지원합니다.</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroup 볼륨은 메타데이터가 많은 워크로드에 수 페타바이트에 달하는 용량과 예측 가능한 짧은 지연 시간을 제공합니다.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">동일한 네임스페이스에서 최대 4천억 개의 파일을 지원합니다.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">CPU, 노드, 애그리게이트, 구성 FlexVol 볼륨에서 NAS 워크로드에 병렬 작업을 지원합니다.</block>
  <block id="07e40bce6e02494c0af7b6a5f2aeaad8" category="paragraph"><block ref="07e40bce6e02494c0af7b6a5f2aeaad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96e1c56a273105095d8b5e23e670f72f" category="inline-link-macro">다음: 하드웨어 및 소프트웨어 요구 사항.</block>
  <block id="1c3ce2e5bdbf1449bbeba4ecbd124676" category="paragraph"><block ref="1c3ce2e5bdbf1449bbeba4ecbd124676" category="inline-link-macro-rx"></block></block>
  <block id="2625fb6375d503af481868caf90606c9" category="summary">이 섹션에서는 이 기술 보고서와 관련된 Jupyter 노트북 2개에 대한 링크를 제공합니다.</block>
  <block id="91409fc3ebd20becb4eb816cbcceb02e" category="doc">Jupyter 노트북을 참조하십시오</block>
  <block id="cdd5560e07964d04d88721f16446a3b6" category="paragraph">이 기술 보고서와 관련하여 2개의 Jupyter 노트북이 있습니다.</block>
  <block id="1490d9a5ddbc6bcbe6cedaa01eb50f99" category="inline-link-macro">* CTR-PandasRF-Collated.ipynb. *</block>
  <block id="562c7333f0fea5590cfeb818a55e6557" category="list-text"><block ref="6f686a9606ae64621340ea0a5e72dfde" category="inline-link-macro-rx"></block> 이 노트북은 Criteo Terabyte Click Logs 데이터 세트에서 15일을 로드하고 Pandas DataFrame으로 데이터를 처리 및 포맷하고 Scikit-Learn 무작위 포리스트 모델을 교육하며 예측을 수행하고 정확도를 계산합니다.</block>
  <block id="c0cb1f1199ae4e4bdfa626e26a5a25cd" category="inline-link-macro">criteo_dask_rf.ipynb. * 를 사용합니다</block>
  <block id="fa93cb17bf7778768ccae778487bf90d" category="list-text"><block ref="01d86d8522c2722466fcbda71181d3ff" category="inline-link-macro-rx"></block> 이 전자 필기장은 Criteo Terabyte Click Logs 데이터 집합에서 15일을 로드하고, 데이터를 처리하여 Dask cuDF로 서식을 지정하고, Dask cuML 임의 포리스트 모델을 교육하고, 예측을 수행하고, 정확도를 계산합니다. GPU에 여러 작업자 노드를 활용함으로써 이러한 분산 데이터 및 모델 처리 및 교육 접근 방식이 매우 효율적입니다. 처리하는 데이터가 많을수록 기존 ML 방식에 비해 시간 절감 효과가 더 커집니다. 네트워킹 설정을 통해 데이터 및 모델 배포를 자유롭게 이동할 수 있는 한, 이 메모장을 클라우드, 온프레미스 또는 Kubernetes 클러스터에 다른 위치의 컴퓨팅 및 스토리지가 포함된 하이브리드 환경에 배포할 수 있습니다.</block>
  <block id="321cf11d6ad313e01614cfa7817893fb" category="doc">Jarvis 배포</block>
  <block id="24a0684c018bf0ed5e7001773d8df2c5" category="inline-link">Jarvis Early Access 프로그램</block>
  <block id="55ce258288b89404cc493de8c839e20a" category="paragraph">에 등록할 수 있습니다<block ref="de4a7b23900edb1996cbcb27f4a65904" category="inline-link-rx"></block> NGC(NVIDIA GPU Cloud)에서 Jarvis 컨테이너에 액세스 NVIDIA로부터 자격 증명을 받은 후 다음 단계를 사용하여 Jarvis를 배포할 수 있습니다.</block>
  <block id="e5a6dabbbe3f9144d9f6e72b568893cd" category="list-text">NGC에 로그인합니다.</block>
  <block id="a668e3da095eca41ef93e0c494a6ebad" category="list-text">NGC를 통해 조직을 "ea-2-Jarvis"로 설정합니다.</block>
  <block id="f3b0315f8d213517a6076eb7aff49cb6" category="list-text">Jarvis EA v0.2 자산 찾기: Jarvis 컨테이너는 '개인 레지스트리'&gt;'조직 컨테이너'에 있습니다.</block>
  <block id="6db8e9899d42bcac6aeb824da5e952ef" category="list-text">자비스(Jarvis) 를 선택하고 모델 스크립트(Model Scripts) 로 이동한 다음 자비스 빠른 시작(Jarvis Quick Start) 을 클릭합니다</block>
  <block id="737af365257800065a6412e56d652acc" category="list-text">모든 자산이 제대로 작동하는지 확인합니다.</block>
  <block id="8a5fd124171d01a74b1af73e73ab7761" category="list-text">PDF는 모델 스크립트 &gt; Jarvis Documentation &gt; File Browser에서 찾을 수 있습니다.</block>
  <block id="f3e3b1e7550f6cf9fe883b01695163b7" category="inline-link-macro">다음: 소매 사용 사례에 대한 상태 및 흐름 사용자 지정</block>
  <block id="3ae7e712d75bd01d43546679548a28a1" category="paragraph"><block ref="3ae7e712d75bd01d43546679548a28a1" category="inline-link-macro-rx"></block></block>
  <block id="e2b5e920360785877a1831ff4b128520" category="summary">NetApp 설정</block>
  <block id="9af8334f3fca73145524498c2f49ee10" category="inline-link-macro">다음: 개요</block>
  <block id="02e8a07ffc2e2c5240049e5214d70427" category="paragraph"><block ref="02e8a07ffc2e2c5240049e5214d70427" category="inline-link-macro-rx"></block></block>
  <block id="adb2100439d02c2978c4a5670cda87b8" category="summary">이 페이지에는 이 작업을 만드는 데 사용된 라이브러리와 프레임워크가 나열되어 있습니다. 이러한 모든 구성 요소는 Azure의 역할 기반 액세스 및 보안 제어와 완벽하게 통합됩니다.</block>
  <block id="235ff38f40d20846e27b4c64e964ce28" category="doc">데이터 처리 및 모델 교육을 위한 라이브러리</block>
  <block id="542e61809d35e9c83a99b29c87aa40fb" category="inline-link-macro">이전: Azure NetApp Files 성능 계층</block>
  <block id="b7fe935ab4f924b870ae1983e3f3a271" category="paragraph"><block ref="b7fe935ab4f924b870ae1983e3f3a271" category="inline-link-macro-rx"></block></block>
  <block id="c4e831049faaa8b89e89eebd0a105dab" category="paragraph">다음 표에서는 이 작업을 만드는 데 사용된 라이브러리와 프레임워크를 보여 줍니다. 이러한 모든 구성 요소는 Azure의 역할 기반 액세스 및 보안 제어와 완벽하게 통합됩니다.</block>
  <block id="faeae27c134f5193efb923d2492daa47" category="cell">라이브러리/프레임워크</block>
  <block id="b540cdb28de9a6c72ef1a92504e69423" category="cell">Dask cuML</block>
  <block id="1fc1b4b6567949aab2cb7e6fecb1e68f" category="inline-link">cuML 라이브러리</block>
  <block id="efe85bbaa5690074ea98a2bfef62d930" category="cell">GPU에서 작업할 ML의 경우<block ref="514c908f6fc3f426a00e1dabdf37831f" category="inline-link-rx"></block> Dask를 사용하여 RAPIDS cuML 패키지에 대한 액세스를 제공합니다. RAPIDS cuML은 고성능 GPU 기반 구축을 통해 클러스터링, 차원 축소, 회귀 접근 방식을 비롯한 인기 있는 ML 알고리즘을 구현하여 CPU 기반 접근 방식에 비해 최대 100배 빠른 속도를 제공합니다.</block>
  <block id="ede0db3d6c9043439d0762ee99543654" category="cell">Dask cuDF</block>
  <block id="a9c380d6e09cc11f858b53d56cf69da4" category="inline-link">dask-cudf 라이브러리</block>
  <block id="13a7d0199f9797a3533ff335da46b446" category="cell">CuDF에는 데이터 하위 설정, 변환, 핫 인코딩 등 GPU 가속 추출, 변환, 로드(ETL)를 지원하는 다양한 함수가 포함되어 있습니다. RAPIDS 팀은 을 유지합니다<block ref="836818db4e43067816d31d2b73198787" category="inline-link-rx"></block> 여기에는 Dask 및 cuDF를 사용하는 도우미 메서드가 포함됩니다.</block>
  <block id="0c9c2e873df681f1ab5b13053be78af7" category="cell">Scikit 학습</block>
  <block id="cd1235fc9b090edba051d73dbc6f66bf" category="inline-link">평가자</block>
  <block id="1977c9daa1d67de51a4651abdb160c09" category="inline-link">맞춤</block>
  <block id="4f54da5a2c4a796e8215f20eb95fddcc" category="cell">Scikit-Learn은 견적기라고 하는 수십 가지의 기계 학습 알고리즘과 모델을 제공합니다. 각각<block ref="855747fa3f470c1754852d09071dd101" category="inline-link-rx"></block> 를 사용하여 일부 데이터에 장착할 수 있습니다<block ref="e52e604a9dbe357e0fb9bc58f4b62add" category="inline-link-rx"></block> 방법.</block>
  <block id="0dd4d530afb3c99ab869350770d7bebd" category="paragraph">비교를 위해 두 대의 노트북을 사용해 ML 파이프라인을 구축했으며, 하나는 기존의 Pandas scikit-learn 접근방식이고, 다른 하나는 RAPIDS 및 Dask를 사용한 분산 훈련입니다. 각 노트북을 개별적으로 테스트하여 시간과 규모의 측면에서 성능을 확인할 수 있습니다. RAPIDS 및 DASK를 사용한 분산 훈련의 이점을 설명하기 위해 각 노트북을 개별적으로 다룹니다.</block>
  <block id="7dd297826f91c438fab12307224d2c40" category="inline-link-macro">다음: Pandas에서 Logs day 15를 클릭하고 좌골키트학습 무작위 포리스트 모델을 훈련합니다.</block>
  <block id="ade9906123700a8bf734457510b6b3c8" category="paragraph"><block ref="ade9906123700a8bf734457510b6b3c8" category="inline-link-macro-rx"></block></block>
  <block id="4ac9fa791a6d1c7c97bbae134dd22586" category="paragraph">진정한 대화형 AI 시스템은 인간과 같은 대화에 참여하고, 컨텍스트를 이해하고, 지능적인 응답을 제공합니다. 이러한 AI 모델은 대개 규모가 크고 매우 복잡합니다. NVIDIA GPU 및 NetApp 스토리지를 사용하면 최첨단 대용량 언어 모델을 훈련 및 최적화하여 추론을 신속하게 실행할 수 있습니다. 빠르게, 크고 복잡한 AI 모델 간에 이루어지는 거래를 끝내기 위한 주요 발걸음을 내딛습니다. 의료, 소매 및 금융 서비스 등의 산업을 위해 GPU에 최적화된 언어 이해 모델을 AI 애플리케이션에 통합하여 스마트 스피커 및 고객 서비스 분야에서 고급 디지털 음성 지원 기능을 제공할 수 있습니다. 이러한 고품질 대화형 AI 시스템을 통해 수직 시장에 있는 기업들은 고객과 교류할 때 이전에는 불가능했던 맞춤형 서비스를 제공할 수 있습니다.</block>
  <block id="45d5663acc501eba25058f8956035e9a" category="paragraph">Jarvis를 사용하면 가상 보조자, 디지털 아바타, 다중 모드 센서 Fusion(CV와 ASR/NLP/TTS 결합) 또는 변환 등의 ASR/NLP/TTS/CV 독립 실행형 사용 사례를 구축할 수 있습니다. 날씨, 관심 지점 및 재고 가격 관련 질문에 답할 수 있는 가상 소매 도우미를 구축했습니다. 또한 Cloud Sync를 사용하여 대화 내용을 보관하고 새 데이터에 Nemo 모델을 교육하여 대화형 AI 시스템의 자연어 이해 기능을 개선하는 방법을 시연했습니다.</block>
  <block id="38a609a97a676f2cc28ccec3d3097d4b" category="paragraph"><block ref="38a609a97a676f2cc28ccec3d3097d4b" category="inline-link-macro-rx"></block></block>
  <block id="4ed0a51bc1c995651eec6f50591eec1a" category="section-title">NetApp ONTAP AI 및 Cloud Sync</block>
  <block id="bff183f31dd9706bece9767f4388a819" category="paragraph">NVIDIA DGX 시스템 및 NetApp 클라우드 연결형 스토리지 시스템을 기반으로 하는 NetApp ONTAP AI 아키텍처는 NetApp과 NVIDIA가 개발 및 검증했습니다. 이 참조 아키텍처는 IT 조직이 다음과 같은 이점을 얻을 수 있도록 해 줍니다.</block>
  <block id="88acd7d612f76d7928b6b0448806e1ea" category="list-text">다양한 성능 및 비용 관련 다양한 스토리지 옵션을 제공합니다.NetApp ONTAP AI는 DGX 시스템과 NetApp AFF A220 스토리지 시스템을 최첨단 네트워킹과 완벽하게 통합합니다. NetApp ONTAP AI 및 DGX 시스템은 설계 복잡성과 추측을 제거함으로써 AI 배포를 단순화합니다. 고객은 작은 규모로 시작한 후 에지에서 코어 및 클라우드까지 포괄하여 데이터를 지능적으로 관리하면서 중단 없이 시스템을 확장할 수 있습니다.</block>
  <block id="69be3bc10a1ad78dbe823def1907c730" category="paragraph">NetApp Cloud Sync를 사용하면 두 개의 NFS 공유, 두 개의 CIFS 공유, 한 개의 파일 공유와 Amazon S3, Amazon Elastic File System(EFS) 또는 Azure Blob 스토리지 간에 다양한 프로토콜을 통해 데이터를 쉽게 이동할 수 있습니다. 액티브-액티브 작업은 소스와 타겟을 동시에 계속 사용하여 필요한 경우 데이터 변경 사항을 점진적으로 동기화할 수 있음을 의미합니다. 온프레미스 또는 클라우드 기반 등 모든 소스 시스템과 대상 시스템 간에 데이터를 이동 및 증분 동기화하여 Cloud Sync은 데이터를 사용할 수 있는 다양한 새로운 방법을 제시합니다. 사내 시스템, 클라우드 온보딩, 클라우드 마이그레이션, 협업 및 데이터 분석 간에 데이터를 마이그레이션하는 작업을 모두 쉽게 수행할 수 있게 되었습니다. 아래 그림은 사용 가능한 소스 및 대상을 보여줍니다.</block>
  <block id="1e01782ef13699818c9eb9eab796bffc" category="paragraph">대화형 AI 시스템에서 개발자는 Cloud Sync를 활용하여 클라우드에서 데이터 센터에 이르는 대화 내역을 아카이브하여 NLP(자연어 처리) 모델의 오프라인 교육을 수행할 수 있습니다. 더 많은 연고를 인식하는 교육 모델을 통해 대화형 AI 시스템은 최종 사용자의 더 복잡한 질문을 더 효과적으로 관리할 수 있습니다.</block>
  <block id="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="paragraph"><block ref="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ad66827309f61fd22dc58cbbb2f8273" category="inline-link">NVIDIA Jarvis</block>
  <block id="241d985aedf9124840f9adfa9496755d" category="paragraph"><block ref="9f89431954623c8e5c580e4350b427e7" category="inline-link-rx"></block> 대화형 AI 서비스를 구축하기 위한 엔드 투 엔드 프레임워크입니다. 다음과 같은 GPU 최적화 서비스가 포함됩니다.</block>
  <block id="bb3e7af8136880e3a92118c172aed302" category="list-text">자동 음성 인식(ASR)</block>
  <block id="3c07089a439435a2998f14ea97f90825" category="list-text">자연어 이해(NLU)</block>
  <block id="8375cc1d63ce172363c4ed9c3cddd508" category="list-text">도메인별 이행 서비스와 통합</block>
  <block id="84fb561f92aa70d5e118f429e98ee99b" category="list-text">TTS(Text-to-Speech)</block>
  <block id="9478a4e1be70e1be0fdd56f3929bbdc2" category="list-text">컴퓨터 비전(CV) Jarvis 기반 서비스는 최첨단 딥 러닝 모델을 사용하여 실시간 대화 AI의 복잡하고 까다로운 작업을 해결합니다. 최종 사용자와의 자연스러운 실시간 상호 작용을 지원하기 위해 모델은 300밀리초 이내에 계산을 완료해야 합니다. 자연스러운 상호작용은 어려운 과제이며, 다중 모드 감각 통합이 필요합니다. 또한 모델 파이프라인은 복잡하며 위 서비스 간의 조정이 필요합니다.</block>
  <block id="c29efa8b1d5c9d6d647a8ce72bef1b74" category="paragraph">Jarvis는 엔드 투 엔드 딥 러닝 파이프라인을 사용하는 다중 모달 대화 AI 서비스를 구축하기 위한 애플리케이션 프레임워크입니다. Jarvis 프레임워크는 음성, 비전 및 NLU 작업을 위한 사전 교육 대화 AI 모델, 도구 및 최적화된 엔드 투 엔드 서비스를 포함합니다. Jarvis를 사용하면 AI 서비스 외에도 비전, 오디오 및 기타 센서 입력을 동시에 결합하여 가상 보조자, 다중 사용자 양극화 및 콜센터 보조자와 같은 애플리케이션에서 다중 사용자, 다중 컨텍스트 대화 등의 기능을 제공할 수 있습니다.</block>
  <block id="dc3652fc64a2a6ea2a3cfd5c40443b16" category="paragraph"><block ref="4282ee73b9eecd67e90ed51f4f36b077" category="inline-link-rx"></block> 사용하기 쉬운 API(애플리케이션 프로그래밍 인터페이스)를 사용하여 GPU 가속 첨단 대화 AI 모델을 구축, 교육 및 미세 조정하는 오픈 소스 Python 툴킷입니다. Nemo는 NVIDIA GPU에서 Tensor Core를 사용하여 혼합 정밀 컴퓨팅을 실행하며 여러 GPU로 손쉽게 확장하여 가능한 최고의 교육 성능을 제공할 수 있습니다. Nemo는 의료, 재무, 소매 및 통신 등 다양한 산업 분야에서 화상 통화 기록, 지능형 비디오 비서, 자동화된 콜 센터 지원 등의 실시간 ASR, NLP 및 TTS 애플리케이션을 위한 모델을 구축하는 데 사용됩니다.</block>
  <block id="4e5ae683e2a399c166a1724b0aa6952e" category="paragraph">Nemo를 사용하여 아카이빙된 대화 기록의 사용자 질문에서 복잡한 인텐트를 인식하는 모델을 교육했습니다. 이 교육은 소매 가상 보조자의 능력을 Jarvis가 제공하는 지원 범위를 넘어 확장합니다.</block>
  <block id="053bc62e92a61e44afd338bcb27c422f" category="section-title">소매 사용 사례 요약</block>
  <block id="8b6b761738b93e745ffa4f73dd233c08" category="paragraph">NVIDIA Jarvis를 사용하여 음성 또는 텍스트 입력을 수용하는 가상 소매 도우미를 구축하고 날씨, 관심 지점 및 재고 가격 관련 질문에 답변했습니다. 대화형 AI 시스템은 예를 들어, 사용자가 날씨 또는 관심 지점을 지정하지 않은 경우 후속 질문을 하여 대화 흐름을 기억할 수 있습니다. 또한 이 시스템은 "태국식 음식" 또는 "노트북 메모리"와 같은 복잡한 엔터티도 인식합니다. 그것은 “다음주 로스앤젤레스에서 비가 올까요?”와 같은 자연어 질문을 이해합니다. 소매 가상 비서의 데모는 에서 확인할 수 있습니다<block ref="0ba395e7fb59bace5ff35ab3c02ad737" category="inline-link-rx"></block>.</block>
  <block id="af8f881c5074e5e10cd7a34ccbaa9e57" category="paragraph"><block ref="af8f881c5074e5e10cd7a34ccbaa9e57" category="inline-link-macro-rx"></block></block>
  <block id="61133eed21544af8c4988e345e562ce0" category="summary">데이터 보호 및 보안 솔루션 기능에 대해 설명하는 비디오 및 데모 시리즈</block>
  <block id="80a9ba2a1f85a5cf26d01122fd696973" category="doc">데이터 보호 및 보안 비디오 및 데모</block>
  <block id="ea233cf80b43de3a730e01b8e376a9bd" category="paragraph">데이터 보호 및 보안 솔루션의 특정 기능을 중점적으로 설명하는 비디오 및 데모 개요</block>
  <block id="b9332d9812fee56d4f22fd8f245323a9" category="section-title">데모/비디오</block>
  <block id="a712a0e553d0302aa27009e1ebc815ce" category="summary">엔터프라이즈 하이브리드 클라우드 솔루션에 대한 비디오 및 데모 시리즈</block>
  <block id="a867425c6a29a742f3dc77c80f5adac8" category="doc">엔터프라이즈 하이브리드 클라우드 비디오 및 데모</block>
  <block id="02ca4b8a1f54adf2c0d931bc5bdb61f3" category="paragraph">세 가지 주요 클라우드 공급자 모두를 대상으로 하는 엔터프라이즈 하이브리드 클라우드 솔루션의 특정 기능을 소개하는 다음 비디오와 데모를 확인하십시오.</block>
  <block id="c94d29f1f4f8ef37e9d27f30b7d7c67d" category="summary">SnapCenter 하이브리드 클라우드 데이터베이스 워크로드 환경을 준비하려면 이 섹션에 설명된 작업을 사내 에서 완료해야 합니다.</block>
  <block id="f6a196d9d3a941e76765e4a9395630c4" category="doc">사전 요구 사항 온-프레미스</block>
  <block id="eac55cbc45bfe6b98b8847b3952de7d3" category="inline-link-macro">이전: 사전 요구 사항 구성.</block>
  <block id="e63a288cc25b5c4127d3021b339c9f20" category="paragraph"><block ref="e63a288cc25b5c4127d3021b339c9f20" category="inline-link-macro-rx"></block></block>
  <block id="40931dcd4d9132545ec0faf2c5fb1b64" category="paragraph">SnapCenter 하이브리드 클라우드 데이터베이스 워크로드 환경을 준비하기 위해 온프레미스에서 다음 작업을 완료해야 합니다.</block>
  <block id="79daf399b9626cde309801f41a1e2e14" category="section-title">SnapCenter 설치 및 구성</block>
  <block id="2607530756fefa4173e12cfcd5fbfb01" category="paragraph">워크그룹 배포도 가능하긴 하지만, NetApp SnapCenter 툴은 Windows 도메인 환경에서 일반적으로 실행되는 Windows 기반 애플리케이션입니다. 데이터베이스 작업 부하를 위해 중앙 집중식 관리 서버(SnapCenter 서버)와 데이터베이스 서버 호스트의 SnapCenter 플러그인을 포함하는 다중 계층 아키텍처를 기반으로 합니다. 다음은 하이브리드 클라우드 구축과 관련된 몇 가지 주요 고려 사항입니다.</block>
  <block id="9f8c0bcd11d7afd1dd2ee818191cb914" category="list-text">* 단일 인스턴스 또는 HA 배포. * HA 배포는 단일 SnapCenter 인스턴스 서버 장애 시 중복성을 제공합니다.</block>
  <block id="1bfa2867d5aa49106efbf3ac752f3084" category="list-text">* 이름 확인. * 정방향 및 역방향 조회를 위해 모든 데이터베이스 호스트와 스토리지 SVM을 확인하도록 SnapCenter 서버에서 DNS를 구성해야 합니다. 또한 정방향 및 역방향 조회를 위해 SnapCenter 서버와 스토리지 SVM을 확인하기 위해 데이터베이스 서버에도 DNS를 구성해야 합니다.</block>
  <block id="41f54308d86c1d7b525475d6ead22892" category="list-text">* 역할 기반 액세스 제어(RBAC) 구성. * 혼합 데이터베이스 워크로드의 경우 RBAC를 사용하여 Oracle 데이터베이스의 관리자 또는 SQL Server의 관리자와 같은 서로 다른 DB 플랫폼의 관리 책임을 분리할 수 있습니다. DB 관리자 사용자에게 필요한 권한이 부여되어야 합니다.</block>
  <block id="5aee5dffd2e329652ec35995add763ae" category="list-text">* 정책 기반 백업 전략을 활성화합니다. * 백업 일관성 및 안정성을 적용합니다.</block>
  <block id="dde4790e572aa9d01cd58fcfd8498766" category="list-text">* 방화벽에서 필요한 네트워크 포트를 엽니다. * 온프레미스 SnapCenter 서버가 클라우드 DB 호스트에 설치된 에이전트와 통신합니다.</block>
  <block id="e2962676531ebdcf62cb2a7b96042e77" category="list-text">* 사내 및 퍼블릭 클라우드 간 SnapMirror 트래픽이 가능하도록 포트가 열려 있어야 합니다. * SnapCenter 서버는 ONTAP SnapMirror를 기반으로 온사이트 Snapshot 백업을 클라우드 CVO 스토리지 SVM으로 복제합니다.</block>
  <block id="549762060d7242346fa79f39cba51791" category="inline-link-macro">SnapCenter 설치 워크플로우</block>
  <block id="aec875397d57826c45f7072636026a07" category="paragraph">신중하게 사전 설치 계획 및 고려했으면 이 항목을 클릭합니다 <block ref="f44e9d032441cc842cad02c3aab57d84" category="inline-link-macro-rx"></block> SnapCenter 설치 및 구성에 대한 자세한 내용은 를 참조하십시오.</block>
  <block id="df3fb602185c77a88bab186791d02636" category="section-title">온프레미스 데이터베이스 서버 스토리지 구성</block>
  <block id="f7f3a649be867b87ccb26789453199db" category="paragraph">스토리지 성능은 데이터베이스 및 애플리케이션의 전반적인 성능에서 중요한 역할을 합니다. 잘 설계된 스토리지 레이아웃은 DB 성능을 개선할 뿐만 아니라 데이터베이스 백업 및 복구를 쉽게 관리할 수 있도록 합니다. 데이터베이스 크기, 데이터베이스의 예상 데이터 변경율, 백업을 수행하는 빈도 등 스토리지 레이아웃을 정의할 때 몇 가지 요소를 고려해야 합니다.</block>
  <block id="8481231881c8e64b34aa3c7e29510a25" category="paragraph">가상화된 데이터베이스 워크로드를 위해 NFS 또는 iSCSI를 통해 스토리지 LUN을 게스트 VM에 직접 연결하면 일반적으로 VMDK를 통해 할당된 스토리지보다 성능이 향상됩니다. 다음 그림에 표시된 LUN의 대규모 SQL Server 데이터베이스에 대한 스토리지 레이아웃을 사용하는 것이 좋습니다.</block>
  <block id="cc75f443d22e45e490468a8f20689d77" category="paragraph"><block ref="cc75f443d22e45e490468a8f20689d77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99aea05cf884bfdec230afa5250968b2" category="paragraph">다음 그림은 LUN의 중소 규모 SQL Server 데이터베이스에 대한 NetApp 권장 스토리지 레이아웃을 보여 줍니다.</block>
  <block id="9fc72535f1113895818f8aa60ef773e7" category="paragraph"><block ref="9fc72535f1113895818f8aa60ef773e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ecde8f778d0dd0676f392793ce4382" category="admonition">로그 디렉토리는 SnapCenter 전용으로 데이터베이스 복구를 위한 트랜잭션 로그 롤업을 수행합니다. 초대형 데이터베이스의 경우, 성능 향상을 위해 여러 LUN을 볼륨에 할당할 수 있습니다.</block>
  <block id="ee9158729a15dbd90d166650ba285d0e" category="paragraph">Oracle 데이터베이스 워크로드의 경우 SnapCenter는 호스트에 물리적 또는 가상 디바이스로 마운트된 ONTAP 스토리지가 지원하는 데이터베이스 환경을 지원합니다. 환경의 중요도에 따라 단일 또는 여러 스토리지 장치에서 전체 데이터베이스를 호스팅할 수 있습니다. 일반적으로 고객은 전용 스토리지의 데이터 파일을 제어 파일, 재실행 파일 및 아카이브 로그 파일과 같은 다른 모든 파일에서 격리합니다. 따라서 관리자는 Snapshot 기술을 사용하여 (ONTAP 단일 파일 SnapRestore)를 신속하게 복원하거나 (페타바이트 규모)의 대규모 중요 데이터베이스를 몇 초에서 몇 분 이내에 클론 복제할 수 있습니다.</block>
  <block id="b31fbb7e1a6e863315e431fdf9c00db9" category="paragraph"><block ref="b31fbb7e1a6e863315e431fdf9c00db9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="959a3405dfdfb0469534f5276ffb8e5e" category="paragraph">지연 시간에 민감한 미션 크리티컬 워크로드의 경우, 최적의 지연 시간을 달성하기 위해 다양한 유형의 Oracle 파일에 전용 스토리지 볼륨을 구축해야 합니다. 대규모 데이터베이스의 경우 볼륨당 여러 개의 LUN(최대 8개 권장)을 데이터 파일에 할당해야 합니다.</block>
  <block id="ac111cbcae2e9eaedafe418acc3a2cab" category="paragraph"><block ref="ac111cbcae2e9eaedafe418acc3a2cab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702ce3d59ec94853fa030462b309f2f" category="paragraph">소규모 Oracle 데이터베이스의 경우 SnapCenter는 여러 데이터베이스 또는 데이터베이스의 일부를 동일한 스토리지 볼륨 또는 LUN에 호스팅할 수 있는 공유 스토리지 레이아웃을 지원합니다. 이 레이아웃의 예로는 + data ASM 디스크 그룹 또는 볼륨 그룹의 모든 데이터베이스에 대한 데이터 파일을 호스팅할 수 있습니다. 나머지 파일(재실행, 아카이브 로그 및 제어 파일)은 다른 전용 디스크 그룹 또는 볼륨 그룹(LVM)에서 호스팅할 수 있습니다. 이러한 구축 시나리오는 아래에 나와 있습니다.</block>
  <block id="6c12e98a6e201f55836390c2a6232e5a" category="paragraph"><block ref="6c12e98a6e201f55836390c2a6232e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93cf45b97655292e0536b810cb248828" category="paragraph">Oracle 데이터베이스 재배치를 용이하게 하기 위해 일반 백업 정책에 포함된 별도의 LUN에 Oracle 바이너리를 설치해야 합니다. 따라서 새 서버 호스트로 데이터베이스를 재배치할 경우 동기화 해제된 Oracle 바이너리로 인해 발생할 수 있는 문제 없이 Oracle 스택을 복구에 시작할 수 있습니다.</block>
  <block id="1e69a4a8adec0842d1e110e970112268" category="section-title">라이센스 요구 사항</block>
  <block id="7f59934b2c0edd33f0d981f3bc4d12e7" category="paragraph">SnapCenter은 NetApp의 라이센스 소프트웨어입니다. 일반적으로 사내 ONTAP 라이센스에 포함됩니다. 하지만 하이브리드 클라우드를 구축할 경우, SnapCenter용 클라우드 라이센스를 통해 SnapCenter에 CVO를 타겟 데이터 복제 대상으로 추가해야 합니다. 자세한 내용은 SnapCenter 표준 용량 기반 라이센스에 대한 다음 링크를 참조하십시오.</block>
  <block id="9e86ae6c96041e3cb31e88116102ee35" category="inline-link-macro">SnapCenter 표준 용량 기반 라이센스</block>
  <block id="a1d51b5b5f3258b40cbe392146bc8868" category="paragraph"><block ref="a1d51b5b5f3258b40cbe392146bc8868" category="inline-link-macro-rx"></block></block>
  <block id="85db56d490cdd7a31d40697ad1c9be3c" category="section-title">네트워킹 및 보안</block>
  <block id="254215e6d18fb5582ba78464fa468553" category="paragraph">개발/테스트 및 재해 복구를 위해 클라우드로 안전하게 전환하는 온프레미스 운영 데이터베이스가 필요한 하이브리드 데이터베이스 작업에서는 환경을 설정하고 사내 데이터 센터에서 퍼블릭 클라우드에 연결할 때 네트워킹 및 보안을 고려해야 합니다.</block>
  <block id="1e356fab450b44971b6cdbd1c25586b8" category="paragraph">퍼블릭 클라우드는 일반적으로 VPC(가상 프라이빗 클라우드)를 사용하여 퍼블릭 클라우드 플랫폼 내에서 서로 다른 사용자를 격리합니다. 개별 VPC 내에서 보안은 VPC 잠금에 대한 사용자 요구에 따라 구성할 수 있는 보안 그룹과 같은 방법을 사용하여 제어됩니다.</block>
  <block id="5192a6d33c7a0127a67cbd7e07801735" category="paragraph">VPN 터널을 통해 사내 데이터 센터에서 VPC로의 연결을 보호할 수 있습니다. VPN 게이트웨이에서 NAT 및 방화벽 규칙을 사용하여 보안을 강화할 수 있습니다. 이 규칙은 인터넷에 있는 호스트로부터 회사 데이터 센터 내의 호스트로의 네트워크 연결을 설정하는 시도를 차단합니다.</block>
  <block id="04a3995237c020c6a587d8a7723af6a6" category="paragraph">네트워킹 및 보안 고려 사항에 대해서는 선택한 퍼블릭 클라우드에 대한 관련 인바운드 및 아웃바운드 CVO 규칙을 검토하십시오.</block>
  <block id="d15513a147fbd525b88805bee9ea17ea" category="inline-link-macro">CVO-AWS의 보안 그룹 규칙</block>
  <block id="f8d1f085169118c4d407be16136389c6" category="list-text"><block ref="f8d1f085169118c4d407be16136389c6" category="inline-link-macro-rx"></block></block>
  <block id="39f48b44d100d16ed6e2b931111663b7" category="inline-link-macro">CVO-Azure의 보안 그룹 규칙</block>
  <block id="bcde746324630d82052a4fc9861cfea6" category="list-text"><block ref="bcde746324630d82052a4fc9861cfea6" category="inline-link-macro-rx"></block></block>
  <block id="7b20c547f2fd113499deaa3c0e418282" category="inline-link-macro">CVO-GCP의 방화벽 규칙</block>
  <block id="acde731d82a437ab33cb200791f7a197" category="list-text"><block ref="acde731d82a437ab33cb200791f7a197" category="inline-link-macro-rx"></block></block>
  <block id="d9446a69434b7c7fdec5c9e35d222834" category="section-title">Ansible 자동화를 사용하여 온프레미스 및 클라우드 간 DB 인스턴스를 동기화하십시오(선택 사항)</block>
  <block id="1c7c9b49a62ea0dc765d1439120cfc8f" category="paragraph">하이브리드 클라우드 데이터베이스 환경의 관리를 단순화하기 위해, NetApp은 산연 인스턴스를 온프레미스 및 클라우드에 동기화하는 등 일부 관리 작업을 자동화하기 위해 Ansible 컨트롤러를 구축할 것을 적극 권장하지만 필요로 하지는 않습니다. 이는 특히 중요합니다. 클라우드의 비동기 컴퓨팅 인스턴스는 커널 패키지 및 기타 문제가 누락되어 복구된 데이터베이스를 클라우드에서 오류가 발생하기 쉬운 상태로 만들 수 있기 때문입니다.</block>
  <block id="7468552c7fc3a7ca377b7fc2405a9940" category="paragraph">Ansible 컨트롤러의 자동화 기능도 SnapMirror 인스턴스를 확장하여 운영 시 DR 데이터 복사본을 활성화하는 등 특정 작업에 SnapCenter를 보강할 수 있습니다.</block>
  <block id="6ac547919eb6ca11f5a8387eaf990843" category="inline-link-macro">RedHat/CentOS Ansible 컨트롤러 설치</block>
  <block id="c8e133fc33bbdb52f84b3532496f2ac8" category="inline-link-macro">Ubuntu/Debian Ansible 컨트롤러 설치</block>
  <block id="6f332c2f54a4d49478f9588c5cd6c57c" category="paragraph">다음 지침에 따라 RedHat 또는 CentOS 시스템에 대한 Ansible 제어 노드를 설정합니다. <block ref="fedce547519117863322cfa54cc2ba7d" category="inline-link-macro-rx"></block>. 다음 지침에 따라 Ubuntu 또는 Debian 시스템용 Ansible 제어 노드를 설정합니다. <block ref="1c50818f5fe40dbc8b2e05138d554fa4" category="inline-link-macro-rx"></block>.</block>
  <block id="d5316785c089f90464e8e683aadd02e1" category="inline-link-macro">다음으로: 퍼블릭 클라우드.</block>
  <block id="d09f79a080b121cb1acc181711b5d02a" category="paragraph"><block ref="d09f79a080b121cb1acc181711b5d02a" category="inline-link-macro-rx"></block></block>
  <block id="467bda78c0e1adcc5ed650843fbfbdf5" category="summary">이 섹션에서는 AWS에서 Cloud Manager 및 Cloud Volumes ONTAP를 구축하는 프로세스에 대해 설명합니다.</block>
  <block id="298a4809d5445df75b6c4a9fb94074a4" category="doc">AWS 퍼블릭 클라우드 시작하기</block>
  <block id="b8f5ff8c1ae69fa5befe459d3f34b68a" category="inline-link-macro">이전: 온-프레미스 시작.</block>
  <block id="19f84106226ff97c314f55dd621bbd98" category="paragraph"><block ref="19f84106226ff97c314f55dd621bbd98" category="inline-link-macro-rx"></block></block>
  <block id="8a3f037eef48de78bfe13d14e3d7cdfa" category="section-title">설치하고</block>
  <block id="87aa698992e009d04733c9906225592c" category="admonition">그 결과를 더욱 쉽게 확인할 수 있도록 AWS에 구축된 이 문서를 토대로 마련했습니다. 그러나 프로세스는 Azure 및 GCP와 매우 유사합니다.</block>
  <block id="39845311263ccad04c0d4f0b9aa9d4c6" category="section-title">비행 전 점검</block>
  <block id="12ed93944854c12caa37886d620f16db" category="paragraph">배포 전에 다음 단계에서 배포할 수 있도록 인프라가 마련되어 있는지 확인합니다. 여기에는 다음이 포함됩니다.</block>
  <block id="c6368ae044df0f7bb26ed60afda5c591" category="list-text">설치하 고 있습니다</block>
  <block id="4019c185756035c18c03fabfccd7d4b2" category="list-text">선택한 지역에서 VPC를 사용할 수 있습니다</block>
  <block id="fca5d2fece6e360f78dff4573ba04a20" category="list-text">공용 인터넷에 액세스할 수 있는 서브넷입니다</block>
  <block id="e3e5c3dadc3e70d536645a3be9744f79" category="list-text">AWS 계정에 IAM 역할을 추가할 수 있는 권한</block>
  <block id="bd5c82fb0e0371a168f609848b11e92a" category="list-text">AWS 사용자를 위한 비밀 키 및 액세스 키입니다</block>
  <block id="c3d1ff3c88148b2246bb0972916da82a" category="section-title">2.AWS에서 Cloud Manager 및 Cloud Volumes ONTAP를 구축하는 단계</block>
  <block id="6d0eb695a99109617b806676e9610075" category="inline-link">NetApp 클라우드 문서</block>
  <block id="593581e466784760a050bceaea5e0c48" category="admonition">Cloud Manager와 Cloud Volumes ONTAP를 구축하는 방법은 매우 간단합니다. 이 방법은 가장 간단하지만 가장 많은 권한이 필요합니다. 이 방법이 AWS 환경에 적합하지 않은 경우 을 참조하십시오<block ref="97a20614f8c0e53f461a9353634e5e51" category="inline-link-rx"></block>.</block>
  <block id="bb3e779fdf877143137572122cf424e3" category="section-title">Cloud Manager 커넥터를 배포합니다</block>
  <block id="49fc376ed35249f3841846ede4dab884" category="inline-link">NetApp Cloud Central에서</block>
  <block id="4c6e32ff373dc3ce5b49202f92f01b08" category="list-text">로 이동합니다<block ref="143fea272f01f72dbdc942451156df21" category="inline-link-rx"></block> 로그인 또는 가입</block>
  <block id="356cf5e12d635c19d987b1b195ff5a40" category="paragraph"><block ref="356cf5e12d635c19d987b1b195ff5a40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2300b8579a8761e452d89a2af6636b7d" category="list-text">로그인한 후 Canvas로 옮겨야 합니다.</block>
  <block id="af93b0b88e1db5f3aa229d2336fedb3c" category="paragraph"><block ref="af93b0b88e1db5f3aa229d2336fedb3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fbf2c408ce86ff3403990e7e32dcb3" category="list-text">"작업 환경 추가"를 클릭하고 AWS에서 Cloud Volumes ONTAP를 선택합니다. 단일 노드 시스템을 배포할지 고가용성 쌍을 구축할지를 선택할 수도 있습니다. 고가용성 쌍을 구축하기로 선택했습니다.</block>
  <block id="bb18ff1ebac7ea2039aa297469c76b76" category="paragraph"><block ref="bb18ff1ebac7ea2039aa297469c76b76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="016aa0c0a7322975ec4b8eeac805f2c0" category="list-text">커넥터가 작성되지 않은 경우 커넥터를 작성하라는 팝업 메시지가 나타납니다.</block>
  <block id="a05691eb0d806668c3796d3d6fe01157" category="paragraph"><block ref="a05691eb0d806668c3796d3d6fe01157" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fc3362a0d8ab63cc8fa21bbd0fb07db" category="list-text">시작 을 클릭한 다음 AWS 를 선택합니다.</block>
  <block id="55f5adc74d49945abd7798742f307124" category="paragraph"><block ref="55f5adc74d49945abd7798742f307124" category="inline-image-macro-rx" type="image"></block></block>
  <block id="deae4c054bb3102bbf634b14534da9bf" category="inline-link">NetApp 정책 페이지를 참조하십시오</block>
  <block id="651d429a2b6cfcd93f6adb1d4825a214" category="list-text">암호 키와 액세스 키를 입력합니다. 사용자에게 에 설명된 올바른 권한이 있는지 확인합니다<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block>.</block>
  <block id="94497191b0b0c6d05a2df7d2175e87f5" category="paragraph"><block ref="94497191b0b0c6d05a2df7d2175e87f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d59b60a74630e45f83fd3c48207b47" category="list-text">커넥터에 이름을 지정하고 에 설명된 대로 미리 정의된 역할을 사용합니다<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block> 또는 Cloud Manager에게 역할을 맡도록 요청하십시오.</block>
  <block id="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="paragraph"><block ref="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02d395705fb063ad8d33d8c83c856e6f" category="list-text">커넥터를 배포하는 데 필요한 네트워킹 정보를 제공합니다. 다음과 같은 방법으로 아웃바운드 인터넷 액세스가 활성화되었는지 확인합니다.</block>
  <block id="8215126360cbe5d8f5566c7ffc8cf224" category="list-text">커넥터에 공용 IP 주소를 제공합니다</block>
  <block id="22adb619c008bfd7495288573093ae44" category="list-text">커넥터를 통해 작업할 프록시를 제공합니다</block>
  <block id="58a149795bbe86e4e0d4ab8f10413219" category="list-text">인터넷 게이트웨이를 통해 공용 인터넷에 연결되는 경로를 커넥터에 제공합니다</block>
  <block id="5908ad1cf5bd748238e305dd5fc52fac" category="paragraph"><block ref="5908ad1cf5bd748238e305dd5fc52fac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c58ebc9f032dc8d2e5c4f522cedbe0b" category="list-text">보안 그룹을 제공하거나 새 보안 그룹을 생성하여 SSH, HTTP 및 HTTPS를 통해 커넥터와 통신할 수 있습니다. IP 주소에서만 커넥터에 대한 액세스를 활성화했습니다.</block>
  <block id="1d39d9c13f50dd25f7e54173c87c633a" category="paragraph"><block ref="1d39d9c13f50dd25f7e54173c87c633a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb444cfaba774437ecdbbb95856d94cd" category="list-text">요약 페이지의 정보를 검토하고 추가 를 클릭하여 커넥터를 배포합니다.</block>
  <block id="5576df68e3720f55e585e7e091d5b9e3" category="paragraph"><block ref="5576df68e3720f55e585e7e091d5b9e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4255ace47c9ad7f2907c18df7512bb9f" category="list-text">이제 커넥터는 클라우드 형성 스택을 사용하여 전개됩니다. Cloud Manager에서 또는 AWS를 통해 진행률을 모니터링할 수 있습니다.</block>
  <block id="ff7fb4bedc0d09880f85d9745ec258a5" category="paragraph"><block ref="ff7fb4bedc0d09880f85d9745ec258a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca320cc147e2b9fac2dd7379e91012b6" category="list-text">배포가 완료되면 성공 페이지가 나타납니다.</block>
  <block id="f5bbadf1ed57058e80e27764684e6314" category="paragraph"><block ref="f5bbadf1ed57058e80e27764684e6314" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6382283fd45b13b5c983745731fec990" category="section-title">Cloud Volumes ONTAP 구축</block>
  <block id="5fe90897c7135ba3020c4a397f55adb6" category="list-text">요구사항에 따라 AWS 및 구축 유형을 선택하십시오.</block>
  <block id="63b636f2002a2e7b7c2e2420cd64ff73" category="paragraph"><block ref="63b636f2002a2e7b7c2e2420cd64ff73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf1300c5621fdebe8c1a70fade44f3b" category="list-text">구독이 할당되지 않은 상태에서 PAYGO를 사용하여 구매하려는 경우 자격 증명 편집 을 선택합니다.</block>
  <block id="b893bded7e1bd3419a443758a8ef410f" category="paragraph"><block ref="b893bded7e1bd3419a443758a8ef410f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88eb84b1a8f0417c9de6e1202125df56" category="list-text">구독 추가 를 선택합니다.</block>
  <block id="0b5d3e3d1a9347ff4a7395d09208a8f4" category="paragraph"><block ref="0b5d3e3d1a9347ff4a7395d09208a8f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="052208bafdfe08bc8f0735a78226e541" category="list-text">가입하려는 계약 유형을 선택합니다. 나는 선불 종량제 를 선택했습니다.</block>
  <block id="4d5ab1ed0682fe644e831558598d4638" category="paragraph"><block ref="4d5ab1ed0682fe644e831558598d4638" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65577508f7897e730adb501d0db73913" category="list-text">AWS로 리디렉션됩니다. 구독으로 계속 을 선택합니다.</block>
  <block id="ac33260d1e06f504f1dcac229aeb269c" category="paragraph"><block ref="ac33260d1e06f504f1dcac229aeb269c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="439c4fb23c120f0a99894c630cedaabd" category="list-text">구독하면 NetApp Cloud Central로 리디렉션됩니다. 이미 가입되어 있고 리디렉션되지 않는 경우 "여기를 클릭" 링크를 선택하십시오.</block>
  <block id="a90c8b1fc04a41aff490fd2b269f5932" category="paragraph"><block ref="a90c8b1fc04a41aff490fd2b269f5932" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b9e98d2b57da92c29826ce7de32c32" category="list-text">구독의 이름을 지정하고 Cloud Central 계정에 할당해야 하는 Cloud Central로 리디렉션됩니다.</block>
  <block id="c89376fd9624f6ebda7959df6176ef34" category="paragraph"><block ref="c89376fd9624f6ebda7959df6176ef34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4508f5994d1b34ff85cd1e8a1884d6c1" category="list-text">성공하면 확인 표시 페이지가 나타납니다. Cloud Manager 탭으로 다시 이동합니다.</block>
  <block id="2b206bbd8f3b20e3282b660a356d90be" category="paragraph"><block ref="2b206bbd8f3b20e3282b660a356d90be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3294e5fb9ec1c42cde7ebf9b206c583" category="list-text">이제 Cloud Central에 구독이 나타납니다. 계속하려면 적용을 클릭하십시오.</block>
  <block id="37ce5c33a55d907edabe632c39a2707c" category="paragraph"><block ref="37ce5c33a55d907edabe632c39a2707c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7927b068a5dddb4852b2e7dc256544" category="list-text">다음과 같은 작업 환경 세부 정보를 입력합니다.</block>
  <block id="0dbae4d42c7a0db53e2eb32adee12892" category="list-text">클러스터 이름입니다</block>
  <block id="0c191ee206a91460fd94e2ff976a38e7" category="list-text">클러스터 암호입니다</block>
  <block id="53aa18427d1e2c7b7113c668561a62d2" category="list-text">AWS 태그(선택 사항)</block>
  <block id="d3b6ff1e8c6317d132d3a5e974f1374c" category="paragraph"><block ref="d3b6ff1e8c6317d132d3a5e974f1374c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fb5b261ae3a3581304a283ef70a5246" category="inline-link">NetApp Cloud 홈 페이지</block>
  <block id="e7b29c75e71a48483734401322ef6e92" category="list-text">구축할 추가 서비스를 선택하십시오. 이러한 서비스에 대한 자세한 내용은 를 참조하십시오<block ref="1bb1213784e04e4f47d06f252d1ba164" category="inline-link-rx"></block>.</block>
  <block id="88e71a2c19d98c79d2ed51a753c8a4c2" category="paragraph"><block ref="88e71a2c19d98c79d2ed51a753c8a4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0dffa77d5644a3816ba69e24ce813ff" category="list-text">여러 가용성 영역(각각 다른 AZ에 있는 3개의 서브넷이 필요함) 또는 단일 가용성 영역에 구축할지 선택합니다. 여러 개의 AZs를 선택했습니다.</block>
  <block id="6e4a3fe2b0629dae504d8e727147f709" category="paragraph"><block ref="6e4a3fe2b0629dae504d8e727147f709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b889b7255c34e7f230e392668605860" category="list-text">구축할 클러스터의 지역, VPC 및 보안 그룹을 선택합니다. 이 섹션에서는 노드별(및 중재자) 가용성 영역과 해당 영역이 차지하는 서브넷도 할당합니다.</block>
  <block id="9ad68c9f72863557931a8569462bff52" category="paragraph"><block ref="9ad68c9f72863557931a8569462bff52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be43ebbf5380089f153e4f1b13e35e6f" category="list-text">노드 및 중재자의 연결 방법을 선택합니다.</block>
  <block id="8bf6da8b537127466c4421c1ae3169be" category="paragraph"><block ref="8bf6da8b537127466c4421c1ae3169be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="204bd52e1d13052712299779cf041df6" category="admonition">중재자가 AWS API와 통신해야 합니다. 중재자 EC2 인스턴스를 구축한 후 API에 연결할 수 있으면 공용 IP 주소가 필요하지 않습니다.</block>
  <block id="52fade87431f9acc43b7bf6e4c5fd2f1" category="inline-link">NetApp 클라우드 문서화</block>
  <block id="0c79e4a46253eeb94ba6b8218928aa99" category="list-text">부동 IP 주소는 클러스터 관리 및 데이터 서비스 IP를 포함하여 Cloud Volumes ONTAP가 사용하는 다양한 IP 주소에 대한 액세스를 허용하는 데 사용됩니다. 이러한 주소는 네트워크 내에서 아직 라우팅할 수 없는 주소여야 하며 AWS 환경의 라우팅 테이블에 추가됩니다. 이러한 주소는 페일오버 중에 HA 쌍의 일관된 IP 주소를 지원하는 데 필요합니다. 부동 IP 주소에 대한 자세한 내용은 에서 찾을 수 있습니다<block ref="72cde540b4f97efa19e071f729439801" category="inline-link-rx"></block>.</block>
  <block id="fd4a46ceddfb2402b7e37177af575e04" category="paragraph"><block ref="fd4a46ceddfb2402b7e37177af575e04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ca6b5e9b64aed9132a6be07d061f3b" category="list-text">부동 IP 주소를 추가할 라우팅 테이블을 선택합니다. 이러한 라우팅 테이블은 클라이언트가 Cloud Volumes ONTAP와 통신하는 데 사용됩니다.</block>
  <block id="3453ab81a2f04d5c39ae750fb79ece2a" category="paragraph"><block ref="3453ab81a2f04d5c39ae750fb79ece2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af918e519f9c0db1ed5ab4fd4b6e9e05" category="list-text">ONTAP 루트, 부팅 및 데이터 디스크를 암호화하기 위해 AWS 관리 암호화를 사용할지 AWS KMS를 사용할지 여부를 선택합니다.</block>
  <block id="058eaefa711702bd45c5f6650cf01e4c" category="paragraph"><block ref="058eaefa711702bd45c5f6650cf01e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01bd54fa77587425fca4a6c352309b5c" category="list-text">라이센스 모델을 선택합니다. 선택할 항목을 모르는 경우 NetApp 담당자에게 문의하십시오.</block>
  <block id="e5e49184799594a9fa690c9122eb883e" category="paragraph"><block ref="e5e49184799594a9fa690c9122eb883e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04110b24d1459a6e21e35ad976a8f10e" category="list-text">사용 사례에 가장 적합한 구성을 선택하십시오. 이는 사전 요구 사항 페이지에서 다룬 크기 조정 고려 사항과 관련이 있습니다.</block>
  <block id="e19584159c9c3791a9e3c462cb0aa451" category="paragraph"><block ref="e19584159c9c3791a9e3c462cb0aa451" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ed47788a525c6d08246bfa2f90922da" category="list-text">필요에 따라 볼륨을 생성합니다. 다음 단계에서는 SnapMirror를 사용하고, 이로 인해 볼륨이 생성되므로 필요하지 않습니다.</block>
  <block id="01da9401385484b72ba9c016ac6c19ab" category="paragraph"><block ref="01da9401385484b72ba9c016ac6c19ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76011f95c4e1b3f68fa5829dab0fb786" category="list-text">선택 사항을 검토하고 상자를 선택하여 Cloud Manager가 AWS 환경에 리소스를 구축함을 이해했는지 확인합니다. 준비가 되면 이동 을 클릭합니다.</block>
  <block id="7b78e746aa55ffe6fee1f3e0b65b8cca" category="paragraph"><block ref="7b78e746aa55ffe6fee1f3e0b65b8cca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13b7f009673a469e5482a96832be1473" category="list-text">이제 Cloud Volumes ONTAP가 배포 프로세스를 시작합니다. Cloud Manager는 AWS API 및 클라우드 형성 스택을 사용하여 Cloud Volumes ONTAP를 구축합니다. 그런 다음 시스템을 사양에 맞게 구성하여 즉시 활용할 수 있는 즉시 사용 가능한 시스템을 제공합니다. 이 프로세스의 타이밍은 선택한 항목에 따라 달라집니다.</block>
  <block id="11d15d8a4bb9195b48d5010fa30fa547" category="paragraph"><block ref="11d15d8a4bb9195b48d5010fa30fa547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e63d2329924bb302fb012e7916b3614" category="list-text">타임라인으로 이동하여 진행 상황을 모니터링할 수 있습니다.</block>
  <block id="77405312cc4c1e96d3f7f796e838bf89" category="paragraph"><block ref="77405312cc4c1e96d3f7f796e838bf89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b4df7cc92b3ee31f5d95082a78c7903" category="list-text">타임라인은 Cloud Manager에서 수행된 모든 작업에 대한 감사 역할을 합니다. AWS와 ONTAP 클러스터 모두에 설정하는 동안 Cloud Manager에서 수행하는 모든 API 호출을 볼 수 있습니다. 또한 이 기능을 사용하면 발생하는 모든 문제를 효과적으로 해결할 수 있습니다.</block>
  <block id="8c17e020c76595308d57605fa71dc7af" category="paragraph"><block ref="8c17e020c76595308d57605fa71dc7af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5674ad1910f0a25455fdeb0f3f097a" category="list-text">구축이 완료되면 CVO 클러스터가 현재 용량인 Canvas에 표시됩니다. 현재 상태의 ONTAP 클러스터는 즉시 사용 가능한 진정한 환경을 제공할 수 있도록 완전히 구성되어 있습니다.</block>
  <block id="db044bc640be9fc8227b7ada891f279d" category="paragraph"><block ref="db044bc640be9fc8227b7ada891f279d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28d2e01957d5845ff59688f17bd34339" category="section-title">사내에서 클라우드까지 SnapMirror를 구성합니다</block>
  <block id="081494b1a178710486921a42e2bdfa87" category="paragraph">소스 ONTAP 시스템과 타겟 ONTAP 시스템을 구축했으므로 이제 데이터베이스 데이터가 포함된 볼륨을 클라우드에 복제할 수 있습니다.</block>
  <block id="cb3269c2496a99fb03bebe82b6a3e4bc" category="inline-link">SnapMirror 호환성 매트릭스</block>
  <block id="46aad6288d89ba29f38b4742bf018aca" category="paragraph">SnapMirror용 호환 ONTAP 버전에 대한 지침은 를 참조하십시오<block ref="f75a4f2138bf92eb17ef87cad85a9e34" category="inline-link-rx"></block>.</block>
  <block id="36c5350a8474f2212fecc811eb77df57" category="list-text">소스 ONTAP 시스템(온-프레미스)을 클릭하고 대상을 끌어다 놓고 복제 &gt; 활성화 를 선택하거나 복제 &gt; 메뉴 &gt; 복제 를 선택합니다.</block>
  <block id="5dbe69ec28d70286f46385336e96d003" category="paragraph"><block ref="5dbe69ec28d70286f46385336e96d003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8771a8fdaa9e84a7eef7540edcca5f40" category="paragraph">사용을 선택합니다.</block>
  <block id="ac21962f3f0ae9f9c17b26196452f903" category="paragraph"><block ref="ac21962f3f0ae9f9c17b26196452f903" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a8dc55f6f333187a100f6ed328bdc0" category="paragraph">또는 옵션 을 선택합니다.</block>
  <block id="949fa0a5e194cf44c9e08903cb914566" category="paragraph"><block ref="949fa0a5e194cf44c9e08903cb914566" category="inline-image-macro-rx" type="image"></block></block>
  <block id="066bf779660ad446aa9b0d4021c4bf40" category="paragraph">복제.</block>
  <block id="deafbb4908c633cb93a7f7e76b31da08" category="paragraph"><block ref="deafbb4908c633cb93a7f7e76b31da08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a803b2a55429f981d25fbb8da94aef7" category="list-text">끌어서 놓기를 하지 않은 경우 복제할 대상 클러스터를 선택합니다.</block>
  <block id="630e74180bc1b6c0c0c866d5478ff029" category="paragraph"><block ref="630e74180bc1b6c0c0c866d5478ff029" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761124dc5e0730086556a7d33d43418c" category="list-text">복제할 볼륨을 선택합니다. 데이터와 모든 로그 볼륨을 복제했습니다.</block>
  <block id="7bec2596a51a0d4a808a37dec9e6c540" category="paragraph"><block ref="7bec2596a51a0d4a808a37dec9e6c540" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bde4e8497f5ecaef866c0f049aada776" category="list-text">대상 디스크 유형 및 계층화 정책을 선택합니다. 재해 복구를 위해 디스크 유형으로 SSD를 사용하고 데이터 계층화를 유지하는 것이 좋습니다. 데이터 계층화는 미러링된 데이터를 저비용 오브젝트 스토리지로 계층화하여 로컬 디스크의 비용을 절감합니다. 관계를 끊거나 볼륨을 클론하면 데이터에 빠른 로컬 스토리지가 사용됩니다.</block>
  <block id="a7d9908d0f610b3db167c894d109d1ec" category="paragraph"><block ref="a7d9908d0f610b3db167c894d109d1ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f06f2f09c024b69ef3944a8cd78ad9" category="list-text">대상 볼륨 이름 선택: '[source_volume_name]_dr'을 선택했습니다.</block>
  <block id="6f8ba85bc89d216799431f124e48b25f" category="paragraph"><block ref="6f8ba85bc89d216799431f124e48b25f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2882a0dbc1a6ad74198ac2cb6316870d" category="list-text">복제에 대한 최대 전송 속도를 선택합니다. 따라서 VPN과 같이 클라우드에 대역폭이 낮은 경우 대역폭을 절약할 수 있습니다.</block>
  <block id="041263f562a9058ae414685962469951" category="paragraph"><block ref="041263f562a9058ae414685962469951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f81dd66e0f0847d4cb1d2d12fadcc2f3" category="list-text">복제 정책을 정의합니다. 우리는 미러를 선택했습니다. 이 미러는 최신 데이터 세트를 가져와 타겟 볼륨에 복제합니다. 요구 사항에 따라 다른 정책을 선택할 수도 있습니다.</block>
  <block id="d0b86e2934c870915aaa77674d1d79d7" category="paragraph"><block ref="d0b86e2934c870915aaa77674d1d79d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4db5384e8d04b01ff24a9178b3efaf6a" category="list-text">복제를 트리거할 스케줄을 선택합니다. 요구사항에 따라 변경할 수 있지만 데이터 볼륨에 대한 "일별" 스케줄과 로그 볼륨에 대한 "시간별" 스케줄을 설정하는 것이 좋습니다.</block>
  <block id="c6715d4de4d68a1f8eb9cb8acb63b097" category="paragraph"><block ref="c6715d4de4d68a1f8eb9cb8acb63b097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02e3a269661e3c96a86a075872a1b269" category="list-text">입력한 정보를 검토하고 이동을 클릭하여 클러스터 피어와 SVM 피어를 트리거한 다음(두 클러스터 간에 처음 복제하는 경우) SnapMirror 관계를 구축하고 초기화합니다.</block>
  <block id="75c2d297cd7282b30ce0400170110307" category="paragraph"><block ref="75c2d297cd7282b30ce0400170110307" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c160366cab97ee8f1a35416d1294ddb" category="list-text">데이터 볼륨 및 로그 볼륨에 대해 이 프로세스를 계속합니다.</block>
  <block id="64853c47f4f907262466c1e5ad154c8c" category="list-text">모든 관계를 확인하려면 Cloud Manager 내의 Replication 탭으로 이동합니다. 여기에서 관계를 관리하고 상태를 확인할 수 있습니다.</block>
  <block id="641e620fe8c714d7381775d20a707726" category="paragraph"><block ref="641e620fe8c714d7381775d20a707726" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c88bec52f9e24233a78b6a90efa32ec6" category="list-text">모든 볼륨이 복제된 후에는 안정적 상태가 되며 재해 복구 및 개발/테스트 워크플로우로 이동할 준비가 된 것입니다.</block>
  <block id="86fb3ee49ae2f8c0ee121c551a8f08c2" category="section-title">데이터베이스 워크로드에 EC2 컴퓨팅 인스턴스를 구축합니다</block>
  <block id="91ba52045df2b9244f28270482f749c9" category="inline-link">EC2 인스턴스 유형</block>
  <block id="33aaa72e62140af9cecb2c48f836b84b" category="paragraph">AWS는 다양한 워크로드를 위해 EC2 컴퓨팅 인스턴스를 사전 구성되어 있습니다. 인스턴스 유형 선택에 따라 CPU 코어 수, 메모리 용량, 스토리지 유형 및 용량, 네트워크 성능이 결정됩니다. 사용 사례의 경우, OS 파티션을 제외하고 데이터베이스 워크로드를 실행할 기본 스토리지가 CVO 또는 FSx ONTAP 스토리지 엔진에서 할당됩니다. 따라서 고려해야 할 주요 요소는 CPU 코어, 메모리 및 네트워크 성능 수준을 선택하는 것입니다. 일반적인 AWS EC2 인스턴스 유형은 여기에서 찾을 수 있습니다.<block ref="9334d5b9e602c5921b4f295f6041489b" category="inline-link-rx"></block>.</block>
  <block id="0af43c3d809d6e56a6a7a0d1ed039bbc" category="section-title">컴퓨팅 인스턴스 사이징</block>
  <block id="0b6e77aedd6bd733f979314fef2a98d7" category="list-text">필요한 워크로드를 기준으로 적합한 인스턴스 유형을 선택합니다. 고려해야 할 요소에는 지원할 비즈니스 트랜잭션 수, 동시 사용자 수, 데이터 세트 사이징 등이 포함됩니다.</block>
  <block id="c421d122321bec48d6b30858f4e7b515" category="inline-link">Amazon EC2</block>
  <block id="ed4b68006572e288530a2152f7fbe5fe" category="list-text">EC2 대시보드에서 EC2 인스턴스 구축을 시작할 수 있습니다. 정확한 배포 절차는 이 솔루션의 범위를 벗어납니다. 을 참조하십시오<block ref="3a5862dd365e3998013717e9cf118a9a" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="708991723f71fa1bd7b8081be442552c" category="section-title">Oracle 워크로드를 위한 Linux 인스턴스 구성</block>
  <block id="5c17b7d75ff16063f772234e1ea8eeb1" category="paragraph">이 섹션에는 EC2 Linux 인스턴스를 배포한 이후의 추가 구성 단계가 포함되어 있습니다.</block>
  <block id="39d786446455bb2b3017b793805fc902" category="list-text">SnapCenter 관리 도메인 내에서 이름 확인을 위해 DNS 서버에 Oracle 대기 인스턴스를 추가합니다.</block>
  <block id="385a2a4f5305fe5ce8017f18fb7eabd4" category="list-text">암호 없이 sudo 권한을 가진 SnapCenter OS 자격 증명으로 Linux 관리 사용자 ID를 추가합니다. EC2 인스턴스에서 SSH 암호 인증을 사용하여 ID를 활성화합니다. (기본적으로 EC2 인스턴스에서는 SSH 암호 인증 및 암호 없는 sudo가 해제되어 있습니다.)</block>
  <block id="a2b4677d7a72840a78373c600441681a" category="list-text">OS 패치, Oracle 버전 및 패치 등과 같은 온프레미스 Oracle 설치와 일치하도록 Oracle 설치를 구성합니다.</block>
  <block id="66b65364302a847feb2630bfd7974256" category="inline-link">Oracle 19c 자동화된 구축</block>
  <block id="fa470598a181c1ed905bace243e46aa3" category="list-text">NetApp Ansible DB 자동화 역할을 활용하여 데이터베이스 개발/테스트 및 재해 복구 사용 사례에 맞게 EC2 인스턴스를 구성할 수 있습니다. 자동화 코드는 NetApp 퍼블릭 GitHub 사이트에서 다운로드할 수 있습니다.<block ref="437f8b44ff65600fb5697e9d369a0c54" category="inline-link-rx"></block>. 목표는 사내 OS 및 데이터베이스 구성과 일치하도록 EC2 인스턴스에 데이터베이스 소프트웨어 스택을 설치 및 구성하는 것입니다.</block>
  <block id="97875b4799caf4c948118e7b4776c9fb" category="section-title">SQL Server 작업 부하에 대한 Windows 인스턴스 구성</block>
  <block id="c63751cfdcf8c0b4e26635a47c7f0d97" category="paragraph">이 섹션에는 EC2 Windows 인스턴스를 처음 구축한 이후의 추가 구성 단계가 나와 있습니다.</block>
  <block id="5f44e6a78874f9f49acae3caa71cc14d" category="list-text">RDP를 통해 인스턴스에 로그인하려면 Windows 관리자 암호를 검색합니다.</block>
  <block id="eabafc642b0901afd6622ab0f19d9ef0" category="list-text">Windows 방화벽을 비활성화하고, 호스트를 Windows SnapCenter 도메인에 연결하고, DNS 서버에 인스턴스를 추가하여 이름을 확인합니다.</block>
  <block id="08bf2d7ff3ac9ab37cfa8dc449b3c8da" category="list-text">SnapCenter 로그 볼륨을 프로비저닝하여 SQL Server 로그 파일을 저장합니다.</block>
  <block id="f97ac9d1946c873247af15165559b47a" category="list-text">Windows 호스트에서 iSCSI를 구성하여 볼륨을 마운트하고 디스크 드라이브를 포맷합니다.</block>
  <block id="6c2a9c611f48cae767f6ebea6fca0457" category="inline-link">NetApp 자동화</block>
  <block id="6dea6226167bd38268de4c4d948d72de" category="list-text">SQL Server용 NetApp 자동화 솔루션을 사용하면 이전 작업 중 많은 작업을 자동화할 수 있습니다. 새로 게시된 역할 및 솔루션은 NetApp 자동화 퍼블릭 GitHub 사이트 에서 확인할 수 있습니다.<block ref="8cafb3a3b1222d318fcd262791229701" category="inline-link-rx"></block>.</block>
  <block id="752c08adf364adb2721c9a373759f8f6" category="inline-link-macro">다음: 개발/테스트 환경의 클라우드 용량 증가를 위한 워크플로우</block>
  <block id="4e3fc3c2eb04754fcac9e4e23b6de054" category="paragraph"><block ref="4e3fc3c2eb04754fcac9e4e23b6de054" category="inline-link-macro-rx"></block></block>
  <block id="d0bb28dcc0cc1b523a41bbb46875db9e" category="summary">Cloud Manager 커넥터와 Cloud Volumes ONTAP를 설치하고 SnapMirror를 구성하기 전에 먼저 클라우드 환경에 대한 몇 가지 준비를 수행해야 합니다. 이 페이지에서는 수행해야 하는 작업과 Cloud Volumes ONTAP를 구축할 때의 고려 사항에 대해 설명합니다.</block>
  <block id="8c6fb9ece3bad11d3e76d1344d9ed9ab" category="doc">퍼블릭 클라우드의 사전 요구사항</block>
  <block id="ac7eeb8ecebe00daa1fdf4fd06cc46de" category="inline-link-macro">이전: 사전 요구 사항 온-프레미스.</block>
  <block id="70ba5e430ac8eade85f8e01e51412fe4" category="paragraph"><block ref="70ba5e430ac8eade85f8e01e51412fe4" category="inline-link-macro-rx"></block></block>
  <block id="5a2798d22185b0e40ea502bbbb171d38" category="section-title">Cloud Manager 및 Cloud Volumes ONTAP 구축 사전 요구 사항 체크리스트</block>
  <block id="1e094e6477be231098329b0096c7221f" category="list-text">NetApp Cloud Central 로그인</block>
  <block id="b59e275c4ece2430dff67db92845ab7f" category="list-text">웹 브라우저에서 여러 엔드포인트로 네트워크 액세스</block>
  <block id="d2ed5c7ede8a1ce9d218ec60b0f03935" category="list-text">커넥터의 네트워크 위치입니다</block>
  <block id="0d07862d67097acd517fe27c0de099d7" category="list-text">클라우드 공급자 권한</block>
  <block id="203802866ac2835e79bd76c94a3761c2" category="list-text">개별 서비스를 위한 네트워킹</block>
  <block id="c4d5e1cbdfc47a0fdcb4a1a9dddd9e17" category="inline-link">클라우드 문서</block>
  <block id="1a22a3f7b690b2ec8919c8806633fb26" category="paragraph">시작하는 데 필요한 사항에 대한 자세한 내용은 를 참조하십시오<block ref="247d95fa755d21bb8790cc6d7a2fc412" category="inline-link-rx"></block>.</block>
  <block id="ea61e2c2ff507048203824add1eb7c21" category="section-title">고려 사항</block>
  <block id="176ca67b83510a1281a4cfc749a3543a" category="section-title">Cloud Manager 커넥터란 무엇입니까?</block>
  <block id="1681641037afae45bd6074dcde9eed00" category="paragraph">대부분의 경우 Cloud Central 계정 관리자는 클라우드 또는 온-프레미스 네트워크에 커넥터를 배포해야 합니다. Connector를 사용하면 Cloud Manager에서 퍼블릭 클라우드 환경 내의 리소스 및 프로세스를 관리할 수 있습니다.</block>
  <block id="8a78be5d168f00b24bf1625de3d5409c" category="paragraph">커넥터에 대한 자세한 내용은 를 참조하십시오<block ref="f39c14bbbbdd46ca70a63fb06046c789" category="inline-link-rx"></block>.</block>
  <block id="fcc2bf38b8157a22b5fc6975b7054acc" category="section-title">2.Cloud Volumes ONTAP 사이징 및 아키텍처</block>
  <block id="1c09b5154aa1f43cb9ebcbd6fea5eadc" category="paragraph">Cloud Volumes ONTAP를 배포할 때 미리 정의된 패키지 또는 사용자 고유의 구성 생성 중에서 선택할 수 있습니다. 이러한 값 중 대부분은 중단 없이 변경할 수 있지만, 클라우드에 구축할 워크로드를 기반으로 구축하기 전에 결정해야 할 몇 가지 중요한 사항이 있습니다.</block>
  <block id="331ce28903aee0b30cd3c94e5483edf5" category="inline-link">CVO 사이징 툴</block>
  <block id="acaed5d74e38e1779b3831dcf51c7600" category="paragraph">각 클라우드 공급자마다 구축 옵션이 다르며, 워크로드에 따라 저마다 고유한 속성이 있습니다. NetApp에는 이 있습니다<block ref="6a71e7e42ab9335484c5530029f79b92" category="inline-link-rx"></block> 따라서 용량과 성능을 기준으로 구축 환경을 올바르게 사이징하는 데 도움이 될 수 있지만, 다음과 같은 몇 가지 기본 개념을 기반으로 구축되었습니다.</block>
  <block id="145c90afb7955854f2371e9decf3de9b" category="list-text">필요한 용량</block>
  <block id="f1521b662bf51f1af6c2d38bd610afae" category="list-text">클라우드 가상 머신의 네트워크 기능</block>
  <block id="f75d8ba5edc8017382d5df68baf9e30f" category="list-text">클라우드 스토리지의 성능 특성</block>
  <block id="af9d66ea3132fcfeb46b85557bc1af1b" category="paragraph">핵심은 현재의 용량 및 성능 요구사항을 충족할 뿐만 아니라 향후 성장을 내다보는 구성을 계획하는 것입니다. 이는 일반적으로 용량 여유 공간 및 성능 여유 공간 이라고 합니다.</block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="inline-link">설치하고</block>
  <block id="3a580f142203677f1f0bc30898f63f53" category="inline-link">Azure를 지원합니다</block>
  <block id="c731f72e1d22a7c5e01a7cb789a8885e" category="inline-link">GCP</block>
  <block id="180f0326dff3a03aecf5e184943d108a" category="paragraph">자세한 내용을 보려면 에 대한 계획에 대한 문서를 참조하십시오<block ref="af5d70b69c3436f8bcf6f7b9579c4e83" category="inline-link-rx"></block>,<block ref="c2e85b51d3015b4c720388e64a3de23e" category="inline-link-rx"></block>, 및<block ref="b1068926334a08925797774f64291db4" category="inline-link-rx"></block>.</block>
  <block id="c50ea1f0c6dcf02fbdd39e1e6b5befc2" category="section-title">3.단일 노드 또는 고가용성?</block>
  <block id="eadb13b9c72271dbf16967e78059fea4" category="paragraph">모든 클라우드에서 CVO를 단일 노드 또는 2개의 노드로 구성된 클러스터 고가용성 쌍에 구축할 수 있는 옵션이 있습니다. 사용 사례에 따라 비용 절감을 위해 단일 노드를 구축하거나 추가 가용성과 이중화를 제공하기 위해 HA 쌍을 구축할 수 있습니다.</block>
  <block id="9cbd119b18cd836b6020fcfd3bfbe37f" category="paragraph">DR 사용 사례 또는 개발 및 테스트를 위한 임시 스토리지 회전 시 갑작스러운 조널 또는 인프라 중단의 영향이 더 낮기 때문에 단일 노드가 일반적인 경우가 많습니다. 그러나 모든 운영 사용 사례에서 데이터가 단일 위치에만 있거나 데이터 세트에 더 많은 이중화 및 가용성이 필요할 경우 고가용성을 사용하는 것이 좋습니다.</block>
  <block id="83d2ad0cda1f71c52878284cc7c1f713" category="paragraph">각 클라우드 버전의 고가용성 아키텍처에 대한 자세한 내용은 의 설명서를 참조하십시오<block ref="4344469628657b2a6a0d147e5e6fbc9a" category="inline-link-rx"></block>,<block ref="28a8305eced80cb5b1351f5cffb268ae" category="inline-link-rx"></block> 및<block ref="1b945d178a8347e94e5c5456dc9e6db8" category="inline-link-rx"></block>.</block>
  <block id="f0d106c1997a933ecb53ee88e83670e7" category="inline-link-macro">다음: 시작하기 개요</block>
  <block id="fd43d07d375b44f30fde6995279b9265" category="paragraph"><block ref="fd43d07d375b44f30fde6995279b9265" category="inline-link-macro-rx"></block></block>
  <block id="64899c745691f41e5b1dc01d3a4487d2" category="summary">이 섹션에서는 클라우드에서 SQL Server와 함께 Azure NetApp Files를 사용할 때 고려해야 할 여러 가지 문제에 대해 설명합니다.</block>
  <block id="bb4695a70b92668f0a7927d04580db60" category="doc">고려해야 할 요소</block>
  <block id="4dd91c7652639dacea041fe6033e2627" category="section-title">VM 성능</block>
  <block id="e6ac657ee6eac68b739c5cc437863922" category="inline-link">메모리 최적화</block>
  <block id="68e5d4a238cdfe033afa141123484499" category="paragraph">공용 클라우드에서 관계형 데이터베이스의 성능을 최적화하려면 올바른 VM 크기를 선택하는 것이 중요합니다. 온프레미스 서버 환경의 SQL Server에 적용되는 것과 동일한 데이터베이스 성능 조정 옵션을 계속 사용하는 것이 좋습니다. 사용<block ref="187f54af8632f4f6696d6052e8b74aec" category="inline-link-rx"></block> SQL Server 워크로드에 가장 적합한 성능을 제공하는 VM 크기입니다. 기존 배포의 성능 데이터를 수집하여 올바른 인스턴스를 선택하는 동안 RAM 및 CPU 사용률을 식별합니다. 대부분의 배포는 D, E 또는 M 시리즈 중에서 선택합니다.</block>
  <block id="fcbd19b726fdd6160dfe2ab43f285a55" category="paragraph">* 참고: *</block>
  <block id="8b2db846b8ed65b2919d93a68b819a43" category="list-text">SQL Server 워크로드의 성능을 최적화하려면 메모리에 최적화된 VM 크기를 사용합니다.</block>
  <block id="32a3b4d7b7e6cf1ecde48636119e0288" category="list-text">NetApp과 Microsoft는 적절한 메모리 대 VCORE 비율을 갖는 인스턴스 유형을 선택하기 전에 스토리지 성능 요구 사항을 파악하기를 권장합니다. 또한 VM의 스토리지 처리량 제한을 극복하기 위해 적절한 네트워크 대역폭을 가진 낮은 인스턴스 유형을 선택하는 데도 도움이 됩니다.</block>
  <block id="0abdff1d9e33eca61c14ccafe8012cd5" category="section-title">VM 중복성</block>
  <block id="9fecd525b2d9ad39ac38bbfc4d05ee17" category="inline-link">사용 가능 여부 설정</block>
  <block id="26075dbb6cfad683e0d9bd0d29c570b8" category="inline-link">가용성 영역</block>
  <block id="e936e004eab3eccfc1e7f46a3187dfd1" category="paragraph">중복성과 고가용성을 높이려면 SQL Server VM이 같아야 합니다<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> 또는 다른<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. Azure VM을 생성할 때 가용성 세트 구성과 가용성 영역 중 하나를 선택해야 합니다. Azure VM은 두 영역에 모두 참여할 수 없습니다.</block>
  <block id="05807e454c19f244770adae059b3c330" category="section-title">고가용성</block>
  <block id="94eeeae1e60f97a446e8c4f69d6d6f43" category="paragraph">고가용성을 위해 SQL Server AOAG 또는 FCI(Always On Failover Cluster Instance)를 구성하는 것이 가장 좋습니다. AOAG의 경우 가상 네트워크의 Azure 가상 머신에 있는 SQL Server의 여러 인스턴스가 포함됩니다. 데이터베이스 수준에서 고가용성이 필요한 경우 SQL Server 가용성 그룹을 구성하는 것이 좋습니다.</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">스토리지 구성</block>
  <block id="fa32aac4116ce1980c311f004157a133" category="paragraph">Microsoft SQL Server를 SMB 파일 공유와 함께 스토리지 옵션으로 구축할 수 있습니다. SQL Server 2012, 시스템 데이터베이스(master, model, msdb 또는 tempdb), 사용자 데이터베이스는 SMB(Server Message Block) 파일 서버와 함께 스토리지 옵션으로 설치할 수 있습니다. 이는 SQL Server 독립 실행형 및 SQL Server FCI 모두에 적용됩니다.</block>
  <block id="250548ef00796e6a203215b1d550bb0d" category="admonition">SQL Server 데이터베이스용 파일 공유 스토리지는 지속적인 사용 가능 속성을 지원해야 합니다. 따라서 파일 공유 데이터에 중단 없이 액세스할 수 있습니다.</block>
  <block id="ba110408cece764b57b56f1129b3ba2e" category="inline-link">Azure NetApp Files for SQL Server 구축의 이점</block>
  <block id="45a6af9c92529e3da9ccdbeae9d692ac" category="paragraph">Azure NetApp Files는 까다로운 작업 부하를 모두 충족할 수 있는 고성능 파일 스토리지를 제공하며 블록 스토리지 솔루션과 비교하여 SQL Server TCO를 줄입니다. 블록 스토리지에서 VM은 디스크 작업에 대해 I/O 및 대역폭에 제한을 가했으며 네트워크 대역폭 제한만 Azure NetApp Files에 적용됩니다. 즉, Azure NetApp Files에는 VM 레벨의 I/O 제한이 적용되지 않습니다. 이러한 I/O 제한이 없다면 Azure NetApp Files에 연결된 소규모 VM에서 실행되는 SQL Server는 물론 훨씬 큰 VM에서 실행되는 SQL Server도 수행할 수 있습니다. Azure NetApp Files는 컴퓨팅 및 소프트웨어 라이센싱 비용을 줄여 SQL Server 구축 비용을 절감합니다. SQL Server 배포용으로 Azure NetApp Files를 사용할 때의 비용 분석 및 성능 이점에 대한 자세한 내용은 를 참조하십시오<block ref="458fda910151e8d66385b2aabb6cd60e" category="inline-link-rx"></block>.</block>
  <block id="9d2b7eb8bc76e60b0d9cd237d67a34fb" category="paragraph">SQL Server용 Azure NetApp Files를 사용하면 다음과 같은 이점이 있습니다.</block>
  <block id="8ee22743237d82e9adc18a596977a138" category="list-text">Azure NetApp Files를 사용하면 더 작은 인스턴스를 사용할 수 있으므로 컴퓨팅 비용이 절감됩니다.</block>
  <block id="3de639403ea86ae87a5883d359deb4ab" category="list-text">또한 Azure NetApp Files는 소프트웨어 라이센스 비용을 줄여 전체 TCO를 절감합니다.</block>
  <block id="46790c8fe72176f6262b4b5531482ee5" category="list-text">볼륨에 대한 재구성 및 동적 서비스 수준 기능은 안정적인 워크로드 사이징과 오버 프로비저닝을 방지하여 비용을 최적화합니다.</block>
  <block id="860d93b2ef30525111fa6440bf4d5bd7" category="list-text">중복성과 고가용성을 높이려면 SQL Server VM이 같아야 합니다<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> 또는 다른 방식으로<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. 사용자 정의 데이터 파일이 필요한 경우 파일 경로 요구 사항을 고려합니다. 이 경우 SQL AOAG 대신 SQL FCI를 선택합니다.</block>
  <block id="c6fbfcd868e29e37e88eaeff82a7f430" category="inline-link">ANFSMB-b4ca.anf.test\SQLDB 및\\ANFSMB-b4ca.anf.test\SQLDB\</block>
  <block id="e2bed4e218692d056237b3ae3d24293c" category="list-text">다음 UNC 경로가 지원됩니다.<block ref="cb8cdd6ee3ebeed12086142f1a66cc3e" category="inline-link-rx"></block>.</block>
  <block id="0b4d3828f5dae91cd27e48bffa786d91" category="list-text">루프백 UNC 경로는 지원되지 않습니다.</block>
  <block id="db3d2f4f54b992af225801eb51ea7387" category="list-text">사이징의 경우 사내 환경의 기존 데이터를 사용하십시오. OLTP 워크로드의 경우 디스크 읽기/초 및 디스크 쓰기/초 성능 카운터와 함께 평균 및 최대 사용 시간에 워크로드를 사용하여 성능 요구 사항에 맞는 타겟 IOPS를 제공합니다. 데이터 웨어하우스 및 보고 워크로드의 경우 평균 및 최대 시간에 워크로드를 사용하여 목표 처리량과 디스크 읽기 바이트/초 및 디스크 쓰기 바이트/초를 일치시킵니다 평균 값은 볼륨 재구성 기능과 함께 사용할 수 있습니다.</block>
  <block id="da3259c6aa3dafdc8ca15c687022a5cd" category="section-title">지속적으로 사용 가능한 공유를 생성합니다</block>
  <block id="f7ee3eee4fa679986e37911272d13a29" category="inline-link">지속적으로 사용 가능한 공유 생성</block>
  <block id="de7d92d6f4ac1f140ac05886ec017f09" category="paragraph">Azure Portal 또는 Azure CLI를 통해 지속적으로 사용 가능한 공유를 생성합니다. 포털에서 지속적인 가용성 사용 속성 옵션을 선택합니다. Azure CLI의 경우 '$True'로 설정된 SMB-Continuously-aVL을 사용하여 생성한 az netapfile volume을 사용하여 공유를 지속적으로 사용 가능한 공유로 지정합니다. 지속적인 가용성을 지원하는 새 볼륨을 생성하는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="86e4b436e8054cc83fccec640f98e218" category="inline-link-rx"></block>.</block>
  <block id="9a3932b7bdfdbb892087fd595ec7acb9" category="list-text">다음 이미지와 같이 SMB 볼륨에 대한 지속적인 가용성을 설정합니다.</block>
  <block id="c012fe8c05a3d9875a4f87cee09d1ca9" category="list-text">관리자가 아닌 도메인 계정을 사용하는 경우 계정에 필요한 보안 권한이 할당되었는지 확인합니다.</block>
  <block id="762783478495f0889d01a59db256f92c" category="list-text">공유 수준에서 적절한 사용 권한과 적절한 파일 수준 사용 권한을 설정합니다.</block>
  <block id="bfb74db6a55528f52e8ecb83a507a043" category="inline-link">기존 SMB 볼륨을 무중단 가용성을 사용하도록 변환</block>
  <block id="3cad4a4fcd378074292bfc2ff45fd4ca" category="list-text">기존 SMB 볼륨에서 지속적으로 사용 가능한 속성을 설정할 수 없습니다. 기존 볼륨을 변환하여 지속적으로 사용 가능한 공유를 사용하려면 NetApp Snapshot 기술을 사용하십시오. 자세한 내용은 을 참조하십시오<block ref="25dc0603f84029cfd15a97a37903a54c" category="inline-link-rx"></block>.</block>
  <block id="015dd90c833178044ff327aee63f72ec" category="paragraph"><block ref="015dd90c833178044ff327aee63f72ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">성능</block>
  <block id="ee38206503545cf54ad072dee7f8ab1a" category="paragraph">Azure NetApp Files는 Standard(테라바이트당 16MBps), Premium(테라바이트당 64MBps), Ultra(테라바이트당 128MBps)의 세 가지 서비스 수준을 지원합니다. 데이터베이스 워크로드의 성능을 최적화하려면 적절한 볼륨 크기를 프로비저닝하는 것이 중요합니다. Azure NetApp Files에서는 다음과 같은 요소의 조합을 기반으로 볼륨 성능과 처리량 제한이 있습니다.</block>
  <block id="b87f5218989e854f2889f939a4e2ec06" category="list-text">볼륨이 속한 용량 풀의 서비스 수준입니다</block>
  <block id="9320cce40e9ab4d677bfcc78eddc64d5" category="list-text">볼륨에 할당된 할당량입니다</block>
  <block id="2d98af90367bed299b95066a85be0a17" category="list-text">용량 풀의 서비스 품질(QoS) 유형(자동 또는 수동</block>
  <block id="a6f08c2897faaf4d449d71d87f473ff1" category="inline-link">Azure NetApp Files의 서비스 레벨</block>
  <block id="ac56170d8576092b90989d467f2d383e" category="paragraph">자세한 내용은 을 참조하십시오<block ref="1e8ed0f384e427209ce2e9dfbaed249d" category="inline-link-rx"></block>.</block>
  <block id="79bcc7c0be7625b4b6b95ac8189ec45e" category="paragraph"><block ref="79bcc7c0be7625b4b6b95ac8189ec45e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">성능 검증</block>
  <block id="af3948d0fe6860f3a865cd04abebc009" category="inline-link">SQL Server 저장 벤치마크(SB) 도구</block>
  <block id="01384acc34d886b9383610a7494ca75a" category="paragraph">다른 구현 기능과 마찬가지로 VM 및 스토리지를 테스트하는 것이 중요합니다. 스토리지 검증의 경우 HammerDB, Apploader, 등의 도구가 필요합니다<block ref="df8d6ca8d2831e94c0812b2b971f8958" category="inline-link-rx"></block>또는 적절한 읽기/쓰기 혼합이 있는 사용자 지정 스크립트 또는 FIO를 사용해야 합니다. 그러나 대부분의 SQL Server 워크로드는 OLTP 워크로드가 많을 때에도 80%–90% 읽기, 10%–20% 쓰기에 더 가깝습니다.</block>
  <block id="10fde396dd4a669ec17689dd7cf8b599" category="paragraph">성능을 보여주기 위해 프리미엄 서비스 수준을 사용하여 볼륨에 대해 빠른 테스트를 수행했습니다. 이 테스트에서는 애플리케이션 액세스와 데이터 마이그레이션 없이 볼륨 크기가 100GB에서 2TB로 즉석에서 증가했습니다.</block>
  <block id="6fab14b7b6a90422e865a3b09497edaa" category="paragraph"><block ref="6fab14b7b6a90422e865a3b09497edaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eedfe317eed7692e9d95ba36177a80e9" category="paragraph">이 백서에서 다룬 구축을 위해 HammerDB를 사용하여 실시간 성능 테스트를 수행한 또 다른 예를 살펴보겠습니다. 이 테스트에서는 vCPU 8개, 500GB 프리미엄 SSD, 500GB SMB Azure NetApp Files 볼륨이 포함된 작은 인스턴스를 사용했습니다. HammerDB는 80개의 웨어하우스와 8명의 사용자로 구성되었습니다.</block>
  <block id="c365893719ad3de45f14fa9c19408eca" category="paragraph">다음 차트는 Azure NetApp Files이 비슷한 크기의 볼륨(500GB)을 사용할 때 4배 더 낮은 지연 시간으로 분당 2.6배의 트랜잭션 수를 제공할 수 있음을 보여 줍니다.</block>
  <block id="d50d666921da97fdc14e35f752474e41" category="paragraph">32x vCPU 및 16TB Azure NetApp Files 볼륨으로 더 큰 인스턴스로 크기를 조정하여 추가 테스트를 수행했습니다. 1ms 지연 시간의 일관적 으로 분당 트랜잭션 수가 크게 증가했습니다. HammerDB는 이 테스트를 위해 80개의 웨어하우스와 64명의 사용자로 구성되었습니다.</block>
  <block id="3b38e0407e747349840c72259c5da930" category="paragraph"><block ref="3b38e0407e747349840c72259c5da930" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a39ae09f8be4327fc176cfeb76a0e366" category="section-title">비용 최적화</block>
  <block id="892725223bbd64ebec595545eeaf8c28" category="paragraph">Azure NetApp Files를 사용하면 투명한 볼륨 크기 조정 및 서비스 수준 변경 기능을 다운타임 없이 애플리케이션에 영향을 주지 않습니다. 이 기능은 최대 메트릭으로 데이터베이스 사이징을 수행할 필요가 없는 동적 비용 관리를 가능하게 하는 고유한 기능입니다. 대신, 안정적인 상태의 워크로드를 사용하여 초기 비용을 방지할 수 있습니다. 볼륨 재구성 및 동적 서비스 수준 변경을 통해 데이터 액세스를 유지하면서 I/O를 일시 중지하지 않고 필요 시 Azure NetApp Files 볼륨의 대역폭과 서비스 수준을 거의 즉시 조정할 수 있습니다.</block>
  <block id="44aaafbc17f2a4fcbd6d52e1c8ee0cae" category="paragraph">LogicApp 또는 기능과 같은 Azure PaaS 오퍼링을 사용하면 특정 웹 후크 또는 경고 규칙 트리거를 기반으로 볼륨 크기를 쉽게 조정할 수 있으므로 비용을 동적으로 처리하면서 워크로드 수요를 충족할 수 있습니다.</block>
  <block id="d613d5e1ef7a7f52eed191ef1066a08a" category="paragraph">예를 들어, 안정적인 상태 작업을 위해 250MBps가 필요한 데이터베이스를 예로 들어 보겠습니다. 하지만 이 데이터베이스에는 400Mbps의 피크 처리량도 필요합니다. 이 경우 정상 상태 성능 요구사항을 충족하려면 Premium 서비스 레벨 내에서 4TB 볼륨을 사용하여 구축을 수행해야 합니다. 최대 사용 워크로드를 처리하기 위해 Azure 기능을 사용할 경우 특정 기간 동안 볼륨 크기를 7TB로 늘리고, 볼륨 크기를 줄여 구축이 비용 효율적입니다. 이렇게 구성하면 스토리지의 오버 프로비저닝이 방지됩니다.</block>
  <block id="47373f46adef617d17665b0b94be8f67" category="paragraph">로그 복제 플레이북 예약</block>
  <block id="931ea399c80122517d9eeb617f1594a0" category="list-text">작업 템플릿을 구성하고 시작합니다.</block>
  <block id="2c777d857235f251004d6d8d70c9751d" category="list-text">이전에 생성한 작업 템플릿을 복사합니다.</block>
  <block id="3624b34cb634949984bcb28c79fd327f" category="list-text">리소스 → 템플릿 으로 이동합니다.</block>
  <block id="1eb977b1f69b531db931e9c62c1a0de9" category="list-text">ONTAP/CVO 설정 템플릿을 찾은 후 Copy Template을 마우스 오른쪽 버튼으로 클릭합니다</block>
  <block id="048f2ee27b8617cb0e13b6a0b7da956f" category="list-text">복사된 템플릿에서 템플릿 편집 을 클릭하고 이름을 로그 복제 플레이북 으로 변경합니다.</block>
  <block id="b07fb736e8c17cea7e9e3753e7a67fd1" category="list-text">템플릿에 대해 동일한 재고, 프로젝트, 자격 증명을 유지합니다.</block>
  <block id="d4a86123c8e623e35eaa51ab9583e03b" category="list-text">실행할 플레이북으로 ora_replication_logs.yml을 선택합니다.</block>
  <block id="69fa06239fd734936aac1af5250c7f57" category="list-text">변수는 동일하게 유지되지만 CVO 클러스터 IP는 dst_cluster_ip 변수에 설정되어야 합니다.</block>
  <block id="7557bd62e953fb4d48f07977151ea94f" category="list-text">저장 을 클릭합니다.</block>
  <block id="ec7445bbcbadd1f11fe1bc3e5e56eef9" category="list-text">작업 템플릿을 예약합니다.</block>
  <block id="d6e504930da1d0732ea4162514a38e8e" category="list-text">Log Replication Playbook 템플릿을 클릭한 다음 최상위 옵션 집합에서 Schedules를 클릭합니다.</block>
  <block id="1c03188c731004905466903c2eb763c4" category="list-text">추가, 로그 복제에 대한 이름 스케줄 추가, 시간 시작 시 시작 날짜/시간 선택, 로컬 시간대 선택 및 실행 빈도 를 차례로 클릭합니다. 실행 빈도는 대개 SnapMirror 복제가 업데이트됩니다.</block>
  <block id="d23bfe090a9fd09613c7a6573f619c02" category="admonition">마지막 1시간 단위 업데이트까지 복구할 수 있도록 매 시간마다 업데이트되도록 로그 스케줄을 설정하는 것이 좋습니다.</block>
  <block id="40640c0c34d4427f5d18b9ca476e3158" category="summary">이 페이지에서는 NetApp ONTAP 스토리지에서 Oracle19c의 자동화된 데이터 보호에 대해 설명합니다.</block>
  <block id="6551468cb4811e7add616eea103efea9" category="doc">단계별 배포 절차</block>
  <block id="261e91a1afdfe1123497b1b9ba5ab3e1" category="section-title">AWX/Tower Oracle 데이터 보호</block>
  <block id="32003b051ef9368756d1e9cd79796719" category="section-title">환경의 인벤토리, 그룹, 호스트 및 자격 증명을 생성합니다</block>
  <block id="2c8b94d570dd5a63a27d112e32a1c799" category="paragraph">이 섹션에서는 NetApp 자동화 솔루션을 사용하는 환경을 준비하기 위해 AWX/Ansible 타워에서 인벤토리, 그룹, 호스트, 액세스 자격 증명을 설정하는 방법을 설명합니다.</block>
  <block id="134d501fee5367069f0746f15302ce1f" category="list-text">인벤토리를 구성합니다.</block>
  <block id="af2c7dd4ecef5e42e9bc8f88213d51d9" category="list-text">Resources(리소스) → Inventory(인벤토리) → Add(추가) 로 이동하고 Add Inventory(재고 추가) 를 클릭합니다.</block>
  <block id="56fc26ef1c8ae54dced3529eec65fa26" category="list-text">이름 및 조직 세부 정보를 입력하고 저장 을 클릭합니다.</block>
  <block id="fe0981da08a8d2f4fed2006bafd9fb30" category="list-text">재고 페이지에서 생성된 재고를 클릭합니다.</block>
  <block id="65d119ae335d9e7c9c798b3e6db1b2d0" category="list-text">Groups 하위 메뉴로 이동하여 Add를 클릭합니다.</block>
  <block id="db2b28449b6d868d910cd53527934988" category="list-text">첫 번째 그룹에 대해 Oracle 이름을 입력하고 저장 을 클릭합니다.</block>
  <block id="200e1fa09608b23de5cd04d22d3a5bdb" category="list-text">DR_ORACLE이라는 두 번째 그룹에 대해 이 프로세스를 반복합니다.</block>
  <block id="1e29c17b60e9145858da82263315e402" category="list-text">생성된 Oracle 그룹을 선택하고 Hosts 하위 메뉴로 이동한 다음 Add New Host를 클릭합니다.</block>
  <block id="250d5368537e295251f9ccf63f950087" category="list-text">소스 Oracle 호스트 관리 IP의 IP 주소를 제공하고 Save를 클릭합니다.</block>
  <block id="22dcd973cf7a10ed9d03c5b959e65807" category="list-text">DR_Oracle 그룹에 대해 이 프로세스를 반복하고 DR/대상 Oracle 호스트의 관리 IP/호스트 이름을 추가해야 합니다.</block>
  <block id="1a4eca6a53be80f21117669b80a5dbc8" category="admonition">다음은 ONTAP 온프레미스 또는 AWS의 CVO에 대한 자격 증명 유형 및 자격 증명을 생성하는 지침입니다.</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="open-title">사내</block>
  <block id="c4053f20c3fe50fe899484a64367439e" category="list-text">자격 증명을 구성합니다.</block>
  <block id="50d33cb309a9ea4bacb0a5541498b670" category="list-text">자격 증명 형식을 만듭니다. ONTAP와 관련된 솔루션의 경우 자격 증명 유형을 사용자 이름 및 암호 항목과 일치하도록 구성해야 합니다.</block>
  <block id="c87e3da0a9f8d5eeacea4eac9bef80ea" category="list-text">Administration → Credential Types로 이동한 후 Add를 클릭합니다.</block>
  <block id="e6bf632438290fdf98265b2b18943118" category="list-text">이름과 설명을 입력합니다.</block>
  <block id="5f5a0974b600f86bd4e77595282fcf70" category="list-text">입력 구성에 다음 내용을 붙여 넣습니다.</block>
  <block id="c048e95ab07253cc1cb87bef130c410b" category="list-text">Injector Configuration(주입기 구성)에 다음 내용을 붙여넣고 Save(저장)를 클릭합니다.</block>
  <block id="9302fe5c60a983a24bb8787c00db4862" category="list-text">ONTAP에 대한 자격 증명을 생성합니다</block>
  <block id="41dcc8a8aaaa79a511ba0ab4e6bde225" category="list-text">Resources → Credentials로 이동한 후 Add를 클릭합니다.</block>
  <block id="0a0aab79fb5a20fa5f830947226ef87c" category="list-text">ONTAP 자격 증명에 대한 이름과 조직 세부 정보를 입력합니다</block>
  <block id="81999e930ad44af27e84682c3ea1e750" category="list-text">이전 단계에서 만든 자격 증명 유형을 선택합니다.</block>
  <block id="1546222d368538c25b5704b5fcf160f5" category="list-text">유형 세부 정보 에서 소스 및 대상 클러스터에 대한 사용자 이름 및 암호를 입력합니다.</block>
  <block id="c4be718383c8ca0aa17633d911fc38fd" category="list-text">저장 을 클릭합니다</block>
  <block id="39f6f9fe82cbf0c0970d13b6a043ad84" category="list-text">Oracle에 대한 자격 증명을 생성합니다</block>
  <block id="30d4be106e7fb63befec4c8c7c815ad0" category="list-text">Oracle의 이름 및 조직 세부 정보를 입력합니다</block>
  <block id="9ef3fcc446a5f500717f9b5e9291bce4" category="list-text">시스템 자격 증명 유형을 선택합니다.</block>
  <block id="9fadc5c4eed350a8a1423628227dad59" category="list-text">유형 세부 정보 에서 Oracle 호스트의 사용자 이름 및 암호를 입력합니다.</block>
  <block id="b4ca3125325138b1dbfc309e6bd67b80" category="list-text">올바른 권한 에스컬레이션 방법을 선택하고 사용자 이름과 암호를 입력합니다.</block>
  <block id="61d6c643401e4a602f3c8b4b6fc0a93c" category="list-text">DR_Oracle 호스트에 대해 다른 자격 증명에 대해 필요한 경우 프로세스를 반복합니다.</block>
  <block id="f7fc367b5de87581ac78fc80805439af" category="open-title">CVO</block>
  <block id="61efb6ce79debd57f1e5eb28b08f94ba" category="list-text">자격 증명 유형을 만듭니다. ONTAP와 관련된 솔루션의 경우 자격 증명 유형을 사용자 이름 및 암호 항목과 일치하도록 구성해야 합니다. 또한 Cloud Central 및 AWS에 대한 항목을 추가합니다.</block>
  <block id="b95cd128bfca5d5c9181a46d0392c360" category="list-text">Injector Configuration(주입기 구성)에 다음 내용을 붙여넣고 Save(저장)를 클릭합니다.</block>
  <block id="75f3f97810b5eef177a5355b86dabfd0" category="list-text">ONTAP/CVO/AWS에 대한 자격 증명을 생성합니다</block>
  <block id="68085bee9e04417d4d9e74101a357a22" category="list-text">유형 세부 정보 아래에 소스 및 CVO 클러스터, Cloud Central/Manager, AWS 액세스/비밀 키 및 Cloud Central 업데이트 토큰의 사용자 이름 및 암호를 입력합니다.</block>
  <block id="922922f515b0ac072e20128999512b50" category="list-text">Oracle에 대한 자격 증명 생성(소스)</block>
  <block id="7ebca140d5dcaa006aeda44b19cfc52e" category="list-text">Oracle 호스트의 이름 및 조직 세부 정보를 입력합니다</block>
  <block id="ca530facf78f2112c60ee838d85b9b5b" category="list-text">Oracle Destination에 대한 자격 증명을 생성합니다</block>
  <block id="063e8368b0de123266b00f2c88e317fb" category="list-text">DR Oracle 호스트의 이름 및 조직 세부 정보를 입력합니다</block>
  <block id="0d28c8cc8415971cf2cd02507176bf94" category="list-text">세부 정보 유형 에 사용자 이름(EC2-USER 또는 기본값에서 변경한 경우 해당 입력) 및 SSH 개인 키를 입력합니다</block>
  <block id="cb8f433dfb62a17f7a02f4d7a8839b1c" category="list-text">올바른 권한 에스컬레이션 방법(sudo)을 선택하고 필요한 경우 사용자 이름과 암호를 입력합니다.</block>
  <block id="51b04d83367483575e89740841d94262" category="section-title">프로젝트를 만듭니다</block>
  <block id="e56fa1e2655db1bc7664a00295bd62a2" category="list-text">Resources → Projects로 이동하여 Add를 클릭합니다.</block>
  <block id="9c78f8d8687776e79018ded982e14c25" category="list-text">이름 및 조직 세부 정보를 입력합니다.</block>
  <block id="4096a1870a258e9d46585f08d4906f21" category="list-text">소스 제어 자격 증명 유형 필드에서 Git 를 선택합니다.</block>
  <block id="791ef966f9be349751448b9066bdd8fa" category="list-text">를 입력합니다 <block ref="1881636a0f344e587cc2202e2db4c5ac" category="inline-link-rx"></block> 소스 제어 URL입니다.</block>
  <block id="99bc2ea435ea8ae0ed38ef3051a4350a" category="list-text">소스 코드가 변경되면 프로젝트를 가끔 동기화해야 할 수 있습니다.</block>
  <block id="07ecfe1ec895f624e5c5d082fb961d1c" category="section-title">글로벌 변수를 설정합니다</block>
  <block id="e5cac740ce6bd43e6ff83881e150d0f3" category="paragraph">이 섹션에 정의된 변수는 모든 Oracle 호스트, 데이터베이스 및 ONTAP 클러스터에 적용됩니다.</block>
  <block id="87b55102ec2889891b0258253b739244" category="list-text">다음 임베디드 글로벌 변수 또는 VAR 양식에 환경별 매개 변수를 입력합니다.</block>
  <block id="93be2ec6954884b83ac9df8117967949" category="admonition">파란색 항목은 환경에 맞게 변경해야 합니다.</block>
  <block id="dad1349ef99312028aeda3703d53efdb" category="section-title">자동화 플레이북</block>
  <block id="285a3bb8fb6f692046facadb3c0984cf" category="paragraph">4개의 개별 플레이북을 실행해야 합니다.</block>
  <block id="37472723bc7712fedddee6d02e29228d" category="list-text">온프레미스 또는 CVO 환경 설정을 위한 플레이북</block>
  <block id="5138c89250c5086accf2d1a5961c9b17" category="list-text">Oracle 바이너리 및 데이터베이스 복제를 위한 일정 계획</block>
  <block id="3e552d6e5b2c316c63eb1fc2081d42a8" category="list-text">일정에 따라 Oracle 로그를 복제하는 데 필요한 Playbook</block>
  <block id="33f4f1514dc2ceb963af16685f4de58c" category="list-text">타겟 호스트에서 데이터베이스를 복구하는 플레이북입니다</block>
  <block id="17ae7167fac3c2364c6ad7b58819a920" category="open-title">ONTAP/CVO 설정</block>
  <block id="cc335cb73dc47f7a9b404288e3b4330f" category="paragraph">ONTAP 및 CVO 설정</block>
  <block id="b1171f0b44b8d9b11ac555972ebc8c3b" category="list-text">작업 템플릿을 작성합니다.</block>
  <block id="0fd181172a82ebe5219e9a30e5d97c0d" category="list-text">Resources → Templates → Add로 이동하여 Add Job Template을 클릭합니다.</block>
  <block id="6bc14a28f101e9d80ecc643ef13ef7fb" category="list-text">ONTAP/CVO 설정의 이름을 입력합니다</block>
  <block id="a7244f663b97629084f004e6c89b4a75" category="list-text">작업 유형을 선택합니다. 실행 은 Playbook을 기반으로 시스템을 구성합니다.</block>
  <block id="daefcb84cec2b58089094a64cefb845f" category="list-text">Playbook의 해당 인벤토리, 프로젝트, 플레이북 및 자격 증명을 선택합니다.</block>
  <block id="57344b3bd58c0e451513e303e45d49b7" category="list-text">사내 환경의 경우 ONTAP_setup.yml 플레이북을 선택하고 CVO 인스턴스로 복제할 때 cvo_setup.yml을 선택합니다.</block>
  <block id="ce150ce9cfe145db199958e7cd2ecce0" category="list-text">4단계에서 복사한 글로벌 변수를 YAML 탭의 템플릿 변수 필드에 붙여 넣습니다.</block>
  <block id="31e2568c13fbdaaad088eb3b665dea9d" category="list-text">작업 템플릿을 시작합니다.</block>
  <block id="56ae7378358ba2b1c55c47283f544991" category="list-text">원하는 템플릿을 클릭한 다음 실행을 클릭합니다.</block>
  <block id="41c1d72990c270d0221458749497c3e6" category="admonition">이 템플릿을 사용하여 다른 Playbook에 복사할 것입니다.</block>
  <block id="16f928d0ebd67060f6b3b2abf0481928" category="open-title">바이너리 및 데이터베이스 볼륨의 복제입니다</block>
  <block id="ea490901c403ce2b2a89f80227d0fb90" category="paragraph">바이너리 및 데이터베이스 복제 플레이북 예약</block>
  <block id="3c96e57d33780bedfb652def025f39de" category="list-text">복사된 템플릿에서 템플릿 편집 을 클릭하고 이름을 바이너리 및 데이터베이스 복제 플레이북으로 변경합니다.</block>
  <block id="f42c6e71dcb07b403b8393d5ab7f7fe4" category="list-text">실행할 플레이북으로 ora_replication_cg.yml을 선택합니다.</block>
  <block id="ce0d20e65f0354847807516cbcc696f6" category="list-text">바이너리 및 데이터베이스 복제 플레이북 템플릿을 클릭한 다음, 최상위 옵션 세트에서 일정을 클릭합니다.</block>
  <block id="d9a6405dc4a6cd71f6d77c749070a5e6" category="list-text">추가 를 클릭하고 바이너리 및 데이터베이스 복제에 대한 이름 일정 추가 를 클릭한 다음 시간 시작 시 시작 날짜/시간을 선택하고 로컬 표준 시간대를 선택한 다음 실행 빈도 를 선택합니다. 실행 빈도는 대개 SnapMirror 복제가 업데이트됩니다.</block>
  <block id="2dc4dec75c83aeb010419dc2a02da40b" category="admonition">로그 볼륨 복제에 대해 별도의 일정이 생성되므로 보다 빈번한 케이던스로 복제할 수 있습니다.</block>
  <block id="b723f9a72bec39ac17d89e51ff0ba336" category="open-title">로그 볼륨의 복제입니다</block>
  <block id="f76dbca531ab83300165aacf97e1b7ff" category="open-title">데이터베이스 복원 및 복구</block>
  <block id="8e43fbf8e210fdbb3e1d59ca59cde628" category="list-text">복사된 템플릿에서 템플릿 편집 을 클릭하고 이름을 복원 및 복구 Playbook 으로 변경합니다.</block>
  <block id="42f2159b893bbf4b6bf098ba9a026a1c" category="list-text">실행할 플레이북으로 ora_recovery.yml을 선택합니다.</block>
  <block id="0a3fe9b740fe79971ae2379eaec4822c" category="admonition">이 플레이북은 원격 사이트에서 데이터베이스를 복원할 준비가 될 때까지 실행할 수 없습니다.</block>
  <block id="8cc6746c11a65da30c7d875819acecfe" category="section-title">5.Oracle 데이터베이스 복구 중</block>
  <block id="b8a177e5fd059f33473cad4d1d073d38" category="list-text">사내 운영 Oracle 데이터베이스 데이터 볼륨은 NetApp SnapMirror 복제를 통해 2차 데이터 센터의 이중 ONTAP 클러스터나 퍼블릭 클라우드의 Cloud Volume ONTAP로 보호됩니다. 완전히 구성된 재해 복구 환경에서는 2차 데이터 센터 또는 퍼블릭 클라우드의 복구 컴퓨팅 인스턴스가 대기 상태이며 재해 발생 시 운영 데이터베이스를 복구할 수 있는 준비가 되어 있습니다. 대기 컴퓨팅 인스턴스는 OS 커널 패치에서 parellel 업데이트를 실행하거나 잠금 단계에서 업그레이드를 실행하여 온프레미스 인스턴스와 동기화된 상태를 유지합니다.</block>
  <block id="57d8ad774cb4fef3d53ee8836bfee761" category="list-text">이 솔루션에서 Oracle 바이너리 볼륨은 타겟 인스턴스에 복제되어 타겟 인스턴스에 마운트하여 Oracle 소프트웨어 스택을 실행하는 것으로 나타났습니다. Oracle을 복구하는 이러한 접근 방식은 재해가 발생한 마지막 순간에 Oracle을 새로 설치하는 데 비해 많은 이점을 제공합니다. 이 제품은 Oracle 설치가 현재 온프레미스 프로덕션 소프트웨어 설치 및 패치 수준 등과 완벽하게 동기화되도록 보장합니다. 그러나 소프트웨어 라이센스가 Oracle과 어떻게 구성되어 있는지에 따라 복구 사이트에서 복제된 Oracle 바이너리 볼륨에 대한 소프트웨어 라이센스가 추가로 부여되거나 적용되지 않을 수 있습니다. 사용자는 동일한 접근 방식을 사용하기 전에 소프트웨어 라이센스 담당자에게 잠재적인 Oracle 라이센스 요구 사항을 평가하는 것이 좋습니다.</block>
  <block id="74eaa493ffed695592003e0844d93c46" category="list-text">대상의 대기 Oracle 호스트는 Oracle 필수 구성 요소 구성으로 구성됩니다.</block>
  <block id="0be4357ac224d44b11800179b23eb202" category="list-text">SnapMirror가 손상되고 볼륨이 쓰기 가능으로 만들어져 대기 Oracle 호스트에 마운트됩니다.</block>
  <block id="69504b415e8aad20e18beca0de96ab6a" category="list-text">Oracle 복구 모듈은 모든 DB 볼륨이 대기 컴퓨팅 인스턴스에 마운트된 후 복구 사이트에서 Oracle을 복구 및 시작하는 다음과 같은 작업을 수행합니다.</block>
  <block id="5e52a9563e31960cdf02c7b83e6495e7" category="list-text">제어 파일 동기화: 중요한 데이터베이스 제어 파일을 보호하기 위해 서로 다른 데이터베이스 볼륨에 중복 Oracle 제어 파일을 구축했습니다. 하나는 데이터 볼륨에 있고 다른 하나는 로그 볼륨에 있습니다. 데이터 및 로그 볼륨은 서로 다른 빈도로 복제되므로 복구 시 동기화되지 않습니다.</block>
  <block id="26b9a788a0ef0527f25f68892b364d19" category="list-text">Oracle 바이너리 다시 연결: Oracle 바이너리가 새 호스트로 재배치되므로 재링크가 필요합니다.</block>
  <block id="b66ad18a7982f7c233e9d0af2f867856" category="list-text">Oracle 데이터베이스 복구: 복구 메커니즘은 Oracle 로그 볼륨에서 마지막으로 사용 가능한 아카이브 로그의 마지막 시스템 변경 번호를 제어 파일에서 검색하고 Oracle 데이터베이스를 복구하여 장애 발생 시 DR 사이트에 복제할 수 있는 모든 비즈니스 트랜잭션을 복구합니다. 그런 다음 복구 사이트에서 사용자 연결 및 비즈니스 트랜잭션을 수행할 수 있도록 데이터베이스가 새로 도입되었습니다.</block>
  <block id="861503fb33ea04fecb13449e713e8ac6" category="admonition">복구 플레이북을 실행하기 전에 /etc/oratab 및 /etc/oraInst.loc을 소스 Oracle 호스트에서 대상 호스트로 복제해야 합니다</block>
  <block id="ff9d8653752bd48bb6b73cf97f207af1" category="summary">SnapCenter DR 워크플로우를 사용하는 하이브리드 클라우드 데이터베이스 솔루션</block>
  <block id="ac2e8778240cb518ee14b1defbf55765" category="doc">재해 복구 워크플로우</block>
  <block id="461887ca64f2d60da58c130a00656a96" category="inline-link-macro">이전: 개발/테스트 환경의 클라우드 용량 증가를 위한 워크플로우</block>
  <block id="b8499237e1a42a05b5306219f80b35ba" category="paragraph"><block ref="b8499237e1a42a05b5306219f80b35ba" category="inline-link-macro-rx"></block></block>
  <block id="8e84608bd62584b2f262d60fd734714f" category="paragraph">기업은 퍼블릭 클라우드를 재해 복구를 위한 실행 가능한 리소스와 대상으로 채택하였습니다. SnapCenter는 이 프로세스를 가능한 한 원활하게 만듭니다. 이 재해 복구 워크플로우는 클론 워크플로우와 매우 유사하지만, 가능한 모든 비즈니스 트랜잭션을 복구하기 위해 클라우드에 복제한 마지막 가용 로그를 통해 데이터베이스 복구가 실행됩니다. 그러나 재해 복구와 관련된 추가적인 사전 구성 및 사후 구성 단계가 있습니다.</block>
  <block id="e230d95c57c5534b3e90b93fddbcb1c9" category="section-title">DR을 위해 사내 Oracle 운영 DB를 클라우드에 클론 복제합니다</block>
  <block id="db9517755259859dbae095126c803544" category="list-text">마지막으로 사용 가능한 로그를 통해 클론 복구가 실행되는지 확인하기 위해 작은 테스트 테이블을 만들고 행을 삽입했습니다. 테스트 데이터는 마지막 사용 가능한 로그로 전체 복구 후 복구됩니다.</block>
  <block id="39f00f2f1a95739a075844dcffac1441" category="paragraph"><block ref="39f00f2f1a95739a075844dcffac1441" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fd1337293be82f7472d90bc35f51e90" category="list-text">SnapCenter에 Oracle의 데이터베이스 관리 사용자 ID로 로그인합니다. 리소스 탭으로 이동하여 SnapCenter에서 보호 중인 Oracle 데이터베이스를 표시합니다.</block>
  <block id="1ddb1f7854ac534473544de627fc5289" category="paragraph"><block ref="1ddb1f7854ac534473544de627fc5289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e795ef17ab8e08159909afe558c32a1c" category="list-text">Oracle 로그 리소스 그룹을 선택하고 지금 백업 을 클릭하여 Oracle 로그 백업을 수동으로 실행하여 최신 트랜잭션을 클라우드의 대상으로 플러시합니다. 실제 DR 시나리오에서 복구할 수 있는 마지막 트랜잭션은 클라우드에 대한 데이터베이스 로그 볼륨 복제 빈도에 따라 달라지며, 이 빈도는 회사의 RTO 또는 RPO 정책에 따라 달라집니다.</block>
  <block id="e3ea77c81b6559a6984aee62074951ec" category="paragraph"><block ref="e3ea77c81b6559a6984aee62074951ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44d1c907c1d5302eb896d76cae9b5e7f" category="paragraph"><block ref="44d1c907c1d5302eb896d76cae9b5e7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d77575716b9cd49ab1453e367c405abe" category="admonition">비동기식 SnapMirror는 재해 복구 시나리오에서 데이터베이스 로그 백업 간격의 클라우드 대상으로 하지 않은 데이터를 손실합니다. 데이터 손실을 최소화하기 위해 로그 백업을 더 자주 예약할 수 있습니다. 그러나 기술적으로 달성 가능한 로그 백업 빈도에는 제한이 있습니다.</block>
  <block id="c684c2587fa959f3df40953faab1c1a1" category="list-text">보조 미러 백업에서 마지막 로그 백업을 선택하고 로그 백업을 마운트합니다.</block>
  <block id="4d27921136b62a393650eec8f38c5a39" category="paragraph"><block ref="4d27921136b62a393650eec8f38c5a39" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6784de36878125b88feb4c3192d2aa3d" category="paragraph"><block ref="6784de36878125b88feb4c3192d2aa3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fbfa0a2a63c1090863dedb14664d443c" category="list-text">마지막 전체 데이터베이스 백업을 선택하고 클론 을 클릭하여 클론 워크플로우를 시작합니다.</block>
  <block id="ecafa568fe2f36fee38130d0f80eeafc" category="paragraph"><block ref="ecafa568fe2f36fee38130d0f80eeafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3aa765536eeb5bd55823afbb43c9efdc" category="list-text">호스트에서 고유한 클론 DB ID를 선택합니다.</block>
  <block id="6d4d1ea488e25d46cd7824491f3f98fb" category="paragraph"><block ref="6d4d1ea488e25d46cd7824491f3f98fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d57d235b31b66e982ae6d433fa33948e" category="list-text">로그 볼륨을 프로비저닝하고 Oracle 플래시 복구 영역 및 온라인 로그에 대해 타겟 DR 서버에 마운트합니다.</block>
  <block id="4ef6ef644cc7510226d8d150ce9cfe73" category="paragraph"><block ref="4ef6ef644cc7510226d8d150ce9cfe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d5730b3167534121e5ac4fcdf84cf1f" category="paragraph"><block ref="4d5730b3167534121e5ac4fcdf84cf1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6142419cbd2b279a240db52011ea3cab" category="admonition">Oracle 클론 절차에서는 복제 전에 DR 서버에 프로비저닝해야 하는 로그 볼륨을 생성하지 않습니다.</block>
  <block id="b20da77a777ef0a84d95f447b254387c" category="list-text">타겟 클론 호스트 및 위치를 선택하여 데이터 파일, 제어 파일 및 재실행 로그를 배치합니다.</block>
  <block id="326062662ffdb461c61b5ddfc54974bc" category="paragraph"><block ref="326062662ffdb461c61b5ddfc54974bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b126b14adfdc04f12e6a00531155f4a" category="list-text">클론의 자격 증명을 선택합니다. 대상 서버의 Oracle 홈 구성에 대한 세부 정보를 입력합니다.</block>
  <block id="ee4a9d80953ee6db29e5577ef13327ba" category="paragraph"><block ref="ee4a9d80953ee6db29e5577ef13327ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c76f59dc52686a71eb5917bbcabfa212" category="list-text">클론 생성 전에 실행할 스크립트를 지정합니다. 필요한 경우 데이터베이스 매개 변수를 조정할 수 있습니다.</block>
  <block id="31b131b08153ae34a96d1e17fa891e1f" category="paragraph"><block ref="31b131b08153ae34a96d1e17fa891e1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7018f70f78c5e3154b2620e31167c12e" category="list-text">사용 가능한 모든 아카이브 로그를 통해 복구를 실행하여 보조 클라우드 위치로 복제된 마지막 트랜잭션을 회복하려면 복구 옵션으로 취소 를 선택합니다.</block>
  <block id="57fa7fef5a8266470204775391a701d3" category="paragraph"><block ref="57fa7fef5a8266470204775391a701d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6233d74c8f9820a1029624d60ab66049" category="list-text">필요한 경우 e-메일 알림을 위해 SMTP 서버를 구성합니다.</block>
  <block id="a563132424d4d3d255697521a0446bc9" category="paragraph"><block ref="a563132424d4d3d255697521a0446bc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0cd00abfa258b121d480ce7d27e63" category="list-text">DR 클론 요약</block>
  <block id="0f66818ccf8a8dd3d6491b9bcf74c02e" category="paragraph"><block ref="0f66818ccf8a8dd3d6491b9bcf74c02e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4ff014e6bff5ee06349d607c14fcf9e" category="list-text">클론 생성된 DB는 클론 생성 완료 후 즉시 SnapCenter에 등록되고 백업 보호에 사용할 수 있습니다.</block>
  <block id="18eac7477ab0c6038ec443444677a1eb" category="paragraph"><block ref="18eac7477ab0c6038ec443444677a1eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22d74aee547ad10d104f875521cfa6d7" category="section-title">Oracle에 대한 DR 클론 생성 후 검증 및 구성</block>
  <block id="9d58cce71d4c85948ccecfea105367ed" category="list-text">클라우드의 DR 위치에서 플러시, 복제 및 복구된 마지막 테스트 트랜잭션을 검증합니다.</block>
  <block id="1db3ba1f62cbb82a66232de851bad3ce" category="paragraph"><block ref="1db3ba1f62cbb82a66232de851bad3ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61b3573abc722a493f53ed27503f7eff" category="list-text">플래시 복구 영역을 구성합니다.</block>
  <block id="71ca9fe67f8c3826e171fb227af4f666" category="paragraph"><block ref="71ca9fe67f8c3826e171fb227af4f666" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4005d553f013abc53c6a1a65aed1d65f" category="list-text">사용자 액세스를 위해 Oracle 수신기를 구성합니다.</block>
  <block id="0c79c2a9e4fd1ea908a63d58f1f44917" category="list-text">복제된 볼륨을 복제된 소스 볼륨에서 분리합니다.</block>
  <block id="42e82bb35283d9f2e2b444419f518667" category="list-text">클라우드에서 사내로 역방향 복제를 수행하고 실패한 온프레미스 데이터베이스 서버를 재구성합니다.</block>
  <block id="4ce2420dd00dd0b543e2e51bf7c1c135" category="admonition">클론 분할 시 일반 작업보다 훨씬 높은 임시 스토리지 공간 사용률이 발생할 수 있습니다. 그러나 온프레미스 DB 서버를 재구축한 후에는 추가 공간을 릴리즈할 수 있습니다.</block>
  <block id="0e70133bb418f4025b82a6a35301e209" category="section-title">DR을 위해 사내 SQL 운영 DB를 클라우드에 클론 복제합니다</block>
  <block id="32bfa00a92b9f85d791a43f6d70a35cd" category="list-text">마찬가지로, SQL 클론 복구가 마지막 사용 가능한 로그를 통해 실행되었는지 확인하기 위해 작은 테스트 테이블을 만들고 행을 삽입했습니다. 테스트 데이터는 사용 가능한 마지막 로그로 전체 복구 후 복구됩니다.</block>
  <block id="321bd96e83b00fcd04bfcc72ec4564ff" category="paragraph"><block ref="321bd96e83b00fcd04bfcc72ec4564ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3b7f1fcf93afdd055ec19e230b54347" category="list-text">SQL Server의 데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인합니다. SQL Server 보호 리소스 그룹을 보여 주는 리소스 탭으로 이동합니다.</block>
  <block id="c9673e38d22c239c3b46259620b7b190" category="paragraph"><block ref="c9673e38d22c239c3b46259620b7b190" category="inline-image-macro-rx" type="image"></block></block>
  <block id="608bfa3334f97023b71f6b7a04742bd6" category="list-text">로그 백업을 수동으로 실행하여 퍼블릭 클라우드의 보조 스토리지에 복제할 마지막 트랜잭션을 플러시합니다.</block>
  <block id="94ca8d0daf1445cae1bbc5a13d7b0c42" category="paragraph"><block ref="94ca8d0daf1445cae1bbc5a13d7b0c42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b9ced1d8d8e91eb2606cb7d0932fa4" category="list-text">클론에 대한 마지막 전체 SQL Server 백업을 선택합니다.</block>
  <block id="f93fa51d605a26ef233b6fb9c5489266" category="paragraph"><block ref="f93fa51d605a26ef233b6fb9c5489266" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82efcc579f2220a65dbe5cdd64f47253" category="list-text">클론 서버, 클론 인스턴스, 클론 이름 및 마운트 옵션과 같은 클론 설정을 지정합니다. 클론 생성이 수행되는 보조 스토리지 위치는 자동으로 채워집니다.</block>
  <block id="bb5bdefa03845f9483d1e3fcf8d3b40f" category="paragraph"><block ref="bb5bdefa03845f9483d1e3fcf8d3b40f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d84ecf0ed314694d6e3ad9b2a96a198" category="list-text">적용할 모든 로그 백업을 선택합니다.</block>
  <block id="79284af3915a1bc3e4d4d3993acd9042" category="paragraph"><block ref="79284af3915a1bc3e4d4d3993acd9042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f68fbd76be71ebe267aa207f7bef25f" category="list-text">클론 생성 전후에 실행할 선택적 스크립트를 지정합니다.</block>
  <block id="1f29cf99c49ef1910181e451424c3796" category="paragraph"><block ref="1f29cf99c49ef1910181e451424c3796" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ac43ede08a0b7154673a619b979f17d" category="list-text">e-메일 알림을 원할 경우 SMTP 서버를 지정합니다.</block>
  <block id="e8aa5b543b67c22f0a2a205562794787" category="paragraph"><block ref="e8aa5b543b67c22f0a2a205562794787" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7338d3af995c4a281de85493129cc18" category="list-text">DR 클론 요약 클론 생성된 데이터베이스는 SnapCenter에 즉시 등록되며 백업 보호에 사용할 수 있습니다.</block>
  <block id="332fb27e1cc349fc79252fbfc5de6ad0" category="paragraph"><block ref="332fb27e1cc349fc79252fbfc5de6ad0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8be7490bb89f986a83768e6a71d78ee8" category="paragraph"><block ref="8be7490bb89f986a83768e6a71d78ee8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f01a56e31a650c5bb83408b5238270e" category="section-title">SQL에 대한 DR 클론 생성 후 검증 및 구성</block>
  <block id="029640b7bf09578f05703e407e99b8d7" category="list-text">클론 작업 상태를 모니터링합니다.</block>
  <block id="d5f350d5580b71105a1718557ce88137" category="paragraph"><block ref="d5f350d5580b71105a1718557ce88137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68236fcee9bee8dbdc1c54b7b2d84b34" category="list-text">모든 로그 파일 클론 및 복구를 사용하여 마지막 트랜잭션이 복제 및 복구되었는지 확인합니다.</block>
  <block id="3ebb58ab28579acf2742808bf95fc07e" category="paragraph"><block ref="3ebb58ab28579acf2742808bf95fc07e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50159c53d6f87eb33c314abd9f0bd28f" category="list-text">SQL Server 로그 백업을 위해 DR 서버에 새 SnapCenter 로그 디렉토리를 구성합니다.</block>
  <block id="52320018ddc230fda7bdeccfda8b9f0a" category="section-title">도움을 받을 수 있는 곳</block>
  <block id="2d6962c20ba37b34437afc30e6838e0d" category="inline-link-macro">NetApp Solution Automation 커뮤니티는 Slack 채널을 지원합니다</block>
  <block id="50f8c30e062c542679b96127a844db6a" category="paragraph">이 솔루션 및 사용 사례에 대한 도움이 필요한 경우 에 가입하십시오 <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> 질문 또는 질문을 게시할 수 있는 솔루션 자동화 채널을 찾아보십시오.</block>
  <block id="d83342bb55cac062a4841a3b7a62a7fd" category="summary">이 섹션에서는 이전 섹션에서 설명한 사전 요구 사항을 충족하기 위해 완료해야 하는 작업을 요약합니다. 다음 섹션에서는 사내 및 퍼블릭 클라우드 운영에 모두 필요한 개략적인 작업 목록을 제공합니다. 자세한 프로세스와 절차는 관련 링크를 클릭하여 액세스할 수 있습니다.</block>
  <block id="21475c5fe4cf73cfbf7756ed71e43375" category="doc">시작 개요</block>
  <block id="fa952e93a2f3bc19270cbedd1510f523" category="inline-link-macro">이전: 퍼블릭 클라우드의 사전 요구 사항</block>
  <block id="f50eb88fd106752cf99e25d4a7259bb7" category="paragraph"><block ref="f50eb88fd106752cf99e25d4a7259bb7" category="inline-link-macro-rx"></block></block>
  <block id="f0e69ccbb7ad96f546f7924206944bfa" category="section-title">온프레미스</block>
  <block id="b2e7ae8381268c9d97dc3576aa67da04" category="list-text">SnapCenter에서 데이터베이스 관리자 사용자를 설정합니다</block>
  <block id="e1c4efcd7b5b155c8a6e57d348b6c071" category="list-text">SnapCenter 플러그인 설치 필수 구성 요소</block>
  <block id="cf69df8da81eda7b468d606f3e9aff06" category="list-text">SnapCenter 호스트 플러그인 설치</block>
  <block id="2a6faa57bc6cc0f7a4c90cebd5e63344" category="list-text">DB 리소스 검색</block>
  <block id="2a36af746a3cc41f6964edac717b5206" category="list-text">스토리지 클러스터 피어링 및 DB 볼륨 복제를 설정합니다</block>
  <block id="a227a5da83d0a04e6e8e7e76a89eba09" category="list-text">SnapCenter에 CVO 데이터베이스 스토리지 SVM 추가</block>
  <block id="c615eed91e2ab578525394d0ff0138d9" category="list-text">SnapCenter에서 데이터베이스 백업 정책을 설정합니다</block>
  <block id="8ecb914dad4186dafb38268be6fc8a1f" category="list-text">백업 정책을 구현하여 데이터베이스를 보호합니다</block>
  <block id="3041fe5faf49efefd030e278790b4faf" category="list-text">백업을 검증합니다</block>
  <block id="0bcf61b20ebca1ef90cb7982284867a6" category="list-text">사전 항공편 확인</block>
  <block id="c27b238e54d27696cafed4684c6f1335" category="list-text">AWS에서 Cloud Manager 및 Cloud Volumes ONTAP를 구축하는 단계</block>
  <block id="2bb50575568fc6429e2c1cef751d40f4" category="list-text">데이터베이스 워크로드를 위한 EC2 컴퓨팅 인스턴스 구축</block>
  <block id="bc2dcb446bec0ecd131a2e612dbd1ecd" category="paragraph">자세한 내용을 보려면 다음 링크를 클릭하십시오.</block>
  <block id="7146594a919f2b006b1b0911c7b6d7da" category="inline-link-macro">온프레미스</block>
  <block id="21aa279d0a145dcaab5feaa02df2c02a" category="inline-link-macro">퍼블릭 클라우드 - AWS</block>
  <block id="fd0476c0c92270df2d75402a67cfe0f4" category="paragraph"><block ref="8f0e2d08c6bad9ef491c2061921b9d90" category="inline-link-macro-rx"></block>, <block ref="11145243f1982fd305768240bff5daad" category="inline-link-macro-rx"></block></block>
  <block id="d4c96dcd516adf0c5bde093b0b7b7255" category="summary">이 페이지에서는 NetApp ONTAP 스토리지에 Oracle19c를 구축하는 자동화된 방법에 대해 설명합니다.</block>
  <block id="0e6b1c16527d2792d391c578bbf12efe" category="section-title">CLI 구축 Oracle 19c Database</block>
  <block id="57daddd847cdbab22b7363630de48a2f" category="inline-link-macro">시작하기 및 요구 사항 섹션을 참조하십시오</block>
  <block id="82ba94e85d91493ea6c88423c0b34605" category="paragraph">이 섹션에서는 CLI를 사용하여 Oracle19c 데이터베이스를 준비하고 배포하는 데 필요한 단계를 설명합니다. 을(를) 검토했는지 확인합니다 <block ref="598ea103507880273a5a1840cac102d8" category="inline-link-macro-rx"></block> 적절히 대비했습니다.</block>
  <block id="0f2d7675188dbfc7b9df587588bff71b" category="section-title">Oracle19c repo 를 다운로드합니다</block>
  <block id="4e2b619426350db7e7d5b09c96b8010b" category="section-title">HOSTS 파일을 편집합니다</block>
  <block id="b183e47af1fa85c93e4a4368205c3249" category="paragraph">배포 전에 다음을 완료합니다.</block>
  <block id="c4ab1530ffd8a3306d47c804ca88240c" category="list-text">호스트 파일 na_oracle19c_deploy 디렉토리를 편집합니다.</block>
  <block id="bc1dd0e50a3c20e78cc2d680eaf32378" category="list-text">[ONTAP] 아래에서 IP 주소를 클러스터 관리 IP로 변경합니다.</block>
  <block id="6475f51ce7ff0a21a5635ea50b1f1a86" category="list-text">[Oracle] 그룹에서 Oracle 호스트 이름을 추가합니다. 호스트 이름은 DNS 또는 호스트 파일을 통해 IP 주소로 확인되거나 호스트에 지정되어야 합니다.</block>
  <block id="5c3f5e9dc815ca28c7cf1ff64cdc61a2" category="list-text">이 단계를 완료한 후 변경 사항을 저장합니다.</block>
  <block id="b27994a7bba852ac9a8f1a262413e68b" category="paragraph">다음 예에서는 호스트 파일을 보여 줍니다.</block>
  <block id="1caa2eee0ed6a6c5c6edcbc0320e8671" category="paragraph">이 예에서는 Playbook을 실행하고 두 개의 Oracle DB 서버에 동시에 Oracle 19c를 구축합니다. 하나의 DB 서버만으로 테스트할 수도 있습니다. 이 경우 하나의 호스트 변수 파일만 구성하면 됩니다.</block>
  <block id="d11927d6f93a4edaa78dc52c6e34fd5f" category="admonition">이 플레이북은 구축하는 Oracle 호스트 및 데이터베이스의 수에 관계없이 동일한 방식으로 실행됩니다.</block>
  <block id="030c98564d5fbd7c8672a76e2a593b21" category="section-title">host_name.yml 파일을 host_vars에서 편집합니다</block>
  <block id="86c40bb4891f3e6b34a2eece7bb19532" category="paragraph">각 Oracle 호스트에는 호스트별 변수를 포함하는 호스트 이름으로 식별되는 호스트 변수 파일이 있습니다. 호스트 이름을 지정할 수 있습니다. Host VAR Config 섹션에서 host_vars를 편집 및 복사하고 원하는 host_name.yml 파일에 붙여 넣습니다.</block>
  <block id="5bbe8264b4d6c6787657c66d4017c183" category="section-title">호스트 VAR 구성</block>
  <block id="44505c1007599884b05c0148599ad1b0" category="section-title">VAR.yml 파일을 편집합니다</block>
  <block id="41cdd95196e2753968e0d69375c41825" category="paragraph">VAR.yml 파일은 Oracle 구축을 위해 모든 환경 관련 변수(ONTAP, Linux 또는 Oracle)를 통합합니다.</block>
  <block id="271f9ccf9c8189bb1888d25c7f0e025b" category="list-text">VAR 섹션에서 변수를 편집 및 복사하고 해당 변수를 'VAR.yml' 파일에 붙여 넣습니다.</block>
  <block id="d0db3f5a4a306cff20be4187b3ef3445" category="section-title">VAR</block>
  <block id="78d77851709e21512097cee585c59d0c" category="section-title">플레이북을 실행합니다</block>
  <block id="8f42d9f703ada5b4f1374ca96a4f1cec" category="paragraph">필요한 환경 전제 조건을 완료하고 변수를 VAR.yml과 your_host.yml에 복사하면 이제 Playbook을 배포할 준비가 된 것입니다.</block>
  <block id="6226590ec5d4a109e4b93317425994c1" category="admonition">사용자 환경과 일치하도록 &lt;username&gt;을(를) 변경해야 합니다.</block>
  <block id="24b2767982b51deb19947fb3e94279c6" category="section-title">동일한 Oracle 호스트에 추가 데이터베이스를 구축합니다</block>
  <block id="5cc75d1029461de7ddcd02bbc784af26" category="paragraph">플레이북의 Oracle 부분은 실행 당 Oracle 서버에 단일 Oracle 컨테이너 데이터베이스를 생성합니다. 동일한 서버에 추가 컨테이너 데이터베이스를 만들려면 다음 단계를 수행하십시오.</block>
  <block id="b4a35a2d5c3a4f3efb7c77f6bcd2a905" category="list-text">host_vars 변수를 수정합니다.</block>
  <block id="5641cb71d4e10abef15918c2dd828917" category="list-text">3단계로 돌아가기 - host_vars에서 host_name.yml 파일을 편집합니다.</block>
  <block id="ffcc6e6df9c3839334c063a9223c65b3" category="list-text">Oracle SID를 다른 명명 문자열로 변경합니다.</block>
  <block id="a936a5fabc881eb3591658385409dfb8" category="list-text">수신기 포트를 다른 번호로 변경합니다.</block>
  <block id="24f0029973c35b16fc49847b27215915" category="list-text">EM Express를 설치한 경우 EM Express 포트를 다른 번호로 변경하십시오.</block>
  <block id="365c64de6adc281d7f484029d1356855" category="list-text">수정된 호스트 변수를 복사하여 'host_vars' 아래의 Oracle 호스트 변수 파일에 붙여넣습니다.</block>
  <block id="b64219fd8290ac8a154f733df0825dbb" category="list-text">위의 에 나와 있는 것처럼 "ORACLE_config" 태그를 사용하여 플레이북을 실행합니다 <block ref="1c892654e23ff69bf71caefc702aa8b4" category="inline-xref-macro-rx"></block>.</block>
  <block id="0dd197c8abd1f3c3607887dbc615148f" category="section-title">Oracle 설치를 검증합니다</block>
  <block id="f673434da0f39c1b4366cbc45f67da8a" category="admonition">설치가 예상대로 완료되고 Oracle DB가 시작되면 Oracle 프로세스가 나열됩니다</block>
  <block id="91bcd024d07cb33293902b287b0cc68c" category="paragraph">[oracle@localhost~]$sqlplus/as sysdba</block>
  <block id="b95bce10ef504692a6d971d3a30ac8c4" category="paragraph">SQL* Plus: 릴리스 19.0.0.0.0 - 5월 6일 목요일 프로덕션 12:52:51 2021년 버전 19.8.0.0.0</block>
  <block id="a2494ba30f29d91ff6876152fc693ab3" category="paragraph">Copyright (c) 1982, 2019, Oracle. 모든 권리 보유.</block>
  <block id="ce8b3f5af3f95d98bbbf478e4c37024f" category="paragraph">연결 대상: Oracle Database 19c Enterprise Edition 릴리스 19.0.0.0.0 - 프로덕션 버전 19.8.0.0.0</block>
  <block id="28a359e505158300600d776ae9347cac" category="paragraph">sql&gt; 을 클릭합니다</block>
  <block id="63102463594ac5bd274343651065779d" category="paragraph">sql&gt; v$database에서 이름, log_mode 선택; name log_mode--------- ---------- CDB2 ARCHIVELOG</block>
  <block id="7d8bf5a6b847068ff3c0eb0ca0892acf" category="paragraph">sql &gt; PDB 표시</block>
  <block id="33c7676f0bdcf42bed62c146feaf485c" category="paragraph">sql&gt; col svrname form a30 sql&gt; col dirname form a30 sql&gt; v$dnfs_servers에서 svrname, dirname, nfsversion을 선택합니다.</block>
  <block id="d6bee2dc52f5708cd8af49c1c263c714" category="paragraph">SVRNAME dirname NFSVERSION------------------------------------------------------------ ------------------------------------------------------------ --------------- 172.21.126.200/rhelora03_u02 NFSv3.0 172.21.126.200/rhelora03_uNFSv03 3.0 172.21.126.200/rhelora03_u01 NFSv3.0</block>
  <block id="ea12870da72347cdd45bc11ae4d603dc" category="paragraph">[Oracle@localhost~]$sqlplus system@//localhost:1523/cdb2_pdb1.cie.netapp.com</block>
  <block id="aff680efe40afd832819af131e324051" category="paragraph">SQL* Plus: 릴리스 19.0.0.0.0 - 5월 6일 13:19:57 2021년 11월 19일 버전 19.8.0.0.0의 목요일 프로덕션</block>
  <block id="6c3d252188792733323cf879b5d196cf" category="paragraph">비밀번호 입력: 마지막으로 성공한 로그인 시간: 2021년 5월 5일 17:11:11-04:00</block>
  <block id="531fea2bb939d7c35cad66fde1640511" category="paragraph">sql&gt; show user is "system" sql&gt; show con_name con_name CDB2_PDB1</block>
  <block id="1b6a5f8b328d3175066895d7ff5ea576" category="inline-link-macro">NetApp 솔루션 자동화 커뮤니티는 여유 채널을 지원합니다</block>
  <block id="12f178498803c606c23e7166dcefb0cb" category="paragraph">툴킷에 대한 도움이 필요한 경우 에 가입하십시오 <block ref="f1bb21e2ce6888d898ae31a2098245a1" category="inline-link-macro-rx"></block> 질문 또는 질문을 게시할 수 있는 솔루션 자동화 채널을 찾아보십시오.</block>
  <block id="75b7d47e2aa19968e092ab7ddb108a3f" category="summary">확장 데이터베이스가 있는 All-Cloud 또는 하이브리드 클라우드를 타겟팅하는 경우 모두 Azure NetApp Files는 애플리케이션 계층에 데이터 요구사항을 원활하게 구현하여 TCO를 절감하는 동시에 데이터베이스 워크로드를 구축 및 관리할 수 있는 탁월한 옵션을 제공합니다.</block>
  <block id="d8d2e6021f496c4e4a31a3d5d51c0a97" category="paragraph">이 문서에서는 Azure NetApp Files를 사용하여 Microsoft SQL Server 배포를 계획, 설계, 최적화 및 확장하는 권장 사항에 대해 설명합니다. 이러한 권장 사항은 구현에 따라 크게 다를 수 있습니다. 올바른 솔루션은 구현의 기술 세부사항과 프로젝트의 원동력이 되는 비즈니스 요구 사항 둘 다에 따라 달라집니다.</block>
  <block id="56925354251a536c23de1174d3001595" category="section-title">이점</block>
  <block id="033e6e43f2148e187e072dc7e6585802" category="paragraph">이 문서의 핵심 사항은 다음과 같습니다.</block>
  <block id="b2b363e230905b04f6e9c7263aa93f42" category="list-text">이제 Azure NetApp Files를 사용하여 SQL Server 클러스터에 대한 데이터베이스 및 파일 공유 증인을 호스팅할 수 있습니다.</block>
  <block id="4d6ec76303888bc681d543d1f4593c55" category="list-text">필요 시 언제 어디서나 SQL Server 데이터에 액세스할 수 있도록 애플리케이션 응답 시간을 높이고 99.9999%의 가용성을 제공할 수 있습니다.</block>
  <block id="408e4b7fbec4ba85e097b9393d2b27a7" category="list-text">SQL Server 배포 및 지속적인 관리(예: RAID 스트라이핑)의 전반적인 복잡성을 간단하고 즉각적으로 조정할 수 있습니다.</block>
  <block id="41642b38214243168d907d92759dde36" category="list-text">지능형 운영 기능을 사용하면 SQL Server 데이터베이스를 몇 분 내에 구축하고 개발 주기를 단축할 수 있습니다.</block>
  <block id="61a32d891a5f7bca599a014bc56eec61" category="list-text">Azure 클라우드가 그 목적이라면, Azure NetApp Files는 최적의 구축을 위한 최적의 스토리지 솔루션입니다.</block>
  <block id="a2810b66f557bf43f1c602ecfe7f52b1" category="summary">이 문서에서는 Azure 가상 시스템을 활용하는 Azure NetApp Files의 AOAG(SQL Server Always On Availability Group)를 실시간으로 구축하는 방법에 대해 설명합니다.</block>
  <block id="0ecccb1d48727b6da357728efe7b6375" category="doc">TR-4897: Azure NetApp Files 기반 SQL Server - 실제 배포 보기</block>
  <block id="4eae423bbc6520b4a8fa4d0d4de28b8a" category="paragraph">Niyaz Mohamed, NetApp</block>
  <block id="8ae2b9aab28b6c00df7581f99f9211ef" category="paragraph">IT 조직은 끊임없이 변화합니다. Gartner에 따르면 모든 데이터베이스의 약 75%가 2022년까지 클라우드 기반 스토리지를 필요로 할 것이라고 합니다. 선도적인 RDBMS(관계형 데이터베이스 관리 시스템)인 Microsoft SQL Server는 ERP(전사적 자원 관리)에서 분석, 콘텐츠 관리에 이르기까지 SQL Server를 사용하는 Windows 플랫폼 설계 응용 프로그램 및 조직에 적합합니다. SQL Server는 기업이 대규모 데이터 집합을 관리하는 방식을 혁신시키고 스키마 및 쿼리 성능 요구를 충족하도록 응용 프로그램에 전력을 공급하는 데 도움을 주었습니다.</block>
  <block id="eae371fd2d593d80849fab02c4e8b90b" category="paragraph">대부분의 IT 조직은 클라우드 우선 방식을 따릅니다. 전환 단계의 고객은 현재 IT 환경을 평가한 다음 평가 및 검색 결과를 기반으로 데이터베이스 워크로드를 클라우드로 마이그레이션합니다. 고객의 클라우드 마이그레이션 방향을 결정하는 요인에는 탄력성/버스트, 데이터 센터 이탈, 데이터 센터 통합, 수명 종료 시나리오, 인수 합병, 인수 합병 등 마이그레이션 이유는 각 조직과 각 조직의 비즈니스 우선 순위에 따라 달라질 수 있습니다. 클라우드로 이동할 때 SQL Server 데이터베이스 클라우드 구현의 잠재력을 최대한 활용하려면 적절한 클라우드 스토리지를 선택하는 것이 매우 중요합니다.</block>
  <block id="f9468c81b3d59ac0030570c4f58e95f1" category="section-title">사용 사례</block>
  <block id="cf8b0bda1e058c1f8383f434c4da9b71" category="paragraph">SQL Server 자산을 Azure로 이전하고 Azure Data Factory, Azure IoT Hub 및 Azure Machine Learning과 같은 Azure의 광범위한 PaaS(서비스로서의 플랫폼) 기능과 SQL Server를 통합하면 디지털 혁신을 지원하는 엄청난 비즈니스 가치를 창출할 수 있습니다. 또한 클라우드를 채택하면 각 사업부에서 자본 지출 모델 또는 기존 프라이빗 클라우드 모델을 사용할 때보다 생산성 및 새로운 기능/개선 기능(DevTest 사용 사례)을 더 빠르게 제공할 수 있습니다. 이 문서에서는 Azure 가상 시스템을 활용하는 Azure NetApp Files의 AOAG(SQL Server Always On Availability Group)를 실시간으로 구축하는 방법에 대해 설명합니다.</block>
  <block id="239a02aaaf9289a3093f682835f65f88" category="paragraph">Azure NetApp Files는 지속적으로 사용 가능한 파일 공유를 지원하는 엔터프라이즈급 스토리지를 제공합니다. 지속적으로 사용 가능한 공유는 SMB 파일 공유에서 SQL Server 운영 데이터베이스에 의해 요구되며, 컨트롤러 업그레이드 또는 장애와 같은 운영 중단 시나리오를 포함하여 노드에서 항상 데이터베이스 스토리지에 액세스할 수 있도록 합니다. 지속적으로 사용 가능한 파일 공유를 사용하면 스토리지 노드 간에 데이터를 복제할 필요가 없습니다. Azure NetApp Files은 SMB 3.0 스케일아웃, 영구 핸들 및 투명한 페일오버를 사용하여 다양한 관리 작업을 포함한 계획된 다운타임과 계획되지 않은 다운타임 이벤트에 대한 무중단 운영(NDO)을 지원합니다.</block>
  <block id="f47a858d79de9725a0d6881541748e9b" category="paragraph">클라우드 마이그레이션을 계획할 때는 항상 가장 적합한 사용 방법을 평가해야 합니다. 애플리케이션 마이그레이션에 가장 일반적이고 가장 쉬운 접근 방식은 재호스팅(리프트 및 변속이라고도 함)입니다. 이 문서에 제공된 예제 시나리오에서는 재호스팅 메서드를 사용합니다. Azure NetApp Files가 설치된 Azure 가상 시스템의 SQL Server를 사용하면 온프레미스 하드웨어를 관리할 필요 없이 클라우드에서 전체 버전의 SQL Server를 사용할 수 있습니다. 또한 SQL Server VM(가상 머신)은 사용한 만큼만 비용을 지불하면 라이센스 비용을 절감할 수 있으며 개발, 테스트 및 부동산 갱신 시나리오에 대한 탄력성과 버스팅 기능을 제공합니다.</block>
  <block id="4db58285a0e634acd6843c40f7a6f4e0" category="paragraph">이 문서에 설명된 정보에 대한 자세한 내용은 다음 웹 사이트 링크를 참조하십시오.</block>
  <block id="d53a72004974ee8431ee292856c0bba3" category="list-text">Azure NetApp Files를 사용하는 솔루션 아키텍처</block>
  <block id="653ba0610595f0695c3ceb2c59afed59" category="inline-link"><block ref="653ba0610595f0695c3ceb2c59afed59" category="inline-link-rx"></block></block>
  <block id="d5ec9321fb49816034de6b296ef6baa2" category="paragraph"><block ref="d5ec9321fb49816034de6b296ef6baa2" category="inline-link-rx"></block></block>
  <block id="62b5dbc436fc2540c46476bd8e484c11" category="inline-link"><block ref="62b5dbc436fc2540c46476bd8e484c11" category="inline-link-rx"></block></block>
  <block id="44594562b4f528fe8d864bd3f48ddff6" category="paragraph"><block ref="44594562b4f528fe8d864bd3f48ddff6" category="inline-link-rx"></block></block>
  <block id="7aa91f5f0414f1488ce2f5324e63d12e" category="list-text">Azure NetApp Files를 사용한 Azure 기반 SQL Server 배포 가이드</block>
  <block id="9021ea474df74856b145a78c58c35e05" category="inline-link"><block ref="9021ea474df74856b145a78c58c35e05" category="inline-link-rx"></block></block>
  <block id="52a5313d9aca117b5d167e6be79c5bc7" category="paragraph"><block ref="52a5313d9aca117b5d167e6be79c5bc7" category="inline-link-rx"></block></block>
  <block id="49217b0d4a68c88899c93d24203a34b4" category="list-text">Azure NetApp Files의 내결함성, 고가용성 및 복구 기능</block>
  <block id="9e5e063336d276080a054861016aadd8" category="inline-link"><block ref="9e5e063336d276080a054861016aadd8" category="inline-link-rx"></block></block>
  <block id="7ff89d0ad939652d37cbab9b6f420f65" category="paragraph"><block ref="7ff89d0ad939652d37cbab9b6f420f65" category="inline-link-rx"></block></block>
  <block id="0679a51ae3a4071a6bd3dedbe97fd329" category="summary">이 페이지에서는 NetApp ONTAP 스토리지에 Oracle 데이터 보호를 구축하는 자동화된 방법에 대해 설명합니다.</block>
  <block id="cb59b87e00d11222bfd9159d0d23836f" category="doc">시작하기</block>
  <block id="22e3bbd761fbb7ae69b8035eb12f222d" category="paragraph">이 솔루션은 AWX/Tower 환경에서 실행되도록 설계되었습니다.</block>
  <block id="008ba800d97cb969def651e93f0d93fb" category="section-title">AWX/타워</block>
  <block id="a481f1841043d60245f18522a86731b1" category="paragraph">AWX/Tower 환경의 경우 ONTAP 클러스터 관리 및 Oracle 서버(IP 및 호스트 이름)의 인벤토리 생성, 자격 증명 생성, NetApp Automation GitHub에서 Ansible 코드를 가져오는 프로젝트 구성, 자동화를 시작하는 작업 템플릿 등이 있습니다.</block>
  <block id="ad5310e9dcd8f367be2b92490488d86d" category="list-text">이 솔루션은 프라이빗 클라우드 시나리오(사내-사내), 하이브리드 클라우드(사내-퍼블릭 클라우드 간 Cloud Volumes ONTAP[CVO])에서 실행되도록 설계되었습니다.</block>
  <block id="5055de7b9d28f88e537f99f34959c80c" category="list-text">사용자 환경에 맞는 변수를 입력하고 이를 복사하여 작업 템플릿의 추가 VAR 필드에 붙여 넣습니다.</block>
  <block id="d116f375db402ba471f519c0a4df15dc" category="list-text">추가 VAR이 작업 템플릿에 추가되면 자동화를 시작할 수 있습니다.</block>
  <block id="4d0c05180ba83e5c8a9bbac094c365e2" category="list-text">자동화는 3단계(설정, Oracle 바이너리, 데이터베이스, 로그 및 로그용 복제 일정)와 DR 사이트에서 데이터베이스를 복구하기 위한 4단계로 구성됩니다.</block>
  <block id="936c99ed52ca08a052ebf611285dd998" category="inline-link-macro">CVO 및 Connector 구축을 위한 사전 요구 사항을 수집합니다</block>
  <block id="ec329a9106131eb9bf99b0f9e67b0564" category="list-text">CVO 데이터 보호에 필요한 키 및 토큰을 얻기 위한 자세한 지침은 을 참조하십시오 <block ref="e21f73de51752f791cddc773d1f38740" category="inline-link-macro-rx"></block></block>
  <block id="13716f12996b882bb4c7e0bd84c7c128" category="open-title">strong class="big"&gt;온프레미스&lt;/strong&gt;&lt;strong&gt;|&lt;/strong&gt;</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">방법입니다</block>
  <block id="9d5cfca4ad04b54536e5ad15210f7dc2" category="cell">* Ansible 환경 *</block>
  <block id="3f0733e14ebf265f0abf4b32371043ac" category="cell">Ansible v. 2.10 이상</block>
  <block id="3c91a74236fab100f024452f6df13b5e" category="cell">Python 3</block>
  <block id="215b38d177939de20bbb7b7913ce32c1" category="cell">Python 라이브러리 - NetApp-lib-xmltodictt-jmespath</block>
  <block id="d911b17f4f4cdcca62a04ad77aa9403d" category="cell">* ONTAP *</block>
  <block id="72bd33cc372377848ab3bb360deb365e" category="cell">ONTAP 버전 9.8 이상</block>
  <block id="10aadda84b1b1da26c3757dfdb59379d" category="cell">두 개의 데이터 애그리게이트</block>
  <block id="9f998f9668ffe69c62d78760d1c531f0" category="cell">NFS VLAN 및 ifgrp가 생성되었습니다</block>
  <block id="ba5f343281b90f0408008806c66bce86" category="cell">* Oracle 서버 *</block>
  <block id="6f1de5f0d7966ebf5f8d255fe28ebffe" category="cell">RHEL 7/8</block>
  <block id="aa596da3b79631d86c0d35e1c4b03aac" category="cell">Oracle Linux 7/8</block>
  <block id="814e8f57514db6134b6ffcd7a4ce20a6" category="cell">NFS, 공용 및 선택적 관리를 위한 네트워크 인터페이스</block>
  <block id="3ca63226b942aff3abcf62934a91e382" category="cell">소스의 기존 Oracle 환경과 대상(DR 사이트 또는 퍼블릭 클라우드)의 동급 Linux 운영 체제</block>
  <block id="6114118ecf4e8d86a2e7c80bfab462f6" category="open-title">strong class="big"&gt;CVO&lt;/strong&gt;</block>
  <block id="675b1e5a01195fa5d419962701704b96" category="cell">Oracle EC2 인스턴스에 적절한 스왑 공간을 설정합니다. 기본적으로 일부 EC2 인스턴스는 0 스왑으로 구축됩니다</block>
  <block id="2f960df807c8ad51e74c447149eb2033" category="cell">* Cloud Manager/AWS *</block>
  <block id="571f37fae4494df03321c2abe1fcc053" category="cell">AWS 액세스/비밀 키</block>
  <block id="7a5be8c4513f3bd0696db24a6bd977f4" category="cell">NetApp Cloud Manager 계정</block>
  <block id="99e55608ac5f1697eb6804aaf586af09" category="cell">NetApp Cloud Manager 업데이트 토큰</block>
  <block id="ae9205dab0c26cca7762be5149a93923" category="section-title">자동화 세부 정보</block>
  <block id="ba0676e7ae183e2c0bbd54261818154f" category="paragraph">이 자동 배포는 3개의 개별 역할로 구성된 단일 Ansible 플레이북을 통해 설계되었습니다. 역할은 ONTAP, Linux 및 Oracle 구성을 위한 것입니다. 다음 표에서는 자동화되고 있는 작업을 설명합니다.</block>
  <block id="3f9ec2a23fee1cafeb1a700de677caac" category="cell">플레이북</block>
  <block id="ef615563c8e8ea902c7fcac3cd2c4246" category="cell">작업</block>
  <block id="1f959110c5104b300b1a3d5fe3ee80dc" category="cell">* ONTAP_설정 *</block>
  <block id="c0563eda0fb9d63778efe04a13a5d744" category="cell">ONTAP 환경 사전 점검</block>
  <block id="b7ed1e5c864a764f83f035d7f4f774ee" category="cell">소스 클러스터에서 Intercluster LIF 생성(선택 사항)</block>
  <block id="73ddb5848c16203494697871a4e993cd" category="cell">대상 클러스터에 Intercluster LIF 생성(선택 사항)</block>
  <block id="04a35ce053d611d390fc192544fa4899" category="cell">클러스터 및 SVM 피어링 생성</block>
  <block id="4605aea1d05aa2979e72d73dd2c51773" category="cell">대상 SnapMirror 생성 및 지정된 Oracle 볼륨의 초기화</block>
  <block id="0dd4c7b6672d8937b6eb899b454fb7fe" category="cell">* ora_replication_cg *</block>
  <block id="7187aaa97acef94360159347d76a84c9" category="cell">/etc/oratab의 각 데이터베이스에 대해 백업 모드를 활성화합니다</block>
  <block id="f9198142d6e5690166713858ae8a0cdd" category="cell">Oracle 바이너리 및 데이터베이스 볼륨의 스냅샷을 생성합니다</block>
  <block id="23ba14a0a5cf33c38faec5b66fff712e" category="cell">SnapMirror가 업데이트되었습니다</block>
  <block id="114debcae141b96db77c72e8a1e8fadb" category="cell">/etc/oratab에서 각 데이터베이스의 백업 모드를 해제합니다</block>
  <block id="682094861a79bcba0e0ab2e193198762" category="cell">* ora_replication_log *</block>
  <block id="1d03ae98454d1c807318a1e29a4e2736" category="cell">/etc/oratab에 있는 각 데이터베이스의 현재 로그를 전환합니다</block>
  <block id="47e4696811eedec695f727189503e8df" category="cell">Oracle Log 볼륨의 스냅숏입니다</block>
  <block id="86836efae3e3d868a96ae69bcbc987ba" category="cell">* ora_RECOVERY *</block>
  <block id="6ceab4515ef4144abed0f0ce5ed3038f" category="cell">SnapMirror를 꺾습니다</block>
  <block id="a6066c717f63ac99226b48abb4cf1d85" category="cell">NFS를 사용하도록 설정하고 타겟에서 Oracle 볼륨에 대한 접합 경로를 생성합니다</block>
  <block id="aa46cdc29b66725a1180f57d02f0cee3" category="cell">DR Oracle 호스트를 구성합니다</block>
  <block id="dea9253f9b15f57a0c2161848a3c27a3" category="cell">Oracle 볼륨을 마운트하고 확인합니다</block>
  <block id="ee95819ff53983a149759d555a93ba4b" category="cell">Oracle 데이터베이스 복구 및 시작</block>
  <block id="5a6b57bc1fdf2f0e1259ed22f1d027a4" category="cell">* cvo_setup *</block>
  <block id="331c87cd495ffdc9cd55d8b3935a75f5" category="cell">환경 사전 점검</block>
  <block id="5f17c8d8d95282db12506044ba4d6ab9" category="cell">AWS 구성/AWS 액세스 키 ID/비밀 키/기본 지역</block>
  <block id="cef449920fe163cdd74231266cbdf23d" category="cell">AWS 역할 생성</block>
  <block id="85a4bcbc96cde90931ad369de96535b2" category="cell">AWS에서 NetApp Cloud Manager Connector 인스턴스 생성</block>
  <block id="abe14752834b641e86064c7214f6719c" category="cell">AWS에서 CVO(Cloud Volumes ONTAP) 인스턴스 생성</block>
  <block id="c2a9449cd3b0ae879520f450b65b1621" category="cell">NetApp Cloud Manager에 온프레미스 소스 ONTAP 클러스터를 추가하십시오</block>
  <block id="fbb54d6efa6ca64af90fbe2289812be8" category="cell">NFS를 사용하도록 설정하고 타겟 CVO에서 Oracle 볼륨의 접합 경로를 생성합니다</block>
  <block id="bf60025632dd0c4a2cf35e8b33e80619" category="section-title">기본 매개변수</block>
  <block id="3ef6389d9b9aacdce331793dd2a96ce8" category="paragraph">자동화를 간소화하기 위해 필요한 많은 Oracle 매개 변수를 기본값으로 사전 설정하였습니다. 일반적으로 대부분의 배포에서 기본 매개 변수를 변경할 필요는 없습니다. 고급 사용자는 기본 매개 변수를 주의 깊게 변경할 수 있습니다. 기본 매개 변수는 각 역할 폴더의 defaults 디렉토리에 있습니다.</block>
  <block id="794df3791a8c800841516007427a2aa3" category="section-title">라이센스</block>
  <block id="19adadc497199e16f07f9744d43b2899" category="paragraph">GitHub 리포지토리에 설명된 대로 라이센스 정보를 읽어야 합니다. 이 리포지토리의 콘텐츠에 액세스, 다운로드, 설치 또는 사용하면 라이선스 조항에 동의하는 것입니다 <block ref="07d15b3b85718d883b437fb3739e59a7" category="inline-link-macro-rx"></block>.</block>
  <block id="87d624bc8a7f555a711e7214ee002eec" category="paragraph">이 저장소의 컨텐츠에서 파생 저작물을 생성 및/또는 공유하는 데는 특정 제한이 있습니다. 의 약관을 읽었는지 확인하십시오 <block ref="49480c711afcff6aca610d8294731030" category="inline-link-macro-rx"></block> 콘텐츠를 사용하기 전에. 모든 약관에 동의하지 않는 경우 이 리포지토리에서 콘텐츠를 액세스, 다운로드 또는 사용하지 마십시오.</block>
  <block id="a98d844e94ad28c8e0fb089e005d6b9f" category="inline-link-macro">자세한 AWX/Tower 절차를 보려면 여기를 클릭하십시오</block>
  <block id="7e599865fd1cdad0e26add5715f65267" category="paragraph">준비가 되면 를 클릭합니다 <block ref="d28bc5520349bb0598caaa5132432326" category="inline-link-macro-rx"></block>.</block>
  <block id="ac9bef0f960e3a46befd2d06b223b61d" category="summary">이 섹션에서는 개발/테스트 및 DR 작업을 위한 일반적인 하이브리드 클라우드 아키텍처를 설명합니다.</block>
  <block id="fece52c505c48f2979e3fa0c8b6bd8bc" category="paragraph"><block ref="fece52c505c48f2979e3fa0c8b6bd8bc" category="inline-link-macro-rx"></block></block>
  <block id="4085a97aa705c0122bbcec0c84dd97d3" category="paragraph">다음 아키텍처 다이어그램은 개발/테스트 및 재해 복구 작업을 위해 하이브리드 클라우드에서 엔터프라이즈 데이터베이스 작업을 구축하는 일반적인 과정을 보여 줍니다.</block>
  <block id="acb339f710a626679c374df5b90c5416" category="paragraph"><block ref="acb339f710a626679c374df5b90c5416" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cdc302c6d83b60c8ec7ad0b550e55a8" category="paragraph">정상적인 비즈니스 작업에서는 클라우드에 동기화된 데이터베이스 볼륨을 클론 복제하여 개발/테스트 데이터베이스 인스턴스의 애플리케이션 개발 또는 테스트에 마운트할 수 있습니다. 장애가 발생할 경우 클라우드에서 동기화된 데이터베이스 볼륨을 재해 복구를 위해 활성화할 수 있습니다.</block>
  <block id="fbfd3304757c668454a7bdd10f9de200" category="inline-link-macro">다음은 솔루션 요구 사항입니다.</block>
  <block id="ae3b1bce66c4c75d8abf9828ec9f2608" category="paragraph"><block ref="ae3b1bce66c4c75d8abf9828ec9f2608" category="inline-link-macro-rx"></block></block>
  <block id="0f22160e43c900ef7426d8a19e9f482d" category="summary">하이브리드 클라우드 데이터베이스 워크로드를 실행하기 전에 사내와 클라우드 모두에서 특정 사전 요구사항을 구성해야 합니다. 다음 섹션에서는 이 프로세스에 대한 개략적인 요약을 제공하고 다음 링크를 통해 필요한 시스템 구성에 대한 추가 정보를 제공합니다.</block>
  <block id="1dad826770c4d2c619351c974f725b36" category="doc">사전 요구 사항 구성</block>
  <block id="ce38f65c711e7e3047c9350abe42c0c3" category="inline-link-macro">이전: 솔루션 요구 사항.</block>
  <block id="d3fe0eebddd46d46399cb319c7219427" category="paragraph"><block ref="d3fe0eebddd46d46399cb319c7219427" category="inline-link-macro-rx"></block></block>
  <block id="4df40e141b0559f15db8f84f78aed013" category="section-title">온프레미스</block>
  <block id="761883c0d5c55fba5b200ac8ac0d86e5" category="section-title">퍼블릭 클라우드</block>
  <block id="37aa83a33297d9d16b4423be342598bb" category="list-text">커넥터의 네트워크 위치입니다</block>
  <block id="74c043a4451dd260729a23ce96aa1550" category="paragraph">중요 고려 사항:</block>
  <block id="7aee27c83b5e3622c1d8cbd5c2098c60" category="list-text">Cloud Manager Connector는 어디에 구축합니까?</block>
  <block id="43fd5c6fa3d9ba8a215c31f3bf0a9859" category="list-text">Cloud Volume ONTAP 사이징 및 아키텍처</block>
  <block id="7a0e00d70e3b0ff06476a52565f923c4" category="list-text">단일 노드 또는 고가용성?</block>
  <block id="2d0b46fff3ae203a435b167c7111b389" category="paragraph">다음 링크에서 자세한 내용을 확인할 수 있습니다.</block>
  <block id="cfd98f49422c4fba755a2ff74c55a4a0" category="paragraph"><block ref="cfd98f49422c4fba755a2ff74c55a4a0" category="inline-link-macro-rx"></block></block>
  <block id="704849d56e695ab8f9df0b106e0d7e33" category="inline-link-macro">퍼블릭 클라우드</block>
  <block id="96e41b2b281ca4b71edf4ed16e46a2be" category="paragraph"><block ref="96e41b2b281ca4b71edf4ed16e46a2be" category="inline-link-macro-rx"></block></block>
  <block id="7c12725837ee75c4c0a9bbc14f99934d" category="inline-link-macro">다음: 온프레미스 필수 구성 요소.</block>
  <block id="bc57dd30a9059d494c9d76e4b0a9ce8f" category="paragraph"><block ref="bc57dd30a9059d494c9d76e4b0a9ce8f" category="inline-link-macro-rx"></block></block>
  <block id="9ce6d30135c2644ff34390c65af4061b" category="paragraph">조직은 효율성을 높이고, 구현을 앞당기고, 수동 작업을 줄이기 위해 환경을 자동화하고 있습니다. Ansible과 같은 구성 관리 툴을 사용하여 엔터프라이즈 데이터베이스 운영을 간소화하고 있습니다. 이 솔루션에서는 Ansible을 사용하여 NetApp ONTAP을 사용하여 Oracle 19c의 프로비저닝과 구성을 자동화하는 방법을 보여줍니다. 스토리지 관리자, 시스템 관리자 및 DBA가 새 스토리지를 일관성 있게 신속하게 구축하고 데이터베이스 서버를 구성하며 Oracle 19c 소프트웨어를 설치할 수 있도록 함으로써 다음과 같은 이점을 얻을 수 있습니다.</block>
  <block id="5291cb8e681983247b899ce2364188f2" category="list-text">설계 복잡성과 인적 오류를 제거하고 반복 가능한 일관된 구축 및 모범 사례를 구현합니다</block>
  <block id="a90516bf4597e04e1a97bd9cb37087d8" category="list-text">스토리지 프로비저닝, DB 호스트 구성, Oracle 설치 시간 단축</block>
  <block id="a54e59b6b063d8a2bf18acffab877d09" category="list-text">데이터베이스 관리자, 시스템 및 스토리지 관리자의 생산성 향상</block>
  <block id="d18d76441366273feb36bde890ad5e1c" category="list-text">스토리지와 데이터베이스를 손쉽게 확장</block>
  <block id="7d85c5a5f016aefeda6b89687f1307bb" category="paragraph">NetApp은 고객에게 검증된 Ansible 모듈과 역할을 제공하여 Oracle 데이터베이스 환경의 구축, 구성, 라이프사이클 관리를 가속합니다. 이 솔루션은 다음을 지원하기 위한 지침 및 Ansible 플레이북 코드를 제공합니다.</block>
  <block id="547b893b7cd300d6a8335f5b179ad12e" category="list-text">Oracle 데이터베이스용 ONTAP NFS 스토리지를 생성하고 구성합니다</block>
  <block id="36bb01ec9f02292fb44b9f10f57ceae7" category="list-text">RedHat Enterprise Linux 7/8 또는 Oracle Linux 7/8 에 Oracle 19c를 설치합니다</block>
  <block id="548bf87c41c9d3bb76981decbd599c90" category="list-text">ONTAP NFS 스토리지에 Oracle 19c를 구성합니다</block>
  <block id="950496934d91d07bb089d6ed0999b5a9" category="paragraph">자세한 내용을 보거나 시작하려면 아래의 개요 비디오를 참조하십시오.</block>
  <block id="b923f56ad2a53fa1a3ca1160e48f141e" category="section-title">AWX/타워 배포</block>
  <block id="ab81e47672e89830ec16c581f44cb23c" category="list-text">1부: 시작하기, 요구 사항, 자동화 세부 정보 및 초기 AWX/타워 구성</block>
  <block id="cf7bbd18f18fdc73ee49ffea888126c7" category="list-text">2부: 변수 및 Playbook 실행</block>
  <block id="f5e227cfa54c5693c512c6adf41a3772" category="section-title">CLI 배포</block>
  <block id="0b8a09b5974336d1f5e510d18205c03c" category="list-text">1부: 시작하기, 요구사항, 자동화 세부 정보 및 Ansible Control 호스트 설정</block>
  <block id="a10998cc3e1dc7f2a013754d935c4f26" category="summary">NetApp SnapCenter 툴은 RBAC(역할 기반 액세스 제어)를 사용하여 사용자 리소스 액세스 및 권한 부여를 관리하고 SnapCenter 설치를 통해 미리 채워진 역할을 생성합니다. 필요에 따라 사용자 지정 역할을 만들 수도 있습니다.</block>
  <block id="7e3b07f9add4cd78ade3c795a52dfad2" category="doc">온프레미스에서 시작합니다</block>
  <block id="32229cff9e0b41c513b3e3b9e19cec88" category="inline-link-macro">이전: 시작하기 개요</block>
  <block id="6be036b00e3db4159514171a989cacd6" category="paragraph"><block ref="6be036b00e3db4159514171a989cacd6" category="inline-link-macro-rx"></block></block>
  <block id="d30e54646ba482722332f48ddc22bde5" category="section-title">SnapCenter에서 데이터베이스 관리자 설정</block>
  <block id="72f706d19ed0d09889b4fbc7578cd1a3" category="paragraph">NetApp SnapCenter 툴은 RBAC(역할 기반 액세스 제어)를 사용하여 사용자 리소스 액세스 및 권한 부여를 관리하고 SnapCenter 설치를 통해 미리 채워진 역할을 생성합니다. 필요에 따라 사용자 지정 역할을 만들 수도 있습니다. 데이터베이스 백업, 복원 및/또는 재해 복구를 위해 SnapCenter에서 지원하는 각 데이터베이스 플랫폼에 대해 전용 관리 사용자 ID를 갖는 것이 적합합니다. 단일 ID를 사용하여 모든 데이터베이스를 관리할 수도 있습니다. 테스트 사례 및 데모에서는 Oracle과 SQL Server 모두에 대해 각각 전용 관리 사용자를 생성했습니다.</block>
  <block id="27733e8f07432bb94ac7621b28d3b2c8" category="paragraph">특정 SnapCenter 리소스는 SnapCenter 관리자 역할만 사용하여 프로비저닝할 수 있습니다. 그러면 액세스를 위해 리소스를 다른 사용자 ID에 할당할 수 있습니다.</block>
  <block id="64784aa3cec13e83af6e941f8489cf06" category="paragraph">사전 설치 및 구성된 사내 SnapCenter 환경에서는 다음 작업이 이미 완료되었을 수 있습니다. 그렇지 않은 경우 다음 단계에 따라 데이터베이스 관리자 사용자를 생성합니다.</block>
  <block id="c8867eac833e7bb55520105b00139f1a" category="list-text">Windows Active Directory에 관리자 사용자를 추가합니다.</block>
  <block id="dd3e743eb52cbe7c2b6104573a9767e0" category="list-text">SnapCenter CenterAdmin 역할로 부여된 ID를 사용하여 로그인합니다.</block>
  <block id="a6bd76cb24271ba173d16f01bf4108d0" category="list-text">설정 및 사용자 아래의 액세스 탭으로 이동하고 추가 를 클릭하여 새 사용자를 추가합니다. 새 사용자 ID는 1단계에서 Windows Active Directory에서 만든 관리자 사용자에게 연결됩니다. . 필요에 따라 사용자에게 적절한 역할을 할당합니다. 필요에 따라 admin 사용자에게 리소스를 할당합니다.</block>
  <block id="6a67bb048bd14dd348cca7f81b62d699" category="paragraph"><block ref="6a67bb048bd14dd348cca7f81b62d699" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d2c51e83f473f137861a132554d1916" category="section-title">2.SnapCenter 플러그인 설치 필수 구성 요소입니다</block>
  <block id="7bd973d4d28d6fcf5f50379b33a49758" category="paragraph">SnapCenter는 DB 호스트에서 실행 중인 플러그인 에이전트를 사용하여 백업, 복구, 클론 및 기타 기능을 수행합니다. 플러그인 설치 및 기타 관리 기능을 위해 설정 및 자격 증명 탭에서 구성된 자격 증명을 통해 데이터베이스 호스트 및 데이터베이스에 연결합니다. Linux 또는 Windows와 같은 타겟 호스트 유형과 데이터베이스 유형에 따른 특정 권한 요구 사항이 있습니다.</block>
  <block id="c342f214098114b90cb67297a2ef5dc3" category="paragraph">SnapCenter 플러그인 설치 전에 DB 호스트 자격 증명을 구성해야 합니다. 일반적으로 플러그인 설치를 위한 호스트 연결 자격 증명으로 DB 호스트의 관리자 사용자 계정을 사용합니다. 또한 OS 기반 인증을 사용하여 데이터베이스 액세스에 동일한 사용자 ID를 부여할 수도 있습니다. 반면, DB 관리 액세스를 위해 서로 다른 데이터베이스 사용자 ID를 사용하여 데이터베이스 인증을 사용할 수도 있습니다. OS 기반 인증을 사용하기로 결정한 경우 OS 관리자 사용자 ID에 DB 액세스 권한이 부여되어야 합니다. Windows 도메인 기반 SQL Server 설치의 경우 도메인 관리자 계정을 사용하여 도메인 내의 모든 SQL Server를 관리할 수 있습니다.</block>
  <block id="19df1192effefad83e57653fd3a47415" category="paragraph">SQL Server용 Windows 호스트:</block>
  <block id="e1cc3ce53d7753e33588201db3d3b147" category="list-text">인증에 Windows 자격 증명을 사용하는 경우 플러그인을 설치하기 전에 자격 증명을 설정해야 합니다.</block>
  <block id="a82f1290b72a26d654b93632a1ec50bb" category="list-text">인증에 SQL Server 인스턴스를 사용하는 경우 플러그인을 설치한 후 자격 증명을 추가해야 합니다.</block>
  <block id="63f74bef6650942c6795f96366a39e6a" category="list-text">자격 증명을 설정하는 동안 SQL 인증을 사용하도록 설정한 경우 검색된 인스턴스 또는 데이터베이스에 빨간색 잠금 아이콘이 표시됩니다. 잠금 아이콘이 나타나면 인스턴스 또는 데이터베이스 자격 증명을 지정하여 인스턴스 또는 데이터베이스를 리소스 그룹에 성공적으로 추가해야 합니다.</block>
  <block id="b61dad3bbbf3270bf2dada5c2ac1f775" category="list-text">다음 조건이 충족될 경우 sysadmin 액세스 없이 RBAC 사용자에게 자격 증명을 할당해야 합니다.</block>
  <block id="34cefb5a19894e4f9b1b068544c0f591" category="list-text">자격 증명이 SQL 인스턴스에 할당됩니다.</block>
  <block id="6707464a5871a6aa26dcf785bea4052c" category="list-text">SQL 인스턴스 또는 호스트는 RBAC 사용자에게 할당됩니다.</block>
  <block id="4bc8aac02ff00d874ad8b4ccd4d745ed" category="list-text">RBAC DB 관리자 사용자에게는 리소스 그룹과 백업 권한이 모두 있어야 합니다.</block>
  <block id="9198b455aa67840c7a69c7a54e94301a" category="paragraph">Oracle용 UNIX 호스트:</block>
  <block id="71d53e54a48cfe7de69347bcd854ef30" category="list-text">sshd.conf를 편집하고 sshd 서비스를 다시 시작하여 루트 또는 루트 이외의 사용자에 대해 암호 기반 SSH 연결을 활성화해야 합니다. AWS 인스턴스의 암호 기반 SSH 인증은 기본적으로 해제되어 있습니다.</block>
  <block id="efa873f0464a14d54b066f475ad74480" category="list-text">비루트 사용자에 대한 sudo 권한을 구성하여 플러그인 프로세스를 설치 및 시작합니다. 플러그인을 설치하면 프로세스가 효과적인 루트 사용자로 실행됩니다.</block>
  <block id="82a2174029175f8fbc3f52fea4e18c84" category="list-text">설치 사용자에 대한 Linux 인증 모드를 사용하여 자격 증명을 생성합니다.</block>
  <block id="86b3cc44ebd8e0a9185e48c4f22e81e9" category="list-text">Linux 호스트에 Java 1.8.x(64비트)를 설치해야 합니다.</block>
  <block id="c1e8851d10ecc615c47a47f704569d29" category="list-text">Oracle 데이터베이스 플러그인을 설치하면 Unix용 SnapCenter 플러그인도 설치됩니다.</block>
  <block id="7efb27733d1fb21feae901a41580dced" category="section-title">3.SnapCenter 호스트 플러그인 설치</block>
  <block id="37a5c714defad8175b81b4d49eb0544c" category="admonition">클라우드 DB 서버 인스턴스에 SnapCenter 플러그인을 설치하기 전에 컴퓨팅 인스턴스 구축을 위한 관련 클라우드 섹션에 나와 있는 대로 모든 구성 단계를 완료해야 합니다.</block>
  <block id="283aa502c28fe1c9ff8dadd1700955fc" category="paragraph">다음 단계에서는 SnapCenter 플러그인이 호스트에 설치되어 있는 동안 데이터베이스 호스트를 SnapCenter에 추가하는 방법을 보여 줍니다. 이 절차는 사내 호스트와 클라우드 호스트를 모두 추가하는 데 적용됩니다. 다음 데모에서는 AWS에 상주하는 Windows 또는 Linux 호스트를 추가합니다.</block>
  <block id="81ed46777c39c0d0618953601572fc27" category="section-title">SnapCenter VMware 글로벌 설정을 구성합니다</block>
  <block id="2aa8a40dbbfb6b52621408c81aa5373c" category="paragraph">설정 &gt; 전역 설정 으로 이동합니다. 하이퍼바이저 설정 에서 "VM에 모든 호스트에 대한 iSCSI 직접 연결 디스크 또는 NFS가 있음"을 선택하고 업데이트 를 클릭합니다.</block>
  <block id="4c120331c9eea223eee675b6588d76ee" category="paragraph"><block ref="4c120331c9eea223eee675b6588d76ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f63a469619859e4cfab52fd63523aca" category="section-title">호스트에 Windows 호스트 및 플러그인 설치를 추가합니다</block>
  <block id="997da6deedab4436b559e3a8f7f05a2e" category="list-text">SnapCenter에 SnapCenterAdmin 권한으로 사용자 ID를 사용하여 로그인합니다.</block>
  <block id="97e7f600216a2e9ae18423777e11ad9c" category="list-text">왼쪽 메뉴에서 호스트 탭을 클릭한 다음 추가를 클릭하여 호스트 추가 워크플로우를 엽니다.</block>
  <block id="35314bae57d7ff62ab36156211c1cc71" category="list-text">호스트 유형에 Windows를 선택합니다. 호스트 이름은 호스트 이름 또는 IP 주소일 수 있습니다. 호스트 이름은 SnapCenter 호스트에서 올바른 호스트 IP 주소로 확인되어야 합니다. 2단계에서 생성한 호스트 자격 증명을 선택합니다. 설치할 플러그인 패키지로 Microsoft Windows 및 Microsoft SQL Server를 선택합니다.</block>
  <block id="b9740ae9eb2ef0fe27e4c541d06a961f" category="paragraph"><block ref="b9740ae9eb2ef0fe27e4c541d06a961f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31efcd689861354799bb539ab2571ebe" category="list-text">Windows 호스트에 플러그인을 설치하면 전체 상태가 "Configure log directory"로 표시됩니다.</block>
  <block id="0e15e25c5ee21469698f72cf35caa7bf" category="paragraph"><block ref="0e15e25c5ee21469698f72cf35caa7bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2aeaa4503c6d72513c0dbe0f205ee3b" category="list-text">호스트 이름을 클릭하여 SQL Server 로그 디렉토리 구성을 엽니다.</block>
  <block id="6fc78660a180b747f815b878c89e3cb0" category="paragraph"><block ref="6fc78660a180b747f815b878c89e3cb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb2b40646a77b4f044e7fa04ea20306" category="list-text">"로그 디렉토리 구성"을 클릭하여 "SQL Server용 플러그인 구성"을 엽니다.</block>
  <block id="5e3bf9ddacfcad12c5cf63614a869ad4" category="paragraph"><block ref="5e3bf9ddacfcad12c5cf63614a869ad4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7143b5d162d385dfb1af07f61c59f65" category="list-text">찾아보기 를 클릭하여 로그 디렉토리를 설정할 수 있도록 NetApp 스토리지를 검색합니다. SnapCenter는 이 로그 디렉토리를 사용하여 SQL Server 트랜잭션 로그 파일을 롤업합니다. 저장을 클릭합니다.</block>
  <block id="50eb49de485da684ac1556947ac46aba" category="paragraph"><block ref="50eb49de485da684ac1556947ac46aba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0d88588bdb07dd412a4ba1d08348b29" category="admonition">DB 호스트에 프로비저닝된 NetApp 스토리지의 경우 CVO의 6단계에 나와 있는 것처럼 SnapCenter에 스토리지(온프레미스 또는 CVO)를 추가해야 합니다.</block>
  <block id="d744af12906d55ab51aa932b3ffcd121" category="list-text">로그 디렉토리가 구성된 후 Windows 호스트 플러그인 전체 상태가 실행 중 으로 변경됩니다.</block>
  <block id="3f7bfffdbb76fd620b0a31d300415528" category="paragraph"><block ref="3f7bfffdbb76fd620b0a31d300415528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41517f2e270a138f4ae92988a4cbdd2" category="list-text">데이터베이스를 관리하는 사용자 ID에 호스트를 할당하려면 설정 및 사용자 아래의 액세스 탭으로 이동하고 데이터베이스 관리 사용자 ID(호스트를 할당해야 하는 sqlldba인 경우)를 클릭한 다음 저장 을 클릭하여 호스트 리소스 할당을 완료합니다.</block>
  <block id="b21f826d2ea15e58b9c8aadccb566cfe" category="paragraph"><block ref="b21f826d2ea15e58b9c8aadccb566cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021de72edbb0f174ffe954c5e5367b80" category="paragraph"><block ref="021de72edbb0f174ffe954c5e5367b80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2fe19c733a6342990513e02264db163" category="section-title">Unix 호스트를 추가하고 호스트에 플러그인을 설치합니다</block>
  <block id="6a0f36be9f208d20c3c1145c3a09b876" category="list-text">왼쪽 메뉴에서 호스트 탭을 클릭하고 추가 를 클릭하여 호스트 추가 워크플로우를 엽니다.</block>
  <block id="dd8c6d773e31c4254eb58b4b5e2ae1be" category="list-text">호스트 유형으로 Linux를 선택합니다. 호스트 이름은 호스트 이름 또는 IP 주소일 수 있습니다. 그러나 SnapCenter 호스트에서 호스트 IP 주소를 수정하려면 호스트 이름을 확인해야 합니다. 2단계에서 만든 호스트 자격 증명을 선택합니다. 호스트 자격 증명에는 sudo 권한이 필요합니다. Oracle Database를 설치할 플러그인으로 선택하여 Oracle 및 Linux 호스트 플러그인을 모두 설치합니다.</block>
  <block id="7d4cdef2144fd1466fae298bd27476d1" category="paragraph"><block ref="7d4cdef2144fd1466fae298bd27476d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="711730391561a228d41f7fede13ca6e8" category="list-text">기타 옵션 을 클릭하고 "설치 전 검사 건너뛰기"를 선택합니다. 사전 설치 검사를 건너뛰는 것을 확인하는 메시지가 표시됩니다. 예 를 클릭한 다음 저장 을 클릭합니다.</block>
  <block id="3511b18d059f3f300b5fbe827f7273ac" category="paragraph"><block ref="3511b18d059f3f300b5fbe827f7273ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e095a093138c6b1968d313d5f799255a" category="list-text">제출 을 클릭하여 플러그인 설치를 시작합니다. 아래와 같이 지문을 확인하라는 메시지가 표시됩니다.</block>
  <block id="146c4805beb9310e4554842f776cb88b" category="paragraph"><block ref="146c4805beb9310e4554842f776cb88b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53dcda6f2c03efbe73ae5eb311852a8d" category="list-text">SnapCenter는 호스트 검증 및 등록을 수행한 다음 Linux 호스트에 플러그인을 설치합니다. 상태가 플러그인 설치 에서 실행 중 으로 변경됩니다.</block>
  <block id="2636403a6c50748422736d9d84a3e4be" category="paragraph"><block ref="2636403a6c50748422736d9d84a3e4be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="33ea9d9313933c68d640ebb655ec43dc" category="list-text">새로 추가된 호스트를 적절한 데이터베이스 관리 사용자 ID(여기서는 oradba)에 할당합니다.</block>
  <block id="2815d2f5e3b49d9332a320ec997271dd" category="paragraph"><block ref="2815d2f5e3b49d9332a320ec997271dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb6a9566891a97e0f8fbaefbd4878bdd" category="paragraph"><block ref="eb6a9566891a97e0f8fbaefbd4878bdd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b4c839521fd41e845e6e8c3158b809b" category="section-title">4.데이터베이스 리소스 검색</block>
  <block id="45e46a9524f23884445bf542bf464b93" category="paragraph">플러그인 설치가 완료되면 호스트의 데이터베이스 리소스를 즉시 검색할 수 있습니다. 왼쪽 메뉴에서 리소스 탭을 클릭합니다. 데이터베이스 플랫폼 유형에 따라 데이터베이스, 리소스 그룹 등과 같은 다양한 보기를 사용할 수 있습니다. 호스트의 리소스가 검색되지 않고 표시되지 않으면 리소스 새로 고침 탭을 클릭해야 할 수도 있습니다.</block>
  <block id="79fca6395972f8079320d3229822e491" category="paragraph"><block ref="79fca6395972f8079320d3229822e491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66789731e61fd3d4b6024e5fcb0945e1" category="paragraph">데이터베이스가 처음 검색되면 전체 상태가 "보호되지 않음"으로 표시됩니다. 이전 스크린샷은 아직 백업 정책에 의해 보호되지 않은 Oracle 데이터베이스를 보여 줍니다.</block>
  <block id="68148a1249ca9110d03c698ae152932a" category="paragraph">백업 구성 또는 정책을 설정하고 백업을 실행한 경우 데이터베이스의 전체 상태는 백업 상태를 "Backup Succeeded"로 표시하고 마지막 백업의 타임스탬프를 표시합니다. 다음 스크린샷은 SQL Server 사용자 데이터베이스의 백업 상태를 보여 줍니다.</block>
  <block id="2cdfb74ac3aabfde7e1fae347ed5afc7" category="paragraph"><block ref="2cdfb74ac3aabfde7e1fae347ed5afc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c9616324bc00808729d46fba94ad75" category="paragraph">데이터베이스 액세스 자격 증명이 제대로 설정되어 있지 않으면 빨간색 잠금 단추가 데이터베이스에 액세스할 수 없음을 나타냅니다. 예를 들어, Windows 자격 증명에 데이터베이스 인스턴스에 대한 sysadmin 액세스 권한이 없는 경우 데이터베이스 자격 증명을 다시 구성하여 빨간색 잠금을 해제해야 합니다.</block>
  <block id="dd4606e87689c86d82a694412c5654a5" category="paragraph"><block ref="dd4606e87689c86d82a694412c5654a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f07ad394b89553e7d6d1f90fae584" category="paragraph"><block ref="884f07ad394b89553e7d6d1f90fae584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0024854a814ddd68bcf3907357c46bc2" category="paragraph">Windows 수준 또는 데이터베이스 수준에서 적절한 자격 증명이 구성되면 빨간색 잠금이 사라지고 SQL Server 유형 정보가 수집 및 검토됩니다.</block>
  <block id="95c88e08b2fd416b4514ce2454af2038" category="paragraph"><block ref="95c88e08b2fd416b4514ce2454af2038" category="inline-image-macro-rx" type="image"></block></block>
  <block id="864f4d2595d06e5e8b46b08edb3899e6" category="section-title">스토리지 클러스터 피어링 및 DB 볼륨 복제를 설정합니다</block>
  <block id="785196ec55a9e713ad1a4f962baa31dd" category="paragraph">퍼블릭 클라우드를 타겟 대상으로 사용하여 사내 데이터베이스 데이터를 보호하기 위해 NetApp SnapMirror 기술을 사용하여 사내 ONTAP 클러스터 데이터베이스 볼륨을 클라우드의 CVO에 복제합니다. 그런 다음 복제된 타겟 볼륨을 개발/OPS 또는 재해 복구를 위해 복제할 수 있습니다. 다음은 클러스터 피어링을 설정하고 DB 볼륨 복제를 설정하는 상위 단계입니다.</block>
  <block id="1f1927293f04e4cf0fc91a7e389612eb" category="list-text">온프레미스 클러스터와 CVO 클러스터 인스턴스 모두에서 클러스터 피어링을 위해 인터클러스터 LIF를 구성합니다. 이 단계는 ONTAP 시스템 관리자로 수행할 수 있습니다. 기본 CVO 배포에는 클러스터 간 LIF가 자동으로 구성됩니다.</block>
  <block id="9547803d96e78bbc38305e6300f7a800" category="paragraph">사내 클러스터:</block>
  <block id="2ef6da9ba547bc5361495650ac3fc992" category="paragraph"><block ref="2ef6da9ba547bc5361495650ac3fc992" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3c5b3e342f57b792e2263e69e41677a" category="paragraph">타겟 CVO 클러스터:</block>
  <block id="d94586e4cd285619a4f1ef0e06636dd1" category="paragraph"><block ref="d94586e4cd285619a4f1ef0e06636dd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79d372933b80ed2ca8ca14d8458828af" category="inline-link-macro">시작하기 - AWS 퍼블릭 클라우드</block>
  <block id="6a87ea28950f9209121872c9d2690049" category="list-text">인터클러스터 LIF가 구성된 경우 NetApp Cloud Manager의 끌어서 놓기를 사용하여 클러스터 피어링을 설정하고 볼륨 복제를 설정할 수 있습니다. 을 참조하십시오 <block ref="28783e162df4af496939d6f9f6f31d5f" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="d1567c6c8f0752cbc7deb6d9f639ba12" category="paragraph">또는 ONTAP System Manager를 사용하여 다음과 같이 클러스터 피어링을 수행하고 DB 볼륨 복제를 수행할 수 있습니다.</block>
  <block id="494c0b53ff31502c0c1105881e2e389a" category="list-text">ONTAP 시스템 관리자에 로그인합니다. 클러스터 &gt; 설정 으로 이동하고 피어 클러스터 를 클릭하여 클라우드의 CVO 인스턴스로 클러스터 피어링을 설정합니다.</block>
  <block id="ba770272a0f634af47a5788634e80d54" category="paragraph"><block ref="ba770272a0f634af47a5788634e80d54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54de72c782c4b4ccc7f2914a858d5356" category="list-text">볼륨 탭으로 이동합니다. 복제할 데이터베이스 볼륨을 선택하고 보호 를 클릭합니다.</block>
  <block id="32588f46a47679329b03194fd2e9084f" category="paragraph"><block ref="32588f46a47679329b03194fd2e9084f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0aace069b478e8b2b0753f855f2be94" category="list-text">보호 정책을 Asynchronous로 설정합니다. 대상 클러스터와 스토리지 SVM을 선택합니다.</block>
  <block id="7dbec53b432ae53f7e454836ad0dad00" category="paragraph"><block ref="7dbec53b432ae53f7e454836ad0dad00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a2a64fe8af0790615a9344069794e2e" category="list-text">볼륨이 소스와 타겟 간에 동기화되고 복제 관계가 정상 상태인지 확인합니다.</block>
  <block id="97edcd79a5e90d9caafde40fcb586185" category="paragraph"><block ref="97edcd79a5e90d9caafde40fcb586185" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36097c4ad6058de288de8992f89adbb8" category="section-title">CVO 데이터베이스 스토리지 SVM을 SnapCenter에 추가합니다</block>
  <block id="ebcf85d67af3f672ade8bd7b224a8a2b" category="list-text">메뉴에서 스토리지 시스템 탭을 클릭한 다음 새로 만들기를 클릭하여 복제된 타겟 데이터베이스 볼륨을 SnapCenter에 호스팅하는 CVO 스토리지 SVM을 추가합니다. 스토리지 시스템 필드에 클러스터 관리 IP를 입력하고 적절한 사용자 이름과 암호를 입력합니다.</block>
  <block id="41e9c94a0c8cb108959099b8f87adb82" category="paragraph"><block ref="41e9c94a0c8cb108959099b8f87adb82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a27406b63f99780f65572b95f2f72348" category="list-text">추가 옵션을 클릭하여 추가 스토리지 구성 옵션을 엽니다. 플랫폼 필드에서 Cloud Volumes ONTAP 를 선택하고 보조 를 선택한 다음 저장 을 클릭합니다.</block>
  <block id="8a60464ab91cb2499a03c722639c3aee" category="paragraph"><block ref="8a60464ab91cb2499a03c722639c3aee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b474a0a2de59b8e3013112beb48af7b7" category="list-text">에 나와 있는 대로 스토리지 시스템을 SnapCenter 데이터베이스 관리 사용자 ID에 할당합니다 <block ref="8a46cbc3838a53b9205abb25a577bbc8" category="inline-xref-macro-rx"></block>.</block>
  <block id="8691f91a1fe977fd76aa5e53b0f71034" category="paragraph"><block ref="8691f91a1fe977fd76aa5e53b0f71034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39ec95149453e7bb6b73f1c03228e85c" category="section-title">SnapCenter에서 데이터베이스 백업 정책을 설정합니다</block>
  <block id="37d9f685e375f77a2231e13c88ccc606" category="paragraph">다음 절차에서는 전체 데이터베이스 또는 로그 파일 백업 정책을 만드는 방법을 보여 줍니다. 그런 다음 이 정책을 구현하여 데이터베이스 리소스를 보호할 수 있습니다. RPO(복구 지점 목표) 또는 RTO(복구 시간 목표)는 데이터베이스 및/또는 로그 백업의 빈도를 결정합니다.</block>
  <block id="739184f368f13e142dd034fcdc853594" category="section-title">Oracle에 대한 전체 데이터베이스 백업 정책을 생성합니다</block>
  <block id="94b39254a7aba068b68fec64f6331b0b" category="list-text">SnapCenter에 데이터베이스 관리 사용자 ID로 로그인하고 설정을 클릭한 다음 정책을 클릭합니다.</block>
  <block id="90affc4ffbb767a3d1272be5e1ad8f0c" category="paragraph"><block ref="90affc4ffbb767a3d1272be5e1ad8f0c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1d144b8c78fc8541b57aa9f0ca863a6" category="list-text">New(새로 만들기) 를 클릭하여 새 백업 정책 생성 워크플로우를 시작하거나 수정할 기존 정책을 선택합니다.</block>
  <block id="29618ae8465c694d23d68e171fe9d905" category="paragraph"><block ref="29618ae8465c694d23d68e171fe9d905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c9dac29c26006ce512153a9bdabcc95" category="list-text">백업 유형 및 스케줄 빈도를 선택합니다.</block>
  <block id="10e2791563a2891fd7e4e68c5673671b" category="paragraph"><block ref="10e2791563a2891fd7e4e68c5673671b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4df94ad44381c9fb7fe2f8d01dcd16d8" category="list-text">백업 보존 설정을 지정합니다. 이 경우 보관할 전체 데이터베이스 백업 복사본 수가 정의됩니다.</block>
  <block id="6dcc4aa023085480846059b6b1d5e5b3" category="paragraph"><block ref="6dcc4aa023085480846059b6b1d5e5b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd634020906b35a41e0ba633eddeb96a" category="list-text">클라우드의 2차 위치에 복제할 로컬 기본 스냅샷 백업을 푸시할 2차 복제 옵션을 선택합니다.</block>
  <block id="25ef9e4c73a2da8519e8d232b6a95fcb" category="paragraph"><block ref="25ef9e4c73a2da8519e8d232b6a95fcb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2e3af55a4355bc46e91425ac5701174" category="list-text">백업 실행 전후에 실행할 선택적 스크립트를 지정합니다.</block>
  <block id="326d50fae4f713cebe97d0f6bb23a2d9" category="paragraph"><block ref="326d50fae4f713cebe97d0f6bb23a2d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd009bc210e371d36d466b592179e883" category="list-text">필요한 경우 백업 검증을 실행합니다.</block>
  <block id="0b132e3438f5cf31e90f45e79710f0b9" category="paragraph"><block ref="0b132e3438f5cf31e90f45e79710f0b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba73d3ec3f929ff18665087076291ac" category="list-text">요약.</block>
  <block id="4f92fa99421beeb9f74ee7613de52706" category="paragraph"><block ref="4f92fa99421beeb9f74ee7613de52706" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3594f2789840eda9633139ca530384a" category="section-title">Oracle에 대한 데이터베이스 로그 백업 정책을 생성합니다</block>
  <block id="be763ec2afcb0358426bb0abcae4dd60" category="list-text">데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인하고 설정을 클릭한 다음 정책을 클릭합니다.</block>
  <block id="b0e663a3d363868d6c71ab9ec37940c6" category="list-text">새로 만들기 를 클릭하여 새 백업 정책 생성 워크플로우를 시작하거나 수정할 기존 정책을 선택합니다.</block>
  <block id="fa2687f5a5fbedb43745f649a2e11950" category="paragraph"><block ref="fa2687f5a5fbedb43745f649a2e11950" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0938f6574b189bdac27cdd92abc521c5" category="paragraph"><block ref="0938f6574b189bdac27cdd92abc521c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59480846ec23463481d361bf3026235e" category="list-text">로그 보존 기간을 설정합니다.</block>
  <block id="c8df578fbf71151edda735bc81e8511c" category="paragraph"><block ref="c8df578fbf71151edda735bc81e8511c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04ba33c0584145006ca637b4556aa919" category="list-text">퍼블릭 클라우드의 2차 위치에 복제</block>
  <block id="fdbe42a8484a3e984e4aacb6a31cccef" category="paragraph"><block ref="fdbe42a8484a3e984e4aacb6a31cccef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab9406cbd3a8f082700523fdac8a0c1d" category="list-text">로그 백업 전후에 실행할 선택적 스크립트를 지정합니다.</block>
  <block id="5b04423521e56720f1f5d0291db584ef" category="paragraph"><block ref="5b04423521e56720f1f5d0291db584ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4b55e05a9ae89fe14377b98bc8a8166" category="list-text">백업 검증 스크립트를 지정합니다.</block>
  <block id="c4dc219fd9466ab86c22ac8e859384ea" category="paragraph"><block ref="c4dc219fd9466ab86c22ac8e859384ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2564f2d008c62044da1b7f7397252edf" category="paragraph"><block ref="2564f2d008c62044da1b7f7397252edf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe147647227dfec6603bc76daf30463e" category="section-title">SQL에 대한 전체 데이터베이스 백업 정책을 생성합니다</block>
  <block id="fa726a7e85857bee77ace96dcf7e5316" category="paragraph"><block ref="fa726a7e85857bee77ace96dcf7e5316" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce2168daff0c9b1a74e59d999d6ead44" category="paragraph"><block ref="ce2168daff0c9b1a74e59d999d6ead44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30637cfd5a5cc820d6bc4116fccfff7e" category="list-text">백업 옵션 및 예약 빈도를 정의합니다. 가용성 그룹으로 구성된 SQL Server의 경우 기본 백업 복제본을 설정할 수 있습니다.</block>
  <block id="b520dcfd25c4b29395bb9b12ac643bb2" category="paragraph"><block ref="b520dcfd25c4b29395bb9b12ac643bb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f74ada8393aecd40e892de04b5b30f8" category="list-text">백업 보존 기간을 설정합니다.</block>
  <block id="4ade95d8122243cda1455b04504d3367" category="paragraph"><block ref="4ade95d8122243cda1455b04504d3367" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1a67a80a7ad9403781b210983ea778d" category="list-text">클라우드의 2차 위치에 백업 복사본을 복제할 수 있습니다.</block>
  <block id="caf8324e53d9bb41b3ecb64f3e3b7dda" category="paragraph"><block ref="caf8324e53d9bb41b3ecb64f3e3b7dda" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17b7b360fc2163537795a34cd8d14d6a" category="list-text">백업 작업 전후에 실행할 선택적 스크립트를 지정합니다.</block>
  <block id="abbc7de57d2b0d5d1c462b7513199253" category="paragraph"><block ref="abbc7de57d2b0d5d1c462b7513199253" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb836d972496d965dd2170ed1480917b" category="list-text">백업 확인을 실행할 옵션을 지정합니다.</block>
  <block id="b4dd01df6b310e6b0814328a86bd6ed6" category="paragraph"><block ref="b4dd01df6b310e6b0814328a86bd6ed6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67cfb8548ccb78172db31d7af494fa02" category="paragraph"><block ref="67cfb8548ccb78172db31d7af494fa02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b67ed2348002e614d5a35151577632" category="section-title">SQL에 대한 데이터베이스 로그 백업 정책을 생성합니다.</block>
  <block id="b405195aec7cf62440373fcdc490dec6" category="list-text">데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인하고 설정 &gt; 정책 을 클릭한 다음 새로 만들기 를 클릭하여 새 정책 생성 워크플로를 시작합니다.</block>
  <block id="c236030076b67936a7c1c11d49408838" category="paragraph"><block ref="c236030076b67936a7c1c11d49408838" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acdaf46fc90606d68f3f2b52cca5e95b" category="list-text">로그 백업 옵션 및 스케줄 빈도를 정의합니다. 가용성 그룹으로 구성된 SQL Server의 경우 기본 백업 복제본을 설정할 수 있습니다.</block>
  <block id="19ab604707a9384fa4883cedd5a525f9" category="paragraph"><block ref="19ab604707a9384fa4883cedd5a525f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da00d968a5d810d846ddc815b8f405a4" category="list-text">SQL Server 데이터 백업 정책은 로그 백업 보존을 정의합니다. 여기서 기본값을 사용합니다.</block>
  <block id="783828e5ae6dcfd713966e7301831296" category="paragraph"><block ref="783828e5ae6dcfd713966e7301831296" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d04d89062d3ed67bbc9c4aee35bdba7f" category="list-text">클라우드의 2차 사이트에 로그 백업 복제를 설정합니다.</block>
  <block id="b1968bd01bc5c402dcd27c99ce6326cc" category="paragraph"><block ref="b1968bd01bc5c402dcd27c99ce6326cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30c50cf9d6726341a29a3caf97dc84e8" category="paragraph"><block ref="30c50cf9d6726341a29a3caf97dc84e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4d9b291b4ffaddb50c99313e530077f" category="paragraph"><block ref="c4d9b291b4ffaddb50c99313e530077f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f28f6c36698b3a4cd47cbeead15eddf2" category="section-title">데이터베이스를 보호하기 위해 백업 정책을 구현합니다</block>
  <block id="37b889cc1b57f66ae9018b6eacb891ba" category="paragraph">SnapCenter는 리소스 그룹을 사용하여 서버에서 호스팅되는 여러 데이터베이스, 동일한 스토리지 볼륨을 공유하는 데이터베이스, 비즈니스 애플리케이션을 지원하는 여러 데이터베이스 등 데이터베이스 리소스의 논리적 그룹으로 데이터베이스를 백업합니다. 단일 데이터베이스를 보호하면 고유한 리소스 그룹이 만들어집니다. 다음 절차에서는 Oracle 및 SQL Server 데이터베이스를 보호하기 위해 섹션 7에서 만든 백업 정책을 구현하는 방법을 보여 줍니다.</block>
  <block id="0603dbbe978e4cd3ee1c45ba96a1aa6f" category="section-title">Oracle의 전체 백업을 위한 리소스 그룹을 생성합니다</block>
  <block id="5f4e02f34bcd7993867c4b3297a171d0" category="list-text">데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인하고 리소스 탭으로 이동합니다. 보기 드롭다운 목록에서 데이터베이스 또는 리소스 그룹을 선택하여 리소스 그룹 만들기 워크플로를 시작합니다.</block>
  <block id="6eac6f96ac8d968dfec8184d16a73d43" category="paragraph"><block ref="6eac6f96ac8d968dfec8184d16a73d43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="98dcf41bcde9cb6c4235a6a7dfe69346" category="list-text">리소스 그룹의 이름과 태그를 입력합니다. 스냅샷 복사본의 명명 형식을 정의하고 구성된 경우 중복 아카이브 로그 대상을 건너뛸 수 있습니다.</block>
  <block id="a75ba82042ae54dd2e68cf6c7a26614c" category="paragraph"><block ref="a75ba82042ae54dd2e68cf6c7a26614c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0cd85a82e6f02b779006b158b9c5f828" category="list-text">리소스 그룹에 데이터베이스 리소스를 추가합니다.</block>
  <block id="3836a8be1f86b6658a7fa6b180e4a72d" category="paragraph"><block ref="3836a8be1f86b6658a7fa6b180e4a72d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cee52cb6702e7590fbef45eccc8fb2df" category="list-text">드롭다운 목록에서 섹션 7에 생성된 전체 백업 정책을 선택합니다.</block>
  <block id="af900bffdda986bc1db955ae78832742" category="paragraph"><block ref="af900bffdda986bc1db955ae78832742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fe872cd84ea2e9051770379e63f9caf" category="list-text">(+) 기호를 클릭하여 원하는 백업 일정을 구성합니다.</block>
  <block id="9da504fd8ab60cfcc873608530cf5d56" category="paragraph"><block ref="9da504fd8ab60cfcc873608530cf5d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdc27a4c5d48dbfc04f81ecac85acd64" category="list-text">Load Locators(로케이터 로드) 를 클릭하여 소스 및 대상 볼륨을 로드합니다.</block>
  <block id="7242164857e43688f8a7bec97559c36e" category="paragraph"><block ref="7242164857e43688f8a7bec97559c36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a752afaf144d06159ca3eec8bb23455f" category="list-text">필요한 경우 이메일 알림에 사용할 SMTP 서버를 구성합니다.</block>
  <block id="b612dc8868902cf8fbf2b1024ad94e65" category="paragraph"><block ref="b612dc8868902cf8fbf2b1024ad94e65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95633243861715786b64e1554b629435" category="paragraph"><block ref="95633243861715786b64e1554b629435" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f7192b9766e6f09c261f3ca3d3bddc8" category="section-title">Oracle의 로그 백업을 위한 리소스 그룹을 생성합니다</block>
  <block id="1a0cd5de7c84ddbf632838dd9f510d37" category="paragraph"><block ref="1a0cd5de7c84ddbf632838dd9f510d37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0ad3d9537c50952c04b71be3f9d4579" category="paragraph"><block ref="f0ad3d9537c50952c04b71be3f9d4579" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c33c31714f671e112fbe52b660d3e7a4" category="paragraph"><block ref="c33c31714f671e112fbe52b660d3e7a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03955b73285eab0d68e90c627da9726d" category="list-text">드롭다운 목록에서 섹션 7에 생성된 로그 백업 정책을 선택합니다.</block>
  <block id="6286629570d2ca91cf6860e7da6e9073" category="paragraph"><block ref="6286629570d2ca91cf6860e7da6e9073" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88c73129e9a418955658ce5c48d9d8b5" category="list-text">(+) 기호를 클릭하여 원하는 백업 일정을 구성합니다.</block>
  <block id="8cdd30063d988671ffa9240fe171b1ce" category="paragraph"><block ref="8cdd30063d988671ffa9240fe171b1ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eacfd6f10777b8dfb41199e4d4dfa915" category="list-text">백업 검증이 구성된 경우 여기에 표시됩니다.</block>
  <block id="69911c1794125b768effca94c8153987" category="paragraph"><block ref="69911c1794125b768effca94c8153987" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a27fac4b1d49d5468930a56c3a6de56" category="list-text">필요한 경우 e-메일 알림을 위한 SMTP 서버를 구성합니다.</block>
  <block id="fd540644538dcedf1f6543455447728f" category="paragraph"><block ref="fd540644538dcedf1f6543455447728f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="554dbe35f6afa38e8232497f5d05d1c1" category="paragraph"><block ref="554dbe35f6afa38e8232497f5d05d1c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf688c7a95f421447e84a47fd03f3aa2" category="section-title">SQL Server의 전체 백업을 위한 리소스 그룹을 생성합니다</block>
  <block id="d08ef097ee33c4a3506183adeb51c5e7" category="list-text">데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인하고 리소스 탭으로 이동합니다. 보기 드롭다운 목록에서 데이터베이스 또는 리소스 그룹을 선택하여 리소스 그룹 만들기 워크플로를 시작합니다. 리소스 그룹의 이름과 태그를 입력합니다. 스냅샷 복사본의 명명 형식을 정의할 수 있습니다.</block>
  <block id="87d2630813d214672697efc01974d64e" category="paragraph"><block ref="87d2630813d214672697efc01974d64e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ace5324d60cb3faa1863efd675149" category="list-text">백업할 데이터베이스 리소스를 선택합니다.</block>
  <block id="15330fe5b8f32032bd3b30c091d7dc4b" category="paragraph"><block ref="15330fe5b8f32032bd3b30c091d7dc4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fc1974f486effa4a60bf216e63a88d5" category="list-text">섹션 7에서 생성한 전체 SQL 백업 정책을 선택합니다.</block>
  <block id="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="paragraph"><block ref="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b70beeb570488ba753a620378cacd8" category="list-text">백업 빈도와 정확한 백업 시간을 추가합니다.</block>
  <block id="8fa0a3897bc03e9b1653d17308464031" category="paragraph"><block ref="8fa0a3897bc03e9b1653d17308464031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49252579bd8140847f4bbac20ef89b07" category="list-text">백업 확인을 수행할 경우 보조 백업에 대한 검증 서버를 선택합니다. Load Locator를 클릭하여 보조 스토리지 위치를 채웁니다.</block>
  <block id="355e5eb56524b7365674014ea5868ee6" category="paragraph"><block ref="355e5eb56524b7365674014ea5868ee6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19e819eadb96ee5769ff4c6309352a62" category="paragraph"><block ref="19e819eadb96ee5769ff4c6309352a62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0be278d93ec2e64895e31bf440c54b98" category="paragraph"><block ref="0be278d93ec2e64895e31bf440c54b98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4dd921984d3a8a89e7df5c97875b923" category="section-title">SQL Server의 로그 백업을 위한 리소스 그룹을 생성합니다</block>
  <block id="4e94ca9b995e68691b4e67b82b9f5bce" category="list-text">데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인하고 리소스 탭으로 이동합니다. 보기 드롭다운 목록에서 데이터베이스 또는 리소스 그룹을 선택하여 리소스 그룹 만들기 워크플로를 시작합니다. 리소스 그룹의 이름과 태그를 입력합니다. 스냅샷 복사본의 명명 형식을 정의할 수 있습니다.</block>
  <block id="4e71263f0aec815017fd21a22ddb87d6" category="paragraph"><block ref="4e71263f0aec815017fd21a22ddb87d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="013faf9f6cde83814469c6d583e10702" category="paragraph"><block ref="013faf9f6cde83814469c6d583e10702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23e15d7c127e66b1da1d72072a29e9eb" category="list-text">섹션 7에서 생성한 SQL 로그 백업 정책을 선택합니다.</block>
  <block id="52a8553e4c33eb8353d56286d3845b28" category="paragraph"><block ref="52a8553e4c33eb8353d56286d3845b28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e7cac98c16b45d7e4ebec8786b8fda1" category="list-text">백업 빈도와 정확한 백업 시간을 추가합니다.</block>
  <block id="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="paragraph"><block ref="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68398b6746dde91649e96505d97acc40" category="list-text">백업 확인을 수행할 경우 보조 백업에 대한 검증 서버를 선택합니다. Load Locator를 클릭하여 보조 스토리지 위치를 채웁니다.</block>
  <block id="3bde998a2436b40589b20d91a713d3ee" category="paragraph"><block ref="3bde998a2436b40589b20d91a713d3ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80000e8cb7742af4686df786fdf38249" category="paragraph"><block ref="80000e8cb7742af4686df786fdf38249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d32fb038efa6b409f8dedd0e02a10f26" category="paragraph"><block ref="d32fb038efa6b409f8dedd0e02a10f26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c72629a46c2e88cf7f6a012167bb16" category="section-title">9.백업 검증</block>
  <block id="d1c55c296cbdaa8d88eda765a6158b62" category="paragraph">데이터베이스 리소스 보호를 위해 데이터베이스 백업 리소스 그룹을 생성한 후에는 미리 정의된 일정에 따라 백업 작업이 실행됩니다. Monitor 탭에서 작업 실행 상태를 확인합니다.</block>
  <block id="5f9af2a4e435e2b39c27f43b580d6d20" category="paragraph"><block ref="5f9af2a4e435e2b39c27f43b580d6d20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57882e224a8cbe8f694da9b1d8fa503e" category="paragraph">리소스 탭으로 이동하고 데이터베이스 이름을 클릭하여 데이터베이스 백업에 대한 세부 정보를 확인하고, 로컬 복사본과 미러 복사본 간에 전환하여 스냅샷 백업이 퍼블릭 클라우드의 2차 위치에 복제되었는지 확인합니다.</block>
  <block id="f9b40afbdb387dd32b8523c95080a898" category="paragraph"><block ref="f9b40afbdb387dd32b8523c95080a898" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28268d417882b5cf7a3d3ee3a15834c8" category="paragraph">이때 운영 장애가 발생할 경우 클라우드의 데이터베이스 백업 복사본을 클론 복제하여 개발/테스트 프로세스를 실행하거나 재해 복구를 수행할 수 있습니다.</block>
  <block id="78b29bbf3f07a44b62307ce90b34904e" category="inline-link-macro">다음:AWS 퍼블릭 클라우드 시작하기</block>
  <block id="7d32c0298884bcc4c0211357748d0e6e" category="paragraph"><block ref="7d32c0298884bcc4c0211357748d0e6e" category="inline-link-macro-rx"></block></block>
  <block id="def8ebf26c2dec5f6af5a00893fae037" category="paragraph">이 솔루션은 AWX/Tower 환경 또는 Ansible 제어 호스트의 CLI에서 실행되도록 설계되었습니다.</block>
  <block id="8ca0a52cf9938328875e0a8803ae71dd" category="list-text">작업 템플릿은 ONTAP_config, Linux_config 및 Oracle_config에 대한 태그를 지정하여 3단계로 실행됩니다.</block>
  <block id="da3d0d670ace8a327170aa25ee29f272" category="section-title">Ansible 제어 호스트를 통해 CLI</block>
  <block id="6a5f01bc22c397ee84e04e48c178e980" category="inline-link-macro">RHEL 7/8 또는 CentOS 7/8 에 대해서는 여기를 클릭하십시오</block>
  <block id="7946c3996884ee105962c5334bfd9fef" category="inline-link-macro">Ubuntu/Debian의 경우 여기를 참조하십시오</block>
  <block id="f5344fe4d88d29ee79ba6110f60cfa9b" category="list-text">Ansible 제어 호스트로 사용할 수 있도록 Linux 호스트를 구성합니다<block ref="8688caf90b0dc445f61be35cbf93ed1a" category="inline-link-macro-rx"></block>, 또는<block ref="2b00e81c1e240a58c4df0e850699511b" category="inline-link-macro-rx"></block></block>
  <block id="28e934ddab7714830f8afe8d3b641dc9" category="list-text">Ansible 제어 호스트를 구성한 후 Ansible 자동화 저장소를 클론 복제할 수 있습니다.</block>
  <block id="f667be8dac02593d217a02ac5bfb18de" category="list-text">ONTAP 클러스터 관리 및 Oracle 서버 관리 IP의 IP 및/또는 호스트 이름으로 hosts 파일을 편집합니다.</block>
  <block id="95bd15e6b4a109de659c54c331c06284" category="list-text">해당 환경에 맞는 변수를 작성하고 복사하여 VAR.yml 파일에 붙여 넣습니다.</block>
  <block id="ca548be3e5f238d32286d43dc4c89f7b" category="list-text">각 Oracle 호스트에는 호스트별 변수를 포함하는 호스트 이름으로 식별되는 변수 파일이 있습니다.</block>
  <block id="87192ebbcab92216d25fd694a282971d" category="list-text">모든 변수 파일이 완료된 후 'ONTAP_config', 'linux_config', 'oracle_config'에 대한 태그를 지정하여 3단계로 플레이북을 실행할 수 있습니다.</block>
  <block id="eebc1357e7d1e88ed4e4908d5ae86c0b" category="cell">Ansible 제어 호스트가 될 AWX/Tower 또는 Linux 호스트</block>
  <block id="0a928fe81d89083ed303ea3d9f1af8c9" category="cell">ONTAP 버전 9.3-9.7</block>
  <block id="515f291f3ecc550c5d13cf31fadba91d" category="cell">Oracle 서버에 Oracle 설치 파일</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">역할</block>
  <block id="9bb642814808cd0cab510ddfb9e5969c" category="cell">ONTAP_구성 * 을 참조하십시오</block>
  <block id="79b814c8267c6b7822e78ab4624db8e0" category="cell">Oracle용 NFS 기반 SVM 생성</block>
  <block id="0c981d6164da0d8e69cdb199966316b0" category="cell">엑스포트 정책 생성</block>
  <block id="99179ac01bbb0236fc540871377c55c4" category="cell">Oracle의 볼륨 생성</block>
  <block id="db738705829d97db1e287ad8ea9e5400" category="cell">NFS LIF 생성</block>
  <block id="089c4c184b079d771501d8ceb0f3bb05" category="cell">Linux_config *</block>
  <block id="3ea572544d30a39d236496578f980d13" category="cell">마운트 지점을 생성하고 NFS 볼륨을 마운트합니다</block>
  <block id="db6c0f994cc39fbf66d58eea6c627e6a" category="cell">NFS 마운트를 확인합니다</block>
  <block id="6a882e7966e7869ab1d2112a0b1c0074" category="cell">OS별 구성</block>
  <block id="6e6d41d1398fafd8809de20e831c9ce3" category="cell">Oracle 디렉토리를 생성합니다</block>
  <block id="6f965a5d44e1653dac9825f465f71c84" category="cell">HugePages를 구성합니다</block>
  <block id="be577868fe0712b7bbb6d5cb5eae613c" category="cell">SELinux 및 방화벽 데몬을 해제합니다</block>
  <block id="bb6f16330211bf24baa83db38b11e4a9" category="cell">시간 기록 서비스를 활성화하고 시작합니다</block>
  <block id="e9e5cefa281d2c696aac82ef9c756f51" category="cell">파일 설명자 하드 제한값을 늘립니다</block>
  <block id="a4acc779f882208c081f943aedfeab5c" category="cell">PAM.d 세션 파일을 생성합니다</block>
  <block id="d03021f9e02b9fa9ebac591ad4bfea08" category="cell">* oracle_config *</block>
  <block id="5e706781d4bf141c80e249a244179235" category="cell">Oracle 소프트웨어 설치</block>
  <block id="1a98fce6d77de1126bf3cb8247747621" category="cell">Oracle Listener를 생성합니다</block>
  <block id="841df7bfbef212936073c6d261d4dba9" category="cell">Oracle 데이터베이스를 생성합니다</block>
  <block id="845a6e024025bb13aafdc167511e5e7d" category="cell">Oracle 환경 구성</block>
  <block id="666113957f940ba4319b4f0d9c3e86c0" category="cell">PDB 상태를 저장합니다</block>
  <block id="264bca6ddd5a16346460d9c21e8f926d" category="cell">인스턴스 아카이브 모드를 활성화합니다</block>
  <block id="620ca5ae835411d2031ca0fdbbbe61a1" category="cell">DNFS 클라이언트를 활성화합니다</block>
  <block id="4d7e6c9b84f6f86cf4817262ad424eeb" category="cell">OS 재부팅 간에 데이터베이스 자동 시작 및 종료를 활성화합니다</block>
  <block id="ebda2606845855cc07ce0ce15ecf8a00" category="paragraph">자동화를 간소화하기 위해 필요한 많은 Oracle 구축 매개 변수를 기본값으로 사전 설정하였습니다. 일반적으로 대부분의 배포에서 기본 매개 변수를 변경할 필요는 없습니다. 고급 사용자는 기본 매개 변수를 주의 깊게 변경할 수 있습니다. 기본 매개 변수는 각 역할 폴더의 defaults 디렉토리에 있습니다.</block>
  <block id="452eff11ca6d680a279a3e81b8dc8974" category="section-title">배포 지침</block>
  <block id="1cf7ad9cd74067dd3f4aee3c1690ea32" category="paragraph">시작하기 전에 다음 Oracle 설치 및 패치 파일을 다운로드하여 구축할 각 DB 서버의 모든 사용자에 대한 읽기, 쓰기 및 실행 액세스 권한이 있는 '/tmp/archive' 디렉토리에 배치합니다. 자동화 작업은 Oracle 설치 및 구성을 위해 특정 디렉토리에 명명된 설치 파일을 찾습니다.</block>
  <block id="5abe869dd828ac1e4527f07db79841a8" category="inline-link-macro">자세한 AWX/Tower 배치 절차를 보려면 여기를 클릭하십시오</block>
  <block id="c3bcf861ccc9247a7c0a9b4749747e4e" category="inline-link-macro">CLI 배포는 여기에서 확인할 수 있습니다</block>
  <block id="f867ea86471dd6849f2c840cf13d1536" category="paragraph">준비가 되면 를 클릭합니다 <block ref="0ecf76284fbf596cdd030af085c16a3b" category="inline-link-macro-rx"></block> 또는 <block ref="42cd9508ebf775e8df0efba80be76af7" category="inline-link-macro-rx"></block>.</block>
  <block id="8f7280c86689be0a39cdf74aa673040d" category="summary">이 솔루션은 하이브리드 클라우드 설정에서 개발/테스트 및 재해 복구 작업에 널리 사용되는 모든 퍼블릭 클라우드에 버스트가 가능한 온프레미스 운영 데이터베이스를 지원하도록 설계되었습니다.</block>
  <block id="132f2888eb2cfdeef2730212f50c53e3" category="doc">SnapCenter 요구 사항</block>
  <block id="e2a7d0854ef572e10255339732bb005d" category="inline-link-macro">이전: 솔루션 아키텍처.</block>
  <block id="b10927905ed5379ba0d73333abdbe06d" category="paragraph"><block ref="b10927905ed5379ba0d73333abdbe06d" category="inline-link-macro-rx"></block></block>
  <block id="bc3a731533b339cd62ba7f7149313e3b" category="paragraph">이 솔루션은 현재 SnapCenter에서 지원하는 모든 데이터베이스를 지원하지만 Oracle 및 SQL Server 데이터베이스만 여기에 나와 있습니다. 이 솔루션은 베어 메탈 워크로드도 지원되지만 가상화된 데이터베이스 워크로드에서 검증을 받았습니다.</block>
  <block id="185b108b21dccef917f415be6026c91c" category="paragraph">ONTAP 스토리지 클러스터에서 DB 호스트에 제공된 DB 볼륨이 있는 운영 데이터베이스 서버가 사내에서 호스팅된다고 가정합니다. SnapCenter 소프트웨어는 데이터베이스 백업 및 클라우드 데이터 복제를 위해 사내에 설치됩니다. Ansible 컨트롤러를 사용할 것을 권장하지만, 퍼블릭 클라우드의 개발/테스트 인스턴스 또는 대기 DR 인스턴스와 동기화되는 데이터베이스 배포 자동화 또는 OS 커널 및 DB 구성에는 필요하지 않습니다.</block>
  <block id="47099d9ea153f8abfa5b6b70da253b3a" category="cell">* 사내 *</block>
  <block id="d36407241494bfc1e84614ad1b0dd6a4" category="cell">SnapCenter에서 지원하는 모든 데이터베이스 및 버전</block>
  <block id="8c8c8ca7a4093a1210412a3a5e5ad55f" category="cell">SnapCenter v4.4 이상</block>
  <block id="9d9ebf67dab68c3c892de99e981039cf" category="cell">Ansible v2.09 이상</block>
  <block id="62dd4f48e99b13c8a00fbaba684f9592" category="cell">ONTAP 클러스터 9.x</block>
  <block id="d0fdc58e1e05d6cbc8b1beb072bfa235" category="cell">인터클러스터 LIF가 구성되었습니다</block>
  <block id="7135df562bcb25bfdf20e4317b923b88" category="cell">온프레미스에서 클라우드 VPC로 연결(VPN, 상호 연결 등)</block>
  <block id="8c27863f5ffd0e66a9304eaca2e47fde" category="cell">네트워킹 포트 open-ssh 22-tcp 8145, 8146, 10000, 11104, 11105</block>
  <block id="bcb9f3419f724f768e30956a4427261d" category="cell">* 클라우드-AWS *</block>
  <block id="61c90d44785278f980592f082ef500f1" category="inline-link">Cloud Manager 커넥터</block>
  <block id="97bc5062dceccb6827b1e3f0522035f0" category="cell"><block ref="97bc5062dceccb6827b1e3f0522035f0" category="inline-link-rx"></block></block>
  <block id="117bdbda976fe8b3212bc3b6327a0a1b" category="inline-link">Cloud Volumes ONTAP</block>
  <block id="2f077494ceff1f33085c5b163c3673b3" category="cell"><block ref="2f077494ceff1f33085c5b163c3673b3" category="inline-link-rx"></block></block>
  <block id="59b2c9424963f98d73ec69c59dde54cb" category="cell">DB OS EC2 인스턴스를 온프레미스에 일치시킵니다</block>
  <block id="e26786a16da88ee829ab76c48fd3b003" category="cell">* 클라우드 - Azure *</block>
  <block id="c2f8674b07907f393b67a3f9e98d3d56" category="cell"><block ref="c2f8674b07907f393b67a3f9e98d3d56" category="inline-link-rx"></block></block>
  <block id="a8dd724647657a383eb37fd8775ec1a9" category="cell"><block ref="a8dd724647657a383eb37fd8775ec1a9" category="inline-link-rx"></block></block>
  <block id="8bede1f0e559918be01f0646b75b4257" category="cell">DB OS Azure 가상 시스템을 온프레미스에 일치시킵니다</block>
  <block id="b2a454fb4ff03b84162c59d674fdae25" category="cell">* Cloud-GCP *</block>
  <block id="af072236983e991ab34e773871b10236" category="cell"><block ref="af072236983e991ab34e773871b10236" category="inline-link-rx"></block></block>
  <block id="499477cf7953707f63a1b1313c8c065a" category="cell"><block ref="499477cf7953707f63a1b1313c8c065a" category="inline-link-rx"></block></block>
  <block id="2900c5e1ee191606f20d007194e70edf" category="cell">DB OS Google Compute Engine 인스턴스를 온프레미스에 일치시킵니다</block>
  <block id="126b29c0beff0884077277115103a374" category="inline-link-macro">다음: 사전 요구 사항 구성.</block>
  <block id="a6d027dea0e97ba248528210d36e5475" category="paragraph"><block ref="a6d027dea0e97ba248528210d36e5475" category="inline-link-macro-rx"></block></block>
  <block id="d798c6a829fee4b3d8316144e8769e91" category="paragraph">조직은 효율성을 높이고, 구현을 앞당기고, 수동 작업을 줄이기 위해 환경을 자동화하고 있습니다. Ansible과 같은 구성 관리 툴을 사용하여 엔터프라이즈 데이터베이스 운영을 간소화하고 있습니다. 이 솔루션에서는 Ansible을 사용하여 NetApp ONTAP을 통해 Oracle의 데이터 보호를 자동화하는 방법을 보여줍니다. 스토리지 관리자, 시스템 관리자 및 DBA가 오프사이트 데이터 센터 또는 퍼블릭 클라우드에 대한 데이터 복제를 일관되고 신속하게 설정할 수 있도록 함으로써 다음과 같은 이점을 얻을 수 있습니다.</block>
  <block id="1d4694b7ed077df8b2c51d4ef956ce0c" category="list-text">클러스터 간 복제, CVO 인스턴스화 및 Oracle 데이터베이스 복구 구성 시간 단축</block>
  <block id="60bcf8682ddc3583a74e6cd2d95e1ccb" category="list-text">DR 시나리오의 테스트를 쉽게 수행할 수 있는 데이터베이스 복구 워크플로우를 제공합니다.</block>
  <block id="7fa4d3428dbef9829f6325b288c071bc" category="section-title">온프레미스에서 온프레미스 복제까지</block>
  <block id="911a9e8dd85bfeeba31c1ed049e41e1c" category="list-text">소스와 대상에 대한 인터클러스터 LIF를 만듭니다</block>
  <block id="2f4eb56dd9301fc33f559b4345b90eb3" category="list-text">클러스터 및 SVM 피어링 설정</block>
  <block id="2b71f4136dce37491ef0f319f5d1fbd9" category="list-text">Oracle 볼륨의 SnapMirror를 생성하고 초기화합니다</block>
  <block id="20f4a46f5b12b0533f7a2268c4c2bf41" category="list-text">Oracle 바이너리, 데이터베이스 및 로그용 AWX/Tower를 통해 복제 일정을 생성합니다</block>
  <block id="6ef1c2ae7c9ca61a54d88de28349a772" category="list-text">대상에서 Oracle DB를 복원하고 데이터베이스를 온라인 상태로 전환합니다</block>
  <block id="f4ec61d9ffa147f621f854609523a0fb" category="section-title">온프레미스에서 AWS의 CVO로</block>
  <block id="3f155aa6a9345b3e25f3bb44ecccfc0a" category="list-text">AWS 커넥터를 생성합니다</block>
  <block id="1531cb3c2d4db27dcd3bfa2ad4711ec5" category="list-text">AWS에서 CVO 인스턴스를 생성합니다</block>
  <block id="2f159b717f78e9925b219e87cbd20f9a" category="list-text">Cloud Manager에 온프레미스 클러스터 추가</block>
  <block id="df16a1e23dbbcc2f19f07ab1af741617" category="list-text">소스에 대한 인터클러스터 LIF를 만듭니다</block>
  <block id="d1f660bb2bff2f31a46c751115155999" category="list-text">1부: TBD</block>
  <block id="421b47ffd946ca083b65cd668c6b17e6" category="list-text">비디오</block>
  <block id="1ee2253d8fe666dbea54ab3648a62511" category="list-text">2부: TBD</block>
  <block id="68eff5f8d34b801d40ab55f098bc6478" category="inline-link-macro">여기 에서 솔루션 시작 을 확인하십시오</block>
  <block id="e5dec240e8be4a30564a7e8ddc0d568a" category="list-text">준비가 되면 를 클릭합니다 <block ref="a171481e1cde5211da297c03090cb7ce" category="inline-link-macro-rx"></block>.</block>
  <block id="d89002d36151bd13d2bba69f3533ee5f" category="summary">이 솔루션은 NetApp 현장 및 고객에게 NetApp SnapCenter GUI 기반 툴과 퍼블릭 클라우드의 NetApp 스토리지 서비스 CVO를 사용하여 데이터베이스를 하이브리드 클라우드 환경으로 구성, 운영 및 마이그레이션하는 데 필요한 지침과 지침을 제공합니다.</block>
  <block id="8269707c3930f3cbcd49193be33bc125" category="doc">TR-4908: SnapCenter를 지원하는 하이브리드 클라우드 데이터베이스 솔루션 개요</block>
  <block id="7c4d94e1b484fb577b0aeafbec788ea1" category="paragraph">NetApp의 Felix Melligan, Alan Cao</block>
  <block id="268a30b4d0cad062acd42967ce0fab50" category="paragraph">이 솔루션은 NetApp 현장 및 고객에게 NetApp SnapCenter GUI 기반 툴과 퍼블릭 클라우드의 NetApp 스토리지 서비스 CVO를 사용하여 데이터베이스를 하이브리드 클라우드 환경으로 구성, 운영 및 마이그레이션하는 데 필요한 지침과 사용 사례를 제공합니다.</block>
  <block id="e88a2467c8ad8bf481854b1a745a875b" category="list-text">하이브리드 클라우드에서 데이터베이스 개발/테스트 작업</block>
  <block id="3c9552536897a076f75b078a5e2a3703" category="list-text">하이브리드 클라우드에서 데이터베이스 재해 복구</block>
  <block id="a1ac690c228caf22f3228d3a4d8b5cab" category="paragraph">오늘날 많은 엔터프라이즈 데이터베이스는 성능, 보안 및/또는 기타 이유로 여전히 프라이빗 기업 데이터 센터에 있습니다. 기업에서는 이 하이브리드 클라우드 데이터베이스 솔루션을 사용하여 기본 데이터베이스를 사이트에서 운영하는 동시에 개발/테스트 데이터베이스 운영뿐 아니라 재해 복구에 퍼블릭 클라우드를 사용하여 라이센스 및 운영 비용을 절감할 수 있습니다.</block>
  <block id="d900d125b3be40bcb79452d624c38561" category="paragraph">Oracle, SQL Server, SAP HANA 등 많은 엔터프라이즈 데이터베이스 높은 라이센스 및 운영 비용 수행 많은 고객은 개발, 테스트, 운영 또는 재해 복구에 코어를 사용하는지에 관계없이 데이터베이스 환경의 컴퓨팅 코어 수를 기준으로 1회 라이센스 비용 및 연간 지원 비용을 지불합니다. 이러한 환경 중 대부분은 애플리케이션 라이프사이클 동안 완전히 활용하지 못할 수 있습니다.</block>
  <block id="1f49cc83c5c3735827e3353f320f5f7f" category="paragraph">이 솔루션은 고객이 개발, 테스트 또는 재해 복구 전용 데이터베이스 환경을 클라우드로 이동하여 라이센스 대상 코어 수를 잠재적으로 줄일 수 있는 옵션을 제공합니다. 퍼블릭 클라우드의 확장, 이중화, 고가용성, 소비 기반 청구 모델을 활용하면 애플리케이션 사용성이나 가용성에 영향을 주지 않으면서 라이센스 및 운영 비용을 크게 절감할 수 있습니다.</block>
  <block id="1a197dd926608052c7d43edfd09556fa" category="paragraph">NetApp의 용량 기반 CVO 라이센스 모델은 잠재적인 데이터베이스 라이센스 비용 절감 외에도, 고객이 경쟁 스토리지 서비스에서 제공되지 않는 높은 수준의 데이터베이스 관리 효율성을 통해 GB당 스토리지 비용을 절감할 수 있도록 지원합니다. 다음 차트에는 퍼블릭 클라우드에서 사용 가능한 주요 스토리지 서비스의 스토리지 비용 비교가 나와 있습니다.</block>
  <block id="810fba7bc9a3829eb522ebbc24326a08" category="paragraph"><block ref="810fba7bc9a3829eb522ebbc24326a08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e222eb27a0002f2960d1cf1e14bbf7d" category="paragraph">이 솔루션은 SnapCenter GUI 기반 소프트웨어 툴과 NetApp SnapMirror 기술을 사용하여 하이브리드 클라우드 데이터베이스 운영을 쉽게 설정, 구현, 운영할 수 있다는 것을 보여 줍니다.</block>
  <block id="26cc8c416b5c9fd6bec3dc68e6f2f0c8" category="paragraph">다음 비디오에서는 SnapCenter의 실제 작동 방법을 보여줍니다.</block>
  <block id="edc6673fe24c4867029921bbe72f25cb" category="inline-link">SnapCenter를 사용하여 하이브리드 클라우드에서 Oracle 데이터베이스 백업</block>
  <block id="b10d6cd72b187359c3769fbf5ff10e4c" category="list-text"><block ref="0d160cec2141981b284cd9986321651e" category="inline-link-rx"></block></block>
  <block id="68d9033a95c0ed286c9b7e0e7454cd86" category="inline-link">SnapCenter - Oracle 데이터베이스용 AWS 클라우드에 개발/테스트 클론을 생성할 수 있습니다</block>
  <block id="da8d0116fa67f0499837675277668911" category="list-text"><block ref="da8d0116fa67f0499837675277668911" category="inline-link-rx"></block></block>
  <block id="3b04263461ad5a7b57aa872e093ec9fa" category="paragraph">이 문서의 그림에서는 CVO를 퍼블릭 클라우드의 타겟 스토리지 인스턴스로 보여 주지만, 이 솔루션은 AWS용 FSx ONTAP 스토리지 엔진의 새로운 릴리즈에서 완벽하게 검증되었습니다.</block>
  <block id="c5a6d2f45fc4352f35e95d92c804b6f2" category="paragraph">솔루션 및 사용 사례를 직접 테스트하기 위해 https://labondemand.netapp.com/lod3/labtest/request?nodeid=68761&amp;destination=lod3/testlabs[TL_AWS_004 HCoD:AWS-NW, SnapCenter(OnPrem)^]에서 NetApp Lab-On-Demand SL10680을 요청할 수 있습니다.</block>
  <block id="d31314285161c777a09609cc4fb2d07a" category="inline-link-macro">다음은 솔루션 아키텍처입니다.</block>
  <block id="0830319fc7a6b051bbb0602c2778e67c" category="paragraph"><block ref="0830319fc7a6b051bbb0602c2778e67c" category="inline-link-macro-rx"></block></block>
  <block id="9b64a6dfae1f3fa326b750c2790c79fe" category="summary">이 섹션에서는 Azure NetApp Files SMB 볼륨을 사용하는 AOAG 구성에서 SQL 데이터베이스 자산의 실시간 구축에 대해 설명합니다.</block>
  <block id="5ca1071c67ab704b04ed27747f213551" category="doc">실시간 고수준 참조 디자인</block>
  <block id="bb0357d1c0b3b8ebd31a43c9b30f3745" category="list-text">노드 수: 4</block>
  <block id="7f4f30d96e1d0a820a6962ad6ac994ee" category="list-text">데이터베이스 수: 21</block>
  <block id="f28735e3e5e57049aa575b3f0ec83c61" category="list-text">가용성 그룹 수: 4</block>
  <block id="96fb94ba9fad0b4452c212b21df61eab" category="list-text">백업 보존: 7일</block>
  <block id="a8d1485807d36562316fb8b2254bca57" category="list-text">백업 아카이브: 365일</block>
  <block id="4afa49afd4ebc3638f3e000d65825370" category="admonition">Azure NetApp Files 공유를 통해 Azure 가상 시스템에서 SQL Server와 FCI를 배포하면 데이터의 단일 복사본을 통해 비용 효율적인 모델을 제공할 수 있습니다. 이 솔루션은 파일 경로가 보조 복제본과 다를 경우 추가 파일 작업 문제를 방지할 수 있습니다.</block>
  <block id="ab030ea777250278c4f110a497eeef88" category="paragraph"><block ref="ab030ea777250278c4f110a497eeef88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4822d9597460a9166778308da312709c" category="paragraph">다음 이미지는 노드에 분산된 AOAG 내의 데이터베이스를 보여 줍니다.</block>
  <block id="af316199cc8e77dcbb6fb560cbc4c44c" category="paragraph"><block ref="af316199cc8e77dcbb6fb560cbc4c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">데이터 레이아웃</block>
  <block id="35c33dd0c5565dbdba04dc2b313d7a2e" category="paragraph">tempdb와 함께 사용자 데이터베이스 파일(.mdf) 및 사용자 데이터베이스 트랜잭션 로그 파일(.ldf)은 동일한 볼륨에 저장됩니다. 서비스 수준은 울트라입니다.</block>
  <block id="9b7d6479a15395afefc6d7f9e38a4f17" category="paragraph">이 구성은 노드 4개와 AGS 4개로 구성됩니다. 21개의 데이터베이스(동적 AX, SharePoint, RDS 연결 브로커 및 인덱싱 서비스의 일부)는 모두 Azure NetApp Files 볼륨에 저장됩니다. 데이터베이스는 AOAG 노드 간에 균형을 이루어 노드의 리소스를 효과적으로 사용합니다. AOAG 구성에 참여하는 4개의 D32 v3 인스턴스가 WSFC에 추가됩니다. 이러한 4개 노드는 Azure 가상 네트워크에 프로비저닝되며 사내의 경우 마이그레이션되지 않습니다.</block>
  <block id="09a10f0ab048cde1d7b704392ba05d9a" category="list-text">응용 프로그램 및 실행된 쿼리의 특성에 따라 로그에 더 많은 성능 및 처리량이 필요한 경우 데이터베이스 파일을 프리미엄 서비스 수준에 배치하고 로그를 Ultra 서비스 수준에 저장할 수 있습니다.</block>
  <block id="51368a236b969e288242f0b0b615cf74" category="list-text">tempdb 파일이 Azure NetApp Files에 배치된 경우 Azure NetApp Files 볼륨은 사용자 데이터베이스 파일과 분리되어야 합니다. 다음은 AOAG의 데이터베이스 파일 배포 예입니다.</block>
  <block id="2e66f3d288799e6f4235b883bb2f693c" category="list-text">스냅샷 복사본 기반 데이터 보호의 이점을 유지하려면 동일한 볼륨에 데이터와 로그 데이터를 결합하지 않는 것이 좋습니다.</block>
  <block id="1452bcdb4aeb229a2c2e503f9bbba753" category="list-text">보조 데이터베이스의 파일 경로가 해당 기본 데이터베이스의 경로와 다른 경우 기본 복제본에 대해 수행되는 추가 파일 작업이 보조 데이터베이스에서 실패할 수 있습니다. 이 문제는 공유 경로가 운영 노드와 보조 노드에서 다른 경우(컴퓨터 계정이 서로 다르기 때문에) 발생할 수 있습니다. 이 실패로 인해 보조 데이터베이스가 일시 중단될 수 있습니다. 확장 또는 성능 패턴을 예측할 수 없고 나중에 파일을 추가하는 것이 계획이면 Azure NetApp Files를 사용하는 SQL Server 장애 조치 클러스터를 사용할 수 있습니다. 대부분의 구축 환경에서 Azure NetApp Files은 성능 요구사항을 충족합니다.</block>
  <block id="19f59b74448f6a27519db281a44e4b12" category="section-title">마이그레이션</block>
  <block id="cd6b4503e07d15cebc0842bb8da7b765" category="paragraph">온프레미스 SQL Server 사용자 데이터베이스를 Azure 가상 머신의 SQL Server로 마이그레이션하는 방법에는 여러 가지가 있습니다. 마이그레이션은 온라인 또는 오프라인일 수 있습니다. 선택한 옵션은 SQL Server 버전, 비즈니스 요구 사항 및 조직 내에서 정의된 SLA에 따라 다릅니다. 데이터베이스 마이그레이션 프로세스 중에 다운타임을 최소화하려면 AlwaysOn 옵션 또는 트랜잭션 복제 옵션을 사용하는 것이 좋습니다. 이러한 방법을 사용할 수 없는 경우 데이터베이스를 수동으로 마이그레이션할 수 있습니다.</block>
  <block id="2d4221f1ee93c102ca047daac1fba4a7" category="paragraph">시스템 간에 데이터베이스를 이동하는 가장 간단하고 철저한 테스트를 거친 접근 방식은 백업 및 복원입니다. 일반적으로 데이터베이스 백업 후 Azure로 데이터베이스 백업 복사본을 사용하여 시작할 수 있습니다. 그런 다음 데이터베이스를 복원할 수 있습니다. 최상의 데이터 전송 성능을 얻으려면 압축된 백업 파일을 사용하여 데이터베이스 파일을 Azure VM으로 마이그레이션합니다. 이 문서에서 참조되는 고급 설계에서는 Azure 파일 동기화를 사용하여 Azure 파일 저장소에 대한 백업 방식을 사용한 다음 Azure NetApp Files로 복원합니다.</block>
  <block id="623f8382f97ee8df2d7af54439833812" category="admonition">Azure 마이그레이션을 사용하여 SQL Server 워크로드를 검색, 평가, 마이그레이션할 수 있습니다.</block>
  <block id="fbc25f1c70f1a9c133715cac6d66b21b" category="paragraph">마이그레이션을 수행하려면 다음 단계를 따르십시오.</block>
  <block id="d807caa187d2fea33bab50ed1e1c79bb" category="list-text">요구 사항에 따라 연결을 설정합니다.</block>
  <block id="59f59f1aebe4fc18ab054480b3a1098a" category="list-text">온-프레미스 파일 공유 위치에 전체 데이터베이스 백업을 수행합니다.</block>
  <block id="4891d727582d5df766ee6737fe7fb761" category="list-text">Azure 파일 동기화를 사용하여 Azure 파일 공유에 백업 파일을 복사합니다.</block>
  <block id="135899cc34886eb6ce9baf7211d4adb5" category="list-text">원하는 버전의 SQL Server로 VM을 프로비저닝합니다.</block>
  <block id="fbef0b11b7ee9e0d709d3d1c6efbd4d4" category="list-text">명령 프롬프트에서 "copy" 명령을 사용하여 백업 파일을 VM에 복사합니다.</block>
  <block id="b9786aca69df61c5165147929b4ced89" category="list-text">전체 데이터베이스를 Azure 가상 머신의 SQL Server로 복구합니다.</block>
  <block id="e937691d64dcb1188cbbcbcd83d87d2f" category="admonition">21개 데이터베이스를 복원하는 데 약 9시간이 걸렸습니다. 이 접근 방식은 이 시나리오에만 적용됩니다. 그러나 아래 나열된 다른 마이그레이션 기술은 고객의 상황과 요구 사항에 따라 사용할 수 있습니다.</block>
  <block id="2b9d85faa379ef985ae3851810db1403" category="paragraph">온-프레미스 SQL Server에서 Azure NetApp Files로 데이터를 이동하는 기타 마이그레이션 옵션은 다음과 같습니다.</block>
  <block id="90248308f9c24bd3bf817ee129838603" category="list-text">데이터와 로그 파일을 분리하고 Azure Blob 저장소에 복사한 다음 URL에서 ANF 파일 공유가 마운트된 Azure VM의 SQL Server에 연결합니다.</block>
  <block id="82ce70205698ed956d1fce48af1360c0" category="inline-link">Azure 복제본 추가 마법사</block>
  <block id="e5e07f1ff84f0082089e4fec71ed43a4" category="list-text">Always On Availability Group Deployment On-Premises를 사용하는 경우 를 사용합니다<block ref="aea558e3371e9956f5e03828309464a0" category="inline-link-rx"></block> 를 눌러 Azure에서 복제본을 생성한 다음 페일오버를 수행합니다.</block>
  <block id="eedc53c13a9992999dba36bda1b62255" category="inline-link">트랜잭션 복제</block>
  <block id="47a43d904457c52da2918f290a0ae5cb" category="list-text">SQL Server를 사용합니다<block ref="21bf5f41b40b598aae9dd55aa9dcb960" category="inline-link-rx"></block> Azure SQL Server 인스턴스를 구독자로 구성하려면 복제를 사용하지 않도록 설정하고 사용자를 Azure 데이터베이스 인스턴스로 지정합니다.</block>
  <block id="bf4614882fd1000329cfcb76f98f6c17" category="list-text">Windows 가져오기/내보내기 서비스를 사용하여 하드 드라이브를 배송합니다.</block>
  <block id="be062cdcabbb3055334e8f19b4bdf378" category="section-title">백업 및 복구</block>
  <block id="b855582b6472c4fbe2a5f606191e66d6" category="paragraph">백업 및 복구는 모든 SQL Server 배포의 중요한 부분입니다. AOAG와 같은 고가용성 솔루션과 함께 다양한 데이터 장애 및 손실 시나리오에서 신속하게 복구할 수 있는 적절한 안전망을 갖추고 있어야 합니다. SQL Server 데이터베이스 정지 도구, Azure 백업(스트리밍) 또는 Commvault와 같은 타사 백업 도구를 사용하여 데이터베이스의 애플리케이션 정합성이 보장되는 백업을 수행할 수 있습니다.</block>
  <block id="3896e1102f68b0bc974f324bb134f6e6" category="inline-link">SCSQLAPI 도구</block>
  <block id="e372173044ccba12657b2e3dbff1879b" category="paragraph">Azure NetApp Files 스냅샷 기술을 사용하면 성능이나 네트워크 활용도에 영향을 주지 않고 사용자 데이터베이스의 시점(PiT) 복사본을 쉽게 생성할 수 있습니다. 또한 이 기술을 사용하면 스냅샷 복사본을 새 볼륨으로 복원하거나 복원 볼륨 기능을 사용하여 스냅샷 복사본이 생성된 시점의 상태로 빠르게 되돌릴 수 있습니다. Azure NetApp Files 스냅샷 프로세스는 매우 빠르고 효율적이므로 Azure 백업에서 제공되는 스트리밍 백업과 달리 매일 여러 번 백업할 수 있습니다. 특정 날짜에 여러 개의 Snapshot 복사본이 가능하므로 RPO 및 RTO 시간이 크게 줄어들 수 있습니다. 스냅샷 복사본을 생성하기 전에 데이터가 손상되지 않고 디스크에 적절히 플러시되도록 응용 프로그램 일관성을 추가하려면 SQL Server 데이터베이스 정지 도구를 사용합니다 <block ref="b800e9e09a17fc5b41967404ec8e47ac" category="inline-link-rx"></block>; 이 링크에 액세스하려면 NetApp SSO 로그인 자격 증명이 필요합니다.) 이 툴은 PowerShell 내에서 실행할 수 있습니다. PowerShell은 SQL Server 데이터베이스를 중지시키고 애플리케이션 정합성이 보장되는 스토리지 Snapshot 복사본을 백업에 사용할 수 있도록 합니다.</block>
  <block id="04666a337d02195d17089298f5773f4c" category="paragraph">* 참고: *</block>
  <block id="a4d5ac6087b7ce119cfe6b7ad4d77ee5" category="list-text">SCSQLAPI 도구는 2016 및 2017 버전의 SQL Server만 지원합니다.</block>
  <block id="fdcb10d4c2db07cf930247a4f9898ec5" category="list-text">SCSQLAPI 도구는 한 번에 하나의 데이터베이스에서만 작동합니다.</block>
  <block id="2f65ae42dc3aa8b735406a2d56ceb6fb" category="list-text">파일을 별도의 Azure NetApp Files 볼륨에 배치하여 각 데이터베이스에서 격리합니다.</block>
  <block id="879351e17b2cd6d740ac0974e9ff8a5a" category="inline-link">Azure 백업</block>
  <block id="794b24c8957eec03a1402459d32f6810" category="paragraph">SCSQL API의 방대한 제한으로 인해<block ref="10a72c6743c3c6714e03b5537ec15603" category="inline-link-rx"></block> SLA 요구사항을 충족하기 위해 데이터 보호에 사용되었습니다. Azure 가상 머신 및 Azure NetApp Files에서 실행되는 SQL Server의 스트림 기반 백업을 제공합니다. Azure Backup은 빈번한 로그 백업 및 최대 1초의 피트 복구를 통해 15분 RPO를 실현합니다.</block>
  <block id="423e555c5ec3885f2bb5d9d2d6627f63" category="section-title">모니터링</block>
  <block id="fe58430a0bb00057a08eed382c5d82b2" category="paragraph">Azure NetApp Files는 Azure Monitor와 통합되어 시계열 데이터를 제공하며, 할당된 스토리지, 실제 스토리지 사용량, 볼륨 IOPS, 처리량, 디스크 읽기 바이트/초, 디스크 쓰기 바이트/초, 디스크 읽기/초 및 디스크 쓰기/초, 관련 지연 시간 이 데이터를 사용하여 경고 병목 현상을 식별하고 상태 점검을 수행하여 SQL Server 배포가 최적의 구성으로 실행되고 있는지 확인할 수 있습니다.</block>
  <block id="48419e90c914ae5fa935283404de8a2a" category="paragraph">이 HLD에서 ScienceLogic은 적절한 서비스 보안 주체를 사용하여 메트릭을 노출하여 Azure NetApp Files를 모니터링하는 데 사용됩니다. 다음 그림은 Azure NetApp Files 메트릭 옵션의 예입니다.</block>
  <block id="2bede5da6907dcdcebc6a8f407f07467" category="paragraph"><block ref="2bede5da6907dcdcebc6a8f407f07467" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fe292df6373534e554d5a7938bc3c3b" category="section-title">일반 클론을 사용한 DevTest</block>
  <block id="652f67778e6d02c7b5bfe46a3e579f7f" category="paragraph">Azure NetApp Files를 사용하면 응용 프로그램 개발 주기 동안 현재 데이터베이스 구조 및 콘텐츠를 사용하여 구현해야 하는 기능을 테스트하기 위해 데이터베이스의 즉각적인 복사본을 만들 수 있으며, 데이터 웨어하우스를 채울 때 데이터 추출 및 조작 도구를 사용할 수 있습니다. 실수로 삭제하거나 변경한 데이터를 복구할 수도 있습니다. 이 프로세스에서는 Azure Blob 컨테이너에서 데이터를 복사할 필요가 없어 매우 효율적입니다. 볼륨이 복원된 후 읽기/쓰기 작업에 사용할 수 있어 검증 및 출시 시간이 크게 단축됩니다. 이 기능은 애플리케이션 일관성을 위해 SCSQLAPI와 함께 사용해야 합니다. 이 접근 방식은 Azure NetApp Files와 함께 새로운 볼륨으로 복원 옵션을 활용하는 또 다른 연속 비용 최적화 기술을 제공합니다.</block>
  <block id="e4665dd99280634e4b44ff82666fbb9f" category="list-text">새 볼륨 복원 옵션을 사용하여 스냅샷 복사본에서 생성된 볼륨은 용량 풀의 용량을 사용합니다.</block>
  <block id="0031911d8ba66a79d06b9819afd4f082" category="list-text">REST 또는 Azure CLI를 사용하여 복제된 볼륨을 삭제하여 추가 비용을 방지할 수 있습니다(용량 풀을 늘려야 하는 경우).</block>
  <block id="cb4d46fdcb0881652013c495d90ae732" category="section-title">하이브리드 스토리지 옵션</block>
  <block id="e6a1767911a937e11cc1750fcc4256c3" category="paragraph">SQL Server 가용성 그룹의 모든 노드에 대해 동일한 스토리지를 사용하는 것이 권장되지만, 여러 스토리지 옵션을 사용할 수 있는 시나리오가 있습니다. 이 시나리오는 AOAG의 노드가 Azure NetApp Files SMB 파일 공유에 연결되어 있고 두 번째 노드가 Azure 프리미엄 디스크에 연결되어 있는 Azure NetApp Files에 대해 가능합니다. 이 경우 Azure NetApp Files SMB 공유가 사용자 데이터베이스의 기본 복사본을 갖고 있고 프리미엄 디스크가 보조 복사본으로 사용되는지 확인하십시오.</block>
  <block id="009d3d51226fdccd09052934b65100db" category="list-text">이러한 구축에서 페일오버 문제를 방지하려면 SMB 볼륨에서 지속적인 가용성을 활성화해야 합니다. 지속적으로 사용 가능한 속성이 없으므로 스토리지 계층에 백그라운드 유지 관리가 있는 경우 데이터베이스에 장애가 발생할 수 있습니다.</block>
  <block id="918e9d895272e6a326c6585e05ae4c08" category="list-text">데이터베이스의 기본 복사본을 Azure NetApp Files SMB 파일 공유에 유지합니다.</block>
  <block id="1a5c3601eda1cd38072323e418968743" category="section-title">비즈니스 연속성</block>
  <block id="064ea84d2e6072b28bfd7a8b36aed3db" category="paragraph">재해 복구는 일반적으로 모든 구현에서 나중에 고려해야 하는 사안입니다. 그러나 비즈니스에 영향을 주지 않도록 초기 설계 및 구축 단계에서 재해 복구를 해결해야 합니다. Azure NetApp Files를 사용하면 CRR(Cross-Region Replication) 기능을 사용하여 블록 레벨의 볼륨 데이터를 페어링된 영역으로 복제하여 예기치 않은 지역 운영 중단을 처리할 수 있습니다. CRR 지원 대상 볼륨을 읽기 작업에 사용할 수 있으므로 재해 복구 시뮬레이션에 적합합니다. 또한 CRR 대상을 가장 낮은 서비스 수준(예: 표준)으로 할당하여 전체 TCO를 줄일 수 있습니다. 페일오버 발생 시 복제를 깨고 각 볼륨을 읽기/쓰기 가능하게 만들 수 있습니다. 또한 동적 서비스 수준 기능을 사용하여 재해 복구 비용을 크게 줄여 볼륨의 서비스 수준을 변경할 수 있습니다. 이는 Azure 내에서 블록 복제를 사용하는 Azure NetApp Files의 또 다른 고유한 기능입니다.</block>
  <block id="86258094262f66b30d10068d1d9c29d4" category="section-title">장기적인 스냅샷 복사본 아카이브</block>
  <block id="65bd92a3b5fcfea7efeb973a0a2483d8" category="inline-link">AzCopy</block>
  <block id="e6bf440e9e7e787ce92e6f8661daf9e9" category="paragraph">많은 조직에서는 필수 규정 준수 요구 사항으로 데이터베이스 파일의 스냅샷 데이터를 장기간 보존해야 합니다. 이 프로세스는 HLD에서 사용되지 않지만 를 사용하여 간단한 배치 스크립트를 사용하여 쉽게 수행할 수 있습니다<block ref="f326c7b047cd071718d141dba06c550f" category="inline-link-rx"></block> 를 눌러 Azure Blob 컨테이너에 스냅샷 디렉토리를 복사합니다. 예약된 작업을 사용하여 특정 일정에 따라 배치 스크립트를 트리거할 수 있습니다. 이 프로세스는 다음과 같은 단계로 구성되어 있습니다.</block>
  <block id="dfdc6514d824f948d82ee2ac6515603f" category="list-text">AzCopy V10 실행 파일을 다운로드합니다. exe 파일이기 때문에 설치할 것이 없습니다.</block>
  <block id="5434519f37049a19d388fb3edabd08f7" category="list-text">적절한 권한이 있는 컨테이너 수준에서 SAS 토큰을 사용하여 AzCopy에 권한을 부여합니다.</block>
  <block id="73facdc1e77927e1c0d4c2f66c6fedf9" category="list-text">AzCopy가 승인된 후 데이터 전송이 시작됩니다.</block>
  <block id="a2c31034ac77c6ad0ce6dae2a7882d73" category="list-text">배치 파일에서 SAS 토큰에 나타나는 % 문자를 이스케이프해야 합니다. 이 작업은 SAS 토큰 문자열의 기존 % 문자 옆에 % 문자를 추가하여 수행할 수 있습니다.</block>
  <block id="0eed577952fd376af1fa48aa241e3df7" category="inline-link">보안 전송이 필요합니다</block>
  <block id="b2f731ca364e7df30cd69650bdc19d46" category="list-text">를 클릭합니다<block ref="7e9be5c7f255e20f7f3a81046108dcad" category="inline-link-rx"></block> 저장소 계정 설정에 따라 저장소 계정에 대한 연결이 TLS(Transport Layer Security)로 보호되는지 여부가 결정됩니다. 이 설정은 기본적으로 사용됩니다. 다음 배치 스크립트 예제에서는 스냅샷 복사본 디렉토리에서 지정된 Blob 컨테이너로 데이터를 재귀적으로 복제합니다.</block>
  <block id="f2c225fb316953652d9040f71e76717c" category="paragraph">다음 명령 예는 PowerShell에서 실행됩니다.</block>
  <block id="e7cc24e4ddff469c6304653aea869597" category="list-text">Azure NetApp Files에서는 장기 보존을 위한 유사한 백업 기능을 곧 사용할 수 있습니다.</block>
  <block id="03930ecbc2c505278298d571631e23bb" category="list-text">배치 스크립트는 모든 영역의 Blob 컨테이너에 데이터를 복사해야 하는 모든 시나리오에서 사용할 수 있습니다.</block>
  <block id="07ecdeff0f5a70968e882eb4ace6f576" category="paragraph">데이터베이스에 전혀 영향을 주지 않는 볼륨 재구성 및 동적 서비스 수준 변경을 통해 Azure NetApp Files은 Azure에서 지속적인 비용 최적화를 지원합니다. 이 HLD에서는 워크로드 폭증을 처리하기 위해 추가 스토리지의 오버 프로비저닝을 방지하기 위해 이 기능이 광범위하게 사용됩니다.</block>
  <block id="bf511e8b678dd2ecee162930e6c8c9e6" category="paragraph">Azure 경고 로그와 함께 Azure 기능을 만들어 볼륨 크기를 쉽게 조정할 수 있습니다.</block>
  <block id="012b603d852affe4779f095a5c59f0c5" category="summary">퍼블릭 클라우드의 민첩성, 가치 창출 시간, 비용 절감은 모두 기업에서 데이터베이스 애플리케이션 개발 및 테스트 노력을 위해 퍼블릭 클라우드를 채택할 때 의미 있는 가치 제안입니다. SnapCenter보다 더 나은 도구는 없습니다. SnapCenter은 운영 데이터베이스를 사내에서 보호할 수 있을 뿐만 아니라 추가 스토리지를 거의 사용하지 않고 퍼블릭 클라우드에서 애플리케이션 개발 또는 코드 테스트용 복사본을 빠르게 복제할 수 있습니다. 다음은 도구를 사용한 단계별 프로세스의 세부 정보입니다.</block>
  <block id="38da6679588aeb2754e14dd58994685e" category="doc">개발/테스트 급증에 대비하여 클라우드로 전환하는 워크플로우</block>
  <block id="5b9681a3caf5db6230c17718122074d3" category="inline-link-macro">이전:AWS 퍼블릭 클라우드 시작하기</block>
  <block id="e9e59a2a982f81f5f964248f351b2446" category="paragraph"><block ref="e9e59a2a982f81f5f964248f351b2446" category="inline-link-macro-rx"></block></block>
  <block id="4d8a5b6bc9c43ab79e376d1aa4d83217" category="paragraph">퍼블릭 클라우드의 민첩성, 가치 창출 시간, 비용 절감은 모두 데이터베이스 애플리케이션 개발 및 테스트 노력을 위한 퍼블릭 클라우드를 채택하는 기업에게 의미 있는 가치 제안입니다. SnapCenter보다 더 나은 도구는 없습니다. SnapCenter은 운영 데이터베이스를 사내에서도 보호할 수 있을 뿐만 아니라 추가 스토리지를 거의 사용하지 않고 퍼블릭 클라우드에서 애플리케이션 개발 또는 코드 테스트용 복사본을 신속하게 클론 복제할 수 있습니다. 다음은 이 도구를 사용하는 단계별 프로세스에 대한 세부 정보입니다.</block>
  <block id="b47b42841be2e173707ab5884714970b" category="section-title">복제된 스냅샷 백업에서 개발/테스트용 Oracle 데이터베이스의 클론을 생성합니다</block>
  <block id="8d90529d1117b8d3781bd6781acf4e91" category="list-text">Oracle용 데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인합니다. 리소스 탭으로 이동하여 SnapCenter에서 보호 중인 Oracle 데이터베이스를 표시합니다.</block>
  <block id="a95ff2a2ae2905b0bb3bd0efa211a040" category="paragraph"><block ref="a95ff2a2ae2905b0bb3bd0efa211a040" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d539d2e9659870aa79747206fac4769" category="list-text">백업 토폴로지와 세부 정보에 대해 원하는 온-프레미스 데이터베이스 이름을 클릭합니다. 보조 복제 위치가 설정된 경우 연결된 미러 백업이 표시됩니다.</block>
  <block id="20111f4a74a9c065157aa13379000a73" category="paragraph"><block ref="20111f4a74a9c065157aa13379000a73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4a9c1f33e524696d6f3adebf89947bb" category="list-text">미러링된 백업을 클릭하여 미러링된 백업 보기로 전환했습니다. 그러면 2차 미러 백업이 표시됩니다.</block>
  <block id="e1cbaea95bcc154ccf9e8aece7fc73b3" category="paragraph"><block ref="e1cbaea95bcc154ccf9e8aece7fc73b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4726a244c3941457e8f62b49c83d35d1" category="list-text">복제할 미러링된 보조 데이터베이스 백업 복제본을 선택하고 시간 및 시스템 변경 번호 또는 SCN에 의해 복구 지점을 결정합니다. 일반적으로 복구 지점은 전체 데이터베이스 백업 시간 또는 SCN을 지나 클론을 생성해야 합니다. 복구 지점을 결정한 후에는 복구에 필요한 로그 파일 백업을 마운트해야 합니다. 로그 파일 백업은 클론 데이터베이스를 호스팅할 대상 DB 서버에 마운트되어야 합니다.</block>
  <block id="81d132cd1ae26e007bb608e5f8609288" category="paragraph"><block ref="81d132cd1ae26e007bb608e5f8609288" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2dc441031605bf54d78fde13b3efc3c" category="paragraph"><block ref="b2dc441031605bf54d78fde13b3efc3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22a17e5abcfc4b5e70ebdea098cd1891" category="admonition">로그 잘라내기를 사용하도록 설정하고 복구 지점이 마지막 로그 잘라내기 이후에 확장된 경우 여러 아카이브 로그 백업을 마운트해야 할 수 있습니다.</block>
  <block id="e9606676533bbe916f4b4b6824eac195" category="list-text">클론 복제할 전체 데이터베이스 백업 복사본을 강조 표시한 다음 클론 버튼을 클릭하여 DB 클론 워크플로우를 시작합니다.</block>
  <block id="48493c19ee97a291cd320501daf5c721" category="paragraph"><block ref="48493c19ee97a291cd320501daf5c721" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c06d82b497809fcc0fd06d00c6d91a5" category="list-text">전체 컨테이너 데이터베이스 또는 CDB 클론에 대해 적절한 클론 DB SID를 선택합니다.</block>
  <block id="f6ee6a459784097119ec1eee6224152e" category="paragraph"><block ref="f6ee6a459784097119ec1eee6224152e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2c50a030b1c5313fca09568edf8c0f9" category="list-text">클라우드에서 타겟 클론 호스트를 선택하고 데이터 파일, 제어 파일 및 재실행 로그 디렉토리는 클론 워크플로우에 의해 생성됩니다.</block>
  <block id="323554a005f5e77dfaa765ea81e645be" category="paragraph"><block ref="323554a005f5e77dfaa765ea81e645be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="701f017aeafb71656cf2bc3a9bd34862" category="list-text">없음 자격 증명 이름은 OS 기반 인증에 사용되며 데이터베이스 포트를 상관 없이 만듭니다. 타겟 클론 DB 서버에 구성된 적절한 Oracle Home, Oracle OS User 및 Oracle OS Group을 입력합니다.</block>
  <block id="c5237b674d4a9cd38d44c5e546cc51d4" category="paragraph"><block ref="c5237b674d4a9cd38d44c5e546cc51d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26a911f3c85fc3c73d79253e65bf30e3" category="list-text">클론 작업 전에 실행할 스크립트를 지정합니다. 더 중요한 것은 여기에서 데이터베이스 인스턴스 매개 변수를 조정하거나 정의할 수 있다는 것입니다.</block>
  <block id="56774e452bc62021e52de3e3fea844a2" category="paragraph"><block ref="56774e452bc62021e52de3e3fea844a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09d7240367714707474d63a3a574222b" category="list-text">날짜 및 시간 또는 SCN을 기준으로 복구 지점을 지정합니다. 취소 전까지 는 데이터베이스를 사용 가능한 아카이브 로그까지 복구합니다. 아카이브 로그 볼륨이 마운트된 타겟 호스트에서 외부 아카이브 로그 위치를 지정합니다. 대상 서버 Oracle 소유자가 온-프레미스 운영 서버와 다른 경우 대상 서버 Oracle 소유자가 아카이브 로그 디렉터리를 읽을 수 있는지 확인합니다.</block>
  <block id="6cb86841376102e5b8924f9909b8f570" category="paragraph"><block ref="6cb86841376102e5b8924f9909b8f570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70b171a9c984de6358afb3557fe84586" category="paragraph"><block ref="70b171a9c984de6358afb3557fe84586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b30b70196320d22207ea0d5d95d2c841" category="paragraph"><block ref="b30b70196320d22207ea0d5d95d2c841" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0421be6f676ac1ddace9e39eeeb54f0f" category="list-text">클론 요약</block>
  <block id="a930a442bf914f516109fbb28bf2fbd1" category="paragraph"><block ref="a930a442bf914f516109fbb28bf2fbd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d929881b22cd699e243e2343bd707d" category="list-text">클론 생성 후 검증하여 클론 복제된 데이터베이스가 작동하는지 확인해야 합니다. 리스너를 시작하거나 DB 로그 아카이브 모드를 해제하는 등의 일부 추가 작업은 개발/테스트 데이터베이스에서 수행할 수 있습니다.</block>
  <block id="9991775de6f914e5a41601ba523e3193" category="paragraph"><block ref="9991775de6f914e5a41601ba523e3193" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58732c8d9b1293bb6666ef2284840fd3" category="section-title">복제된 Snapshot 백업에서 개발/테스트용 SQL 데이터베이스의 클론을 생성합니다</block>
  <block id="605f2bb9d099f78e26260848db117df7" category="list-text">SQL Server의 데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인합니다. 리소스 탭으로 이동합니다. 이 탭에는 SnapCenter로 보호되는 SQL Sever 사용자 데이터베이스와 퍼블릭 클라우드의 타겟 대기 SQL 인스턴스가 표시됩니다.</block>
  <block id="d238acd8e02d4df70c9b55828a4b8801" category="paragraph"><block ref="d238acd8e02d4df70c9b55828a4b8801" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39c34a717e197c67b1fc8d678db5815b" category="list-text">백업 토폴로지 및 상세 보기에 사용할 온-프레미스 SQL Server 사용자 데이터베이스 이름을 클릭합니다. 보조 복제 위치가 설정된 경우 연결된 미러 백업이 표시됩니다.</block>
  <block id="8c57a9d29ca9640330e03e6edca2b6e5" category="paragraph"><block ref="8c57a9d29ca9640330e03e6edca2b6e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5910fa5df5b6482c00b15ae683eef0f" category="list-text">미러링된 백업을 클릭하여 미러링된 백업 보기로 전환합니다. 그러면 보조 미러 백업이 표시됩니다. SnapCenter는 복구를 위해 전용 드라이브에 SQL Server 트랜잭션 로그를 백업하므로 전체 데이터베이스 백업만 여기에 표시됩니다.</block>
  <block id="f8d3ed6786c765a87cec8464a574076a" category="paragraph"><block ref="f8d3ed6786c765a87cec8464a574076a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="368014bae8201ab49d2207a53c907069" category="list-text">백업 복사본을 선택한 다음 클론 버튼을 클릭하여 백업에서 클론 복제를 시작합니다.</block>
  <block id="87dbbaf733c71b9d4e0027ad4a85e709" category="paragraph"><block ref="87dbbaf733c71b9d4e0027ad4a85e709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75c22c861d423e3f3450da18d56f0599" category="paragraph"><block ref="75c22c861d423e3f3450da18d56f0599" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44258030a87117191bde6d62511ddb9a" category="list-text">클라우드 서버를 타겟 클론 서버, 클론 인스턴스 이름 및 클론 데이터베이스 이름으로 선택합니다. 자동 할당 마운트 지점 또는 사용자 정의 마운트 지점 경로를 선택합니다.</block>
  <block id="7841eed97c9a860bcb6a46b08ea08c11" category="paragraph"><block ref="7841eed97c9a860bcb6a46b08ea08c11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18145dc97ae06034ae9aafa8b98cb36e" category="list-text">로그 백업 시간 또는 특정 날짜 및 시간으로 복구 지점을 결정합니다.</block>
  <block id="b2798123b4d42e447362355b510a424c" category="paragraph"><block ref="b2798123b4d42e447362355b510a424c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b9becceddf802cada91d9e2aa84ac5a" category="list-text">클론 생성 작업 전후에 실행할 선택적 스크립트를 지정합니다.</block>
  <block id="adee0219db450497bd0f545df8d862c7" category="paragraph"><block ref="adee0219db450497bd0f545df8d862c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e41b01ffd717fd3d0b5788e608e50b52" category="list-text">e-메일 알림이 필요한 경우 SMTP 서버를 구성합니다.</block>
  <block id="9b758c550d5da3ecb44f04ae804293d4" category="paragraph"><block ref="9b758c550d5da3ecb44f04ae804293d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc89ae2ec0203249b8e60785a63ca258" category="list-text">클론 요약.</block>
  <block id="ab74d2d908acf5c3e01544cd4b871b73" category="paragraph"><block ref="ab74d2d908acf5c3e01544cd4b871b73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28725828580a55d904e8b2a39f377eb9" category="list-text">작업 상태를 모니터링하고 원하는 사용자 데이터베이스가 클라우드 클론 서버의 대상 SQL 인스턴스에 연결되어 있는지 확인합니다.</block>
  <block id="766259946fc034002a24d5f23655c73e" category="paragraph"><block ref="766259946fc034002a24d5f23655c73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d512bf68b17268adfe539f9722d869b4" category="section-title">사후 클론 구성</block>
  <block id="50d9180ea26c89fbe6506d71d81d3fb1" category="list-text">온프레미스 Oracle 운영 데이터베이스는 일반적으로 로그 아카이브 모드에서 실행됩니다. 이 모드는 개발 또는 테스트 데이터베이스에 필요하지 않습니다. 로그 아카이브 모드를 끄려면 Oracle DB에 sysdba로 로그인하고 로그 모드 변경 명령을 실행한 다음 액세스를 위해 데이터베이스를 시작합니다.</block>
  <block id="b205237d51ff9525496f4b2252942213" category="list-text">Oracle 수신기를 구성하거나 새로 복제된 DB를 사용자 액세스를 위해 기존 수신기에 등록합니다.</block>
  <block id="800699a04cdaa75b2219988799b0a048" category="list-text">SQL Server의 경우 로그 볼륨을 채울 때 SQL Server 개발/테스트 로그 파일을 쉽게 축소할 수 있도록 로그 모드를 Full에서 Easy로 변경합니다.</block>
  <block id="89e018d207fd292a4926870904035c18" category="section-title">클론 데이터베이스를 새로 고칩니다</block>
  <block id="d84550ba9a340ebf4fa6698dff5ba344" category="list-text">복제된 데이터베이스를 떨어뜨리거나 클라우드 DB 서버 환경을 정리합니다. 그런 다음 이전 절차에 따라 새 DB를 새 데이터로 복제합니다. 새 데이터베이스를 복제하는 데는 몇 분 밖에 걸리지 않습니다.</block>
  <block id="1170d6f09309cb8dc382034a34680937" category="inline-link-macro">클론을 새로 고칩니다</block>
  <block id="fef062eeb7771b01e620bb2460b1bf9a" category="list-text">클론 데이터베이스를 종료하고 CLI를 사용하여 클론 새로 고침 명령을 실행합니다. 자세한 내용은 다음 SnapCenter 설명서를 참조하십시오. <block ref="1e4035dee07650c706f8f0714c384872" category="inline-link-macro-rx"></block>.</block>
  <block id="7b88d7d11804db6b079e226a6f043ea7" category="paragraph">이 솔루션 및 사용 사례에 대한 도움이 필요한 경우 에 가입하십시오 <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> 질문 또는 질문을 게시할 수 있는 솔루션 자동화 채널을 찾아보십시오.</block>
  <block id="e2a76301a4117f21d6192304aa650018" category="inline-link-macro">다음: 재해 복구 워크플로.</block>
  <block id="28a87ee64d4675e6c24cd960fe71d9bf" category="paragraph"><block ref="28a87ee64d4675e6c24cd960fe71d9bf" category="inline-link-macro-rx"></block></block>
  <block id="c150393fd3b1bd9d801cbd062234f73d" category="section-title">AWX/Tower 구축 Oracle 19c Database</block>
  <block id="3fa16e80574aff03c27de1253474a20f" category="list-text">재고 변수가 있는 경우 변수 필드에 붙여 넣습니다.</block>
  <block id="396641e01a7451ca821b5d7d1377b0c7" category="list-text">ONTAP 그룹 이름을 입력하고 그룹 변수(있는 경우)를 붙여 넣은 다음 저장을 클릭합니다.</block>
  <block id="a4f13b6e4100f2d5db093eb54a3ffe0c" category="list-text">Oracle에 대해 다른 그룹에 대해서도 이 프로세스를 반복합니다.</block>
  <block id="6f29f21d5f3e40494291fb357b9f4f73" category="list-text">생성된 ONTAP 그룹을 선택하고 Hosts 하위 메뉴로 이동한 다음 Add New Host를 클릭합니다.</block>
  <block id="8d92ffd9d0d2b033d05731ec4af50af8" category="list-text">ONTAP 클러스터 관리 IP의 IP 주소를 제공하고 호스트 변수(있는 경우)를 붙여 넣은 다음 저장 을 클릭합니다.</block>
  <block id="f1254ecbe57ff98d850d541b8a1ab988" category="list-text">Oracle 그룹 및 Oracle 호스트 관리 IP/호스트 이름에 대해 이 프로세스를 반복해야 합니다.</block>
  <block id="f11c5853bdca384314b28c9c59f2d6d0" category="list-text">자격 증명 유형을 만듭니다. ONTAP와 관련된 솔루션의 경우 자격 증명 유형을 사용자 이름 및 암호 항목과 일치하도록 구성해야 합니다.</block>
  <block id="1616edbabbc3bbfd22afe144d1929386" category="list-text">다음 내용을 주입기 구성에 붙여넣습니다.</block>
  <block id="cc865c923bcb1c61acf9985311675b93" category="list-text">ONTAP의 이름과 조직 세부 정보를 입력합니다.</block>
  <block id="ea314f484653e7f9f25144ea61d34888" category="list-text">ONTAP에 대해 만든 사용자 지정 자격 증명 유형을 선택합니다.</block>
  <block id="179cae6336461d9f165e8fa87146362a" category="list-text">세부 정보 입력 아래에 사용자 이름, 암호 및 vsadmin_password를 입력합니다.</block>
  <block id="659fb4c811f1a73cf40492056e6d3c3f" category="list-text">자격 증명으로 돌아가기 를 클릭하고 추가 를 클릭합니다.</block>
  <block id="3b9c90c4bf202563a3cdeda5ec78fac2" category="list-text">Oracle의 이름 및 조직 세부 정보를 입력합니다.</block>
  <block id="784148c4a03cf22250dddc5756684e39" category="list-text">를 입력합니다 <block ref="4509731a8f0f86cf7d8a010739dfd7c5" category="inline-link-rx"></block> 소스 제어 URL입니다.</block>
  <block id="14e017f358e18dd612a468713206093f" category="section-title">Oracle host_VAR을 구성합니다</block>
  <block id="05557c38b20e42173356b53f42c92152" category="paragraph">이 섹션에 정의된 변수는 각 개별 Oracle 서버 및 데이터베이스에 적용됩니다.</block>
  <block id="ac886b852fd1b481e9c7e68c217b5e21" category="list-text">다음과 같은 내장된 Oracle hosts 변수 또는 host_vars 양식에 환경별 매개 변수를 입력합니다.</block>
  <block id="e1847b1a99378b07a0df71cf2baac5da" category="list-text">파란색 필드에 모든 변수를 입력합니다.</block>
  <block id="741c92ab2429ff59927918c7a07ad9a5" category="list-text">변수 입력을 완료한 후 양식의 복사 버튼을 클릭하여 AWX 또는 타워로 전송할 모든 변수를 복사합니다.</block>
  <block id="1e1ea51549ac2a644a3e965113c1d370" category="list-text">AWX 또는 Tower로 돌아가서 Resources → Hosts 로 이동한 다음 Oracle 서버 구성 페이지를 선택하여 엽니다.</block>
  <block id="0d630b14098a793ac4586173286d0805" category="list-text">세부 정보 탭에서 편집 을 클릭하고 1단계에서 복사한 변수를 YAML 탭의 변수 필드에 붙여 넣습니다.</block>
  <block id="c6dca9e669d097298fc6059b27f96e09" category="list-text">시스템에 있는 모든 추가 Oracle 서버에 대해 이 프로세스를 반복합니다.</block>
  <block id="7890327bd98d1ec932e453254511754d" category="section-title">글로벌 변수를 설정합니다</block>
  <block id="7d2a3c2ad9ee2eeb7547d205d30b9335" category="list-text">파란색 필드에 모든 변수를 입력합니다.</block>
  <block id="099f04b51539ed973890f1d1af2d5063" category="list-text">변수 입력을 완료한 후 양식의 복사 버튼을 클릭하여 AWX 또는 Tower로 전송할 모든 변수를 다음 작업 템플릿으로 복사합니다.</block>
  <block id="c807b1735c1915c52547b9f7e917b55d" category="section-title">작업 템플릿을 구성하고 시작합니다.</block>
  <block id="c7fa74fb4cbaab9d336a8e55bf164684" category="list-text">이름과 설명을 입력합니다</block>
  <block id="3dcca032e3328f54206079a87830aa27" category="list-text">작업 유형을 선택합니다. Run은 Playbook을 기반으로 시스템을 구성하고 Check는 실제로 시스템을 구성하지 않고 Playbook을 건조하게 실행합니다.</block>
  <block id="b01c6189ccdc531874f3442803680525" category="list-text">All_Playbook.yml을 실행할 기본 플레이북으로 선택합니다.</block>
  <block id="e8f0426d97d09775fb78bdeb793b0b3e" category="list-text">작업 태그 필드에서 시작 시 프롬프트 표시 확인란을 선택합니다.</block>
  <block id="ad7ad1bbc416fda1f9518ff4004d891c" category="list-text">작업 태그를 시작할 때 메시지가 나타나면 requirements_config 를 입력합니다. 작업 태그를 입력하려면 requirements_config 아래의 작업 태그 작성 줄을 클릭해야 할 수도 있습니다.</block>
  <block id="b9ef793a3db3f07ed7dc808f4709c6ca" category="admonition">requirements_config 다른 역할을 실행할 올바른 라이브러리가 있는지 확인합니다.</block>
  <block id="6ac039e55dcf8a249f5122b1fdbbf60e" category="list-text">다음 을 클릭한 다음 시작 을 클릭하여 작업을 시작합니다.</block>
  <block id="06f392c8dfb4783859e67f16fed69bc7" category="list-text">보기 → 작업 을 클릭하여 작업 출력 및 진행률을 모니터링합니다.</block>
  <block id="7f6a02c24592bd309f31b5a72a0f8d6d" category="list-text">작업 태그를 시작할 때 프롬프트가 표시되면 ONTAP_config를 입력합니다. ONTAP_config 바로 아래에 있는 "작업 태그" 생성 라인을 클릭하여 작업 태그를 입력해야 할 수 있습니다.</block>
  <block id="18c003af9ed29d295877baabf7b42ce1" category="list-text">보기 → 작업 을 클릭하여 작업 출력 및 진행률을 모니터링합니다</block>
  <block id="c0029d5cdcaae1ceef3bed244b3ab3c6" category="list-text">ONTAP_config 역할이 완료된 후 Linux_config에 대해 프로세스를 다시 실행하십시오.</block>
  <block id="fc71758268fe1c3aba4b75df3ee0560f" category="list-text">원하는 템플릿을 선택한 다음 실행을 클릭합니다.</block>
  <block id="bbe073bafc2875db8b48e59284636931" category="list-text">Linux_config에서 작업 태그 유형을 시작할 때 메시지가 표시되면 Linux_config 바로 아래의 "작업 태그 생성" 행을 선택하여 작업 태그를 입력해야 할 수 있습니다.</block>
  <block id="bc43b7acafead2cdee67de733ae10b13" category="list-text">보기 → 작업 을 선택하여 작업 출력 및 진행률을 모니터링합니다.</block>
  <block id="e73718535637e07111f6a4925685c0bd" category="list-text">Linux_config 역할이 완료된 후 ORACLE_config에 대해 프로세스를 다시 실행하십시오.</block>
  <block id="574f8726a5cc088da32ab84269c8e0f8" category="list-text">리소스 → 템플릿 으로 이동합니다.</block>
  <block id="252b85bc679cb8ecdccbcd127c65b795" category="list-text">작업 태그 시작 시 메시지가 표시되면 ORACLE_config 를 입력합니다. 작업 태그를 입력하려면 ORACLE_config 바로 아래에 있는 "작업 태그 생성" 행을 선택해야 할 수 있습니다.</block>
  <block id="6757805f64ddba2566927ece0d9f30e1" category="section-title">동일한 Oracle 호스트에 추가 데이터베이스를 구축합니다</block>
  <block id="4edc1d4492ab93edbbb0a67c0c265b84" category="paragraph">플레이북의 Oracle 부분은 실행 당 Oracle 서버에 단일 Oracle 컨테이너 데이터베이스를 생성합니다. 동일한 서버에 추가 컨테이너 데이터베이스를 만들려면 다음 단계를 완료하십시오.</block>
  <block id="a12a0fa7fe728658376da87df04fa7c2" category="list-text">host_vars 변수를 수정합니다.</block>
  <block id="ba52bf2d165115d60675d61a4b84b0c6" category="list-text">2단계 - Configure Oracle host_VAR로 돌아갑니다.</block>
  <block id="d9fa63a6f267402d4cf6068165e04a38" category="list-text">EM Express를 설치할 경우 EM Express 포트를 다른 번호로 변경하십시오.</block>
  <block id="23f5c9b4f57b3075f9890f1bc1896ebe" category="list-text">호스트 구성 세부 정보 탭의 Oracle 호스트 변수 필드에 수정된 호스트 변수를 복사하여 붙여 넣습니다.</block>
  <block id="4d4426a703dd8227727fef5758b680d8" category="list-text">ORACLE_config 태그만 사용하여 구축 작업 템플릿을 시작합니다.</block>
  <block id="0c138556fe4f10d4cdba4c61933afd91" category="doc">Google Cloud Virtualization Engine용 NetApp 솔루션(GCVE)</block>
  <block id="dc740fd7aabd59b53cda21fc57a7c10c" category="paragraph">NetApp이 Google Cloud에 제공하는 솔루션에 대해 자세히 알아보십시오. 마이그레이션 워크플로우, 클라우드로의 확장/급증, 백업/복원, 재해 복구 등</block>
  <block id="1d71c2a7928e8ff703779db43b80044f" category="section-title">GCVE용 솔루션</block>
  <block id="5a2d7e3c6d0ab5aa27c06042f28c3198" category="open-title">확장/버스트</block>
  <block id="ba32bd76ecebfdb42efa20b6de24b808" category="paragraph">TR&gt;에서 해당 섹션을 가리킵니다</block>
  <block id="8553825f2c93feb7d32c670401e5f338" category="open-title">데이터 센터 유지 관리</block>
  <block id="10b5b21ed1ee90eca305b558caf7d03b" category="open-title">마이그레이션</block>
  <block id="72b05a5f0a9b1e3f2eded42f0dbdd848" category="open-title">백업/복원</block>
  <block id="e413eba49b15917b0c9dbf2620f3e66e" category="open-title">재해 복구</block>
  <block id="21a1e68164f738b8be1dae11d5a694b3" category="open-title">데이터 보호</block>
  <block id="29f8b77f5f7c79b566706e0d55c9de8b" category="doc">Amazon VMC(VMware Managed Cloud)를 위한 NetApp 솔루션</block>
  <block id="c24b87c4afee5d42310b2dd6144617af" category="paragraph">NetApp이 AWS에 제공하는 마이그레이션 워크플로우, 클라우드로의 확장/버스팅, 백업/복원, 재해 복구 솔루션에 대해 자세히 알아보십시오.</block>
  <block id="37cbb75112a68116251619ab33efe24a" category="section-title">VMC용 NetApp 솔루션</block>
  <block id="7e0686a26bc7a91429819c2aeb7b414a" category="doc">Azure VMware 솔루션용 NetApp 솔루션(AVS)</block>
  <block id="7e868c580794349e459e166e04a5abcd" category="paragraph">NetApp이 Azure에 제공하는 마이그레이션 워크플로우, 클라우드로의 확장/버스팅, 백업/복원, 재해 복구 솔루션에 대해 자세히 알아보십시오.</block>
  <block id="93d6c31a1f56cb2d2f25af1274c4abdd" category="section-title">AVS용 솔루션</block>
  <block id="44f55a60cc8f70d1e10efc62b75eeddc" category="doc">하이퍼스케일 솔루션 에서 VMware를 위한 NetApp 솔루션</block>
  <block id="b583dc49832a978014ef0d14fe7ef1ce" category="paragraph">NetApp이 마이그레이션 워크플로우, 클라우드로의 확장/버스팅, 백업/복원, 재해 복구 등 각 하이퍼스케일러에 VMware 환경을 제공하는 솔루션에 대해 자세히 알아보십시오.</block>
  <block id="2c3412ea249289d455415fc5974540d7" category="paragraph">다음 매트릭스에서는 각 하이퍼스케일러와 NetApp 스토리지 옵션 간의 솔루션 사용 사례를 정의합니다. 솔루션 세부 정보를 보려면 원하는 셀의 세부 정보를 클릭합니다.</block>
  <block id="205549244e00d8fc3aed42cc242b6e66" category="open-title">AWS(VMC)</block>
  <block id="7fb61d6790786c6584895ba13b1d7acf" category="cell">* 사용 사례 *</block>
  <block id="23b14f1282da64a4a69cef795c672d69" category="cell">* FSx ONTAP *</block>
  <block id="5e6a9c7508fcb882686fb57577c20564" category="cell">클라우드로 백업</block>
  <block id="fca9cd52865f9c45b9c1c0810944323a" category="cell">클라우드로 DR</block>
  <block id="1f7519825c9e66f611f1b8a2dfab6d98" category="cell">개발/테스트</block>
  <block id="03a85053364f989565c431e1f3cb14b6" category="cell">클라우드에 최대 사용량</block>
  <block id="520a0900399ea06bc457dd365ce39b56" category="cell">클라우드로 마이그레이션</block>
  <block id="1d8b77813302d5fc10b4a01c9d1f71ba" category="open-title">Azure(AVS)</block>
  <block id="f06436d87956805c42a72d20c6e0c6aa" category="cell">* ANF *</block>
  <block id="a060ea40d8e1f38832adc8dab3110308" category="cell">CVO *</block>
  <block id="7896a48b4cb2f9b6d3c3612c0b5a8886" category="open-title">Google(GCVE)</block>
  <block id="cb56c4671d6ec2da0b5f3b248999cba7" category="cell">CVS *</block>
  <block id="07b0eade4402d209b5dbe587a8ad3f6f" category="doc">AWS에서 가상화 환경을 구축하고 구성합니다</block>
  <block id="e647d88b9bd859d2c3e943c24b4fef00" category="paragraph">사내 환경과 마찬가지로, AWS에서 VMware Cloud를 계획하는 것은 VM과 마이그레이션을 성공적으로 운영 환경에 구축하는 데 매우 중요합니다.</block>
  <block id="162e9e1fd4657b8d9588a5ae8c8e6e66" category="paragraph">이 섹션에서는 AWS SDDC에서 VMware Cloud를 설정 및 관리하고, NetApp 스토리지를 연결하는 데 사용할 수 있는 옵션과 함께 사용하는 방법을 설명합니다.</block>
  <block id="35dcee3fd9faac08f48b3df2e8e0e63c" category="admonition">현재 게스트 내 스토리지는 FSx ONTAP 및 Cloud Volumes ONTAP를 AWS VMC에 연결하는 유일한 지원 방법입니다.</block>
  <block id="d6d7fade0a5d1cd7723c64125e595b08" category="paragraph">설치 프로세스는 다음 단계로 나눌 수 있습니다.</block>
  <block id="389544cc8199f2ddd936397695d0dbe9" category="inline-link-macro">VMware Cloud for AWS 구축 및 구성</block>
  <block id="fc6ca296e478de217b1d91ca6a51669e" category="list-text"><block ref="fc6ca296e478de217b1d91ca6a51669e" category="inline-link-macro-rx"></block></block>
  <block id="b4f284d3b5bb40ee91901933b8f7ef5f" category="inline-link-macro">VMware Cloud를 FSx ONTAP에 연결합니다</block>
  <block id="0e488e496c84968dd373c3acab443dd7" category="list-text"><block ref="0e488e496c84968dd373c3acab443dd7" category="inline-link-macro-rx"></block></block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="inline-link-macro">AWS 기반 VMware 클라우드</block>
  <block id="02b412692a538ee9dc2534f0f9c73dc1" category="paragraph"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block> AWS 에코시스템의 VMware 기반 워크로드에 클라우드 네이티브 경험을 제공합니다. 각 VMware SDDC(소프트웨어 정의 데이터 센터)는 VPC(Amazon Virtual Private Cloud)에서 실행되며 전체 VMware 스택(vCenter Server 포함), NSX-T 소프트웨어 정의 네트워킹, vSAN 소프트웨어 정의 스토리지, 워크로드에 컴퓨팅 및 스토리지 리소스를 제공하는 하나 이상의 ESXi 호스트를 제공합니다.</block>
  <block id="dc77b78f59a0c38a9a2e8927dc05e916" category="paragraph">이 섹션에서는 AWS에서 VMware Cloud를 설정 및 관리하고, 게스트 내 스토리지에서 AWS에서 NetApp ONTAP용 Amazon FSx 및/또는 Cloud Volumes ONTAP와 함께 사용하는 방법에 대해 설명합니다.</block>
  <block id="1687622e662f209ef64e3a88de409466" category="admonition">게스트 내 스토리지는 NetApp ONTAP용 Amazon FSx 및 Cloud Volumes ONTAP를 AWS의 VMware 클라우드에 연결하는 유일한 지원 방법입니다.</block>
  <block id="3712f34e1b7039d6d9bfb255ecc54445" category="paragraph">설정 프로세스는 다음 세 부분으로 나눌 수 있습니다.</block>
  <block id="f54d8dbbc1cb20fd37a59a4563644ef8" category="inline-link-macro">아마존 웹 서비스 계정</block>
  <block id="4ca1486cd3276884e41ad4b36080c10b" category="list-text">에 등록하십시오 <block ref="ab3390028f6599a1b73b747febbf672d" category="inline-link-macro-rx"></block>.</block>
  <block id="020e995219c3fad42714462fc9368253" category="inline-link-macro">내 VMware</block>
  <block id="4f87cd22b54abb602d4264ede77c75fd" category="list-text">에 등록하십시오 <block ref="6fb1d438d7363efa930c55af527a6c23" category="inline-link-macro-rx"></block> 계정.</block>
  <block id="969c176eb8515e73c2df6805bd09d5de" category="list-text">VMware 클라우드에서 SDDC 프로비저닝</block>
  <block id="28cefea59e6b78bfecc1439107469038" category="section-title">AWS 계정을 등록하십시오</block>
  <block id="252c0d3625c410f643362d13f1e35681" category="paragraph">이미 생성된 계정이 없는 경우 시작하려면 AWS 계정이 필요합니다. 이 절차의 여러 단계에 대해 새 계정 또는 기존 계정에 관리 권한이 필요합니다. 자세한 내용은 다음을 참조하십시오 <block ref="d01b332d778720bc2fe2a9a15e6ba01d" category="inline-link-macro-rx"></block> AWS 자격 증명에 대한 자세한 내용은</block>
  <block id="ed463b922006aa54f2aceda63f25caed" category="section-title">내 VMware 계정을 등록합니다</block>
  <block id="e1ed167660991d514f55d806a323f3b5" category="paragraph">VMware의 클라우드 포트폴리오(AWS의 VMware Cloud 포함)에 액세스하려면 VMware 고객 계정 또는 My VMware 계정이 필요합니다. 아직 생성하지 않은 경우 VMware 계정을 생성합니다 <block ref="aefb6f511cceca70505b3e5bf76155fe" category="inline-link-macro-rx"></block>.</block>
  <block id="60fa505f14fb504e941cbc61b74d644a" category="section-title">VMware 클라우드에서 SDDC 프로비저닝</block>
  <block id="6d931b72d8efc3fd87b7fdd5127cbba7" category="paragraph">VMware 계정을 구성하고 적절한 사이징을 수행한 후에는 AWS에서 VMware Cloud 서비스를 사용하기 위한 확실한 다음 단계로 소프트웨어 정의 데이터 센터를 구축할 수 있습니다. SDDC를 생성하려면 호스팅할 AWS 영역을 선택하고 SDDC에 이름을 지정하고 SDDC에 포함할 ESXi 호스트 수를 지정합니다. 아직 AWS 계정이 없는 경우에도 단일 ESXi 호스트를 포함하는 시작 구성 SDDC를 생성할 수 있습니다.</block>
  <block id="7e70ad389301fa9d8936c18cefd85b53" category="list-text">기존 또는 새로 생성한 VMware 자격 증명을 사용하여 VMware Cloud Console에 로그인합니다.</block>
  <block id="28570a642842f2bfa7db5cc3679fd904" category="paragraph"><block ref="28570a642842f2bfa7db5cc3679fd904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53722f60844c899c63607413f74e8dd8" category="list-text">AWS 지역, 구축 및 호스트 유형과 SDDC 이름을 구성합니다.</block>
  <block id="5ec07ba481e6291d3af5e3ca61f27f57" category="paragraph"><block ref="5ec07ba481e6291d3af5e3ca61f27f57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5c464b97b208b8c43e9fdd315c80793" category="list-text">원하는 AWS 계정에 연결하고 AWS Cloud 포메이션 스택을 실행합니다.</block>
  <block id="b6822d593b3a1b683cb4e513b210c080" category="paragraph"><block ref="941b74b5e4d054f44fb05f89bfb30732" category="inline-image-macro-rx" type="image"></block>
<block ref="5ca301c5ba248bc9f9566d74470fcc6b" category="inline-image-macro-rx" type="image"></block>
<block ref="54108005ae53e37fa06b081374d6ea43" category="inline-image-macro-rx" type="image"></block>
<block ref="9f7f4a317cf9d46aa6a2aa8f441279ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59e9afc055ce73e7e6154ea7609eec59" category="admonition">이 검증에는 단일 호스트 구성이 사용됩니다.</block>
  <block id="3f68cef60baccc27cfef6b618e56f809" category="list-text">원하는 AWS VPC를 선택하여 VMC 환경을 에 연결합니다.</block>
  <block id="49e131b27a342d4970e86a31a127d41c" category="paragraph"><block ref="49e131b27a342d4970e86a31a127d41c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="102a37b9412553c4ae6b25a174592fbb" category="list-text">VMC 관리 서브넷을 구성합니다. 이 서브넷에는 vCenter, NSX 등과 같은 VMC 관리 서비스가 포함됩니다. SDDC 환경에 대한 연결이 필요한 다른 네트워크와 겹치는 주소 공간을 선택하지 마십시오. 마지막으로 아래에 기입된 CIDR 크기에 대한 권장 사항을 따르십시오.</block>
  <block id="0e8db488f9554136a65dd18025db8cf0" category="paragraph"><block ref="0e8db488f9554136a65dd18025db8cf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a541610269aad8edaf8defd851246b08" category="list-text">SDDC 구성을 검토 및 확인한 다음 SDDC 구축 을 클릭합니다.</block>
  <block id="a8246981b8dc3e6123523500b3b1371d" category="paragraph"><block ref="a8246981b8dc3e6123523500b3b1371d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bb7bef7f28887197cfca7059ef2d6d3" category="paragraph">일반적으로 구축 프로세스를 완료하는 데 약 2시간이 소요됩니다.</block>
  <block id="e9dcc1b6680c77f105c83d040009d685" category="paragraph"><block ref="e9dcc1b6680c77f105c83d040009d685" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79b6ae1d041f5cd8b33d3f351b301275" category="list-text">완료되면 SDDC를 사용할 수 있습니다.</block>
  <block id="9013490d3a116eed1c849197a6c8aac0" category="paragraph"><block ref="9013490d3a116eed1c849197a6c8aac0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e149dd16e33c6137fe08782e96c9b226" category="inline-link-macro">VMC 콘솔에서 SDDC를 구축합니다</block>
  <block id="086760513a416fbc6578703211523314" category="paragraph">SDDC 구축에 대한 단계별 가이드는 를 참조하십시오 <block ref="7279ebe13e8b8c4ee89b8961f2bf1157" category="inline-link-macro-rx"></block>.</block>
  <block id="8a69f1bae52e494c6960f92a27390dcf" category="paragraph">VMware Cloud를 FSx ONTAP에 연결하려면 다음 단계를 수행하십시오.</block>
  <block id="7ca6fbd8bbb6725fab7413e4179738f6" category="list-text">VMware 클라우드 구축이 완료되고 AWS VPC에 연결되면 NetApp ONTAP용 Amazon FSx를 원래 연결된 VPC가 아닌 새 VPC에 구축해야 합니다(아래 스크린샷 참조). 연결된 VPC에 FSX(NFS 및 SMB 부동 IP)를 구축하면 FSX에 액세스할 수 없습니다. Cloud Volumes ONTAP와 같은 iSCSI 엔드포인트는 연결된 VPC에서 정상적으로 작동합니다.</block>
  <block id="da6646a18f048724eb432bf61285ca7f" category="paragraph"><block ref="da6646a18f048724eb432bf61285ca7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85dd65f7163e587c050ea8931a368ae" category="list-text">동일한 지역에 추가 VPC를 구축한 다음 NetApp ONTAP용 Amazon FSx를 새 VPC에 구축합니다.</block>
  <block id="c78834afa7d24e921aa4d756d0a6409f" category="paragraph">VMware Cloud Console에서 SDDC 그룹을 구성하면 FSx가 구축된 새 VPC에 연결하는 데 필요한 네트워킹 구성 옵션을 사용할 수 있습니다. 3단계에서 "그룹에 대한 VMware Transit Connect 구성 시 첨부 파일 및 데이터 전송당 비용이 청구됨"이 선택되어 있는지 확인한 다음 그룹 생성 을 선택합니다. 이 프로세스를 완료하는 데 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="f91a2b452c63b5ccfcb4c39c2957c74e" category="paragraph"><block ref="ca83e0582a449c1b4399270025e1cc4a" category="inline-image-macro-rx" type="image"></block>
<block ref="9232dff72050e533bd1e173e5a0dd48c" category="inline-image-macro-rx" type="image"></block>
<block ref="5a108f597862e683ab9463f7c3ba6df6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fae60fbb10da5c3df46ec8ae03cd29b5" category="inline-link-macro">외부 VPC 연결 지침</block>
  <block id="784ad3266f853af20763bb78f5eec87a" category="list-text">새로 생성된 VPC를 방금 생성된 SDDC 그룹에 연결합니다. External VPC 탭을 선택하고 에 따릅니다 <block ref="19928d01a63fe78e1303b296c2046666" category="inline-link-macro-rx"></block> 그룹에. 이 프로세스를 완료하는 데 10-15분 정도 걸릴 수 있습니다.</block>
  <block id="14466a85376e8776f891db4cb3c38c6c" category="paragraph"><block ref="dd1eb585a08c833cec9544c048af36b6" category="inline-image-macro-rx" type="image"></block>
<block ref="38542de5661e382aba9345fe6e5a991b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8acea1c4fcca87631ca127e2bc757f13" category="inline-link-macro">AWS Transit Gateway를 참조하십시오</block>
  <block id="77508ef16874a250b66be2f90fc59918" category="list-text">외부 VPC 프로세스의 일환으로, 리소스 액세스 관리자를 통해 AWS 콘솔을 통해 새 공유 리소스에 대한 메시지가 표시됩니다. 공유 리소스는 입니다 <block ref="ccce2323414354d76e9cea0c1df9221b" category="inline-link-macro-rx"></block> VMware Transit Connect에서 관리합니다.</block>
  <block id="ac81300f843e6b91377e64a8edb819c2" category="paragraph"><block ref="63de05888c0a11205c33fd560dba3bc5" category="inline-image-macro-rx" type="image"></block>
<block ref="0455c56bd9863ddfae4079b5aabd42e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf415daee6d6f894a54f025534ba071" category="list-text">Transit Gateway Attachment를 생성합니다.</block>
  <block id="e222d36183b455bb51f289144826c239" category="paragraph"><block ref="e222d36183b455bb51f289144826c239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b6693c4eff7f7923c59277702b441a9" category="list-text">VMC 콘솔에서 VPC 첨부 파일을 수락합니다. 이 프로세스를 완료하는 데 약 10분 정도 걸릴 수 있습니다.</block>
  <block id="64d5d06ed03c085c4f5ce23ff6eeddac" category="paragraph"><block ref="64d5d06ed03c085c4f5ce23ff6eeddac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9b85dc0e557eb865bfa9ae84e251623" category="list-text">External VPC 탭에서 Routes 열의 편집 아이콘을 클릭하고 다음과 같은 필수 경로를 추가합니다.</block>
  <block id="ae6434a5ebe0bad2f978fef8e0ed9efe" category="inline-link-macro">유동 IP</block>
  <block id="06651ace1eab88d681ca9a8852bf26e2" category="list-text">NetApp ONTAP용 Amazon FSx의 부동 IP 범위에 대한 경로입니다 <block ref="14a98976d888daccbd07561411cfd6fa" category="inline-link-macro-rx"></block>.</block>
  <block id="5e16e681111a1a5b2dc805d69827532f" category="list-text">Cloud Volumes ONTAP의 부동 IP 범위에 대한 라우트입니다(해당하는 경우).</block>
  <block id="efffbab523616433e2c1ea67cbcaab53" category="list-text">새로 생성된 외부 VPC 주소 공간의 경로입니다.</block>
  <block id="daa8a39ba75e8ac01fd26d579ce35fd9" category="paragraph"><block ref="daa8a39ba75e8ac01fd26d579ce35fd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="853349bb92eccb477b47eef3b8a5d9e2" category="inline-link-macro">방화벽 규칙</block>
  <block id="499ca5dd26dbcc4c89a04ac771b316a6" category="inline-link-macro">세부 단계</block>
  <block id="14c6314f2ae331d7f9a01ac04a75cd2b" category="list-text">마지막으로 양방향 트래픽을 허용합니다 <block ref="0756551700fd3215666355892b2f3692" category="inline-link-macro-rx"></block> FSx/CVO에 액세스하기 위한 것입니다. 다음 사항을 따르십시오 <block ref="583f77470215de8611ddf3fba5fc6512" category="inline-link-macro-rx"></block> SDDC 워크로드 연결을 위한 컴퓨팅 게이트웨이 방화벽 규칙의 경우</block>
  <block id="098b98cba4d6766e7de663adf0fdabb0" category="paragraph"><block ref="098b98cba4d6766e7de663adf0fdabb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f4480b9caed7d956fd6071b4cce03b9" category="list-text">방화벽 그룹이 관리 및 컴퓨팅 게이트웨이 모두에 대해 구성된 후에는 다음과 같이 vCenter에 액세스할 수 있습니다.</block>
  <block id="f1c1b29fad3f2bdb9d8d054686b86542" category="paragraph"><block ref="f1c1b29fad3f2bdb9d8d054686b86542" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8b86f112029b19bf6451ba4624a4090" category="paragraph">다음 단계에서는 요구 사항에 따라 Amazon FSx ONTAP 또는 Cloud Volumes ONTAP가 구성되어 있는지, 그리고 구축을 최적화하기 위해 vSAN에서 스토리지 구성 요소를 오프로드하기 위해 볼륨이 프로비저닝되었는지 확인합니다.</block>
  <block id="a724b4fc4c5f79672a5c572466d5e001" category="doc">Azure용 NetApp 게스트 연결 스토리지 옵션</block>
  <block id="5f18b04dd7d7089a2177c4c930d8d57f" category="paragraph">Azure는 다음과 같은 구성에서 NetApp 스토리지를 지원합니다.</block>
  <block id="1ffaf40c19facb6829b48b667d1dcaa3" category="inline-link-macro">게스트 연결 스토리지로서의 Azure NetApp Files(ANF)</block>
  <block id="ca0f2c52a62624ee3babda4927666866" category="list-text"><block ref="ca0f2c52a62624ee3babda4927666866" category="inline-link-macro-rx"></block></block>
  <block id="3017a9031d66c55b0258c102decfd1b9" category="inline-link-macro">CVO(Cloud Volumes ONTAP)를 게스트 연결 스토리지로 사용합니다</block>
  <block id="426cc154d20d2e0075b81fa214c4d27d" category="list-text"><block ref="426cc154d20d2e0075b81fa214c4d27d" category="inline-link-macro-rx"></block></block>
  <block id="f43b203ec7020e7ea0e408d9d67255fc" category="section-title">AVS(Azure VMware Solution)를 사용하여 Azure NetApp Files 구성</block>
  <block id="f9a184882060f3e5a8b6045e2a53107f" category="paragraph">Azure NetApp Files 공유는 Azure VMware SDDC 솔루션 환경에서 생성된 VM에서 마운트할 수 있습니다. Azure NetApp Files는 SMB 및 NFS 프로토콜을 지원하므로 Linux 클라이언트에 볼륨을 마운트하고 Windows 클라이언트에 매핑할 수도 있습니다. Azure NetApp Files 볼륨은 간단한 5단계를 통해 설정할 수 있습니다.</block>
  <block id="5bb6f16c69df9b9f54bddaaa5e32b415" category="paragraph">Azure NetApp Files 및 Azure VMware 솔루션은 동일한 Azure 지역에 있어야 합니다.</block>
  <block id="8c8b1c25fd4bcb4102a3a834f721ec3e" category="section-title">Azure NetApp Files 볼륨을 생성하고 마운트합니다</block>
  <block id="763b2af90e10e00124392e31d5792be5" category="paragraph">Azure NetApp Files 볼륨을 생성 및 마운트하려면 다음 단계를 수행하십시오.</block>
  <block id="e56fb44cec3cde26b63f919055458c3a" category="list-text">Azure 포털에 로그인하고 Azure NetApp Files에 액세스합니다. Azure NetApp Files 서비스에 대한 액세스를 확인하고 _az 공급자 레지스터--namespace Microsoft.NetApp –wait_명령을 사용하여 Azure NetApp Files 리소스 공급자를 등록합니다. 등록이 완료되면 NetApp 계정을 생성합니다.</block>
  <block id="792c2610bbb56b5803bae91a54f34f51" category="inline-link-macro">Azure NetApp Files 공유</block>
  <block id="a7ad1b2194256789e815facefa65206d" category="paragraph">자세한 단계는 을 참조하십시오 <block ref="8dd8f38a60f74263b1cf35e18285061e" category="inline-link-macro-rx"></block>. 이 페이지에서는 단계별 프로세스를 안내합니다.</block>
  <block id="710954ec785b2a7f67c2ef1c3f2f9d19" category="paragraph"><block ref="710954ec785b2a7f67c2ef1c3f2f9d19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe57bd1c78e967b463574e3089a42968" category="list-text">NetApp 계정을 생성한 후 필요한 서비스 수준과 크기로 용량 풀을 설정합니다.</block>
  <block id="3928a91ce2a9b26c809bec745d6b9daf" category="paragraph">자세한 내용은 을 참조하십시오 <block ref="e7281cc99a6c9a39d5a16325a46f1f7c" category="inline-link-macro-rx"></block>.</block>
  <block id="7ffd44a691267afdf7cc1178ab6115f8" category="paragraph"><block ref="7ffd44a691267afdf7cc1178ab6115f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42e9b5ee697da49886fd18e89e6ab1af" category="inline-link-macro">Azure NetApp Files에 서브넷 위임</block>
  <block id="ee13d45546639cd210b35ce3665b6885" category="list-text">Azure NetApp Files에 대해 위임된 서브넷을 구성하고 볼륨을 생성하는 동안 이 서브넷을 지정합니다. 위임된 서브넷을 생성하는 자세한 단계는 을 참조하십시오 <block ref="ad52de6b143679c946d36f9e4248f40c" category="inline-link-macro-rx"></block>.</block>
  <block id="70a08a2f18d96817bf63302571e62634" category="paragraph"><block ref="70a08a2f18d96817bf63302571e62634" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96501b128e8ffab4b107cd6ffa7da649" category="list-text">Capacity Pools 블레이드 아래의 Volumes 블레이드를 사용하여 SMB 볼륨을 추가합니다. SMB 볼륨을 생성하기 전에 Active Directory 커넥터가 구성되어 있는지 확인합니다.</block>
  <block id="f676bcdffa60a69ff49ba9ffdbb2b912" category="paragraph"><block ref="f676bcdffa60a69ff49ba9ffdbb2b912" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9095b4995e678294045e2a1501d1db3" category="list-text">검토 + 생성 을 클릭하여 SMB 볼륨을 생성합니다.</block>
  <block id="e48925dc65abf32faa19c5d430cf6d6d" category="paragraph">애플리케이션이 SQL Server인 경우 SMB의 지속적인 가용성을 설정합니다.</block>
  <block id="be1613efbff068fd23ee511fe4e6dc51" category="paragraph"><block ref="be1613efbff068fd23ee511fe4e6dc51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2b999c81e324f553ec9720c334325ee" category="paragraph"><block ref="b2b999c81e324f553ec9720c334325ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe5eed95829ff2b525461ee72a9f3f23" category="inline-link-macro">Azure NetApp Files에 대한 성능 고려 사항</block>
  <block id="2c5ce17dd48f2551465b828065fd8300" category="paragraph">크기 또는 할당량별 Azure NetApp Files 볼륨 성능에 대한 자세한 내용은 을 참조하십시오 <block ref="ffec162f488d413e68dfe18d328e177e" category="inline-link-macro-rx"></block>.</block>
  <block id="bef7cec065f33ededdd1b50d74800b72" category="list-text">연결이 완료되면 볼륨을 마운트하여 애플리케이션 데이터에 사용할 수 있습니다.</block>
  <block id="8b3c17098d0d024937d60849b3bd8edb" category="paragraph">이를 수행하려면 Azure 포털에서 볼륨 블레이드를 클릭한 다음 마운트할 볼륨을 선택하고 마운트 지침을 액세스합니다. 경로를 복사하고 Map Network Drive 옵션을 사용하여 Azure VMware Solution SDDC에서 실행되는 VM에 볼륨을 마운트합니다.</block>
  <block id="413fcfe1d831f95cd95f8f3bb9030eec" category="paragraph"><block ref="413fcfe1d831f95cd95f8f3bb9030eec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e50c675280580c3249f58f2f3eefdb86" category="paragraph"><block ref="e50c675280580c3249f58f2f3eefdb86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13c8bc9575bbdc3a8a30021320abbd69" category="list-text">Azure VMware Solution SDDC에서 실행되는 Linux VM에 NFS 볼륨을 마운트하려면 이 프로세스를 사용합니다. 볼륨 재구성 또는 동적 서비스 수준 기능을 사용하여 워크로드 요구 사항을 충족합니다.</block>
  <block id="ff817c6ff423e680ddf0a8398efdfb5a" category="paragraph"><block ref="ff817c6ff423e680ddf0a8398efdfb5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da94ac228f6efdf07fe7e43b1441faf2" category="paragraph">자세한 내용은 을 참조하십시오 <block ref="ea07f7f3cbdf3d62072fbe16546616d3" category="inline-link-macro-rx"></block>.</block>
  <block id="1d583a1a8ff1ca8ae3360c7e33ecd984" category="section-title">Azure에 새로운 Cloud Volumes ONTAP 구축</block>
  <block id="ed1019c297fadb83e87437230788320c" category="paragraph">Cloud Volumes ONTAP 공유 및 LUN은 Azure VMware Solution SDDC 환경에서 생성된 VM에서 마운트할 수 있습니다. Cloud Volumes ONTAP는 iSCSI, SMB 및 NFS 프로토콜을 지원하므로 Linux 클라이언트와 Windows 클라이언트에도 볼륨을 마운트할 수 있습니다. Cloud Volumes ONTAP 볼륨은 몇 가지 간단한 단계를 통해 설정할 수 있습니다.</block>
  <block id="3b020916a45973167bc70cb4517bd8c8" category="inline-link-macro">시스템 간 데이터 복제 설정</block>
  <block id="e9cac40069a313b824541cda06c18a06" category="paragraph">재해 복구 또는 마이그레이션을 위해 사내 환경에서 클라우드로 볼륨을 복제하려면 사이트 간 VPN 또는 ExpressRoute를 사용하여 Azure에 대한 네트워크 연결을 설정합니다. 사내의 데이터를 Cloud Volumes ONTAP로 복제하는 작업은 이 문서의 범위를 벗어납니다. 사내 시스템과 Cloud Volumes ONTAP 시스템 간에 데이터를 복제하려면 을 참조하십시오 <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="9eb931a836eecf8e743b47b449c70bc5" category="inline-link-macro">Cloud Volumes ONTAP Sizer</block>
  <block id="165fc07e6910d8748be18ecaaab5392d" category="admonition">사용 <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Cloud Volumes ONTAP 인스턴스의 크기를 정확하게 지정합니다. 또한 Cloud Volumes ONTAP Sizer에서 입력으로 사용할 온프레미스 성능을 모니터링합니다.</block>
  <block id="a1d02afc571062ee1235156b645846f8" category="list-text">NetApp Cloud Central에 로그인 - 패브릭 보기 화면이 표시됩니다. Cloud Volumes ONTAP 탭을 찾아 Cloud Manager로 이동 을 선택합니다. 로그인하면 Canvas 화면이 표시됩니다.</block>
  <block id="1563f27024f7b2b0a96be687f878206d" category="paragraph"><block ref="1563f27024f7b2b0a96be687f878206d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f067fbf4a3196796318f7e878eaa2a3" category="list-text">Cloud Manager 홈 페이지에서 작업 환경 추가를 클릭한 다음 클라우드로 Microsoft Azure를 선택하고 시스템 구성의 유형을 선택합니다.</block>
  <block id="e59c8066b7736d6ede98e2b57d619b60" category="paragraph"><block ref="e59c8066b7736d6ede98e2b57d619b60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21568dd1e2a5acafeee9d119cd012876" category="list-text">첫 번째 Cloud Volumes ONTAP 작업 환경을 생성할 때 Cloud Manager에서 커넥터를 배포하라는 메시지를 표시합니다.</block>
  <block id="4c3665ca095a8a103c69fac1ac46fb59" category="paragraph"><block ref="4c3665ca095a8a103c69fac1ac46fb59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54ae357a0d5e74ebab86e52641490fc0" category="list-text">커넥터가 생성되면 세부 정보 및 자격 증명 필드를 업데이트합니다.</block>
  <block id="9b971596a6ee599483fd04c84d2ce18d" category="paragraph"><block ref="9b971596a6ee599483fd04c84d2ce18d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf5341803b0061ef190495343f39fa02" category="list-text">환경 이름 및 관리자 자격 증명을 비롯하여 생성할 환경에 대한 세부 정보를 제공합니다. Azure 환경의 리소스 그룹 태그를 선택적 매개 변수로 추가합니다. 작업을 마친 후 계속 을 클릭합니다.</block>
  <block id="350a5c2219e5e14fd23dda8372344842" category="paragraph"><block ref="350a5c2219e5e14fd23dda8372344842" category="inline-image-macro-rx" type="image"></block></block>
  <block id="360a69a0b184770c2409949f2c7e1140" category="list-text">클라우드 데이터 감지, 클라우드 백업 및 Cloud Insights를 포함하여 Cloud Volumes ONTAP 구축을 위한 애드온 서비스를 선택하십시오. 서비스를 선택한 다음 계속 을 클릭합니다.</block>
  <block id="11728d9ffc9e6944adf4891d5543e154" category="paragraph"><block ref="11728d9ffc9e6944adf4891d5543e154" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee060e03da823e605453fbfa27743d77" category="list-text">Azure 위치 및 연결을 구성합니다. 사용할 Azure 지역, 리소스 그룹, VNET 및 서브넷을 선택합니다.</block>
  <block id="4549d76a3daf0d322686b6d4f6fb1490" category="paragraph"><block ref="4549d76a3daf0d322686b6d4f6fb1490" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1c88093dde70f0165ade30b74c908ad" category="list-text">라이센스 옵션 선택: 사용한 만큼만 지불 또는 BYOL 방식으로 기존 라이센스 사용 이 예에서는 pay-as-you-go 옵션을 사용합니다.</block>
  <block id="10085b1c84507f0da366d741a248d728" category="paragraph"><block ref="10085b1c84507f0da366d741a248d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2c782d387cdd1de07d0119c2794edc8" category="list-text">다양한 유형의 워크로드에 사용할 수 있는 사전 구성된 여러 패키지 중 하나를 선택합니다.</block>
  <block id="942b902e3715b75e8e6257349bbe93ff" category="paragraph"><block ref="942b902e3715b75e8e6257349bbe93ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c7055bfbaac9b0236d0bedccfb616d0" category="list-text">Azure 리소스의 활성화 및 할당과 관련된 두 가지 계약에 동의합니다. Cloud Volumes ONTAP 인스턴스를 만들려면 이동을 클릭합니다.</block>
  <block id="c19dadb8117ac0d88e543accbb1c1096" category="paragraph"><block ref="c19dadb8117ac0d88e543accbb1c1096" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b8217eede1f57c19d7d36c1501891b" category="list-text">Cloud Volumes ONTAP를 프로비저닝하면 Canvas 페이지의 작업 환경에 나열됩니다.</block>
  <block id="b6bb322a7578acfb8670b3ce8bc96fc9" category="paragraph"><block ref="b6bb322a7578acfb8670b3ce8bc96fc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="962c53cd54b0b3876e054c2fea4c4ff8" category="section-title">SMB 볼륨을 위한 추가 구성</block>
  <block id="9af22b589cfa398b9a704f786d96a90d" category="list-text">작업 환경이 준비되면 CIFS 서버가 적절한 DNS 및 Active Directory 구성 매개 변수로 구성되어 있는지 확인합니다. 이 단계는 SMB 볼륨을 생성하기 전에 필요합니다.</block>
  <block id="02cbbc24385dbe83fb42a1bd0c5668da" category="paragraph"><block ref="02cbbc24385dbe83fb42a1bd0c5668da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d923f79d8112841c7df8503e86f0af4a" category="list-text">SMB 볼륨을 생성하는 것은 쉬운 프로세스입니다. CVO 인스턴스를 선택하여 볼륨을 생성하고 Create Volume 옵션을 클릭합니다. 적절한 크기를 선택하고 클라우드 관리자가 포함하는 애그리게이트를 선택하거나, 고급 할당 메커니즘을 사용하여 특정 애그리게이트에 배치할 수 있습니다. 이 데모에서는 SMB가 프로토콜로 선택됩니다.</block>
  <block id="a74d409c32c4bc504768c6a7607fc409" category="paragraph"><block ref="a74d409c32c4bc504768c6a7607fc409" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a14aa082ec04534624b099e0a4bd9" category="list-text">볼륨 용량 할당 후 볼륨 창 아래에서 사용할 수 있습니다. CIFS 공유가 프로비저닝되므로 사용자 또는 그룹에 파일 및 폴더에 대한 권한을 제공하고 해당 사용자가 공유를 액세스하고 파일을 생성할 수 있는지 확인합니다. 파일 및 폴더 권한이 모두 SnapMirror 복제의 일부로 유지되므로 볼륨이 사내 환경에서 복제된 경우에는 이 단계가 필요하지 않습니다.</block>
  <block id="8923d310a6b50c677ed6f68410181b46" category="paragraph"><block ref="8923d310a6b50c677ed6f68410181b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="776a8d832701253eb40b056e68086fcd" category="list-text">볼륨을 생성한 후 mount 명령을 사용하여 Azure VMware Solution SDDC 호스트에서 실행 중인 VM에서 공유에 연결합니다.</block>
  <block id="70307f46aa9c37929516c971f3445caa" category="list-text">다음 경로를 복사하고 Map Network Drive 옵션을 사용하여 Azure VMware Solution SDDC에서 실행되는 VM에 볼륨을 마운트합니다.</block>
  <block id="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="paragraph"><block ref="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d1f50043685559ea05d7c21ae5a6d8a" category="paragraph"><block ref="1d1f50043685559ea05d7c21ae5a6d8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27c47ada1e7cb796a499ede048474b99" category="section-title">LUN을 호스트에 연결합니다</block>
  <block id="2e7b38e3108ed39835e616f3a8eef4d9" category="paragraph">LUN을 호스트에 연결하려면 다음 단계를 수행하십시오.</block>
  <block id="2fc81fae057994bbe703cb2892b727c9" category="list-text">Canvas 페이지에서 Cloud Volumes ONTAP 작업 환경을 두 번 클릭하여 볼륨을 생성하고 관리합니다.</block>
  <block id="3a596dcd3d3dd43ed187aea6bea5842e" category="list-text">볼륨 추가 &gt; 새 볼륨 을 클릭하고 iSCSI 를 선택한 다음 이니시에이터 그룹 생성 을 클릭합니다. 계속 을 클릭합니다.</block>
  <block id="06fcf6729491b5106094916e154fb565" category="paragraph"><block ref="06fcf6729491b5106094916e154fb565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6297ccc26d99397b36875f005bb1b800" category="list-text">볼륨이 프로비저닝되면 볼륨을 선택한 다음 대상 IQN을 클릭합니다. IQN(iSCSI Qualified Name)을 복사하려면 Copy(복사)를 클릭합니다. 호스트에서 LUN으로의 iSCSI 접속을 설정합니다.</block>
  <block id="7af0094f03c81886be499600b8563647" category="paragraph">Azure VMware Solution SDDC에 있는 호스트에 대해 동일한 작업을 수행하려면 다음을 수행합니다.</block>
  <block id="640e587a72f6b61dc8d20a6de477db96" category="list-text">Azure VMware Solution SDDC에서 호스팅되는 VM에 대한 RDP</block>
  <block id="c4b994ff6c03cf45471392a32ff9809b" category="list-text">iSCSI 초기자 속성 대화 상자(서버 관리자 &gt; 대시보드 &gt; 도구 &gt; iSCSI 초기자)를 엽니다.</block>
  <block id="beacd9a0aebca77f6cc20d5cab0fb37c" category="list-text">검색 탭에서 포털 검색 또는 포털 추가 를 클릭한 다음 iSCSI 대상 포트의 IP 주소를 입력합니다.</block>
  <block id="c4ab0fc2a07f004fb45eacc91a07e22c" category="list-text">대상 탭에서 검색된 대상을 선택한 다음 로그온 또는 연결을 클릭합니다.</block>
  <block id="4f04cc11e470becd190503a4cea0e217" category="list-text">다중 경로 활성화 를 선택한 다음 컴퓨터가 시작될 때 이 연결 자동 복원 또는 즐겨찾기 대상 목록에 이 연결 추가 를 선택합니다. 고급 을 클릭합니다.</block>
  <block id="2d5b864b177738fa7a03f083ae03d2a3" category="paragraph">* 참고: * Windows 호스트에는 클러스터의 각 노드에 대한 iSCSI 연결이 있어야 합니다. 기본 DSM은 가장 적합한 경로를 선택합니다.</block>
  <block id="829bd9f13853ee7a86f5805c316df650" category="paragraph"><block ref="829bd9f13853ee7a86f5805c316df650" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f2340e83f93b283dd5fc7023e4e72a2" category="paragraph">SVM(스토리지 가상 머신)의 LUN은 Windows 호스트에 디스크로 표시됩니다. 추가된 새 디스크는 호스트에서 자동으로 검색되지 않습니다. 수동 재검색을 트리거하여 다음 단계를 수행하여 디스크를 검색합니다.</block>
  <block id="d16c566049378cf49448803dfc6ab25d" category="list-text">시작 &gt; 관리 도구 &gt; 컴퓨터 관리를 차례로 클릭하여 Windows 컴퓨터 관리 유틸리티를 엽니다.</block>
  <block id="b1babb2780a260f54d7e9f21602773df" category="list-text">탐색 트리에서 스토리지 노드를 확장합니다.</block>
  <block id="678149d88ae91abbb05c5df448a4e8af" category="list-text">디스크 관리를 클릭합니다.</block>
  <block id="35e2e6c4175353900be410088efcc1b9" category="list-text">작업 &gt; 디스크 다시 검사 를 클릭합니다.</block>
  <block id="d378c726809748df2090ec116c7232b4" category="paragraph"><block ref="d378c726809748df2090ec116c7232b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8a056111a10f9e055d309c54e7ca2bb" category="paragraph">Windows 호스트에서 새 LUN을 처음 액세스할 때 파티션이나 파일 시스템이 없습니다. LUN을 초기화하고 필요에 따라 다음 단계를 완료하여 파일 시스템으로 LUN을 포맷합니다.</block>
  <block id="8db13bd6122ee1a2b04931073cb808d7" category="list-text">Windows 디스크 관리를 시작합니다.</block>
  <block id="18e601e3f0e159e918f7adb9fd89fb99" category="list-text">LUN을 마우스 오른쪽 버튼으로 클릭한 다음 필요한 디스크 또는 파티션 유형을 선택합니다.</block>
  <block id="6b3a58a7b9961d5d214b65da735d2f89" category="list-text">마법사의 지침을 따릅니다. 이 예에서는 드라이브 E:가 마운트되었습니다</block>
  <block id="586f9ee0f7d5544a894ea05b9df312d7" category="paragraph"><block ref="586f9ee0f7d5544a894ea05b9df312d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ff716a75c3423262418c90aad971f10" category="paragraph"><block ref="6ff716a75c3423262418c90aad971f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6120544c737d67dd31f47d101fe21a84" category="doc">클라우드 공급자에서 가상화 환경 구성</block>
  <block id="f4f7adb7cbe18f2cdd82be75a52b0417" category="paragraph">지원되는 각 하이퍼 스케일러에서 가상화 환경을 구성하는 방법에 대한 자세한 내용은 여기 를 참조하십시오.</block>
  <block id="5032d5a1ed8a62f591efaaf45204907f" category="paragraph">다음 옵션 중 하나를 선택하여 원하는 하이퍼스케일러의 섹션으로 이동합니다.</block>
  <block id="00bdc2e43f70d995636d66a898fe5e40" category="inline-link-macro">AVS(Amazon VMware Solution) 구성</block>
  <block id="0753e0a92e5826dd007d8fd27f5b31c9" category="list-text"><block ref="0753e0a92e5826dd007d8fd27f5b31c9" category="inline-link-macro-rx"></block></block>
  <block id="c44ad7e3733396d542197ea02e4dd5b7" category="inline-link-macro">Azure VMware VMC(Managed Cloud) 구성</block>
  <block id="91ef3d1a8fa3d61d3abb32b5f583d779" category="list-text"><block ref="91ef3d1a8fa3d61d3abb32b5f583d779" category="inline-link-macro-rx"></block></block>
  <block id="5f80992ee008938a45a68b0f0ae94709" category="inline-link-macro">GCVE(Google Cloud Virtualization Engine) 구성</block>
  <block id="a98da75fcd0e1711d652d1e209647651" category="list-text"><block ref="a98da75fcd0e1711d652d1e209647651" category="inline-link-macro-rx"></block></block>
  <block id="8b9304861ce23a5778f658d1ba557184" category="section-title">AWS용 VMC 구성</block>
  <block id="e6719013bc5803c0da0d4bf78fc8c4a0" category="admonition">게스트 내 스토리지는 FSx ONTAP 및 Cloud Volumes ONTAP를 AWS VMC에 연결하는 유일한 지원 방법입니다.</block>
  <block id="2bdad04391749295f6c0f0f0f0d5df87" category="section-title">Azure용 AVS 구성</block>
  <block id="00ce356ad004b72efc4b99389b52af63" category="paragraph">온프레미스와 마찬가지로 Azure VMware 솔루션 계획은 VM 및 마이그레이션을 생성할 수 있는 성공적인 프로덕션 준비 환경에 매우 중요합니다.</block>
  <block id="491aa8f554f95207a4b7d47f89777e13" category="paragraph">이 섹션에서는 Azure VMware 솔루션을 설정 및 관리하고 NetApp 스토리지를 연결하는 데 사용할 수 있는 옵션과 함께 사용하는 방법을 설명합니다.</block>
  <block id="cc887bc72eb6e7422bfa13437f902e54" category="admonition">게스트 내 스토리지는 Azure NetApp Files 및 Cloud Volumes ONTAP를 Azure VMware 솔루션에 연결하는 유일한 지원 방법입니다.</block>
  <block id="3d24cd3e433bf1992e011c9f92c3fab6" category="inline-link-macro">리소스 공급자를 등록하고 프라이빗 클라우드를 생성합니다</block>
  <block id="a1123889b6465e93a2209c2a0ca667ef" category="inline-link-macro">새 또는 기존 ExpressRoute 가상 네트워크 게이트웨이에 연결합니다</block>
  <block id="ae1764c7cb70aed2d4548c424d7bf34a" category="inline-link-macro">네트워크 연결을 확인하고 프라이빗 클라우드에 액세스합니다</block>
  <block id="c8ecd368a187a4d847c04af93c7ca292" category="section-title">Google Cloud Platform용 GCVE 구성</block>
  <block id="9883d049f97d69a9f2326d61585d8fbe" category="paragraph">온프레미스에서와 마찬가지로, VM 및 마이그레이션을 생성하기 위한 성공적인 프로덕션 준비 환경을 위해서는 Google Cloud VMware Engine(GCVE)을 계획하는 것이 매우 중요합니다.</block>
  <block id="6ad49d2b544134f2192d1612a572bdd6" category="paragraph">이 섹션에서는 GCVE를 설정 및 관리하고 NetApp 스토리지를 연결하는 데 사용할 수 있는 옵션과 함께 사용하는 방법을 설명합니다.</block>
  <block id="a74a86037d1564ce62843a1252f6ad37" category="admonition">게스트 내 저장소는 Cloud Volumes ONTAP 및 Cloud Volumes Services를 GCVE에 연결하는 유일한 지원 방법입니다.</block>
  <block id="11a31c6d83a723b3ea9c348c22e86238" category="inline-link-macro">GCVE 배포 및 구성</block>
  <block id="3e5cc29621d2619be0d7b1569da6909c" category="inline-link-macro">GCVE에 대한 개인 액세스를 활성화합니다</block>
  <block id="9eaed1d83e18be57bbead8a1f4bf4abe" category="doc">NetApp 기본 데이터 저장소 옵션 for GCP</block>
  <block id="ae295ef15cb155f8a1af7d255e34298d" category="doc">AWS를 위한 NetApp 게스트 연결 스토리지 옵션</block>
  <block id="0d349db2638a92fd70bcc7d2f31663ab" category="paragraph">AWS는 다음과 같은 구성에서 게스트 연결 NetApp 스토리지를 지원합니다.</block>
  <block id="4a7272ea95323d5fef2e377b91b5f16d" category="inline-link-macro">FSX ONTAP를 게스트 연결 스토리지로 사용합니다</block>
  <block id="ac68b9acaa4ad0b0a4dc57efbda279fc" category="list-text"><block ref="ac68b9acaa4ad0b0a4dc57efbda279fc" category="inline-link-macro-rx"></block></block>
  <block id="6e3fe132749fe21d23cf75f00317a6fe" category="section-title">AWS에서 VMware Cloud를 사용하여 NetApp ONTAP용 Amazon FSx를 구성합니다</block>
  <block id="5f19d821dc2e2e3a8e9418909df59733" category="paragraph">NetApp ONTAP용 Amazon FSx 파일 공유 및 LUN은 AWS의 VMware Cloud에서 VMware SDDC 환경 내에 생성된 VM에서 마운트할 수 있습니다. Linux 클라이언트에도 볼륨을 마운트하고 NFS 또는 SMB 프로토콜을 사용하여 Windows 클라이언트에 매핑할 수 있으며, iSCSI를 통해 마운트하면 Linux 또는 Windows 클라이언트에서 LUN에 블록 디바이스로 액세스할 수 있습니다. NetApp ONTAP 파일 시스템용 Amazon FSx는 다음 단계를 통해 빠르게 설정할 수 있습니다.</block>
  <block id="190b27040d3191ccf35bdb35221f0682" category="admonition">AWS 기반 NetApp ONTAP 및 VMware Cloud용 Amazon FSx는 더 나은 성능을 달성하고 가용성 영역 간의 데이터 전송 비용을 방지하려면 동일한 가용성 영역에 있어야 합니다.</block>
  <block id="f8caa19e45e4a42ea7bc10cad5d49ae8" category="section-title">ONTAP 볼륨용 Amazon FSx를 생성하고 마운트합니다</block>
  <block id="e765d7d83fde51af5391c87cc45dccf2" category="paragraph">NetApp ONTAP 파일 시스템용 Amazon FSx를 생성하고 마운트하려면 다음 단계를 완료하십시오.</block>
  <block id="43935f267f64b4ca1a3f1803272df64b" category="inline-link-macro">Amazon FSx 콘솔</block>
  <block id="4d33567207f0232b86c9bec4b4f38d45" category="list-text">를 엽니다 <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block> 파일 시스템 생성 마법사를 시작하려면 파일 시스템 생성 을 선택합니다.</block>
  <block id="df08dda7dc18ddb7de0e9ad5001a9f04" category="list-text">파일 시스템 유형 선택 페이지에서 NetApp ONTAP용 Amazon FSx 를 선택하고 다음 을 선택합니다. 파일 시스템 생성 페이지가 나타납니다.</block>
  <block id="c40ea60211b89b2179fe7a947527ff66" category="paragraph"><block ref="c40ea60211b89b2179fe7a947527ff66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f29804f0e866cb47ba2fa233a71a54fd" category="list-text">네트워킹 섹션의 VPC(가상 프라이빗 클라우드)에서 경로 테이블과 함께 적절한 VPC 및 기본 서브넷을 선택합니다. 이 경우 드롭다운에서 vmcfsx2.vpc가 선택됩니다.</block>
  <block id="628892e49fa967795d4d8d3269c5bb31" category="paragraph"><block ref="628892e49fa967795d4d8d3269c5bb31" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf9c04e1d81f05e344db236ac47ea588" category="list-text">생성 방법의 경우 표준 작성을 선택합니다. 빠른 만들기를 선택할 수도 있지만 이 문서에서는 표준 만들기 옵션을 사용합니다.</block>
  <block id="e3c13c0fe612a941f86617c0ad730fca" category="paragraph"><block ref="e3c13c0fe612a941f86617c0ad730fca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e47c53bc440aebf2328e497b46953118" category="paragraph"><block ref="e47c53bc440aebf2328e497b46953118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed02b1594feb57e5c5c1ca0678086dd" category="list-text">보안 및 암호화 섹션의 암호화 키에 대해 파일 시스템의 유휴 데이터를 보호하는 AWS KMS(Key Management Service) 암호화 키를 선택합니다. 파일 시스템 관리 암호에 fsxadmin 사용자의 보안 암호를 입력합니다.</block>
  <block id="450514d9ec3a47df8e580605e80579b7" category="paragraph"><block ref="450514d9ec3a47df8e580605e80579b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b969656105cc9174e398fa5754382d5b" category="list-text">가상 시스템에서 REST API 또는 CLI를 사용하여 ONTAP를 관리하는 데 vsadmin과 함께 사용할 암호를 지정합니다. 암호를 지정하지 않으면 fsxadmin 사용자를 SVM 관리에 사용할 수 있습니다. Active Directory 섹션에서 Active Directory를 SVM에 가입하여 SMB 공유를 프로비저닝해야 합니다. 기본 스토리지 가상 머신 구성 섹션에서 이 검증에 사용할 스토리지의 이름을 제공합니다. SMB 공유는 자체 관리되는 Active Directory 도메인을 사용하여 프로비저닝됩니다.</block>
  <block id="0b0a8d3b6da586b1c3d7ace81f086743" category="paragraph"><block ref="0b0a8d3b6da586b1c3d7ace81f086743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89a8b582feabb26f60740f7b0a57aaef" category="list-text">기본 볼륨 구성 섹션에서 볼륨 이름 및 크기를 지정합니다. NFS 볼륨입니다. 스토리지 효율성의 경우 사용 을 선택하여 ONTAP 스토리지 효율성 기능(압축, 중복제거, 컴팩션)을 사용하도록 설정하거나 해제 를 선택하여 해제합니다.</block>
  <block id="2cfdc5814e94a8d05a802a6b639158b7" category="paragraph"><block ref="2cfdc5814e94a8d05a802a6b639158b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59ed30f46b9afae4f90b77ac3ed74f8e" category="list-text">파일 시스템 생성 페이지에 표시된 파일 시스템 구성을 검토합니다.</block>
  <block id="08ef5aaea85c8112d5d0e368443ee4fe" category="list-text">파일 시스템 생성 을 클릭합니다.</block>
  <block id="d385818e8551a5f93e9591daf3cf7c22" category="paragraph"><block ref="aae4a315cf943820b378b71447a7994a" category="inline-image-macro-rx" type="image"></block>
<block ref="e34db9249abae41534adba1bed16b8d1" category="inline-image-macro-rx" type="image"></block>
<block ref="f1c6728d54b85d98dd49bf5dc91e4f97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f5cc47067a5c4b536ab91f1a843de82" category="inline-link-macro">NetApp ONTAP용 Amazon FSx 시작하기</block>
  <block id="e37ec80b6a23f377fd957d8c83c7a7b5" category="paragraph">자세한 내용은 을 참조하십시오 <block ref="01eec31289b39ab7b89a00515912c371" category="inline-link-macro-rx"></block>.</block>
  <block id="af62c8c40f4b51eaee5cfbcfdb7bffaa" category="paragraph">위와 같이 파일 시스템을 생성한 후 필요한 크기와 프로토콜을 사용하여 볼륨을 생성합니다.</block>
  <block id="5eb9e90ab2c5435bcefd918c8c8a7304" category="list-text">를 엽니다 <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block>.</block>
  <block id="4cdc643691b84580850903954cdca1d1" category="list-text">왼쪽 탐색 창에서 파일 시스템 을 선택한 다음 볼륨을 생성할 ONTAP 파일 시스템을 선택합니다.</block>
  <block id="05c0eed2abbd9c20871b6af0eb7b1e38" category="list-text">Volumes 탭을 선택합니다.</block>
  <block id="511e546bcb3da3ea3db700200e857ebf" category="list-text">Create Volume 탭을 선택합니다.</block>
  <block id="328a4173ff8b40f0204a78c6a579b01e" category="list-text">볼륨 생성 대화 상자가 나타납니다.</block>
  <block id="b1734fefd5bf5fc9e481a277d683ca10" category="paragraph">이 섹션에서는 데모용으로 NFS 볼륨을 생성하여 AWS의 VMware 클라우드에서 실행되는 VM에 손쉽게 마운트할 수 있습니다. nfsdemovol01은 아래 그림과 같이 생성됩니다.</block>
  <block id="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="paragraph"><block ref="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72e172d843c1baf9acb881337f0bb2cc" category="section-title">Linux 클라이언트에 FSx ONTAP 볼륨을 마운트합니다</block>
  <block id="682dccf32ec3d6c1e1ca2548a43c4245" category="paragraph">이전 단계에서 생성한 FSx ONTAP 볼륨을 마운트합니다. AWS SDDC의 VMC 내에 있는 Linux VM에서 다음 단계를 완료합니다.</block>
  <block id="e059ff9407d5207f003eae103b4c7a3a" category="list-text">지정된 Linux 인스턴스에 연결합니다.</block>
  <block id="a8dc83c93fa2350d1419b44103864f2c" category="list-text">SSH(Secure Shell)를 사용하여 인스턴스의 터미널을 열고 적절한 자격 증명을 사용하여 로그인합니다.</block>
  <block id="454d9d1fe6ad680e393543d5e7b11669" category="list-text">다음 명령을 사용하여 볼륨의 마운트 지점에 대한 디렉토리를 만듭니다.</block>
  <block id="9e770ba792bd4db694940294a77cccee" category="list-text">NetApp ONTAP NFS 볼륨용 Amazon FSx를 이전 단계에서 생성한 디렉토리에 마운트합니다.</block>
  <block id="6631f82f4a955cf7fe5644adadf79e47" category="paragraph"><block ref="6631f82f4a955cf7fe5644adadf79e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2774f9046ee4873805e1f044fa12fe85" category="list-text">실행된 후 df 명령을 실행하여 마운트를 확인합니다.</block>
  <block id="d06051412d6da4495ca1a69429ea4fdf" category="paragraph"><block ref="d06051412d6da4495ca1a69429ea4fdf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0927b028b8b35cb7421cd2d29ebac0ab" category="section-title">Microsoft Windows 클라이언트에 FSx ONTAP 볼륨을 연결합니다</block>
  <block id="49a305dd021166bf8a508fb51b3fce24" category="paragraph">Amazon FSx 파일 시스템에서 파일 공유를 관리 및 매핑하려면 공유 폴더 GUI를 사용해야 합니다.</block>
  <block id="0f51d6ad9d95d24bf6d5b0e18d947382" category="list-text">시작 메뉴를 열고 관리자 권한으로 실행 을 사용하여 fsmgmt.msc 를 실행합니다. 이렇게 하면 공유 폴더 GUI 도구가 열립니다.</block>
  <block id="0186f9c0fa21b0c8ab82fadf036afe8f" category="list-text">작업 &gt; 모든 작업 을 클릭하고 다른 컴퓨터에 연결 을 선택합니다.</block>
  <block id="f5cf362d19da392bad46d1cb4bbea453" category="list-text">다른 컴퓨터의 경우 SVM(스토리지 가상 머신)의 DNS 이름을 입력합니다. 예를 들어, FSXSMBTESTING01.FSXTESTING.LOCAL이 이 예제에서 사용됩니다.</block>
  <block id="882da317003fa80717e3939e41c5aa32" category="admonition">TP는 Amazon FSx 콘솔에서 SVM의 DNS 이름을 찾아 Storage Virtual Machines를 선택하고 SVM을 선택한 다음 Endpoints로 스크롤하여 SMB DNS 이름을 찾습니다. 확인 을 클릭합니다. 공유 폴더 목록에 Amazon FSx 파일 시스템이 나타납니다.</block>
  <block id="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="paragraph"><block ref="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd517d0d40877562e2dae460910a5260" category="list-text">공유 폴더 도구의 왼쪽 창에서 공유 를 선택하여 Amazon FSx 파일 시스템에 대한 활성 공유를 표시합니다.</block>
  <block id="e4fb530e581118e4aa66166f33242547" category="paragraph"><block ref="e4fb530e581118e4aa66166f33242547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b994a2e22edf9cb0de792e6a494da514" category="list-text">이제 새 공유를 선택하고 공유 폴더 생성 마법사를 완료합니다.</block>
  <block id="9630a309cdca9ed17b688fe15c03a200" category="paragraph"><block ref="f821d910b54d4df166bfb6c9a0fbeac1" category="inline-image-macro-rx" type="image"></block>
<block ref="1456921fb33e6c835f2ea077607c478a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed3796b20dc1d1a4f1756d0cb0f45489" category="inline-link-macro">SMB 공유 생성</block>
  <block id="dc77f3b6074a456c2be3f16b862db081" category="paragraph">Amazon FSx 파일 시스템에서 SMB 공유를 생성 및 관리하는 방법에 대한 자세한 내용은 를 참조하십시오 <block ref="a85495f11ff3e696252abf798d30d57d" category="inline-link-macro-rx"></block>.</block>
  <block id="470140537c670eb8edb32bf6e8b2bad5" category="list-text">접속이 완료되면 SMB 공유를 연결하고 애플리케이션 데이터에 사용할 수 있습니다. 이 작업을 수행하려면 공유 경로를 복사하고 네트워크 드라이브 매핑 옵션을 사용하여 AWS SDDC의 VMware Cloud에서 실행되는 VM에 볼륨을 마운트합니다.</block>
  <block id="0542af5401c04588abf9b665f31829b6" category="paragraph"><block ref="0542af5401c04588abf9b665f31829b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6c5856c2845517bb6408529fb90b57e" category="section-title">NetApp ONTAP LUN용 FSx를 iSCSI를 사용하여 호스트에 연결합니다</block>
  <block id="716fd43b3bc7735b075d056d4ac18dc4" category="paragraph">FSx의 iSCSI 트래픽은 이전 섹션에 제공된 경로를 통해 VMware Transit Connect/AWS Transit Gateway를 통과합니다. NetApp ONTAP용 Amazon FSx에서 LUN을 구성하려면 찾은 문서를 따르십시오 <block ref="70da71f7286decf7407c5db884b5344a" category="inline-link-macro-rx"></block>.</block>
  <block id="32139f76f200f13f9078d49f80c95815" category="paragraph">Linux 클라이언트에서 iSCSI 데몬이 실행되고 있는지 확인합니다. LUN을 프로비저닝한 후 Ubuntu를 사용한 iSCSI 구성에 대한 자세한 지침을 참조하십시오(예:). <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>.</block>
  <block id="102b54837bec429c2bc9f3f9fee8a857" category="paragraph">이 문서에서는 iSCSI LUN을 Windows 호스트에 연결하는 방법을 설명합니다.</block>
  <block id="29980d065df6792c6cf2015646e8744d" category="section-title">NetApp ONTAP용 FSx에서 LUN 프로비저닝:</block>
  <block id="6da38655de350d44c878e17adb0fd12c" category="list-text">ONTAP 파일 시스템용 FSx의 관리 포트를 사용하여 NetApp ONTAP CLI에 액세스합니다.</block>
  <block id="6f8dec9d607d68b3712504d90548dc7f" category="list-text">사이징 출력에 표시된 대로 필요한 크기의 LUN을 생성합니다.</block>
  <block id="c31d63ac510efc7c433e07d70ef0a11a" category="paragraph">이 예에서는 5G 크기의 LUN(5368709120)을 생성했습니다.</block>
  <block id="e3de6fee1eaf0d0777dc125d42255a4b" category="list-text">특정 LUN에 액세스할 수 있는 호스트를 제어하는 데 필요한 igroup을 생성합니다.</block>
  <block id="8c92602adf53776d90c46162f150dd3c" category="paragraph">두 개의 항목이 표시되었습니다.</block>
  <block id="e71def0bc16c2989d418764ced77c368" category="list-text">다음 명령을 사용하여 LUN을 igroup에 매핑합니다.</block>
  <block id="fd29357379ec9a1916e7512ba9cba2d5" category="list-text">새로 프로비저닝된 LUN을 Windows VM에 연결합니다.</block>
  <block id="15bea41b01d7287439a04eb0c57a5ef5" category="paragraph">새 LUN을 AWS SDDC의 VMware 클라우드에 있는 Windows 호스트에 연결하려면 다음 단계를 수행하십시오.</block>
  <block id="eabaddae6242a6352bd11a6bdf29b55a" category="list-text">AWS SDDC 기반 VMware 클라우드에서 호스팅되는 Windows VM에 대한 RDP</block>
  <block id="debd85c1c5da22a2c5e207ae0ad4b91a" category="list-text">Server Manager &gt; Dashboard &gt; Tools &gt; iSCSI Initiator로 이동하여 iSCSI Initiator Properties 대화 상자를 엽니다.</block>
  <block id="213e827694caf7236290f845284dcc05" category="list-text">대상 탭에서 검색된 대상을 선택한 다음 로그온 또는 연결을 클릭합니다.</block>
  <block id="43237019bec64292757878b08a9d1a63" category="list-text">다중 경로 사용을 선택한 다음 “컴퓨터를 시작할 때 이 연결 자동 복원” 또는 “즐겨찾는 대상 목록에 이 연결 추가”를 선택합니다. 고급 을 클릭합니다.</block>
  <block id="ed010f49a5a1ad0895131daffcd73a3c" category="admonition">Windows 호스트에는 클러스터의 각 노드에 대한 iSCSI 연결이 있어야 합니다. 기본 DSM은 가장 적합한 경로를 선택합니다.</block>
  <block id="6aa775ce454f9bfcd13c7e20b90531e7" category="paragraph"><block ref="6aa775ce454f9bfcd13c7e20b90531e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc2a4ed37392086accdd3db98b75509" category="paragraph">SVM(스토리지 가상 머신)의 LUN은 Windows 호스트에 디스크로 표시됩니다. 추가된 새 디스크는 호스트에서 자동으로 검색되지 않습니다. 수동 재검색을 트리거하여 다음 단계를 수행하여 디스크를 검색합니다.</block>
  <block id="3ba2e4c8502f30b8e6d44fc88ebe784a" category="paragraph"><block ref="3ba2e4c8502f30b8e6d44fc88ebe784a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="405bdc4379d9776fbda741356a79c543" category="paragraph">Windows 호스트에서 새 LUN을 처음 액세스할 때 파티션이나 파일 시스템이 없습니다. LUN을 초기화하고 필요에 따라 다음 단계를 완료하여 파일 시스템으로 LUN을 포맷합니다.</block>
  <block id="605158a22ab35f7223fe6f37b0f761b7" category="list-text">마법사의 지침을 따릅니다. 이 예에서는 드라이브 F:가 마운트되었습니다.</block>
  <block id="848c01bbaad78639e22ba05626884091" category="paragraph"><block ref="848c01bbaad78639e22ba05626884091" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4859596b2360db2dac4c6a687efe10d2" category="section-title">AWS에 새로운 Cloud Volumes ONTAP 인스턴스 구축(직접 구현)</block>
  <block id="ddf355809a57f794eb4f9cff41a1ad86" category="paragraph">Cloud Volumes ONTAP 공유 및 LUN은 AWS SDDC 환경의 VMware 클라우드에서 생성된 VM에서 마운트할 수 있습니다. 또한 볼륨은 네이티브 AWS VM Linux Windows 클라이언트에 마운트할 수 있으며, Cloud Volumes ONTAP는 iSCSI, SMB 및 NFS 프로토콜을 지원하므로 iSCSI를 통해 마운트할 때 Linux 또는 Windows 클라이언트에서 LUN에 블록 디바이스로 액세스할 수 있습니다. Cloud Volumes ONTAP 볼륨은 몇 가지 간단한 단계를 통해 설정할 수 있습니다.</block>
  <block id="091112e3dbffea1fef77b4b6bbcec4d3" category="paragraph">재해 복구 또는 마이그레이션을 위해 사내 환경에서 클라우드로 볼륨을 복제하려면 사이트 간 VPN 또는 DirectConnect를 사용하여 AWS에 대한 네트워크 연결을 설정합니다. 사내의 데이터를 Cloud Volumes ONTAP로 복제하는 작업은 이 문서의 범위를 벗어납니다. 사내 시스템과 Cloud Volumes ONTAP 시스템 간에 데이터를 복제하려면 을 참조하십시오 <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="c4fab68ae07564acd6ecd9b911dfff79" category="admonition">를 사용합니다 <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Cloud Volumes ONTAP 인스턴스의 크기를 정확하게 지정합니다. 또한, Cloud Volumes ONTAP Sizer에서 입력으로 사용할 온프레미스 성능을 모니터링합니다.</block>
  <block id="44ca838e7d04a1071dc78602ef005cb3" category="list-text">NetApp Cloud Central에 로그인하면 Fabric View 화면이 표시됩니다. Cloud Volumes ONTAP 탭을 찾아 Cloud Manager로 이동 을 선택합니다. 로그인하면 Canvas 화면이 표시됩니다.</block>
  <block id="6b0e3e8cb8d190a2310f526f49f7908f" category="paragraph"><block ref="6b0e3e8cb8d190a2310f526f49f7908f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="613b8a42b8ee051cdae0288a52604a55" category="list-text">Cloud Manager 홈 페이지에서 작업 환경 추가를 클릭한 다음 AWS를 클라우드로 선택하고 시스템 구성의 유형을 선택합니다.</block>
  <block id="1ce9ef4a253b6301539d9cab4fca67b6" category="paragraph"><block ref="1ce9ef4a253b6301539d9cab4fca67b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1552a04c8237c4a2d938cca2db53683" category="list-text">환경 이름 및 관리자 자격 증명을 비롯하여 생성할 환경에 대한 세부 정보를 제공합니다. 계속 을 클릭합니다.</block>
  <block id="525c0dbff313821edbeaa46a9b5d88dd" category="paragraph"><block ref="525c0dbff313821edbeaa46a9b5d88dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fdbae44a4deac52e923aa6480a3f1f2" category="list-text">클라우드 데이터 감지, 클라우드 백업 및 Cloud Insights를 포함하여 Cloud Volumes ONTAP 구축을 위한 애드온 서비스를 선택하십시오. 계속 을 클릭합니다.</block>
  <block id="7191330ca38db1397356e7619c4baf63" category="paragraph"><block ref="7191330ca38db1397356e7619c4baf63" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5908a77615c1d6294f872ff6f0e9ec5c" category="list-text">HA 배포 모델 페이지에서 여러 가용성 영역 구성을 선택합니다.</block>
  <block id="e2dff93e99a18f3bbf601965a86556d3" category="paragraph"><block ref="e2dff93e99a18f3bbf601965a86556d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5eee77262911549d8a2fd262ee2a983d" category="list-text">지역 및 VPC 페이지에서 네트워크 정보를 입력한 다음 계속 을 클릭합니다.</block>
  <block id="94a6592c275cad51dc739b4ab70338db" category="paragraph"><block ref="94a6592c275cad51dc739b4ab70338db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6f20610782706f69940c617f7154ffe" category="list-text">연결 및 SSH 인증 페이지에서 HA 쌍의 연결 방법과 중재자를 선택합니다.</block>
  <block id="d121b588f00dfd906d6291024c708f8d" category="paragraph"><block ref="d121b588f00dfd906d6291024c708f8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a012735965bc67df3b6e4c64b7b894f" category="list-text">부동 IP 주소를 지정하고 계속 을 클릭합니다.</block>
  <block id="bc0e2f9513cce33557343a1867d4bdfb" category="paragraph"><block ref="bc0e2f9513cce33557343a1867d4bdfb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b2221e159f51173ae2b52e02587cc42" category="list-text">부동 IP 주소에 대한 라우트를 포함할 적절한 라우트 테이블을 선택한 다음 계속 을 클릭합니다.</block>
  <block id="5486a792746fe5fbf546c327f6be2773" category="paragraph"><block ref="5486a792746fe5fbf546c327f6be2773" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e18f42f3f9ea4d4f2e8df33f334d9939" category="list-text">데이터 암호화 페이지에서 AWS 관리 암호화 를 선택합니다.</block>
  <block id="143c5081e907e69e16f1df952eafae3e" category="paragraph"><block ref="143c5081e907e69e16f1df952eafae3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a25e3ac90ce2b5cc921531efdc5963e" category="list-text">라이센스 옵션 선택: 사용한 만큼만 지불 또는 BYOL 방식으로 기존 라이센스 사용 이 예에서는 pay-as-you-go 옵션을 사용합니다.</block>
  <block id="e3750564d3942e5c1d3cec322e411d5e" category="paragraph"><block ref="e3750564d3942e5c1d3cec322e411d5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df531dd5efab87543ed07d56595eca08" category="list-text">AWS SDDC 기반 VMware 클라우드에서 실행되는 VM에 구축할 워크로드 유형을 기반으로 사용할 수 있는 사전 구성된 패키지 몇 개 중 하나를 선택합니다.</block>
  <block id="30e80bd4d8d23ac64059627389a8b348" category="paragraph"><block ref="30e80bd4d8d23ac64059627389a8b348" category="inline-image-macro-rx" type="image"></block></block>
  <block id="623ce055c6e7272198e998744efd8deb" category="list-text">검토 및 승인 페이지에서 선택 항목을 검토하고 확인합니다. Cloud Volumes ONTAP 인스턴스를 만들려면 이동을 클릭합니다.</block>
  <block id="ce4ab7c38fc244e8d1e30dd47a1c578d" category="paragraph"><block ref="ce4ab7c38fc244e8d1e30dd47a1c578d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc498db1b5b048e74d02bcfa90076dfe" category="paragraph"><block ref="bc498db1b5b048e74d02bcfa90076dfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8427c8fe11e3a00ca10a2cf45a96dd90" category="paragraph"><block ref="8427c8fe11e3a00ca10a2cf45a96dd90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31574a22471145d2a1ea069062aa95ec" category="list-text">CVO 인스턴스를 선택하여 볼륨을 생성하고 Create Volume 옵션을 클릭합니다. 적절한 크기를 선택하고 클라우드 관리자가 포함하는 애그리게이트를 선택하거나, 고급 할당 메커니즘을 사용하여 특정 애그리게이트에 배치할 수 있습니다. 이 데모에서는 SMB가 프로토콜로 선택됩니다.</block>
  <block id="d657856abbf9bb39436a3f6f849251ea" category="paragraph"><block ref="d657856abbf9bb39436a3f6f849251ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="976543d01a4b5d38482c487005aadc68" category="list-text">볼륨 용량 할당 후 볼륨 창 아래에서 사용할 수 있습니다. CIFS 공유가 프로비저닝되므로 사용자나 그룹에 파일 및 폴더에 대한 권한을 제공하고 해당 사용자가 공유를 액세스하고 파일을 생성할 수 있는지 확인해야 합니다.</block>
  <block id="eac2d4365044c30420d99e4450f5b3da" category="paragraph"><block ref="eac2d4365044c30420d99e4450f5b3da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ea4081e5d5395a0dd61744757f9abb9" category="list-text">볼륨을 생성한 후 mount 명령을 사용하여 AWS SDDC 호스트의 VMware Cloud에서 실행되는 VM에서 공유에 접속합니다.</block>
  <block id="7786302dcdbb8e27839c1d68acb8c3ba" category="list-text">다음 경로를 복사하고 Map Network Drive 옵션을 사용하여 AWS SDDC의 VMware Cloud에서 실행되는 VM에 볼륨을 마운트합니다.</block>
  <block id="fff9636198d4c8106d5edeb1a72f789c" category="paragraph"><block ref="97606ae260ebd0d0acdf4aac70a2a0b5" category="inline-image-macro-rx" type="image"></block>
<block ref="b4382417b1dd50929cfd78b7e90bc2aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70ac69b194f074f8b2ce79ee769a0c96" category="paragraph">Cloud Volumes ONTAP LUN을 호스트에 연결하려면 다음 단계를 수행하십시오.</block>
  <block id="4a8c2e183609aa00cfce8401be26e193" category="list-text">Cloud Manager Canvas 페이지에서 Cloud Volumes ONTAP 작업 환경을 두 번 클릭하여 볼륨을 생성하고 관리합니다.</block>
  <block id="298c5ecf2fc7c7ab04d3ff27df17c420" category="list-text">볼륨 추가 &gt; 새 볼륨 을 클릭하고 iSCSI 를 선택한 다음 이니시에이터 그룹 생성 을 클릭합니다. 계속 을 클릭합니다.</block>
  <block id="a3f6544e066d08b352bdd873e84efd9f" category="paragraph"><block ref="d08d8d37d464a0090209067a27ccf9bf" category="inline-image-macro-rx" type="image"></block>
<block ref="dd9a8ac9d2dee64126f68f4ab9b10f3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a9ec38aba893e2a0d701ba2f45a50e" category="paragraph">AWS SDDC의 VMware Cloud에 있는 호스트에 대해 동일한 작업을 수행하려면 다음 단계를 수행하십시오.</block>
  <block id="2cbe60394fdca23a31c3a05a49aba035" category="list-text">RDP를 AWS의 VMware 클라우드에서 호스팅되는 VM에 대한 것입니다.</block>
  <block id="04d63507299c2b866ddad09b32b37fb3" category="list-text">다중 경로 사용 을 선택한 다음 컴퓨터가 시작될 때 이 연결 자동 복원 또는 즐겨찾기 대상 목록에 이 연결 추가 를 선택합니다. 고급 을 클릭합니다.</block>
  <block id="15c42f0d55e1a75b7606d8cd1d0f0840" category="paragraph">를 누릅니다<block ref="f87da6f2c46cbdbedc31faf67374f8f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11f54f9bd2797dc115ca9e98fb0116d" category="paragraph">SVM의 LUN은 Windows 호스트에 디스크로 표시됩니다. 추가된 새 디스크는 호스트에서 자동으로 검색되지 않습니다. 수동 재검색을 트리거하여 다음 단계를 수행하여 디스크를 검색합니다.</block>
  <block id="733dc90ee8ecde5a3fe64fd837d0eec1" category="paragraph"><block ref="733dc90ee8ecde5a3fe64fd837d0eec1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b173d8aceed1850c1882fee5f7479d4" category="paragraph"><block ref="5b173d8aceed1850c1882fee5f7479d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1085f8441673a34397360c417066d18f" category="paragraph">Linux 클라이언트에서 iSCSI 데몬이 실행되고 있는지 확인합니다. LUN을 프로비저닝한 후에는 Linux 배포용 iSCSI 구성에 대한 자세한 지침을 참조하십시오. 예를 들어 Ubuntu iSCSI 구성을 찾을 수 있습니다 <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>. 확인하려면 셸에서 lsblk cmd 를 실행합니다.</block>
  <block id="7b88883556cc41d9ed2a47bd0cfe1bb4" category="section-title">Linux 클라이언트에 Cloud Volumes ONTAP NFS 볼륨을 마운트합니다</block>
  <block id="af16b968e0e3b3975cdcefb5cdd9858a" category="paragraph">AWS SDDC의 VMC 내에서 DIY(Cloud Volumes ONTAP) 파일 시스템을 VM에서 마운트하려면 다음 단계를 수행하십시오.</block>
  <block id="b3bcde31f03d76e154f81e6b5221b007" category="list-text">SSH(Secure Shell)를 사용하여 인스턴스의 터미널을 열고 적절한 자격 증명을 사용하여 로그인합니다.</block>
  <block id="42d35ecc4606c7783372ab3953fb10d6" category="list-text">다음 명령을 사용하여 볼륨의 마운트 지점에 대한 디렉토리를 만듭니다.</block>
  <block id="2b9f5ac2397a7a0e82ca568de7f62512" category="paragraph"><block ref="c1b4b180fa34b46779c12a4e278fa487" category="inline-image-macro-rx" type="image"></block>
<block ref="cf487bf9f5a361811181e443893feb53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ade1814101b0113034e0f446307b3db3" category="doc">Google Cloud Platform GCVE를 위한 NetApp의 기능</block>
  <block id="e8650e82200d7cca856f3795833c4382" category="paragraph">NetApp이 GCP(Google Cloud Platform) GCVE(Google Cloud Virtualization Ending)에 제공하는 기능에 대해 자세히 알아보십시오. NetApp은 게스트 연결 스토리지 장치 또는 네이티브 데이터 저장소를 워크플로우 마이그레이션, 클라우드로의 확장/버스팅, 백업/복원, 재해 복구 등</block>
  <block id="addac5e706b2148d9c7b3bbe2d2fcdde" category="paragraph">다음 옵션 중 하나를 선택하여 원하는 콘텐츠의 섹션으로 이동합니다.</block>
  <block id="06262015df4851b380189212274a0e3e" category="inline-link-macro">하이퍼스케일 구성의 VMware</block>
  <block id="7f08237a127b62af444f720f15216cee" category="list-text"><block ref="7f08237a127b62af444f720f15216cee" category="inline-link-macro-rx"></block></block>
  <block id="c774c23e9a97e08bfa096f1cbf18cc17" category="inline-link-macro">NetApp 스토리지 옵션</block>
  <block id="d3fc27ff58dc3a0d839a16af858e7999" category="list-text"><block ref="d3fc27ff58dc3a0d839a16af858e7999" category="inline-link-macro-rx"></block></block>
  <block id="bb48bc786b7087ed5efe4969dda9fc85" category="section-title">Google Cloud에서 GCVE 구성</block>
  <block id="833413440fbbe13837d8b58256cfba65" category="paragraph">온프레미스에서와 마찬가지로 클라우드 기반 가상화 환경을 계획하는 것은 VM 및 마이그레이션을 생성할 수 있는 성공적인 프로덕션 준비 환경에 매우 중요합니다.</block>
  <block id="6eb516b97eae0ab93b8d6aab35fbb764" category="section-title">GCVE용 NetApp 스토리지 옵션</block>
  <block id="50b53922d656bce75f35201b661fc378" category="paragraph">NetApp 스토리지는 GCP GCVE 내에서 추측으로 연결되거나 기본 데이터 저장소로 사용될 수 있습니다.</block>
  <block id="94772ee4b241fe0706c3aaef6e3a4505" category="inline-link-macro">지원되는 NetApp 스토리지 옵션</block>
  <block id="67b586cdf9703ba67abe711415768cc0" category="paragraph">를 방문하십시오 <block ref="01a9bd21bfc714c8dec8aabc5b88eda7" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="8f08ff97ca555f50f0d05fdf950a0568" category="paragraph">Google Cloud는 다음과 같은 구성에서 NetApp 스토리지를 지원합니다.</block>
  <block id="703133f070dbe0ec953855a2291e151a" category="paragraph">* 게스트 연결 스토리지 *</block>
  <block id="9bb210767ccb9c085c816c82f3b6b1cb" category="inline-link-macro">CVS(Cloud Volumes Service)를 게스트 연결 스토리지로 사용합니다</block>
  <block id="94f644afad50386ab13d527e1056ce71" category="paragraph">* 네이티브 데이터 저장소 *</block>
  <block id="1234d67e696757e4666b0611f60b80d8" category="inline-link-macro">CVS(Cloud Volumes Service)를 네이티브 데이터 저장소 ^1로 사용합니다</block>
  <block id="a508a86f372584a11bee8d3d41e3afca" category="list-text"><block ref="a508a86f372584a11bee8d3d41e3afca" category="inline-link-macro-rx"></block></block>
  <block id="c567300e15e9f9b873771e56c72c938b" category="admonition">1-현재 비공개 미리보기에 있습니다</block>
  <block id="e3a2a8e4a74a67a9514c2aec5e4fac69" category="doc">Azure용 NetApp 기본 데이터 저장소 옵션</block>
  <block id="04999f88dfbb06dc4f6a71901a7e9b18" category="paragraph">리드&gt;</block>
  <block id="2a172299398c31c1e2cd726175d3a270" category="paragraph">content&gt;를 선택합니다</block>
  <block id="99d04ce0dcd35b869d3c86120b76a443" category="summary">NetApp 엔터프라이즈 하이브리드 클라우드 솔루션은 주요 퍼블릭 클라우드 하이퍼스케일러에 대한 NetApp 스토리지의 기능을 시연하는 전략적 기술 기능 집합입니다.</block>
  <block id="3cce9a9057a6d96d9ac2ddab52d477fe" category="doc">NetApp 엔터프라이즈 하이브리드 클라우드 솔루션</block>
  <block id="5b2a691ebf81d334bb42112bb635d34d" category="doc">엔터프라이즈 하이브리드 클라우드(EHC)에 지원되는 구성</block>
  <block id="5e1c36a2c24e0aaf7844ec890c15e430" category="paragraph">주요 하이퍼 스케일러에서 NetApp 스토리지 지원 조합을 이해합니다.</block>
  <block id="aa1f7516e656fcf88a02be4feaa432c5" category="cell">* Azure AVS *</block>
  <block id="9acf96fea18557ec8c6d660d6503f3bf" category="cell">* AWS VMC *</block>
  <block id="66fbf46ae142d95c688698893879b8af" category="cell">* GCP GCVE *</block>
  <block id="990372eb325efff403b4117c31a055a8" category="cell">* CVO(Cloud Volumes ONTAP) *</block>
  <block id="b7c8d0420d929de49959aae6ce8ba3e4" category="inline-link-macro">게스트가 연결되었습니다</block>
  <block id="33cc6e358d22c6f19d9b7924dc3cdc6d" category="cell">CVS(Cloud Volumes Service) *</block>
  <block id="336d5ebc5436534e61d16e63ddfca327" category="cell">-</block>
  <block id="53ece9afd987905da70066422fba9879" category="inline-link-macro">네이티브 데이터 저장소 ^1</block>
  <block id="df635045d1bc577d1f8f5b4da11409be" category="cell">* Azure NetApp Files(ANF) *</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">해당 없음</block>
  <block id="a7714bc43e9a27f2c98a38e6b6d7f3d8" category="doc">퍼블릭 클라우드 공급자를 위한 NetApp 스토리지 옵션</block>
  <block id="8db50e5729f7a5d770aaceef947a2982" category="paragraph">세 가지 주요 하이퍼 스케일러의 스토리지로서의 NetApp 옵션에 대해 알아보십시오.</block>
  <block id="30024089a3aab34e33b3a9766ff8c662" category="section-title">AWS용 NetApp 스토리지 옵션</block>
  <block id="60ce80493de8468bdfd597af1c219a9f" category="paragraph">AWS는 다음과 같은 구성에서 NetApp 스토리지를 지원합니다.</block>
  <block id="83c87929208a5770dfb09e33514193f4" category="inline-link-macro">FSX ONTAP를 기본 데이터 저장소 ^1로 사용합니다</block>
  <block id="ad476c4cac730935959743eb28c5ca66" category="list-text"><block ref="ad476c4cac730935959743eb28c5ca66" category="inline-link-macro-rx"></block></block>
  <block id="a1010f9f8442cf9caff454cd5d3914ec" category="section-title">Azure용 NetApp 스토리지 옵션</block>
  <block id="98ba63f921be22bb183a43d868521ce1" category="inline-link-macro">Azure NetApp Files(ANF)를 기본 데이터 저장소 ^1로 사용합니다</block>
  <block id="c054a58e4fcd496e4fa5c1b0c16dfa69" category="list-text"><block ref="c054a58e4fcd496e4fa5c1b0c16dfa69" category="inline-link-macro-rx"></block></block>
  <block id="74eb4c6138d4b8cd8399b01966c5af28" category="section-title">GCP용 NetApp 스토리지 옵션</block>
  <block id="8811a4f5d0046113ac94b851ec1b1990" category="list-text"><block ref="8811a4f5d0046113ac94b851ec1b1990" category="inline-link-macro-rx"></block></block>
  <block id="4177c39712dda5976b0ba657b24af234" category="section-title">Google Cloud에 Cloud Volumes ONTAP 배포(직접 수행)</block>
  <block id="2839d8571363b149cc3fd9db82a7183d" category="paragraph">Cloud Volumes ONTAP 공유 및 LUN은 GCVE 프라이빗 클라우드 환경에서 생성된 VM에서 마운트할 수 있습니다. Cloud Volumes ONTAP는 iSCSI, SMB 및 NFS 프로토콜을 지원하기 때문에 iSCSI를 통해 마운트할 때 Linux 또는 Windows 클라이언트에서 볼륨을 Linux 클라이언트 및 Windows 클라이언트에 블록 디바이스로 마운트할 수 있습니다. Cloud Volumes ONTAP 볼륨은 몇 가지 간단한 단계를 통해 설정할 수 있습니다.</block>
  <block id="83f1904115d07e05de148ff5c69277db" category="paragraph">재해 복구 또는 마이그레이션을 위해 사내 환경에서 클라우드로 볼륨을 복제하려면 사이트 간 VPN 또는 Cloud Interconnect를 사용하여 Google Cloud에 대한 네트워크 연결을 설정합니다. 사내의 데이터를 Cloud Volumes ONTAP로 복제하는 작업은 이 문서의 범위를 벗어납니다. 사내 시스템과 Cloud Volumes ONTAP 시스템 간에 데이터를 복제하려면 을 참조하십시오 <block ref="17b5522e2d467cfa8e1eed2f77bb1eff" category="inline-link-macro-rx"></block>.</block>
  <block id="52111b7d24cc23248fa9cf8138732943" category="paragraph"><block ref="52111b7d24cc23248fa9cf8138732943" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67b4a468763f61993484edb54b0d5eaa" category="list-text">Cloud Manager Canvas 탭에서 작업 환경 추가를 클릭한 다음 Google Cloud Platform을 클라우드로 선택하고 시스템 구성 유형을 선택합니다. 다음 을 클릭합니다.</block>
  <block id="da94c5003e26421e5282adb2dc7794bf" category="paragraph"><block ref="da94c5003e26421e5282adb2dc7794bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="956a76d4c71f02e39d36ada071ba66ca" category="list-text">환경 이름 및 관리자 자격 증명을 비롯하여 생성할 환경에 대한 세부 정보를 제공합니다. 작업을 마친 후 계속 을 클릭합니다.</block>
  <block id="786bd072b9aad97a5bb9b71b8988a176" category="paragraph"><block ref="786bd072b9aad97a5bb9b71b8988a176" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f716cee2acaef077786ecfa7a3f8bfe7" category="list-text">데이터 감지 및 규정 준수, 클라우드 백업 등 Cloud Volumes ONTAP 구축을 위한 추가 서비스 를 선택하거나 선택 취소합니다. 그런 다음 계속 을 클릭합니다.</block>
  <block id="03e0c2afea8f7c3aff4a53d66784f843" category="paragraph">힌트: 추가 서비스를 비활성화할 때 확인 팝업 메시지가 표시됩니다. 추가 서비스는 CVO 배포 후 추가/제거할 수 있습니다. 비용을 피하기 위해 처음부터 필요하지 않은 경우 선택을 취소하십시오.</block>
  <block id="d784fbb10e1bdb60322e86126fe6b77a" category="paragraph"><block ref="d784fbb10e1bdb60322e86126fe6b77a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faa5bffdcdb67efcb08e91a60de40950" category="list-text">위치를 선택하고 방화벽 정책을 선택한 다음 확인란을 선택하여 Google Cloud 스토리지에 대한 네트워크 연결을 확인합니다.</block>
  <block id="5eb45a43e8f46d401f435ef2b77fc946" category="paragraph"><block ref="5eb45a43e8f46d401f435ef2b77fc946" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f73472fc9b5e80548aa8910eb7b409d7" category="list-text">라이센스 옵션 선택: 사용한 만큼만 지불 또는 BYOL 방식으로 기존 라이센스 사용 이 예제에서는 Freemium 옵션을 사용합니다. 그런 다음 계속 을 클릭합니다.</block>
  <block id="ef8c5ea172d5c008d091f693a2a4b4bd" category="paragraph"><block ref="ef8c5ea172d5c008d091f693a2a4b4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e3f0304199574fcad7150c8cbc80cf" category="list-text">AWS SDDC 기반 VMware 클라우드에서 실행되는 VM에 구축할 워크로드의 유형에 따라 사용할 수 있는 사전 구성된 패키지 몇 개 중 하나를 선택합니다.</block>
  <block id="1cd93d1b6baa56bdec898225ef3fea89" category="paragraph">힌트: 타일 위로 마우스를 가져가 세부 정보를 보거나 구성 변경 을 클릭하여 CVO 구성 요소 및 ONTAP 버전을 사용자 지정합니다.</block>
  <block id="7498ab388fb0a7938d43af30f32657b5" category="paragraph"><block ref="7498ab388fb0a7938d43af30f32657b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcf4e1533222260897c2613078eae18e" category="paragraph"><block ref="fcf4e1533222260897c2613078eae18e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37030c826a75013cff1396c6351d33c0" category="paragraph"><block ref="37030c826a75013cff1396c6351d33c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f10b252acc74e058dc00a78e8c33250" category="paragraph">힌트: 메뉴 아이콘( º)을 클릭하고 고급을 선택하여 더 많은 옵션을 표시하고 CIFS 설정을 선택합니다.</block>
  <block id="0cd857f422db3bb835695ca4400e7afb" category="paragraph"><block ref="0cd857f422db3bb835695ca4400e7afb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c2efcf3ec5fbe68c5a418d6b0d5ed94" category="list-text">SMB 볼륨을 생성하는 것은 쉬운 프로세스입니다. Canvas에서 Cloud Volumes ONTAP 작업 환경을 두 번 클릭하여 볼륨을 생성 및 관리하고 볼륨 생성 옵션을 클릭합니다. 적절한 크기를 선택하고 클라우드 관리자가 포함하는 애그리게이트를 선택하거나, 고급 할당 메커니즘을 사용하여 특정 애그리게이트에 배치할 수 있습니다. 이 데모에서는 CIFS/SMB가 프로토콜로 선택됩니다.</block>
  <block id="597899b3d186b1c50739aeb0a82a2094" category="paragraph"><block ref="597899b3d186b1c50739aeb0a82a2094" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cdd5a747f01838b94117ef6fb699278" category="paragraph">힌트: 볼륨 메뉴(º)를 클릭하여 옵션을 표시합니다.</block>
  <block id="368cd84bdda136cebde14eea38e8a0f2" category="paragraph"><block ref="368cd84bdda136cebde14eea38e8a0f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7a0ccac4888fc1553dadeee03d7e99" category="list-text">볼륨을 생성한 후 mount 명령을 사용하여 볼륨 연결 지침을 표시한 다음 Google Cloud VMware Engine의 VM에서 공유에 연결합니다.</block>
  <block id="92890420fd7a7668e3b04db90e8a2ff2" category="paragraph"><block ref="92890420fd7a7668e3b04db90e8a2ff2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5ee926d870d7b6e5ee68e0001a9db42" category="list-text">다음 경로를 복사하고 네트워크 드라이브 매핑 옵션을 사용하여 Google Cloud VMware Engine에서 실행 중인 VM에 볼륨을 마운트합니다.</block>
  <block id="809f33612149b405423b98b77a13d18f" category="paragraph"><block ref="809f33612149b405423b98b77a13d18f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0895b43b6a4f7ded9ce501e420da7cae" category="paragraph">매핑되면 쉽게 액세스할 수 있으며 NTFS 권한을 적절하게 설정할 수 있습니다.</block>
  <block id="2565b7a7d81a362c6b3fc5f32d83075b" category="paragraph"><block ref="2565b7a7d81a362c6b3fc5f32d83075b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="262a1d892164ab4100a969a952274934" category="section-title">Cloud Volumes ONTAP의 LUN을 호스트에 연결합니다</block>
  <block id="049f63d3d6479b8801f942e53b31cfd6" category="paragraph">Cloud Volumes ONTAP LUN을 호스트에 연결하려면 다음 단계를 수행하십시오.</block>
  <block id="b5f2af2dc909b8d634ef7e8dd729c0bc" category="paragraph"><block ref="99dce170472373a603dcc6cab1306eea" category="inline-image-macro-rx" type="image"></block>
<block ref="99eed8d2ce50ff339d9bff41a9fe9a51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4296bb5afd2416d05f951e9d3380e5e4" category="list-text">볼륨이 프로비저닝되면 볼륨 메뉴( º)를 선택한 다음 대상 IQN을 클릭합니다. IQN(iSCSI Qualified Name)을 복사하려면 Copy(복사)를 클릭합니다. 호스트에서 LUN으로의 iSCSI 접속을 설정합니다.</block>
  <block id="5bbe705670fa05ddb0b508acf301a379" category="paragraph">Google Cloud VMware Engine에 상주하는 호스트에 대해 동일한 작업을 수행하려면 다음을 수행합니다.</block>
  <block id="a730e43d2afac8730f77c3fab06bcdc0" category="list-text">Google Cloud VMware Engine에서 호스팅되는 VM에 대한 RDP</block>
  <block id="88c7456aa49f0bfe0258958c4c42a153" category="paragraph"><block ref="88c7456aa49f0bfe0258958c4c42a153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da663e5eac7f594bcac6564a22726142" category="paragraph"><block ref="da663e5eac7f594bcac6564a22726142" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74edf50412d8a6c920ebdf456ca74d6f" category="paragraph"><block ref="74edf50412d8a6c920ebdf456ca74d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8bce76f68494174fa21e44b39be75e7" category="paragraph">Linux 클라이언트에서 iSCSI 데몬이 실행되고 있는지 확인합니다. LUN을 프로비저닝한 후에는 여기에서 Ubuntu를 사용한 iSCSI 구성에 대한 자세한 지침을 참조하십시오. 확인하려면 셸에서 lsblk cmd 를 실행합니다.</block>
  <block id="5800551032817b82a3780efc5c365b61" category="paragraph"><block ref="5d8610d622621cfaf5f5af9098efada8" category="inline-image-macro-rx" type="image"></block>
<block ref="0e5aea74b7dab4389459e8f03d7961e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a676f5d05c6d1f36341948d03289c3f" category="paragraph">Google Cloud VMware Engine 내의 VM에서 DIY(Cloud Volumes ONTAP) 파일 시스템을 마운트하려면 다음 단계를 수행하십시오.</block>
  <block id="99ff74a348250b7148d219f224bc40b4" category="paragraph">아래 단계에 따라 볼륨을 프로비저닝합니다</block>
  <block id="17d1d28660c0ff68f1ee26c3bc7c2e0d" category="list-text">볼륨 탭에서 새 볼륨 생성 을 클릭합니다.</block>
  <block id="6fa266ccf8c1f303a7ed67b355770afb" category="list-text">새 볼륨 생성 페이지에서 볼륨 유형을 선택합니다.</block>
  <block id="8d7c2959a73ccf424e912497fa729dfa" category="paragraph"><block ref="8d7c2959a73ccf424e912497fa729dfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e89e2106ea79d032d48e99a6498e2584" category="list-text">볼륨 탭에서 마우스 커서를 볼륨 위에 놓고 메뉴 아이콘( º)을 선택한 다음 Mount Command를 클릭합니다.</block>
  <block id="1367b1db6f5a641c16b673b4f75f02de" category="paragraph"><block ref="1367b1db6f5a641c16b673b4f75f02de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a4175c7cb7e059193f8bdcafc1395b0" category="list-text">복사를 클릭합니다.</block>
  <block id="2432c695bbc97e5283e213ba846e86dc" category="paragraph"><block ref="2432c695bbc97e5283e213ba846e86dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5cbcad6705273d58a27b5b92fdc1700" category="list-text">이전 단계에서 생성한 디렉토리에 Cloud Volumes ONTAP NFS 볼륨을 마운트합니다.</block>
  <block id="f505f299a6f5e1e9f6b91adec6ef8f38" category="paragraph"><block ref="4aa22d1032194bb618fa2b2a8bbc5d82" category="inline-image-macro-rx" type="image"></block>
<block ref="73581b61100d82e506cc05faa5fc45c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c0dd0de38e3c9e55ef5f52e46641376" category="section-title">VMware 엔진을 사용하여 Cloud Volumes Service를 구성합니다</block>
  <block id="8e12272d11d90cdb919c737591f398f6" category="paragraph">Cloud Volumes Service 공유는 VMware 엔진 환경에서 생성된 VM에서 마운트할 수 있습니다. Cloud Volumes Service는 SMB 및 NFS 프로토콜을 지원하므로 Linux 클라이언트에 볼륨을 마운트하고 Windows 클라이언트에 매핑할 수도 있습니다. Cloud Volumes Service 볼륨은 간단한 단계를 통해 설정할 수 있습니다.</block>
  <block id="992031e7435f44536a649bfc9de30683" category="paragraph">Cloud Volume Service 및 Google Cloud VMware Engine 프라이빗 클라우드는 같은 지역에 있어야 합니다.</block>
  <block id="a0c391dc49c440fc9962168353cedde3" category="inline-link-macro">가이드</block>
  <block id="e9676faeb0b33249abc3a47d95e55ed8" category="paragraph">Google Cloud Marketplace에서 NetApp Cloud Volumes Service for Google Cloud를 구매, 활성화 및 구성하려면 다음 세부 정보를 따르십시오 <block ref="c9eb1a9870bc9f20357f50bf16ec5704" category="inline-link-macro-rx"></block>.</block>
  <block id="84c877bb77a313d307054a0824ffff03" category="section-title">CVS NFS 볼륨을 GCVE 프라이빗 클라우드에 생성합니다</block>
  <block id="1ec5bbc38708de3f8cfad6d6ca608742" category="paragraph">NFS 볼륨을 생성 및 마운트하려면 다음 단계를 수행하십시오.</block>
  <block id="ca5470246976d59ea6a32d3e2094059d" category="list-text">Google 클라우드 콘솔 내의 파트너 솔루션에서 Cloud Volumes에 액세스합니다.</block>
  <block id="45ab48bbbad4380f09ef6b41f9eb8f8a" category="paragraph"><block ref="45ab48bbbad4380f09ef6b41f9eb8f8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46577653160772df2b1548b726d7c9ce" category="list-text">Cloud Volumes Console에서 Volumes 페이지로 이동하고 Create를 클릭합니다.</block>
  <block id="4a43547530a8ef079adc80160de3dde9" category="paragraph"><block ref="4a43547530a8ef079adc80160de3dde9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="825700271a3acfeaf96fa0bfb5f15b65" category="list-text">파일 시스템 생성 페이지에서 차지백 메커니즘에 필요한 볼륨 이름 및 청구 레이블을 지정합니다.</block>
  <block id="8a81559c79124aa1a1cd2093faed73ee" category="paragraph"><block ref="8a81559c79124aa1a1cd2093faed73ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4bbe773302576667095a132b75c48fc" category="list-text">적절한 서비스를 선택합니다. GCVE의 경우 애플리케이션 워크로드 요구 사항에 따라 지연 시간 및 성능 향상을 위해 CVS 성능 및 원하는 서비스 수준을 선택합니다.</block>
  <block id="184fe9f42c4d5eaab1cc6079778040c2" category="paragraph"><block ref="184fe9f42c4d5eaab1cc6079778040c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492d6cb3c36c984d9f52d9461c5b69b" category="list-text">볼륨 및 볼륨 경로에 대해 Google Cloud 영역을 지정합니다. 볼륨 경로는 프로젝트의 모든 클라우드 볼륨에서 고유해야 합니다.</block>
  <block id="594c2b024401023acd7deae8f3cb8ceb" category="paragraph"><block ref="594c2b024401023acd7deae8f3cb8ceb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0697a6c38463b0b06d7dc66b16b74" category="list-text">볼륨의 성능 수준을 선택합니다.</block>
  <block id="aebc437f9bb3656c19ecebe1becc99fa" category="paragraph"><block ref="aebc437f9bb3656c19ecebe1becc99fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd9c26fe6b5f33ab2b0002050ff831d8" category="list-text">볼륨의 크기와 프로토콜 유형을 지정합니다. 이 테스트에서는 NFSv3을 사용합니다.</block>
  <block id="e5ba61d9c8c666d452e9e78256762019" category="paragraph"><block ref="e5ba61d9c8c666d452e9e78256762019" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3a8099bd03f7da2c641e049e354ea1" category="list-text">이 단계에서는 볼륨에 액세스할 수 있는 VPC 네트워크를 선택합니다. VPC 피어링을 제자리에 배치했는지 확인합니다.</block>
  <block id="d3dba730ef6d3f046910d94696ca086d" category="paragraph">힌트: VPC 피어링을 수행하지 않은 경우 피어링 명령을 안내하는 팝업 버튼이 표시됩니다. 클라우드 셸 세션을 열고 적절한 명령을 실행하여 VPC를 Cloud Volumes Service 생산자와 동종합니다. 사전에 VPC 피어링을 준비하려는 경우 다음 지침을 참조하십시오.</block>
  <block id="ecf942f7df1f072f5910afb3fa45f36e" category="paragraph"><block ref="ecf942f7df1f072f5910afb3fa45f36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ed1352ea98f362074fa7855ec6bb89c" category="list-text">적절한 규칙을 추가하여 엑스포트 정책 규칙을 관리하고 해당 NFS 버전의 확인란을 선택합니다.</block>
  <block id="3ae650d16c298e2f5dc9e005a2f8934a" category="paragraph">참고: 내보내기 정책을 추가하지 않으면 NFS 볼륨에 액세스할 수 없습니다.</block>
  <block id="2f6d29a5c21fb51bb181c4b97241a955" category="paragraph"><block ref="2f6d29a5c21fb51bb181c4b97241a955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a194552e035de341a4a7c99a1c687956" category="list-text">Save(저장) 를 클릭하여 볼륨을 생성합니다.</block>
  <block id="fe18028768c2ffc16d5cb32aa5b70d5b" category="paragraph"><block ref="fe18028768c2ffc16d5cb32aa5b70d5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3588b0992732355d67655af9f6450c5d" category="section-title">VMware Engine에서 실행 중인 VM에 NFS 내보내기를 마운트합니다</block>
  <block id="87397baf86d56e19a3bdac712966da5d" category="paragraph">NFS 볼륨 마운트를 준비하기 전에 전용 연결의 피어링 상태가 Active(활성)로 표시되는지 확인합니다. 상태가 Active인 경우 mount 명령을 사용합니다.</block>
  <block id="c9f09539bbf502703a4f5e2d480a5972" category="paragraph">NFS 볼륨을 마운트하려면 다음을 수행합니다.</block>
  <block id="726f902a0b5536d71345114fb942d81b" category="list-text">Cloud Console에서 Cloud Volumes &gt; Volumes로 이동합니다.</block>
  <block id="1feaf778ab1cf141cf92a316d53e1365" category="list-text">볼륨 페이지로 이동합니다</block>
  <block id="76d2df71caae5e1ec3f81822829504f5" category="list-text">NFS 내보내기를 마운트할 NFS 볼륨을 클릭합니다.</block>
  <block id="4fc82f44f951748bf462898e43d08054" category="list-text">오른쪽으로 스크롤하고 자세히 표시 에서 마운트 지침 을 클릭합니다.</block>
  <block id="692afb2fddb72a6cfc89dd1df12945ab" category="paragraph">VMware VM의 게스트 OS 내에서 마운트 프로세스를 수행하려면 다음 단계를 따르십시오.</block>
  <block id="2c7df76595ada01b5b08659283021aa7" category="list-text">SSH 클라이언트 및 SSH를 사용하여 가상 머신에 접속합니다.</block>
  <block id="2b64d099377e2935e786009804205feb" category="list-text">인스턴스에 NFS 클라이언트를 설치합니다.</block>
  <block id="d8aa2b3304fc65e5fd1cae735194aef6" category="list-text">Red Hat Enterprise Linux 또는 SuSE Linux 인스턴스:</block>
  <block id="d610fa6d370a8d35fb4c26359f086aa0" category="list-text">Ubuntu 또는 Debian 인스턴스에서:</block>
  <block id="9bc2e27c16ca55bfc1a7ba94b91a21dc" category="list-text">인스턴스에 "/nimCVSNFSol01"과 같은 새 디렉토리를 생성합니다.</block>
  <block id="9e21b9d85251decc0982b75506826828" category="paragraph"><block ref="9e21b9d85251decc0982b75506826828" category="inline-image-macro-rx" type="image"></block></block>
  <block id="174714918db1cc87ef113e3087cba5da" category="list-text">적절한 명령을 사용하여 볼륨을 마운트합니다. 실습의 명령 예는 다음과 같습니다.</block>
  <block id="1ec7767a139a3f95923511d7bf547a6c" category="paragraph"><block ref="811572ed35d4b134bc0d7769dd80ab6c" category="inline-image-macro-rx" type="image"></block>
<block ref="b780e126200cb608d0de968e965e9c71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3df234dd2e63d779a2d017bb1ef3375d" category="section-title">VMware Engine에서 실행 중인 VM에 SMB 공유 생성 및 마운트</block>
  <block id="400db805dd1f9fc929e5bf72fafb1661" category="paragraph">SMB 볼륨의 경우 SMB 볼륨을 생성하기 전에 Active Directory 연결이 구성되어 있는지 확인합니다.</block>
  <block id="94f9379544859ae4d8990b84731870aa" category="paragraph"><block ref="94f9379544859ae4d8990b84731870aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c62a73033a0e9f64b5b2b311ded0cc5" category="paragraph">AD 연결이 설정되면 원하는 서비스 수준으로 볼륨을 생성합니다. 단계는 적절한 프로토콜을 선택하는 경우를 제외하고 NFS 볼륨을 생성하는 것과 같습니다.</block>
  <block id="228ba1c797822b63cd7c6f54ca40b87e" category="paragraph"><block ref="228ba1c797822b63cd7c6f54ca40b87e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54cd15dd2d6121aa16f0b4b87b46ef2a" category="list-text">적절한 서비스를 선택합니다. GCVE의 경우 워크로드 요구 사항에 따라 지연 시간을 개선하고 성능을 향상시키하려면 CVS 성능 및 원하는 서비스 수준을 선택합니다.</block>
  <block id="b8eb8307790a9b22c2f6997c097b344e" category="paragraph"><block ref="b8eb8307790a9b22c2f6997c097b344e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb91d5f8a608e41cd1f217e30a536437" category="paragraph"><block ref="cb91d5f8a608e41cd1f217e30a536437" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e5a0a3c08f102d8c49c1d811b71d97f" category="paragraph"><block ref="7e5a0a3c08f102d8c49c1d811b71d97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d1a06f98a1c133a8a0c74cc4222e23b" category="list-text">볼륨의 크기와 프로토콜 유형을 지정합니다. 이 테스트에서는 SMB가 사용됩니다.</block>
  <block id="6eb5a9152f38c77efc6d14902aa7dec8" category="paragraph"><block ref="6eb5a9152f38c77efc6d14902aa7dec8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">지침</block>
  <block id="15adcf662b8b92c623f4256a65f605ed" category="paragraph">힌트: VPC 피어링을 수행하지 않은 경우 피어링 명령을 안내하는 팝업 버튼이 표시됩니다. 클라우드 셸 세션을 열고 적절한 명령을 실행하여 VPC를 Cloud Volumes Service 생산자와 동종합니다. 미리 VPC 피어링을 준비하려는 경우 이를 참조하십시오 <block ref="3b4469537a7b14dcfd28e3d301600ff6" category="inline-link-macro-rx"></block>.</block>
  <block id="7f88d48c3b0283642fe6b1f3f061d0fd" category="paragraph"><block ref="7f88d48c3b0283642fe6b1f3f061d0fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ac40323c41c29fb75f6e19c4c683e47" category="paragraph"><block ref="8ac40323c41c29fb75f6e19c4c683e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4990031dcfbd871d95ce4ae0321e7156" category="paragraph">SMB 볼륨을 마운트하려면 다음을 수행합니다.</block>
  <block id="fd78728be3a82142558c815267b8daa0" category="list-text">SMB 공유를 매핑할 SMB 볼륨을 클릭합니다.</block>
  <block id="58dc78a5cd30078188f7c605e636a975" category="paragraph">VMware VM의 Windows 게스트 OS 내에서 마운트 프로세스를 수행하려면 다음 단계를 수행하십시오.</block>
  <block id="3dcb4e26f80951bdb3beeb0a03a3ba83" category="list-text">시작 단추를 클릭한 다음 컴퓨터를 클릭합니다.</block>
  <block id="202bba1ab43a099f57e49b350eb2ad1a" category="list-text">네트워크 드라이브 연결 을 클릭합니다.</block>
  <block id="7dea65bdd8e9fbcd8a5b7249c71e1f0b" category="list-text">드라이브 목록에서 사용 가능한 드라이브 문자를 클릭합니다.</block>
  <block id="695179e494f30a851f80409f824a80f8" category="list-text">폴더 상자에 다음을 입력합니다.</block>
  <block id="2653f3365feaf0a8bf80106cba1b9ad8" category="paragraph"><block ref="2653f3365feaf0a8bf80106cba1b9ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cd95358048d9f5d18cf70f66126e1e7" category="paragraph">컴퓨터에 로그온할 때마다 연결하려면 로그인할 때 다시 연결 확인란을 선택합니다.</block>
  <block id="7968f043139de8ff0e5df4451c437426" category="list-text">마침 을 클릭합니다.</block>
  <block id="8902b5e2f0c169ccf7ad8b5c335531e5" category="paragraph"><block ref="8902b5e2f0c169ccf7ad8b5c335531e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="104948b3593a97ed92fc801aaf126581" category="doc">엔터프라이즈 하이브리드 클라우드(EHC) 개요</block>
  <block id="415be703c228d9c6838b18850a1d9f31" category="paragraph">대부분의 IT 조직은 하이브리드 클라우드 우선 접근 방식을 따릅니다. 전환 단계에 있는 이들 조직은 고객이 현재 IT 환경을 평가한 다음 평가 및 검색 결과를 기반으로 워크로드를 클라우드로 마이그레이션하고 있습니다.</block>
  <block id="346972233965e89cf5b17c3907b35f86" category="paragraph">클라우드로 마이그레이션하는 고객의 요인에는 탄력성 및 버스트, 데이터 센터 이탈, 데이터 센터 통합, 수명 종료 시나리오, 인수 합병, 인수 합병 등 이 마이그레이션의 이유는 각 조직 및 각 비즈니스 우선순위에 따라 달라질 수 있습니다. 하이브리드 클라우드로 전환할 때 클라우드 구축과 탄력성의 잠재력을 최대한 활용하려면 클라우드에 적합한 스토리지를 선택하는 것이 매우 중요합니다.</block>
  <block id="0c4a16ed987359b14dc407a858d1a78e" category="section-title">퍼블릭 클라우드의 VMware 클라우드 옵션</block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="section-title">Azure VMware 솔루션</block>
  <block id="d788a5499d320b05602a6a0805c81403" category="image-alt">AVS</block>
  <block id="c7b818b90803789a74058cfb4396383d" category="paragraph">Azure VMware 솔루션은 Microsoft Azure 퍼블릭 클라우드 내에서 VMware DC를 완벽하게 작동하는 하이브리드 클라우드 서비스입니다. Azure VMware 솔루션은 Microsoft에서 완벽하게 관리 및 지원하는 타사 솔루션으로, Azure 인프라를 활용하는 VMware에서 검증되었습니다. 즉, Azure VMware 솔루션을 구축할 때 고객은 컴퓨팅 가상화를 위한 VMware ESXi, 하이퍼 컨버지드 스토리지를 위한 vSAN을 얻게 됩니다. 네트워킹 및 보안을 위한 NSX는 물론, Microsoft Azure의 세계적인 입지, 동급 최고의 데이터 센터 시설을 활용하고 네이티브 Azure 서비스 및 솔루션의 풍부한 에코시스템에 근접합니다.</block>
  <block id="22b0614f106e2b7c956c60c8fc0d35c3" category="image-alt">VMC</block>
  <block id="8641a2440fc22db60ec877f3a8946fa2" category="paragraph">VMware Cloud on AWS는 기본 AWS 서비스에 최적화된 액세스를 통해 VMware의 엔터프라이즈급 SDDC 소프트웨어를 AWS 클라우드에 제공합니다. VMware Cloud Foundation을 기반으로 하는 AWS 기반 VMware Cloud는 VMware의 컴퓨팅, 스토리지 및 네트워크 가상화 제품(VMware vSphere, VMware vSAN 및 VMware NSX)을 VMware vCenter Server 관리 기능과 통합하여 유연하고 전용 베어 메탈 AWS 인프라에서 실행되도록 최적화되었습니다.</block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="section-title">Google Cloud VMware 엔진</block>
  <block id="5292de1147a4b3a1d5c63d057c4b0096" category="image-alt">Gcve</block>
  <block id="1ffd600a1d8e07fe3b4bca16ae02167c" category="paragraph">Google Cloud VMware Engine은 Google Cloud의 고성능 확장형 인프라와 VMware Cloud Foundation 스택(VMware vSphere, vCenter, vSAN 및 NSX-T)을 기반으로 구축된 IaaS(Infrastructure-as-a-Service) 제품입니다 이 서비스를 사용하면 비용, 노력 또는 애플리케이션 재설계 또는 운영 재조정 위험 없이 기존 VMware 워크로드를 온프레미스 환경에서 Google Cloud Platform으로 원활하게 마이그레이션하거나 확장할 수 있습니다. Google에서 판매 및 지원하는 서비스로서 VMware와 긴밀하게 협력하고 있습니다.</block>
  <block id="3310d189628fa6ef843aac57894a6db2" category="admonition">SDDC 프라이빗 클라우드 및 NetApp Cloud Volumes 코로케이션을 통해 최소한의 네트워크 지연 시간으로 최상의 성능을 제공합니다.</block>
  <block id="c771fce16e2ba5df07df53cc5ab0748f" category="section-title">알고 계셨습니까?</block>
  <block id="8bba30129de0461b328be1e49f02b4d9" category="paragraph">사용된 클라우드에 관계없이 VMware SDDC를 구축할 때 초기 클러스터에 포함되는 제품은 다음과 같습니다.</block>
  <block id="7110e7a8682a9bc1c7105b83fe0cd9ea" category="list-text">관리를 위해 vCenter Server 어플라이언스를 사용하여 컴퓨팅 가상화를 위한 VMware ESXi 호스트</block>
  <block id="7d7a80e207de2136f4f19820758703fc" category="list-text">VMware vSAN 하이퍼 컨버지드 스토리지는 각 ESXi 호스트의 물리적 스토리지 자산을 통합합니다</block>
  <block id="d2852e9d73c0ef81033c835719128b81" category="list-text">관리를 위해 NSX Manager 클러스터를 사용하여 가상 네트워킹 및 보안을 위한 VMware NSX</block>
  <block id="afb91ca7e7763c77e44a41cb5ad0f78b" category="paragraph">스토리지 집약적인 워크로드를 호스팅하거나 클라우드 호스팅 VMware 솔루션에서 스케일아웃하려는 고객의 경우 기본 하이퍼 컨버지드 인프라는 확장이 컴퓨팅 및 스토리지 리소스 모두에 있어야 한다는 것을 나타냅니다.</block>
  <block id="fdb27bea654a8d874baecced2be84a1b" category="paragraph">Azure NetApp Files, Amazon FSx for NetApp ONTAP, Cloud Volumes ONTAP(세 가지 주요 하이퍼 스케일러 모두에서 사용 가능) 및 Cloud Volumes Service for Google Cloud와 같은 NetApp Cloud Volumes와 통합함으로써 고객은 이제 스토리지를 개별적으로 확장할 수 있는 옵션을 갖게 됩니다. 필요에 따라 SDDC 클러스터에만 컴퓨팅 노드를 추가할 수 있습니다.</block>
  <block id="2a01d572b1447155c310cabafac3fae9" category="section-title">참고:</block>
  <block id="a752c3529f0285d457f3b33b3c80d9a4" category="list-text">VMware는 불균형 클러스터 구성을 권장하지 않습니다. 따라서 스토리지를 확장한다는 것은 더 많은 호스트를 추가해야 한다는 것을 의미하며, 이는 더 많은 TCO를 의미합니다.</block>
  <block id="1d8249c60cae81d82fc5bfb80167babc" category="list-text">하나의 vSAN 환경만 가능합니다. 따라서 모든 스토리지 트래픽은 운영 워크로드와 직접 경쟁하게 됩니다.</block>
  <block id="c231690c8e9fabbd819ec1805becb157" category="list-text">애플리케이션 요구사항, 성능, 비용을 맞추기 위해 여러 성능 계층을 제공하는 옵션은 없습니다.</block>
  <block id="5d4c92ddd5fe9a6044b25c17d3368207" category="list-text">클러스터 호스트 위에 구축된 vSAN의 스토리지 용량 제한에 매우 쉽게 도달할 수 있습니다. NetApp Cloud Volumes를 사용하여 액티브 데이터 세트를 호스트하거나 영구 스토리지로 계층 쿨러 데이터를 계층화하도록 스토리지를 확장할 수 있습니다.</block>
  <block id="c1cf68955de5fa20274b29fa4a2a863f" category="paragraph">Azure NetApp Files, Amazon FSx for NetApp ONTAP, Cloud Volumes ONTAP(세 가지 주요 하이퍼 스케일러 모두에서 사용 가능) 및 Cloud Volumes Service for Google Cloud를 게스트 VM과 함께 사용할 수 있습니다. 이 하이브리드 스토리지 아키텍처는 게스트 운영 체제 및 애플리케이션 바이너리 데이터를 보관하는 vSAN 데이터스토어로 구성됩니다. 애플리케이션 데이터는 각각 NetApp ONTAP용 Amazon FSx, Cloud Volume ONTAP, Azure NetApp Files 및 Google Cloud용 Cloud Volumes Service와 직접 통신하는 게스트 기반 iSCSI 이니시에이터 또는 NFS/SMB 마운트를 통해 VM에 연결됩니다. 이 구성을 사용하면 vSAN과 같이 스토리지 용량과 관련된 문제를 쉽게 해결할 수 있습니다. 사용 가능한 여유 공간은 사용된 여유 공간 및 스토리지 정책에 따라 달라집니다.</block>
  <block id="1a5208bfffc624ccf99dfcbbf2078050" category="paragraph">AWS의 VMware Cloud에서 3노드 SDDC 클러스터를 살펴보겠습니다.</block>
  <block id="fab7fb31baaec1ccac4fe688e1a4c5d4" category="list-text">3노드 SDDC의 총 물리적 용량은 31.1TB(각 노드당 약 10TB)입니다.</block>
  <block id="ca189b47c3a1dfe1adbd1519688e4cc8" category="list-text">호스트를 추가하기 전에 유지 관리해야 하는 여유 공간 = 25% = (.25 x 31.1TB) = 7.7TB</block>
  <block id="999b2c719df3f3e524bb10fb76521726" category="list-text">여유 공간 차감 후의 가용 물리적 용량 = 23.4TB</block>
  <block id="2e1f3b31385d3304e1cda70b9cd8ed4c" category="list-text">사용 가능한 유효 여유 공간은 적용된 스토리지 정책에 따라 달라집니다.</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">예를 들면 다음과 같습니다.</block>
  <block id="2f5e6d9b0a4708c4d137ba14ac704a7b" category="list-text">RAID 0 = 유효 여유 공간 = 23.4TB(사용 가능한 물리적 용량/1)</block>
  <block id="df6b502d4d7283ef27d3821b69836c2d" category="list-text">RAID 1 = 유효 여유 공간 = 11.7TB(사용 가능한 물리적 용량/2)</block>
  <block id="921c660c11d4880048f3ef723f079e17" category="list-text">RAID 5 = 유효 여유 공간 = 17.5TB(사용 가능한 물리적 용량/1.33)</block>
  <block id="e3bdc3102c3de4f73860c229550bc6f4" category="paragraph">따라서 NetApp Cloud Volumes를 게스트 연결 스토리지로 사용하면 스토리지를 확장하고 TCO를 최적화하는 동시에 성능 및 데이터 보호 요구사항을 충족할 수 있습니다.</block>
  <block id="e79592580385a4ae403f3655a7200469" category="paragraph">현재 NetApp 스토리지를 데이터 저장소로 제공하는 것은 모든 주요 하이퍼스케일러 클라우드에서 프라이빗 preview의 기능이 되고 있습니다. 자세한 내용은 다음 링크를 참조하십시오.</block>
  <block id="bb747e48aa1d3d3e7f7770860486da18" category="inline-link-macro">FSX ONTAP는 AWS의 기본 데이터 저장소입니다</block>
  <block id="0e8dc2a599bea7faae9351c694a4f162" category="inline-link-macro">Azure NetApp Files(ANF)를 Azure용 네이티브 데이터 저장소로 사용합니다</block>
  <block id="3e6b003f71badaeb92ae26f7ed351a37" category="inline-link-macro">CVS(Cloud Volumes Service)를 GCP용 기본 데이터 저장소로 사용합니다</block>
  <block id="5ab63999a01c682c3e901f550611531f" category="paragraph"><block ref="6b7315f1b0dd5562c105ae89b6efa525" category="inline-link-macro-rx"></block>
<block ref="730b198f919befec53ca8dcebabd176b" category="inline-link-macro-rx"></block>
<block ref="7fb3f61cbe4dcbff12c3d3e4fb2e9565" category="inline-link-macro-rx"></block></block>
  <block id="571c0d425ce03c2532e7d9f34ca87cb1" category="section-title">기억해야 할 사항</block>
  <block id="8e6eaed3852a3b311ab6ed1b8b6fc239" category="list-text">하이브리드 스토리지 모델에서는 Tier 1 또는 높은 우선 순위의 워크로드를 vSAN 데이터 저장소에 배치하여 호스트 자체의 일부이고 근접하기 때문에 특정 지연 시간 요구 사항을 처리합니다. 트랜잭션 지연 시간이 허용되는 워크로드 VM에 대해 게스트 내 메커니즘을 사용합니다.</block>
  <block id="43ff7a71a2ea2fc47a29d410cd1e4944" category="list-text">NetApp SnapMirror ® 기술을 사용하여 온프레미스 ONTAP 시스템에서 Cloud Volumes ONTAP 또는 NetApp ONTAP용 Amazon FSx로 워크로드 데이터를 복제하여 블록 레벨 메커니즘을 사용하여 손쉽게 마이그레이션할 수 있습니다. Azure NetApp Files 및 Cloud Volumes Services에는 적용되지 않습니다. 데이터를 Azure NetApp Files 또는 Cloud Volumes Services로 마이그레이션하려면 사용되는 파일 프로토콜에 따라 NetApp XCP, Cloud Sync, rysnc 또는 robocopy를 사용하십시오.</block>
  <block id="d3c0fd4b510310b9bd00463208eade94" category="list-text">테스트 결과, 각 SDDC에서 스토리지에 액세스하는 동안 지연 시간이 2-4ms로 더 길어집니다. 스토리지를 매핑할 때 애플리케이션 요구 사항에 이러한 추가 지연 시간을 고려하십시오.</block>
  <block id="b83cf0bc9b65a0fcd5f49d4c96dceea8" category="list-text">테스트 페일오버 및 실제 페일오버 중에 게스트 연결 스토리지를 마운트하려면 iSCSI 이니시에이터가 재구성되고 DNS가 SMB 공유용으로 업데이트되며 NFS 마운트 지점이 fstab에서 업데이트되도록 합니다.</block>
  <block id="1b4048870ed334dbc2e7d6f09a814188" category="list-text">게스트 내 Microsoft MPIO(Multipath I/O), 방화벽 및 디스크 시간 초과 레지스트리 설정이 VM 내에서 올바르게 구성되어 있는지 확인합니다.</block>
  <block id="bf3f0fd9ec5faf81793c3abc5e3b9127" category="admonition">이는 게스트 연결 스토리지에만 적용됩니다.</block>
  <block id="00b23e82efc2ec82b134496e575a934c" category="section-title">NetApp 클라우드 스토리지의 이점</block>
  <block id="80def6ec4d999fc4d082800c8c33f6ec" category="paragraph">NetApp 클라우드 스토리지는 다음과 같은 이점을 제공합니다.</block>
  <block id="2e594db552f7cd9c7f02d87507dbb471" category="list-text">컴퓨팅과 상관없이 스토리지를 확장함으로써 컴퓨팅 및 스토리지 간 밀도 향상</block>
  <block id="479f9f236fc4cffa74f2e94b654bbeeb" category="list-text">호스트 수를 줄여 전체 TCO를 줄일 수 있습니다.</block>
  <block id="108dd736471686a2b8b87154d73cbc5b" category="list-text">컴퓨팅 노드 장애는 스토리지 성능에 영향을 주지 않습니다.</block>
  <block id="a85e0a264279b851fbcec367c181932e" category="list-text">Azure NetApp Files의 볼륨 재구성 및 동적 서비스 수준 기능을 사용하면 안정적인 워크로드 크기를 조정하여 비용을 최적화하고 오버 프로비저닝을 방지할 수 있습니다.</block>
  <block id="4e24ca7789e0b9320e302b8efa2caf9f" category="list-text">Cloud Volumes ONTAP의 스토리지 효율성, 클라우드 계층화 및 인스턴스 유형 수정 기능을 사용하면 스토리지를 최적의 방법으로 추가 및 확장할 수 있습니다.</block>
  <block id="d7a87fa8fc914cf57f38eff05d53faa2" category="list-text">필요 시에만 스토리지 리소스의 초과 프로비저닝을 방지합니다.</block>
  <block id="940eacbcb0faa8c3b1e0d995c154f693" category="list-text">효율적인 스냅샷 복사본 및 복제를 사용하면 성능에 영향을 미치지 않고 복사본을 빠르게 생성할 수 있습니다.</block>
  <block id="a9e4a9fcd1f9bf0a9d0d0b2c0f198db5" category="list-text">Snapshot 복사본에서 빠른 복구를 사용하여 랜섬웨어 공격을 해결할 수 있도록 도와줍니다.</block>
  <block id="caf9b805c37cab661d4e3a26b7f71109" category="list-text">효율적인 증분 블록 전송 기반 지역 재해 복구 및 여러 지역에 걸쳐 통합된 백업 블록 레벨을 제공하여 RPO 및 RTO가 향상됩니다.</block>
  <block id="658fb5ef00749e8af5a974f612adea9b" category="section-title">가정</block>
  <block id="a9e63f2a8549d717b777806268a0c0cb" category="list-text">SnapMirror 기술 또는 기타 관련 데이터 마이그레이션 메커니즘이 사용됩니다. 온프레미스에서 하이퍼스케일러 클라우드에 이르기까지 다양한 연결 옵션이 있습니다. 적절한 경로를 사용하고 관련 네트워킹 팀과 협력하십시오.</block>
  <block id="c63dc0feeff939bc83ba1537a1e8ac9a" category="list-text">이 문서가 작성된 시점에서 게스트 내 저장소가 유일하게 사용 가능한 옵션이었습니다.</block>
  <block id="478a13ed02b948c9cfd89a6197062012" category="admonition">스토리지 계획 및 사이징과 필요한 호스트 수에 대해서는 NetApp 솔루션 설계자와 각각의 하이퍼스케일러 클라우드 설계자를 설득하십시오. Cloud Volumes ONTAP Sizer를 사용하여 스토리지 인스턴스 유형 또는 적절한 서비스 수준을 최적의 처리량으로 확정하기 전에 스토리지 성능 요구사항을 파악하는 것이 좋습니다.</block>
  <block id="c748546b5854ecb146d9caa41d781bdb" category="section-title">상세 아키텍처</block>
  <block id="2b6a2372968d8ec2639d784ce8aee350" category="paragraph">개략적인 관점에서 볼 때 이 아키텍처(아래 그림에 표시)에서는 NetApp Cloud Volumes ONTAP, Cloud Volumes Service for Google Cloud 및 Azure NetApp Files를 추가 게스트 스토리지 옵션으로 사용하여 여러 클라우드 공급자 간에 하이브리드 멀티 클라우드 연결과 앱 이동성을 달성하는 방법을 설명합니다.</block>
  <block id="1a8ac44404b1e5888d83801ac116ff66" category="inline-image-macro">엔터프라이즈 하이브리드 클라우드 아키텍처</block>
  <block id="855b05f645c80247a3f11392cab187c2" category="paragraph"><block ref="855b05f645c80247a3f11392cab187c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63b9fbe67e7dd9b9f7623683244cb7f8" category="doc">Azure AVS용 NetApp 기능</block>
  <block id="ea7f7b3af23a2abea8816902269875f9" category="paragraph">NetApp이 AVS(Azure VMware Solution)에 제공하는 기능에 대해 자세히 알아보십시오. NetApp은 게스트 연결 스토리지 장치 또는 기본 데이터 저장소로 마이그레이션 워크플로우에 전환하여 클라우드, 백업/복원 및 재해 복구를 확장/급증할 수 있습니다.</block>
  <block id="1f0a2077c33b91b3daaaea05c7fadc07" category="section-title">Azure에서 AVS 구성</block>
  <block id="cdac9a2e7f1dc52240712d4a191378e8" category="section-title">AVS용 NetApp 스토리지 옵션</block>
  <block id="a69a7b9e874f9f6e0703191e7825cc4f" category="paragraph">NetApp 스토리지는 Azure AVS에서 추측으로 연결되거나 기본 데이터 저장소로 사용될 수 있습니다.</block>
  <block id="cf3ac5a0dae3780b356e57c121b3eab0" category="doc">Google Cloud Platform(GCP)에서 가상화 환경 구축 및 구성</block>
  <block id="8514045c5551663f28246e665ca2f189" category="list-text"><block ref="8514045c5551663f28246e665ca2f189" category="inline-link-macro-rx"></block></block>
  <block id="3cef16671ee166d12c5fd192fa419358" category="list-text"><block ref="3cef16671ee166d12c5fd192fa419358" category="inline-link-macro-rx"></block></block>
  <block id="fd558e50adcdcb0d667a4790f70f75a9" category="paragraph">GCP에서 GCVE 환경을 구성하려면 GCP 콘솔에 로그인하고 VMware Engine 포털에 액세스합니다.</block>
  <block id="fb33f758c28f8ef8d56e41f74b4c47ab" category="paragraph">“새 사설 클라우드” 버튼을 클릭하고 GCVE 프라이빗 클라우드에 대해 원하는 구성을 입력합니다. “위치”에서 CVS/CVO가 배포된 동일한 지역/영역에 프라이빗 클라우드를 배포하여 최상의 성능과 최저 지연 시간을 보장해야 합니다.</block>
  <block id="63b31ca49de01854f780d1e1722cd1c1" category="paragraph">전제 조건:</block>
  <block id="d79b0ab3cbae1dcd79007a97d26af5b1" category="list-text">VMware Engine Service Admin IAM 역할을 설정합니다</block>
  <block id="72a7f08f840ab91a28a2558393971c47" category="inline-link-macro">VMware Engine API 액세스 및 노드 할당량을 설정합니다</block>
  <block id="88e3e4c9b1c9efec399f7dda7a0c5887" category="list-text"><block ref="88e3e4c9b1c9efec399f7dda7a0c5887" category="inline-link-macro-rx"></block></block>
  <block id="a88d670b04af96a871dad56001e8f742" category="list-text">CIDR 범위가 온-프레미스 또는 클라우드 서브넷과 겹치지 않도록 하십시오. CIDR 범위는 /27 이상이어야 합니다.</block>
  <block id="33d7d6c631c2d2cb3608445ef761fe16" category="paragraph"><block ref="33d7d6c631c2d2cb3608445ef761fe16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65bdc0673006b33d0c876e18a9a98787" category="paragraph">참고: 프라이빗 클라우드를 생성하는 데 30분에서 2시간까지 걸릴 수 있습니다.</block>
  <block id="d77d7a022616e70a9987aa0974241779" category="paragraph">프라이빗 클라우드가 프로비저닝되면 높은 처리량과 짧은 지연 시간의 데이터 경로 연결을 위해 프라이빗 클라우드에 대한 프라이빗 액세스를 구성합니다.</block>
  <block id="256431e41a96deb49bcd86b1ca56393e" category="inline-link-macro">GCP 문서</block>
  <block id="e4cf8d7f33a9dafc85be0439cd8fbc4d" category="paragraph">이렇게 하면 Cloud Volumes ONTAP 인스턴스가 실행 중인 VPC 네트워크가 GCVE 프라이빗 클라우드와 통신할 수 있습니다. 이렇게 하려면 를 따르십시오 <block ref="9cd64b8fb1b43e7f674c1b78b2a86f74" category="inline-link-macro-rx"></block>. 클라우드 볼륨 서비스의 경우 테넌트 호스트 프로젝트 간에 일회성 피어링을 수행하여 VMware 엔진과 Cloud Volumes Service 간에 연결을 설정합니다. 자세한 단계는 다음과 같습니다 <block ref="04a9f04edfdd7b0a53da57f015378c5a" category="inline-link-macro-rx"></block>.</block>
  <block id="e6945148d9a888e52db99c5ebce86868" category="paragraph"><block ref="e6945148d9a888e52db99c5ebce86868" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3eb3a1c6330fe124fc0706cbdd91df" category="paragraph">CloudOwner@gve.loca l 사용자를 사용하여 vCenter에 로그인합니다. 자격 증명을 액세스하려면 VMware Engine 포털로 이동하여 리소스 로 이동한 다음 적절한 프라이빗 클라우드를 선택합니다. 기본 정보 섹션에서 vCenter 로그인 정보(vCenter Server, HCX Manager) 또는 NSX-T 로그인 정보(NSX Manager)에 대한 보기 링크를 클릭합니다.</block>
  <block id="6f32389268763bedb9e6716b5f0973d0" category="paragraph"><block ref="6f32389268763bedb9e6716b5f0973d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ec2407381a4f65d228483b566b6907f" category="paragraph">Windows 가상 머신에서 브라우저를 열고 vCenter 웹 클라이언트 URL로 이동합니다 <block ref="d325f0342d122dda054a3ca8b0c44019" category="inline-link-rx"></block> admin 사용자 이름을 CloudOwner@gve.loca l 로 사용하여 복사한 암호를 붙여 넣습니다. 마찬가지로 웹 클라이언트 URL을 사용하여 NSX-T Manager에 액세스할 수도 있습니다 <block ref="c694eb5be92097a8fdea8cdda0ad5ea5" category="inline-link-rx"></block> 관리자 사용자 이름을 사용하여 복사한 암호를 붙여 넣어 새 세그먼트를 만들거나 기존 계층 게이트웨이를 수정합니다.</block>
  <block id="3a9cff0eb1abb119c1c264dbfff216f6" category="paragraph">사내 네트워크에서 VMware Engine 프라이빗 클라우드로 연결하려면 클라우드 VPN 또는 Cloud Interconnect를 활용하여 적절한 연결을 설정하고 필요한 포트가 열려 있는지 확인합니다. 자세한 단계는 다음과 같습니다 <block ref="6fe8ac83365e22e24c5c8eb9edc2d548" category="inline-link-macro-rx"></block>.</block>
  <block id="b433f901707e7fd0f6d64371dfca4af9" category="paragraph"><block ref="b433f901707e7fd0f6d64371dfca4af9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="989afab9e0dfcc6d523ddb1d23145834" category="paragraph"><block ref="989afab9e0dfcc6d523ddb1d23145834" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b23824e61fecb77e1ae6d9f739a9fb83" category="doc">AWS용 NetApp 기본 데이터 저장소 옵션</block>
  <block id="ba756c1a2b93ad97a639914aae828a16" category="doc">AWS VMC를 위한 NetApp 솔루션</block>
  <block id="c31fafd8fe5f702d3722404547cc8cb5" category="paragraph">NetApp이 AWS VMware 클라우드(VMC)에 제공하는 기능에 대해 자세히 알아보십시오. NetApp은 게스트 연결 스토리지 장치 또는 기본 데이터 저장소로 마이그레이션 워크플로우에 전환하여 클라우드, 백업/복원 및 재해 복구를 확장/급증할 수 있습니다.</block>
  <block id="8658ccb747e94ac624861f5761a34716" category="section-title">AWS에서 VMC 구성</block>
  <block id="e9f84da32eb512bd768458a738ed8aa6" category="section-title">VMC용 NetApp 스토리지 옵션</block>
  <block id="cd5a564d709538be5df5e7167600498d" category="paragraph">AWS VMC에서 NetApp 스토리지를 추측으로 연결 또는 기본 데이터 저장소로 활용할 수 있습니다.</block>
  <block id="ee5c3b650204d422e3d3e7bd725ec032" category="paragraph">NetApp이 게스트 연결 스토리지 장치 또는 네이티브 데이터 저장소로 NetApp의 3가지 운영 하이퍼스케일러에 제공하는 기능에 대해 자세히 알아보십시오. 마이그레이션 워크플로우, 백업/복원, 재해 복구 등 확대/버스팅이 확장됩니다.</block>
  <block id="f21c97f5b239021bb3f13d148516abb4" category="paragraph">클라우드를 선택하시면 NetApp에서 나머지 작업을 해 드립니다!</block>
  <block id="c1304f98c6be845a236d7a27951ece4f" category="paragraph"><block ref="c1304f98c6be845a236d7a27951ece4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca4ac823f3f130f3c78d6ac26ba9f46b" category="admonition">특정 하이퍼스케일러의 기능을 보려면 해당 하이퍼스케일러의 적절한 탭을 클릭하십시오.</block>
  <block id="56ef2682280ac110060b881925a87b80" category="open-title">Google 클라우드</block>
  <block id="ff264305bf70750f504c04f48ab02038" category="paragraph">NetApp 스토리지는 3가지 주요 하이퍼 스케일러 내에서 상호 연결된 추측이나 기본 데이터 저장소로 활용할 수 있습니다.</block>
  <block id="76b7cf7d0f36f0986e2c7ef578303aab" category="doc">요약 및 결론: 엔터프라이즈 하이브리드 클라우드(EHC)에 NetApp을 선택해야 하는 이유</block>
  <block id="dd6f2ba05323a537582c1f232e8a2c60" category="paragraph">주요 하이퍼스케일러를 위한 VMware 솔루션과 NetApp Cloud Volumes는 하이브리드 클라우드를 활용하려는 조직에 최고의 잠재력을 제공합니다. 이 섹션의 나머지 부분에서는 NetApp Cloud Volumes 통합을 통해 진정한 하이브리드 멀티 클라우드 기능을 실현하는 사용 사례를 소개합니다.</block>
  <block id="e7441dbfabeaebba75ddd1bf2bcf25e9" category="section-title">사용 사례 #1: 스토리지 최적화</block>
  <block id="b9a8c3d27aa6638e02992c8b76fea769" category="paragraph">RVtools 출력을 사용하여 사이징 작업을 수행할 때 마력(vCPU/vmem) 스케일이 스토리지와 평행하다는 것이 항상 명백합니다. 스토리지 공간에 필요한 드라이브의 크기가 마력을 훨씬 넘어서는 상황에 처하게 되는 경우가 많습니다.</block>
  <block id="cb575e0b8e023ca0a1789ea03bdb86fd" category="paragraph">NetApp Cloud Volumes를 통합하면 간단한 마이그레이션 방식을 통해 vSphere 기반 클라우드 솔루션을 실현할 수 있습니다. 플랫폼 재구축 또는 IP 변경 없이 아키텍처 변경 없이 모든 작업을 수행할 수 있습니다. 또한 이러한 최적화를 통해 vSphere에서 호스트 수를 최소한으로 유지하면서 스토리지 설치 공간을 확장할 수 있으며, 스토리지 계층, 보안 또는 사용 가능한 파일은 변경되지 않습니다. 따라서 구축을 최적화하고 전체 TCO를 35~45% 절감할 수 있습니다. 또한 이러한 통합을 통해 스토리지를 따뜻한 스토리지에서 운영 수준의 성능으로 몇 초 이내에 확장할 수 있습니다.</block>
  <block id="9ae8084cfbf8c00bc50891fe51bb70b4" category="section-title">사용 사례 2: 클라우드 마이그레이션</block>
  <block id="40c30ee45ee11e766ec77dfd0d98cef0" category="paragraph">조직에서는 향후 임대 만료, 자본 지출(capex) 지출에서 운영 비용(opex) 지출로 전환해야 하는 재무 지침, 모든 것을 클라우드로 이동하는 하향식 등 다양한 이유로 애플리케이션을 사내 데이터 센터에서 퍼블릭 클라우드로 마이그레이션해야 한다는 압박을 받고 있습니다.</block>
  <block id="4744ec437cce262edc7110652b69ab21" category="paragraph">속도가 중요한 경우에는 클라우드의 특정 IaaS 플랫폼에 맞게 애플리케이션을 재구성하고 리팩토링하는 작업이 느리고 비용이 많이 들며 종종 몇 달이 소요되기 때문에 간소화된 마이그레이션 방식만 실현 가능합니다. NetApp Cloud Volumes를 게스트 연결 스토리지를 위한 대역폭 효율적인 SnapMirror 복제(애플리케이션 정합성이 보장된 Snapshot 복사본 및 HCX와 함께 RDM 포함, 클라우드 특정 마이그레이션(예 Azure 마이그레이션) 또는 타사 제품으로 VM 복제), 시간이 많이 소요되는 I/O 필터 메커니즘에 의존하는 것보다 훨씬 더 쉽게 전환할 수 있습니다.</block>
  <block id="d393e254c1adb8df50cfc41394c68645" category="section-title">사용 사례 3: 데이터 센터 확장</block>
  <block id="90c724dd3ba1ec0f533f7fb73a10323a" category="paragraph">데이터 센터가 특정 시기별 수요 급증 또는 지속적인 유기적 성장으로 인해 용량 제한에 도달할 경우, NetApp Cloud Volumes와 함께 클라우드 호스팅 VMware로 손쉽게 전환할 수 있습니다. NetApp Cloud Volumes를 활용하면 가용성 영역 및 동적 확장 기능에 걸쳐 고가용성을 제공하여 스토리지를 쉽게 생성, 복제 및 확장할 수 있습니다. NetApp Cloud Volumes를 활용하면 확장 클러스터의 필요성을 극복하여 호스트 클러스터 용량을 최소화할 수 있습니다.</block>
  <block id="0b95336d0f31a3bd4775f96c750bb9bc" category="section-title">사용 사례 4: 클라우드로 재해 복구</block>
  <block id="c2aee451a27e7cf3993f462ee5b760e9" category="paragraph">기존 방식에서는 재해가 발생할 경우 클라우드로 복제된 VM을 복원하기 전에 클라우드의 자체 하이퍼바이저 플랫폼으로 변환해야 합니다. 위기 상황에서 처리할 작업은 아닙니다.</block>
  <block id="772dec0515d132f26bfa87cb31b5758d" category="paragraph">퍼블릭 클라우드 가상화 솔루션과 함께 SnapCenter 및 온프레미스에서 SnapMirror 복제를 사용하여 게스트 연결 스토리지에 NetApp Cloud Volumes를 사용함으로써 재해 복구를 위한 더 나은 접근법을 고안하여, 클라우드 관련 복구 툴과 함께 완전히 일관된 VMware SDDC 인프라에서 VM 복제본을 복구할 수 있습니다(예 Azure Site Recovery) 또는 Veeam과 같은 타사 툴을 사용할 수 있습니다. 또한, 이 접근 방식을 통해 랜섬웨어에서 신속하게 재해 복구 훈련 및 복구를 수행할 수 있습니다. 또한 필요에 따라 호스트를 추가하여 테스트 또는 재해 발생 시 전체 운영 환경으로 확장할 수 있습니다.</block>
  <block id="24d0e6ab8003b406cf7e3f42363acbf5" category="section-title">사용 사례 5: 애플리케이션 현대화</block>
  <block id="59e56fb67c730af04acf8a13665cadb3" category="paragraph">퍼블릭 클라우드에 애플리케이션이 포함된 후에는 강력한 수백 가지 클라우드 서비스를 활용하여 애플리케이션을 현대화하고 확장하려고 할 것입니다. NetApp Cloud Volumes를 사용할 경우 애플리케이션 데이터가 vSAN에 종속되지 않고 Kubernetes를 포함한 광범위한 사용 사례에서 데이터를 이동할 수 있기 때문에 현대화는 쉬운 프로세스입니다.</block>
  <block id="eea420abccd820355b4bddd3524ae083" category="paragraph">All-Cloud와 하이브리드 클라우드 중 무엇을 목표로 하든 NetApp Cloud Volumes는 파일 서비스 및 블록 프로토콜과 함께 애플리케이션 워크로드를 구축 및 관리하는 데 탁월한 옵션을 제공하는 한편, 데이터 요구사항을 애플리케이션 계층에 원활하게 구현하여 TCO를 절감합니다.</block>
  <block id="cd51ff9774803e84c79e8ab19bb7ffd2" category="paragraph">어떤 사용 사례에서든 즐겨 사용하는 클라우드/하이퍼스케일러와 NetApp Cloud Volumes를 함께 사용하여 사내 및 멀티 클라우드 전체의 클라우드 이점, 일관된 인프라 및 운영을 빠르게 실현하고, 워크로드의 양방향 이동성을 제공하며, 엔터프라이즈급 용량과 성능을 실현할 수 있습니다.</block>
  <block id="2993778cba8ea9a69af4ff9dc7e18fb8" category="paragraph">스토리지를 연결하는 데 사용되는 것과 동일한 친숙한 프로세스와 절차입니다. 이는 새로운 이름으로 변경된 데이터의 위치일 뿐입니다. 도구와 프로세스는 그대로 유지되며 NetApp Cloud Volumes는 전체 구축을 최적화하는 데 도움이 됩니다.</block>
  <block id="bb01fec2870d3f698517f8471454637b" category="doc">Azure에서 가상화 환경을 구축하고 구성합니다</block>
  <block id="c33cce5b25d7b62b8be123136ad64ae1" category="list-text"><block ref="c33cce5b25d7b62b8be123136ad64ae1" category="inline-link-macro-rx"></block></block>
  <block id="d47c67e14996fb3c08deb5311a358578" category="list-text"><block ref="d47c67e14996fb3c08deb5311a358578" category="inline-link-macro-rx"></block></block>
  <block id="5a8521e0e0ab0935654c959eba47d6a0" category="list-text"><block ref="5a8521e0e0ab0935654c959eba47d6a0" category="inline-link-macro-rx"></block></block>
  <block id="6a3b9d31df0a58cc23207c2af925ef0f" category="paragraph">Azure VMware 솔루션을 사용하려면 먼저 확인된 구독 내에 리소스 공급자를 등록해야 합니다.</block>
  <block id="58c59ab4d5d488609913efa7b1daaa31" category="list-text">Azure 포털에 로그인합니다.</block>
  <block id="5d704d400396fefbe3427ee665a0ec16" category="list-text">Azure 포털 메뉴에서 모든 서비스를 선택합니다.</block>
  <block id="eff35df9bedc80337261af1399e526a2" category="list-text">모든 서비스 대화 상자에서 구독을 입력한 다음 구독 을 선택합니다.</block>
  <block id="41825376d695df481d13f37e3e1587db" category="list-text">보려면 구독 목록에서 구독을 선택합니다.</block>
  <block id="4d3e5a69b8f8c0bec64cf18db73fff95" category="list-text">리소스 공급자 를 선택하고 검색에 Microsoft.AVS 를 입력합니다.</block>
  <block id="2bf384915bc11a9360bdf9792dc43bf3" category="list-text">리소스 공급자가 등록되지 않은 경우 등록 을 선택합니다.</block>
  <block id="0b4b8a7bf2e1e647f3be6dde423b9b79" category="paragraph"><block ref="0b4b8a7bf2e1e647f3be6dde423b9b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb08f4992bb541aec19da4c688d0239" category="paragraph"><block ref="bdb08f4992bb541aec19da4c688d0239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="382da60e8008eed186472cc1a3c3ca37" category="list-text">리소스 공급자를 등록한 후 Azure 포털을 사용하여 Azure VMware Solution 프라이빗 클라우드를 생성합니다.</block>
  <block id="397065cbdc87787d17122a18f5c5088d" category="list-text">새 리소스 만들기 를 선택합니다.</block>
  <block id="39d2b5824a6dce05a74b5a60d5769656" category="list-text">Marketplace 검색 텍스트 상자에 Azure VMware Solution을 입력하고 결과에서 선택합니다.</block>
  <block id="d090262ac8690f612cbc8bd5fc83b11c" category="list-text">Azure VMware 솔루션 페이지에서 생성 을 선택합니다.</block>
  <block id="4a62c7a4f3f3f4a3927621c33c12bb63" category="list-text">기본 탭에서 필드에 값을 입력하고 검토 + 만들기를 선택합니다.</block>
  <block id="7c1ec568c35f8a03d9cfd64b465a4e4f" category="list-text">빠른 시작을 위해 계획 단계에서 필요한 정보를 수집합니다.</block>
  <block id="d61ffacba4094067e86b90bcf3739fcf" category="list-text">기존 리소스 그룹을 선택하거나 프라이빗 클라우드에 대한 새 리소스 그룹을 생성합니다. 리소스 그룹은 Azure 리소스가 배포 및 관리되는 논리적 컨테이너입니다.</block>
  <block id="81d6141ddb9ac3b3888dce83fbf00cf6" category="list-text">CIDR 주소가 고유하며 다른 Azure 가상 네트워크 또는 온-프레미스 네트워크와 겹치지 않도록 하십시오. CIDR은 프라이빗 클라우드 관리 네트워크를 나타내며 vCenter Server 및 NSX-T Manager와 같은 클러스터 관리 서비스에 사용됩니다. /22 주소 공간을 사용하는 것이 좋습니다. 이 예에서는 10.21.0.0/22 가 사용됩니다.</block>
  <block id="266811324b3ca32d24624ba571c07de8" category="paragraph"><block ref="266811324b3ca32d24624ba571c07de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd710e77504d5568fd5079361107a7eb" category="paragraph">프로비저닝 프로세스는 약 4~5시간이 소요됩니다. 프로세스가 완료된 후 Azure 포털에서 프라이빗 클라우드에 액세스하여 성공적으로 배포되었는지 확인합니다. 구축이 완료되면 성공 상태가 표시됩니다.</block>
  <block id="411f20742da0d4f8cdc568d7aee8fab3" category="paragraph">Azure VMware 솔루션 프라이빗 클라우드에는 Azure 가상 네트워크가 필요합니다. Azure VMware 솔루션은 사내 vCenter를 지원하지 않으므로 기존 사내 환경과 통합하려면 추가 단계가 필요합니다. 또한 ExpressRoute 회로 및 가상 네트워크 게이트웨이를 설정해야 합니다. 클러스터 프로비저닝이 완료될 때까지 기다리는 동안 새 가상 네트워크를 생성하거나 기존 가상 네트워크를 사용하여 Azure VMware 솔루션에 연결합니다.</block>
  <block id="aa86eba8b2b706f81a805eb35b834541" category="paragraph"><block ref="aa86eba8b2b706f81a805eb35b834541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae6569fd64694b91a054cbdfdfef84d2" category="paragraph">새 Azure VNet(Virtual Network)을 생성하려면 Azure VNET Connect 탭을 선택합니다. 또는 가상 네트워크 생성 마법사를 사용하여 Azure 포털에서 수동으로 생성할 수도 있습니다.</block>
  <block id="34b04201ae997eaabb6802b04d5c1708" category="list-text">Azure VMware Solution 프라이빗 클라우드로 이동하고 관리 옵션 아래에서 접속 구성에 액세스합니다.</block>
  <block id="da40ae630b63a930be4e1230efc306e1" category="list-text">Azure VNET Connect를 선택합니다.</block>
  <block id="40292c219898a1253befc6301234575a" category="list-text">새 VNET를 생성하려면 Create New 옵션을 선택합니다.</block>
  <block id="f98e10d9ba9ac83ac2adeacde774d051" category="paragraph">이 기능을 사용하면 VNET를 Azure VMware Solution 프라이빗 클라우드에 연결할 수 있습니다. VNET는 Azure VMware Solution에서 ExpressRoute를 통해 생성된 프라이빗 클라우드에 필요한 구성 요소(예: 점프 박스, Azure NetApp Files와 같은 공유 서비스, 클라우드 볼륨 ONTAP)를 자동으로 생성하여 이 가상 네트워크의 워크로드 간 통신을 지원합니다.</block>
  <block id="0314a97a9eb0aae73531717ef45ad195" category="paragraph">* 참고: * VNET 주소 공간은 사설 클라우드 CIDR과 겹치지 않아야 합니다.</block>
  <block id="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="paragraph"><block ref="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="inline-image-macro-rx" type="image"></block></block>
  <block id="206843027dd7ebe90f425f9ee4765a01" category="list-text">새 VNET에 대한 정보를 제공하거나 업데이트하고 OK(확인) 를 선택합니다.</block>
  <block id="26c6d54522f3fd79684f463116e9634b" category="paragraph"><block ref="26c6d54522f3fd79684f463116e9634b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="027524e66bad6099279342bf8d8f6dd4" category="paragraph">제공된 주소 범위 및 게이트웨이 서브넷이 있는 VNET는 지정된 가입 및 리소스 그룹에 생성됩니다.</block>
  <block id="5ecf2fb7501138eaa14be97a59d2a773" category="inline-link-macro">Azure에서 VMware 프라이빗 클라우드에 대한 네트워킹을 구성합니다</block>
  <block id="5da6ff60860f48de7bb7f4467c28f26f" category="admonition">VNET를 수동으로 생성하는 경우 해당 SKU와 ExpressRoute를 게이트웨이 유형으로 사용하여 가상 네트워크 게이트웨이를 생성합니다. 구축이 완료되면 인증 키를 사용하여 Azure VMware Solution 프라이빗 클라우드가 포함된 가상 네트워크 게이트웨이에 ExpressRoute 연결을 연결합니다. 자세한 내용은 을 참조하십시오 <block ref="4807c1aea8c93bde3104bd4ecfa22a07" category="inline-link-macro-rx"></block>.</block>
  <block id="5c2d9a62bb25b00981f59e22e27bfd17" category="section-title">Azure VMware Solution 프라이빗 클라우드에 대한 네트워크 연결 및 액세스 검증</block>
  <block id="40228f700f5965975e4aff8c6c2ff4b3" category="paragraph">Azure VMware 솔루션에서는 사내 VMware vCenter를 통해 프라이빗 클라우드를 관리할 수 없습니다. 대신, 점프 호스트는 Azure VMware Solution vCenter 인스턴스에 연결하는 데 필요합니다. 지정된 리소스 그룹에 점프 호스트를 생성하고 Azure VMware Solution vCenter에 로그인합니다. 이 점프 호스트는 연결을 위해 생성된 동일한 가상 네트워크의 Windows VM이고 vCenter 및 NSX Manager에 대한 액세스를 제공해야 합니다.</block>
  <block id="d88c36b93ae5dcb2646d56c57f27bf0e" category="paragraph"><block ref="d88c36b93ae5dcb2646d56c57f27bf0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44f5524c6ac4144dbabf7a4d365b837b" category="paragraph">가상 시스템을 프로비저닝한 후에는 연결 옵션을 사용하여 RDP에 액세스합니다.</block>
  <block id="443f53614721177f7c44df93d426a919" category="paragraph"><block ref="443f53614721177f7c44df93d426a919" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36cb4e54805ffde727ffbc809183608e" category="paragraph">새로 생성된 이 점프 호스트 가상 머신에서 클라우드 관리자 사용자를 사용하여 vCenter에 로그인합니다. 자격 증명에 액세스하려면 Azure 포털로 이동하여 ID로 이동합니다(프라이빗 클라우드 내의 관리 옵션 아래). 프라이빗 클라우드 vCenter 및 NSX-T Manager의 URL 및 사용자 자격 증명은 여기에서 복사할 수 있습니다.</block>
  <block id="9620acd59a8e7ad0f318754391c40c4e" category="paragraph"><block ref="9620acd59a8e7ad0f318754391c40c4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73d88630b730fa00c46338a0aef4c2d3" category="paragraph">Windows 가상 머신에서 브라우저를 열고 vCenter 웹 클라이언트 URL로 이동합니다 <block ref="2db127a24dc88638a76677b404bda5a4" category="inline-link-rx"></block> 관리자 사용자 이름을 * cloudadmin@vsphere.loca l * 로 사용하고 복사한 암호를 붙여 넣습니다. 마찬가지로 웹 클라이언트 URL을 사용하여 NSX-T Manager에 액세스할 수도 있습니다 <block ref="bb142e18a679100de3817fcefaa25b07" category="inline-link-rx"></block> 관리자 사용자 이름을 사용하여 복사한 암호를 붙여 넣어 새 세그먼트를 만들거나 기존 계층 게이트웨이를 수정합니다.</block>
  <block id="4a6e0ba5b4d42fb0f658bdfdbbea32fc" category="admonition">웹 클라이언트 URL은 프로비저닝된 각 SDDC에 따라 다릅니다.</block>
  <block id="49848931415b32db238a2dd1daddf3a7" category="paragraph"><block ref="49848931415b32db238a2dd1daddf3a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f65f698ac6bac1ada03193e1cdabb8" category="paragraph"><block ref="87f65f698ac6bac1ada03193e1cdabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec3eeb836273dbc92b27ce718a90b212" category="inline-link-macro">온프레미스 환경을 Azure VMware 솔루션에 대해 알아보십시오</block>
  <block id="097529edf2feb9ed1237427eaa3b2599" category="paragraph">이제 Azure VMware Solution SDDC가 구축 및 구성되었습니다. ExpressRoute Global Reach를 활용하여 사내 환경을 Azure VMware 솔루션 프라이빗 클라우드에 연결합니다. 자세한 내용은 을 참조하십시오 <block ref="29749340a5d7bf5df1867a3f2d2723a1" category="inline-link-macro-rx"></block>.</block>
  <block id="2195b6c1bba772f631332c732395b829" category="doc">엔터프라이즈 하이브리드 클라우드(EHC)의 사용 사례</block>
  <block id="5f1bd6ade489565bebba9a771b93fe70" category="paragraph">하이브리드 클라우드 또는 클라우드 우선 구축을 계획할 때 IT 조직에 중요한 사용 사례에 대한 개요입니다.</block>
  <block id="0812fc943ecbd9a54d88fb25729d0aa5" category="section-title">보편적인 사용 사례</block>
  <block id="f136615e6f2c1b330afb72bf4a45b4a4" category="paragraph">사용 사례는 다음과 같습니다.</block>
  <block id="3481fb80f122383c65ff8c6c8fd8c943" category="list-text">재해 복구,</block>
  <block id="4127bac8297e2af8866315910651ce47" category="list-text">데이터 센터 유지 관리 중에 워크로드를 호스팅 * 로컬 데이터 센터에서 프로비저닝되는 것 이상의 추가 리소스가 필요한 빠른 증가,</block>
  <block id="20b1c73b5938d2d878aa1d96fee7f1b2" category="list-text">VMware 사이트 확장,</block>
  <block id="5fe13b2b805496310dbaa281d7325877" category="list-text">클라우드로 신속하게 마이그레이션,</block>
  <block id="b278a6d011d590bb350b9cb81c21a732" category="list-text">개발/테스트, 및</block>
  <block id="2116d89ca4be9d5a23f758068a2225b2" category="list-text">클라우드 네이티브 기술을 활용하여 애플리케이션 현대화</block>
  <block id="bc262005b263505cc0464e05c4324687" category="section-title">IT의 여정</block>
  <block id="cfdb9aabb4aedf8cad2e330ba5a516a3" category="paragraph">대부분의 조직은 혁신과 현대화를 향한 여정을 진행 중입니다. 이 프로세스의 일환으로 기업들은 기존 VMware 투자를 활용하는 동시에 클라우드의 이점을 활용하고 마이그레이션 프로세스를 최대한 원활하게 만드는 방법을 모색하고 있습니다. 이 접근 방식은 데이터가 이미 클라우드에 있기 때문에 현대화에 대한 노력을 매우 쉽게 할 수 있습니다.</block>
  <block id="9576824e6ccc9e436057f6d3bcd644d2" category="paragraph">이 시나리오에 대한 가장 쉬운 답은 각 하이퍼스케일러의 VMware 오퍼링입니다. NetApp ® Cloud Volumes와 마찬가지로 VMware는 사내 VMware 환경을 클라우드로 이동 또는 확장하는 방법을 제공하므로 클라우드에서 워크로드를 기본적으로 실행하면서 기존 온프레미스 자산, 기술 및 툴을 유지할 수 있습니다. 따라서 서비스 중단이나 IP 변경이 필요하지 않고 IT 팀이 기존 기술과 툴을 사용하여 사내에서 작업하는 방식을 운영할 수 있으므로 위험이 감소합니다. 따라서 클라우드 마이그레이션 속도가 향상되고 하이브리드 멀티 클라우드 아키텍처로의 전환이 더욱 원활해질 수 있습니다.</block>
  <block id="ca0a16f344ac7703cf785163a8f07f5d" category="section-title">기본 스토리지 옵션의 중요성 이해</block>
  <block id="46da638bac867fb225c11e1d8504da00" category="paragraph">어떤 클라우드에서든 VMware는 모든 고객에게 고유한 하이브리드 기능을 제공하지만, 제한된 기본 스토리지 옵션으로 스토리지 집약적인 워크로드를 사용하는 조직에는 유용성이 제한됩니다. 스토리지는 호스트에 직접 연결되므로 스토리지를 확장하는 유일한 방법은 호스트를 추가하는 것입니다. 이렇게 하면 스토리지 집약적인 워크로드의 비용이 35-40% 이상 증가할 수 있습니다. 이러한 워크로드는 추가 마력이 아닌 추가 스토리지만 필요합니다. 하지만 이는 추가 호스트에 대한 비용을 지불하는 것을 의미합니다.</block>
  <block id="0362604333fcf179ebf8b873f8f8c0ec" category="paragraph">다음 시나리오를 생각해 봅시다.</block>
  <block id="b401aa039e47ba98bfaca10532e40d08" category="paragraph">고객은 CPU와 메모리에 대해 5개의 호스트만 필요로 하지만 스토리지 요구 사항이 많으므로 스토리지 요구 사항을 충족하기 위해 12개의 호스트가 필요합니다. 이 요구사항은 스토리지를 증가하기만 하면 되는 추가 마력을 구매해야 하는 만큼 재무 규모를 넘어주는 결과를 제공합니다.</block>
  <block id="7c25e9d8a9748905f5d456e20a93b413" category="paragraph">클라우드 도입 및 마이그레이션을 계획할 때는 항상 최상의 접근 방식을 평가하고 총 투자 비용을 절감하는 가장 쉬운 방법을 찾는 것이 중요합니다. 모든 애플리케이션 마이그레이션의 가장 일반적이고 쉬운 방법은 가상 머신(VM) 또는 데이터 변환이 없는 재호스팅(리프트 및 변속이라고도 함)입니다. NetApp Cloud Volumes를 VMware SDDC(소프트웨어 정의 데이터 센터)와 함께 사용하는 동시에 vSAN을 보완하는 것은 쉬운 전환 옵션을 제공합니다.</block>
  <block id="506b02d257f89febd090ded6564e8c4f" category="summary">NetApp 솔루션의 자동화 기능에 대한 최신 추가 사항</block>
  <block id="3b1dbad34c6f708a2653d9c6ae15b15d" category="doc">솔루션 자동화의 새로운 기능</block>
  <block id="a90193527119bcbd79a1084d94ec3914" category="paragraph">NetApp 솔루션을 위한 최신 자동화 기능에 대한 개요</block>
  <block id="153fbde949ec10e69bae256a4114f480" category="cell">* 솔루션 자동화 시작하기 *</block>
  <block id="3d45b043c5518eca1e47fb4ba8a813da" category="inline-link-macro">RHEL/CentOS에서 CLI 배포를 위해 Ansible Control Node를 설정합니다</block>
  <block id="0d4c9e63678641d4ae0e23bd36684722" category="cell"><block ref="0d4c9e63678641d4ae0e23bd36684722" category="inline-link-macro-rx"></block></block>
  <block id="2afb5cc3404c6c8162722fd41895c2de" category="inline-link-macro">Ubuntu/Debian에서 CLI 배포를 위해 Ansible Control Node를 설정합니다</block>
  <block id="0f752948a660f9bbb5956c86d669a395" category="cell"><block ref="0f752948a660f9bbb5956c86d669a395" category="inline-link-macro-rx"></block></block>
  <block id="6b8c64be0bad88fb867c6576ac777b25" category="inline-link-macro">타워/AWX 배포용으로 Ansible 타워 또는 AWX를 설치합니다</block>
  <block id="b8c65aa5893cb554f17ec9c5b653c9bc" category="cell"><block ref="b8c65aa5893cb554f17ec9c5b653c9bc" category="inline-link-macro-rx"></block></block>
  <block id="e7760fa86ac312b359215e15113fde9b" category="cell">* 하이브리드 클라우드에서 Oracle 데이터베이스 인프라를 자동화합니다 *</block>
  <block id="e9dcec3e531a3cec5ee733f23baab91d" category="inline-link-macro">NFS 기반 ONTAP용 Oracle 19c의 자동 구축</block>
  <block id="e10944318a093524b44d6671144720e9" category="cell"><block ref="e10944318a093524b44d6671144720e9" category="inline-link-macro-rx"></block></block>
  <block id="c6f59500cff9fc154e284a0b9b18bb83" category="summary">NetApp 솔루션의 자동화 기능에 대해 설명하는 비디오 및 데모 시리즈</block>
  <block id="cff1a9d42f081481f7d374df8bcbb26b" category="doc">솔루션 자동화 비디오 및 데모</block>
  <block id="4e59e2d3d9f78c4e87a82b3cbcc7e1a3" category="paragraph">NetApp 솔루션의 자동화 기능에 대한 구체적인 기능을 소개하는 비디오 및 데모를 소개합니다.</block>
  <block id="9efcc0ad3c93b238cc0495e3c87b715f" category="inline-link-macro">Ansible을 사용하여 FlexPod에 Oracle 19c RAC 구축 자동화</block>
  <block id="9c4ada146a28af07eecc939b540c3541" category="list-text"><block ref="9c4ada146a28af07eecc939b540c3541" category="inline-link-macro-rx"></block></block>
  <block id="548bebbdb3ac596c6116cbd05e474fe0" category="summary">모든 퍼블릭 클라우드 공급자를 위한 엔터프라이즈 하이브리드 클라우드 솔루션을 설명하는 블로그 시리즈</block>
  <block id="b8136929c18b90d36d40eb475da80f06" category="doc">엔터프라이즈 하이브리드 클라우드 블로그</block>
  <block id="27f22a085d12c1434c2027f4d64f9418" category="paragraph">세 가지 주요 클라우드 공급자 모두를 대상으로 하는 엔터프라이즈 하이브리드 클라우드 솔루션의 특정 기능을 소개하는 블로그를 소개합니다.</block>
  <block id="8d7efa937e97b1a8187ff8f122d9732a" category="inline-link-macro">클라우드 기반 VMware 구축을 위한 스토리지 최적화</block>
  <block id="5a6bd3a9e0048284caf2b5f521d90959" category="list-text"><block ref="5a6bd3a9e0048284caf2b5f521d90959" category="inline-link-macro-rx"></block></block>
  <block id="00d07ce14f227693b9dabba2f52b53a5" category="inline-link-macro">NetApp 기반 클라우드 오퍼링을 사용하여 Azure VMware 솔루션을 시작하십시오</block>
  <block id="ac66988ead29ba5f4ed32ec3894527e7" category="list-text"><block ref="ac66988ead29ba5f4ed32ec3894527e7" category="inline-link-macro-rx"></block></block>
  <block id="6a0ecfbed3f66ec0b5d8989880431ad7" category="summary">데이터 보호 및 보안 솔루션 기능을 설명하는 블로그 시리즈</block>
  <block id="16be77be7dcecad552bca4efda1efcb1" category="doc">데이터 보호 및 보안 블로그</block>
  <block id="fdaef51553bfad628d1d8ee4cd314d79" category="paragraph">데이터 보호 및 보안 솔루션의 특정 기능을 강조하는 블로그의 개요</block>
  <block id="dca91c3343cc0ad062506cdd14eb7d41" category="summary">하이브리드 클라우드, 데스크탑 가상화 및 컨테이너 솔루션 자료에 대한 최신 추가 정보</block>
  <block id="120c02d2aa6cda1e3b75902fb4fc0b53" category="doc">하이브리드 클라우드, 데스크탑 가상화 및 컨테이너 솔루션의 새로운 기능</block>
  <block id="07e257430bade6bc5bce1c2170c6fc0d" category="paragraph">최신 하이브리드 클라우드, 데스크탑 가상화 및 컨테이너 솔루션 및 솔루션 자료 개요</block>
  <block id="c1e392a90896851b3319d6075402fd4d" category="cell">* 하이브리드/프라이빗 클라우드 *</block>
  <block id="526cee55e2936716b5481f8a933bd217" category="inline-link-macro">NetApp 및 VMware Tanzu Basic에서 VVOL을 사용하는 방법 1부</block>
  <block id="c2240101c5a3a188541ce87c59265df9" category="cell"><block ref="c2240101c5a3a188541ce87c59265df9" category="inline-link-macro-rx"></block></block>
  <block id="2e933c421900ce4ed68883bfdf00a487" category="inline-link-macro">NetApp 및 VMware Tanzu Basic에서 VVOL을 사용하는 방법, 2부</block>
  <block id="fe72963b1d3021a9f6d8ae34414601c3" category="cell"><block ref="fe72963b1d3021a9f6d8ae34414601c3" category="inline-link-macro-rx"></block></block>
  <block id="4c1c4ad5c7782eafb30ad4704dbf4419" category="inline-link-macro">NetApp 및 VMware Tanzu Basic에서 VVOL을 사용하는 방법, 3부</block>
  <block id="4d066173d8401c92a19650e99dcaae5d" category="cell"><block ref="4d066173d8401c92a19650e99dcaae5d" category="inline-link-macro-rx"></block></block>
  <block id="8ef4e9c7260e8d314760329e07c618ae" category="cell">* 가상화 *</block>
  <block id="2bdc87f51d413e6d2fa23dd26238501f" category="inline-link-macro">ONTAP용 VMware vSphere</block>
  <block id="1f23e5de73e650f12cbafec55d8a98cd" category="cell"><block ref="1f23e5de73e650f12cbafec55d8a98cd" category="inline-link-macro-rx"></block></block>
  <block id="236122c6ab4c764632437a76fa95e5c0" category="cell">* 데스크탑 가상화 *</block>
  <block id="4b47c65474ab7fae9b08ddf38d598971" category="inline-link-macro">NetApp VDS(가상 데스크톱 서비스)가 포함된 하이브리드 클라우드 VDI</block>
  <block id="dea91bec9e85387a496bb2c228fc7dc3" category="cell"><block ref="dea91bec9e85387a496bb2c228fc7dc3" category="inline-link-macro-rx"></block></block>
  <block id="1ebfe0d8e53e3f7f2c37e8b3835c2adf" category="cell">* 컨테이너 *</block>
  <block id="5df9589990c71ed42c69a8bcc053d0d4" category="inline-link-macro">비디오: NetApp Astra Control을 활용하여 사후 분석 및 애플리케이션 복원을 수행합니다</block>
  <block id="51d1589966ca772274944bc0cd6b15bc" category="cell"><block ref="51d1589966ca772274944bc0cd6b15bc" category="inline-link-macro-rx"></block></block>
  <block id="72feee9e055adc523c4c9ca3c1453409" category="inline-link-macro">비디오: Astra Control을 통해 CI/CD 파이프라인에서 데이터 보호</block>
  <block id="3bf54df2b09b6352059075c261817bd0" category="cell"><block ref="3bf54df2b09b6352059075c261817bd0" category="inline-link-macro-rx"></block></block>
  <block id="6be5bc354916244292cf704d8a451541" category="inline-link-macro">비디오: Astra Control Center를 사용한 워크로드 마이그레이션 - NetApp의 Red Hat OpenShift</block>
  <block id="b0fd8947f538fb2988e86d35bac6d6fa" category="cell"><block ref="b0fd8947f538fb2988e86d35bac6d6fa" category="inline-link-macro-rx"></block></block>
  <block id="306a916d056a0d0a4b898b9dca9692ee" category="inline-link-macro">Red Hat OpenShift 기반 NetApp Astra Control Center</block>
  <block id="20c49a9a4d903fa259d4f8820b3755d2" category="cell"><block ref="20c49a9a4d903fa259d4f8820b3755d2" category="inline-link-macro-rx"></block></block>
  <block id="c0a8420c339dd9d57d40448c30a749df" category="inline-link-macro">비디오: NetApp의 Astra Trident 및 SnapMirror-Red Hat OpenShift를 사용하여 워크로드 마이그레이션</block>
  <block id="a43d8fe0429e313d082e6919f1fd2b75" category="cell"><block ref="a43d8fe0429e313d082e6919f1fd2b75" category="inline-link-macro-rx"></block></block>
  <block id="4c37a5afd480a0042f69d7628cadd57d" category="inline-link-macro">NetApp OpenShift를 사용한 Kubernetes용 고급 클러스터 관리</block>
  <block id="119ad672b0d69ab3f968877b6ec83dd3" category="cell"><block ref="119ad672b0d69ab3f968877b6ec83dd3" category="inline-link-macro-rx"></block></block>
  <block id="65cd53ff19e601ea00bf9688be4dd86a" category="inline-link-macro">NetApp ONTAP 기반의 Red Hat OpenShift 가상화</block>
  <block id="ad1cf94aab71c9962e22037ed60d41e9" category="cell"><block ref="ad1cf94aab71c9962e22037ed60d41e9" category="inline-link-macro-rx"></block></block>
  <block id="762a14964ee1713d320b8beefaf55b17" category="inline-link-macro">비디오: OpenShift 가상화 설치 - NetApp과 함께 Red Hat OpenShift</block>
  <block id="5ac70ba9dc4ef90bfb3a829919c8044d" category="cell"><block ref="5ac70ba9dc4ef90bfb3a829919c8044d" category="inline-link-macro-rx"></block></block>
  <block id="aad993afc3c78a3a38ae471fa2ae1060" category="inline-link-macro">비디오: OpenShift 가상화를 통한 가상 머신 구축 - NetApp과 함께 Red Hat OpenShift</block>
  <block id="1c9dc04aa9e0e0aaf52a33af61d8d630" category="cell"><block ref="1c9dc04aa9e0e0aaf52a33af61d8d630" category="inline-link-macro-rx"></block></block>
  <block id="e6ba927c9d14295015e39be05cf54040" category="inline-link-macro">NetApp ONTAP 기반 Red Hat OpenShift의 멀티 테넌시</block>
  <block id="ab439bcac737f2565970fe2612976b75" category="cell"><block ref="ab439bcac737f2565970fe2612976b75" category="inline-link-macro-rx"></block></block>
  <block id="ad95c47343e102dc30ec33fa6f1ccc55" category="inline-link-macro">NetApp을 사용한 NVA-1160-Red Hat OpenShift</block>
  <block id="1043b5153afff839b84d714aa9127913" category="cell"><block ref="1043b5153afff839b84d714aa9127913" category="inline-link-macro-rx"></block></block>
  <block id="0fd00a19fb12bb899dfe7cefbcbbcb79" category="inline-link-macro">Red Hat OpenShift에 NetApp Trident 설치 – Docker의 'toomanyrequest' 문제를 해결하는 방법!</block>
  <block id="43e5d9153d1fc4a35be5f57189605919" category="cell"><block ref="43e5d9153d1fc4a35be5f57189605919" category="inline-link-macro-rx"></block></block>
  <block id="da38226e07ff21f147182bb08be38f6f" category="inline-link-macro">NetApp의 Anthos Bare Metal</block>
  <block id="ac1da2af455fc001ba8b58af0e62d151" category="cell"><block ref="ac1da2af455fc001ba8b58af0e62d151" category="inline-link-macro-rx"></block></block>
  <block id="7108e02acdfbc9a7cf66345731d3ec5e" category="summary">AI 및 최신 데이터 분석 솔루션 기능을 설명하는 블로그 시리즈</block>
  <block id="407c5c4d36c8f404212036765bd911ac" category="doc">AI 및 최신 데이터 분석 블로그</block>
  <block id="2aa8a49ee37d7496cf666062c18c3ad3" category="paragraph">AI 및 최신 데이터 분석 솔루션의 특정 기능을 소개하는 블로그를 소개합니다.</block>
  <block id="27f80f5fcc8cfd10fa4ffd9f6c3bc57e" category="section-title">인공 지능 블로그 시리즈</block>
  <block id="750b570f7c6cacf7b9f43c1c7919ad96" category="inline-link-macro">AI 블로그: thePub</block>
  <block id="183754618306c7f8d7df04f981d234f0" category="list-text"><block ref="183754618306c7f8d7df04f981d234f0" category="inline-link-macro-rx"></block></block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="summary">법적 고지 사항은 저작권 선언, 상표, 특허 등에 대한 액세스를 제공합니다.</block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">법적 고지</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">저작권</block>
  <block id="09e95b77ffe81fe465a83ba99efad5c8" category="paragraph"><block ref="09e95b77ffe81fe465a83ba99efad5c8" category="inline-link-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">상표</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp, NetApp 로고, NetApp 상표 페이지에 나열된 마크는 NetApp Inc.의 상표입니다. 기타 회사 및 제품 이름은 해당 소유자의 상표일 수 있습니다.</block>
  <block id="7aa531e9acfe2b98e34d2c92fe9846ff" category="paragraph"><block ref="7aa531e9acfe2b98e34d2c92fe9846ff" category="inline-link-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">특허</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">NetApp 소유 특허 목록은 다음 사이트에서 확인할 수 있습니다.</block>
  <block id="d7f1fbcf9ce4e42f705add574d262b2c" category="paragraph"><block ref="d7f1fbcf9ce4e42f705add574d262b2c" category="inline-link-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">개인 정보 보호 정책</block>
  <block id="fc248f74f5e36542f7f5627b8610e9a3" category="paragraph"><block ref="fc248f74f5e36542f7f5627b8610e9a3" category="inline-link-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">오픈 소스</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">통지 파일은 NetApp 소프트웨어에 사용된 타사의 저작권 및 라이센스에 대한 정보를 제공합니다.</block>
  <block id="c8d20ce0b6bb23d912f3368f706d5794" category="summary">NetApp 솔루션은 고객의 가장 중요한 비즈니스 요구사항을 지원하기 위해 NetApp 제품 및 서비스 포트폴리오를 강조하는 전략적 및 기술 역량 집합입니다.</block>
  <block id="fcf140abed196b8eba71c45f21312bce" category="doc">NetApp 솔루션</block>
  <block id="cb1501db8fac0fe0b1cc3b53200f0ab9" category="summary">비즈니스 응용 프로그램 및 엔터프라이즈 데이터베이스 솔루션 자료에 최신 내용이 추가되었습니다</block>
  <block id="54998e7855609864b7a05e49355662b5" category="doc">비즈니스 애플리케이션 및 엔터프라이즈 데이터베이스 솔루션의 새로운 기능</block>
  <block id="9de8e04d062d5eb8e2ff199783964174" category="paragraph">최신 비즈니스 응용 프로그램 및 엔터프라이즈 데이터베이스 솔루션 및 솔루션 자료 개요</block>
  <block id="4878d0f06c45c7f565e6545cccf18c88" category="inline-link-macro">SnapCenter를 사용한 Hybird 클라우드 데이터베이스 솔루션</block>
  <block id="a07f396f8180d71ad8372bd51f3800d7" category="cell">* 하이브리드 클라우드 데이터베이스 솔루션 *<block ref="642bb53d1747dfdf3e6f0ebcbb604cfe" category="inline-link-macro-rx"></block></block>
  <block id="2dc95f2080ad2dba9a9207db808106e5" category="cell">* Oracle 데이터베이스 *</block>
  <block id="14c4dbb7c61081eee1c499c4cf138c96" category="inline-link-macro">FC를 통해 Cisco UCS 및 NetApp AFF A800을 사용하는 FlexPod 데이터 센터에서 Oracle 19c RAC 데이터베이스</block>
  <block id="24743f8350683e7f1d7d5f6802de3aab" category="cell"><block ref="24743f8350683e7f1d7d5f6802de3aab" category="inline-link-macro-rx"></block></block>
  <block id="dcad2dec3906d4a902bdfb0b7093ce21" category="cell"><block ref="dcad2dec3906d4a902bdfb0b7093ce21" category="inline-link-macro-rx"></block></block>
  <block id="71e4dd221a9f0c3610e81f8ebab870ea" category="cell">* SAP HANA *</block>
  <block id="c55aef4f96cafe48d6e5cf37af33721b" category="inline-link-macro">SAP HANA B&amp;A, R with SnapCenter</block>
  <block id="59fbb2b8017dcaa261a32ed33941a3bd" category="cell"><block ref="41f97968c03372ffce726ec89c54fc9a" category="inline-link-macro-rx"></block></block>
  <block id="ffbfe314fcb0f0531b18b666e3f70bcc" category="inline-link-macro">FC SAN 기반 SAP HANA</block>
  <block id="8e7cb8af41001c3eeb84421bdf0bf30f" category="cell"><block ref="8e7cb8af41001c3eeb84421bdf0bf30f" category="inline-link-macro-rx"></block></block>
  <block id="03bd539868199e3d2eb12809418e0815" category="cell">* Microsoft SQL Server *</block>
  <block id="760b7d532df381143dc946fd59bf0b62" category="inline-link-macro">Azure NetApp Files 기반 SQL Server</block>
  <block id="5a6ed16cce1a08e1b3de84293a1c0a11" category="cell"><block ref="5a6ed16cce1a08e1b3de84293a1c0a11" category="inline-link-macro-rx"></block></block>
  <block id="9b849a5e6a46a992279087781315f191" category="inline-link-macro">Microsoft SQL Server 기반 SAP 애플리케이션</block>
  <block id="7dffec91055830f84efb7bc18ab4f86d" category="cell"><block ref="7dffec91055830f84efb7bc18ab4f86d" category="inline-link-macro-rx"></block></block>
  <block id="77c484629c9e9b5aed6fa32ebb0e7229" category="inline-link-macro">가상화된 인프라용 SolidFire ESDS 기반 SQL Server</block>
  <block id="cce65a4a66212b1b6a69449993338407" category="cell"><block ref="cce65a4a66212b1b6a69449993338407" category="inline-link-macro-rx"></block></block>
  <block id="91be6e42fe122f20831dcd474322dc82" category="inline-link-macro">SQL Server - NetApp HCI를 통한 데이터베이스 성능 보장</block>
  <block id="de2b8e7716b57342938375941b7e521a" category="cell"><block ref="de2b8e7716b57342938375941b7e521a" category="inline-link-macro-rx"></block></block>
  <block id="f3c961b3fcb2ae7229add932837c205a" category="summary">비즈니스 애플리케이션 및 엔터프라이즈 데이터베이스 솔루션 기능에 대해 설명하는 비디오 및 데모 시리즈</block>
  <block id="f7164629c6d69e9fc50c2435382e23c8" category="doc">비즈니스 애플리케이션 및 엔터프라이즈 데이터베이스 비디오 및 데모</block>
  <block id="9c8f0f2cea03121d5372f653983bb29b" category="paragraph">비즈니스 응용 프로그램 및 엔터프라이즈 데이터베이스 솔루션의 특정 기능을 중점적으로 설명하는 비디오 및 데모 개요</block>
  <block id="a0d2b6fe9ab0a7e386c4c21f70331226" category="section-title">사례 연구</block>
  <block id="33be49f7ebc56eb7d336a201f7ac0df6" category="inline-link-macro">Azure NetApp Files 기반 SAP</block>
  <block id="626865aeb52c00e03e8f0df7695c5a5c" category="list-text"><block ref="626865aeb52c00e03e8f0df7695c5a5c" category="inline-link-macro-rx"></block></block>
  <block id="e131204502a58630f2f72937238604c8" category="section-title">비디오/데모</block>
  <block id="e9194e819cadddfb8f6c5e69d11e366b" category="inline-link-macro">Oracle 데이터베이스용 NetApp 솔루션</block>
  <block id="2c389096a43e749160e32214cb4a3b89" category="list-text"><block ref="2c389096a43e749160e32214cb4a3b89" category="inline-link-macro-rx"></block></block>
  <block id="2b1dd692c0da980c4ec2ad9fd523c47d" category="inline-link-macro">Azure NetApp Files의 SQL 고가용성 클러스터</block>
  <block id="99945a626f3fb01dbeac75f40a6c2c8e" category="list-text"><block ref="99945a626f3fb01dbeac75f40a6c2c8e" category="inline-link-macro-rx"></block></block>
  <block id="bfd22ae6cd60e663ed70e43729a64b1a" category="summary">하이브리드 클라우드, 데스크탑 가상화 및 컨테이너 솔루션 기능을 설명하는 블로그 시리즈</block>
  <block id="0ffff76bcc7d5f89f6a352694b916dbd" category="doc">하이브리드 클라우드, 데스크톱 가상화 및 컨테이너 블로그 를 참조하십시오</block>
  <block id="0aef0d80b80eebee0590e019fffb3715" category="paragraph">하이브리드 클라우드, 데스크탑 가상화 및 컨테이너 솔루션의 특정 기능을 강조하는 블로그의 개요</block>
  <block id="95e5ff389c2796a171f904ad5b9322f6" category="list-text">NetApp 및 VMware Cloud Foundation(VCF)</block>
  <block id="81cd1d42ffdb75544144e24cf0f8dc54" category="inline-link-macro">1부: 시작하기</block>
  <block id="837bbffc16dc6e344470df1114a13c87" category="list-text"><block ref="837bbffc16dc6e344470df1114a13c87" category="inline-link-macro-rx"></block></block>
  <block id="0437c596200f9be8466a3200f5cf2438" category="inline-link-macro">2부: VCF 및 ONTAP 주 저장소</block>
  <block id="e361fc9a6477c5857207bca25b3d797f" category="list-text"><block ref="e361fc9a6477c5857207bca25b3d797f" category="inline-link-macro-rx"></block></block>
  <block id="14c9e898417d6b3caceb9c60335c4bb3" category="inline-link-macro">3부: VCF 및 Element Principal storage</block>
  <block id="aa37de763ea804c1fb3fe637fb6ee5ef" category="list-text"><block ref="aa37de763ea804c1fb3fe637fb6ee5ef" category="inline-link-macro-rx"></block></block>
  <block id="fbbcbe8b70235742e3e6aa656c7815d9" category="inline-link-macro">4부: VMware용 ONTAP 툴 및 보조 스토리지</block>
  <block id="de8f12d6d2f85119918d1bbb774d43c8" category="list-text"><block ref="de8f12d6d2f85119918d1bbb774d43c8" category="inline-link-macro-rx"></block></block>
  <block id="ec7f98a3714557d87968dc6a898f7912" category="inline-link-macro">ONTAP와 함께 VMware Tanzu를 사용하여 Kubernetes 여정을 가속화하십시오</block>
  <block id="32e124b0349f41e06bf1e03f11950665" category="list-text"><block ref="32e124b0349f41e06bf1e03f11950665" category="inline-link-macro-rx"></block></block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">가능하면 항상 ONTAP 툴을 사용하여 데이터 저장소와 볼륨을 프로비저닝하십시오. 이렇게 하면 볼륨, 접합 경로, LUN, igroup, 엑스포트 정책이 및 기타 설정은 호환되는 방식으로 구성됩니다.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">운영 모범 사례</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="section-title">데이터 저장소 및 프로토콜</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM은 SRA를 통해 어레이 기반 복제를 사용할 때 ONTAP 9를 통해 iSCSI, 파이버 채널 및 NFS 버전 3을 지원합니다. SRM은 기존 데이터 저장소 또는 VVOL 데이터 저장소를 사용하는 NFS 버전 4.1에 대한 어레이 기반 복제를 지원하지 않습니다.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">접속을 확인하려면 항상 대상 ONTAP 클러스터에서 DR 사이트의 새 테스트 데이터 저장소를 마운트하고 마운트 해제할 수 있는지 확인하십시오. 데이터 저장소 연결에 사용할 각 프로토콜을 테스트합니다. 모범 사례는 ONTAP 툴을 사용하여 테스트 데이터 저장소를 생성하는 것입니다. 이는 SRM의 지시에 따라 모든 데이터 저장소 자동화를 수행하기 때문입니다.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">SAN 프로토콜은 각 사이트에서 동종이어야 합니다. NFS와 SAN을 혼합할 수 있지만 SAN 프로토콜을 사이트 내에서 혼합하면 안 됩니다. 예를 들어 사이트 A에서는 FCP를, 사이트 B에서는 iSCSI를 사용할 수 있습니다 사이트 A에서 FCP와 iSCSI를 둘 다 사용해서는 안 됩니다 그 이유는 SRA가 복구 사이트에 혼합 igroup을 생성하지 않으며 SRM은 SRA에 제공된 이니시에이터 목록을 필터링하지 않기 때문입니다.</block>
  <block id="150f8d9d5018ff00285d9aa158451d7b" category="paragraph">이전 가이드에서는 LIF와 데이터 지역성을 만드는 것이 좋습니다. 다시 말해, 볼륨을 물리적으로 소유한 노드에 있는 LIF를 사용하여 데이터 저장소를 항상 마운트합니다. 이는 ONTAP 9의 최신 버전에서 더 이상 필요하지 않습니다. 가능할 때마다 그리고 클러스터 범위 자격 증명이 제공되는 경우 ONTAP 툴은 여전히 데이터에 대한 로컬 LIF의 로드 밸런싱을 수행하지만, 고가용성과 성능이 반드시 필요한 것은 아닙니다.</block>
  <block id="ef6e8713285283721507f92e3c3ec674" category="paragraph">자동 크기 조정이 필요한 비상 용량을 충분히 제공하지 못하는 경우 공간 부족 상태에 있는 경우 가동 시간을 유지하기 위해 스냅샷 복사본을 자동으로 제거하도록 NetApp ONTAP 9를 구성할 수 있습니다. 이 기능의 기본 설정은 SnapMirror에서 만든 스냅샷 복사본을 자동으로 삭제하지 않습니다. SnapMirror Snapshot 복사본이 삭제된 경우 NetApp SRA는 영향을 받는 볼륨의 복제를 역으로 재동기화할 수 없습니다. ONTAP에서 SnapMirror 스냅샷 복사본을 삭제하지 않도록 하려면 스냅샷 자동 삭제 기능을 시험 사용 으로 구성하십시오.</block>
  <block id="774a065cb3548cc61fb0ec3bc1494fbe" category="inline-link">ONTAP 9 문서 센터</block>
  <block id="a4f47f677f45e1e7075186d98e4f3ec1" category="paragraph">SAN 데이터 저장소가 포함된 볼륨의 경우 볼륨 자동 크기 조정을 '확대'로 설정하고 NFS 데이터 저장소의 경우 'grow_shrink'로 설정해야 합니다. 을 참조하십시오<block ref="ee2474fa4563985f2f3ebe16d4e1ab3a" category="inline-link-rx"></block> 특정 구문입니다.</block>
  <block id="e6955db66b8dc4aee170ebdb0b560249" category="section-title">SPBM 및 VVol</block>
  <block id="3077a08ffed60acebf18d37874130d44" category="paragraph">SRM 8.3부터는 VVOL 데이터 저장소를 사용한 VM 보호가 지원됩니다. 다음 스크린샷과 같이 ONTAP 도구 설정 메뉴에서 VVOL 복제가 활성화된 경우 VASA Provider가 SnapMirror 스케줄을 VM 스토리지 정책에 표시합니다.</block>
  <block id="399c1894baf71c0529aa0fba66ea18fb" category="paragraph">다음 예에서는 VVOL 복제 기능을 보여줍니다.</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">다음 스크린샷에서는 VM 스토리지 정책 생성 마법사에 표시되는 SnapMirror 일정의 예를 보여 줍니다.</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">ONTAP VASA Provider는 이기종 스토리지로의 페일오버를 지원합니다. 예를 들어, 시스템은 에지 위치의 ONTAP Select에서 코어 데이터 센터의 AFF 시스템으로 페일오버할 수 있습니다. 스토리지의 유사성에 관계없이 항상 복제 가능 VM 스토리지 정책에 대한 스토리지 정책 매핑 및 역매핑을 구성하여 복구 사이트에서 제공되는 서비스가 기대 사항 및 요구 사항을 충족하는지 확인해야 합니다. 다음 스크린샷에서는 샘플 정책 매핑을 보여 줍니다.</block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">VVOL 데이터 저장소의 복제된 볼륨을 생성합니다</block>
  <block id="18231879821321e0aed7de84fe876766" category="paragraph">이전 VVOL 데이터 저장소와 달리 복제된 VVOL 데이터 저장소는 복제를 활성화한 상태로 처음부터 생성해야 하며 SnapMirror 관계가 있는 ONTAP 시스템에서 미리 생성된 볼륨을 사용해야 합니다. 이를 위해서는 클러스터 피어링 및 SVM 피어링 같은 요소를 사전에 구성해야 합니다. 이러한 작업은 ONTAP 관리자가 수행해야 합니다. 따라서 여러 사이트에서 ONTAP 시스템을 관리하는 사람과 vSphere 운영을 주로 담당하는 사이트 간에 책임을 엄격하게 분리할 수 있습니다.</block>
  <block id="0a8c8293003bf411817ef3cedf18a2a9" category="paragraph">vSphere 관리자 대신 새로운 요구 사항이 적용됩니다. 볼륨은 ONTAP 도구의 범위를 벗어나 생성되므로 정기적으로 예약된 재검색 기간까지 ONTAP 관리자가 수행한 변경 사항을 인식하지 못합니다. 이러한 이유로 VVOL과 함께 사용할 볼륨 또는 SnapMirror 관계를 만들 때마다 항상 재검색을 실행하는 것이 모범 사례입니다. 다음 스크린샷과 같이 호스트 또는 클러스터를 마우스 오른쪽 버튼으로 클릭하고 NetApp ONTAP tools &gt; Update Host and Storage Data를 선택하면 됩니다.</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">VVOL 및 SRM의 경우 한 가지 주의해야 합니다. 보호 VM과 보호되지 않은 VM을 동일한 VVOL 데이터 저장소에 혼합하지 마십시오. 그 이유는 SRM을 사용하여 DR 사이트로 페일오버할 때 보호 그룹에 속한 VM만 DR에서 온라인 상태로 전환되기 때문입니다. 따라서 SnapMirror를 DR에서 운영 환경으로 다시 되돌릴 때 페일오버되지 않은 VM을 덮어쓰거나 중요한 데이터를 포함할 수 있습니다.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">스토리지 쌍 정보</block>
  <block id="6dd3f3008fe81f402905b00c8dca007c" category="paragraph">각 스토리지 쌍에 대해 스토리지 관리자가 생성됩니다. SRM 및 ONTAP 툴을 사용하면 클러스터 자격 증명을 사용해도 SVM의 범위에서 각 어레이 페어링을 수행할 수 있습니다. 따라서 각 테넌트가 관리하기 위해 할당된 SVM에 따라 테넌트 간에 DR 워크플로우를 분할할 수 있습니다. 따라서 특정 클러스터에 대해 여러 어레이 관리자를 생성할 수 있으며 이는 본질적으로 비대칭입니다. 서로 다른 ONTAP 9 클러스터 간에 팬아웃 또는 팬할 수 있습니다. 예를 들어, 클러스터 1의 SVM-A 및 SVM-B를 클러스터 2의 SVM-C, 클러스터 3의 SVM-D 또는 그 반대로 복제할 수 있습니다.</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">SRM에서 어레이 쌍을 구성할 때는 항상 ONTAP 툴에 추가한 것과 같은 방법으로 SRM에 어레이 쌍을 추가해야 합니다. 즉, 이들은 동일한 사용자 이름, 암호 및 관리 LIF를 사용해야 합니다. 이 요구 사항은 SRA가 어레이와 제대로 통신하도록 보장합니다. 다음 스크린샷은 ONTAP 툴에 클러스터가 표시되는 방식과 이를 어레이 관리자에 추가하는 방법을 보여 줍니다.</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">복제 그룹 정보</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">복제 그룹에는 함께 복구되는 가상 머신의 논리적 컬렉션이 포함됩니다. ONTAP 툴 VASA Provider는 자동으로 복제 그룹을 생성합니다. ONTAP SnapMirror 복제는 볼륨 레벨에서 수행되기 때문에 볼륨의 모든 VM이 동일한 복제 그룹에 속해 있습니다.</block>
  <block id="b57ec021fce4e5261ba61df6f0c013af" category="paragraph">복제 그룹과 FlexVol 볼륨 간에 VM을 배포하는 방법은 여러 가지 요소를 고려해야 합니다. 같은 볼륨에서 유사한 VM을 그룹화하면 집계 수준 중복 제거 기능이 없는 이전 ONTAP 시스템에서 스토리지 효율성이 향상되지만 그룹화는 볼륨 크기를 증가시키고 볼륨 I/O 동시성을 줄입니다. 최신 ONTAP 시스템에서는 동일한 애그리게이트에서 FlexVol 볼륨 전체에 VM을 분산하여 애그리게이트 레벨의 중복제거를 활용하고 여러 볼륨 간에 I/O 병렬 처리를 더 효율적으로 수행할 수 있습니다. 아래에 설명된 보호 그룹에 여러 복제 그룹이 포함될 수 있으므로 볼륨에서 VM을 함께 복구할 수 있습니다. 이 레이아웃의 단점은 볼륨 SnapMirror에서는 애그리게이트 중복제거가 적용되지 않으므로 블록을 여러 번 유선으로 전송할 수 있다는 것입니다.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">복제 그룹에 대한 마지막 고려 사항은 각 그룹이 기본적으로 논리적 정합성 보장 그룹이라는 점입니다(SRM 정합성 보장 그룹과 혼동하지 마십시오). 볼륨의 모든 VM이 동일한 스냅샷을 사용하여 함께 전송되기 때문입니다. 따라서 VM이 서로 일치해야 하는 경우 동일한 FlexVol에 VM을 저장하는 것이 좋습니다.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">보호 그룹 정보</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">보호 그룹은 보호 사이트에서 함께 복구되는 그룹으로 VM 및 데이터 저장소를 정의합니다. 보호 사이트는 정상적인 정상 상태 작업 중에 보호 그룹에 구성된 VM이 존재하는 곳입니다. SRM이 보호 그룹에 대해 여러 스토리지 관리자를 표시할 수 있지만 보호 그룹은 여러 스토리지 관리자를 포괄할 수 없습니다. 따라서 서로 다른 SVM의 데이터 저장소에 VM 파일을 확장해서는 안 됩니다.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">복구 계획에 대해 설명합니다</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">복구 계획은 동일한 프로세스에서 복구할 보호 그룹을 정의합니다. 동일한 복구 계획에서 여러 보호 그룹을 구성할 수 있습니다. 또한 복구 계획 실행을 위한 추가 옵션을 사용하기 위해 단일 보호 그룹을 여러 복구 계획에 포함할 수 있습니다.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">복구 계획을 사용하면 SRM 관리자가 우선 순위 그룹에 VM을 1(가장 높음)에서 5(가장 낮음)까지 할당하고 3(중간)을 기본값으로 지정하여 복구 워크플로를 정의할 수 있습니다. 우선 순위 그룹 내에서 VM을 종속성에 맞게 구성할 수 있습니다.</block>
  <block id="6d72567442b1f361e3c0e89cbc7dfd6a" category="paragraph">예를 들어, 데이터베이스에 Microsoft SQL Server를 사용하는 Tier-1 비즈니스 크리티컬 애플리케이션을 보유하고 있을 수 있습니다. 따라서 우선 순위 그룹 1에 VM을 배치하기로 결정합니다. 우선 순위 그룹 1 내에서 서비스를 가져오기 위한 주문 계획을 시작합니다. Microsoft SQL Server 전에 Microsoft Windows 도메인 컨트롤러가 부팅되기를 원할 것입니다. 이 경우 응용 프로그램 서버 이전에 온라인 상태가 되어야 합니다. 이러한 모든 VM을 우선 순위 그룹에 추가한 다음 종속성을 설정합니다. 종속성은 지정된 우선 순위 그룹 내에서만 적용되기 때문입니다.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp은 애플리케이션 팀과 협력하여 페일오버 시나리오에 필요한 운영 순서를 파악하고 그에 따라 복구 계획을 수립하는 것이 좋습니다.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">테스트 대체 작동</block>
  <block id="2772828493452c4a2ff21f8b2b66a1a7" category="paragraph">모범 사례로서, 보호된 VM 스토리지의 구성을 변경할 때마다 항상 테스트 페일오버를 수행하십시오. 이렇게 하면 재해가 발생할 경우 Site Recovery Manager가 예상 RTO 목표 내에서 서비스를 복구할 수 있다는 것을 신뢰할 수 있습니다.</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">또한, 특히 VM 스토리지를 재구성한 후에는 게스트 내 애플리케이션 기능을 확인하는 것이 좋습니다.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">테스트 복구 작업이 수행되면 VM에 대한 전용 테스트 버블 네트워크가 ESXi 호스트에 생성됩니다. 그러나 이 네트워크는 물리적 네트워크 어댑터에 자동으로 연결되지 않으므로 ESXi 호스트 간에 연결을 제공하지 않습니다. DR 테스트 중에 서로 다른 ESXi 호스트에서 실행 중인 VM 간의 통신을 허용하기 위해 DR 사이트의 ESXi 호스트 간에 물리적 전용 네트워크가 생성됩니다. 테스트 네트워크가 전용인지 확인하기 위해 테스트 버블 네트워크를 물리적으로 또는 VLAN 또는 VLAN 태깅을 사용하여 분리할 수 있습니다. VM이 복구될 때 실제 운영 시스템과 충돌할 수 있는 IP 주소를 사용하여 운영 네트워크에 배치할 수 없으므로 이 네트워크를 운영 네트워크와 분리해야 합니다. SRM에서 복구 계획을 생성할 때 생성된 테스트 네트워크를 테스트 중에 VM을 연결할 전용 네트워크로 선택할 수 있습니다.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">테스트를 검증하고 더 이상 필요하지 않은 후에는 정리 작업을 수행합니다. 정리 작업을 실행하면 보호된 VM이 초기 상태로 돌아가고 복구 계획이 준비 상태로 재설정됩니다.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">페일오버 고려 사항</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">이 가이드에 언급된 작업 순서 외에 사이트 장애 조치 시 몇 가지 다른 고려 사항이 있습니다.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">사이트 간 네트워크 차이는 문제가 될 수 있습니다. 일부 환경에서는 운영 사이트와 DR 사이트 모두에서 동일한 네트워크 IP 주소를 사용할 수 있습니다. 이러한 기능을 확장 가상 LAN(VLAN) 또는 확장 네트워크 설정이라고 합니다. 다른 환경에서는 DR 사이트와 관련하여 운영 사이트에서 서로 다른 네트워크 IP 주소(예: VLAN)를 사용해야 할 수 있습니다.</block>
  <block id="1b41638d2115765dc12f82d77ce70138" category="paragraph">VMware는 이 문제를 해결할 수 있는 여러 가지 방법을 제공합니다. VMware NSX-T Data Center와 같은 네트워크 가상화 기술은 운영 환경의 계층 2에서 계층 7까지 전체 네트워킹 스택을 추상화하여 보다 휴대성이 뛰어난 솔루션을 제공합니다. SRM에서 NSX-T 옵션에 대한 자세한 내용을 읽을 수 있습니다<block ref="99d78d594865360c3d4b527bf0a2a7f6" category="inline-link-rx"></block>.</block>
  <block id="09a74136e56a63c5aba38b89802d9080" category="paragraph">또한 SRM은 VM이 복구될 때 VM의 네트워크 구성을 변경할 수 있는 기능을 제공합니다. 이 재구성에는 IP 주소, 게이트웨이 주소 및 DNS 서버 설정과 같은 설정이 포함됩니다. 복구 시 개별 VM에 적용되는 다양한 네트워크 설정을 복구 계획에 있는 VM의 속성 설정에서 지정할 수 있습니다.</block>
  <block id="99f0a91111e8acb2462e8df5ecf0ab8f" category="paragraph">복구 계획에서 각 VM의 속성을 편집하지 않고도 여러 VM에 서로 다른 네트워크 설정을 적용하도록 SRM을 구성하려면 VMware에서 DR-IP-customizer라는 도구를 제공합니다. 이 유틸리티를 사용하는 방법에 대한 자세한 내용은 VMware 설명서를 참조하십시오<block ref="b959814092e3e6cdc8d22e768887e618" category="inline-link-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">재보호</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">복구 후에는 복구 사이트가 새 운영 사이트가 됩니다. 복구 작업이 SnapMirror 복제를 중단했기 때문에 새 프로덕션 사이트는 이후의 재해로부터 보호되지 않습니다. 모범 사례는 복구 후 즉시 새 프로덕션 사이트를 다른 사이트로 보호하는 것입니다. 원래 운영 사이트가 작동 중인 경우 VMware 관리자는 원래 운영 사이트를 새 복구 사이트로 사용하여 새 운영 사이트를 보호할 수 있으므로 보호 방향을 효과적으로 바꿀 수 있습니다. 재보호는 비치명적인 오류에서만 사용할 수 있습니다. 따라서 원래 vCenter Server, ESXi Server, SRM Server 및 해당 데이터베이스를 최종적으로 복구할 수 있어야 합니다. 사용할 수 없는 경우 새 보호 그룹과 새 복구 계획을 생성해야 합니다.</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">장애 복구</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">장애 복구 작업은 기본적으로 이전과 다른 방식으로 장애 조치입니다. 모범 사례로서, 원래 사이트가 장애 복구를 시도하기 전에 허용 가능한 수준의 기능으로 복구되었는지 또는 다시 말해 원래 사이트로 장애 조치를 수행하는 것이 좋습니다. 원래 사이트가 여전히 손상된 경우 장애가 충분히 해결될 때까지 페일백을 지연해야 합니다.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">또 다른 장애 복구 모범 사례는 재보호 완료 후 그리고 최종 장애 복구를 수행하기 전에 항상 테스트 장애 조치를 수행하는 것입니다. 이렇게 하면 원래 사이트에 있는 시스템이 작업을 완료할 수 있는지 확인합니다.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">원래 사이트를 다시 보호합니다</block>
  <block id="2a0c13d7b927063987bf931a141f2662" category="paragraph">페일백 후, 모든 이해 관계자(stake 보유자)에게 해당 서비스가 정상 상태로 복구되었는지 확인한 후 다시 재보호를 실행해야 합니다.</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">페일백 후 재보호를 실행하면 기본적으로 환경이 원래 상태로 전환되며, 이때 SnapMirror 복제가 운영 사이트에서 복구 사이트로 다시 실행됩니다.</block>
  <block id="8ce83a5c4c3183c4e25f0d8d7b657ffc" category="summary">이 페이지에서는 VMware vSphere 환경에서 NFS 데이터 저장소를 지원합니다.</block>
  <block id="3769193a46f06731838a6d904cf1da37" category="doc">ONTAP를 사용한 vSphere 기존 파일 스토리지 용량 할당</block>
  <block id="8d3005420a2cb4cc915402d9c5604538" category="paragraph">VMware vSphere는 다음 NFS 프로토콜을 지원하며 두 프로토콜 모두 ONTAP를 지원합니다.</block>
  <block id="78aa97ac78d1291969b5893edcfe448a" category="inline-link-macro">NFS 버전 3</block>
  <block id="fb110cc4ad992a0846c0eaea7fbf2d94" category="list-text"><block ref="fb110cc4ad992a0846c0eaea7fbf2d94" category="inline-link-macro-rx"></block></block>
  <block id="2d6affbd5ec6eb1f6009383ca5ba9b2b" category="inline-link-macro">NFS 버전 4.1</block>
  <block id="3f65d9416139ab7c1ff75966bccf6f7d" category="list-text"><block ref="3f65d9416139ab7c1ff75966bccf6f7d" category="inline-link-macro-rx"></block></block>
  <block id="fc5929c224818a87a89047d2813dd2c5" category="inline-link-macro">이 비교 내용은 NFS 클라이언트 버전입니다</block>
  <block id="ce51dd3c15b8a6638d0c212b990ae643" category="paragraph">올바른 vSphere NFS 버전을 선택하는 데 도움이 필요한 경우 을(를) 확인하십시오 <block ref="8055fbd4933fc4c8b583fa212ff14ff2" category="inline-link-macro-rx"></block>.</block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">vSphere를 사용하면 엔터프라이즈급 NFS 스토리지를 사용하여 ESXi 클러스터의 모든 노드에 대한 데이터 저장소에 대한 동시 액세스를 제공할 수 있습니다. 데이터 저장소 섹션에서 언급한 것처럼, NFS를 vSphere와 함께 사용할 경우 사용 편의성과 스토리지 효율성 가시성의 이점이 있습니다.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">vSphere와 함께 ONTAP NFS를 사용할 때는 다음과 같은 Best Practice를 따르는 것이 좋습니다.</block>
  <block id="265e673c00294cf97a90c3b0d4fcb076" category="list-text">ONTAP 클러스터의 각 노드에서 각 SVM에 대해 단일 논리 인터페이스(LIF)를 사용합니다. 데이터 저장소당 LIF의 과거 권장사항은 더 이상 필요하지 않습니다. 직접 액세스(LIF 및 데이터 저장소 같은 노드의 경우)가 가장 좋기는 하지만, 성능 영향은 일반적으로 최소(마이크로초)이기 때문에 간접 액세스에 대해 걱정할 필요가 없습니다.</block>
  <block id="83deede0d0158f0f2469080b6208e88a" category="list-text">VMware는 VMware Infrastructure 3 이후 NFSv3을 지원했습니다. vSphere 6.0은 NFSv4.1에 대한 지원을 추가하여 Kerberos 보안과 같은 일부 고급 기능을 지원합니다. NFSv3에서는 클라이언트측 잠금을 사용하는 경우 NFSv4.1은 서버 측 잠금을 사용합니다. ONTAP 볼륨은 두 프로토콜을 통해 내보낼 수 있지만 ESXi는 하나의 프로토콜을 통해서만 마운트할 수 있습니다. 이 단일 프로토콜 마운트는 다른 ESXi 호스트가 다른 버전을 통해 동일한 데이터 저장소를 마운트하는 것을 배제하지 않습니다. 모든 호스트가 동일한 버전과 동일한 잠금 스타일을 사용하도록 마운트할 때 사용할 프로토콜 버전을 지정해야 합니다. 호스트 간에 NFS 버전을 혼합하지 마십시오. 가능한 경우 호스트 프로필을 사용하여 규정 준수 여부를 확인하십시오.</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">NFSv3과 NFSv4.1 간에는 자동 데이터 저장소가 변환되지 않으므로 새로운 NFSv4.1 데이터 저장소를 생성하고 Storage vMotion을 사용하여 VM을 새 데이터 저장소로 마이그레이션합니다.</block>
  <block id="a9577e779ab70bdd45392b1e0125cc77" category="list-text">이 보고서가 작성된 시점에서 NetApp은 NFSv4.1 데이터 저장소 및 스토리지 장애 복구와 관련된 문제를 해결하기 위해 VMware와 계속 협력하고 있습니다. NetApp은 이러한 문제를 곧 해결할 것으로 기대합니다.</block>
  <block id="04826f858f8ad9c66b9d805ca9ff88a3" category="list-text">NFS 내보내기 정책은 vSphere 호스트의 액세스를 제어하는 데 사용됩니다. 여러 볼륨(데이터 저장소)에 하나의 정책을 사용할 수 있습니다. NFSv3에서 ESXi는 sys(UNIX) 보안 스타일을 사용하며 VM을 실행하려면 루트 마운트 옵션이 필요합니다. ONTAP에서 이 옵션을 수퍼 유저라고 하며, 수퍼유저 옵션을 사용할 때 익명 사용자 ID를 지정할 필요가 없습니다. '-anon' 및 '-allow-suid'에 대해 서로 다른 값을 갖는 엑스포트 정책 규칙은 ONTAP 툴에서 SVM 검색 문제를 유발할 수 있습니다. 샘플 정책은 다음과 같습니다.</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">액세스 프로토콜:NFS3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">클라이언트 일치 사양: 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">ro 액세스 규칙: sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">rw 액세스 규칙: sys</block>
  <block id="0fd74b9f6a61e12b4a204b3489bd05a9" category="list-text">익명 UID:</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">슈퍼유저: sys</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">VMware VAAI용 NetApp NFS 플러그인을 사용하는 경우 엑스포트 정책 규칙을 생성하거나 수정할 때 프로토콜을 NFS로 설정해야 합니다. VAAI 복제 오프로드가 작동하려면 NFSv4 프로토콜이 필요하며, 프로토콜을 "NFS"로 지정하면 NFSv3 버전과 NFSv4 버전이 모두 자동으로 포함됩니다.</block>
  <block id="44e8816851b6d24723bf0e06c3b8b40d" category="list-text">NFS 데이터 저장소 볼륨은 SVM의 루트 볼륨에서 접합되므로 ESXi에서 루트 볼륨에 액세스하여 데이터 저장소 볼륨을 탐색하고 마운트해야 합니다. 루트 볼륨과 데이터 저장소 볼륨의 연결이 중첩된 다른 볼륨에 대한 내보내기 정책에는 읽기 전용 액세스를 허용하는 ESXi 서버에 대한 규칙 또는 규칙이 포함되어야 합니다. 다음은 VAAI 플러그인을 사용하는 루트 볼륨에 대한 샘플 정책입니다.</block>
  <block id="88b77eec23ea926d7dac5b6ec36713d2" category="list-text">액세스 프로토콜. NFS(NFS3 및 nfs4 모두 포함)</block>
  <block id="2e5d116b123742b0c1f9b9266e3d45e4" category="list-text">클라이언트 일치 사양. 192.168.42.21</block>
  <block id="e79bd23a286e2e109f901ac7b9fc1052" category="list-text">ro 액세스 규칙. 시스템</block>
  <block id="6854a3cd4d70ef13145d55305c745f1c" category="list-text">RW 액세스 규칙. 사용 안 함(루트 볼륨에 대한 최상의 보안)</block>
  <block id="629cac79e5ae376b5235b5cb87c8c03d" category="list-text">익명 UID.</block>
  <block id="e76eb6f8b3ceafc6b70386efb46a8295" category="list-text">고급 사용자. Sys(VAAI를 사용하는 루트 볼륨에도 필요)</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">VMware vSphere용 ONTAP 툴 사용(가장 중요한 모범 사례):</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">VMware vSphere용 ONTAP 툴을 사용하면 엑스포트 정책의 관리를 자동으로 간소화할 수 있으므로 데이터 저장소를 프로비저닝할 수 있습니다.</block>
  <block id="55cf2206291fced620eed577cb8c8a42" category="list-text">플러그인을 사용하여 VMware 클러스터용 데이터 저장소를 생성할 때 단일 ESX Server가 아닌 클러스터를 선택합니다. 이 옵션을 선택하면 데이터 저장소가 클러스터의 모든 호스트에 자동으로 마운트됩니다.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">플러그인 마운트 기능을 사용하여 기존 데이터 저장소를 새 서버에 적용합니다.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">VMware vSphere용 ONTAP 툴을 사용하지 않는 경우 모든 서버 또는 추가 액세스 제어가 필요한 각 서버 클러스터에 대해 단일 엑스포트 정책을 사용하십시오.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">ONTAP는 접합을 사용하여 트리에서 볼륨을 정렬하는 유연한 볼륨 네임스페이스 구조를 제공하지만, 이 접근 방식에는 vSphere의 가치가 없습니다. 스토리지의 네임스페이스 계층에 관계없이 데이터 저장소의 루트에 각 VM에 대한 디렉토리를 생성합니다. 따라서 가장 좋은 방법은 SVM의 루트 볼륨에서 vSphere의 볼륨에 대한 접합 경로를 마운트하는 것입니다. 이것이 바로 VMware vSphere용 ONTAP 툴이 데이터 저장소를 프로비저닝하는 방법입니다. 중첩된 연결 경로가 없다는 것은 루트 볼륨 이외의 볼륨에 종속되지 않으며 볼륨을 오프라인으로 전환하거나 의도적으로 파괴하더라도 다른 볼륨에 대한 경로에 영향을 주지 않는다는 것을 의미합니다.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">NFS 데이터 저장소의 NTFS 파티션에 4K 블록 크기가 적합합니다. 다음 그림에서는 vSphere 호스트에서 ONTAP NFS 데이터 저장소로의 접속을 보여 줍니다.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">다음 표에는 NFS 버전 및 지원되는 기능이 나와 있습니다.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">vSphere 기능</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">vMotion 및 Storage vMotion입니다</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">예</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">내결함성</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">호스트 프로파일</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">Storage DRS를 참조하십시오</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">아니요</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">스토리지 I/O 제어</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">가상 볼륨</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">하드웨어 가속(VAAI)</block>
  <block id="aa32fdb70496d9a7395ef0d3ccb1c986" category="cell">예(vSphere 6.5 이상, NetApp VAAI 플러그인 1.1.2)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Kerberos 인증</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">예(AES, krb5i를 지원하도록 vSphere 6.5 이상에서 향상)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">다중 경로 지원</block>
  <block id="4cdf980fd6cee432c76402bb142269e9" category="cell">아니요(ESXi 6.5 이상은 세션 트렁킹을 통해 지원되며 ONTAP는 pNFS를 통해 지원)</block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP 스토리지 솔루션을 구축하는 모범 사례를 설명합니다.</block>
  <block id="1e6584aafa5ae98aebb88d3ddecdaae5" category="doc">vSphere 관리자를 위한 ONTAP 소개</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">ONTAP for vSphere를 선택해야 하는 이유</block>
  <block id="135b7f440129fbbacbc948adfb10ccec" category="paragraph">NetApp ONTAP는 스토리지 및 데이터 관리 운영을 간소화하고 사내 또는 클라우드에 관계없이 VMware 환경을 분명하게 보완합니다. 수많은 고객들이 vSphere 구축을 위해 ONTAP를 스토리지 솔루션으로 선택한 이유로는 NetApp의 동급 최고의 데이터 보호, 스토리지 효율성 혁신, SAN 기반 및 NAS 기반 VMware 아키텍처 모두에서 뛰어난 성능이 있습니다.</block>
  <block id="f93e431aaf745d4b5e4ecbd6c005b564" category="paragraph">NetApp은 가상화 환경 관리와 관련된 고유한 당면 과제를 해결하는 고객을 지원하기 위해 다양한 VMware 제품의 수많은 VMware 플러그인, 검증 및 자격을 제공합니다. NetApp은 VMware가 가상화를 위해 수행하는 스토리지 및 데이터 관리를 위해 하므로 고객이 물리적 스토리지 관리보다 핵심 역량에 집중할 수 있습니다. VMware와 NetApp은 20년에 가까운 파트너 관계를 유지하고 있으며, VMware Cloud Foundation 및 Tanzu와 같은 새로운 기술이 등장하면서 vSphere의 기반을 지속적으로 지원하는 등 고객 가치를 지속해서 개선하고 있습니다.</block>
  <block id="b4e56252f38c98dde71bd489a93805fc" category="paragraph">고객이 중요하게 고려하는 요소는 다음과 같습니다.</block>
  <block id="d6f750861d7ae27706ca32ed1f4c1ac8" category="list-text">* 유니파이드 스토리지 *</block>
  <block id="04d737333774adefb9817d0115bab79b" category="list-text">* 스토리지 효율성 *</block>
  <block id="c44a0be5f0db0511994f2f8e76afeb25" category="list-text">* 가상 볼륨 및 스토리지 정책 기반 관리 *</block>
  <block id="d78a5fe569360bb327d51dd5060d723c" category="list-text">* 하이브리드 클라우드 *</block>
  <block id="45649dc755190fc40be0b7e38ec84851" category="paragraph">지원되는 NetApp 및 VMware 솔루션에 대한 자세한 내용은 다음 리소스를 참조하십시오.</block>
  <block id="ec1bd76731eb238fa601fb03391f78d4" category="inline-link">NetApp 상호 운용성 매트릭스 툴</block>
  <block id="d46e58d91be6ffba761ab9bd05a46fc5" category="list-text"><block ref="b47ad5992ee82e05d51ff22d87ae20c3" category="inline-link-rx"></block> (IMT). IMT에는 FC/FCoE, iSCSI, NFS 및 CIFS 구성을 구축하는 데 사용할 수 있는 검증된 구성 요소와 버전이 정의되어 있습니다.</block>
  <block id="8034c6a17370dafb5b3f6f5add755c62" category="inline-link">VMware 호환성 가이드 를 참조하십시오</block>
  <block id="f0c67c4d38f07e6eb4bead0202260ddb" category="list-text"><block ref="a9846c61dcf62d503a7738adf47f11be" category="inline-link-rx"></block>. VMware 호환성 가이드 에는 VMware Infrastructure 및 소프트웨어 제품과의 시스템, I/O, 스토리지/SAN 및 백업 호환성 목록이 나와 있습니다</block>
  <block id="0f0b69f9725d17d0a8d3ceebcf33f72f" category="inline-link">VMware용 NetApp ONTAP 툴</block>
  <block id="2be6bbf4ea543b07ab3b9a218eb509cc" category="list-text"><block ref="d1284fbca35bc1b47ead37f18b1c3ba2" category="inline-link-rx"></block>. VMware vSphere용 ONTAP 툴은 VSC, VASA 공급자, SRA(스토리지 복제 어댑터) 확장을 포함한 단일 vCenter Server 플러그인입니다.</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">NetApp ONTAP는 2002년 현대적인 데이터 센터에 도입된 이후 VMware vSphere 환경을 위한 업계 최고의 스토리지 솔루션이며, 비용을 절감하는 동시에 관리를 단순화하는 혁신적인 기능을 지속적으로 추가하고 있습니다.</block>
  <block id="1fdf67ffe178876efb8b8cacfb0f052b" category="doc">TR-4900: NetApp ONTAP 9를 사용하는 VMware 사이트 복구 관리자</block>
  <block id="cc6ab3d11d2dc330a573866f7c9f67aa" category="paragraph">Chance Bingen, NetApp</block>
  <block id="60398bdc931fc67a9b6d781434c3a15a" category="section-title">vSphere용 ONTAP</block>
  <block id="09d6c6a1868cc36795c7a0f8f84e50c9" category="paragraph">NetApp ONTAP는 2002년 현대적인 데이터 센터에 도입된 이후 VMware vSphere 환경을 위한 업계 최고의 스토리지 솔루션이며, 비용을 절감하는 동시에 관리를 단순화하는 혁신적인 기능을 지속적으로 추가하고 있습니다. 이 문서에서는 최신 제품 정보 및 모범 사례를 포함하여 배포를 간소화하고 위험을 줄이며 지속적인 관리를 단순화하는 VMware의 업계 최고 DR(재해 복구) 소프트웨어인 VMware SRM(Site Recovery Manager)을 위한 ONTAP 솔루션을 소개합니다.</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">모범 사례는 가이드 및 호환성 도구와 같은 다른 문서를 보완합니다. 이러한 전문 분야는 연구소 테스트와 NetApp 엔지니어 및 고객의 광범위한 현장 경험을 기반으로 합니다. 권장 모범 사례가 귀사의 환경에 적합하지 않은 경우도 있지만, 일반적으로 대부분의 고객 요구사항을 충족하는 가장 간단한 솔루션입니다.</block>
  <block id="c3edc14dbc5862176444f521372d1744" category="paragraph">이 문서는 ONTAP 9의 최신 릴리즈와 VMware vSphere(NetApp SRA(스토리지 복제 어댑터) 및 VASA 공급자[VP] 포함)용 ONTAP 툴 지원 버전과 함께 사용할 경우 VMware 사이트 복구 관리자 8의 기능에 중점을 둡니다. 4.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">SRM에 ONTAP를 사용해야 하는 이유</block>
  <block id="3c41d5be62c97a13079e9c7abf078292" category="paragraph">ONTAP 소프트웨어로 구동되는 NetApp 데이터 관리 플랫폼은 SRM을 위해 가장 널리 채택된 스토리지 솔루션 중 일부입니다. 그 이유는 수많은 기업이 스토리지 효율성, 멀티 테넌시, 서비스 품질 제어, 공간 효율적인 Snapshot 복사본을 사용한 데이터 보호 및 SnapMirror 복제를 제공하는 업계 정의 스토리지 효율성 기능을 제공하는 고성능 보안 통합 프로토콜(NAS 및 SAN 함께) 데이터 관리 플랫폼입니다. 이 모든 기능은 기본 하이브리드 멀티 클라우드 통합을 활용하여 VMware 워크로드를 보호하고 다양한 자동화 및 오케스트레이션 툴을 손쉽게 사용할 수 있도록 지원합니다.</block>
  <block id="0d573b6a27c08499fee406e3db49812f" category="paragraph">어레이 기반 복제에 SnapMirror를 사용하는 경우 ONTAP의 가장 검증되고 성숙된 기술 중 하나를 활용할 수 있습니다. SnapMirror를 사용하면 전체 VM 또는 데이터 저장소가 아닌 변경된 파일 시스템 블록만 복제하여 안전하고 효율성이 높은 데이터 전송을 이용할 수 있습니다. 이러한 블록조차도 중복제거, 압축, 컴팩션과 같은 공간 절약 효과를 활용합니다. 최신 ONTAP 시스템은 이제 버전에 상관없이 SnapMirror를 사용하므로 소스 및 타겟 클러스터를 유연하게 선택할 수 있습니다. SnapMirror는 실제로 재해 복구에 사용할 수 있는 가장 강력한 툴 중 하나가 되었습니다.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">기존 NFS, iSCSI 또는 파이버 채널 연결 데이터 저장소(VVOL 데이터 저장소 지원)를 사용하는 경우 SRM은 재해 복구 또는 데이터 센터 마이그레이션 계획 및 오케스트레이션을 위해 최상의 ONTAP 기능을 활용하는 강력한 타사 오퍼링을 제공합니다.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">SRM이 ONTAP 9를 활용하는 방법</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM은 세 가지 주요 구성 요소가 포함된 가상 어플라이언스인 ONTAP for VMware vSphere와 통합하여 ONTAP 시스템의 고급 데이터 관리 기술을 활용합니다.</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">vCenter 플러그인을 사용하면 이전에 VSC(Virtual Storage Console)라고 부르던 기능을 통해 SAN 또는 NAS를 사용하든지 스토리지 관리 및 효율성 기능을 단순화하고, 가용성을 높이며, 스토리지 비용과 운영 오버헤드를 줄일 수 있습니다. Best Practice를 사용하여 데이터 저장소를 프로비저닝하고 NFS 및 블록 스토리지 환경에 대한 ESXi 호스트 설정을 최적화합니다. 이러한 모든 이점을 누리게 하려면 ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 이 플러그인을 사용하는 것이 좋습니다.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">VASA Provider for ONTAP는 VMware VASA(vStorage APIs for Storage Awareness) 프레임워크를 지원합니다. VASA Provider는 vCenter Server를 ONTAP와 연결하여 VM 스토리지를 프로비저닝하고 모니터링할 수 있도록 지원합니다. VVOL(VMware Virtual Volumes)을 통해 스토리지 기능 프로필(VVOL 복제 기능 포함)과 개별 VM VVol 성능을 지원하고 관리할 수 있습니다. 또한 용량을 모니터링하고 프로파일 준수를 위한 알람을 제공합니다. SRM과 함께 VASA Provider for ONTAP를 사용하면 SRM 서버에 SRA 어댑터를 설치할 필요 없이 VVOL 기반 가상 머신을 지원할 수 있습니다.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA는 SRM과 함께 사용되어 기존 VMFS 및 NFS 데이터 저장소의 프로덕션 및 재해 복구 사이트 간에 VM 데이터 복제를 관리하고 DR 복제본의 무중단 테스트를 수행합니다. 검색, 복구 및 재보호 작업을 자동화할 수 있습니다. SRA 서버 어플라이언스와 Windows SRM 서버용 SRA 어댑터 및 SRM 어플라이언스가 모두 포함됩니다.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">VASA Provider 설정에서 비 VVol 데이터 저장소 및/또는 활성화된 VVol 복제를 보호하기 위해 SRM 서버에 SRA 어댑터를 설치 및 구성한 후에는 재해 복구를 위해 vSphere 환경을 구성하는 작업을 시작할 수 있습니다.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">SRA 및 VASA Provider는 SRM 서버에 대한 명령 및 제어 인터페이스를 제공하여 VMware VM(가상 시스템)이 포함된 ONTAP FlexVol과 이들을 보호하는 SnapMirror 복제를 관리합니다.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">SRM 8.3부터 SRM 서버에 새로운 SRM VVol Provider 제어 경로가 도입되어 vCenter Server와 통신하고 SRA를 사용하지 않고도 VASA Provider와 통신할 수 있게 되었습니다. 따라서 VASA는 긴밀한 통합을 위한 완벽한 API를 제공하므로 SRM 서버가 ONTAP 클러스터에 대한 훨씬 더 깊은 제어를 활용할 수 있게 되었습니다.</block>
  <block id="53e971f0dfb3ef96ca359dcb648176b9" category="paragraph">SRM은 NetApp의 독점 FlexClone 기술을 사용하여 DR 사이트에 보호된 데이터 저장소의 거의 즉각적인 복제본을 만들어 DR 계획을 중단 없이 테스트할 수 있습니다. SRM은 안전한 테스트를 위한 샌드박스를 생성하여 실제 재해 발생 시 조직 및 고객이 보호를 받을 수 있도록 함으로써 재해 발생 시 조직의 장애 조치 실행 능력을 확실히 제공합니다.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">실제 재해 또는 계획된 마이그레이션이 있는 경우 SRM을 사용하면 최종 SnapMirror 업데이트(선택한 경우)를 통해 데이터 세트에 대한 최신 변경 사항을 보낼 수 있습니다. 그런 다음 미러를 해제하고 데이터 저장소를 DR 호스트에 마운트합니다. 이 시점에서 사전 계획된 전략에 따라 임의의 순서로 VM을 자동으로 켤 수 있습니다.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">ONTAP 및 기타 사용 사례를 지원하는 SRM: 하이브리드 클라우드 및 마이그레이션</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">Equinix의 NetApp 프라이빗 스토리지</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">SRM 배포를 ONTAP 고급 데이터 관리 기능과 통합하면 로컬 스토리지 옵션에 비해 확장성과 성능이 크게 향상됩니다. 그 이상의 것은 하이브리드 클라우드의 유연성을 제공합니다. 하이브리드 클라우드를 사용하면 FabricPool StorageGRID와 같은 사내 S3 저장소일 수 있는를 사용하여 고성능 어레이에서 선호하는 하이퍼스케일러를 사용하여 사용하지 않는 데이터 블록을 계층화하여 비용을 절감할 수 있습니다. 또한 CVO(Cloud Volumes ONTAP) 또는 를 사용하여 소프트웨어 정의 ONTAP Select 또는 클라우드 기반 DR이 있는 에지 기반 시스템에 SnapMirror를 사용할 수도 있습니다<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> AWS(Amazon Web Services), Microsoft Azure 및 GCP(Google Cloud Platform)를 이용하여 클라우드에 완전히 통합된 스토리지, 네트워킹 및 컴퓨팅 서비스 스택을 구축할 수 있습니다.</block>
  <block id="10ae334f731d3c4fabafa8017f7a3ab2" category="paragraph">그런 다음 FlexClone을 사용하여 스토리지 공간을 거의 차지하지 않고 클라우드 서비스 공급자의 데이터 센터 내에서 테스트 대체 작동을 수행할 수 있습니다. 이제 조직을 보호하는 데 드는 비용이 그 어느 때보다 줄어듭니다.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">또한 SRM은 SnapMirror를 활용하여 VM을 하나의 데이터 센터에서 다른 데이터 센터로 효율적으로 전송하거나 자체 또는 NetApp 파트너 서비스 공급자의 수를 통해 동일한 데이터 센터 내에서 효율적으로 전송하여 계획된 마이그레이션을 실행하는 데 사용할 수 있습니다.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">VVol(Virtual Volumes) 및 SPBM(Storage Policy Based Management)</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">VVol 및 SPBM 정보</block>
  <block id="ab3304a5226d57b9bcaf0c7b3f819735" category="paragraph">NetApp은 VVOL(vSphere Virtual Volumes)을 개발하여 초기 설계 파트너로 VMware와 협력하여 VVOL과 VMware VASA(vSphere API for Storage Awareness)를 조기에 지원하고 아키텍처 입력을 제공했습니다. 이 접근 방식은 VM의 세분화된 스토리지 관리를 VMFS에 제공하는 것은 물론, SPBM(Storage Policy-Based Management)을 통한 스토리지 프로비저닝 자동화도 지원했습니다.</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">SPBM은 가상화 환경에서 사용 가능한 스토리지 서비스와 정책을 통해 프로비저닝된 스토리지 요소 간의 추상화 계층 역할을 하는 프레임워크를 제공합니다. 스토리지 설계자는 이 접근 방식을 통해 VM 관리자가 쉽게 사용할 수 있는 다양한 기능을 갖춘 스토리지 풀을 설계할 수 있습니다. 그런 다음 관리자는 프로비저닝된 스토리지 풀에 대해 가상 머신 워크로드 요구 사항을 일치시킬 수 있으므로 VM별 또는 가상 디스크 레벨의 다양한 설정을 세부적으로 제어할 수 있습니다.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP은 스토리지 업계에서 VVOL을 선도하여 단일 클러스터에서 수십만 개의 VVOL을 지원하는 반면, 엔터프라이즈 어레이와 소규모 플래시 어레이 공급업체는 어레이당 수백 개의 VVOL을 지원합니다. NetApp은 또한 VVOL 3.0을 지원함으로써 VM 세부 관리의 발전을 이끌고 있습니다.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400: ONTAP를 포함한 VMware vSphere 가상 볼륨</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">VMware vSphere 가상 볼륨, SPBM 및 ONTAP에 대한 자세한 내용은 을 참조하십시오<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>.</block>
  <block id="5a44477fe5ac4beac2dc6574097cf079" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP 스토리지 iSCSI VMFS 데이터 저장소를 구축하는 단계를 제공합니다.</block>
  <block id="6d5f52fb3cf097647a57da8b55e5b08f" category="doc">ONTAP를 사용한 vSphere 기존 블록 스토리지 프로비저닝</block>
  <block id="7c2d57185437da757ecede58f5a842d4" category="paragraph">VMware vSphere는 ONTAP SAN 프로토콜이 지원되는 다음 VMFS 데이터 저장소 옵션을 지원합니다.</block>
  <block id="c90881491d716de5c0ed7f9f4b09a3ad" category="cell">VMFS 데이터 저장소 옵션</block>
  <block id="a9181ef164a32ec0949c2cf63315ca31" category="cell">ONTAP SAN 프로토콜 지원</block>
  <block id="5903a917b575023b60264c602c220771" category="inline-link-macro">파이버 채널(FC)</block>
  <block id="a4bce6d7794ee38a14e6a6d3785039f9" category="cell"><block ref="a4bce6d7794ee38a14e6a6d3785039f9" category="inline-link-macro-rx"></block></block>
  <block id="a6105c0a611b41b08f1209506350279e" category="cell">예</block>
  <block id="8da5577a58a95e2ebe9c6dd4f19f6c11" category="inline-link-macro">FCoE(Fibre Channel over Ethernet)</block>
  <block id="40b814244a055d57c1af5fd02e4a8747" category="cell"><block ref="40b814244a055d57c1af5fd02e4a8747" category="inline-link-macro-rx"></block></block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="inline-link-macro">iSCSI</block>
  <block id="b26caac6068e09e5f849cfcb3e8c0c90" category="cell"><block ref="b26caac6068e09e5f849cfcb3e8c0c90" category="inline-link-macro-rx"></block></block>
  <block id="c38e870d503879d110dbddd5bf388ab2" category="cell">RDMA용 iSCSI 확장(iSER)</block>
  <block id="7fa3b767c460b54a2be4d49030b349c7" category="cell">아니요</block>
  <block id="de5a656362f0d785d2cc7d3097a507ef" category="inline-link-macro">NVMe over Fabric 및 FC(NVMe/FC)</block>
  <block id="71a94ffc9bd97f314990ee2cd7a87154" category="cell"><block ref="71a94ffc9bd97f314990ee2cd7a87154" category="inline-link-macro-rx"></block></block>
  <block id="16d2954ba1640e32b21c312695337233" category="cell">RDMA over Converged Ethernet(NVMe/RoCE)을 통한 NVMe over Fabric</block>
  <block id="344567ba51767dd5805c908c602fb10e" category="admonition">iSER 또는 NVMe/RoCE VMFS가 필요한 경우 SANtricity 기반 스토리지 시스템을 확인하십시오.</block>
  <block id="d4f43ea12f3f521c93fb3dd4d93c428d" category="summary">이 페이지에서는 VMware vSphere 환경에서 VMFS 데이터 저장소용 NetApp ONTAP NVMe/FC 스토리지를 구축하는 단계를 제공합니다.</block>
  <block id="9e433440cdaf3b61716784200e8abf6d" category="doc">vSphere VMFS 데이터 저장소 - ONTAP가 포함된 NVMe/FC</block>
  <block id="bbe48fb854ea022537208eeeff822f91" category="section-title">이 작업에 대해</block>
  <block id="9367f3df6c8d54eba1da3cd9c5fa2776" category="paragraph">이 섹션에서는 NVMe/FC를 사용하여 ONTAP 스토리지로 VMFS 데이터 저장소를 생성하는 방법을 설명합니다.</block>
  <block id="1563a554e82b055714efd37bc6d1fdd6" category="paragraph">자동 프로비저닝의 경우 다음 스크립트 중 하나를 사용합니다. <block ref="a45ba722ee80832fb205d0588df91e01" category="inline-xref-macro-rx"></block>, <block ref="d9559d06f0afa5b213d78afb48b783e7" category="inline-xref-macro-rx"></block>, 또는 <block ref="e5e7d2f44064f3bfeddfdbea251f7835" category="inline-xref-macro-rx"></block>.</block>
  <block id="6ac65708de8f04eeb173ca99f3eb19fa" category="section-title">필요한 것</block>
  <block id="6af0e7a38739ed6e2658342101a7b51e" category="list-text">vSphere 환경 및 ONTAP를 관리하는 데 필요한 기본 기술</block>
  <block id="7890464cdce93f078097395e27132775" category="inline-link-macro">NVMe/FC에 대한 기본 이해</block>
  <block id="c6e7cd589502f52a9398e779ede56d14" category="list-text"><block ref="62a43aa3bd2eb01e27a6091d3017311c" category="inline-link-macro-rx"></block>.</block>
  <block id="5422bc00db54a341b2c538f4cea614c0" category="list-text">{ONTAP_VERSION}을 실행하는 ONTAP 스토리지 시스템(FAS/AFF/CVO/ONTAP Select/ASA</block>
  <block id="fdb8f60c37b623874df816146436f56b" category="list-text">ONTAP 자격 증명(SVM 이름, userID 및 암호)</block>
  <block id="2ec64af43682ffa45eeaf33a86950347" category="list-text">호스트, 타겟, SVM 및 LUN 정보를 위한 ONTAP WWPN</block>
  <block id="62eadfe081f86e1f9a72988a4feb7bfc" category="inline-link-macro">완료된 FC 구성 워크시트</block>
  <block id="f186921a73873df63dc496b515bc2099" category="list-text"><block ref="f186921a73873df63dc496b515bc2099" category="inline-link-macro-rx"></block></block>
  <block id="c4436d4a190778b7ec1e9461f6454bdd" category="list-text">vCenter Server를 선택합니다</block>
  <block id="5fd6c6da49bc906cc217c5aff2041a52" category="list-text">vSphere 호스트 정보({vSphere_version})</block>
  <block id="63fc76a195a29345d466bc86f293ca14" category="list-text">패브릭 스위치</block>
  <block id="60ce38e4967c52c316eff771b7a3c4ec" category="list-text">ONTAP FC 데이터 포트 및 vSphere 호스트가 연결된 경우</block>
  <block id="32086766e64ae646fcadddc3e16b203b" category="list-text">N_port ID 가상화(NPIV) 기능이 활성화된 경우</block>
  <block id="b6e0bd021536c90aa87cfea18d73d453" category="list-text">단일 이니시에이터 타겟 존을 생성합니다.</block>
  <block id="df7f994fb0c494b66708667a64b2c406" category="list-text">각 이니시에이터에 대해 하나의 존(Zone)을 생성합니다(단일 이니시에이터 존).</block>
  <block id="f386e9f209710f55d41a97e9502d1c7c" category="list-text">각 존에 SVM을 위한 ONTAP FC 논리 인터페이스(WWPN)인 타겟을 포함합니다. SVM당 노드당 논리 인터페이스는 2개 이상 있어야 합니다. 물리적 포트의 WWPN을 사용하지 마십시오.</block>
  <block id="71d4977f0fd6be92644e1ff9f8096637" category="section-title">VMFS 데이터 저장소를 프로비저닝합니다</block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">상호 운용성 매트릭스 툴(IMT)</block>
  <block id="a9df884192a193f56d8208439b4d1fca" category="list-text">과의 호환성을 확인하십시오<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block>.</block>
  <block id="f42c50210dcc0a3a69c8258256e75e4b" category="inline-link-macro">NVMe/FC 구성이 지원되는지 확인하십시오.</block>
  <block id="5312bcc81ee6d7bce6549b2089c9d1ac" category="list-text"><block ref="5312bcc81ee6d7bce6549b2089c9d1ac" category="inline-link-macro-rx"></block></block>
  <block id="cfa5eceb5ac37d5ebd3af6f265d9ce4c" category="section-title">ONTAP 작업</block>
  <block id="1a04100ec801e5e2d1708d89eb1159b6" category="inline-link-macro">FCP의 ONTAP 라이센스를 확인합니다.</block>
  <block id="9d17f91ad987b7e7cf2fa7249cd97343" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block>'system license show' 명령어를 이용하여 NVMe_of가 나열되는지 확인한다. 사용권을 추가하려면 'license add-license-code &lt;license code&gt;'를 사용하십시오.</block>
  <block id="7193bed15c5b4f7c80f1f19630b57e1e" category="list-text">SVM에서 NVMe 프로토콜이 활성화되어 있는지 확인합니다.</block>
  <block id="5eabd2d7390fc49cb61f882324bdcac0" category="inline-link-macro">NVMe용 SVM을 구성합니다.</block>
  <block id="3838b8ad26ea53cc8ddea76f2a58b20a" category="list-text"><block ref="3838b8ad26ea53cc8ddea76f2a58b20a" category="inline-link-macro-rx"></block></block>
  <block id="f2fd2de931ce484e947c89ae8207346a" category="list-text">SVM에서 NVMe/FC 논리 인터페이스를 사용할 수 있는지 확인합니다.</block>
  <block id="aa01379022dd5b86e18f436c76f651f5" category="list-text">네트워크 인터페이스 show를 사용하여 FCP 어댑터를 확인합니다.</block>
  <block id="978583cfbb47e2700c599c43b7949a53" category="list-text">GUI로 SVM을 생성할 때 논리 인터페이스는 이 프로세스의 일부입니다.</block>
  <block id="3866119a70b69102c1584c0baa386190" category="list-text">네트워크 인터페이스의 이름을 바꾸려면 네트워크 인터페이스 수정 명령을 사용합니다.</block>
  <block id="6ad7e9002145710745843d16314895e3" category="inline-link-macro">NVMe 네임스페이스 및 하위 시스템을 생성합니다</block>
  <block id="06badf30aa173febc3374aceef25c5ce" category="list-text"><block ref="06badf30aa173febc3374aceef25c5ce" category="inline-link-macro-rx"></block></block>
  <block id="722a3f8fc9c281f41b6ca7a69ca15ec0" category="section-title">VMware vSphere 작업</block>
  <block id="7407e0a15262132133381a890e36e47a" category="inline-link-macro">스토리지 어댑터 정보</block>
  <block id="c6613394adcc7526a48f6e92b61ee067" category="list-text">HBA 드라이버가 설치되어 있는지 확인합니다. VMware 지원 HBA에는 드라이버가 즉시 배포되어 있으며 에서 볼 수 있습니다 <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block></block>
  <block id="9761a89a99469e468e71b7a0087be29d" category="inline-link-macro">vSphere Host NVMe 드라이버 설치 및 검증 작업을 수행합니다</block>
  <block id="926e4d89379d3dde2510965ca53771af" category="list-text"><block ref="926e4d89379d3dde2510965ca53771af" category="inline-link-macro-rx"></block></block>
  <block id="e229fd9b7b8948ddebf276bda8a9145e" category="inline-link-macro">VMFS 데이터 저장소를 생성합니다</block>
  <block id="3dbbea9263919f89335d7ba053f09a39" category="list-text"><block ref="3dbbea9263919f89335d7ba053f09a39" category="inline-link-macro-rx"></block></block>
  <block id="c0ddbacfe0f703e62904558059e40001" category="summary">이 섹션에서는 특정 릴리즈의 ONTAP 및 vSphere에서 지원하는 기능에 대한 지침을 제공합니다. NetApp 상호 운용성 매트릭스와 특정 조합의 릴리즈를 확인하는 것이 좋습니다.</block>
  <block id="737453909be77692f8cfdf08a17cee61" category="doc">ONTAP 및 vSphere 릴리즈별 정보입니다</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">NetApp 상호 운용성 매트릭스</block>
  <block id="2f6ae9fa35fbcb0ec3205505ee027642" category="paragraph">이 섹션에서는 특정 릴리즈의 ONTAP 및 vSphere에서 지원하는 기능에 대한 지침을 제공합니다. NetApp은 와 릴리스의 특정 조합을 확인하는 것이 좋습니다<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block>.</block>
  <block id="7912c2100fd9b3b96b0b03e7a068fc9a" category="section-title">ONTAP 릴리스</block>
  <block id="8ee2892e0fb10cc58205a3d682abdb58" category="paragraph">NetApp은 출시 당시 다음과 같은 제품군을 완벽하게 지원합니다.</block>
  <block id="0fcf2ee62acd9eae83b609a0e7ecaa72" category="list-text">ONTAP 9.5</block>
  <block id="7dd2a92fd3f41a5334edf46f95d77e71" category="list-text">ONTAP 9.6</block>
  <block id="3447b91e516e4fc6b5dba827fcb68bee" category="list-text">ONTAP 9.7</block>
  <block id="2abfff2974f589f7a217325f304e0ec5" category="list-text">ONTAP 9.8</block>
  <block id="ee4651b72d795faf25a1382eb1315a95" category="section-title">vSphere 및 ESXi 지원</block>
  <block id="c3123497dcfdcdf46908ad18a51928ca" category="paragraph">NetApp ONTAP는 vSphere ESXi 호스트를 광범위하게 지원합니다. 방금 설명한 네 가지 주요 릴리즈 제품군(9.5, 9.6, 9.7 및 9.8)은 6.0, 6.5 및 7.0(이러한 릴리즈에 대한 업데이트 포함)을 비롯한 최신 vSphere 릴리스의 데이터 스토리지 플랫폼으로 완벽하게 지원됩니다. NFS v3 상호 운용성은 광범위하게 정의되며 NetApp은 NFS v3 표준을 준수하는 하이퍼바이저를 포함하여 모든 클라이언트를 지원합니다. NFSv4.1 지원은 vSphere 6.0에서 7.0으로 제한됩니다.</block>
  <block id="8276b4666ec9fee7d71b01f6ee2b9955" category="paragraph">SAN 환경의 경우 NetApp에서 SAN 구성요소를 광범위하게 테스트합니다. 일반적으로 NetApp은 표준 x86-64 랙 서버와 Cisco UCS 서버를 iSCSI 연결용 표준 이더넷 어댑터와 함께 지원합니다. FC, FCoE 및 NVMe/FC 환경에서는 필요한 HBA 펌웨어 및 드라이버로 인해 지원이 명확하게 정의되었습니다.</block>
  <block id="a9854fb3ed44e3b8e9236c5b70405101" category="paragraph">항상 을 확인하십시오<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block> 특정 하드웨어 및 소프트웨어 구성에 대한 지원을 확인합니다.</block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">VMware VAAI용 NFS 플러그인</block>
  <block id="eb3ac5aa51c1cacfa31cee70ac6586f0" category="paragraph">ESXi 호스트용 이 플러그인은 VAAI를 사용하여 ONTAP로 작업을 오프로드하는 데 도움이 됩니다. 최신 릴리스인 1.1.2에는 Kerberos(krb5 및 krb5i) 지원을 비롯한 NFSv4.1 데이터 저장소가 지원됩니다. ONTAP 9.5-9.8과 함께 ESXi 6.0, 6.5 및 7.0에서 지원됩니다.</block>
  <block id="b2dd36bd4918e00f8b2e15e6d62a4b94" category="section-title">VASA 공급자</block>
  <block id="15c15a65e1486d45a44c6f61927ef836" category="paragraph">NetApp의 VASA Provider는 VVOL 프로비저닝 및 관리를 지원합니다(섹션 3.7 참조). 최신 VASA Provider 릴리즈는 ESXi 6.0, 6.5 및 7.0과 ONTAP 9.5-9.8을 함께 지원합니다.</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="section-title">VMware vSphere용 ONTAP 툴</block>
  <block id="c13550c8bc0f9b77e92bd2533221de9d" category="paragraph">VMware vSphere용 ONTAP 툴은 ONTAP 스토리지를 vSphere와 함께 관리하는 데 있어 매우 중요합니다(모범 사례). 최신 릴리스인 9.8은 ONTAP 9.5-9.8과 함께 vSphere 6.5 및 7.0에서 지원됩니다.</block>
  <block id="a9b73ebef33c98ef5a1044177d2b49f3" category="summary">VMware vCenter Site Recovery Manager는 모든 가상화된 애플리케이션의 재해 복구 관리를 간소화하기 위해 중앙 집중식 복구 계획의 자동화된 오케스트레이션 및 무중단 테스트를 제공하는 재해 복구 솔루션입니다.</block>
  <block id="06f589670c0d0455912cc8bb70b78701" category="paragraph">NetApp ONTAP 시스템에 Site Recovery Manager를 구축하면 재해 복구 비용을 크게 절감하고 복잡성을 줄일 수 있습니다. NetApp은 관리하기 쉽고 확장성이 뛰어난 고성능 스토리지 어플라이언스 및 강력한 소프트웨어 제품을 통해 vSphere 환경을 지원하는 유연한 스토리지 및 데이터 관리 솔루션을 제공합니다.</block>
  <block id="00549aec33ddcae6a708ed7368a7bcd0" category="paragraph">이 가이드에서 제공하는 모범 사례와 권장 사항은 모든 요구사항을 한 가지 솔루션으로 제시되는 것이 아닙니다. 이 문서에는 SRM DR 계획의 계획, 배포 및 관리에 대한 지침을 제공하는 모범 사례와 권장 사항이 포함되어 있습니다. NetApp 스토리지에 VMware vCenter Site Recovery 환경을 계획 및 구축하려면 현지 NetApp VMware 전문가에게 문의하십시오. NetApp VMware 전문가는 vSphere 환경의 요구 사항과 수요를 빠르게 파악하고 그에 따라 스토리지 솔루션을 조정할 수 있습니다.</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">ONTAP를 사용하면 SVM(스토리지 가상 머신)이라는 개념을 통해 보안 멀티 테넌트 환경에서 엄격한 세분화를 제공할 수 있습니다.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">배포 모범 사례</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">SMT를 위한 SVM 레이아웃 및 Segmentation</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">ONTAP를 사용하면 SVM(스토리지 가상 머신)이라는 개념을 통해 보안 멀티 테넌트 환경에서 엄격한 세분화를 제공할 수 있습니다. 한 SVM의 SVM 사용자는 다른 SVM에서 리소스를 액세스하거나 관리할 수 없습니다. 이렇게 하면 동일한 클러스터에서 고유한 SRM 워크플로우를 관리하는 여러 사업부에 대해 별도의 SVM을 생성하여 ONTAP 기술을 활용함으로써 전반적인 스토리지 효율성을 높일 수 있습니다.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">보안 제어를 개선하면서 성능을 향상할 뿐만 아니라 SVM 범위 계정 및 SVM 관리 LIF를 사용하여 ONTAP를 관리하는 것을 고려해 보십시오. SRA는 물리적 리소스를 포함하여 전체 클러스터의 모든 리소스를 처리할 필요가 없으므로 SVM 범위 연결을 사용할 때 기본적으로 성능이 향상됩니다. 대신, 특정 SVM에 추상화된 논리적 자산만 이해해야 합니다.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">NAS 프로토콜만 사용하는 경우(SAN 액세스 없음), 다음 매개 변수를 설정하여 새로운 NAS 최적화 모드를 활용할 수도 있습니다(SRA 및 VASA는 어플라이언스에서 동일한 백엔드 서비스를 사용하기 때문에 이름이 동일함).</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">"\https://&lt;IP address&gt;:9083"에서 제어판에 로그인하고 웹 기반 CLI 인터페이스를 클릭합니다.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">vp updateeconfig -key=enable.qtree.discovery-value=true 명령을 실행합니다.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">vp updateeconfig -key=enable.optimized.SRA-value=true 명령을 실행합니다.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">'vp reloadconfig' 명령어를 실행한다.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">VVOL을 위한 ONTAP 툴 및 고려사항 배포</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">VVOL이 포함된 SRM을 사용하려면 클러스터 범위 자격 증명 및 클러스터 관리 LIF를 사용하여 스토리지를 관리해야 합니다. 이는 VASA Provider가 VM 스토리지 정책에 필요한 정책을 충족하기 위해 기본 물리적 아키텍처를 이해해야 하기 때문입니다. 예를 들어, All-Flash 스토리지가 필요한 정책이 있는 경우 VASA Provider는 모든 All-Flash 시스템을 확인할 수 있어야 합니다.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">또 다른 구축 모범 사례는 관리 중인 VVOL 데이터 저장소에 ONTAP 툴 어플라이언스를 저장하지 않는 것입니다. 어플라이언스가 오프라인이므로 어플라이언스에 대한 스왑 VVol을 생성할 수 없으므로 VASA Provider의 전원을 켤 수 없는 상황이 발생할 수 있습니다.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">ONTAP 9 시스템 관리 모범 사례</block>
  <block id="b4cbecf196108ad163c73c4e4194dde2" category="paragraph">앞서 언급했듯이 클러스터 또는 SVM 범위의 자격 증명 및 관리 LIF를 사용하여 ONTAP 클러스터를 관리할 수 있습니다. 최적의 성능을 위해 VVOL을 사용하지 않을 때마다 SVM 범위 자격 증명을 사용하는 것이 좋습니다. 그러나 이렇게 하면 일부 요구 사항을 인식하고 일부 기능을 사용할 수 없게 됩니다.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">기본 vsadmin SVM 계정에는 ONTAP 툴 작업을 수행하는 데 필요한 액세스 수준이 없습니다. 따라서 새 SVM 계정을 생성해야 합니다.</block>
  <block id="8557644859e03f54860c95ffb0bcfd53" category="list-text">ONTAP 9.8 이상을 사용하는 경우, ONTAP System Manager의 사용자 메뉴와 함께 ONTAP 도구 어플라이언스의 JSON 파일을 사용하여 RBAC 최소 권한 사용자 계정을 "\https://&lt;IP address&gt;:9083/VSC/config/"에서 생성하는 것이 좋습니다. 관리자 암호를 사용하여 JSON 파일을 다운로드합니다. SVM 또는 클러스터 범위 어카운트에 사용할 수 있습니다.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">NetApp Support 사이트 Toolchest</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">ONTAP 9.6 이하를 사용하는 경우 에서 사용할 수 있는 RBAC 사용자 작성 도구(RUC)를 사용해야 합니다<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">vCenter UI 플러그인, VASA Provider 및 SRA 서버는 모두 완전히 통합된 서비스이므로 ONTAP용 vCenter UI 툴에서 스토리지를 추가하는 것과 동일한 방식으로 SRM에서 SRA 어댑터에 스토리지를 추가해야 합니다. 그렇지 않으면 SRA 서버는 SRA 어댑터를 통해 SRM에서 전송되는 요청을 인식하지 못할 수 있습니다.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">SVM 범위 자격 증명을 사용할 때는 NFS 경로 검사가 수행되지 않습니다. 물리적 위치가 SVM에서 논리적으로 추상화되기 때문입니다. 하지만 최신 ONTAP 시스템은 간접 경로를 사용할 때 눈에 띄는 성능 저하가 더 이상 발생하지 않으므로 이는 우려의 원인이 아닙니다.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">스토리지 효율성으로 인한 애그리게이트 공간 절약은 보고되지 않을 수 있습니다.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">지원되는 경우 로드 공유 미러를 업데이트할 수 없습니다.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">SVM 범위 자격 증명으로 관리되는 ONTAP 시스템에서는 EMS 로깅이 수행되지 않을 수 있습니다.</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">기존 가상 어플라이언스로 전환한 ONTAP 툴은 다양한 새로운 기능, 더 높은 제한, 새로운 VVOL 지원을 제공합니다.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">SRM 및 ONTAP 도구의 새로운 기능</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">vSphere 및 Site Recovery Manager의 최신 버전입니다</block>
  <block id="aa73b07f008975ca9fcabf87bfafb167" category="paragraph">SRM 8.3 이상 릴리즈와 ONTAP 툴 9.7.1 이상 릴리즈를 사용하면 이제 VMware vSphere 7에서 실행 중인 VM을 보호할 수 있습니다.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp은 약 20년 동안 VMware와 긴밀한 파트너 관계를 유지하고 있으며, 최대한 빠른 시일 내에 최신 릴리즈를 지원하기 위해 노력하고 있습니다. 항상 NetApp 상호 운용성 매트릭스 툴(IMT) 에서 적격 소프트웨어의 최신 조합을 확인하십시오.</block>
  <block id="63fe9875fcf8108a4dca29a0795d8674" category="paragraph">NetApp IMT를 찾을 수 있습니다<block ref="dd81e3609a71c92c2a90d9165ca7bb00" category="inline-link-rx"></block>.</block>
  <block id="23a6222620917211381cf4455d9e0a83" category="section-title">VVol 지원(및 SRM을 사용하는 경우에도 SPBM이 중요한 이유)</block>
  <block id="a36269071ceeb480e636654c4620f7fb" category="paragraph">이제 8.3 릴리스로 시작하여 SRM은 VVol 및 어레이 기반 복제를 활용하는 복제의 스토리지 정책 기반 관리(SPBM)를 지원합니다. 이를 위해 VASA 관련 작업을 위해 vCenter 서버의 SMS 서비스와 통신하는 새로운 SRM VVol 공급자 서비스를 포함하도록 SRM 서버가 업데이트되었습니다.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">이 아키텍처의 한 가지 이점은 모든 것이 VASA를 통해 처리되므로 SRA가 더 이상 필요하지 않는다는 것입니다.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM은 vSphere 툴박스에 포함된 강력한 툴로, 프라이빗 및 하이브리드 클라우드 환경의 자동화 프레임워크에서 간편하고 예측 가능하며 일관된 스토리지 서비스를 사용할 수 있습니다. 기본적으로 SPBM을 사용하면 다양한 고객 기반의 요구 사항을 충족하는 서비스 클래스를 정의할 수 있습니다. SRM을 사용하면 강력한 업계 표준 재해 복구 오케스트레이션 및 자동화가 필요한 중요 워크로드에 대한 복제 기능을 고객에게 제공할 수 있습니다.</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48e2854d95fac45929940abc72062193" category="section-title">VVOL 아키텍처 2.3 어플라이언스 기반 SRM 서버에 대한 지원</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">이제 Photon OS 기반 SRM 서버는 기존 Windows 기반 플랫폼뿐만 아니라 지원됩니다.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">이제 기본 SRM 서버 유형에 관계없이 SRA 어댑터를 설치할 수 있습니다.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">IPv6를 지원합니다</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6은 이제 다음과 같은 제한 사항으로 지원됩니다.</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">vCenter 6.7 이상</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">SRM 8.2(8.1, 8.3 및 8)에서는 지원되지 않습니다. 4개 지원)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">상호 운용성 매트릭스 툴</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">를 확인하십시오<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> 최신 버전의 경우.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">향상된 성능</block>
  <block id="3efd4ca8de094abf49f004186cd70fff" category="paragraph">운영 성능은 SRM 작업 실행을 위한 핵심 요구 사항입니다. 최신 RTO 및 RPO의 요구 사항을 충족하기 위해 ONTAP 도구가 포함된 SRA에 두 가지 새로운 개선 사항이 추가되었습니다.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">* 동시 재보호 작업 지원. * SRA 9.7.1에서 처음 도입된 이 기능을 사용하면 두 개 이상의 복구 계획에서 동시에 재보호를 실행할 수 있으므로 페일오버 또는 마이그레이션 후 데이터 저장소를 재보호하는 데 필요한 시간을 줄이고 RTO 및 RPO 매개 변수를 계속 유지할 수 있습니다.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">* ONTAP Tools 9.8은 NAS 전용 최적화 모드를 새로 추가했습니다. * SVM 범위 계정을 사용하고 NFS 기반 데이터 저장소만 있는 ONTAP 클러스터에 연결할 때 지원되는 환경에서 NAS 전용 최적화 모드를 사용하여 최대 성능을 실현할 수 있습니다.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">더 뛰어난 확장성</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">ONTAP 도구 SRA는 이제 SRM 8.3 이상에서 사용할 경우 최대 500개의 보호 그룹(PG)을 지원할 수 있습니다.</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">동기식 복제</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">오랫동안 기다려온 새로운 기능은 미션 크리티컬 애플리케이션에 볼륨 세분화 제로 RPO 데이터 복제 솔루션을 제공하는 ONTAP 9.5 이상의 SM-S(SnapMirror Synchronous)입니다. SM-S에는 ONTAP 도구 9.8 이상이 필요합니다.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">REST API 지원</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">이제 REST API를 통해 SRA 서버 구성을 관리할 수 있습니다. Swagger UI는 자동화 워크플로우 구축을 지원하기 위해 추가되었으며 ONTAP 툴 어플라이언스('https://&lt;appliance&gt;:8143/api/rest/swagger-ui.html#/` )에서 찾을 수 있습니다.</block>
  <block id="9db3527848e891e0a9340c443515e770" category="doc">NetApp 및 VMware 시작하기</block>
  <block id="4b1c76979225b75a8e5f476356ed17e8" category="paragraph">VMware on NetApp: 여정이 시작됩니다!</block>
  <block id="d7b056332bb039010d62c71ede534471" category="paragraph">VMware 환경 혁신을 시작할 준비가 되었으면 최신 솔루션 개요를 살펴보고 최신 기술 솔루션 및 제품 데모를 검토하십시오. 다음 단계로 진행할 준비가 되면 NetApp 및 VMware 전문가 커뮤니티를 통해 데이터 센터 현대화, 하이브리드 클라우드 또는 컨테이너식 애플리케이션 이니셔티브를 계획하고 실행할 수 있습니다.</block>
  <block id="bbaff12800505b22a853e8b7f4eb6a22" category="inline-link-macro">연락처</block>
  <block id="be52ccc9c4dbcee449a6257062c0bcda" category="paragraph">어디서부터 시작해야 할지 잘 모르십니까? <block ref="dcd7ec98fb935d9a5fd8ade723a47456" category="inline-link-macro-rx"></block> NetApp의 VMware 전문가 구성원</block>
  <block id="27b7a196b8196df4eeee9d21ade20a45" category="inline-link-macro">PDF 형식</block>
  <block id="e2fd99d21fbe7a1b2ed6388c40d48b0f" category="admonition">이 페이지에 표시된 내용은 에서도 다운로드할 수 있습니다 <block ref="a182addaadbc8a97de909268c8dc9bf0" category="inline-link-macro-rx"></block>.</block>
  <block id="11eb332ab75184a78c40c9174e16f520" category="video-title">NetApp과 VMware: 더 나은 협력</block>
  <block id="d3db539e5d56da6e251021138c5fe53f" category="section-title">NetApp과 VMware의 솔루션에 대해 알아보십시오</block>
  <block id="09f93ac387258fa68c085baba3c8fc44" category="inline-link-macro">NetApp과 AMP, VMware: 더욱 유기적으로</block>
  <block id="fb758bbc93c23b25607ef41f302d4eef" category="list-text"><block ref="35ef54e3b8ad8ec505bab4b973f86177" category="inline-link-macro-rx"></block></block>
  <block id="b6741313b8f46ab1018ebd6a361c22a4" category="inline-link-macro">ONTAP 9.8 VMware 개요를 위한 최신 기능</block>
  <block id="d393be6d50183d7362f0adb8bc92ae08" category="list-text"><block ref="d393be6d50183d7362f0adb8bc92ae08" category="inline-link-macro-rx"></block></block>
  <block id="b25a3522acbb33341ccacac99424fcce" category="inline-link-macro">VMware vSphere용 SnapCenter 플러그인 활용</block>
  <block id="a65898b7011ddfb663cdba62f90581c6" category="list-text"><block ref="a65898b7011ddfb663cdba62f90581c6" category="inline-link-macro-rx"></block></block>
  <block id="60b0390f50a5ad13d613d49cfe1bce0b" category="inline-link-macro">NetApp 및 NVMe로 VMware 성능 재정의</block>
  <block id="f6dde7f191b6b8f8351902b139ec8672" category="list-text"><block ref="f6dde7f191b6b8f8351902b139ec8672" category="inline-link-macro-rx"></block></block>
  <block id="c576371db342dc9cb166c73b0e157fb5" category="inline-link-macro">AWS 기반 VMware 클라우드를 위한 저비용 성능 세계</block>
  <block id="89487ceb1ada10e49befbbaed3b714ec" category="list-text"><block ref="89487ceb1ada10e49befbbaed3b714ec" category="inline-link-macro-rx"></block></block>
  <block id="92061b0dd7904e2299ac65ed9bc2d6af" category="inline-link-macro">NetApp의 VMware Tanzu 소개</block>
  <block id="ae7c9beb8e4adca6da75607ee83e2403" category="list-text"><block ref="ae7c9beb8e4adca6da75607ee83e2403" category="inline-link-macro-rx"></block></block>
  <block id="a88a91878fb958db59873117d16ad078" category="inline-link-macro">가상 데스크탑 인프라(VDI): 직원 워크스테이션을 온디맨드로 제공합니다</block>
  <block id="9467ff6388811a059199513a0a484f0b" category="list-text"><block ref="9467ff6388811a059199513a0a484f0b" category="inline-link-macro-rx"></block></block>
  <block id="d5e64137a19403f8c1c89f50546b82c5" category="inline-link-macro">AWS 기반 VMware: 아키텍처 및 서비스 옵션</block>
  <block id="6cb2c8a80e576f132097e4d28cec24cd" category="list-text"><block ref="6cb2c8a80e576f132097e4d28cec24cd" category="inline-link-macro-rx"></block></block>
  <block id="cd4efd0ada1938b240dd48aa08010f04" category="inline-link-macro">NetApp Cloud Volumes Service API를 통한 프로그래밍으로 AWS 경험 최적화</block>
  <block id="f61369e9428a21eb1090be340ef36f16" category="list-text"><block ref="f61369e9428a21eb1090be340ef36f16" category="inline-link-macro-rx"></block></block>
  <block id="6d14f3ca0f5be54f01fd579906dd80bb" category="inline-link-macro">Kubernetes: vSphere 및 Tanzu에서 K8s 실행</block>
  <block id="ef8e103737164442c629df5b5d98769d" category="list-text"><block ref="ef8e103737164442c629df5b5d98769d" category="inline-link-macro-rx"></block></block>
  <block id="7e0caac7f6d493fab662f4f4d65ae213" category="section-title">가상화된 Data Fabric을 구축하세요</block>
  <block id="f1f4041236ed90e2a5e65e9a3c858875" category="section-title">최신 VMware용 NetApp 솔루션을 검토해 보십시오</block>
  <block id="0e8dd76bc961a90df87833953de6d067" category="inline-link-macro">ONTAP 기반의 VMware vSphere: NetApp 솔루션</block>
  <block id="b761cb4d962320708880627e8e2fe971" category="inline-link-macro">ONTAP를 사용하는 VMware vSphere 가상 볼륨</block>
  <block id="5b90454e2bf0f381c8f7fc928ef6fb9e" category="list-text"><block ref="5b90454e2bf0f381c8f7fc928ef6fb9e" category="inline-link-macro-rx"></block></block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="inline-link-macro">VMware vSphere용 SnapCenter 플러그인</block>
  <block id="730c2cf92bbe409c31ef1f39cf25377a" category="list-text"><block ref="730c2cf92bbe409c31ef1f39cf25377a" category="inline-link-macro-rx"></block></block>
  <block id="c375e5bb7184da46adef700a9a36d674" category="inline-link-macro">NetApp의 최신 데이터 보호, VMware vSphere 워크로드 설계 및 검증</block>
  <block id="b54be27467e63a98d65e6b17a914e373" category="list-text"><block ref="902dd483e9192a0b4645b4c8be7acbff" category="inline-link-macro-rx"></block></block>
  <block id="b860a89f6215a92f2320f0afe4e0ee05" category="inline-link-macro">VMware 및 AMP용 NetApp의 최신 데이터 보호 클라우드 연결 플래시 솔루션, SQL Server</block>
  <block id="0ebff16085636352cc1aa1e5b0003bdb" category="list-text"><block ref="ac70b8666634dd9095602966c4c61093" category="inline-link-macro-rx"></block></block>
  <block id="eccda9b55035b56259299545d5781136" category="inline-link-macro">VMware Tanzu &amp; amp; ONTAP를 통해 Kubernetes를 더 빠르게 전환하십시오</block>
  <block id="bb79e474557eb86fc30118354eef0039" category="list-text"><block ref="5dd92e330c2d45255a2025ee1eedd52d" category="inline-link-macro-rx"></block></block>
  <block id="7f8cf1c43494d40e935f5e99e38ce659" category="inline-link-macro">AWS에서 VMware Cloud를 실행하는 데 드는 비용 절감</block>
  <block id="f0d8a1b084d604c4db4319a2c5bbd522" category="list-text"><block ref="f0d8a1b084d604c4db4319a2c5bbd522" category="inline-link-macro-rx"></block></block>
  <block id="5ab6c918ee903c74a7d7c97b2432ebaf" category="section-title">최신 VMware 솔루션의 비디오 데모를 살펴보십시오</block>
  <block id="7128c22bfdae1fe8be75c9a9ee56eca9" category="inline-link-macro">VMware vSphere 및 NetApp ONTAP 모범 사례</block>
  <block id="04e008204e728ef166ffc8c85db580ed" category="list-text"><block ref="04e008204e728ef166ffc8c85db580ed" category="inline-link-macro-rx"></block></block>
  <block id="d2fa143a4aaef3477f2edb0d92676341" category="inline-link-macro">VMware 환경 - NVMe-oF with ONTAP에서 실행하겠습니다</block>
  <block id="207681662de4971035cc8d5c9347c986" category="list-text"><block ref="207681662de4971035cc8d5c9347c986" category="inline-link-macro-rx"></block></block>
  <block id="e9c2b8b8a9962013c07f83742ca35f0e" category="inline-link-macro">ONTAP 도구 및 VMware SRM을 사용한 VVOL 재해 복구</block>
  <block id="8ca7386c3cb63b01ffc6387ba41427ae" category="list-text"><block ref="8ca7386c3cb63b01ffc6387ba41427ae" category="inline-link-macro-rx"></block></block>
  <block id="f156fde75de09cf5f045522cf738b2c7" category="inline-link-macro">ONTAP 툴을 사용하여 FlexGroup 데이터 저장소를 프로비저닝하고 관리합니다</block>
  <block id="c2a201ca982ecfefdcfec43a8df28397" category="list-text"><block ref="c2a201ca982ecfefdcfec43a8df28397" category="inline-link-macro-rx"></block></block>
  <block id="977a548ba3853fdac6d708915a1b752a" category="inline-link-macro">NetApp NFS VAAI 플러그인 업데이트</block>
  <block id="a8e3bfc2dc840604c0168dd5f89aacec" category="list-text"><block ref="a8e3bfc2dc840604c0168dd5f89aacec" category="inline-link-macro-rx"></block></block>
  <block id="233398cd850d9903958583fd85621f6d" category="inline-link-macro">NetApp ONTAP FlexGroup를 지원하는 스케일아웃 가상 데스크톱</block>
  <block id="6ef66ca131701cfdb70302d3099b7550" category="list-text"><block ref="6ef66ca131701cfdb70302d3099b7550" category="inline-link-macro-rx"></block></block>
  <block id="e308c2a1dacddb5bc6ffa093081111e4" category="inline-link-macro">Data Fabric을 위한 VMware 백업 및 복구</block>
  <block id="9934e59457fa5f31d39a58f1d55ac5d5" category="list-text"><block ref="9934e59457fa5f31d39a58f1d55ac5d5" category="inline-link-macro-rx"></block></block>
  <block id="a81738572d94bce863615a7d94a84051" category="inline-link-macro">VMware vSphere용 SnapCenter 플러그인을 통한 간편한 데이터 보호</block>
  <block id="f09e9fdda59d2e9d9172bd89b5dc9369" category="list-text"><block ref="f09e9fdda59d2e9d9172bd89b5dc9369" category="inline-link-macro-rx"></block></block>
  <block id="c10a86f3b9530baf3bed3b02aaaf873f" category="section-title">VMware용 유연한 하이브리드 클라우드 및 현대화된 애플리케이션 인프라를 구축합니다</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="section-title">비디오</block>
  <block id="f20368920280b50131814db2f83fda66" category="inline-link-macro">NetApp All Flash FAS를 기반으로 VMware 데이터 저장소 설계</block>
  <block id="8ff6498eeabd53b4271d75f543dc3bc4" category="list-text"><block ref="8ff6498eeabd53b4271d75f543dc3bc4" category="inline-link-macro-rx"></block></block>
  <block id="841a1e2733baa662db1207d5075a798f" category="inline-link-macro">자동화해 봅시다. ONTAP을 사용하여 VMware 클라우드를 구축하십시오</block>
  <block id="4d0f73eb280cb12c373e099d1c320690" category="list-text"><block ref="4d0f73eb280cb12c373e099d1c320690" category="inline-link-macro-rx"></block></block>
  <block id="f1c2408ffc6e67ac6b34eb8da2b3039c" category="list-text"><block ref="f1c2408ffc6e67ac6b34eb8da2b3039c" category="inline-link-macro-rx"></block></block>
  <block id="253d309203cf1f2c1bb57255bd0a5bdc" category="inline-link-macro">VMware VM을 Google Cloud로 마이그레이션합니다</block>
  <block id="baa1898009cc7495f8c4e7732ce7433a" category="list-text"><block ref="baa1898009cc7495f8c4e7732ce7433a" category="inline-link-macro-rx"></block></block>
  <block id="7518aab5e189037f632ee46ea9e3cf07" category="video-title">VMware Tanzu용 동적 영구 NetApp 스토리지 구축 1부</block>
  <block id="f86bf601d6e42c44cf076ea1772ae13c" category="video-title">VMware Tanzu용 동적 영구 NetApp 스토리지 구축 2부</block>
  <block id="bf5c12d4eed319d2dc2b2b7279944f71" category="video-title">Deploying Dynamic Persistent NetApp Storage for VMware Tanzu, 3을 참조하십시오</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="section-title">블로그</block>
  <block id="a398d57165e21c951dd9c9def41598a9" category="inline-link-macro">AWS 기반 VMware 클라우드: Fujitsu가 CVO를 사용하여 수백만 달러를 절약하는 방법</block>
  <block id="d750d47d5e87a6c526e7b40e12eab95b" category="list-text"><block ref="d750d47d5e87a6c526e7b40e12eab95b" category="inline-link-macro-rx"></block></block>
  <block id="3ca2b14e719d79aed66780282e879db4" category="section-title">NetApp 및 VMware 전문가에게 문의하십시오</block>
  <block id="20475522c77401af1c203f23942ffda5" category="inline-link-macro">VMware 솔루션 토론 포럼에 참여하십시오</block>
  <block id="1dccc60a61431b3ef3f48709a0f68de7" category="list-text"><block ref="1dccc60a61431b3ef3f48709a0f68de7" category="inline-link-macro-rx"></block></block>
  <block id="a5810200dda7a3f37fc7eae5378cc8f3" category="inline-link-macro">시작하려면 NetApp 글로벌 서비스 팀에 문의하십시오</block>
  <block id="efb954cbfdbe0c54f04c904a2719b98a" category="list-text"><block ref="efb954cbfdbe0c54f04c904a2719b98a" category="inline-link-macro-rx"></block></block>
  <block id="a7ba4bd9aa10b0456b8f13ef40a2d1d5" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP 스토리지 FCoE VMFS 데이터 저장소를 구축하는 단계를 제공합니다.</block>
  <block id="1937a4bfde18bb02682d378132d0b6a9" category="doc">vSphere VMFS 데이터 저장소 - ONTAP를 사용하는 이더넷 스토리지 프로토콜을 통한 Fibre Channel</block>
  <block id="66439ac6171413528646918952bff23e" category="paragraph">이 섹션에서는 FCoE(Fibre Channel over Ethernet) 전송 프로토콜을 사용하여 ONTAP 스토리지로 VMFS 데이터 저장소를 생성하는 방법에 대해 설명합니다.</block>
  <block id="6b70d8f91894fa50b3c04af804f090b6" category="list-text">vSphere 환경 및 ONTAP를 관리하는 데 필요한 기본 기술</block>
  <block id="b087c7e1213b84e69de1a6e5214cd942" category="list-text">{ONTAP_VERSION}을 실행하는 ONTAP 스토리지 시스템(FAS/AFF/CVO/ONTAP Select</block>
  <block id="d9da372e69584852a9808bfa9fcc99a9" category="inline-link-macro">지원되는 FCoE 조합</block>
  <block id="b61947ecee08267d1f6930ccbd646d52" category="list-text"><block ref="b61947ecee08267d1f6930ccbd646d52" category="inline-link-macro-rx"></block></block>
  <block id="08b42ec45ef1147093b9161cc743b0a0" category="inline-link-macro">완성된 구성 워크시트</block>
  <block id="bcf78e9148ebbc12ed4a54d2149cc2bc" category="list-text"><block ref="bcf78e9148ebbc12ed4a54d2149cc2bc" category="inline-link-macro-rx"></block></block>
  <block id="24c066a87410cc7b08ad4b5ca45565d7" category="list-text">vCenter Server 자격 증명</block>
  <block id="c7f58b1f94665d7ebf6f107970d1b91b" category="list-text">vSphere 호스트 정보입니다</block>
  <block id="cdce6351191da46d795898e4570b8da2" category="list-text">{vSphere_version}</block>
  <block id="80ba2a0b5b5ae31742a18c682e724b6e" category="list-text">ONTAP FC 데이터 포트 또는 vSphere 호스트가 연결된 경우</block>
  <block id="52dd4b667b031cd80a33b9d176e43827" category="list-text">N_port ID 가상화(NPIV) 기능이 활성화된 경우</block>
  <block id="46fdd1539543376bfbbf2cc6da976539" category="list-text">단일 이니시에이터 단일 타겟 존을 생성합니다.</block>
  <block id="d7b3fbe677a7bffd7e387a3578d6b481" category="inline-link-macro">FC/FCoE 조닝 구성</block>
  <block id="434da439fcd2a7729ac67cef537d6651" category="list-text"><block ref="434da439fcd2a7729ac67cef537d6651" category="inline-link-macro-rx"></block></block>
  <block id="9068992a529de63b07b7c2250be12f87" category="list-text">네트워크 스위치</block>
  <block id="5d914ccaef7b5404838cb47cff27fa11" category="list-text">FCoE 지원</block>
  <block id="b74438cda33fca6618da9e30ef5fee5d" category="list-text">DCB 지원</block>
  <block id="69b788fe29f78e1fb439efd1bec08ab6" category="inline-link-macro">FCoE에 대한 점보 프레임입니다</block>
  <block id="e92f4c11834e879e94fa441894d8e9c9" category="list-text"><block ref="e92f4c11834e879e94fa441894d8e9c9" category="inline-link-macro-rx"></block></block>
  <block id="503023bddb3bd1c7803b35b4ace6aa7a" category="list-text">구축, 구성 및 바로 사용할 수 있는 VMware vSphere용 ONTAP 툴</block>
  <block id="42cdbee955a0e208306a321b74a948b1" category="section-title">VMFS 데이터 저장소를 프로비저닝합니다</block>
  <block id="f067d14dc86c5c0ec984803b3485a7a6" category="inline-link-macro">FCoE 구성이 지원되는지 확인합니다</block>
  <block id="79d164739c1e0aaf7f56e13c2a4c66ac" category="list-text"><block ref="4201ef99768aac8f72883e5cb6ec656f" category="inline-link-macro-rx"></block>.</block>
  <block id="7fcd357d480b8eaa4a38cdbbddfd6c97" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block></block>
  <block id="f2a0a9000f5ff3910235e570c0ac5e44" category="list-text">'system license show' 명령을 사용하여 FCP가 나열되는지 확인합니다.</block>
  <block id="8b3434ec0db76b4d537ae9c645aa913c" category="list-text">사용권을 추가하려면 'license add-license-code &lt;license code&gt;'를 사용하십시오.</block>
  <block id="e5b8ca3e9ff580bcc9315fabcb34312e" category="list-text">SVM에서 FCP 프로토콜이 활성화되어 있는지 확인합니다.</block>
  <block id="169e237a691059b9ac1933f0e7be8f56" category="inline-link-macro">기존 SVM에서 FCP를 확인합니다.</block>
  <block id="5bb60b756067a0334c310be1e2260c3b" category="list-text"><block ref="5bb60b756067a0334c310be1e2260c3b" category="inline-link-macro-rx"></block></block>
  <block id="fab6621b43b19a018afc1860a5b85c21" category="inline-link-macro">기존 SVM에서 FCP를 구성합니다.</block>
  <block id="7d4ca3fa89beb77990d305e17ed9ba64" category="list-text"><block ref="7d4ca3fa89beb77990d305e17ed9ba64" category="inline-link-macro-rx"></block></block>
  <block id="015c565181667d59b83b7761e35682d1" category="inline-link-macro">FCP를 사용하여 새 SVM을 생성합니다.</block>
  <block id="de4606f963140e2d2d0a3df251ffd646" category="list-text"><block ref="de4606f963140e2d2d0a3df251ffd646" category="inline-link-macro-rx"></block></block>
  <block id="2d6fd01ea0767b50e214a74ff1fcfae0" category="list-text">SVM에서 FCP 논리 인터페이스를 사용할 수 있는지 확인합니다.</block>
  <block id="46f04290f169589dff914e050d1a987b" category="list-text">GUI로 SVM을 생성할 때 논리 인터페이스는 이 프로세스의 일부입니다.</block>
  <block id="ee7f4720a3fc60686c4a9f7429a60cbc" category="list-text">네트워크 인터페이스의 이름을 바꾸려면 네트워크 인터페이스 수정 을 사용합니다.</block>
  <block id="6e67c7d604ae439f60ceb51480fdbb1c" category="inline-link-macro">LUN을 생성하고 매핑합니다</block>
  <block id="e4eeb9421963195597743339d2f38ff6" category="list-text"><block ref="96e32c32f267ac1d65d603f36f017a41" category="inline-link-macro-rx"></block>VMware vSphere용 ONTAP 툴을 사용하는 경우 이 단계를 건너뛰십시오.</block>
  <block id="e4f7ebeb9544fb23a73028ab714ca87c" category="section-title">VMware vSphere 작업</block>
  <block id="f6c0391a150cfd40a68682285c56e835" category="inline-link-macro">스토리지 어댑터 정보입니다</block>
  <block id="60f05805eb8189d665c19856d5388e3c" category="list-text">HBA 드라이버가 설치되어 있는지 확인합니다. VMware 지원 HBA에는 드라이버가 기본적으로 배포되어 있으며 에서 볼 수 있습니다 <block ref="c5f1cce809af8cfecf09908d33f4c097" category="inline-link-macro-rx"></block>.</block>
  <block id="c57f32bc5ce6f95f5f9bec8260ecdb08" category="inline-link-macro">ONTAP 툴을 사용하여 VMFS 데이터 저장소를 프로비저닝합니다</block>
  <block id="b3a5f140339b1ca0940c5875b2a76d0b" category="list-text"><block ref="89ebfed741bd060c10a4a1472581f4e2" category="inline-link-macro-rx"></block>.</block>
  <block id="fa7b524ea902bff51145e4279b653d84" category="summary">이 페이지에서는 비디오 및 자습서에 대한 소개 및 설명을 제공합니다.</block>
  <block id="246bb366fee5c7eda4fcd280728ec465" category="doc">하이브리드 클라우드, 데스크톱 가상화, 컨테이너 비디오 및 데모</block>
  <block id="d04d1afcb2d01179846658f678623306" category="paragraph">하이브리드 클라우드, 데스크톱 가상화 및 컨테이너 솔루션의 특정 기능을 소개하는 다음 비디오 및 데모를 참조하십시오.</block>
  <block id="4267881eb271396086a3cc1387da9a3a" category="section-title">NetApp과 VMware Tanzu</block>
  <block id="2dd739333b022cfeccd93e19c8c39d83" category="paragraph">VMware Tanzu를 사용하면 vSphere 또는 VMware Cloud Foundation을 통해 Kubernetes 환경을 구축, 관리 및 관리할 수 있습니다. 고객은 VMware의 이 제품 포트폴리오를 통해 요구사항에 가장 적합한 VMware Tanzu 에디션을 선택하여 단일 제어 플레인에서 모든 관련 Kubernetes 클러스터를 관리할 수 있습니다.</block>
  <block id="f8d0723a562ed498a977795477b75cb0" category="inline-link">VMware Tanzu 개요</block>
  <block id="2d3e9ef8ae693e8ff80c4d6e70f0a876" category="paragraph">VMware Tanzu에 대한 자세한 내용은 를 참조하십시오<block ref="1951d4038519ab642a1c0f8898cecfe0" category="inline-link-rx"></block>. 이 리뷰에서는 VMware Tanzu에 대한 사용 사례, 추가 기능 및 기타 정보를 제공합니다.</block>
  <block id="f90851c66bcfaa6ba091b34fe8a7428b" category="section-title">NetApp 및 VMware Tanzu 비디오 시리즈</block>
  <block id="31c49b154032d3d6039542b651e0f3d4" category="list-text"><block ref="31c49b154032d3d6039542b651e0f3d4" category="inline-link-rx"></block></block>
  <block id="fcf1189eaf4e4e32d27ee5174d63ae3c" category="list-text"><block ref="fcf1189eaf4e4e32d27ee5174d63ae3c" category="inline-link-rx"></block></block>
  <block id="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="list-text"><block ref="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="inline-link-rx"></block></block>
  <block id="20cf4402cce1622d010e58ef54b0c753" category="section-title">NetApp 및 Red Hat OpenShift의 조합</block>
  <block id="0454c59b86dfb678c92c2c7480958d1c" category="paragraph">엔터프라이즈 Kubernetes 플랫폼인 Red Hat OpenShift를 사용하면 오픈 하이브리드 클라우드 전략으로 컨테이너 기반 애플리케이션을 실행할 수 있습니다. Red Hat OpenShift는 주요 퍼블릭 클라우드 또는 자가 관리 소프트웨어에서 클라우드 서비스로 사용할 수 있으며 컨테이너 기반 솔루션을 설계할 때 고객이 필요로 하는 유연성을 제공합니다.</block>
  <block id="2426b725f5be26f50931584ae804c2eb" category="inline-link">Red Hat OpenShift 개요</block>
  <block id="ad973740d0b3378d367abba8a74a610e" category="paragraph">Red Hat OpenShift에 대한 자세한 내용은 다음을 참조하십시오<block ref="dc6de73076240cafa99651f2d6acfef4" category="inline-link-rx"></block>. 제품 설명서 및 배포 옵션을 검토하여 Red Hat OpenShift에 대해 자세히 알아볼 수도 있습니다.</block>
  <block id="282b81467c1dda139fb97c67a904cdcb" category="section-title">NetApp 및 Red Hat OpenShift 비디오</block>
  <block id="3699cb747ce71b2fed488fef61ad35be" category="inline-link">워크로드 마이그레이션 - NetApp의 Red Hat OpenShift</block>
  <block id="ade88b04ec62ed28eb857e48bc32cef5" category="list-text"><block ref="ade88b04ec62ed28eb857e48bc32cef5" category="inline-link-rx"></block></block>
  <block id="68d13ef3d87e892878a6e6cbb44d1f21" category="inline-link">RHV 기반 Red Hat OpenShift Deployment: NetApp 기반 Red Hat OpenShift</block>
  <block id="a2f2cd3053597e34724347a57620122b" category="list-text"><block ref="a2f2cd3053597e34724347a57620122b" category="inline-link-rx"></block></block>
  <block id="2093983846bbd6cd7e3d486531259f7d" category="summary">이 페이지에서는 ONTAP 및 VMware vSphere에서 사용할 수 있는 하이브리드 클라우드 기능에 대해 설명합니다.</block>
  <block id="df94231e8c7a2b7372365ba3eb8ad621" category="doc">ONTAP 및 vSphere 기반의 하이브리드 클라우드</block>
  <block id="c689fcb3c54ae34ac006a005e03aad07" category="section-title">하이브리드 클라우드에 대해 알아보십시오</block>
  <block id="cc81a55aaf5bd2bdf603a2aea92a875a" category="paragraph">ONTAP 솔루션은 사내 프라이빗 클라우드, 퍼블릭 클라우드 인프라 또는 두 클라우드의 장점인 하이브리드 클라우드를 사용하든 데이터 관리를 간소화하고 최적화할 수 있도록 Data Fabric을 구축할 수 있도록 도와줍니다. 고성능 All-Flash 시스템으로 시작한 다음 디스크 또는 클라우드 스토리지 시스템과 커플하여 데이터 보호 및 클라우드 컴퓨팅을 지원합니다.</block>
  <block id="9afb01441ce427bb3863eaccd46b9b5d" category="paragraph">Azure, AWS, IBM 또는 Google 클라우드 중에서 선택하여 비용을 최적화하고 종속 문제를 방지합니다. OpenStack 및 컨테이너 기술에 대한 고급 지원을 필요에 따라 활용합니다.</block>
  <block id="8a61dac106bf2a7f3b869c8ff58c4ce5" category="paragraph">데이터 보호는 고객이 클라우드 여정을 시작할 때 가장 먼저 시도하는 경우가 많습니다. 주요 데이터의 비동기식 복제만큼 간편하게 보호할 수 있으며 전체 핫 백업 사이트만큼 복잡해질 수 있습니다. 데이터 보호는 기본적으로 NetApp SnapMirror 기술을 기반으로 합니다.</block>
  <block id="d059ff0a497ad1427248dbb8f770b1d5" category="paragraph">일부 고객은 전체 워크로드를 클라우드로 이동하도록 선택합니다. 이는 단순히 클라우드를 데이터 보호에 사용하는 것보다 더 복잡할 수 있지만 클라우드 기반 스토리지를 사용하기 위해 애플리케이션을 재작성할 필요가 없기 때문에 ONTAP를 사용하면 손쉽게 이전할 수 있습니다. 클라우드의 ONTAP는 사내 ONTAP처럼 작동합니다. 사내 ONTAP 시스템은 더 적은 물리적 공간에 더 많은 데이터를 저장하고 거의 사용되지 않는 데이터를 계층화하여 스토리지 비용을 절감할 수 있는 데이터 효율성 기능을 제공합니다. 하이브리드 클라우드 구성을 사용하거나 전체 워크로드를 클라우드로 이동할 때 ONTAP은 스토리지 성능 및 효율성을 극대화합니다.</block>
  <block id="ad622d292f56f20b32a61fe1b8bd2f56" category="paragraph">또한 NetApp은 ONTAP용 클라우드 기반 백업(SnapMirror 클라우드, Cloud Backup Service 및 Cloud Sync), 스토리지 계층화 및 아카이빙 툴(FabricPool)을 제공하여 운영 비용을 줄이고 광범위한 클라우드 활용을 지원합니다.</block>
  <block id="49c437176039e1c910728eac1f332689" category="paragraph">다음 그림은 샘플 하이브리드 클라우드 사용 사례를 보여줍니다.</block>
  <block id="e61ead4102c89a9758572df81301a1d2" category="inline-image-macro">하이브리드 클라우드</block>
  <block id="9188eeccf6b5386d9573cea87cf05102" category="paragraph"><block ref="9188eeccf6b5386d9573cea87cf05102" category="inline-image-macro-rx" type="image"></block></block>
  <block id="293f510d2162f186910d817d97121159" category="inline-link">ONTAP과 클라우드</block>
  <block id="3963100a9d31ca50911a23ac5c87aca1" category="admonition">ONTAP 및 하이브리드 클라우드에 대한 자세한 내용은 를 참조하십시오<block ref="92883b1d8840f28e1ad4810811bf56b5" category="inline-link-rx"></block> ONTAP 9 문서 센터</block>
  <block id="01a7d7174ccc6593753679eefec17d49" category="summary">이 페이지에서는 VMware vSphere 환경에서 기본 ONTAP 기능을 자동화할 때의 이점에 대해 설명합니다.</block>
  <block id="1406aa071af210d31c6a2951fe66ddcc" category="doc">ONTAP 및 vSphere 자동화 소개</block>
  <block id="8e2b0503a0ad76f57c96738d7f0a3b0d" category="section-title">VMware 자동화</block>
  <block id="b5845209cb81dad561de4abe6e4481c4" category="paragraph">자동화는 VMware ESX의 첫 날부터 VMware 환경을 관리하는 데 있어 필수적인 요소입니다. 코드로 인프라를 구축하고 프라이빗 클라우드 운영으로 사례를 확장하는 기능은 확장, 유연성, 셀프 프로비저닝 및 효율성에 관한 문제를 해결하는 데 도움이 됩니다.</block>
  <block id="f7c9a2e2ec395a7e4b605bb3df40abf8" category="paragraph">자동화는 다음 범주로 구성할 수 있습니다.</block>
  <block id="cba6f5a209d4f2ac1839f1c1e0a10051" category="list-text">* 가상 인프라 구축 *</block>
  <block id="f41d0733c4edc0bf273a3d0587efb21e" category="list-text">* 게스트 시스템 작동 *</block>
  <block id="7f2a4b0fa787b1f058accb56cc377af8" category="list-text">* 클라우드 운영 *</block>
  <block id="290a03d97ea4e48144d20f313e0a0826" category="paragraph">관리자는 인프라 자동화와 관련하여 다양한 옵션을 사용할 수 있습니다. 호스트 프로필 등의 기본 vSphere 기능 또는 가상 머신에 대한 사용자 지정 사양을 VMware 소프트웨어 구성 요소, 운영 체제 및 NetApp 스토리지 시스템의 사용 가능한 API에 사용할 수 있는지 여부와 관계없이, 관련 설명서와 지침을 참조할 수 있습니다.</block>
  <block id="217dd73ccc3bd89b5d4e35d0bf50ea6c" category="paragraph">Data ONTAP 8.0.1 이상은 ESX 호스트가 ESX 4.1 이상을 실행하는 경우 VAAI(VMware vSphere APIs for Array Integration) 기능을 지원합니다. VAAI는 VMware vSphere ESXi 호스트와 스토리지 디바이스 간의 통신을 지원하는 API 세트입니다. 이러한 기능은 ESX 호스트에서 스토리지 시스템으로 작업을 오프로드하고 네트워크 처리량을 늘리는 데 도움이 됩니다. ESX 호스트는 올바른 환경에서 자동으로 기능을 활성화합니다. VAAI 카운터에 포함된 통계를 확인하여 시스템에서 VAAI 기능을 사용하는 범위를 결정할 수 있습니다.</block>
  <block id="16123583d64fd438c5d7f5b61a1c1d2f" category="paragraph">VMware 환경 구축을 자동화하는 가장 일반적인 시작 지점은 프로비저닝 블록 또는 파일 기반 데이터 저장소입니다. 해당 자동화를 개발하기 전에 실제 작업의 요구 사항을 매핑하는 것이 중요합니다.</block>
  <block id="a78bd4dd1db96affe0c2889376cccf53" category="paragraph">VMware 환경 자동화에 대한 자세한 내용은 다음 리소스를 참조하십시오.</block>
  <block id="ebd98e15bf07fe37dfdc879f9d0d1f48" category="inline-link">NetApp 펍</block>
  <block id="6123648b7dec055b609781b4d47c1b26" category="list-text"><block ref="6c65ff4f1dfb7aa26df896b1c9c849eb" category="inline-link-rx"></block>. NetApp 구성 관리 및 자동화:</block>
  <block id="7c4272bef0cc405b65fc74e3791664bc" category="inline-link">VMware용 Ansible Galaxy 커뮤니티</block>
  <block id="59fb42204e71850f7fd7024e5e6a1058" category="list-text"><block ref="c471bcaf7efa6fb129f37edaa7c41a56" category="inline-link-rx"></block>. VMware를 위한 Ansible 리소스 모음입니다.</block>
  <block id="1ec695bd70399ce37180f1d84a33d151" category="inline-link">VMware {code} 리소스</block>
  <block id="489c5322cef99651507b070e2240b6a8" category="list-text"><block ref="77e0562f07512a7a248241b7170b6944" category="inline-link-rx"></block>. 포럼, 설계 표준, 샘플 코드 및 개발자 도구를 비롯하여 소프트웨어 정의 데이터 센터를 위한 솔루션을 설계하는 데 필요한 리소스입니다.</block>
  <block id="c9b6ad26821d78c27282a65584d5f485" category="summary">NetApp은 온프레미스와 클라우드 모두에서 강력한 가상화 환경을 위한 다수의 모범 사례와 솔루션을 제공합니다.</block>
  <block id="ba64ee63cc4950b57bfb868fabec0db3" category="doc">가상화를 위한 NetApp 솔루션</block>
  <block id="334af7a3f788d83aa889d1ca7bd769f5" category="summary">이 페이지에서는 ONTAP의 스토리지 효율성을 설명합니다.</block>
  <block id="c13f924c3ceac59a16a8a1ea96d43c91" category="doc">ONTAP 스토리지 효율성</block>
  <block id="241a4f0482dfad2f5fc79419b18356c0" category="section-title">이야기를 자세히 알아보십시오</block>
  <block id="185081022bfbcfda8db4798eb4eed8c0" category="paragraph">NetApp은 운영 워크로드에 대한 중복 제거 기능을 최초로 제공했지만 이 분야에서 최초이자 마지막 기술이 아니었습니다. 공간 효율적인 데이터 보호 메커니즘인 ONTAP 스냅샷 복사본에서 시작되어, 성능 저하 없이 VM의 읽기/쓰기 복사본을 즉시 만들어 운영 및 백업을 지원합니다. NetApp은 계속해서 중복제거, 압축, 제로 블록 중복제거 등과 같은 인라인 기능을 제공하여 고가의 SSD에서 최대한의 스토리지를 짜내었습니다. 가장 최근에 ONTAP은 컴팩션을 추가하여 스토리지 효율성을 강화합니다.</block>
  <block id="d019495551b4899a9019567122f1e076" category="list-text">* 인라인 제로 블록 중복제거. * 제로 블록 전체에서 낭비되는 공간을 없앱니다.</block>
  <block id="7634d08ecc5702f74271a3313502ec02" category="list-text">* 인라인 압축 * 데이터 블록을 압축하여 필요한 물리적 스토리지의 양을 줄입니다.</block>
  <block id="8b7bb53489bfc2a6808c1d76314fa0d4" category="list-text">* 인라인 데이터 중복 제거. * 디스크에 있는 기존 블록을 사용하여 들어오는 블록을 제거합니다.</block>
  <block id="b762ae2f528b0eca55e7be3f599e909d" category="list-text">* 인라인 데이터 컴팩션 * 소규모 I/O 작업과 파일을 각 물리적 블록에 압축</block>
  <block id="fba6442665875d123719f22baafc619d" category="inline-image-macro">스토리지 효율성</block>
  <block id="f468c00b41afc3485647008dcf80cba1" category="paragraph"><block ref="f468c00b41afc3485647008dcf80cba1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8405ea940cfeab85adddf9d3ed915a97" category="paragraph">중복제거, 데이터 압축, 데이터 컴팩션을 함께 실행하거나 독립적으로 실행하여 FlexVol 볼륨에서 최적의 공간 절약 효과를 달성할 수 있습니다. 이러한 기능을 결합하여 고객은 VSI의 경우 최대 5:1, VDI의 경우 최대 30:1의 비용을 절감할 수 있었습니다.</block>
  <block id="b8c11cd315128247329c3d878c2143fe" category="inline-link">중복제거, 데이터 압축, 데이터 컴팩션을 사용하여 스토리지 효율성을 높입니다</block>
  <block id="65bbb718266195d68e8d1accfc443e28" category="admonition">ONTAP 스토리지 효율성에 대한 자세한 내용은 를 참조하십시오<block ref="f358a7faf94e9f579d11f8fc4efdbdec" category="inline-link-rx"></block> ONTAP 9 문서 센터</block>
  <block id="02d4482d332e1aef3437cd61c9bcc624" category="doc">문의하기</block>
  <block id="3dd3a0a8eebc543e239dc4af5d76b322" category="paragraph">이 기술 보고서에 대한 의견이 있으십니까?</block>
  <block id="3c48757505a122bf371d1bf0105b6871" category="paragraph">이메일 주소는 doccomments@netapp.com 으로 보내주시고 제목 줄에 TR-4597을 포함시키십시오.</block>
  <block id="3b2287aeb862e195f44c02694fff89fe" category="summary">SnapCenter를 사용하면 여러 작업에 적용할 수 있는 백업 정책을 생성할 수 있습니다. 이러한 정책은 스케줄, 보존, 복제 및 기타 기능을 정의할 수 있습니다. VMware 스냅샷을 생성하기 전에 하이퍼바이저의 I/O 중지 기능을 활용하는 VM 정합성 보장 스냅샷을 옵션으로 선택할 수 있습니다.</block>
  <block id="b1c93d491ba776d955eb2e3b90908fb9" category="doc">기타 vSphere 기능</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="section-title">데이터 보호</block>
  <block id="343775d7b18c4ca0af9b7fad57690839" category="paragraph">VM을 백업하고 신속하게 복구하는 것은 ONTAP for vSphere의 탁월한 강점 중 하나로서, vCenter에서 VMware vSphere용 SnapCenter 플러그인을 사용하여 이러한 기능을 쉽게 관리할 수 있습니다. Snapshot 복사본을 사용하여 성능에 영향을 주지 않고 VM 또는 데이터 저장소의 빠른 복사본을 만든 다음 SnapMirror를 사용하여 보조 시스템으로 보내 장기적인 오프 사이트 데이터 보호를 제공할 수 있습니다. 이러한 접근 방식은 변경된 정보만 저장하여 스토리지 공간과 네트워크 대역폭을 최소화합니다.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">권장</block>
  <block id="8cc688149346249b3a92e59282755f3e" category="paragraph">SnapCenter를 사용하면 여러 작업에 적용할 수 있는 백업 정책을 생성할 수 있습니다. 이러한 정책은 스케줄, 보존, 복제 및 기타 기능을 정의할 수 있습니다. VMware 스냅샷을 생성하기 전에 하이퍼바이저의 I/O 중지 기능을 활용하는 VM 정합성 보장 스냅샷을 옵션으로 선택할 수 있습니다. 그러나 VMware 스냅샷의 성능 때문에 게스트 파일 시스템을 중지해야 하는 경우가 아니면 일반적으로 이러한 스냅샷을 사용하지 않는 것이 좋습니다. 대신 ONTAP 스냅샷 복사본을 일반 보호에 사용하고 SnapCenter 플러그인과 같은 애플리케이션 툴을 사용하여 SQL Server 또는 Oracle 등의 트랜잭션 데이터를 보호합니다. 이러한 스냅샷 복사본은 VMware(정합성 보장) 스냅샷과 다르며 장기 보호에 적합합니다. VMware 스냅샷은 전용입니다<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> 성능 및 기타 효과로 인한 단기 사용.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">이러한 플러그인은 물리적 환경과 가상 환경 모두에서 데이터베이스를 보호하는 확장된 기능을 제공합니다. vSphere를 사용하면 RDM LUN에 데이터가 저장되어 있는 SQL Server 또는 Oracle 데이터베이스, 게스트 OS에 직접 연결된 iSCSI LUN 또는 VMFS 또는 NFS 데이터 저장소의 VMDK 파일을 보호할 수 있습니다. 플러그인을 사용하면 다양한 유형의 데이터베이스 백업을 지정할 수 있고, 온라인 또는 오프라인 백업을 지원하고, 로그 파일과 함께 데이터베이스 파일을 보호할 수 있습니다. 플러그인은 백업 및 복구 외에도 개발 또는 테스트 용도로 데이터베이스 클론 복제도 지원합니다.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">다음 그림은 SnapCenter 구축의 예를 보여 줍니다.</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">향상된 재해 복구 기능을 위해 ONTAP용 NetApp SRA를 VMware Site Recovery Manager와 함께 사용하는 것이 좋습니다. 데이터 저장소를 DR 사이트로 복제할 수 있을 뿐만 아니라, 복제된 데이터 저장소를 클론 복제하여 DR 환경에서 무중단 테스트를 수행할 수도 있습니다. SRA에 내장된 자동화를 통해 운영 중단이 해결된 후 재해 복구 및 운영 재보호 작업도 쉽게 수행할 수 있습니다.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">마지막으로, 최고 수준의 데이터 보호를 위해 NetApp MetroCluster를 사용하는 VMware vMSC(vSphere Metro Storage Cluster) 구성을 고려해 보십시오. vMSC는 동기식 복제와 스토리지 기반 클러스터링이 결합된 VMware 인증 솔루션으로, 고가용성 클러스터의 이점을 동일하게 제공하고 별도의 사이트에 분산하여 사이트 재해로부터 보호합니다. NetApp MetroCluster은 단일 스토리지 구성 요소 장애로부터 투명하게 복구하고 사이트 재해 발생 시 단일 명령 복구를 통해 동기식 복제를 위한 비용 효율적인 구성을 제공합니다. vMSC는 에 자세히 설명되어 있습니다<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">공간 재확보</block>
  <block id="d490382851fbc5bd6720046bf9bc0c03" category="paragraph">VM이 데이터 저장소에서 삭제될 때 공간을 다른 용도로 재확보할 수 있습니다. NFS 데이터 저장소를 사용할 경우 VM이 삭제될 때 공간이 즉시 재확보됩니다. 물론 이 방법은 볼륨이 씬 프로비저닝될 때만 의미가 있습니다. 즉, 볼륨 보장이 없음으로 설정됩니다. 하지만 VM 게스트 OS 내에서 파일이 삭제되면 NFS 데이터 저장소에서 공간이 자동으로 재확보되지 않습니다. LUN 기반 VMFS 데이터 저장소의 경우 ESXi 및 게스트 OS에서 VAAI UNMAP 프리미티브를 스토리지에 발급하여(씬 프로비저닝을 사용하는 경우 다시) 공간을 재확보할 수 있습니다. 릴리스에 따라 이 지원은 수동 또는 자동입니다.</block>
  <block id="6a2bff0a8d10ca0fc6c782e7978f696a" category="inline-link">2057513</block>
  <block id="8927aab76c49d1deb0b407fd261d5aa6" category="inline-link">저장 공간 재확보</block>
  <block id="0c5a70f66ff77925d7dd7192191ec8f2" category="paragraph">vSphere 5.5 이상에서는 "vmkfstools –y" 명령이 사용 가능한 블록 수를 지정하는 esxcli storage vmfs unmap" 명령으로 대체됩니다(VMware KB 참조)<block ref="1d61bd4e8925f7d5aac61e083b728439" category="inline-link-rx"></block> 참조). vSphere 6.5 이상에서는 VMFS 6을 사용할 때 공간이 자동으로 비동기적으로 재확보되어야 합니다(참조)<block ref="a9ae15a1c91a14939aefb313015202e6" category="inline-link-rx"></block> vSphere 설명서 참조), 필요한 경우 수동으로 실행할 수도 있습니다. 이 자동 UNMAP은 ONTAP에서 지원되며, VMware vSphere용 ONTAP 툴을 사용하면 우선 순위가 낮습니다.</block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="section-title">VM 및 데이터 저장소 클론 생성</block>
  <block id="d355cf5d1a16095124a54902f7cf49db" category="paragraph">스토리지 객체를 클론 복제하면 추가 VM 프로비저닝, 백업/복구 작업 등과 같은 추가 사용을 위한 복사본을 빠르게 생성할 수 있습니다. vSphere에서 VM, 가상 디스크, VVOL 또는 데이터 저장소를 복제할 수 있습니다. 복제된 개체는 대개 자동화된 프로세스를 통해 추가로 사용자 지정할 수 있습니다. vSphere는 전체 복제본 클론과 연결된 클론을 모두 지원하며, 이 클론에서는 원래 객체와 별도로 변경 사항을 추적합니다.</block>
  <block id="78f8f8d69825dfe8e6085151fa565f28" category="paragraph">연결된 클론은 공간을 절약하는 데 좋지만 vSphere에서 VM에 대해 처리하는 I/O 양을 늘려 해당 VM 및 호스트의 성능에 영향을 줄 수 있습니다. 이것이 바로 NetApp 고객이 스토리지 시스템 기반 복제본을 사용하여 두 가지 기능을 최대한 활용하는 경우가 많은 이유입니다. 즉, 스토리지를 효율적으로 사용하고 성능을 향상시킬 수 있습니다.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">다음 그림은 ONTAP 클론을 보여 줍니다.</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">클론 복제는 일반적으로 VM, VVOL 또는 데이터 저장소 레벨의 다양한 메커니즘을 통해 ONTAP 소프트웨어를 실행하는 시스템으로 오프로드될 수 있습니다. 여기에는 다음이 포함됩니다.</block>
  <block id="3b6d066ffdecb2beb542ef68e773d4ae" category="list-text">NetApp VASA(vSphere APIs for Storage Awareness) 공급자를 사용하여 VVOL을 이동합니다. ONTAP 클론은 최소한의 I/O 효과로 vCenter에서 관리하는 VVOL 스냅샷 복사본을 생성 및 삭제하는 데 사용됩니다. vCenter를 사용하여 VM을 복제할 수도 있으며, 단일 데이터 저장소/볼륨 내에서 또는 데이터 저장소/볼륨 간에 ONTAP로 오프로드됩니다.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">VAAI(vSphere API – Array Integration)를 사용한 vSphere 클론 생성 및 마이그레이션 SAN 및 NAS 환경 모두에서 VM 클론 복제 작업을 ONTAP로 오프로드할 수 있습니다(NetApp은 NFS용 VAAI를 지원하기 위해 ESXi 플러그인을 제공합니다). vSphere는 NAS 데이터 저장소의 콜드(전원이 꺼진) VM에 대한 작업만 오프로드하는 반면, 핫 VM(클론 생성 및 Storage vMotion)에 대한 작업도 SAN에 오프로드됩니다. ONTAP는 소스, 대상 및 설치된 제품 라이센스를 기반으로 가장 효율적인 방식을 사용합니다. 이 기능은 VMware Horizon View에서 사용할 수도 있습니다.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA(VMware Site Recovery Manager와 함께 사용) 이 경우 클론은 DR 복제본의 복구를 중단 없이 테스트하는 데 사용됩니다.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">SnapCenter와 같은 NetApp 툴을 사용한 백업 및 복구 VM 클론은 백업 작업을 확인하는 데 사용되며 개별 파일을 복제할 수 있도록 VM 백업을 마운트하는 데 사용됩니다.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">ONTAP 오프로드 클론 복제는 VMware, NetApp 및 타사 툴에서 호출할 수 있습니다. ONTAP로 오프로드되는 클론에는 여러 가지 이점이 있습니다. 대부분의 경우 오브젝트 변경에만 스토리지가 필요한 공간 효율적이며, 데이터를 읽고 쓰는 데는 추가 성능 영향이 없으며, 고속 캐시에서 블록을 공유하여 성능을 향상할 수도 있습니다. 또한 CPU 사이클과 네트워크 I/O를 ESXi 서버에서 오프로드합니다. FlexClone 라이센스가 있는 경우 FlexVol 볼륨을 사용하는 기존 데이터 저장소 내에서 복사 오프로드를 빠르고 효율적으로 수행할 수 있지만, FlexVol 볼륨 간의 복사 속도가 느려질 수 있습니다. VM 템플릿을 클론의 소스로 유지 관리하는 경우 빠르고 공간 효율적인 클론을 위해 데이터 저장소 볼륨(폴더 또는 콘텐츠 라이브러리를 사용하여 구성) 내에 배치하는 것이 좋습니다.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">ONTAP 내에서 직접 볼륨 또는 LUN을 복제하여 데이터 저장소를 복제할 수도 있습니다. NFS 데이터 저장소를 사용하면 FlexClone 기술을 통해 전체 볼륨을 클론 복제할 수 있으며, ONTAP에서 클론을 내보내고 ESXi에서 다른 데이터 저장소로 마운트할 수 있습니다. VMFS 데이터 저장소의 경우 ONTAP는 LUN 내에 하나 이상의 LUN을 포함하여 볼륨 또는 전체 볼륨 내에서 LUN을 클론 복제할 수 있습니다. VMFS를 포함하는 LUN은 ESXi 이니시에이터 그룹(igroup)에 매핑한 다음 ESXi에 의해 재서명하여 일반 데이터 저장소로 마운트하고 사용해야 합니다. 일부 임시 사용 사례에서는 재서명 없이 클론 생성된 VMFS를 마운트할 수 있습니다. 데이터 저장소의 클론을 생성한 후에는 해당 데이터 저장소 내의 VM을 개별적으로 클론 복제된 VM처럼 등록, 재구성 및 사용자 지정할 수 있습니다.</block>
  <block id="1c12a8dd266e356901d22c0b7711369d" category="paragraph">경우에 따라 라이센스가 부여된 추가 기능을 사용하여 백업용 SnapRestore 또는 FlexClone과 같은 복제를 향상시킬 수 있습니다. 이러한 라이센스는 라이센스 번들에 추가 비용 없이 포함되는 경우가 많습니다. VVOL 클론 복제 작업은 물론 VVOL(하이퍼바이저에서 ONTAP으로 오프로드됨)의 관리되는 스냅샷 복사본을 지원하려면 FlexClone 라이센스가 필요합니다. FlexClone 라이센스는 데이터 저장소/볼륨 내에서 사용할 때 특정 VAAI 기반 클론을 개선할 수도 있습니다. 블록 복사본 대신 즉각적이고 공간 효율적인 복사본을 생성합니다. 또한 SRA에서는 DR 복제본의 복구를 테스트할 때, 클론 작업을 위한 SnapCenter 및 개별 파일을 복원할 백업 복사본을 찾아볼 때 사용됩니다.</block>
  <block id="6d30b2619de7fa18e965516b291a1937" category="section-title">스토리지 효율성 및 씬 프로비저닝</block>
  <block id="616c027f14ee5f1bbc866171c4017141" category="paragraph">NetApp은 운영 워크로드를 위한 최초의 중복제거, 압축을 강화하고 작은 파일 및 I/O를 효율적으로 저장하는 인라인 데이터 컴팩션 등의 스토리지 효율성 혁신을 통해 업계를 선도하고 있습니다. ONTAP는 인라인 및 백그라운드 중복제거와 인라인 및 백그라운드 압축을 모두 지원합니다.</block>
  <block id="8f105eeb6dc3fc4ce0d4758aeab4a256" category="paragraph">다음 그림은 ONTAP 스토리지 효율성 기능이 결합된 결과를 보여 줍니다.</block>
  <block id="4b7a9b58ab55917c054d5a636481a8b8" category="paragraph"><block ref="4b7a9b58ab55917c054d5a636481a8b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e89f9787f44321e33f85595321efc66" category="paragraph">vSphere 환경에서 ONTAP 스토리지 효율성을 사용하는 방법은 다음과 같습니다.</block>
  <block id="c2eea4e122397fa75d749bdbdcd4302d" category="list-text">데이터 중복 제거 절감 효과는 데이터의 공통성을 기반으로 합니다. ONTAP 9.1 이전 버전에서는 데이터 중복제거가 볼륨 레벨에서 작동되지만 ONTAP 9.2 이상의 애그리게이트 중복제거 기능을 사용하면 AFF 시스템의 애그리게이트에서 모든 볼륨에서 데이터가 중복 제거됩니다. 더 이상 단일 데이터 저장소 내에서 유사한 운영 체제 및 유사한 애플리케이션을 그룹화하지 않아도 절감 효과를 극대화할 수 있습니다.</block>
  <block id="59eb554aa77d0e4dfdc304b3b914dd76" category="list-text">블록 환경에서 중복 제거의 이점을 실현하려면 LUN을 씬 프로비저닝해야 합니다. LUN이 여전히 VM 관리자가 프로비저닝된 용량을 차지하는 것으로 보이더라도 중복 제거 절약 효과가 다른 요구에 사용될 볼륨으로 반환됩니다. 씬 프로비저닝된 FlexVol 볼륨에 이러한 LUN을 구축하는 것이 좋습니다. VMware vSphere용 ONTAP 툴은 LUN보다 볼륨 크기를 약 5% 더 크게 조정합니다.</block>
  <block id="1e84230a4e75abc233d64344b14fd511" category="list-text">NFS FlexVol 볼륨에는 씬 프로비저닝도 권장(및 기본값)되어 있습니다. NFS 환경에서는 씬 프로비저닝된 볼륨을 사용하는 스토리지 및 VM 관리자 모두가 중복제거 절약 효과를 즉시 확인할 수 있습니다.</block>
  <block id="b26ed63d0f1199652537e2c4b6752130" category="list-text">씬 프로비저닝은 VM에도 적용되며, NetApp은 일반적으로 일반 파일 대신 씬 프로비저닝된 VMDK를 권장합니다. 씬 프로비저닝을 사용할 때는 ONTAP vSphere, ONTAP 또는 기타 사용 가능한 툴을 사용하여 사용 가능한 공간을 모니터링하여 공간 부족 문제를 방지해야 합니다.</block>
  <block id="041f3a2c9d939c181dbd2a95595455d0" category="list-text">ONTAP 시스템에서 씬 프로비저닝을 사용할 경우 성능 저하가 발생하지 않습니다. 데이터는 사용 가능한 공간에 작성되므로 쓰기 성능과 읽기 성능이 극대화됩니다. 이러한 사실에도 불구하고 Microsoft 장애 조치 클러스터링 또는 기타 지연 시간이 짧은 애플리케이션과 같은 일부 제품은 보장되거나 고정 프로비저닝이 필요할 수 있으며, 지원 문제를 피하기 위해 이러한 요구사항을 따르는 것이 좋습니다.</block>
  <block id="473c8efc5f9b8640820a9cc1f9c84862" category="list-text">중복 제거를 최대한 절약하기 위해서는 하드 디스크 기반 시스템에서 백그라운드 중복제거를 예약하거나 AFF 시스템에서 자동 백그라운드 중복제거를 사용하는 것이 좋습니다. 그러나 예약된 프로세스는 실행 시 시스템 리소스를 사용하므로 주말과 같이 사용량이 적은 시간에 일정을 계획하거나 자주 실행하여 변경된 데이터 처리 양을 줄이는 것이 좋습니다. AFF 시스템에서 자동 백그라운드 중복 제거를 수행하면 전경 작업에 미치는 영향이 훨씬 적습니다. 백그라운드 압축(하드 디스크 기반 시스템의 경우)도 리소스를 사용하므로 성능 요구사항이 제한적인 2차 워크로드에만 고려해야 합니다.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">KB 문서를 참조하십시오</block>
  <block id="ac2fab512a521d04e53c7257ef490187" category="list-text">NetApp AFF 시스템은 주로 인라인 스토리지 효율성 기능을 사용합니다. 7-Mode Transition Tool, SnapMirror 또는 Volume Move와 같은 블록 복제를 사용하는 NetApp 툴을 사용하여 데이터를 해당 데이터 위치로 이동할 경우, 압축 및 컴팩션 스캐너를 실행하여 효율성 절약 효과를 극대화하는 것이 좋습니다. 이 NetApp Support를 검토하십시오<block ref="a24ae202a787a3e4695f02339b72bb57" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="af21d2d4e0d0faaa6435e780ed7fbc49" category="list-text">스냅샷 복사본은 압축 또는 중복제거에 의해 줄어들 수 있는 블록을 잠글 수 있습니다. 예약된 백그라운드 효율성 또는 일회성 스캐너를 사용할 때는 다음 스냅샷 복사본을 생성하기 전에 이러한 작업이 실행되고 완료되었는지 확인하십시오. 스냅샷 복사본 및 보존을 검토하여 백그라운드 또는 스캐너 작업을 실행하기 전에 필요한 스냅샷 복사본만 보존하는지 확인합니다.</block>
  <block id="8f4468ee9f4f074a9f705cd8240de3d9" category="paragraph">다음 표에는 여러 유형의 ONTAP 스토리지에서 가상화된 워크로드를 위한 스토리지 효율성 지침이 나와 있습니다.</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">워크로드</block>
  <block id="84f3306d313cbbe707b0df3807aa77ef" category="cell">스토리지 효율성 지침</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="5325da9878854628027602da18e5fc14" category="cell">Flash Pool을 참조하십시오</block>
  <block id="9aa1187640093122ffdb7e1c18f8586d" category="cell">하드 디스크 드라이브</block>
  <block id="9bbf225892f3ce69fc504d145abe3ded" category="cell">VDI 및 SVI</block>
  <block id="1be6174441cf80d01c59eb7a9c004498" category="paragraph">운영 워크로드 및 보조 워크로드에는 다음 사용:</block>
  <block id="738b6df06bc30a1f2fa6d500095bfceb" category="list-text">적응형 인라인 압축</block>
  <block id="f801303ba7009e27cce2fe9a73dc5ebe" category="list-text">인라인 중복제거</block>
  <block id="f94a70bfe4407315e07db5e64706e531" category="list-text">백그라운드 중복제거</block>
  <block id="95f3762d2d933ff2c0f6e30ef2c767c9" category="list-text">인라인 데이터 컴팩션</block>
  <block id="22be9b04282591df89574efb0e9d2315" category="paragraph">운영 워크로드에는 다음 사용:</block>
  <block id="e37f23785e68eb0a9d5afd7457b0903e" category="paragraph">보조 워크로드에는 다음 사용:</block>
  <block id="7901e1160498e7aff40dc0f858411c54" category="list-text">적응형 백그라운드 압축</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="section-title">서비스 품질(QoS)</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템에서는 ONTAP 스토리지 QoS 기능을 사용하여 파일, LUN, 볼륨 또는 전체 SVM과 같은 다양한 스토리지 개체에 대해 Mbps 또는 IOPS 단위로 처리량을 제한할 수 있습니다.</block>
  <block id="fb4aa9631cd742ae8a88f672b4464b37" category="paragraph">처리량 제한은 다른 워크로드에 영향을 주지 않도록 구축하기 전에 알 수 없거나 워크로드를 테스트하는 데 유용합니다. 이러한 워크로드는 식별된 후 대규모 워크로드를 제한하는 데 사용할 수도 있습니다. ONTAP 9.2의 SAN 오브젝트 및 ONTAP 9.3의 NAS 오브젝트에 대해 일관된 성능을 제공하기 위해 IOPS를 기반으로 하는 최소 서비스 레벨도 지원됩니다.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">NFS 데이터 저장소를 사용하면 QoS 정책을 전체 FlexVol 볼륨 또는 해당 볼륨 내의 개별 VMDK 파일에 적용할 수 있습니다. ONTAP LUN을 사용하는 VMFS 데이터 저장소의 경우 FlexVol가 VMFS 파일 시스템을 인식하지 못하기 때문에 QoS 정책을 LUN 또는 개별 LUN을 포함하는 ONTAP 볼륨에 적용할 수 있지만 개별 VMDK 파일은 적용할 수 없습니다. VVOL을 사용할 경우 스토리지 용량 프로파일 및 VM 스토리지 정책을 사용하여 개별 VM에 최소 및/또는 최대 QoS를 설정할 수 있습니다.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">개체에 대한 QoS 최대 처리량 제한은 Mbps 및/또는 IOPS로 설정할 수 있습니다. 둘 다 사용되는 경우 첫 번째 제한에 도달한 값은 ONTAP에 의해 적용됩니다. 워크로드에는 여러 개체가 포함될 수 있으며 QoS 정책을 하나 이상의 워크로드에 적용할 수 있습니다. 정책이 여러 워크로드에 적용될 경우 워크로드는 정책의 총 한도를 공유합니다. 중첩된 개체는 지원되지 않습니다(예: 볼륨 내의 파일은 각각 고유한 정책을 가질 수 없음). QoS 최소값을 IOPS에서만 설정할 수 있습니다.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">현재 ONTAP QoS 정책을 관리하고 객체에 적용하는 데 사용할 수 있는 툴은 다음과 같습니다.</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">ONTAP CLI를 참조하십시오</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">ONTAP 시스템 관리자</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">ONTAP를 위한 NetApp PowerShell Toolkit</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">VMware vSphere VASA Provider용 ONTAP 툴</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">NFS에서 VMDK에 QoS 정책을 할당하려면 다음 지침을 따르십시오.</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">이 정책은 vmname.vmdk(가상 디스크 설명자 파일) 또는 vmname.vmx(VM 설명자 파일)가 아닌 실제 가상 디스크 이미지가 포함된 vmname-flat.vmdk에 적용해야 합니다.</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">가상 스왑 파일("vmname.vswp")과 같은 다른 VM 파일에는 정책을 적용하지 마십시오.</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">vSphere 웹 클라이언트를 사용하여 파일 경로(데이터 저장소 &gt; 파일)를 찾을 때는 "-flat.vmdk" 및 "의 정보가 결합된다는 점에 유의하십시오. VMDK를 표시하고 이름이 인 파일을 하나만 표시합니다. VMDK로, 그러나 -flat.vmdk의 크기입니다. 파일 이름에 -flat를 추가하여 올바른 경로를 가져옵니다.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">VMFS 및 RDM을 포함하여 LUN에 QoS 정책을 할당하려면 ONTAP vSphere용 ONTAP 툴 홈 페이지의 스토리지 시스템 메뉴에서 SVM(SVM으로 표시됨), LUN 경로 및 일련 번호를 확인할 수 있습니다. 스토리지 시스템(SVM)을 선택한 다음 관련 오브젝트 &gt; SAN을 선택합니다. ONTAP 툴 중 하나를 사용하여 QoS를 지정할 때 이 접근 방식을 사용합니다.</block>
  <block id="8ce0096ff26ebe0a38466de6a64f461d" category="paragraph">VMware vSphere 또는 Virtual Storage Console 7.1 이상을 위한 ONTAP 툴을 VVOL 기반 VM에 최대 및 최소 QoS를 손쉽게 할당할 수 있습니다. VVol 컨테이너의 저장소 용량 프로필을 생성할 때 성능 기능에서 최대 및/또는 최소 IOPS 값을 지정한 다음 VM의 저장소 정책으로 이 SCP를 참조합니다. VM을 생성하거나 기존 VM에 정책을 적용할 때 이 정책을 사용합니다.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">FlexGroup 데이터 저장소는 VMware vSphere 9.8 이상용 ONTAP 툴을 사용할 때 향상된 QoS 기능을 제공합니다. 데이터 저장소 또는 특정 VM의 모든 VM에 대해 QoS를 쉽게 설정할 수 있습니다. 자세한 내용은 이 보고서의 FlexGroup 섹션을 참조하십시오.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">ONTAP QoS 및 VMware SIOC</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">ONTAP QoS 및 VMware vSphere 스토리지 I/O 제어(SIOC)는 vSphere 및 스토리지 관리자가 ONTAP 소프트웨어를 실행하는 시스템에서 호스팅되는 vSphere VM의 성능을 관리하는 데 함께 사용할 수 있는 보완 기술입니다. 다음 표에 나와 있는 것처럼 각 툴마다 고유한 강점이 있습니다. VMware vCenter와 ONTAP의 범위가 서로 다르기 때문에 한 시스템에서 일부 객체를 보고 관리할 수 있으며 다른 객체는 볼 수 없습니다.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">속성</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">ONTAP QoS를 참조하십시오</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">활성화 시</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">정책이 항상 활성화되어 있습니다</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">경합이 있을 때 활성(데이터 저장소 지연 시간이 임계값을 초과함)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">단위 유형</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, MBps</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, 공유</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">vCenter 또는 애플리케이션 범위</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">다양한 vCenter 환경, 기타 하이퍼바이저 및 애플리케이션</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">단일 vCenter Server</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">VM에서 QoS를 설정하시겠습니까?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK는 NFS에만 해당합니다</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">NFS 또는 VMFS의 VMDK입니다</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">LUN(RDM)에 QoS를 설정하시겠습니까?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">LUN(VMFS)에서 QoS를 설정하시겠습니까?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">볼륨에 QoS를 설정하시겠습니까(NFS 데이터 저장소)?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">SVM(테넌트)에서 QoS를 설정하시겠습니까?</block>
  <block id="86aad9b5d177180a5b9e828a8e05e819" category="cell">정책 기반 방식</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">예. 정책의 모든 워크로드에서 공유하거나 정책의 각 워크로드에 전체적으로 적용할 수 있습니다.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">예, vSphere 6.5 이상에서 가능합니다.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">라이센스가 필요합니다</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">ONTAP에 포함되어 있습니다</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">엔터프라이즈급 플러스</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="section-title">VMware 스토리지 분산 리소스 스케줄러입니다</block>
  <block id="06604b0172f4ae639ffe8c44fa7c77d8" category="paragraph">VMware SDRS(Storage Distributed Resource Scheduler)는 현재 입출력 지연 시간 및 공간 사용량을 기반으로 스토리지에 VM을 배치하는 vSphere 기능입니다. 그런 다음 데이터 저장소 클러스터(Pod라고도 함)의 데이터 저장소 간에 VM 또는 VMDK를 중단 없이 이동하여 VM 또는 VMDK를 데이터 저장소 클러스터에 배치할 최상의 데이터 저장소를 선택합니다. 데이터 저장소 클러스터는 vSphere 관리자의 관점에서 단일 소비 단위로 집계되는 유사한 데이터 저장소의 모음입니다.</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">SDRS를 VMware vSphere용 NetApp ONTAP 툴과 함께 사용하는 경우 먼저 플러그인을 사용하여 데이터 저장소를 생성한 다음 vCenter를 사용하여 데이터 저장소 클러스터를 생성한 다음 여기에 데이터 저장소를 추가해야 합니다. 데이터 저장소 클러스터가 생성된 후 세부 정보 페이지의 프로비저닝 마법사에서 추가 데이터 저장소를 데이터 저장소 클러스터에 직접 추가할 수 있습니다.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">SDRS에 대한 기타 ONTAP 모범 사례는 다음과 같습니다.</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">클러스터의 모든 데이터 저장소는 동일한 유형의 스토리지(예: SAS, SATA 또는 SSD)를 사용하고 모든 VMFS 또는 NFS 데이터 저장소이며 복제 및 보호 설정이 동일해야 합니다.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">기본(수동) 모드에서 SDRS 사용을 고려하십시오. 이 접근 방식을 통해 권장 사항을 검토하고 적용 여부를 결정할 수 있습니다. VMDK 마이그레이션의 영향을 숙지하십시오.</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">SDRS에서 VMDK를 데이터 저장소 간에 이동할 경우 ONTAP 클론 생성 또는 중복 제거를 통한 공간 절약이 손실됩니다. 중복제거를 재실행하여 이러한 절약 효과를 다시 실현할 수 있습니다.</block>
  <block id="cc1aa351f771fc36d1542fa93e1fac8e" category="list-text">SDRS에서 VMDK를 이동한 후에는 공간이 이동한 VM에 의해 잠기기 때문에 소스 데이터 저장소에서 스냅샷 복사본을 다시 생성하는 것이 좋습니다.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">동일한 애그리게이트에서 데이터 저장소 간에 VMDK를 이동하는 것은 효과가 거의 없으며 SDRS는 애그리게이트를 공유할 수 있는 다른 워크로드를 파악할 수 없습니다.</block>
  <block id="a30850531baecbfbe4486d4be9e79e30" category="section-title">스토리지 정책 기반 관리 및 VVOL</block>
  <block id="f2606439d8a3fed353e38254458c0a32" category="paragraph">VASA(VMware vSphere APIs for Storage Awareness)를 사용하면 스토리지 관리자가 잘 정의된 기능을 사용하여 데이터 저장소를 쉽게 구성할 수 있으며 VM 관리자는 필요할 때마다 상호 작용하지 않고도 데이터 저장소를 사용하여 VM을 프로비저닝할 수 있습니다. 이 접근 방식을 통해 가상화 스토리지 운영을 간소화하고 많은 사소한 작업을 피할 수 있는 방법을 살펴보시기 바랍니다.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">VASA 이전에는 VM 관리자가 VM 스토리지 정책을 정의할 수 있었지만 대개 문서 또는 명명 규칙을 사용하여 스토리지 관리자와 협력하여 적절한 데이터 저장소를 식별해야 했습니다. 스토리지 관리자는 VASA를 통해 성능, 계층화, 암호화, 복제를 비롯한 다양한 스토리지 기능을 정의할 수 있습니다. 볼륨 또는 볼륨 세트에 대한 기능 세트를 SCP(Storage Capability Profile)라고 합니다.</block>
  <block id="a3af04d147e48682c8be6bd0c1b66520" category="paragraph">SCP는 VM 데이터 VVol에 대한 최소 및/또는 최대 QoS를 지원합니다. 최소 QoS는 AFF 시스템에서만 지원됩니다. VMware vSphere용 ONTAP 툴에는 ONTAP 시스템에서 VVOL을 위한 VM 레벨의 세분화된 성능과 논리적 용량을 보여주는 대시보드가 포함되어 있습니다.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">다음 그림은 VMware vSphere 9.8 VVol 대시보드를 위한 ONTAP 툴을 보여 줍니다.</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6257d346f635c1b16a2f39df0830a48" category="paragraph">스토리지 용량 프로필을 정의한 후에는 요구 사항을 식별하는 스토리지 정책을 사용하여 VM을 프로비저닝하는 데 사용할 수 있습니다. VM 스토리지 정책과 데이터 저장소 스토리지 용량 프로파일 간의 매핑을 통해 vCenter에서 선택할 수 있는 호환 데이터 저장소 목록을 표시할 수 있습니다. 이러한 방식을 스토리지 정책 기반 관리라고 합니다.</block>
  <block id="ca100a4ba1d4641f17806479f93c8b1a" category="paragraph">VASA는 스토리지를 쿼리하고 스토리지 기능 집합을 vCenter에 반환하는 기술을 제공합니다. VASA 공급업체 공급자는 스토리지 시스템 API 및 구성 요소 및 vCenter에서 인식할 수 있는 VMware API 간의 변환을 제공합니다. NetApp의 VASA Provider for ONTAP은 VMware vSphere 어플라이언스 VM을 위한 ONTAP 툴의 일부로 제공되며, vCenter 플러그인을 통해 VVOL 데이터 저장소를 프로비저닝하고 관리할 수 있을 뿐만 아니라 스토리지 기능 프로필(SCP)을 정의할 수 있습니다.</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP는 VMFS 및 NFS VVOL 데이터 저장소를 모두 지원합니다. SAN 데이터 저장소와 VVOL을 함께 사용하면 VM 수준 정밀도와 같은 NFS의 몇 가지 이점이 있습니다. 다음은 고려해야 할 몇 가지 모범 사례이며 에서 추가 정보를 찾을 수 있습니다<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>:</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">VVOL 데이터 저장소는 여러 클러스터 노드의 여러 FlexVol 볼륨으로 구성될 수 있습니다. 가장 간단한 방법은 볼륨에 기능이 다른 경우에도 단일 데이터 저장소를 사용하는 것입니다. SPBM은 호환 볼륨이 VM에 사용되는지 확인합니다. 하지만 모든 볼륨은 단일 ONTAP SVM에 속하고 단일 프로토콜을 사용하여 액세스해야 합니다. 각 프로토콜당 하나의 LIF로 충분합니다. 스토리지 기능이 릴리즈별로 다를 수 있으므로 단일 VVOL 데이터 저장소 내에서 여러 ONTAP 릴리즈를 사용하는 것은 피하십시오.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">VMware vSphere용 ONTAP 툴을 사용하여 VVOL 데이터 저장소를 만들고 관리합니다. 데이터 저장소와 해당 프로필을 관리하는 것 외에도 필요한 경우 데이터 저장소에 액세스하기 위한 프로토콜 엔드포인트가 자동으로 생성됩니다. LUN을 사용하는 경우 LUN PES는 LUN ID 300 이상을 사용하여 매핑됩니다. ESXi 호스트 고급 시스템 설정 Disk.MaxLUN이 300보다 높은 LUN ID 번호를 허용하는지 확인합니다(기본값은 1,024). vCenter에서 ESXi 호스트를 선택한 다음 구성 탭을 선택하고 고급 시스템 설정 목록에서 Disk.MaxLUN을 찾아 이 단계를 수행합니다.</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">VMware vSphere를 위한 VASA Provider, vCenter Server(어플라이언스 또는 Windows 기반) 또는 ONTAP 툴을 VVOL 데이터 저장소에 설치하거나 마이그레이션하지 마십시오. 상호 의존하기 때문에 정전이 발생하거나 기타 데이터 센터가 중단될 경우 이를 관리할 수 없습니다.</block>
  <block id="27bd00c8827fc3d77d1b5650103b676f" category="list-text">VASA Provider VM을 정기적으로 백업합니다. VASA Provider가 포함된 기존 데이터 저장소의 시간별 스냅샷 복사본을 최소한 생성합니다. VASA Provider 보호 및 복구에 대한 자세한 내용은 다음을 참조하십시오<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">다음 그림은 VVol 구성 요소를 보여줍니다.</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">클라우드 마이그레이션 및 백업</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">ONTAP의 또 다른 강점은 하이브리드 클라우드를 광범위하게 지원하여 사내 프라이빗 클라우드의 시스템을 퍼블릭 클라우드 기능과 병합하는 것입니다. 다음은 vSphere와 함께 사용할 수 있는 몇 가지 NetApp 클라우드 솔루션입니다.</block>
  <block id="67464b4510c09197c8a5e16ba6702435" category="list-text">* Cloud Volumes. * NetApp Cloud Volumes Service for AWS 또는 GCP 및 Azure NetApp Files for ANF는 주요 퍼블릭 클라우드 환경에서 고성능 멀티 프로토콜 관리 스토리지 서비스를 제공합니다. VMware Cloud VM 게스트가 직접 사용할 수 있습니다.</block>
  <block id="0ac7b95ec26051fb8842ae35427ecc22" category="list-text">* Cloud Volumes ONTAP. * NetApp Cloud Volumes ONTAP 데이터 관리 소프트웨어는 선택한 클라우드에서 데이터에 제어, 보호, 유연성 및 효율성을 제공합니다. Cloud Volumes ONTAP는 NetApp ONTAP 스토리지 소프트웨어를 기반으로 하는 클라우드 네이티브 데이터 관리 소프트웨어입니다. Cloud Manager와 함께 사용하면 사내 ONTAP 시스템과 함께 Cloud Volumes ONTAP 인스턴스를 구축하고 관리할 수 있습니다. 고급 NAS 및 iSCSI SAN 기능과 함께 스냅샷 복사본 및 SnapMirror 복제를 포함한 통합 데이터 관리를 활용하십시오.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">* 클라우드 서비스. * Cloud Backup Service 또는 SnapMirror 클라우드를 사용하여 퍼블릭 클라우드 스토리지를 사용하는 사내 시스템의 데이터를 보호합니다. Cloud Sync를 사용하면 NAS, 오브젝트 저장소 및 Cloud Volumes Service 스토리지에서 데이터를 마이그레이션하고 동기화 상태를 유지할 수 있습니다.</block>
  <block id="fa9b5353337118a51ced7968bccc02a0" category="inline-link">VM의 스냅샷 복사본을 더 많이 저장합니다</block>
  <block id="c79f1f00e1e3c8f100e8604eec888859" category="list-text">* FabricPool. * FabricPool는 ONTAP 데이터를 빠르고 쉽게 계층화할 수 있도록 지원합니다. 스냅샷 복사본의 콜드 블록은 퍼블릭 클라우드 또는 프라이빗 StorageGRID 오브젝트 저장소의 오브젝트 저장소로 마이그레이션할 수 있으며, ONTAP 데이터에 다시 액세스할 때 자동으로 호출됩니다. 또는 SnapVault에서 이미 관리하는 데이터를 보호하기 위해 개체 계층을 세 번째 수준으로 사용할 수도 있습니다. 이 접근 방식을 통해 다음을 수행할 수 있습니다<block ref="1d0add9d2d81e2d7e790f727021e53aa" category="inline-link-rx"></block> 주요 및/또는 보조 ONTAP 스토리지 시스템</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">* ONTAP Select. * NetApp 소프트웨어 정의 스토리지를 사용하여 프라이빗 클라우드를 인터넷으로 원격 시설 및 사무소로 확장할 수 있습니다. ONTAP Select를 사용하여 블록 및 파일 서비스와 엔터프라이즈 데이터 센터에서 사용하는 vSphere 데이터 관리 기능을 지원할 수 있습니다.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">VM 기반 애플리케이션을 설계할 때는 미래의 클라우드 이동성을 고려해 보십시오. 예를 들어, 애플리케이션과 데이터 파일을 함께 배치하는 대신 데이터에 대해 별도의 LUN 또는 NFS 내보내기를 사용합니다. 따라서 VM 및 데이터를 클라우드 서비스로 별도로 마이그레이션할 수 있습니다.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">vSphere 데이터 암호화</block>
  <block id="eb969673f581d94df982f8e2a6001f30" category="paragraph">오늘날, 암호화를 통해 유휴 데이터를 보호해야 하는 요구가 증가하고 있습니다. 처음에는 재무 및 의료 정보에 집중했지만 파일, 데이터베이스 또는 기타 데이터 유형에 저장된 모든 정보를 보호하는 데 관심이 높아지고 있습니다.</block>
  <block id="77652ecf0c76f1d4194171dc720320be" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템을 사용하면 유휴 데이터를 쉽게 보호할 수 있습니다. NetApp 스토리지 암호화(NSE)는 ONTAP가 포함된 자체 암호화 디스크 드라이브를 사용하여 SAN 및 NAS 데이터를 보호합니다. NetApp은 또한 디스크 드라이브에서 볼륨을 암호화하는 단순한 소프트웨어 기반 접근 방식으로 NetApp 볼륨 암호화 및 NetApp 애그리게이트 Encryption도 제공합니다. 이 소프트웨어 암호화는 특수 디스크 드라이브 또는 외부 키 관리자가 필요하지 않으며 ONTAP 고객이 추가 비용 없이 사용할 수 있습니다. 클라이언트 또는 애플리케이션을 중단하지 않고 업그레이드하거나 사용할 수 있으며 온보드 키 관리자를 포함하여 FIPS 140-2 레벨 1 표준에 따라 검증을 받았습니다.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">VMware vSphere에서 실행되는 가상화된 애플리케이션의 데이터를 보호하기 위한 몇 가지 접근 방식이 있습니다. 한 가지 방법은 게스트 OS 수준에서 VM 내부의 소프트웨어로 데이터를 보호하는 것입니다. vSphere 6.5와 같은 최신 하이퍼바이저는 VM 수준에서 암호화를 지원하는 또 다른 대안으로, 그러나 NetApp 소프트웨어 암호화는 간단하고 쉬우며 다음과 같은 이점을 제공합니다.</block>
  <block id="92fbd315c4413db381567a775570b78c" category="list-text">* 가상 서버 CPU에 영향을 미치지 않습니다. * 일부 가상 서버 환경에서는 애플리케이션에 사용할 수 있는 모든 CPU 사이클이 필요하지만 하이퍼바이저 레벨 암호화를 위해서는 최대 5배의 CPU 리소스가 필요하다는 결과가 있습니다. 암호화 소프트웨어가 암호화 작업 부하를 오프로드하기 위해 인텔의 AES-NI 명령 집합을 지원하는 경우에도(NetApp 소프트웨어 암호화처럼) 이전 서버와 호환되지 않는 새로운 CPU의 요구 사항으로 인해 이 접근 방식이 실현 불가능할 수 있습니다.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">* 온보드 키 관리자가 포함되어 있습니다. * NetApp 소프트웨어 암호화는 추가 비용 없이 온보드 키 관리자를 포함하므로 구입 및 사용이 복잡한 고가용성 키 관리 서버 없이 쉽게 시작할 수 있습니다.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">* 스토리지 효율성에 영향을 미치지 않습니다. * 데이터 중복 제거 및 압축과 같은 스토리지 효율성 기술이 현재 널리 사용되고 있으며 플래시 디스크 미디어를 비용 효율적으로 사용하는 데 핵심적인 역할을 합니다. 그러나 암호화된 데이터는 일반적으로 중복제거되거나 압축할 수 없습니다. NetApp 하드웨어 및 스토리지 암호화는 다른 접근법과는 달리 낮은 수준에서 작동하며 업계 최고의 NetApp 스토리지 효율성 기능을 충분히 활용할 수 있도록 합니다.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">* 데이터스토어의 세분화된 암호화. * NetApp Volume Encryption을 사용하면 각 볼륨에 고유한 AES 256비트 키를 사용할 수 있습니다. 변경해야 하는 경우 단일 명령을 사용하여 변경할 수 있습니다. 이 접근 방식은 테넌트가 여러 개이거나 서로 다른 부서 또는 애플리케이션에 대해 독립적인 암호화를 증명해야 하는 경우에 유용합니다. 이 암호화는 개별 VM을 관리하는 것보다 훨씬 쉬운 데이터 저장소 수준에서 관리됩니다.</block>
  <block id="088124cfa6d59c647e63177c5a4af318" category="paragraph">소프트웨어 암호화를 쉽게 시작할 수 있습니다. 라이센스를 설치한 후 암호를 지정하여 온보드 키 관리자를 구성한 다음 새 볼륨을 생성하거나 스토리지 측 볼륨 이동을 수행하여 암호화를 설정합니다. NetApp은 향후 VMware 툴 릴리즈에서 암호화 기능에 대한 통합 지원을 추가하기 위해 노력하고 있습니다.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager는 가상 인프라의 VM에 대한 가시성을 제공하고 가상 환경에서 스토리지 및 성능 문제를 모니터링하고 문제를 해결할 수 있도록 지원합니다.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">ONTAP 기반의 일반적인 가상 인프라 구축에는 컴퓨팅, 네트워크 및 스토리지 계층 전체에 분산된 다양한 구성 요소가 있습니다. VM 애플리케이션의 성능 지연은 각 계층의 다양한 구성 요소에 의해 발생하는 지연 시간의 조합으로 인해 발생할 수 있습니다.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">다음 스크린샷은 Active IQ Unified Manager 가상 머신 보기를 보여 줍니다.</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager는 가상 환경의 기본 하위 시스템을 토폴로지 뷰에서 제공하므로 컴퓨팅 노드, 네트워크 또는 스토리지에서 지연 시간 문제가 발생했는지 여부를 확인할 수 있습니다. 또한 개선 단계를 수행하고 기본 문제를 해결하는 데 성능 지연이 발생하는 특정 개체를 중점적으로 보여 줍니다.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">다음 스크린샷은 AIQUM 확장 토폴로지를 보여줍니다.</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e69b470437a857bf2d9517ce4ef8d2c1" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP 스토리지 FC VMFS 데이터 저장소를 구축하는 단계를 제공합니다.</block>
  <block id="91d9498cf61618ef81368a106318efd2" category="doc">vSphere VMFS 데이터 저장소 - ONTAP를 사용하는 Fibre Channel 스토리지 백엔드</block>
  <block id="b6e52e53cc59b8620dcdc05f2b812be4" category="paragraph">이 섹션에서는 ONTAP FC(Fibre Channel) 스토리지를 사용하여 VMFS 데이터 저장소를 생성하는 방법에 대해 설명합니다.</block>
  <block id="0335588c7903659bdeaa310c8f7bcdf4" category="list-text">{ONTAP_VERSION}을 실행하는 ONTAP 스토리지 시스템(FAS/AFF/CVO/ONTAP Select/ASA</block>
  <block id="f2a03b032017931383878c3ef48cdb0a" category="list-text">호스트, 타겟 및 SVM, LUN 정보의 ONTAP WWPN</block>
  <block id="d0a36a0dcdef62d026caa08afbaa4a42" category="inline-link-macro">작성한 FC 구성 워크시트</block>
  <block id="5c42144bb611ba366591a823d4c2955e" category="list-text"><block ref="5c42144bb611ba366591a823d4c2955e" category="inline-link-macro-rx"></block></block>
  <block id="6c2e28f86b2049d110f0e73e9bb78709" category="list-text">ONTAP FC 데이터 포트 및 vSphere 호스트가 연결된 경우</block>
  <block id="5a1cb943a687396a356750829002d982" category="list-text">각 존에 SVM을 위한 ONTAP FC 논리 인터페이스(WWPN)인 타겟을 포함합니다. SVM당 노드당 논리 인터페이스는 2개 이상 있어야 합니다. 물리적 포트의 WWPN을 사용하지 마십시오.</block>
  <block id="acd7065eaa19f6ad949216b6dcca52b6" category="list-text">구축, 구성 및 바로 사용할 수 있는 VMware vSphere용 ONTAP 툴</block>
  <block id="d13dd15101d292f5b2c56e5be828fec8" category="section-title">VMFS 데이터 저장소를 프로비저닝합니다</block>
  <block id="95877ca095b0f0a0a981f8a12d234ad5" category="paragraph">VMFS 데이터 저장소를 프로비저닝하려면 다음 단계를 수행하십시오.</block>
  <block id="94dafc85e46c3bc0d374c052b1075890" category="list-text">과(와) 호환 여부를 점검하십시오<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="195e1a47999aff0fbaa4eb8d97be6c40" category="inline-link-macro">FCP 구성이 지원됩니다</block>
  <block id="e1b87801d0d31fd947fb52aa411c2815" category="list-text">를 확인합니다 <block ref="a0240d867f430aa7cc80ec129fc2bdb1" category="inline-link-macro-rx"></block>.</block>
  <block id="0b3f75b021ef6bdc0a532e2d9b2a9d74" category="inline-link-macro">FCP에 대한 ONTAP 라이센스가 있는지 확인합니다.</block>
  <block id="3c56f50608e95955ed2e1a3fb8b1dad1" category="list-text"><block ref="3c56f50608e95955ed2e1a3fb8b1dad1" category="inline-link-macro-rx"></block></block>
  <block id="e7dc6b39e7e5bd6df8fa93e90a426161" category="list-text">'system license show' 명령을 사용하여 FCP가 나열되는지 확인합니다.</block>
  <block id="f8aa00b1a94d3290ba6ac653b792dd8a" category="list-text">라이센스를 추가하려면 "licen se add-license-code &lt;license code&gt;"를 사용합니다.</block>
  <block id="86a53381cefd41dcca81850274f0203a" category="list-text">SVM에서 FCP 프로토콜이 활성화되어 있는지 확인합니다.</block>
  <block id="0d195904efc6cfb176bbc04e93c2947d" category="inline-link-macro">FCP를 사용하여 새 SVM을 생성합니다.</block>
  <block id="df062a6cafa16aee5f7ea64ea6991776" category="list-text"><block ref="df062a6cafa16aee5f7ea64ea6991776" category="inline-link-macro-rx"></block></block>
  <block id="5aab5d056538757626dd0562a563471a" category="list-text">SVM에서 FCP 논리 인터페이스를 사용할 수 있는지 확인합니다.</block>
  <block id="f89eac3d097d3dae5c0159f0da84b1c7" category="list-text">GUI로 SVM을 생성할 때 논리 인터페이스는 이 프로세스의 일부입니다.</block>
  <block id="946b60eb8bd4945ad82b28fd9ccd3c63" category="list-text">네트워크 인터페이스의 이름을 바꾸려면 네트워크 인터페이스 수정 을 사용합니다.</block>
  <block id="52fa81ab62bea2599ed516f01925678d" category="inline-link-macro">LUN 생성 및 매핑</block>
  <block id="c8ecf540bebb63423545ecd3d02c6ca0" category="list-text"><block ref="a2b18e9ce335dd856363e6613d961c1a" category="inline-link-macro-rx"></block> VMware vSphere용 ONTAP 툴을 사용하는 경우 이 단계를 건너뛰십시오.</block>
  <block id="25d85157bcfdbb601bbda056cd3a5bc6" category="list-text">HBA 드라이버가 설치되어 있는지 확인합니다. VMware 지원 HBA에는 드라이버가 기본적으로 배포되어 있으며 에서 볼 수 있어야 합니다 <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block>.</block>
  <block id="f1e09e8062c8a1cddb6f2f68289ea71b" category="doc">VMware 가상화를 위한 ONTAP의 새로운 기능</block>
  <block id="2e130352b486464834bcc7dda1ff2603" category="section-title">VMware 가상화</block>
  <block id="e1ad6e34a69720808e091316ea5e105f" category="inline-link-macro">라인 = 21..38</block>
  <block id="24988a51cebf36bd40a4e4df7f9199a1" category="paragraph"><block ref="24988a51cebf36bd40a4e4df7f9199a1" category="inline-link-macro-rx"></block></block>
  <block id="6fe85aae6e8fa231a1f417edfeef3759" category="doc">vSphere VMFS 데이터 저장소 - ONTAP를 사용하는 iSCSI 스토리지 백엔드</block>
  <block id="4f6f7882fc7b858bc0eb3e3a41991494" category="paragraph">이 섹션에서는 ONTAP iSCSI 스토리지를 사용하여 VMFS 데이터 저장소를 생성하는 방법에 대해 설명합니다.</block>
  <block id="383b1f30f341cb0eff11db96d70e9f50" category="list-text">vSphere 환경 및 ONTAP를 관리하는 데 필요한 기본 기술</block>
  <block id="47c341511ad626bfba98caeaa0762774" category="list-text">iSCSI를 위한 ONTAP 네트워크 포트, SVM 및 LUN 정보</block>
  <block id="f76f5dc5c6861d7938aa8d60b08976c8" category="inline-link-macro">완료된 iSCSI 구성 워크시트</block>
  <block id="275e54409e966e03b62ee630e4856daa" category="list-text"><block ref="275e54409e966e03b62ee630e4856daa" category="inline-link-macro-rx"></block></block>
  <block id="c7e4d06c6b5e45fbb711be2b15976173" category="list-text">iSCSI VMkernel 어댑터 IP 정보</block>
  <block id="980e76f4fd03b06bfe740133284e92a9" category="list-text">ONTAP 시스템 네트워크 데이터 포트 및 연결된 vSphere 호스트를 사용합니다</block>
  <block id="3a6f48cf422509b67592ce2a0b4dd558" category="list-text">iSCSI에 대해 구성된 VLAN입니다</block>
  <block id="44786c36009327ad04469602f3f96832" category="list-text">(선택 사항) ONTAP 네트워크 데이터 포트에 대해 구성된 Link Aggregation입니다</block>
  <block id="f3a29486bed19a90f2da6d007818b427" category="section-title">단계</block>
  <block id="881de4e9f9e9dba55f3d9f09d3fc8eac" category="inline-link-macro">iSCSI 구성이 지원되는지 확인합니다.</block>
  <block id="6a2fb6d042919f5807315156f926ab10" category="list-text"><block ref="6a2fb6d042919f5807315156f926ab10" category="inline-link-macro-rx"></block></block>
  <block id="e103d9cdc55ef0be25a4fd8054bc28bc" category="list-text">다음 ONTAP 및 vSphere 작업을 완료합니다.</block>
  <block id="f04a1b9690234d25ff072d6719666947" category="inline-link-macro">iSCSI에 대한 ONTAP 라이센스를 확인합니다</block>
  <block id="41bf6980693d9ba9f5e7a797fe2f4417" category="list-text"><block ref="0767ceac1f7ac130ade75fb7fae3fc53" category="inline-link-macro-rx"></block>.</block>
  <block id="3ffc628bd3f213f0998146fb5262f366" category="list-text">'system license show' 명령어를 사용하여 iSCSI가 나열되는지 확인한다.</block>
  <block id="d1b0a5732b3cb229ef0f788fbb095f05" category="list-text">사용권을 추가하려면 'license add-license-code &lt;license code&gt;'를 사용하십시오.</block>
  <block id="97035bc2443de65f877c3fddd838c6ae" category="inline-link-macro">SVM에서 iSCSI 프로토콜이 활성화되어 있는지 확인합니다.</block>
  <block id="3807dbdaab3b890b6a293c99c7b46f63" category="list-text"><block ref="3807dbdaab3b890b6a293c99c7b46f63" category="inline-link-macro-rx"></block></block>
  <block id="cb66a92bc9fa6195f8b2914bcf868664" category="list-text">SVM에서 iSCSI 네트워크 논리 인터페이스를 사용할 수 있는지 확인합니다.</block>
  <block id="da91d0d17d1f671a0af23e7ebb96ec92" category="admonition">GUI를 사용하여 SVM을 생성할 때 iSCSI 네트워크 인터페이스도 생성됩니다.</block>
  <block id="da6a83da2309e8dbd81bb5b55c7c9602" category="list-text">네트워크 인터페이스를 보거나 변경하려면 네트워크 인터페이스 명령을 사용합니다.</block>
  <block id="53fd22677faa2085c1fc51f1d116faff" category="admonition">노드당 두 개의 iSCSI 네트워크 인터페이스를 사용하는 것이 좋습니다.</block>
  <block id="69fea75e454b43e67ba176dddb604159" category="inline-link-macro">iSCSI 네트워크 인터페이스를 생성합니다.</block>
  <block id="1bc0e04873be7c6291aef492ff2785cc" category="list-text"><block ref="d503e168b9096ac416caa1c8f13ab28a" category="inline-link-macro-rx"></block> 기본 데이터 블록 서비스 정책을 사용할 수 있습니다.</block>
  <block id="bd494b2c15d88a1dfa29c308b39e8f6e" category="inline-link-macro">데이터 iSCSI 서비스가 서비스 정책에 포함되어 있는지 확인합니다.</block>
  <block id="c436a9a899f5e1cfacf8828c90931ca9" category="list-text"><block ref="24788d985e181b3194881517c2ec7650" category="inline-link-macro-rx"></block> 네트워크 인터페이스 service-policy show를 사용하여 확인할 수 있습니다.</block>
  <block id="c0e1d066d0482fc5cc1554edaa3f36b2" category="inline-link-macro">점보 프레임이 활성화되었는지 확인합니다.</block>
  <block id="a355e4512cfabb746ee4c05a87a61107" category="list-text"><block ref="a355e4512cfabb746ee4c05a87a61107" category="inline-link-macro-rx"></block></block>
  <block id="5ccd820a879b8d1daef5e44125431184" category="inline-link-macro">LUN을 생성하고 매핑합니다.</block>
  <block id="c49b54ab60508b16176724eeb8118049" category="list-text"><block ref="3a73ce9b9237c3e09863bf7b049ce423" category="inline-link-macro-rx"></block> VMware vSphere용 ONTAP 툴을 사용하는 경우 이 단계를 건너뛰십시오. 각 LUN에 대해 이 단계를 반복합니다.</block>
  <block id="5c9b297b088335a8562568dc59549c7d" category="list-text">iSCSI VLAN에 사용할 수 있는 NIC가 하나 이상 있는지 확인합니다. 성능 및 내결함성을 향상시키기 위해 2개의 NIC가 선호됩니다.</block>
  <block id="fe9e58c95c20042a4032ef737d6e8400" category="inline-link-macro">vSphere 호스트에서 사용할 수 있는 물리적 NIC의 수를 확인합니다.</block>
  <block id="96cf3cacac94299a7630f48f5cf5b7e3" category="list-text"><block ref="96cf3cacac94299a7630f48f5cf5b7e3" category="inline-link-macro-rx"></block></block>
  <block id="87d3329dab6e8f24601b6f45d40614ea" category="inline-link-macro">iSCSI 이니시에이터를 구성합니다.</block>
  <block id="536d7ac288972152b209e6f004917285" category="list-text"><block ref="95a6e2e5fae04247474cdc6a729342fc" category="inline-link-macro-rx"></block> 일반적인 사용 사례는 소프트웨어 iSCSI 이니시에이터입니다.</block>
  <block id="fd823eb37045485458bb3d5d52ddc46f" category="inline-link-macro">iSCSI에 대한 TCPIP 스택을 사용할 수 있는지 확인합니다</block>
  <block id="875d65383afa504aad11a619d920adc7" category="list-text"><block ref="025b4ff12eca60b6c5b5be76597b5e95" category="inline-link-macro-rx"></block>.</block>
  <block id="e45f6655250b094b5a8370ff511869c3" category="inline-link-macro">iSCSI 포트 그룹을 사용할 수 있는지 확인합니다</block>
  <block id="4c93429599cf15be2af5aa0f59131c17" category="list-text"><block ref="5e67546a702454fa060946b3e582d0e9" category="inline-link-macro-rx"></block>.</block>
  <block id="b7b554d373b5992838a126134a03ba0d" category="list-text">일반적으로 업링크 포트가 여러 개인 단일 가상 스위치를 사용합니다.</block>
  <block id="879d70f2184599f483fd94f0f274163f" category="list-text">1:1 어댑터 매핑을 사용합니다.</block>
  <block id="9f60e3586ab900b8f879404be003b539" category="list-text">iSCSI VMkernel 어댑터가 NIC 수와 일치하도록 설정되어 있고 IP가 할당되어 있는지 확인합니다.</block>
  <block id="3e6e09b1cda3200c7407173a3473a103" category="inline-link-macro">iSCSI 소프트웨어 어댑터를 iSCSI VMkernel 어댑터에 바인딩합니다.</block>
  <block id="70d687ef257c5d00e0d85844c0101c77" category="list-text"><block ref="70d687ef257c5d00e0d85844c0101c77" category="inline-link-macro-rx"></block></block>
  <block id="187fbd973609969af8f47e857f8579c4" category="inline-link-macro">ONTAP 툴을 사용하여 VMFS 데이터 저장소를 프로비저닝합니다</block>
  <block id="1e9df60603ff2a9fe2495b189aecc647" category="list-text"><block ref="efecd5d76f6fc92c9c9a8111cf809724" category="inline-link-macro-rx"></block>. 모든 데이터 저장소에 대해 이 단계를 반복합니다.</block>
  <block id="5f4723c28ea2b13a27b86c1116720a8a" category="inline-link-macro">하드웨어 가속 지원을 확인합니다.</block>
  <block id="aa0cfa24dd578f0629299a21b453583c" category="list-text"><block ref="aa0cfa24dd578f0629299a21b453583c" category="inline-link-macro-rx"></block></block>
  <block id="3f297ef15cde0668e93b35f2752fd4fd" category="section-title">다음 단계</block>
  <block id="1d3fa7ee382266d716ba7a360f30f188" category="paragraph">이러한 작업이 완료되면 VMFS 데이터 저장소가 가상 머신 프로비저닝에 사용할 준비가 된 것입니다.</block>
  <block id="53001b412ce4896686a413a19f6dcc5f" category="listing-title">Ansible 플레이북</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">SRA 및 기존 데이터스토어에 사용되는 것과 VVol 복제를 사용할 때는 SRM 내 워크플로우가 크게 다릅니다.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">VVOL 복제 사용 시 SRM 문제 해결</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">SRA 및 기존 데이터스토어에 사용되는 것과 VVol 복제를 사용할 때는 SRM 내 워크플로우가 크게 다릅니다. 예를 들어, 어레이 관리자 개념은 없습니다. 따라서 Discovery와 Discovery의 명령은 결코 볼 수 없습니다.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">문제 해결 시 아래 나열된 새 워크플로를 이해하는 것이 좋습니다.</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">queryReplicationPeer: 두 오류 도메인 간의 복제 계약을 검색합니다.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">queryFaultDomain: 오류 도메인 계층을 검색합니다.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">queryReplicationGroup: 소스 또는 타겟 도메인에 있는 복제 그룹을 검색합니다.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup: 소스와 대상 간의 데이터를 동기화합니다.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">queryPointInTimeReplica: 타겟의 시점 복제본을 검색합니다.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">testFailoverReplicationGroupStart: 테스트 대체 작동을 시작합니다.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">testFailoverReplicationGroupStop: 테스트 대체 작동을 종료합니다.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup: 현재 테스트 중인 그룹을 프로덕션 환경으로 승격합니다.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">prepareFailoverReplicationGroup: 재해 복구를 준비합니다.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">failoverReplicationGroup: 재해 복구를 실행합니다.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">reverseReplicateGroup: 역방향 복제를 시작합니다.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">queryMatchingContainer: 지정된 정책으로 프로비저닝 요청을 충족할 수 있는 컨테이너(호스트 또는 복제 그룹과 함께)를 찾습니다.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">queryResourceMetadata: VASA 공급자에서 모든 리소스의 메타데이터를 검색하며 리소스 사용률을 queryMatchingContainer 함수에 대한 응답으로 반환할 수 있습니다.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">VVOL 복제 구성 시 가장 일반적인 오류는 SnapMirror 관계를 검색하지 못하는 것입니다. 이 문제는 볼륨 및 SnapMirror 관계가 ONTAP 도구 모음 외부에서 생성되기 때문에 발생합니다. 따라서 항상 SnapMirror 관계가 완전히 초기화되었는지, 그리고 복제된 VVol 데이터 저장소를 생성하기 전에 두 사이트의 ONTAP 도구에서 재검색을 실행하는 것이 좋습니다.</block>
  <block id="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link"><block ref="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link-rx"></block></block>
  <block id="bc0f3321a29c580fa0e3cca0c00ee7cd" category="list-text">VMware 제품 설명서<block ref="3bdcd80def6a1e2849d8b38049a04af9" category="inline-link-rx"></block></block>
  <block id="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link"><block ref="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link-rx"></block></block>
  <block id="0f185ccd88416daec4eee0a846d110b8" category="list-text">NetApp 제품 설명서<block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="19610155b973358e47466063b4b079a4" category="summary">ONTAP는 SAN 환경을 위한 iSCSI, FC(파이버 채널), FCoE(Fibre Channel over Ethernet) 또는 NVMe/FC(Non-Volatile Memory Express over Fibre Channel)와 NFS(v3 및 v4.1), 게스트 연결을 위한 SMB 또는 S3와 같은 가상화에 사용되는 모든 주요 스토리지 프로토콜을 지원합니다. 고객은 자체 환경에 가장 적합한 프로토콜을 자유롭게 선택할 수 있으며 필요에 따라 단일 시스템에서 프로토콜을 결합할 수 있습니다.</block>
  <block id="93b698fac9d8f378474fb0765494c4e6" category="doc">vSphere를 위한 ONTAP 기능</block>
  <block id="9985b4390c40137573e6da05caf85874" category="section-title">프로토콜</block>
  <block id="561327c79c453379a7f11cb38aabf666" category="paragraph">ONTAP는 SAN 환경을 위한 iSCSI, FC(파이버 채널), FCoE(Fibre Channel over Ethernet) 또는 NVMe/FC(Non-Volatile Memory Express over Fibre Channel)와 NFS(v3 및 v4.1), 게스트 연결을 위한 SMB 또는 S3와 같은 가상화에 사용되는 모든 주요 스토리지 프로토콜을 지원합니다. 고객은 자체 환경에 가장 적합한 프로토콜을 자유롭게 선택할 수 있으며 필요에 따라 단일 시스템에서 프로토콜을 결합할 수 있습니다. 예를 들어, NFS 데이터 저장소의 일반 사용을 몇 개의 iSCSI LUN 또는 게스트 공유로 보강할 수 있습니다.</block>
  <block id="98f770b0af18ca763421bac22b4b6805" category="section-title">피처</block>
  <block id="99dd82c3472eab7ec4ea64a848fe032d" category="paragraph">가상화된 워크로드를 관리하는 데 유용한 ONTAP 기능이 많이 있습니다. 추가 제품 라이센스가 필요한 일부 제품에 대해서는 다음 섹션에서 설명합니다. 그 외 일부는 ONTAP를 비롯한 전체 NetApp 포트폴리오의 독립 실행형 툴로 패키징되어 있습니다.</block>
  <block id="671534601eb09388581f095632f815b2" category="paragraph">기본 ONTAP 기능에 대한 자세한 내용은 다음과 같습니다.</block>
  <block id="ef97088865d8960cc5a3a20f3c10f469" category="list-text">* NetApp 스냅샷 복사본 * ONTAP은 스냅샷 복사본을 생성하거나 사용할 때 성능 저하 없이 VM 또는 데이터 저장소의 즉각적인 스냅샷 복사본을 제공합니다. 패치 적용 전 또는 간단한 데이터 보호를 위해 VM의 복원 지점을 만드는 데 사용할 수 있습니다. 이는 VMware(정합성 보장) 스냅샷과 다릅니다. ONTAP 스냅샷 복사본을 만드는 가장 쉬운 방법은 VMware vSphere용 SnapCenter 플러그인을 사용하여 VM 및 데이터 저장소를 백업하는 것입니다.</block>
  <block id="dbef3659822e80f91a3a561ed6d0b0cd" category="list-text">* 스토리지 효율성 * ONTAP는 인라인 및 백그라운드 중복제거 및 압축, 제로 블록 중복제거, 데이터 컴팩션을 지원합니다.</block>
  <block id="287c4830bc87771bdf2b3ae9880ab67e" category="list-text">* 볼륨 및 LUN 이동. * vSphere 데이터 저장소와 VVOL을 지원하는 볼륨 및 LUN을 ONTAP 클러스터 내에서 중단 없이 이동하여 성능과 용량의 균형을 맞추거나 무중단 유지보수 및 업그레이드를 지원할 수 있습니다.</block>
  <block id="ba96d4d48c1ff15e2732b37e2e7a435c" category="list-text">* QoS. * QoS를 사용하면 개별 LUN, 볼륨 또는 파일의 성능을 관리할 수 있습니다. 이 기능은 알 수 없거나 부족한 VM을 제한하거나 중요한 VM에 충분한 성능 리소스가 확보되도록 하는 데 사용할 수 있습니다.</block>
  <block id="a946b6511f13dc2fbdaf1581d804d5b4" category="list-text">* NetApp 볼륨 암호화, NetApp 애그리게이트 암호화. * NetApp 암호화 옵션은 유휴 데이터를 보호하기 위해 간편한 소프트웨어 기반 암호화를 제공합니다.</block>
  <block id="28f638810590337576cbbe9979329c21" category="list-text">* FabricPool. * 이 기능은 사용 빈도가 낮은 데이터를 블록 레벨에서 별도의 오브젝트 저장소로 자동으로 계층화하고, 사용 빈도가 높은 플래시 스토리지를 사용합니다.</block>
  <block id="ff8a0108cd7cd5019bfee6b6be672b17" category="inline-link">ONTAP REST API</block>
  <block id="9455a10ec937dafee664ae1e0e4fd98c" category="inline-link">Ansible 모듈</block>
  <block id="4fe65be709b755cfdf83cf3ff5534e52" category="list-text">* 안정, Ansible. * 사용<block ref="71191ff17e34498b2463e6167736896a" category="inline-link-rx"></block> 스토리지 및 데이터 관리를 자동화하고, 및 를 누릅니다<block ref="d4fc0de110866702e0b8608590b39b64" category="inline-link-rx"></block> ONTAP 시스템의 구성 관리를 위해 일부 ONTAP 기능은 vSphere 워크로드에 적합하지 않습니다. 예를 들어, ONTAP 9.8 이전의 FlexGroup는 전체 클론 복제 지원을 제공하지 않았으며 vSphere에서 테스트되지 않았습니다(vSphere와 함께 사용하는 최신 정보는 FlexGroup 섹션 참조). FlexCache는 읽기 작업이 많은 워크로드에 맞게 설계되었기 때문에 vSphere에도 적합하지 않습니다. 캐시가 오리진에서 분리되어 양쪽에서 NFS 데이터 저장소 오류가 발생하는 경우 쓰기에 문제가 발생할 수 있습니다.</block>
  <block id="85402a535d923d0511a02d404893d1ba" category="section-title">ONTAP 라이센스</block>
  <block id="4a9fdcb14826a67d38a7b84170c54ea9" category="paragraph">가상화된 워크로드를 관리하는 데 유용한 일부 ONTAP 기능은 추가 비용 없이 라이센스 번들 또는 별도 구매 없이 추가 라이센스가 필요합니다. 많은 고객의 경우 가장 비용 효율적인 방법은 라이센스 번들과 함께 사용하는 것입니다. vSphere와 관련된 주요 라이센스 및 라이센스 사용 방법은 다음과 같습니다.</block>
  <block id="c598be4d4f9f8c476e7f51d6ef5ff139" category="list-text">FlexClone *. * FlexClone은 ONTAP 볼륨 및 파일의 즉각적이고 공간 효율적인 클론을 지원합니다. 이 클론 복제는 VMware vSphere Storage API – 어레이 통합(VAAI), 백업 검증 및 복구(SnapCenter 소프트웨어), VVOL 클론 복제 및 스냅샷 복사본에 의해 스토리지 시스템으로 오프로드되는 경우에 사용됩니다. 사용 방법은 다음과 같습니다.</block>
  <block id="25d6e9f6ac28ecf0d97aaf9f6609f4d4" category="list-text">VAAI는 ONTAP에서 vSphere 클론 및 마이그레이션(Storage vMotion) 작업을 지원하기 위해 오프로드된 복제본을 지원합니다. FlexClone 라이센스를 사용하면 NetApp FlexVol 볼륨 내에서 빠른 클론을 생성할 수 있지만, 라이센스가 없는 경우에는 더 느린 블록 복사본을 사용하여 복제할 수 있습니다.</block>
  <block id="6f9f0acae1b8d33078f1c061dcc662a3" category="list-text">VVOL 기능을 사용하려면 FlexClone 라이센스가 필요합니다. 단일 데이터 저장소 또는 데이터 저장소 간에 VVOL을 클론 복제할 수 있으며, 스토리지 시스템으로 오프로드되는 VVOL의 vSphere 관리 스냅샷 복사본을 사용할 수 있습니다.</block>
  <block id="4370ed35c8063100f2a5b8da39b82668" category="list-text">SRA(스토리지 복제 어댑터)는 VMware Site Recovery Manager와 함께 사용되며, NAS 환경과 SAN 환경 모두에서 복구를 테스트하려면 FlexClone 라이센스가 필요합니다. SRA는 FlexClone 없이 검색, 복구 및 재보호 워크플로우에 사용할 수 있습니다.</block>
  <block id="3117cf0d132cfe6180ee3db3d5250f7f" category="list-text">* SnapRestore. * SnapRestore 기술을 사용하면 데이터를 복사하지 않고도 제자리에서 볼륨을 즉시 복구할 수 있습니다. 검증 및 복원 작업을 위해 데이터 저장소를 마운트하는 데 사용되는 SnapCenter와 같은 NetApp 백업 및 복구 툴에 필요합니다.</block>
  <block id="a30ea87a20e5dd5b267ec41f29219a1d" category="list-text">SnapMirror. * SnapMirror 기술을 사용하면 ONTAP 온프레미스와 클라우드 간에 데이터를 간단하고 빠르게 복제할 수 있습니다. SnapMirror는 블록 복제 성능을 통해 논리 복제의 버전 유연성을 지원하며 변경된 데이터만 보조 시스템으로 전송합니다. 미러 및/또는 볼트 정책으로 데이터를 보호할 수 있으므로 재해 복구뿐만 아니라 백업을 위한 장기 데이터 보존이 가능합니다. SnapMirror는 비동기 및 동기 관계를 지원하며, ONTAP 9.8은 SnapMirror 비즈니스 연속성을 통해 투명한 애플리케이션 장애 조치를 도입했습니다.</block>
  <block id="23862d7fc14d71369b9feaeb8d7f98b9" category="paragraph">SnapMirror는 Site Recovery Manager를 사용한 SRA 복제에 필요합니다. SnapCenter에서 2차 스토리지 시스템으로 스냅샷 복사본을 복제할 수도 있습니다.</block>
  <block id="0fdef6775eeade832499deceb497e1d8" category="list-text">* SnapCenter. * SnapCenter 소프트웨어는 애플리케이션 정합성을 보장하는 데이터 보호 및 클론 관리를 위한 확장 가능한 유니파이드 플랫폼 및 플러그인 제품군을 제공합니다. SnapCenter 라이센스는 AFF 및 FAS 시스템용 데이터 보호 라이센스 번들에 포함되어 있습니다. VMware vSphere용 SnapCenter 플러그인은 FAS, AFF, Cloud Volumes ONTAP 또는 ONTAP Select와 같은 스토리지 시스템을 사용하는 경우 무료로 제공됩니다. 그러나 SnapRestore 및 FlexClone 라이센스가 필요합니다.</block>
  <block id="a20c69bb9262b2ab09ca5248996e7d63" category="list-text">* MetroCluster. * NetApp MetroCluster는 캠퍼스 또는 도심 지역에서 고가용성 및 재해 복구를 결합하여 사이트 재해와 하드웨어 운영 중단을 모두 방지하는 동기식 복제 솔루션입니다. 데이터 무손실(0 RPO) 및 빠른 복구(RTO(분 이내)를 제공하는 투명한 장애 복구 기능을 갖춘 솔루션을 제공합니다. vSphere Metro Storage Cluster 구성의 일부로 vSphere 환경에서 사용됩니다.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="section-title">ONTAP용 가상화 툴</block>
  <block id="7b0abbba24b3ff594f013e524b352ef1" category="paragraph">NetApp은 ONTAP 및 vSphere와 함께 사용하여 가상화 환경을 관리할 수 있는 몇 가지 독립 실행형 소프트웨어 툴을 제공합니다. 다음 툴은 ONTAP 라이센스와 함께 추가 비용 없이 제공됩니다. 그림 1을 참조하여 vSphere 환경에서 이러한 툴이 함께 작동하는 방식을 보여 줍니다.</block>
  <block id="abdbcbccf079982daa8ac87124199525" category="paragraph">VMware vSphere용 ONTAP 툴은 ONTAP 스토리지를 vSphere와 함께 사용하기 위한 일련의 툴입니다. 이전에 VSC(Virtual Storage Console)라고도 하는 vCenter 플러그인을 사용하면 SAN 또는 NAS를 사용하든지 스토리지 관리 및 효율성 기능을 단순화하고, 가용성을 향상하고, 스토리지 비용과 운영 오버헤드를 줄일 수 있습니다. Best Practice를 사용하여 데이터 저장소를 프로비저닝하고 NFS 및 블록 스토리지 환경에 대한 ESXi 호스트 설정을 최적화합니다. 이러한 모든 이점을 누리게 하려면 ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 이러한 ONTAP 툴을 모범 사례로 사용하는 것이 좋습니다. 여기에는 vCenter용 서버 어플라이언스 및 사용자 인터페이스 확장이 모두 포함됩니다.</block>
  <block id="72c2a2003ef348468d72454dc1a4e214" category="paragraph">VMware용 NetApp NFS 플러그인은 ESXi 호스트에서 ONTAP의 NFS 데이터 저장소와 함께 VAAI 기능을 사용할 수 있도록 지원하는 플러그인입니다. 클론 작업을 위한 복제 오프로드, 일반 가상 디스크 파일의 공간 예약, 스냅샷 복사본 오프로드를 지원합니다. 복제 작업을 스토리지로 오프로드하는 것이 반드시 완료되도록 빨라지는 것은 아니지만 CPU 주기, 버퍼 및 큐와 같은 호스트 리소스를 오프로드합니다. VMware vSphere용 ONTAP 툴을 사용하여 ESXi 호스트에 플러그인을 설치할 수 있습니다.</block>
  <block id="e3454e6928ae7a5f9e8a89f5999b80ad" category="section-title">ONTAP를 위한 VASA 공급자</block>
  <block id="708dacf32313dbab741753dcc3ea39fd" category="paragraph">VASA Provider for ONTAP는 VMware VASA(vStorage APIs for Storage Awareness) 프레임워크를 지원합니다. 이 제품은 구축 편의성을 위해 VMware vSphere용 ONTAP 툴의 일부로 단일 가상 어플라이언스로 제공됩니다. VASA Provider는 vCenter Server를 ONTAP와 연결하여 VM 스토리지를 프로비저닝하고 모니터링할 수 있도록 지원합니다. 이를 통해 VVol(VMware Virtual Volumes) 지원, 스토리지 기능 프로필 관리, 개별 VM VVol 성능, 용량 모니터링 및 프로파일 규정 준수에 대한 경보를 수행할 수 있습니다.</block>
  <block id="0d05ff779ab06152e20062d098f7eb4a" category="section-title">스토리지 복제 어댑터</block>
  <block id="33aa22e838a3c843929f5b6b75f6c56c" category="paragraph">SRA는 VMware SRM(Site Recovery Manager)과 함께 사용하여 운영 및 재해 복구 사이트 간 데이터 복제를 관리하고 DR 복제본을 중단 없이 테스트합니다. 검색, 복구 및 재보호 작업을 자동화할 수 있습니다. Windows SRM 서버 및 SRM 어플라이언스에는 SRA 서버 어플라이언스와 SRA 어댑터가 모두 포함됩니다. SRA는 VMware vSphere용 ONTAP 툴의 일부로 제공됩니다.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">다음 그림에서는 vSphere용 ONTAP 툴을 보여 줍니다.</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93ac3f76e97265952e309b2cbb980030" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP NFS 버전 4 데이터 저장소를 구축하는 단계를 제공합니다.</block>
  <block id="11bbb95c80fd3935828f1472bade3ae4" category="doc">vSphere NFS 데이터 저장소 - ONTAP 버전 4.1</block>
  <block id="0a339846bb9d45c2252cf84f27f8390e" category="paragraph">이 섹션에서는 ONTAP NAS 스토리지를 사용하여 NFS 버전 4.1 데이터 저장소를 생성하는 방법을 설명합니다.</block>
  <block id="d5ffdd3b223c5bb3d1d66e5756977564" category="list-text">vSphere 환경 및 ONTAP를 관리하는 데 필요한 기본 기술</block>
  <block id="a65c730562f6a5feffebe8a600829c71" category="list-text">{ONTAP_VERSION}을 실행하는 ONTAP 스토리지 시스템(FAS/AFF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp Files</block>
  <block id="d5ba6255ccf331629f7b1b4598223d33" category="list-text">ONTAP 자격 증명(SVM 이름, userID, 암호)</block>
  <block id="190ba592a6988abfd7566be9b5c8217a" category="list-text">NFS용 ONTAP 네트워크 포트, SVM 및 LUN 정보</block>
  <block id="d5cb637f6500cfa77d4190ebdfd8cce0" category="inline-link-macro">완성된 NFS 구성 워크시트</block>
  <block id="915142cb27ebec8265b54739a95840b5" category="list-text"><block ref="915142cb27ebec8265b54739a95840b5" category="inline-link-macro-rx"></block></block>
  <block id="8e7f2b8f8c015d7ce248683387c1daf5" category="list-text">vSphere 호스트 정보 {vSphere_version}</block>
  <block id="d7850596008b347e3797ad7dcb7252e5" category="list-text">NFS VMkernel 어댑터 IP 정보입니다</block>
  <block id="7d0a7cdd836d94b19d4ecbce81ba2c1e" category="list-text">ONTAP 시스템 네트워크 데이터 포트, vSphere 호스트 및 연결을 통해</block>
  <block id="a7fb6a7233e9c40554334921be362af1" category="list-text">NFS에 대해 구성된 VLAN</block>
  <block id="d4e890b3139e840bac898dc24d2330a3" category="list-text">구축, 구성 및 바로 사용할 수 있는 VMware vSphere용 ONTAP 툴</block>
  <block id="f2f6f93a63f235f63bf8a14ad398ddd0" category="inline-link">상호 운용성 매트릭스 툴(IMT).</block>
  <block id="2c364f266e330209041f2cf854afab91" category="list-text">과(와) 호환 여부를 점검하십시오<block ref="975c7893d48b02c6727b59b0582d74bc" category="inline-link-rx"></block></block>
  <block id="bc295a5edde99316e021476fd74118c6" category="inline-link-macro">NFS 구성이 지원되는지 확인합니다.</block>
  <block id="564210524eadeca61542a5680bf0afca" category="list-text"><block ref="564210524eadeca61542a5680bf0afca" category="inline-link-macro-rx"></block></block>
  <block id="863feef43abaa752e441459bd37722c3" category="list-text">아래에 제공된 ONTAP 및 vSphere 작업을 완료합니다.</block>
  <block id="1b2d2406823c016e35ebeddf0ec29c66" category="inline-link-macro">NFS에 대한 ONTAP 라이센스를 확인합니다</block>
  <block id="7209cd833425a764d216b4e565ac65c6" category="list-text"><block ref="7209cd833425a764d216b4e565ac65c6" category="inline-link-macro-rx"></block></block>
  <block id="55d2948d4abb6ad9ea1e2b6a5b73460b" category="list-text">system license show 명령을 사용하여 NFS가 나열되는지 확인합니다.</block>
  <block id="0a5e80a3066e5036387d5026a58fe582" category="inline-link-macro">NFS 구성 워크플로우를 따릅니다</block>
  <block id="4b9e38c0f910614d9be47f85cf0f07bc" category="list-text"><block ref="4b9e38c0f910614d9be47f85cf0f07bc" category="inline-link-macro-rx"></block></block>
  <block id="4344c7f5d714fb1797033b7d9cca43fd" category="inline-link-macro">vSphere용 NFS 클라이언트 구성 워크플로우를 따릅니다.</block>
  <block id="c9fb47d82da1089992044972b4b65103" category="paragraph"><block ref="c9fb47d82da1089992044972b4b65103" category="inline-link-macro-rx"></block></block>
  <block id="883a5adf98ba177c28c5bc7d95e28763" category="paragraph">이러한 작업이 완료되면 NFS 데이터 저장소가 가상 머신 프로비저닝에 사용할 준비가 된 것입니다.</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="doc">모범 사례</block>
  <block id="ff53ee8001042abcefe5c912d0b5012f" category="section-title">vSphere 데이터 저장소 및 프로토콜 기능</block>
  <block id="7a787d6880ccfe1032af2f4288ce3901" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템의 데이터 저장소에 VMware vSphere를 연결하는 데 5개의 프로토콜이 사용됩니다.</block>
  <block id="6b8f0029ce30f9b4d5fe0def33875511" category="list-text">FC</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE 를 참조하십시오</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="list-text">NFS 를 참조하십시오</block>
  <block id="cbc9a42283809f1edcb32b4a495813f9" category="paragraph">FC, FCoE, NVMe/FC 및 iSCSI는 VMFS(vSphere Virtual Machine File System)를 사용하여 ONTAP 볼륨에 포함된 ONTAP LUN 또는 네임스페이스 내에 VM을 저장하는 블록 프로토콜입니다. VMware는 vSphere 7.0부터 운영 환경에서는 더 이상 소프트웨어 FCoE를 지원하지 않습니다. NFS는 VMFS 없이 VM을 데이터 저장소(단순한 ONTAP 볼륨)에 배치하는 파일 프로토콜입니다. 또한 게스트 OS에서 ONTAP으로 SMB, iSCSI 또는 NFS를 직접 사용할 수도 있습니다.</block>
  <block id="0f2f72ef3f176b98134caf100a06cf5f" category="inline-link">VMware 구성 최대값</block>
  <block id="6a6d2374b838393f6805b58d97c2c490" category="paragraph">다음 표에는 ONTAP에서 vSphere가 지원하는 기존 데이터 저장소 기능이 나와 있습니다. 이 정보는 VVOL 데이터 저장소에는 적용되지 않지만 일반적으로 지원되는 ONTAP 릴리즈를 사용하는 vSphere 6.x 및 7.x 릴리즈에는 적용됩니다. 상담도 할 수 있습니다<block ref="26c5407c98ec413c85131fd8c0d178b4" category="inline-link-rx"></block> 특정 제한 사항을 확인하기 위한 특정 vSphere 릴리즈</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">기능/특징</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">형식</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">VMFS 또는 RDM(Raw Device Mapping)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS 또는 RDM</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">최대 데이터 저장소 또는 LUN 수</block>
  <block id="468abcddfc22ae5cb2288b9937b300fb" category="cell">256개 타겟/HBA</block>
  <block id="72097e262592a146da0e4e856068965b" category="cell">256개 타겟</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256개 마운트 기본 NFS. MaxVolumes는 8입니다. VMware vSphere용 ONTAP 툴을 사용하여 256으로 늘리십시오.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">최대 데이터 저장소 크기입니다</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">FlexGroup 볼륨에서 100TB FlexVol 볼륨 이상</block>
  <block id="a4b27c6cd629522064dc48306e2bf8bb" category="cell">최대 데이터스토어 파일 크기(vSphere 버전 5.5 및 VMFS 5 이상을 사용하는 VMDK의 경우)</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62TB</block>
  <block id="ddf38e51732c3f7da57dc13c31a5483b" category="cell">16TB 62TB는 vSphere에서 지원하는 최대 크기입니다.</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">LUN 또는 파일 시스템당 최적의 큐 크기</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">다음 표에는 지원되는 VMware 스토리지 관련 기능이 나와 있습니다.</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">용량/기능</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">마이그레이션</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">마이그레이션</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">VMware HA</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">SDRS(Storage Distributed Resource Scheduler)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">VMware VADP(vStorage APIs for Data Protection) 지원 백업 소프트웨어</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">VM 내의 MSCS(Microsoft Cluster Service) 또는 장애 조치 클러스터링</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">예 *</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">지원되지 않습니다</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">내결함성</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">사이트 복구 관리자</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">씬 프로비저닝된 VM(가상 디스크)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">예 VAAI를 사용하지 않을 때 NFS의 모든 VM에 대해 이 설정이 기본값입니다.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">VMware 기본 다중 경로</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Windows Server 장애 조치 클러스터링에 대한 설치</block>
  <block id="547211ca8a6b93fee863925a03cd341b" category="paragraph">* NetApp은 VMFS 데이터 저장소에서 멀티writer를 사용하는 VMDK가 아닌 Microsoft 클러스터에 게스트 내 iSCSI를 사용할 것을 권장합니다. 이 접근 방식은 Microsoft 및 VMware에서 완벽하게 지원되며 ONTAP(사내 또는 클라우드의 ONTAP 시스템에 대한 SnapMirror)를 통해 뛰어난 유연성을 제공하고 쉽게 구성 및 자동화할 수 있으며 SnapCenter를 통해 보호할 수 있습니다. vSphere 7은 새로운 클러스터 VMDK 옵션을 추가합니다. 이는 멀티 writer를 사용하는 VMDK와 다르지만 클러스터 VMDK 지원을 활성화한 FC 프로토콜을 통해 제공되는 데이터 저장소가 필요합니다. 기타 제한 사항이 적용됩니다. VMware 를 참조하십시오<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> 구성 지침 설명서.</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">다음 표에는 지원되는 ONTAP 스토리지 관리 기능이 나와 있습니다.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">데이터 중복제거</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">어레이에 대한 비용 절감</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">데이터 저장소의 절감 효과</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">씬 프로비저닝</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">데이터 저장소 또는 RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">데이터 저장소</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">데이터 저장소 크기를 조정합니다</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">성장만 하십시오</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">확장, 자동 확장 및 축소</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Windows, Linux 애플리케이션용 SnapCenter 플러그인(게스트)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">VMware vSphere용 ONTAP 툴을 사용하여 모니터링 및 호스트 구성</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">VMware vSphere용 ONTAP 툴을 사용하여 프로비저닝</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">다음 표에는 지원되는 백업 기능이 나와 있습니다.</block>
  <block id="1208a2df45bea7d2edea13f0b0cbc686" category="cell">ONTAP 스냅샷 복사본</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM은 복제된 백업에서 지원됩니다</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">volume SnapMirror를 선택합니다</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">VMDK 이미지 액세스</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">VADP 지원 백업 소프트웨어</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">VADP 지원 백업 소프트웨어, vSphere Client 및 vSphere Web Client 데이터 저장소 브라우저</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">VMDK 파일 레벨 액세스</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">VADP 지원 백업 소프트웨어, Windows만 해당</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">VADP 지원 백업 소프트웨어 및 타사 애플리케이션</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">NDMP 세분성</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">데이터 저장소 또는 VM</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">스토리지 프로토콜 선택</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템은 모든 주요 스토리지 프로토콜을 지원하므로 고객은 기존 및 계획된 네트워킹 인프라, 직원 기술에 따라 환경에 가장 적합한 프로토콜을 선택할 수 있습니다. NetApp 테스트 결과, 유사한 회선 속도에서 실행되는 프로토콜 간에는 일반적으로 차이가 거의 없으므로 원시 프로토콜 성능보다 네트워크 인프라 및 직원 기능에 초점을 맞추는 것이 가장 좋습니다.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">프로토콜 선택을 고려할 때 다음과 같은 요소가 유용할 수 있습니다.</block>
  <block id="c0ab9c6170165211885267a562d057a2" category="list-text">* 현재 고객 환경 * IT 팀은 일반적으로 이더넷 IP 인프라 관리에 능숙하지만, 모든 팀이 FC SAN 패브릭 관리에 능숙하지는 않습니다. 그러나 스토리지 트래픽용으로 설계되지 않은 범용 IP 네트워크를 사용하면 제대로 작동하지 않을 수 있습니다. 현재 보유하고 있는 네트워킹 인프라, 계획된 개선 사항, 이를 관리할 직원의 기술 및 가용성을 고려하십시오.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">* 손쉬운 설정 * FC 패브릭의 초기 구성(추가 스위치 및 케이블 연결, 조닝, HBA 및 펌웨어의 상호 운용성 검증) 외에도 블록 프로토콜은 LUN 생성 및 매핑과 게스트 OS의 검색 및 포맷이 필요합니다. NFS 볼륨을 생성 및 내보낸 후에는 ESXi 호스트에 의해 마운트되며 사용할 수 있습니다. NFS에는 특별한 하드웨어 검증 또는 관리 펌웨어가 없습니다.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">* 손쉬운 관리. * SAN 프로토콜을 사용할 경우 더 많은 공간이 필요한 경우 LUN 증가, 새로운 크기를 검색하기 위한 재검색, 파일 시스템 확장 등 몇 가지 단계가 필요합니다. LUN을 증대할 수는 있지만 LUN 크기를 줄이는 것은 불가능하므로 사용하지 않는 공간을 복구하려면 추가 작업이 필요합니다. NFS를 사용하면 위나 아래로 쉽게 사이징할 수 있으며, 이러한 크기 조정은 스토리지 시스템에서 자동화할 수 있습니다. SAN은 게스트 OS TRIM/UNMAP 명령을 통해 공간 재확보를 제공하여 삭제된 파일의 공간을 어레이로 반환할 수 있도록 합니다. 이러한 유형의 공간 재확보는 NFS 데이터 저장소에서 더 어렵습니다.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">* 스토리지 공간 투명성. * 씬 프로비저닝이 즉시 절약 효과를 반환하므로 NFS 환경에서는 일반적으로 스토리지 사용률을 쉽게 확인할 수 있습니다. 마찬가지로, 같은 데이터 저장소 또는 다른 스토리지 시스템 볼륨에 있는 다른 VM에 대해서도 중복 제거 및 클론 생성 절약 효과를 즉시 사용할 수 있습니다. 일반적으로 VM 밀도는 NFS 데이터 저장소에서 더 높으며, 관리할 데이터 저장소 수를 줄여 데이터 중복 제거 비용을 절감할 수 있습니다.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">데이터 저장소 레이아웃</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="inline-link-macro">권장되는 ESXi 호스트 및 기타 ONTAP 설정</block>
  <block id="066ed1c180617b2f9028c1f789078de4" category="paragraph">ONTAP 스토리지 시스템은 VM 및 가상 디스크용 데이터 저장소를 유연하게 생성할 수 있습니다. VSC를 사용하여 vSphere용 데이터 저장소를 프로비저닝할 때는 섹션에 나와 있는 ONTAP 모범 사례가 많이 적용되지만 <block ref="311a0f5ed21de3c81d57d9c08f2ace49" category="inline-link-macro-rx"></block>) 다음은 고려해야 할 몇 가지 추가 지침입니다.</block>
  <block id="73ab3808ccb313675f9b890edf67fd09" category="list-text">ONTAP NFS 데이터 저장소를 사용하여 vSphere를 구축하면 관리가 용이한 고성능 구축이 가능하기 때문에 블록 기반 스토리지 프로토콜로는 얻을 수 없는 VM-데이터 저장소 비율을 제공할 수 있습니다. 이 아키텍처를 사용하면 데이터 저장소 밀도가 10배 증가하여 데이터 저장소 수가 서로 관련지어 줄어들 수 있습니다. 더 큰 데이터 저장소가 스토리지 효율성에 이점을 제공하고 운영 이점을 제공할 수 있지만, 하드웨어 리소스의 최대 성능을 얻기 위해 최소 4개의 데이터 저장소(FlexVol 볼륨)를 사용하여 VM을 단일 ONTAP 컨트롤러에 저장하는 것이 좋습니다. 이 방법을 사용하면 복구 정책이 서로 다른 데이터 저장소를 설정할 수도 있습니다. 비즈니스 요구 사항에 따라 다른 사람보다 더 자주 백업하거나 복제할 수 있는 경우도 있습니다. 설계상 확장되므로 성능을 위해 FlexGroup 볼륨에는 여러 데이터 저장소가 필요하지 않습니다.</block>
  <block id="68281e9d236ee27e21f68ce5838462f1" category="list-text">FlexVol 볼륨은 ONTAP 9.8 FlexGroup 볼륨, NFS 데이터 저장소부터 사용하는 것이 좋습니다. qtree와 같은 다른 ONTAP 스토리지 컨테이너는 현재 VMware vSphere용 ONTAP 툴에서 지원되지 않으므로 일반적으로 권장되지 않습니다. 단일 볼륨에 여러 qtree로 데이터 저장소를 구축하면 데이터 저장소 수준 할당량 또는 VM 파일 클론의 이점을 누릴 수 있는 고도로 자동화된 환경에 유용할 수 있습니다.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">FlexVol 볼륨 데이터 저장소의 적절한 크기는 약 4TB에서 8TB입니다. 이 크기는 성능, 관리 용이성 및 데이터 보호 측면에서 우수한 균형 점입니다. 작게 시작하고(예: 4TB) 필요에 따라 데이터 저장소를 최대 100TB까지 확장할 수 있습니다. 작은 데이터 저장소가 백업이나 재해 발생 후 복구 속도가 빨라지므로 클러스터 간에 빠르게 이동할 수 있습니다. ONTAP 자동 크기 조정을 사용하면 사용된 공간이 변경될 때 볼륨을 자동으로 확대 및 축소할 수 있습니다. VMware vSphere 데이터 저장소 용량 할당 마법사용 ONTAP 툴은 새 데이터 저장소에 대해 기본적으로 자동 크기 조정을 사용합니다. System Manager 또는 명령줄을 사용하여 확장 및 축소 임계값과 최대 및 최소 크기를 추가로 사용자 지정할 수 있습니다.</block>
  <block id="12346208f1923ebe162c32f3c4ccf23a" category="list-text">또는 FC, iSCSI 또는 FCoE에서 액세스하는 LUN으로 VMFS 데이터 저장소를 구성할 수도 있습니다. VMFS를 사용하면 클러스터의 모든 ESX 서버에서 기존 LUN에 동시에 액세스할 수 있습니다. VMFS 데이터 저장소의 크기는 최대 64TB이고 최대 32개의 2TB LUN(VMFS 3) 또는 단일 64TB LUN(VMFS 5)으로 구성될 수 있습니다. ONTAP 최대 LUN 크기는 대부분의 시스템에서 16TB이고, 모든 SAN 어레이 시스템에서 128TB입니다. 따라서 16TB LUN 4개를 사용하여 대부분의 ONTAP 시스템에서 VMFS 5 데이터 저장소의 최대 크기를 생성할 수 있습니다. 여러 LUN(하이엔드 FAS 또는 AFF 시스템 사용)을 사용하는 높은 I/O 워크로드에는 성능 이점이 있지만, 데이터 저장소 LUN을 생성, 관리 및 보호하고 가용성 위험을 높이기 위한 관리 복잡성이 추가되어 이러한 이점이 상쇄됩니다. 일반적으로 각 데이터 저장소마다 큰 단일 LUN을 사용하는 것이 좋으며 16TB 데이터 저장소를 넘어서는 특별한 요구 사항이 있는 경우에만 확장할 것을 권장합니다. NFS와 마찬가지로, 단일 ONTAP 컨트롤러에서 성능을 최대화하기 위해 여러 데이터 저장소(볼륨)를 사용하는 것을 고려합니다.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">기존 게스트 운영 체제(OS)는 최고의 성능과 스토리지 효율성을 위해 스토리지 시스템과 조율해야 했습니다. 그러나 Red Hat과 같은 Microsoft 및 Linux 배포업체에서 제공하는 최신 공급업체 지원 OS는 더 이상 가상 환경에서 파일 시스템 파티션을 기본 스토리지 시스템의 블록과 일치시킬 필요가 없습니다. 조정이 필요한 이전 OS를 사용하는 경우 NetApp 지원 기술 자료에서 "VM 정렬"을 사용하는 문서를 검색하거나 NetApp 세일즈 또는 파트너 담당자에게 TR-3747 사본을 요청합니다.</block>
  <block id="3c8b400142a84af9ebe6262bce512ccb" category="list-text">게스트 OS 내에서 조각 모음 유틸리티를 사용하지 마십시오. 성능 이점이 없으며 스토리지 효율성 및 스냅샷 복사본 공간 사용에 영향을 줍니다. 또한 게스트 OS에서 가상 데스크톱에 대한 검색 인덱싱을 해제하는 것도 고려하십시오.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP은 혁신적인 스토리지 효율성 기능으로 업계에서 최고의 가용성을 제공하므로 사용 가능한 디스크 공간을 최대한 활용할 수 있습니다. AFF 시스템은 기본 인라인 중복제거 및 압축을 사용해 이 효율성을 더욱 높여줍니다. 데이터는 애그리게이트 내 모든 볼륨에서 중복 제거되므로, 더 이상 단일 데이터 저장소 내에서 유사한 운영 체제 및 유사한 애플리케이션을 그룹화할 필요가 없으며 절약 효과를 극대화할 수 있습니다.</block>
  <block id="154cd001dd3ef8eabdf209f4faf2ddde" category="inline-link">TR-3633: Data ONTAP 기반 Oracle 데이터베이스</block>
  <block id="8f2f733fd8f32e7aaa1ee62e48a55117" category="list-text">경우에 따라 데이터 저장소가 필요하지 않을 수도 있습니다. 최상의 성능과 관리 효율성을 얻으려면 데이터베이스 및 일부 애플리케이션과 같은 높은 I/O 애플리케이션에 데이터 저장소를 사용하지 마십시오. 대신 게스트에 의해 또는 RDM을 통해 관리되는 NFS 또는 iSCSI 파일 시스템과 같은 게스트 소유 파일 시스템을 고려해 보십시오. 구체적인 애플리케이션 지침은 해당 애플리케이션에 대한 NetApp 기술 보고서를 참조하십시오. 예를 들면, 다음과 같습니다.<block ref="8cb1dd6561aaa08584e14e742f429a3e" category="inline-link-rx"></block> 에는 유용한 세부 정보와 함께 가상화에 대한 섹션이 있습니다.</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">1등급 디스크(또는 개선된 가상 디스크)는 vSphere 6.5 이상을 사용하는 VM과 독립적으로 vCenter 관리 디스크를 사용할 수 있습니다. 주로 API에서 관리되지만, VVOL은 특히 OpenStack 또는 Kubernetes 툴로 관리할 때 유용합니다. ONTAP 및 VMware vSphere용 ONTAP 툴을 통해 지원됩니다.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">데이터 저장소 및 VM 마이그레이션</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">다른 스토리지 시스템의 기존 데이터 저장소에서 ONTAP로 VM을 마이그레이션할 때 다음 몇 가지 사항을 염두에 두어야 합니다.</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Storage vMotion을 사용하여 대량의 가상 머신을 ONTAP로 이동합니다. 이 접근 방식은 실행 중인 VM에 중단 없이 적용할 수 있을 뿐만 아니라 인라인 중복제거 및 압축과 같은 ONTAP 스토리지 효율성 기능을 사용하여 마이그레이션 시 데이터를 처리할 수 있습니다. vCenter 기능을 사용하여 인벤토리 목록에서 여러 VM을 선택한 다음 적절한 시간에 마이그레이션을 예약합니다(작업을 클릭하는 동안 Ctrl 키 사용).</block>
  <block id="008116a0d875d0de070d1a10314abbaa" category="list-text">적절한 대상 데이터 저장소로 마이그레이션을 신중하게 계획할 수 있지만, 대개 대량으로 마이그레이션한 다음 필요에 따라 나중에 구성하는 것이 더 간단합니다. 서로 다른 스냅샷 일정 등과 같은 특정 데이터 보호 요구사항이 있는 경우 이 접근 방식을 사용하여 다른 데이터 저장소로 마이그레이션할 수 있습니다.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">대부분의 VM 및 해당 스토리지는 실행 중(핫) 마이그레이션될 수 있지만 다른 스토리지 시스템에서 ISO, LUN 또는 NFS 볼륨과 같은 연결된(데이터 저장소 아님) 스토리지를 마이그레이션하려면 콜드 마이그레이션이 필요할 수 있습니다.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="282806c282d96fdf15b71278587f2bfe" category="list-text">보다 신중한 마이그레이션이 필요한 가상 머신에는 연결된 스토리지를 사용하는 데이터베이스와 애플리케이션이 포함됩니다. 일반적으로 응용 프로그램의 도구를 사용하여 마이그레이션을 관리합니다. Oracle의 경우 RMAN 또는 ASM과 같은 Oracle 툴을 사용하여 데이터베이스 파일을 마이그레이션할 수 있습니다. 을 참조하십시오<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> 를 참조하십시오. 마찬가지로 SQL Server의 경우 SQL Server Management Studio 또는 SnapManager for SQL Server 또는 SnapCenter와 같은 NetApp 툴을 사용하는 것이 좋습니다.</block>
  <block id="00f47a68ebd81ba943b17dbc30d78db6" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 가장 중요한 Best Practice는 VMware vSphere용 ONTAP 툴 플러그인(이전의 가상 스토리지 콘솔)을 설치하고 사용하는 것입니다. 이 vCenter 플러그인을 사용하면 SAN 또는 NAS를 사용할 때 스토리지 관리를 간소화하고, 가용성을 높이고, 스토리지 비용과 운영 오버헤드를 줄일 수 있습니다. 데이터 저장소를 프로비저닝하는 모범 사례를 사용하고 다중 경로 및 HBA 시간 초과를 위해 ESXi 호스트 설정을 최적화합니다(부록 B에 설명되어 있음). vCenter 플러그인이기 때문에 vCenter 서버에 연결하는 모든 vSphere 웹 클라이언트에서 사용할 수 있습니다.</block>
  <block id="21eddd0bd26d119e0602b3ceb65aff45" category="paragraph">이 플러그인은 vSphere 환경에서 다른 ONTAP 툴을 사용하는 데에도 도움이 됩니다. VMware VAAI용 NFS 플러그인을 설치하면 VM 클론 복제 작업을 위해 ONTAP로 복사본 오프로드를 수행하고, 일반 가상 디스크 파일의 공간 예약 및 ONTAP 스냅샷 복사본 오프로드를 수행할 수 있습니다.</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">플러그인은 ONTAP용 VASA Provider의 다양한 기능을 위한 관리 인터페이스이기도 하여, VVOL을 통한 스토리지 정책 기반 관리를 지원합니다. VMware vSphere용 ONTAP 툴을 등록한 후 이를 사용하여 스토리지 기능 프로필을 생성하고 이를 스토리지에 매핑하며 시간이 지남에 따라 데이터 저장소가 프로파일을 준수하는지 확인합니다. VASA Provider는 VVOL 데이터 저장소를 생성하고 관리하는 인터페이스도 제공합니다.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">일반적으로, vCenter 내에서 VMware vSphere 인터페이스에 ONTAP 툴을 사용하여 기존 데이터 저장소와 VVOL 데이터 저장소를 프로비저닝하면 모범 사례를 따를 수 있습니다.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">일반 네트워킹</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 네트워크 설정을 구성하는 것은 다른 네트워크 구성과 마찬가지로 간단합니다. 다음은 고려해야 할 몇 가지 사항입니다.</block>
  <block id="9600865cce7d923667012211ddac46de" category="list-text">스토리지 네트워크 트래픽을 다른 네트워크와 분리합니다. 전용 VLAN 또는 스토리지에 개별 스위치를 사용하면 별도의 네트워크를 구축할 수 있습니다. 스토리지 네트워크가 업링크와 같은 물리적 경로를 공유하는 경우 충분한 대역폭을 확보하기 위해 QoS 또는 추가 업링크 포트가 필요할 수 있습니다. 호스트를 스토리지에 직접 연결하지 마십시오. 스위치를 사용하여 이중화 경로를 갖게 되고 VMware HA가 별도의 작업 없이 작동할 수 있습니다.</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">원하는 경우 점보 프레임을 사용할 수 있으며 네트워크에서 지원됩니다(특히 iSCSI 사용 시). 사용하는 경우 스토리지와 ESXi 호스트 간 경로에서 모든 네트워크 디바이스, VLAN 등에 동일하게 구성되었는지 확인합니다. 그렇지 않으면 성능 또는 연결 문제가 나타날 수 있습니다. MTU는 ESXi 가상 스위치, VMkernel 포트 및 각 ONTAP 노드의 물리적 포트 또는 인터페이스 그룹에서도 동일하게 설정되어야 합니다.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">ONTAP 클러스터 내의 클러스터 네트워크 포트에서 네트워크 흐름 제어를 사용하지 않도록 설정하는 것만 좋습니다. NetApp은 데이터 트래픽에 사용되는 나머지 네트워크 포트에 대한 모범 사례를 위해 다른 권장사항을 제공하지 않습니다. 필요에 따라 활성화하거나 비활성화해야 합니다. 을 참조하십시오<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> 흐름 제어에 대한 자세한 배경 정보</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">ESXi 및 ONTAP 스토리지 어레이가 이더넷 스토리지 네트워크에 연결되어 있는 경우, 이러한 시스템이 RSTP(Rapid Spanning Tree Protocol) 에지 포트로 연결되거나 Cisco PortFast 기능을 사용하여 연결되는 이더넷 포트를 구성하는 것이 좋습니다. Cisco PortFast 기능을 사용하고 ESXi 서버 또는 ONTAP 스토리지 어레이에 802.1Q VLAN 트렁킹을 사용하는 환경에서는 스패닝 트리 포트패스트 트렁크 기능을 활성화하는 것이 좋습니다.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">Link Aggregation에 대해 다음 모범 사례를 따르는 것이 좋습니다.</block>
  <block id="102e4f88579e89519d8c614561d5e302" category="list-text">Cisco의 vPC(Virtual PortChannel)와 같은 다중 섀시 링크 집선 그룹 접근 방식을 사용하여 두 개의 개별 스위치 섀시에서 포트의 링크 집계를 지원하는 스위치를 사용합니다.</block>
  <block id="f331781b955fd46506835e783c953ed4" category="list-text">LACP가 구성된 dvSwitch 5.1 이상을 사용하지 않는 한 ESXi에 연결된 스위치 포트에 대해 LACP를 사용하지 않도록 설정합니다.</block>
  <block id="eb8cf3a79d16ed9f0e2c1de65c379bc5" category="list-text">LACP를 사용하여 IP 해시를 사용하는 동적 멀티모드 인터페이스 그룹을 통해 ONTAP 스토리지 시스템에 대한 링크 애그리게이트를 생성합니다.</block>
  <block id="8ebcba6104088fb46f64395277d21edd" category="list-text">ESXi에서 IP 해시 팀 구성 정책을 사용합니다.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">다음 표에는 네트워크 구성 항목에 대한 요약과 설정이 적용되는 위치가 나와 있습니다.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">항목</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">스위치</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">노드</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">IP 주소입니다</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">아니요**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Link Aggregation</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">가상 스위치</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">아니요 *</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">VMkernel 및 VM 포트 그룹</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">흐름 제어</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">스패닝 트리</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU(점보 프레임의 경우)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">가상 스위치 및 VMkernel 포트(9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">예(최대로 설정)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">예(9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">페일오버 그룹</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">예(생성)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">예(선택)</block>
  <block id="93e04df6f821105fd0ab88e95eaee167" category="paragraph">* SVM LIF는 VLAN, MTU 및 기타 설정이 있는 포트, 인터페이스 그룹 또는 VLAN 인터페이스에 연결되지만 SVM 레벨에서 설정이 관리되지 않습니다.</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">** 이러한 디바이스에는 자체 관리 IP 주소가 있지만 이러한 주소는 ESXi 스토리지 네트워킹의 맥락에서 사용되지 않습니다.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN(FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">vSphere에서는 블록 스토리지 LUN을 사용하는 세 가지 방법이 있습니다.</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">VMFS 데이터 저장소 사용</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">RDM(Raw Device Mapping) 사용</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">VM 게스트 OS에서 소프트웨어 이니시에이터에 의해 액세스 및 제어되는 LUN입니다</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS는 공유 스토리지 풀인 데이터 저장소를 제공하는 고성능 클러스터 파일 시스템입니다. VMFS 데이터 저장소는 FC, iSCSI, FCoE 또는 NVMe 네임스페이스를 사용하여 액세스할 수 있는 LUN으로 구성할 수 있으며 NVMe/FC 프로토콜을 통해 액세스할 수 있습니다. VMFS를 사용하면 클러스터의 모든 ESX 서버에서 기존 LUN에 동시에 액세스할 수 있습니다. ONTAP 최대 LUN 크기는 일반적으로 16TB입니다. 따라서 64TB의 최대 크기 VMFS 5 데이터 저장소(이 섹션의 첫 번째 표 참조)는 16TB LUN 4개를 사용하여 생성됩니다(모든 SAN 어레이 시스템은 64TB의 최대 VMFS LUN 크기를 지원합니다). ONTAP LUN 아키텍처에는 작은 개별 큐 깊이가 없기 때문에 ONTAP의 VMFS 데이터 저장소는 상대적으로 간단한 방식으로 기존 스토리지 아키텍처보다 더 큰 규모로 확장할 수 있습니다.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">vSphere에는 NMP(기본 경로 다중화)라고 하는 여러 스토리지 디바이스 경로에 대한 기본 지원이 포함되어 있습니다. NMP는 지원되는 스토리지 시스템의 스토리지 유형을 감지하고 NMP 스택을 자동으로 구성하여 사용 중인 스토리지 시스템의 기능을 지원합니다.</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">NMP 및 NetApp ONTAP는 모두 ALUA(Asymmetric Logical Unit Access)를 지원하여 최적화된 경로와 최적화되지 않은 경로를 협상합니다. ONTAP에서 ALUA에 최적화된 경로는 액세스하는 LUN을 호스팅하는 노드의 타겟 포트를 사용하여 직접 데이터 경로를 따릅니다. vSphere와 ONTAP 모두에서 ALUA는 기본적으로 사용하도록 설정되어 있습니다. NMP는 ONTAP 클러스터를 ALUA로 인식하며 ALUA 스토리지 어레이 유형 플러그인('VMW_SATP_ALUA')을 사용하고 라운드 로빈 경로 선택 플러그인('VMW_PSP_RR')을 선택합니다.</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6은 최대 256개의 LUN과 최대 1,024개의 LUN 총 경로를 지원합니다. 이러한 제한을 초과하는 LUN 또는 경로는 ESXi에서 표시되지 않습니다. 최대 LUN 수를 가정할 때 경로 제한에서는 LUN당 경로 수를 4개까지 지정할 수 있습니다. 대규모 ONTAP 클러스터에서는 LUN 제한보다 먼저 경로 제한에 도달할 수 있습니다. 이 제한을 해결하기 위해 ONTAP은 릴리즈 8.3 이상에서 선택적 LUN 맵(SLM)을 지원합니다.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="a1319b3463fde689889152797a3cf966" category="paragraph">SLM은 특정 LUN에 경로를 알리는 노드를 제한합니다. NetApp 모범 사례로서, SVM당 노드당 하나 이상의 LIF를 가지고 SLM을 사용하여 LUN 및 HA 파트너를 호스팅하는 노드에 공고되는 경로를 제한하는 것입니다. 다른 경로는 있지만 기본적으로 광고되지 않습니다. SLM 내에서 ADD 및 REMOVE 노드 인수로 보급된 경로를 수정할 수 있습니다. 8.3 이전 릴리즈에서 생성된 LUN은 모든 경로를 광고하고 호스팅 HA 쌍의 경로만 광고하도록 수정해야 합니다. SLM에 대한 자세한 내용은 의 섹션 5.9를 참조하십시오<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. 이전 portset 방법을 사용하여 LUN에 사용 가능한 경로를 더 줄일 수도 있습니다. Portsets는 igroup의 이니시에이터가 LUN을 볼 수 있는 가시적인 경로의 수를 줄여 줍니다.</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM은 기본적으로 활성화되어 있습니다. 포트 세트를 사용하지 않는 경우 추가 구성이 필요하지 않습니다.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Data ONTAP 8.3 이전에 생성된 LUN의 경우 'lun mapping remove-reporting-nodes' 명령을 실행하여 보고 노드를 제거하고 LUN 소유 노드 및 해당 HA 파트너에 대한 LUN 액세스를 제한하여 SLM을 수동으로 적용합니다.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">블록 프로토콜(iSCSI, FC 및 FCoE)은 고유한 이름과 함께 LUN ID 및 일련 번호를 사용하여 LUN에 액세스합니다. FC 및 FCoE는 WWNs 및 WWPN(Worldwide Name)을 사용하며 iSCSI는 IQN(iSCSI Qualified Name)을 사용합니다. 스토리지 내 LUN의 경로는 블록 프로토콜에는 의미가 없으며 프로토콜의 어느 곳에도 표시되지 않습니다. 따라서 LUN만 포함된 볼륨은 내부적으로 마운트할 필요가 없으며, 데이터 저장소에 사용되는 LUN이 포함된 볼륨에는 접합 경로가 필요하지 않습니다. ONTAP의 NVMe 하위 시스템은 비슷하게 작동합니다.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">기타 모범 사례:</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">가용성과 이동성을 극대화하기 위해 ONTAP 클러스터의 각 노드에서 논리 인터페이스(LIF)를 생성해야 합니다. ONTAP SAN 모범 사례는 노드당 물리적 포트 2개와 LIF를 각 패브릭에 대해 하나씩 사용하는 것입니다. ALUA는 경로를 구문 분석하고 활성 최적화(직접) 경로와 최적화되지 않은 활성 경로를 식별하는 데 사용됩니다. ALUA는 FC, FCoE 및 iSCSI에 사용됩니다.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">iSCSI 네트워크의 경우 여러 가상 스위치가 있을 때 NIC 티밍을 사용하여 서로 다른 네트워크 서브넷에 있는 여러 VMkernel 네트워크 인터페이스를 사용합니다. 또한 여러 물리적 스위치에 연결된 여러 물리적 NIC를 사용하여 HA를 제공하고 처리량을 늘릴 수 있습니다. 다음 그림은 다중 경로 연결의 예입니다. ONTAP에서 둘 이상의 스위치에 연결된 2개 이상의 링크를 사용하여 페일오버에 단일 모드 인터페이스 그룹을 구성하거나 LACP 또는 다중 모드 인터페이스 그룹과 함께 다른 Link-Aggregation 기술을 사용하여 HA와 링크 집계의 이점을 제공합니다.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">대상 인증을 위해 ESXi에서 CHAP(Challenge-Handshake Authentication Protocol)를 사용하는 경우 ONTAP에서 CLI('vserver iSCSI security create') 또는 System Manager(스토리지 &gt; SVM &gt; SVM 설정 &gt; 프로토콜 &gt; iSCSI에서 이니시에이터 보안 편집)를 사용하여 CHAP를 구성해야 합니다.</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">VMware vSphere용 ONTAP 툴을 사용하여 LUN 및 igroup을 생성하고 관리합니다. 이 플러그인은 서버의 WWPN을 자동으로 확인하여 적절한 igroup을 생성합니다. 또한 모범 사례에 따라 LUN을 구성하고 올바른 igroup에 매핑합니다.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">물리적 및 가상 호환성 모드</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">RDM은 관리하기가 더 어려우며 앞에서 설명한 대로 제한된 경로도 사용할 수 있으므로 주의해서 사용해야 합니다. ONTAP LUN은 둘 다 지원합니다<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">ONTAP NVMe/FC 호스트 구성 가이드</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">vSphere 7.0에서 NVMe/FC를 사용하는 방법에 대한 자세한 내용은 다음을 참조하십시오<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> 및<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>다음 그림에서는 vSphere 호스트에서 ONTAP LUN으로의 다중 경로 연결을 보여 줍니다.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="section-title">FlexGroup</block>
  <block id="f203949f2e35204098b66b9c1519b66e" category="paragraph">ONTAP 9.8은 vSphere에서 FlexGroup 데이터 저장소를 지원하며, VMware vSphere 9.8 릴리즈용 ONTAP 툴도 추가로 지원합니다. FlexGroup은 대규모 데이터 저장소의 생성을 간소화하고 여러 구성 볼륨을 자동으로 생성하여 ONTAP 시스템의 성능을 극대화합니다. 전체 ONTAP 클러스터의 강력한 기능을 갖춘 확장 가능한 단일 vSphere 데이터 저장소에 FlexGroup with vSphere를 사용하십시오.</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">ONTAP 9.8은 vSphere 워크로드를 사용한 광범위한 시스템 테스트 외에도 FlexGroup 데이터 저장소를 위한 새로운 복제 오프로드 메커니즘도 추가합니다. 이렇게 하면 향상된 복제 엔진을 사용하여 소스 및 대상 모두에서 액세스할 수 있도록 하면서 백그라운드에서 구성 요소간에 파일을 복사할 수 있습니다. 여러 복사본은 필요할 때 규모에 따라 구성 요소 내에서 즉시 사용 가능한 공간 효율적인 파일 클론을 사용합니다.</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">또한 ONTAP 9.8은 FlexGroup 파일에 대한 새로운 파일 기반 성능 메트릭(IOPS, 처리량, 지연 시간)을 추가하며, 이러한 메트릭은 VMware vSphere 대시보드 및 VM 보고서용 ONTAP 툴에서 확인할 수 있습니다. VMware vSphere 플러그인용 ONTAP 툴을 사용하면 최대 및/또는 최소 IOPS의 조합을 사용하여 서비스 품질(QoS) 규칙을 설정할 수도 있습니다. 데이터 저장소의 모든 VM에 대해 또는 특정 VM에 대해 개별적으로 설정할 수 있습니다.</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">다음은 NetApp에서 개발한 몇 가지 추가 모범 사례입니다.</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">FlexGroup 프로비저닝 기본값을 사용합니다. VMware vSphere용 ONTAP 툴은 vSphere 내에서 FlexGroup를 생성 및 마운트하기 때문에 권장되지만, ONTAP System Manager 또는 명령줄은 특수한 요구 사항에 사용될 수 있습니다. 또한 vSphere에서 테스트한 구성 요소이므로 노드당 구성 멤버 수와 같은 기본값을 사용합니다.</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">FlexGroup 데이터 저장소를 사이징할 때 FlexGroup는 더 큰 네임스페이스를 생성하는 여러 개의 작은 FlexVol 볼륨으로 구성되어 있습니다. 따라서 가장 큰 가상 머신의 크기를 최소 8배 이상 사이징해야 합니다. 예를 들어 환경에 6TB VM이 있는 경우 48TB 이하의 크기로 FlexGroup 데이터 저장소를 구성할 수 있습니다.</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">FlexGroup에서 데이터 저장소 공간을 관리할 수 있도록 허용합니다. vSphere 데이터 저장소에서 자동 크기 조정 및 Elastic Sizing을 테스트했습니다. 데이터 저장소가 전체 용량에 근접하면 VMware vSphere용 ONTAP 툴 또는 다른 툴을 사용하여 FlexGroup 볼륨의 크기를 조정할 수 있습니다. FlexGroup는 용량 및 inode의 균형을 유지하며, 용량이 허용하는 경우 폴더(VM) 내의 파일에 우선 순위를 지정합니다.</block>
  <block id="c4528ad57baf62254d165d4e907e6f59" category="list-text">VMware 및 NetApp은 현재 일반적인 다중 경로 네트워킹 접근 방식을 지원하지 않습니다. NFSv4.1에서는 NetApp이 pNFS를 지원하는 반면 VMware는 세션 트렁킹을 지원합니다. NFSv3은 볼륨에 대한 여러 물리적 경로를 지원하지 않습니다. ONTAP 9.8이 포함된 FlexGroup의 경우 간접 액세스의 영향은 일반적으로 최소(마이크로초)이므로 VMware vSphere용 ONTAP 툴을 단일 마운트로 설정하는 것이 좋습니다. 라운드 로빈 DNS를 사용하여 FlexGroup의 다른 노드에 있는 LIF에 ESXi 호스트를 배포할 수 있지만, 이 경우 VMware vSphere용 ONTAP 툴 없이 FlexGroup를 생성하고 마운트해야 합니다. 그러면 성능 관리 기능을 사용할 수 없습니다.</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">FlexGroup vSphere 데이터 저장소 지원은 9.8 릴리즈에서 VM 1,500대까지 테스트되었습니다.</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">복제 오프로드에 VMware VAAI용 NFS 플러그인을 사용하십시오. FlexGroup 데이터 저장소 내에서 클론 생성이 향상되지만 FlexVol는 FlexGroup 및/또는 ONTAP 볼륨 간에 VM을 복제할 때 ESXi 호스트 복제본보다 성능이 크게 향상되지는 않습니다.</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">VMware vSphere 9.8용 ONTAP 툴을 사용하여 ONTAP 메트릭(대시보드 및 VM 보고서)을 사용하여 FlexGroup VM의 성능을 모니터링하고 개별 VM의 QoS를 관리할 수 있습니다. 이러한 메트릭은 현재 ONTAP 명령 또는 API를 통해 사용할 수 없습니다.</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">QoS(최대/최소 IOPS)는 개별 VM 또는 해당 시점에 데이터 저장소의 모든 VM에 설정할 수 있습니다. 모든 VM에서 QoS를 설정하면 별도의 VM별 설정이 대체됩니다. 설정은 향후 새 VM이나 마이그레이션된 VM으로 확장되지 않습니다. 새 VM에 QoS를 설정하거나 데이터 저장소의 모든 VM에 QoS를 다시 적용하십시오.</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">SnapCenter Plug-in for VMware vSphere 릴리즈 4.4는 운영 스토리지 시스템의 FlexGroup 데이터 저장소에 있는 VM의 백업 및 복구를 지원합니다. FlexGroup를 보조 시스템에 복제하기 위해 SnapMirror를 수동으로 사용할 수 있지만 SCV 4.4는 보조 복사본을 관리하지 않습니다.</block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">NetApp은 NetApp 테스트를 기반으로 ONTAP에서 올바르게 동작하도록 ESXi 호스트 다중 경로와 HBA 시간 초과 설정 세트를 개발했습니다. 이러한 설정은 VMware vSphere용 ONTAP 툴을 사용하여 쉽게 설정할 수 있습니다. 요약 대시보드의 호스트 시스템 윈도우에서 설정 편집 을 클릭하거나 vCenter에서 호스트를 마우스 오른쪽 버튼으로 클릭한 다음 ONTAP 도구 &gt; 권장 값 설정 으로 이동합니다. 다음은 9.8 릴리즈의 현재 권장되는 호스트 설정입니다.</block>
  <block id="dec4361376291bf7e7976c204f3a6cc8" category="cell">호스트 설정</block>
  <block id="024c7088f8cb994f40e5d60b87c10cbb" category="cell">NetApp이 권장하는 가치</block>
  <block id="af4c57809e604bab0cdf9a5ac5766ac8" category="cell">* ESXi 고급 구성 *</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3. HardwareAcceleratedLocking</block>
  <block id="2eabcf9ece81cd6f8095d869d0ecfdb5" category="cell">설정된 상태로 둡니다(VMware 기본값은 1).</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete 를 참조하십시오</block>
  <block id="0fef419d5842ff81bf9c9046c637822c" category="inline-link-macro">2007427)을 참조하십시오</block>
  <block id="f812302694bd63641124f6012aebac60" category="cell">설정된 상태로 둡니다(VMware 기본값은 0이지만 VMFS6에는 필요하지 않음). 자세한 내용은 VMware KB 문서 를 참조하십시오 <block ref="25cd71618ac903bfc347baf53ab838b7" category="inline-link-macro-rx"></block>.</block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">* NFS 설정 *</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">NET.TcpipHeapSize</block>
  <block id="abcf68baf479cae32e490eb770477d84" category="cell">vSphere 6.0 이상, 32로 설정. 다른 모든 NFS 구성은 30으로 설정합니다.</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">net.TcpipHeapMax</block>
  <block id="5f039752b957a359dac1c1e45051a844" category="cell">vSphere 6.0 이상에서는 1536으로 설정합니다.</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="d75533d93e425c0e677c7115b33e8152" category="cell">vSphere 6.0 이상, 256으로 설정 다른 모든 NFS 구성은 64로 설정됩니다.</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">vSphere 6.0 이상, 256으로 설정</block>
  <block id="6f4edfb9f3990d73482442c70e5fc2a0" category="cell">NFS.MaxQueueDepth입니다</block>
  <block id="0e61218c55cae3476207bca2c2f35ca7" category="cell">vSphere 6.0 이상으로, 128로 설정합니다.</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures 를 참조하십시오</block>
  <block id="8a14ec18b6563675357f1050563de774" category="cell">모든 NFS 구성에 대해 10으로 설정합니다.</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency 를 선택합니다</block>
  <block id="072f9680861841ae9a13008a99667a75" category="cell">모든 NFS 구성에 대해 12로 설정합니다.</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">모든 NFS 구성에 대해 5로 설정합니다.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP입니다</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">vSphere 7.0 이상, 128로 설정</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">* FC/FCoE 설정 *</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">경로 선택 정책</block>
  <block id="1e304108bae216d7b24d43f9bc868298" category="cell">ALUA를 사용하는 FC 경로를 사용할 때 RR(라운드 로빈)으로 설정합니다. 다른 모든 설정에 대해 고정으로 설정합니다. 이 값을 RR로 설정하면 모든 활성/최적화 경로에서 로드 밸런싱을 제공하는 데 도움이 됩니다. 고정 값은 이전 비 ALUA 구성에 대한 값이며 프록시 I/O를 방지하는 데 도움이 됩니다 다시 말해, 7-Mode에서 Data ONTAP를 실행하는 환경에서 I/O가 고가용성(HA) 쌍의 다른 노드로 이동하는 것을 돕니다.</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize 를 참조하십시오</block>
  <block id="acaf935911b20ef844daea256f8181b1" category="cell">모든 설정에 대해 32로 설정합니다. 이 값을 설정하면 I/O 오류가 방지됩니다.</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold를 참조하십시오</block>
  <block id="ab1224ed1cd7c63073af652a3bd92a35" category="cell">모든 설정에 대해 8로 설정합니다. 이 값을 설정하면 I/O 오류가 방지됩니다.</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Emulex FC HBA 시간 초과</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">기본값을 사용합니다.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">QLogic FC HBA 시간 초과</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">iSCSI 설정 *</block>
  <block id="d7e64409eb99602fc3b57a9f0b9287d6" category="cell">모든 iSCSI 경로에 대해 RR(라운드 로빈)으로 설정합니다. 이 값을 RR로 설정하면 모든 활성/최적화 경로에서 로드 밸런싱을 제공하는 데 도움이 됩니다.</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">ONTAP 툴은 ONTAP FlexVol 볼륨 및 LUN을 생성할 때 특정 기본 설정도 지정합니다.</block>
  <block id="b97847dc22c9e1f02417ab38785b34e6" category="cell">ONTAP 도구</block>
  <block id="c003231c67265f34100a284092c0cf1f" category="cell">기본 설정</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">스냅숏 예비 공간(-percent-snapshot-space)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">분할 예약(-fractional-reserve)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">액세스 시간 업데이트(-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">거짓</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">최소 미리 읽기(-min-readahead)</block>
  <block id="eee57b9c7d333899f3df6ffd10ec50df" category="cell">예약된 스냅샷 복사본</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">스토리지 효율성</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">활성화됨</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">볼륨 보장</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">없음(씬 프로비저닝됨)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">볼륨 자동 크기 조정</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">grow_shrink</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">LUN 공간 예약</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">사용 안 함</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">LUN 공간 할당</block>
  <block id="0464f851d84d05f0a9db9051354e5581" category="section-title">기타 호스트 다중 경로 구성 고려 사항</block>
  <block id="5fcb3de72ca1920517439049153d961d" category="paragraph">현재 사용 가능한 ONTAP 툴에 의해 구성되어 있지 않지만, NetApp에서는 다음과 같은 구성 옵션을 고려할 것을 권장합니다.</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356)을 참조하십시오</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">고성능 환경에서 또는 단일 LUN 데이터 저장소에서 성능을 테스트할 때는 라운드 로빈(VMW_PSP_RR) 경로 선택 정책(PSP)의 로드 밸런싱 설정을 기본 IOPS 설정인 1000에서 값 1로 변경하는 것이 좋습니다. VMware KB를 참조하십시오<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">경로 선택 플러그인 및 정책</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">vSphere 6.7 업데이트 1에서 VMware는 라운드 로빈 PSP에 새로운 지연 시간 로드 밸런싱 메커니즘을 도입했습니다. 새로운 옵션은 I/O에 가장 적합한 경로를 선택할 때 I/O 대역폭과 경로 지연 시간을 고려합니다 한 경로에 다른 경로보다 더 많은 네트워크 홉이 있거나 NetApp All SAN 어레이 시스템을 사용하는 경우와 같이 비등가 경로 연결이 있는 환경에서 이 홉을 사용하면 도움이 될 수 있습니다. 을 참조하십시오<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">NetApp ONTAP 소프트웨어는 약 20년 동안 VMware vSphere 환경을 위한 최고의 스토리지 솔루션으로, 혁신적인 기능을 지속적으로 추가하여 관리를 단순화하는 동시에 비용을 절감했습니다. 이 문서에서는 구축을 간소화하고 위험을 줄이며 관리를 단순화하는 최신 제품 정보 및 모범 사례를 비롯하여 vSphere용 ONTAP 솔루션에 대해 소개합니다.</block>
  <block id="952fd691754e388c7b7ba473cf410aff" category="doc">TR-4597: ONTAP용 VMware vSphere</block>
  <block id="b4191f5f6b40e39be6030dbbc9052330" category="paragraph">Karl Konnerth, NetApp</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">모범 사례는 가이드 및 호환성 목록 등의 다른 문서를 보완합니다. 이러한 전문 분야는 연구소 테스트와 NetApp 엔지니어 및 고객의 광범위한 현장 경험을 기반으로 합니다. 모든 환경에서 작동하는 유일한 지원 방법은 아니지만 일반적으로 대부분의 고객 요구를 충족하는 가장 간단한 솔루션입니다.</block>
  <block id="18b198d3d2381f05dd78bab3c8cec60c" category="paragraph">이 문서에서는 vSphere 6.0 이상에서 실행되는 최신 ONTAP(9.x) 릴리즈의 기능에 대해 중점적으로 설명합니다. 섹션을 참조하십시오 <block ref="4c9a6d8ccb9dfca3b5ae6e43e9663c99" category="inline-link-macro-rx"></block> 특정 릴리스와 관련된 자세한 내용은 를 참조하십시오.</block>
  <block id="4b401b0a40ae220c77961312c8238cdb" category="paragraph">수많은 고객들이 vSphere를 위한 스토리지 솔루션으로 ONTAP을 선택한 이유는 SAN 및 NAS 프로토콜을 모두 지원하는 유니파이드 스토리지 시스템, 공간 효율적인 NetApp Snapshot 복사본을 사용한 강력한 데이터 보호 기능 등 다양합니다. 애플리케이션 데이터를 관리하는 데 유용한 다양한 툴이 제공됩니다. 하이퍼바이저와 별도로 스토리지 시스템을 사용하면 다양한 기능을 오프로드하고 vSphere 호스트 시스템에 대한 투자를 극대화할 수 있습니다. 이렇게 하면 호스트 리소스가 애플리케이션 워크로드에 집중되도록 할 뿐 아니라 스토리지 작업에서 애플리케이션에 미치는 랜덤 성능 영향을 방지할 수 있습니다.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">ONTAP와 vSphere를 함께 사용하면 호스트 하드웨어 및 VMware 소프트웨어 비용을 절감할 수 있습니다. 또한 일관된 고성능을 통해 저렴한 비용으로 데이터를 보호할 수 있습니다. 가상화된 워크로드는 이동적이기 때문에 Storage vMotion을 사용하여 동일한 스토리지 시스템에서 VMFS, NFS 또는 VVol 데이터 저장소 간에 VM을 이동하는 다양한 접근 방식을 탐색할 수 있습니다.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">고객이 오늘날 가치를 제공하는 주요 요소는 다음과 같습니다.</block>
  <block id="dc4489aacb3c4d74b8253c49732b73e9" category="list-text">* 유니파이드 스토리지. * ONTAP 소프트웨어를 실행하는 시스템은 여러 가지 중요한 방식으로 통합됩니다. 이 접근 방식은 원래 NAS 및 SAN 프로토콜을 모두 갖추고 있으며, ONTAP는 NAS에서 그 원래 강점이 되었던 SAN을 위한 선도적인 플랫폼이 되었습니다. vSphere 환경에서 이 접근 방식은 가상 데스크톱 인프라(VDI)와 가상 서버 인프라(VSI)의 통합 시스템을 의미할 수도 있습니다. ONTAP 소프트웨어를 실행하는 시스템은 일반적으로 기존 엔터프라이즈 어레이보다 VSI 비용이 저렴하지만, 동일한 시스템에서 VDI를 처리할 수 있는 고급 스토리지 효율성 기능이 있습니다. 또한 ONTAP는 SSD에서 SATA에 이르는 다양한 스토리지 미디어를 통합하여 손쉽게 클라우드로 확장할 수 있습니다. 성능 향상을 위해 플래시 어레이 1개, 아카이브용 SATA 어레이 및 클라우드용 개별 시스템을 구입할 필요가 없습니다. ONTAP는 이러한 모든 것을 하나로 묶습니다.</block>
  <block id="ec8cd066c60323f007135b1f083b64de" category="list-text">* 가상 볼륨 및 스토리지 정책 기반 관리 * NetApp은 VVol(vSphere Virtual Volumes) 개발 과정에서 VMware와 초기 설계 파트너 관계를 맺고, VVOL과 VMware VASA(vSphere API for Storage Awareness)를 구조적 입력 및 조기 지원합니다. 이 접근 방식은 VMFS에 세분화된 VM 스토리지 관리를 제공할 뿐만 아니라 스토리지 정책 기반 관리를 통한 스토리지 프로비저닝 자동화도 지원합니다. 스토리지 설계자는 이 접근 방식을 통해 VM 관리자가 쉽게 사용할 수 있는 다양한 기능을 갖춘 스토리지 풀을 설계할 수 있습니다. ONTAP은 VVOL 스케일의 스토리지 산업을 선도하며 단일 클러스터에서 수십만 개의 VVOL을 지원하는 반면, 엔터프라이즈 어레이와 소규모 플래시 어레이 공급업체는 어레이당 수백 개의 VVOL을 지원합니다. NetApp은 또한 VVOL 3.0을 지원함으로써 세부적인 VM 관리 기능의 혁신을 이끌고 있습니다.</block>
  <block id="fd5311fb87e61b58d3c3d278df26af4f" category="list-text">*스토리지 효율성.* NetApp은 프로덕션 작업 부하에 대해 중복 제거 기능을 최초로 제공했지만 이 분야에서 이 혁신은 처음이거나 마지막 기술이 아니었습니다. 공간 효율적인 데이터 보호 메커니즘인 ONTAP 스냅샷 복사본에서 시작되어, 성능 저하 없이 VM의 읽기/쓰기 복사본을 즉시 만들어 운영 및 백업을 지원합니다. NetApp은 계속해서 중복제거, 압축, 제로 블록 중복제거 등과 같은 인라인 기능을 제공하여 고가의 SSD에서 최대한의 스토리지를 짜내었습니다. 가장 최근에 ONTAP은 컴팩션을 사용하여 소규모 I/O 작업 및 파일을 디스크 블록에 포장한 기능을 추가했습니다. 이러한 기능을 결합하여 고객은 VSI의 경우 최대 5:1, VDI의 경우 최대 30:1의 비용을 절감할 수 있었습니다.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">* 하이브리드 클라우드. * 사내 프라이빗 클라우드, 퍼블릭 클라우드 인프라 또는 둘 모두의 장점인 하이브리드 클라우드에 사용하건 간에, ONTAP 솔루션을 사용하면 데이터 패브릭을 구축하여 데이터 관리를 간소화하고 최적화할 수 있습니다. 고성능 All-Flash 시스템으로 시작한 다음 디스크 또는 클라우드 스토리지 시스템과 커플하여 데이터 보호 및 클라우드 컴퓨팅을 지원합니다. Azure, AWS, IBM 또는 Google 클라우드 중에서 선택하여 비용을 최적화하고 종속 문제를 방지합니다. OpenStack 및 컨테이너 기술에 대한 고급 지원을 필요에 따라 활용합니다. 또한 NetApp은 ONTAP용 클라우드 기반 백업(SnapMirror 클라우드, Cloud Backup Service 및 Cloud Sync), 스토리지 계층화 및 아카이빙 툴(FabricPool)을 제공하여 운영 비용을 줄이고 광범위한 클라우드 활용을 지원합니다.</block>
  <block id="0c157ce4e4fd6289dbf0b282993c2f80" category="list-text">* 그 이상. * NetApp AFF A-Series 어레이의 탁월한 성능을 활용하여 가상화 인프라를 가속하고 비용을 관리하십시오. 스케일아웃 ONTAP 클러스터를 사용하면 유지보수, 업그레이드, 스토리지 시스템 전체 교체 등 운영 중단 없이 완벽하게 수행할 수 있습니다. 추가 비용 없이 NetApp 암호화 기능으로 유휴 데이터를 보호합니다. 세분화된 서비스 품질 기능을 통해 성능이 비즈니스 서비스 수준을 충족하는지 확인합니다. 이 모든 기능은 업계 최고의 엔터프라이즈 데이터 관리 소프트웨어인 ONTAP와 함께 제공되는 광범위한 기능의 일부입니다.</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹 사이트를 검토하십시오.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">추가 정보</block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">TR-4400: ONTAP를 포함한 VMware vSphere 가상 볼륨<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">ONTAP 9용 TR-4015 SnapMirror 구성 모범 사례 가이드<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">RBAC ONTAP용 사용자 생성기<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">VMware vSphere 리소스를 위한 ONTAP 툴<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">VMware Site Recovery Manager 설명서<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="014a2413d22e5ac39371ac1333e38898" category="paragraph">을 참조하십시오<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> NetApp Support 사이트에서 본 문서에 기술된 제품과 기능 버전이 귀사의 환경에서 지원되는지 확인하십시오. NetApp IMT에는 NetApp이 지원하는 구성을 설계하는 데 사용할 수 있는 제품 구성요소 및 버전이 정의되어 있습니다. 구체적인 결과는 게시된 기술사양과 그에 따른 고객 설치 환경에 따라 달라집니다.</block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">이 문서에서는 VMware vSphere용 ONTAP 툴의 제품 보안에 대해 설명합니다.</block>
  <block id="289953e1dbd51c07cae2ecf1e6fb88a1" category="doc">WP-7353: VMware vSphere용 ONTAP 툴 - 제품 보안</block>
  <block id="595319f89334a6a0b8edd4f81172fc71" category="paragraph">Chance Bingen, Dan Tullege, Jenn Schrie, NetApp</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">안전한 개발 활동</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">NetApp ONTAP Tools for VMware vSphere를 사용한 소프트웨어 엔지니어링에서는 다음과 같은 안전한 개발 활동을 활용합니다.</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">* 위협 모델링. * 위협 모델링의 목적은 소프트웨어 개발 수명 주기 초기에 피처, 부품 또는 제품의 보안 결함을 발견하기 위한 것입니다. 위협 모델은 응용 프로그램의 보안에 영향을 주는 모든 정보의 구조적 표현입니다. 본질적으로 보안 렌즈를 통해 응용 프로그램과 환경을 볼 수 있습니다.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">* DAST(Dynamic Application Security Testing). * 이 기술은 실행 중인 응용 프로그램의 취약한 상태를 감지하도록 설계되었습니다. DAST는 웹 활성화 애플리케이션의 노출된 HTTP 및 HTML 인터페이스를 테스트합니다.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">* 타사 코드 통화. * 오픈 소스 소프트웨어(OSS)를 통한 소프트웨어 개발의 일환으로 제품에 통합된 OSS와 관련된 보안 취약점을 해결해야 합니다. 이는 새로운 OSS 버전에 새로 발견된 취약점이 언제든지 보고될 수 있기 때문에 지속적인 노력입니다.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">* 취약성 검사. * 취약성 검사의 목적은 NetApp 제품이 고객에게 공개되기 전에 NetApp 제품의 알려진 공통 보안 취약점을 감지하는 것입니다.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">* 침투 테스트 * 침투 테스트는 시스템, 웹 응용 프로그램 또는 네트워크를 평가하여 공격자가 악용할 수 있는 보안 취약점을 찾는 프로세스입니다. NetApp의 침투 테스트(펜 테스트)는 승인되고 신뢰할 수 있는 타사 기업의 그룹에 의해 수행됩니다. 이러한 테스트 범위에는 정교한 악용 방법이나 도구를 사용하는 악의적인 침입자나 해커에 유사한 응용 프로그램 또는 소프트웨어에 대한 공격이 포함됩니다.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">제품 보안 기능</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">VMware vSphere용 NetApp ONTAP 툴에는 각 릴리즈에 다음과 같은 보안 기능이 포함되어 있습니다.</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">* 로그인 배너. * SSH는 기본적으로 비활성화되어 있으며 VM 콘솔에서 활성화된 경우 1회만 로그인할 수 있습니다. 사용자가 로그인 프롬프트에 사용자 이름을 입력하면 다음 로그인 배너가 표시됩니다.</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">경고:* 이 시스템에 대한 무단 액세스는 금지되며 법률로 기소됩니다. 이 시스템에 액세스하면 무단 사용이 의심되는 경우 사용자의 조치를 모니터링할 수 있다는 데 동의하는 것입니다.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">사용자가 SSH 채널을 통해 로그인을 완료하면 다음 텍스트가 표시됩니다.</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">* 역할 기반 액세스 제어(RBAC). * 두 가지 유형의 RBAC 컨트롤이 ONTAP 도구에 연결되어 있습니다.</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">기본 vCenter Server 권한</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">vCenter 플러그인별 권한 자세한 내용은 을 참조하십시오<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">* 암호화된 통신 채널. * 모든 외부 통신은 TLS 버전 1.2를 사용하여 HTTPS를 통해 이루어집니다.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">* 최소 포트 노출. * 필요한 포트만 방화벽에서 열립니다.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">다음 표에서는 열려 있는 포트의 세부 정보를 설명합니다.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">TCP v4/V6 포트 번호</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">기능</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">REST API용 HTTPS 연결</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">HTTPS 연결</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">https 연결을 통한 SOAP에 사용되는 HTTPS 연결 클라이언트가 ONTAP 도구 API 서버에 연결할 수 있도록 이 포트를 열어야 합니다.</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH(기본적으로 비활성화됨)</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">HTTPS 연결 - VP 및 SRA - 루프백에서만 내부 연결</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="25a695aa0122683aad4828e2458bbba6" category="cell">HTTPS 연결 - VP 및 SRA</block>
  <block id="4b8384754c8b30050bb36e840394189b" category="cell">https 연결을 통한 SOAP에 사용됩니다</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">VP SNMP 트랩 패킷입니다</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527)을 참조하십시오</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Derby 데이터베이스 포트, 이 컴퓨터와 자체 사이에서만, 외부 연결은 허용되지 않음 -- 내부 연결만</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">KB 문서를 참조하십시오</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">* CA(인증 기관) 서명 인증서 지원. * VMware vSphere용 ONTAP 툴은 CA 서명 인증서를 지원합니다. 자세한 내용은 다음을 참조하십시오<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">* 감사 로깅. * 지원 번들은 다운로드할 수 있으며 매우 자세히 설명되어 있습니다. ONTAP 도구는 모든 사용자 로그인 및 로그아웃 활동을 별도의 로그 파일에 기록합니다. VASA API 호출은 전용 VASA 감사 로그(로컬 CXF.log)에 기록됩니다.</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">암호 정책 * 다음 암호 정책을 따릅니다.</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">암호는 로그 파일에 기록되지 않습니다.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">암호는 일반 텍스트로 전달되지 않습니다.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">암호는 설치 과정 중에 구성됩니다.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">암호 기록은 구성 가능한 매개 변수입니다.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">최소 암호 사용 기간은 24시간으로 설정됩니다.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">암호 필드에 대한 자동 완성 기능이 비활성화됩니다.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">ONTAP 도구는 SHA256 해싱을 사용하여 저장된 모든 자격 증명 정보를 암호화합니다.</block>
  <block id="62783f5d69cb5d3cb22b077c1d2b8777" category="cell">2021년 11월</block>
  <block id="b1c770f25b823d4453567c0ff9d7cf67" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP NFS 버전 3 데이터 저장소를 구축하는 단계를 제공합니다.</block>
  <block id="168dbfe414d4d4089585360152953a57" category="doc">vSphere NFS 데이터 저장소 - 버전 3(ONTAP 포함</block>
  <block id="2be27a78c84ba5629cd9f2c22983240a" category="paragraph">ONTAP NAS 스토리지를 사용하여 NFS 버전 3 데이터 저장소를 생성합니다.</block>
  <block id="106a118b8a267220cb2c40a4bb68b684" category="list-text">vSphere 환경 및 ONTAP를 관리하는 데 필요한 기본 기술입니다.</block>
  <block id="00c46d0ea9cdf9a5a37b8af04896741f" category="list-text">ONTAP 9.8 이상을 실행하는 ONTAP 스토리지 시스템(FAS/AFF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp Files</block>
  <block id="a9ab6317871b5547fc7bf0dd22151f00" category="list-text">vSphere 7.0 이상에 대한 vSphere 호스트 정보입니다</block>
  <block id="0675fa9a38b420775f29ec7a62d9a8a0" category="list-text">ONTAP 시스템 네트워크 데이터 포트 및 연결된 vSphere 호스트를 사용합니다</block>
  <block id="4b18348d39655902cd0e183596a82856" category="list-text">과의 호환성을 확인하십시오<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="c54d1c547e26987b98af73634278c77a" category="inline-link-macro">NFS에 대한 ONTAP 라이센스를 확인합니다.</block>
  <block id="8174503ab9e5dc2fe2f74068f651770d" category="list-text"><block ref="8174503ab9e5dc2fe2f74068f651770d" category="inline-link-macro-rx"></block></block>
  <block id="5d3f3e14f3096740cb085fa81836d595" category="list-text">'system license show' 명령어를 사용하여 NFS가 나열되는지 확인한다.</block>
  <block id="135850bb72d05ca77b8b8f846429fe71" category="inline-link-macro">NFS 구성 워크플로우를 따릅니다.</block>
  <block id="01a85c06aae02abe9083e7e02d90661f" category="list-text"><block ref="01a85c06aae02abe9083e7e02d90661f" category="inline-link-macro-rx"></block></block>
  <block id="2281b9d958567868b171298a8df5cdee" category="inline-link-macro">vSphere에 대한 NFS 클라이언트 구성의 워크플로우를 따릅니다.</block>
  <block id="c80c5160cfe2127b3ab167103b20488c" category="paragraph"><block ref="c80c5160cfe2127b3ab167103b20488c" category="inline-link-macro-rx"></block></block>
  <block id="63d5049791d9d79d86e9a108b0a999ca" category="section-title">참조하십시오</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">ONTAP 9에서는 클러스터의 물리적 구성 요소가 클러스터 관리자에게 표시되지만 클러스터를 사용하는 애플리케이션과 호스트에는 직접 표시되지 않습니다.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">복제 토폴로지</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">ONTAP 9에서는 클러스터의 물리적 구성 요소가 클러스터 관리자에게 표시되지만 클러스터를 사용하는 애플리케이션과 호스트에는 직접 표시되지 않습니다. 물리적 구성 요소는 논리적 클러스터 리소스가 구성되는 공유 리소스 풀을 제공합니다. 애플리케이션과 호스트는 볼륨 및 LIF가 포함된 SVM을 통해서만 데이터에 액세스합니다.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">각 NetApp SVM은 VMware vCenter Site Recovery Manager에서 어레이로 취급됩니다. SRM은 특정 어레이 간(또는 SVM 간) 복제 레이아웃을 지원합니다.</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">단일 VM은 VMDK(Virtual Machine Disk) 또는 RDM 같은 데이터를 소유할 수 없습니다. 이러한 데이터를 여러 SRM 스토리지에서 소유할 수 없는 이유는 다음과 같습니다.</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM에는 개별 물리적 컨트롤러가 아닌 SVM만 표시됩니다.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">SVM은 하나의 클러스터에서 여러 노드에 걸쳐 있는 LUN 및 볼륨을 제어할 수 있습니다.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">모범 사례</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">지원 가능성을 확인하려면 이 규칙을 염두에 두십시오. SRM 및 NetApp SRA를 사용하여 VM을 보호하려면 VM의 모든 부분이 하나의 SVM에만 존재해야 합니다. 이 규칙은 보호 사이트와 복구 사이트 모두에 적용됩니다.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">지원되는 SnapMirror 레이아웃</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">다음 그림은 SRM 및 SRA에서 지원하는 SnapMirror 관계 레이아웃 시나리오를 보여 줍니다. 복제된 볼륨의 각 VM은 각 사이트의 한 SRM 어레이(SVM)에만 데이터를 소유합니다.</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">지원되는 Array Manager 레이아웃입니다</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">SRM에서 ABR(스토리지 기반 복제)을 사용하면 다음 스크린샷과 같이 보호 그룹이 단일 스토리지 쌍으로 격리됩니다. 이 경우 복구 현장에서는 VM1과 VM2를 VM3과 VM4로 들여다봅니다. 그러나 보호 그룹을 생성할 때는 두 스토리지 쌍 중 하나만 선택할 수 있습니다.</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">지원되지 않는 레이아웃입니다</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">지원되지 않는 구성에는 개별 VM이 소유하는 여러 SVM에 데이터(VMDK 또는 RDM)가 있습니다. 다음 그림에 표시된 예에서 VM1은 두 SVM에 데이터가 있으므로 SRM을 사용하여 보호할 수 있도록 VM1을 구성할 수 없습니다.</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">개별 NetApp 볼륨이 하나의 소스 SVM에서 동일한 SVM의 여러 대상 또는 서로 다른 SVM에 복제된 모든 복제 관계를 SnapMirror 팬아웃(fan-out)이라고 합니다. SRM에서는 팬아웃이 지원되지 않습니다. 다음 그림에 표시된 예제에서 VM1은 SnapMirror를 사용하여 두 개의 다른 위치로 복제되므로 SRM에서 보호용으로 구성할 수 없습니다.</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">SnapMirror 계단식 배열</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM은 소스 볼륨이 타겟 볼륨에 복제되고 해당 타겟 볼륨도 SnapMirror를 통해 다른 타겟 볼륨으로 복제되는 SnapMirror 관계의 다중 구간 기능을 지원하지 않습니다. 다음 그림에 표시된 시나리오에서는 사이트 간 장애 조치에 SRM을 사용할 수 없습니다.</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror 및 SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">NetApp SnapVault 소프트웨어를 사용하면 NetApp 스토리지 시스템 간에 엔터프라이즈 데이터를 디스크 기반으로 백업할 수 있습니다. SnapVault와 SnapMirror는 동일한 환경에 공존할 수 있지만 SRM은 SnapMirror 관계의 페일오버만 지원합니다.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">NetApp SRA는 'Mirror-vault' 정책 유형을 지원합니다.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault는 처음부터 ONTAP 8.2를 위해 재구축되었습니다. 이전 Data ONTAP 7-Mode 사용자에게도 유사한 점이 있긴 하지만, 이 버전의 SnapVault에서는 여러 가지 기능이 크게 향상되었습니다. 한 가지 중요한 발전은 SnapVault 전송 중에 운영 데이터의 스토리지 효율성을 유지할 수 있는 기능입니다.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">중요한 아키텍처 변화는 ONTAP 9의 SnapVault가 7-Mode SnapVault와 마찬가지로 qtree 레벨이 아닌 볼륨 레벨에서 복제된다는 점입니다. 이 설정은 SnapVault 관계의 소스가 볼륨이어야 하며 해당 볼륨이 SnapVault 보조 시스템의 자체 볼륨으로 복제되어야 함을 의미합니다.</block>
  <block id="f7b20cbc14027c7711d53d03a84f31af" category="paragraph">SnapVault가 사용되는 환경에서 특히 이름이 인 스냅샷 복사본이 운영 스토리지 시스템에 생성됩니다. 구축된 구성에 따라 명명된 스냅샷 복사본을 SnapVault 일정에 따라 운영 시스템이나 NetApp Active IQ Unified Manager 같은 애플리케이션에 의해 생성할 수 있습니다. 그런 다음 기본 시스템에서 생성된 명명된 스냅샷 복사본이 SnapMirror 대상에 복제되고, 생성된 스냅샷 복사본은 SnapVault 대상에 복제됩니다.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">소스 볼륨은 DR 사이트의 SnapMirror 대상에 복제되는 계단식 구성으로 생성할 수 있으며, 이 구성에서는 볼륨을 SnapVault 타겟에 저장할 수 있습니다. 한 대상이 SnapMirror 대상이고 다른 대상이 SnapVault 대상인 팬아웃 관계에 소스 볼륨을 생성할 수도 있습니다. 그러나 SRM 페일오버 또는 복제 반전이 발생할 경우 SnapMirror 대상 볼륨을 볼트의 소스로 사용하도록 SRA는 SnapVault 관계를 자동으로 재구성하지 않습니다.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">ONTAP 9용 TR-4015 SnapMirror 구성 모범 사례 가이드.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">SnapMirror 및 SnapVault for ONTAP 9에 대한 최신 정보는 를 참조하십시오<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">SnapVault 및 SRM이 동일한 환경에서 사용되는 경우 SnapVault 백업이 일반적으로 DR 사이트의 SnapMirror 대상에서 수행되는 SnapMirror와 SnapVault 다중 구간 구성을 사용하는 것이 좋습니다. 재해가 발생할 경우 이 구성을 사용하면 운영 사이트에 액세스할 수 없습니다. 복구 사이트에서 SnapVault 대상을 유지하면 복구 사이트에서 운영 중인 동안 SnapVault 백업을 계속할 수 있도록 장애 조치 후 SnapVault 백업을 재구성할 수 있습니다.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">VMware 환경에서 각 데이터 저장소에는 UUID(Universal Unique Identifier)가 있으며 각 VM에는 고유한 MOID(Managed Object ID)가 있습니다. 이러한 ID는 장애 조치 또는 장애 복구 중에 SRM에 의해 유지되지 않습니다. 데이터 저장소 UUID 및 VM MOID는 SRM에서 페일오버 중에 유지되지 않으므로 이러한 ID에 의존하는 모든 애플리케이션은 SRM 페일오버 후에 재구성해야 합니다. 애플리케이션의 예로는 SnapVault 복제를 vSphere 환경과 조정하는 NetApp Active IQ Unified Manager가 있습니다.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">다음 그림은 SnapVault 계단식으로 구성된 SnapMirror를 보여 줍니다. SnapVault 대상이 DR 사이트 또는 운영 사이트의 운영 중단으로 인해 영향을 받지 않는 3차 사이트에 있는 경우, 페일오버 후 백업을 계속할 수 있도록 환경을 재구성할 수 있습니다.</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">다음 그림에서는 SRM을 사용하여 SnapMirror 복제를 기본 사이트로 되돌린 후의 구성을 보여 줍니다. 또한 SnapVault 백업이 현재 SnapMirror 소스에서 발생하도록 환경이 재구성되었습니다. 이 설정은 SnapMirror SnapVault 팬아웃 구성입니다.</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">SRM이 페일백을 수행하고 SnapMirror 관계의 두 번째 반전을 수행한 후 운영 데이터가 기본 사이트로 돌아갑니다. 이 데이터는 SnapMirror 및 SnapVault 백업을 통해 DR 사이트로 페일오버 전의 방식과 동일하게 보호됩니다.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Site Recovery Manager 환경에서 Qtree 사용</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">qtree는 NAS에 대한 파일 시스템 할당량을 적용할 수 있는 특수 디렉토리입니다. ONTAP 9에서는 qtree를 생성할 수 있으며 qtree는 SnapMirror로 복제된 볼륨에 존재할 수 있습니다. 그러나 SnapMirror에서는 개별 qtree 또는 qtree 레벨 복제의 복제를 허용하지 않습니다. 모든 SnapMirror 복제는 볼륨 레벨에만 있습니다. 이러한 이유로 SRM에서는 qtree를 사용하지 않는 것이 좋습니다.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">FC 및 iSCSI 혼합 환경</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">지원되는 SAN 프로토콜(FC, FCoE 및 iSCSI)을 통해 ONTAP 9는 LUN 서비스를 제공합니다. 즉, LUN을 생성하여 연결된 호스트에 매핑할 수 있습니다. 클러스터는 여러 컨트롤러로 구성되며, 개별 LUN에 대한 다중 경로 I/O를 통해 관리되는 여러 논리적 경로가 있습니다. 호스트에서 ALUA(Asymmetric Logical Unit Access)가 사용되므로 LUN에 대한 최적화된 경로가 선택되고 데이터 전송을 위해 활성화됩니다. LUN에 대한 최적화된 경로(예: 포함된 볼륨이 이동됨)가 변경되면 ONTAP 9가 자동으로 해당 변경 사항을 인식하고 중단 없이 조정합니다. 최적화된 경로를 사용할 수 없게 되면 ONTAP는 무중단으로 다른 사용 가능한 경로로 전환할 수 있습니다.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM 및 NetApp SRA는 한 사이트에서 FC 프로토콜을 사용하고 다른 사이트에서는 iSCSI 프로토콜을 사용할 수 있도록 지원합니다. 하지만 동일한 ESXi 호스트 또는 동일한 클러스터의 다른 호스트에 FC 연결 데이터 저장소와 iSCSI 연결 데이터 저장소를 함께 사용할 수는 없습니다. SRM 페일오버 또는 테스트 페일오버 중에 SRM은 요청에 따라 ESXi 호스트의 모든 FC 및 iSCSI 이니시에이터를 포함하므로 SRM에서는 이 구성이 지원되지 않습니다.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM 및 SRA는 보호 사이트와 복구 사이트 간에 혼합 FC 및 iSCSI 프로토콜을 지원합니다. 그러나 각 사이트는 동일한 사이트에서 두 프로토콜을 모두 구성하지 않고 FC 또는 iSCSI 프로토콜을 하나만 사용하여 구성해야 합니다. FC와 iSCSI 프로토콜을 동일한 사이트에 모두 구성해야 하는 경우 일부 호스트는 iSCSI를 사용하고 다른 호스트는 FC를 사용하는 것이 좋습니다. 또한 이 경우에는 VM이 호스트 그룹 또는 다른 그룹으로 페일오버되도록 SRM 리소스 매핑을 설정하는 것이 좋습니다.</block>
  <block id="f5852a230bef6cf666f848c5a2137db2" category="doc">ONTAP 유니파이드 스토리지</block>
  <block id="0dc14c0a294efec0c8cab98ebffa39f0" category="section-title">유니파이드 스토리지 정보</block>
  <block id="d00516b816f266ee64e7b1de5af59ff2" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템은 여러 가지 중요한 방식으로 통합됩니다. 이 접근 방식은 원래 하나의 스토리지 시스템에서 NAS 및 SAN 프로토콜을 모두 지원한다는 것을 언급했으며, ONTAP는 NAS에서 그 원래 강점과 함께 SAN을 위한 최고의 플랫폼이 되었습니다. SVM(스토리지 가상 머신)은 클라이언트가 ONTAP 소프트웨어를 실행하는 시스템에 액세스할 수 있도록 지원하는 논리적 구성입니다. SVM은 논리 인터페이스(LIF)를 통해 여러 데이터 액세스 프로토콜을 통해 데이터를 동시에 제공할 수 있습니다. SVM은 CIFS 및 NFS와 같은 NAS 프로토콜을 통해 파일 레벨 데이터 액세스를 지원하고, iSCSI, FC/FCoE, NVMe와 같은 SAN 프로토콜을 통해 블록 레벨 데이터 액세스를 제공합니다. SVM은 SAN 및 NAS 클라이언트에 데이터를 동시에 독립적으로 제공할 수 있습니다.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="inline-image-macro">유니파이드 스토리지</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d59082aeee25c59b01266eaef6cb14" category="paragraph">vSphere 환경에서 이 접근 방식은 가상 데스크톱 인프라(VDI)와 가상 서버 인프라(VSI)의 통합 시스템을 의미할 수도 있습니다. ONTAP 소프트웨어를 실행하는 시스템은 일반적으로 기존 엔터프라이즈 어레이보다 VSI 비용이 저렴하지만, 동일한 시스템에서 VDI를 처리할 수 있는 고급 스토리지 효율성 기능이 있습니다. 또한 ONTAP는 SSD에서 SATA에 이르는 다양한 스토리지 미디어를 통합하여 손쉽게 클라우드로 확장할 수 있습니다. 성능 향상을 위해 플래시 어레이 1개, 아카이브용 SATA 어레이 및 클라우드용 개별 시스템을 구입할 필요가 없습니다. ONTAP는 이러한 모든 것을 하나로 묶습니다.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">스토리지 가상화</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">SVM, 유니파이드 스토리지 및 클라이언트 액세스에 대한 자세한 내용은 를 참조하십시오<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> ONTAP 9 문서 센터</block>
  <block id="b278438874f41a76068d02368e65aa3e" category="doc">이 리포지터리 정보</block>
  <block id="404af48e0cb5f84306fbd93fac2ff8be" category="paragraph">NetApp Solutions 저장소를 간략하게 소개 - 특정 솔루션을 찾는 위치 및 이 저장소 사용 방법</block>
  <block id="45ac6b09a3b8f5ea07ca656ca8dea987" category="section-title">리포지터리의 탐색</block>
  <block id="c28e40ef527e43509a0fcd3b114ff824" category="paragraph">리포지토리의 탐색은 페이지의 왼쪽에 표시되는 기본 사이드바에 의해 관리됩니다. 솔루션은 NetApp 솔루션을 위한 "기술 타워"로 정의된 상위 수준의 기술 영역으로 분류됩니다.</block>
  <block id="e9982e506e30915713c7485a2e77633b" category="section-title">Technology Towers 개요</block>
  <block id="d67372be0bd12a2ddbcf795ccfacc7de" category="cell">* 섹션 *</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">* 설명 *</block>
  <block id="7324b08f5dfbdb08191404d3fdacfcbd" category="cell">AI 기반 솔루션의 컬렉션 솔루션은 [해군]#AI Converged Infrastructure#[네이비]#Data Pipelines, Data Lakes and Management#[네이비]#사용 사례# 중 하나로 하위 분류되어 있습니다</block>
  <block id="f5f0336c80fe8cdd5a51752c1ce61ac3" category="cell">데이터 분석 솔루션의 수집(예 Splunk SmartStore, Apache Spark 등)</block>
  <block id="e6d792539f0b0370e43d76a3e05a211a" category="cell">가상화 핵심 솔루션의 모음입니다. 솔루션은 [해군]#VMware Virtualization#[네이비]#데모 및 자습서#의 범주 중 하나로 하위 분류되어 있습니다</block>
  <block id="b3f656e5589b8507fed35a5cde55c7ce" category="cell">최종 사용자 컴퓨팅 솔루션의 모음입니다. 솔루션은 [해군]#VDS(Virtual Desktop Service)#[네이비]#VMware Horizon#[네이비]#Citrix Virtual Apps and Desktops#[네이비]#Virtual Desktop Applications# 중 하나로 하위 분류되어 있습니다</block>
  <block id="f4d9ebd0d9f8b0ed1329093e48c11221" category="cell">컨테이너 기반 솔루션의 모음입니다. 솔루션은 [해군]#Red Hat OpenShift#[해군]#Google Anthos# 중 하나로 하위 분류되어 있습니다</block>
  <block id="861a3cbb41e90c0f7d83b50b7522b0bd" category="cell">비즈니스 애플리케이션</block>
  <block id="c343bf84179077b4550742e0222d3349" category="cell">비즈니스 애플리케이션 솔루션의 모음입니다. 솔루션은 [해군]#SAP# 중 하나로 하위 분류되어 있습니다</block>
  <block id="8a0b9e6043677d9587a3e02ced9a6dfd" category="cell">데이터베이스 솔루션 모음입니다. 솔루션은 [해군]#SAP HANA#[네이비]#Oracle#[네이비]#Microsoft SQL Server# 중 하나로 하위 분류되어 있습니다</block>
  <block id="f8aacfa5c683858912c498f517c9b457" category="cell">데이터 액세스</block>
  <block id="c14336a2319ce73616b0fa898a883fe0" category="cell">데이터 액세스 솔루션의 모음입니다. 솔루션은 [해군]#데이터 마이그레이션#[네이비]#데이터 보호#[네이비]#보안# 중 하나로 하위 분류되어 있습니다</block>
  <block id="d83d094e8e3ce7450bf099061814d148" category="cell">Red Hat Ansible을 사용한 솔루션 자동화 시작 개요</block>
  <block id="6174d88cc7c0409df3e035a5c9d089cb" category="section-title">Change Log(로그 변경)</block>
  <block id="a0067ab2420cbaebc335efc5c2433c45" category="inline-link-macro">변경 로그</block>
  <block id="1144ef243d0744e29b8bb83edad3cd0d" category="paragraph">리포지토리의 모든 주요 변경 사항(새로운 솔루션, 주요 업데이트, 새로운 비디오/데모 등)은 에서 추적됩니다 <block ref="95485865b5d32e0932da8207f23060b5" category="inline-link-macro-rx"></block>.</block>
  <block id="bea4c2c8eb82d05891ddd71584881b56" category="section-title">피드백</block>
  <block id="fb6b632cdd61e02434568081cbbf0fae" category="paragraph">을(를) 사용하십시오 <block ref="a5f81f398e43efd62a061a201309bfa7" category="inline-link-macro-rx"></block> 콘텐츠의 변경을 요청하거나 콘텐츠에 대한 피드백을 제공합니다. 귀하의 피드백이 적절하게 처리되도록 최대한 구체적으로 적어 주십시오.</block>
  <block id="89185de94c95d958df7a1d1f328c5d3d" category="summary">마이그레이션은 마이그레이션 계획 및 완료를 위해 따라야 할 단계가 다릅니다. NetApp XCP를 사용하여 타사 NAS 스토리지나 직접 연결된 NAS 내보낸 스토리지에서 데이터를 마이그레이션하려면 이 섹션에 제공된 마이그레이션 지침을 따르십시오.</block>
  <block id="ee5b035493cdde88f6472904ffe00677" category="doc">마이그레이션 워크플로우</block>
  <block id="33af37ca0d75bc0783cc87782a94cb6e" category="inline-link-macro">그 전에 NetApp XCP가 있습니다.</block>
  <block id="c6f303d52bc03c848b2dde21f1b31f9d" category="paragraph"><block ref="c6f303d52bc03c848b2dde21f1b31f9d" category="inline-link-macro-rx"></block></block>
  <block id="5b312b66520bbb17746eeb5c9959e4ef" category="paragraph">다음 그림에서는 NAS에서 NetApp NAS로의 마이그레이션 워크플로우를 보여 줍니다.</block>
  <block id="228d4a26c37192668bb7f7bf0d81ce40" category="paragraph"><block ref="228d4a26c37192668bb7f7bf0d81ce40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8df17c51ab4a9817f3fe7cea57052110" category="paragraph">NAS에서 NetApp NAS로 마이그레이션 워크플로우는 다음 단계를 포함합니다.</block>
  <block id="3bd3dda9341b512ee536cc6e48d51a69" category="list-text">NAS 공유 및 데이터를 검색합니다.</block>
  <block id="7800ed0aa4aebf1d63fd7120c2bcf538" category="list-text">데이터를 스캔하고 보고서를 생성하여 데이터의 레이아웃을 찾습니다.</block>
  <block id="8e9880476ad79e202d93a0a7d0bb5f5b" category="list-text">xCP Copy 명령을 실행하여 기준을 생성합니다. 더 빠른 마이그레이션을 위해 더 많은 XCP 인스턴스를 선택하고 하위 폴더 레벨에서 워크로드를 분할하여 병렬 마이그레이션 작업을 시작합니다.</block>
  <block id="57324e972ea87c8e788d9831e510bc6d" category="list-text">증분 업데이트의 경우 컷오버 기간에 대한 변경률이 낮아질 때까지 xCP 동기화를 사용하십시오.</block>
  <block id="3812202d715addac73d7122672d3c8d0" category="list-text">xCP 동기화 명령을 실행하여 마이그레이션을 완료하여 소스를 읽기 전용으로 표시하여 최종 동기화를 수행합니다.</block>
  <block id="2c1d8a91f274a7723f6ad2ffefc81b62" category="list-text">데이터가 올바르게 전송되었는지 확인하려면 xCP verify 명령을 실행하여 소스와 대상을 비교합니다.</block>
  <block id="b98a6acc7ef428f1ae11e5177447df8c" category="paragraph">클라우드의 경우, 온프레미스와 클라우드 간의 연결이 직접 연결(AWS), ExpressRoute(Azure), 클라우드 인터커넥트(GCP) 인 경우에도 유사한 사내 마이그레이션 워크플로우를 따를 수 있습니다.</block>
  <block id="8f4cde54f5af74d15d142ad98344aab6" category="paragraph">다음 그림에서는 사내에서 클라우드로 마이그레이션 워크플로우를 보여 줍니다.</block>
  <block id="9d1b3862e72bece8266c1c8b1098c696" category="paragraph"><block ref="9d1b3862e72bece8266c1c8b1098c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2fef7fa18bd688132425321b9188bb" category="paragraph">온프레미스와 클라우드 간에 직접 인터넷 연결이 없는 경우 트럭과 같은 오프라인 데이터 전송 방법을 통해 사내 데이터를 클라우드로 전송해야 합니다. 각 클라우드 서비스 공급자마다 다른 용어를 사용하여 데이터를 데이터 센터로 이동하는 방법이 있습니다.</block>
  <block id="9e76bcaf48df4797c2e546f778fd72f8" category="paragraph">다음 그림은 ExpressRoute 없이 사내 및 Azure용 Data Mover 솔루션을 보여 줍니다.</block>
  <block id="e13bab0261f71ca4765f8b68cea20a43" category="paragraph"><block ref="e13bab0261f71ca4765f8b68cea20a43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423066080659363cc444ec5dee611f48" category="paragraph">다양한 클라우드 서비스 공급자의 각 구성 요소와 함께 유사한 아키텍처를 사용할 수 있습니다.</block>
  <block id="050572d01f21dded8086b49419066add" category="inline-link-macro">다음: 파일 분석.</block>
  <block id="ae292ee37a105844872f831698fb440f" category="paragraph"><block ref="ae292ee37a105844872f831698fb440f" category="inline-link-macro-rx"></block></block>
  <block id="ddf97b6ffb913bd772848e3ebecfc8c1" category="summary">이 섹션에서는 NetApp XCP 데이터 전송을 위한 구축 단계에 대해 설명합니다.</block>
  <block id="8388066510b59c8d3387373b6969a7af" category="doc">배포 단계</block>
  <block id="c6310b144c1666a29ec7cacf1c0dceab" category="inline-link-macro">이전: 파일 분석.</block>
  <block id="57c4917a0617c8b675e6cc1dbad5c7fe" category="paragraph"><block ref="57c4917a0617c8b675e6cc1dbad5c7fe" category="inline-link-macro-rx"></block></block>
  <block id="8449c94058b7c2e686c3e19f7e772a65" category="section-title">테스트 베드 세부 정보</block>
  <block id="94cb70bde9d89f0b10ffdca34b0bec22" category="paragraph">다음 표에는 이 배포 및 성능 검증에 사용된 테스트 베드 세부 정보가 나와 있습니다.</block>
  <block id="57419d904381619fcf00bc94e4ce26f1" category="cell">xCP 버전 1.7</block>
  <block id="0bf2dca8ce9b94406660e58b59a3dbbd" category="list-text">Linux 서버 1개 - Linux(RHEL 7.9 또는 RHEL 8)</block>
  <block id="d85d793ce9fe1772209fa5e17fb29449" category="list-text">Windows 서버 1대 – Windows Server 2019 표준</block>
  <block id="91ea491db15b6d672d79b23fb98eb089" category="cell">소스 볼륨의 NetApp AFF 스토리지 어레이 HA 쌍</block>
  <block id="23ec9249d03285a513eaaf182a7bcd49" category="list-text">AFF8080</block>
  <block id="80fdc6d88149270be735269f2ff65645" category="cell">타겟 볼륨을 위한 NetApp AFF 스토리지 어레이 HA 쌍</block>
  <block id="203165a49e3a391bdbc44e3a05d54279" category="list-text">ONTAP 9</block>
  <block id="28712ee052ea500eba0cdbb1d847277f" category="cell">Fujitsu PRIMERGY RX2540 서버</block>
  <block id="539c5af1c2682685cd076697aaa6c700" category="cell">각각 * 48 CPU * 인텔 제온 * 256GB 물리적 메모리 * 10GbE 듀얼 포트가 장착되어 있습니다</block>
  <block id="0cc5c79089d6ca0752529568758efc4c" category="cell">10GbE</block>
  <block id="76e3e2a4e56301dafc50613d96fd624e" category="section-title">구축 단계 - NAS</block>
  <block id="2879e817640f94636340918850eb6903" category="inline-link">NetApp XCP 사용자 가이드</block>
  <block id="f2dd54ec57ec5464ee3aa191a48a8a43" category="paragraph">데이터 전송에 NetApp XCP를 배포하려면 먼저 대상 위치에 XCP 소프트웨어를 설치하고 활성화합니다. 에서 세부 정보를 검토할 수 있습니다<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>. 이렇게 하려면 다음 단계를 완료하십시오.</block>
  <block id="62e9f0426675b856daf874c75830c213" category="inline-link-macro">"XCP의 필수 구성 요소"</block>
  <block id="4f6583b152ef684b4492414bcdcdf877" category="list-text">섹션에 설명된 대로 필수 구성 요소를 충족합니다 <block ref="958d961a425946e5195ca036cea97fab" category="inline-link-macro-rx"></block></block>
  <block id="c58c8903e33903d2e630277aa3a78795" category="inline-link">NetApp XCP(다운로드) 페이지</block>
  <block id="2d1acef34bb45f2c1878c6b576f3b400" category="list-text">에서 XCP 소프트웨어를 다운로드합니다<block ref="13844fc5dba1627d28169d2acfff11e2" category="inline-link-rx"></block>.</block>
  <block id="8319752fe43598ddb329e536217c1cb5" category="list-text">다운로드한 xCP tar 파일을 xCP 서버에 복사합니다.</block>
  <block id="c9b8e059d1597eaead43d286e91c91e3" category="list-text">tar 파일의 압축을 풉니다.</block>
  <block id="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link"><block ref="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link-rx"></block></block>
  <block id="19f1deecf23a78878eb01c772b9233e0" category="list-text">에서 라이센스를 다운로드합니다<block ref="4da39fde529d1b69f60873c302229eed" category="inline-link-rx"></block> xCP 서버에 복사합니다.</block>
  <block id="3df11515e644382207c1430c36ea48bb" category="list-text">라이센스를 활성화합니다.</block>
  <block id="ad7984249c2054b4da5fd3b57b1b91ef" category="list-text">소스 NFS 포트와 대상 NFS 서버를 찾습니다. 기본 포트는 2049입니다.</block>
  <block id="79fe861b8c719b1a534bdbcace1444a2" category="list-text">NFS 연결을 확인합니다. NFS 서버 포트에 대한 텔넷을 사용하여 NFS 서버(소스 및 대상 모두)를 확인합니다.</block>
  <block id="5e471de79dbe02105770bcf04bc501d5" category="list-text">카탈로그를 구성합니다.</block>
  <block id="67005679d502da10622f2104421e894b" category="list-text">NFS 볼륨을 생성하고 XCP 카탈로그용 NFS를 내보냅니다. xCP 카탈로그에 운영 체제 NFS 내보내기를 활용할 수도 있습니다.</block>
  <block id="d6f2a18783592d1858e3e5bdcabd4567" category="list-text">NFS 내보내기를 확인합니다.</block>
  <block id="39b638480b201a7448774e8186012e4e" category="list-text">업데이트: xcp.ini`.</block>
  <block id="9d44d1309af47903754b16c403f68774" category="list-text">xCP 쇼를 사용하여 소스 NAS 내보내기를 찾습니다. 공략 대상:</block>
  <block id="fbff9a42f0ba33571594cb39da93ef4b" category="list-text">(선택 사항) 소스 NAS 데이터를 스캔합니다.</block>
  <block id="82d1938e7390e37babdea8d6fd359156" category="paragraph">소스 NAS 데이터를 스캔하면 데이터 레이아웃을 이해하고 마이그레이션 시 발생할 수 있는 문제를 찾을 수 있습니다. xCP 스캔 작업 시간은 파일 수와 디렉토리 깊이에 비례합니다. NAS 데이터에 익숙한 경우 이 단계를 건너뛸 수 있습니다.</block>
  <block id="c6e94e11da5ba5bce0f27b8c782e4110" category="list-text">xCP 스캔 보고서를 확인하십시오. 읽을 수 없는 폴더와 읽을 수 없는 파일을 주로 검색합니다.</block>
  <block id="6a6a10773cfc849f638ac0137a5f08d6" category="list-text">(선택 사항) inode를 변경합니다. inode 수를 보고 카탈로그 및 대상 볼륨 모두에 대해 마이그레이션하거나 복제할 파일 수에 따라 번호를 수정합니다(필요한 경우).</block>
  <block id="342779baf0b15fdf377f142c987e896a" category="list-text">대상 볼륨을 스캔합니다.</block>
  <block id="a88831977a2b62e982b722f6fa6662b5" category="list-text">소스 및 대상 볼륨 공간을 확인합니다.</block>
  <block id="4b14d92fd07932987cf7416eb7f604ca" category="list-text">xCP COPY를 사용하여 소스에서 대상으로 데이터를 복사하고 요약을 확인합니다.</block>
  <block id="506aae448569ed08125f41ed940eb00b" category="admonition">기본적으로 XCP는 데이터를 복사할 수 있는 7개의 병렬 프로세스를 생성합니다. 이 기능은 조정할 수 있습니다.</block>
  <block id="5c46a2da3e6e0423829946fe877c50b8" category="admonition">소스 볼륨은 읽기 전용을 사용하는 것이 좋습니다. 실시간으로 소스 볼륨은 활성 상태의 라이브 파일 시스템입니다. NetApp XCP는 애플리케이션에 의해 지속적으로 변경되는 라이브 소스를 지원하지 않으므로 'XCP 복사' 작업이 실패할 수 있습니다.</block>
  <block id="0f7dbc07af0b5c3ba51ff604b81ebe8a" category="paragraph">Linux의 경우 xCP Linux가 카탈로그 작성을 수행하기 때문에 xCP에 인덱스 ID가 필요합니다.</block>
  <block id="764363dd147880ab6aca242a0417562e" category="list-text">(선택 사항) 타겟 NetApp 볼륨의 inode를 확인합니다.</block>
  <block id="ab3ba5fb62db279b7d07bac650a6c2d2" category="list-text">xCP 동기화를 사용하여 증가분 업데이트를 수행합니다.</block>
  <block id="6cdfbe571ba2209e0a76f3bcabfee9f6" category="paragraph">이 문서의 경우 실시간으로 시뮬레이션하기 위해 소스 데이터에 있는 100만 개의 파일 이름이 바뀐 다음 XCP 동기화를 사용하여 업데이트된 파일을 대상으로 복사했습니다. Windows의 경우 xCP는 소스 경로와 대상 경로를 모두 필요로 합니다.</block>
  <block id="13475b4ca9a916769b9d63f4fddfa18d" category="list-text">데이터 전송을 확인합니다. 'xCP verify'를 사용하면 소스와 대상의 데이터가 동일한지 확인할 수 있습니다.</block>
  <block id="1cd06f171a5a99926a67bd673014f765" category="paragraph">xCP 문서는 'CAN', '카피', '동기화', 'fy' 작업에 대한 여러 가지 옵션(예)을 제공합니다. 자세한 내용은 를 참조하십시오<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>.</block>
  <block id="efa146517859e051c07fabac4c88d3e7" category="admonition">Windows 고객은 ACL(액세스 제어 목록)을 사용하여 데이터를 복사해야 합니다. NetApp은 'xCP copy -acl -frodbackuser\&lt;사용자 이름&gt; -frodbackgroup\&lt;사용자 이름 또는 groupname&gt;&lt;source&gt;&lt;destination&gt;' 명령을 사용할 것을 권장합니다. 성능을 극대화하려면 ACL이 있는 SMB 데이터와 NFS와 SMB가 모두 액세스할 수 있는 데이터를 가진 소스 볼륨을 고려할 때 타겟은 NTFS 볼륨이어야 합니다. xCP(NFS 버전)를 사용하여 Linux 서버에서 데이터를 복사하고 Windows 서버에서 '-ACL' 및 '-NoData' 옵션을 사용하여 xCP(SMB 버전) 동기화를 실행하여 소스 데이터에서 타겟 SMB 데이터로 ACL을 복사합니다.</block>
  <block id="85760de676a9f74f28f26115c39c9a0b" category="inline-link">'감사 및 보안 로그 관리' 정책 구성</block>
  <block id="a0251b301ad566d86ffa3916c5510295" category="paragraph">자세한 단계는 을 참조하십시오<block ref="06fdba77988da3047baf401e4fdefca5" category="inline-link-rx"></block>.</block>
  <block id="0957326f089aaf98a5b7b9110a2675cd" category="section-title">구축 단계 - HDFS/MapRFS 데이터 마이그레이션</block>
  <block id="1f43fc63f63aad0b707e06b0753182a1" category="paragraph">이 섹션에서는 HDFS/MapRFS에서 NFS로, 그 반대로 데이터를 마이그레이션하는 Hadoop Filesystem Data Transfer to NAS라는 새로운 XCP 기능에 대해 설명합니다.</block>
  <block id="368666825ffae5710ab122fb63937cee" category="paragraph">MapRFS/HDFS 기능의 경우 루트가 아닌 사용자 환경에서 다음 절차를 수행해야 합니다. 일반적으로 비루트 사용자는 HDFS, MapR 또는 HDFS 및 MapRFS 파일 시스템을 변경할 수 있는 권한이 있는 사용자입니다.</block>
  <block id="9adbc05b1436b3e8962253577f1e6441" category="list-text">CLI에서 CLASSPATH, HADOOP_HOME, NHDFS_LIBJVM_PATH, LB_LIBRARY_PATH 및 NHDFS_LIBHDFS_PATH 변수를 설정하거나, 'xCP' 명령과 함께 사용자의 .bashrc 파일을 설정합니다.</block>
  <block id="2a0eda7a7937e303f9e18a57a033fcb8" category="list-text">NHDFS_LIBHDFS_path는 libhdfs.so 파일을 가리킵니다. 이 파일은 HDFS API를 제공하여 Hadoop 배포의 일부로 HDFS/MapRFS 파일 및 파일 시스템을 상호 작용하고 조작합니다.</block>
  <block id="13682a0461e750a2dfb4e86c2ddc1165" category="list-text">NHDFS_LIBJVM_PATH는 libjvm.so 파일을 가리킵니다. JRE 위치에 있는 공유 Java 가상 머신 라이브러리입니다.</block>
  <block id="60ce276a5dde3f2d2e92b1986a2eb339" category="list-text">CLASSPATH는 (Hadoop classpath –glob) 값을 사용하는 모든 jar 파일을 가리킵니다.</block>
  <block id="84cbf778b2572cae5eba01d0ca330078" category="list-text">ld_library_path는 Hadoop 기본 라이브러리 폴더 위치를 가리킵니다.</block>
  <block id="68207eb9f168add2309e88b5223d57c6" category="paragraph">Cloudera 클러스터에 기반한 다음 샘플을 참조하십시오.</block>
  <block id="91328810a5559a740f522f4c5a1da5f1" category="paragraph">이번 릴리즈에서는 HDFS에서 NFS로 운영 및 데이터 마이그레이션을 수행하는 XCP 스캔, 복사 및 검증을 지원합니다. 데이터 레이크 클러스터 단일 작업자 노드 및 여러 작업자 노드에서 데이터를 전송할 수 있습니다. 1.8 릴리즈에서는 루트 및 비루트 사용자가 데이터 마이그레이션을 수행할 수 있습니다.</block>
  <block id="dee4c2c7e685015e9f3cc1ad197f3ab5" category="section-title">구축 단계 - 루트 이외의 사용자가 HDFS/MaprFS 데이터를 NetApp NFS로 마이그레이션합니다</block>
  <block id="5983f77acc016b8138698b32b0ab0405" category="list-text">배포 단계의 1-9 단계에서 설명한 것과 동일한 단계를 따릅니다.</block>
  <block id="c2765e27844a39bfc897cb964eec8711" category="list-text">다음 예에서는 사용자가 데이터를 HDFS에서 NFS로 마이그레이션합니다.</block>
  <block id="e6f549e8013d1f24b8756cd11ff3083e" category="list-text">HDFS에서 폴더 및 파일('Hadoop fs-copyFromLocal' 사용)을 생성합니다.</block>
  <block id="2433ce85404dd68893a2e4abb99843e4" category="list-text">HDFS 폴더에서 권한을 확인합니다.</block>
  <block id="befab6065ddb441f0b260ac75a8e84c8" category="list-text">NFS에서 폴더를 생성하고 권한을 확인합니다.</block>
  <block id="02341ea695e862c3a2d89461b1b8bf37" category="list-text">xCP를 사용하여 HDFS에서 NFS로 파일을 복사하고 권한을 확인합니다.</block>
  <block id="d2bac014bbd39f6954893239102c5678" category="inline-link-macro">다음: 사이징 지침</block>
  <block id="b49cd7fb5a227da1698c527804f31bbb" category="paragraph"><block ref="b49cd7fb5a227da1698c527804f31bbb" category="inline-link-macro-rx"></block></block>
  <block id="dc0b758a04bbb9e380300887d831e4e1" category="summary">이 섹션에서는 XCP 작업의 성능을 향상시키는 데 도움이 되는 튜닝 매개 변수 몇 가지를 제공합니다.</block>
  <block id="9db3ca538820d0cfb7b44ef80f16ca98" category="doc">성능 튜닝</block>
  <block id="7931b9aae255139b42cb605b3b62a6db" category="inline-link-macro">이전: 사이징 지침</block>
  <block id="0ff4824165c6661bc016402e35d2a9fe" category="paragraph"><block ref="0ff4824165c6661bc016402e35d2a9fe" category="inline-link-macro-rx"></block></block>
  <block id="ec6136417c258c9b7f95c39765c5ca51" category="paragraph">이 섹션에서는 XCP 작업의 성능을 향상시키는 데 도움이 되는 튜닝 매개 변수 몇 가지를 제공합니다.</block>
  <block id="dd10b781bf6dd686a8631401ce0fba96" category="list-text">더 나은 확장을 위해 여러 xCP 인스턴스에 워크로드를 분산하려면 마이그레이션 및 데이터 전송을 위해 각 xCP 인스턴스에 대한 하위 폴더를 분할합니다.</block>
  <block id="37e9b10f81fe31cb6b80609f724b34f8" category="list-text">xCP는 최대 CPU 리소스를 사용할 수 있습니다. CPU 코어가 많을수록 성능이 향상됩니다. 따라서 xCP 서버에 더 많은 CPU가 있어야 합니다. 실습은 128GB RAM 및 48배 코어 CPU를 테스트했으며, 이는 8개의 CPU와 8GB RAM보다 뛰어난 성능을 제공했습니다.</block>
  <block id="a02c6dbd226d5506c1b4b07f6d383615" category="list-text">'-parallel' 옵션이 포함된 xCP 복제본은 CPU 수에 따라 달라집니다. 대부분의 XCP 데이터 전송 및 마이그레이션 작업에는 기본 병렬 스레드 수(7개)가 충분할 수 있습니다. xCP Windows의 경우 기본적으로 병렬 프로세스의 수는 CPU 수와 같습니다. '-parallel' 옵션의 최대 개수는 코어 수보다 작거나 같아야 합니다.</block>
  <block id="740950b0e27cdd5def3c4295d5840851" category="list-text">10GbE는 데이터 전송을 시작하는 데 적합합니다. 그러나 25GbE 및 100GbE로 테스트하여 데이터 전송 성능이 향상되었고 대용량 파일 크기 데이터 전송에 권장됩니다.</block>
  <block id="a174d00dcd4849e0653429de84c71cde" category="list-text">Azure NetApp Files의 경우 성능은 서비스 수준에 따라 다릅니다. 자세한 내용은 Azure NetApp Files 서비스 수준 및 성능 세부 정보를 보여 주는 다음 표를 참조하십시오.</block>
  <block id="6d59be48f566a73e053e12167b279be5" category="cell">서비스 레벨</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">표준</block>
  <block id="8d5e7e72f12067991186cdf3cb7d5d9d" category="cell">프리미엄</block>
  <block id="7057376a419b3334cc7b8b7a9f064abb" category="cell">초대형</block>
  <block id="0b85467ebafa7ca3c47e82dc38184484" category="cell">처리량</block>
  <block id="adcda45ec4de9aeb48e1893272b078d1" category="cell">16MBps/테라바이트(TB)</block>
  <block id="93209d2e9d1ed8d87a279cef886b5021" category="cell">64MBps/TB</block>
  <block id="f646efbbd60d091e92b32611965c4f1c" category="cell">128MBps/TB</block>
  <block id="4a9cc851fc41c5762618832386fa4937" category="cell">워크로드 유형</block>
  <block id="11969136028e1ffaeed70de5e59bde33" category="cell">범용 파일 공유, 이메일, 웹</block>
  <block id="76ab8c335a6bb24396ea1953bac75705" category="cell">BMS, 데이터베이스 및 애플리케이션</block>
  <block id="9dab8e594b90062c0612cbb1676234ba" category="cell">지연 시간에 민감한 애플리케이션</block>
  <block id="0a568304277380e4cfb0f2d2abbd99b4" category="cell">성능 설명</block>
  <block id="c55268b956eecd1d58f60723a410c808" category="cell">표준 성능: TB당 1,000 IOPS(16K I/O) 및 16MBps/TB</block>
  <block id="536d2154a9035458ae8efd38b24f3ea7" category="cell">프리미엄 성능 – TB당 4,000 IOPS(16k I/O) 및 TB당 64MBps</block>
  <block id="91ff77656b0dc231fcbe8f488a15a253" category="cell">탁월한 성능: TB당 8,000 IOPS(16k I/O) 및 128MBps/TB</block>
  <block id="121bc30e927e8a3d918fc90c0ec18fee" category="paragraph">처리량 및 워크로드 유형에 따라 적합한 서비스 수준을 선택해야 합니다. 대부분의 고객은 프리미엄 레벨에서 시작하고 워크로드에 따라 서비스 수준을 변경합니다.</block>
  <block id="f44706d8f59ec82b48b083fb246a4fc7" category="inline-link-macro">다음은 고객 시나리오입니다.</block>
  <block id="bb0eaaf9fa62e9175efd3145f00946ea" category="paragraph"><block ref="bb0eaaf9fa62e9175efd3145f00946ea" category="inline-link-macro-rx"></block></block>
  <block id="b25f76deff236f93a3afa73c8a5b2a2c" category="summary">이 사용 사례는 수백만 개의 소규모 사내 파일을 클라우드로 마이그레이션하는 가장 큰 NetApp 관광 산업 고객을 기반으로 합니다.</block>
  <block id="4b1739353c6d18cea69ed6a274b7135f" category="doc">xCP Data Mover를 사용하여 수백만 개의 작은 파일을 유연한 스토리지로 마이그레이션합니다</block>
  <block id="2b2142a0bf2476846ad59f7952380ca1" category="inline-link-macro">이전: ONTAP NFS에 대한 고성능 컴퓨팅.</block>
  <block id="c81efa558deea51a126490ba8d09b59a" category="paragraph"><block ref="c81efa558deea51a126490ba8d09b59a" category="inline-link-macro-rx"></block></block>
  <block id="bb29cc4e9e4447f7bad1e81c1c5a9a1f" category="paragraph">이 사용 사례는 사내-클라우드 데이터 마이그레이션을 위한 가장 큰 NetApp 관광 산업 고객을 기반으로 합니다. COVID-19는 여행 업계의 수요를 감소시켰습니다. 따라서 고객은 온프레미스 환경의 하이엔드 스토리지에서 수요 가격 책정 애플리케이션에 대한 자본 비용을 절감하려고 합니다. 이 고객은 수백만 개의 작은 파일을 클라우드로 마이그레이션하는 엄격한 SLA를 보유하고 있습니다.</block>
  <block id="81ec900a5387f7a686d1451adaddf399" category="paragraph">다음 그림은 Azure NetApp Files 소용량 파일을 위한 사내의 데이터 마이그레이션을 보여 줍니다.</block>
  <block id="214c5e9894032cde0e65b576e32294b9" category="paragraph"><block ref="214c5e9894032cde0e65b576e32294b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="099a60093e7de3795f557974125ce82b" category="inline-link">NetApp XCP Data Mover 솔루션: 사내에서 클라우드로</block>
  <block id="50d4edabefc40ad9614b567197696a2e" category="paragraph">자세한 내용은 를 참조하십시오<block ref="2c0eb3741003532ef113837d4b882a9a" category="inline-link-rx"></block> 블로그:</block>
  <block id="3242fe890cd89c89373a1bd576cef03a" category="inline-link-macro">다음으로 xCP Data Mover를 사용하여 대용량 파일을 마이그레이션합니다.</block>
  <block id="c32441c7755c153b58450a597193448b" category="paragraph"><block ref="c32441c7755c153b58450a597193448b" category="inline-link-macro-rx"></block></block>
  <block id="5dc302565fd7f552e134618ee18d2be2" category="summary">이 솔루션은 특정 날짜를 기준으로 데이터를 복사해야 하는 고객을 기반으로 합니다.</block>
  <block id="07f04efd2f421076b9aa06c4fee83be5" category="doc">특정 날짜 기반 스캔 및 데이터 복사</block>
  <block id="7af90e46070dd59c121e31e1525d4af2" category="inline-link-macro">이전: 파일을 복제합니다.</block>
  <block id="7f58802ce1d6245244bb449cd961f0f3" category="paragraph"><block ref="7f58802ce1d6245244bb449cd961f0f3" category="inline-link-macro-rx"></block></block>
  <block id="e0b5216bc931e3e5fd7efb74ad10b1d3" category="paragraph">이 솔루션은 특정 날짜를 기준으로 데이터를 복사해야 하는 고객을 기반으로 합니다. 다음 세부 정보를 확인합니다.</block>
  <block id="c277b447e2e86b92f26c7dbcf8fecdf2" category="inline-link-macro">다음: SMB/CIFS 공유에서 CSV 파일 생성</block>
  <block id="7a9653d25343b8ddab24257e57b5be7a" category="paragraph"><block ref="7a9653d25343b8ddab24257e57b5be7a" category="inline-link-macro-rx"></block></block>
  <block id="89bddd14a9f02aeace6d5ffadf25e4f3" category="summary">이 문서에서는 NetApp XCP 모범 사례 지침과 테스트 시나리오 기반 솔루션을 제공합니다. 이 모범 사례는 사내 마이그레이션 워크플로와 클라우드, 파일 시스템 분석, 문제 해결, XCP의 성능 튜닝 등에 대해 다룹니다.</block>
  <block id="e7b1326bcbbf0b5513213b2373b5721a" category="doc">TR-4863: NetApp XCP에 대한 모범 사례 지침 - Data Mover, 파일 마이그레이션 및 분석</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">NetApp의 Karthikeyan Nagalingam입니다</block>
  <block id="88d20f11fbf1788b5271fcc5d5297a41" category="paragraph">이 문서에서는 NetApp XCP 모범 사례 지침과 테스트 시나리오 기반 솔루션을 제공합니다. 이 모범 사례는 사내 마이그레이션 워크플로와 클라우드, 파일 시스템 분석, 문제 해결, XCP 성능 튜닝 등에 대해 다룹니다. 테스트 시나리오 섹션에서는 고객 사용 사례와 요구 사항, XCP를 사용하는 NetApp 솔루션 및 고객에게 제공되는 혜택에 대해 설명합니다.</block>
  <block id="842b5068483a5cd5b058644a5d000f1c" category="inline-link-macro">다음으로 NetApp XCP를 살펴보겠습니다.</block>
  <block id="10dbc4bbbec11552354dca73bcd59c78" category="paragraph"><block ref="10dbc4bbbec11552354dca73bcd59c78" category="inline-link-macro-rx"></block></block>
  <block id="322bc614a8031f8c334d233f8221a4ab" category="summary">이 섹션에서는 7-Mode에서 작동하는 NetApp Data ONTAP에서 ONTAP로 데이터를 마이그레이션하기 위한 자세한 단계를 제공합니다.</block>
  <block id="30ee25b2188724428e827e97bab504fe" category="doc">7-Mode에서 ONTAP로 데이터 마이그레이션</block>
  <block id="aecfc9b89f609bfde217a6cf8fc0b00a" category="inline-link-macro">이전: SMB/CIFS 공유에서 CSV 파일 생성</block>
  <block id="6da13b2cdb445320dc3e29759119f4e8" category="paragraph"><block ref="6da13b2cdb445320dc3e29759119f4e8" category="inline-link-macro-rx"></block></block>
  <block id="3ec8186e1900b95154cccf8ccea38023" category="section-title">7-Mode NFSv3 스토리지를 NFS 데이터용 ONTAP으로 전환하는 중입니다</block>
  <block id="e70a6b3d23d1e0da94c71a9ea26747d1" category="paragraph">이 섹션에서는 소스 7-Mode NFSv3 내보내기를 ONTAP 시스템으로 전환하기 위한 다음 표의 단계별 절차를 제공합니다.</block>
  <block id="cad365d13740342c8f6199feb7229137" category="paragraph">NetApp은 소스 7-Mode NFSv3 볼륨을 내보내고 클라이언트 시스템에 마운트했으며 XCP가 Linux 시스템에 이미 설치되어 있다고 가정합니다.</block>
  <block id="b40dbfa52a308abff927380b983cd868" category="list-text">대상 ONTAP 시스템이 정상인지 확인합니다.</block>
  <block id="39745ae9472f91abcd9e844389157858" category="list-text">대상 시스템에 하나 이상의 비루트 Aggregate가 있는지 확인합니다. Aggregate는 정상 상태입니다.</block>
  <block id="47e01226b4fdf549d938eb5c6196970d" category="paragraph">데이터 집계가 없는 경우 'storage aggr create' 명령을 사용하여 새 데이터 애그리게이트를 생성합니다.</block>
  <block id="5c52d0e31e44663ee633be681387faa1" category="list-text">타겟 클러스터 시스템에 SVM(스토리지 가상 머신)을 생성합니다.</block>
  <block id="426b5839edbb7a7772be396e7eaceace" category="list-text">타겟 SVM에서 FCP, iSCSI, NDMP 및 CID 프로토콜을 제거합니다.</block>
  <block id="d03930721e424cdac105ccd0172f7dbe" category="paragraph">이 SVM에서 NFS가 허용되는 프로토콜인지 확인합니다.</block>
  <block id="4d6b5eb9160c3c34e9ff5535c403cea9" category="list-text">대상 SVM에서 새 읽기-쓰기 데이터 볼륨을 생성합니다. 보안 스타일, 언어 설정 및 용량 요구 사항이 소스 볼륨과 일치하는지 확인합니다.</block>
  <block id="a2cebf1e91b2a266a58458873c8980fd" category="list-text">데이터 LIF를 생성하여 NFS 클라이언트 요청을 처리합니다.</block>
  <block id="6817d90b89495074e679248b56128378" category="paragraph">LIF가 성공적으로 생성되었는지 확인합니다.</block>
  <block id="3a014fae7f5d70cc01c593a8401140ee" category="list-text">필요한 경우 SVM으로 정적 경로를 생성합니다.</block>
  <block id="84bb87c2987a4b39ea23430f38570808" category="paragraph">라우트가 성공적으로 생성되었는지 확인합니다.</block>
  <block id="54b19b8b3b6de7bce018de598a1645ea" category="list-text">SVM 네임스페이스에서 타겟 NFS 데이터 볼륨을 마운트합니다.</block>
  <block id="6365adb4324221d944bc90c4663dfe5a" category="paragraph">볼륨이 성공적으로 마운트되었는지 확인합니다.</block>
  <block id="991398c32a43bcf95d7fa14129a6fcb0" category="paragraph">"volume create" 명령을 사용하여 볼륨 마운트 옵션(접합 경로)을 지정할 수도 있습니다.</block>
  <block id="6c02d24a81dd4d9b1ad7a15079b4f122" category="list-text">타겟 SVM에서 NFS 서비스를 시작합니다.</block>
  <block id="e210fe657c5d46e3e11ca263d1a18af7" category="paragraph">서비스가 시작되고 실행 중인지 확인합니다.</block>
  <block id="304683b37151feda067e3acfde300057" category="list-text">기본 NFS 엑스포트 정책이 타겟 SVM에 적용되었는지 확인</block>
  <block id="353fde8a37910716dc00dec81475c0d5" category="list-text">필요한 경우 타겟 SVM을 위한 맞춤형 엑스포트 정책을 새로 생성합니다.</block>
  <block id="174608facfdad6448222d6d46c87fba5" category="paragraph">새 사용자 지정 엑스포트 정책이 성공적으로 생성되었는지 확인합니다.</block>
  <block id="4007cf260b496d35ba0e925f1e7a183d" category="list-text">NFS 클라이언트에 대한 액세스를 허용하도록 엑스포트 정책 규칙을 수정합니다.</block>
  <block id="5f249df749512e129505d18fd47d7010" category="list-text">클라이언트가 볼륨에 액세스할 수 있는지 확인합니다.</block>
  <block id="94a80f56f92334f07fd30337692ca889" category="list-text">Linux NFS 서버에 연결합니다. NFS에서 내보낸 볼륨의 마운트 지점을 생성합니다.</block>
  <block id="725ae014e8d8f66f0f2d477fa656ba32" category="list-text">이 마운트 지점에서 타겟 NFSv3 내보낸 볼륨을 마운트합니다.</block>
  <block id="a345b19bdd483ecd745a2e643b756bc6" category="admonition">NFSv3 볼륨은 내보내야 하지만 반드시 NFS 서버에 의해 마운트되는 것은 아닙니다. 마운트될 수 있는 경우 xCP Linux 호스트 클라이언트는 이러한 볼륨을 마운트합니다.</block>
  <block id="b5b2af7fb88c03cfd258cdd77fc6fbe1" category="paragraph">마운트 지점이 성공적으로 생성되었는지 확인합니다.</block>
  <block id="8d3ac4d5ea9c5d5c45d7322512d7b778" category="list-text">NFS에서 내보낸 마운트 지점에 테스트 파일을 생성하여 읽기-쓰기 액세스를 설정합니다.</block>
  <block id="07e483b5917b8a9e91a22b2ebc20961a" category="admonition">읽기-쓰기 테스트가 완료된 후 타겟 NFS 마운트 지점에서 파일을 삭제합니다.</block>
  <block id="09280cd628b820e696b87163b3fe0fde" category="list-text">xCP가 설치된 Linux 클라이언트 시스템에 연결합니다. xCP 설치 경로로 이동합니다.</block>
  <block id="86de6eeea329a50737c7056637f43e49" category="list-text">xCP Linux 클라이언트 호스트 시스템에서 'xCP show' 명령을 실행하여 소스 7-Mode NFSv3 내보내기를 쿼리합니다.</block>
  <block id="080173849f5fec049b214897a2882295" category="list-text">소스 NFSv3 내보낸 경로를 검색하고 해당 파일 구조의 통계를 인쇄합니다.</block>
  <block id="df86b239e412ba3ba7192b581381b444" category="paragraph">xCP의 캔, 복사, 동기화 작업 중에는 소스 NFSv3 내보내기를 읽기 전용 모드로 설정하는 것이 좋습니다.</block>
  <block id="695efe20ffcfc7c261e44cbb1b62cc78" category="list-text">타겟 ONTAP 시스템에서 NFSv3 내보내기에 소스 7-Mode NFSv3 내보내기를 복사합니다.</block>
  <block id="50515e001679292835a498c6bd3f3c31" category="list-text">복제가 완료된 후 소스 및 타겟 NFSv3 내보내기에 동일한 데이터가 있는지 확인합니다. xCP Verify 명령을 실행합니다.</block>
  <block id="70d6a53ca7c3c592cb4099e2988c226c" category="paragraph">xCP verify가 소스와 대상 데이터의 차이를 발견하면 요약에 해당 파일이나 디렉토리가 없습니다 라는 오류가 보고됩니다. 이 문제를 해결하려면 'xCP sync' 명령을 실행하여 소스 변경 내용을 대상에 복사합니다.</block>
  <block id="505d73172f49d62bd99779ab53aa5eeb" category="list-text">그전과 그 동안 다시 한번 도전하라. 소스에 새 데이터나 업데이트된 데이터가 있는 경우 증분 업데이트를 수행합니다. xCP sync 명령을 실행합니다.</block>
  <block id="887abb0b5917a0a6b0c47f5ef3eca1ce" category="list-text">이전에 중단된 복사 작업을 다시 시작하려면 xCP resume 명령을 실행합니다.</block>
  <block id="f807709818ec3fbc508863a00ea17044" category="paragraph">'SUME'가 파일 복사를 완료한 후 소스와 대상 스토리지에 동일한 데이터가 있도록 'riry'를 다시 실행하십시오.</block>
  <block id="d78900410b9203071958256c3d6a7701" category="list-text">NFSv3 클라이언트 호스트는 7-Mode 스토리지에서 프로비저닝된 소스 NFSv3 내보내기를 마운트 해제하고 ONTAP에서 타겟 NFSv3 엑스포트를 마운트해야 합니다. 컷오버에 중단이 필요합니다.</block>
  <block id="6bd42ffcfd349b793e9f6c6f00c18cd8" category="section-title">7-Mode 볼륨 Snapshot 복사본을 ONTAP로 전환 중</block>
  <block id="fefac3d628a2abc2d1677e073a0688e7" category="paragraph">이 섹션에서는 소스 7-Mode 볼륨의 NetApp Snapshot 복사본을 ONTAP로 전환하기 위한 절차를 다룹니다.</block>
  <block id="721e28a3edb434ca3d7f37307126504c" category="admonition">NetApp은 소스 7-Mode 볼륨을 내보내서 클라이언트 시스템에 마운트하고 Linux 시스템에 XCP가 이미 설치되어 있다고 가정합니다. 스냅샷 복사본은 마지막 스냅샷 복사본 이후의 증분 변경 사항을 기록하는 볼륨의 시점 이미지입니다. 7-Mode 시스템에서 소스로 '-snap' 옵션을 사용합니다.</block>
  <block id="e18566c8fe02de3e35e48df30daa5189" category="paragraph">* 경고: * 기본 스냅샷 복사본을 유지합니다. 기본 복사본이 완료된 후에는 기본 스냅샷 복사본을 삭제하지 마십시오. 추가 동기화 작업을 위해서는 기본 스냅샷 복사본이 필요합니다.</block>
  <block id="50bdf0eaa7b3716343ae0345a98e1a5f" category="list-text">타겟 클러스터 시스템에 SVM을 생성합니다.</block>
  <block id="2e4b636c74015de6d92a2eb874c15a88" category="list-text">타겟 SVM에서 FCP, iSCSI, NDMP 및 CIFS 프로토콜을 제거합니다.</block>
  <block id="c45e0bc468a9249c2954fa84c21f833e" category="list-text">필요한 경우 SVM으로 정적 경로를 생성합니다.</block>
  <block id="f35ea333881cef53fcd944d5a052be9d" category="paragraph">볼륨이 성공적으로 마운트되었는지 확인합니다.</block>
  <block id="71c0d546c4569fd9a5798bdbc9729ab6" category="paragraph">"volume create" 명령을 사용하여 볼륨 마운트 옵션(접합 경로)을 지정할 수도 있습니다.</block>
  <block id="7ec3f8d8dd165416936305e1ca1530f0" category="list-text">기본 NFS 엑스포트 정책이 타겟 SVM에 적용되는지 확인합니다.</block>
  <block id="f69801ea46df8aed1b26399a9330f459" category="list-text">대상 시스템의 NFS 클라이언트에 대한 액세스를 허용하도록 엑스포트 정책 규칙을 수정합니다.</block>
  <block id="9fee35c8bded36b1931a6addb7635a81" category="list-text">클라이언트가 타겟 볼륨에 액세스할 수 있는지 확인합니다.</block>
  <block id="7633c6765c7399ce0f1ecbca891fb11c" category="paragraph">xCP 스캔, 복사, 동기화 작업 중에 소스 NFSv3 내보내기를 읽기 전용 모드로 설정하는 것이 좋습니다. '동기화' 동작에서는 '-snap' 옵션을 해당 값으로 전달해야 합니다.</block>
  <block id="486e9eb5a73ed3d87e070761d3ceeefe" category="list-text">소스 7-Mode NFSv3 스냅샷(기본)을 타겟 ONTAP 시스템의 NFSv3 내보내기에 복사합니다.</block>
  <block id="160bb3a75d27ad175143123df09bce76" category="admonition">추가 동기화 작업을 위해 이 기본 스냅샷을 유지합니다.</block>
  <block id="97ba1a5f7ee8f9243390e46469b6e8f3" category="list-text">복제가 완료된 후 소스 및 타겟 NFSv3 내보내기에 동일한 데이터가 있는지 확인합니다. xCP Verify 명령을 실행합니다.</block>
  <block id="44842ca325a3ba46b3b4703a79fab171" category="paragraph">만약 원본과 대상 데이터의 차이를 발견한다면, 요약에는 '해당 파일 또는 디렉토리 없음' 오류가 보고된다. 이 문제를 해결하려면 'xCP sync' 명령을 실행하여 소스 변경 내용을 대상에 복사합니다.</block>
  <block id="030bc6fe403e876e1c932987ece73d61" category="list-text">그전과 그 동안 다시 한번 도전하라. 소스에 새 데이터나 업데이트된 데이터가 있는 경우 증분 업데이트를 수행합니다. 변동분이 있는 경우 이러한 변경 사항에 대한 새 스냅샷 복사본을 생성하고 동기화 작업을 위한 '-snap' 옵션을 사용하여 해당 스냅샷 경로를 전달합니다.</block>
  <block id="b29cfae254be5e3cfc339ed594ea9378" category="paragraph">'-snap' 옵션과 스냅샷 경로를 사용하여 xCP sync 명령을 실행합니다.</block>
  <block id="2885d0e1370007423656773743ce189b" category="admonition">이 작업을 수행하려면 기본 스냅샷이 필요합니다.</block>
  <block id="121dba07a28112a093b812991271c895" category="list-text">NFSv3 클라이언트 호스트는 7-Mode 스토리지에서 프로비저닝된 소스 NFSv3 내보내기를 마운트 해제하고 ONTAP에서 타겟 NFSv3 내보내기를 마운트해야 합니다. 이 컷오버에는 중단이 필요합니다.</block>
  <block id="6db55966f4a2b44c31ed7672f14d023e" category="section-title">NetApp 7-Mode에서 NetApp 스토리지 시스템으로 ACLv4 마이그레이션</block>
  <block id="8f81754856c547fbd3e5295b9da06cc7" category="paragraph">이 섹션에서는 소스 NFSv4 내보내기를 ONTAP 시스템으로 전환하기 위한 단계별 절차를 설명합니다.</block>
  <block id="fd58e84bd534e0ff49a00942e9ee2002" category="admonition">NetApp은 소스 NFSv4 볼륨을 내보내고 클라이언트 시스템에 마운트하며 Linux 시스템에 XCP가 이미 설치되어 있다고 가정합니다. 소스는 ACL을 지원하는 NetApp 7-Mode 시스템이어야 합니다. ACL 마이그레이션은 NetApp에서 NetApp으로의 마이그레이션만 지원합니다. 이름에 특수 문자가 있는 파일을 복사하려면 소스 및 대상이 UTF-8 인코딩 언어를 지원하는지 확인하십시오.</block>
  <block id="88464fae780b488ca9d39f305a3b3777" category="section-title">소스 NFSv4 내보내기를 ONTAP로 마이그레이션하기 위한 사전 요구 사항</block>
  <block id="078b760bc7ad8cae447a095cc53029af" category="paragraph">소스 NFSv4 내보내기를 ONTAP로 마이그레이션하기 전에 다음과 같은 사전 요구 사항이 충족되어야 합니다.</block>
  <block id="abb629da0d811e197b383d473d19f265" category="list-text">대상 시스템에 NFSv4가 구성되어 있어야 합니다.</block>
  <block id="09e4d7a665b5df121af76a08951028cf" category="list-text">NFSv4 소스와 타겟을 XCP 호스트에 마운트해야 합니다. 소스 및 타겟 스토리지와 일치하는 NFS v4.0을 선택하고 소스 및 타겟 시스템에서 ACL이 설정되었는지 확인합니다.</block>
  <block id="c36e1764174e8e6a7791e7afd73f3294" category="list-text">xCP에서는 ACL 처리를 위해 xCP 호스트에 소스/타겟 경로를 마운트해야 합니다. 다음 예에서는 '/mnt/vol1' 경로에 vol1(10.63.5.56:/vol1)이 마운트되었습니다.</block>
  <block id="baa4716341f52ff4d0642ca1398e16f1" category="section-title">하위 디렉터리 옵션</block>
  <block id="66f63b7de79aaf05b47a1b63467b2a84" category="paragraph">하위 디렉터리와 함께 사용할 수 있는 두 가지 옵션은 다음과 같습니다.</block>
  <block id="5d1498ef6a2ee01cb9031bbf8a8dadc4" category="list-text">xCP가 하위 디렉토리 '(/vol1/dir1/DIR11')에서 작업하려면 전체 경로('10.63.5.56:/vol1/dir1/DIR11')를 xCP 호스트에 마운트합니다.</block>
  <block id="39b3225d42725e9616ca3fee7aa7cbb6" category="paragraph">전체 경로가 마운트되지 않은 경우 xCP에서 다음 오류를 보고합니다.</block>
  <block id="84274fa575b6d9b0177512a818215d91" category="list-text">아래 예와 같이 하위 디렉토리 구문('mount:subdirectory/qtree/.snapshot')을 사용합니다.</block>
  <block id="8dd9bb3f47ac0b27a42761c265b0c720" category="paragraph">NetApp 7-Mode에서 NetApp 스토리지 시스템으로 ACCv4를 마이그레이션하려면 다음 단계를 완료하십시오.</block>
  <block id="b2f12804e995a318c2272527efb05774" category="paragraph">SVM이 성공적으로 생성되었는지 확인합니다.</block>
  <block id="b887d08ec971525ffbfec7f19d01d72d" category="list-text">기본 NFS 엑스포트 정책이 타겟 SVM에 적용되었는지 확인</block>
  <block id="1c94e1638450716cd57f55bafd07e60f" category="paragraph">정책 규칙이 수정되었는지 확인합니다.</block>
  <block id="132fa7c123291d5007311a22ff8f5654" category="list-text">이 마운트 지점에서 타겟 NFSv4 내보낸 볼륨을 마운트합니다.</block>
  <block id="c686c09824f51c6e681d87d1deb44c71" category="admonition">NFSv4 볼륨을 내보내야 하지만 반드시 NFS 서버에 의해 마운트되는 것은 아닙니다. 마운트될 수 있는 경우 xCP Linux 호스트 클라이언트는 이러한 볼륨을 마운트합니다.</block>
  <block id="e943b6ad310412b689f42adec28acf3a" category="paragraph">파일이 생성되었는지 확인합니다.</block>
  <block id="35ce5d99ee6b9bb871da972e459e7259" category="list-text">xCP Linux 클라이언트 호스트 시스템에서 'xCP show' 명령을 실행하여 소스 NFSv4 내보내기를 쿼리합니다.</block>
  <block id="97cc35dcdaf8c5c5fa0e936cd31e9907" category="list-text">소스 NFSv4 내보낸 경로를 검색하고 해당 파일 구조의 통계를 인쇄합니다.</block>
  <block id="5073080976611febfcee79295d42232e" category="paragraph">xCP 스캔, 복사, 동기화 작업 중에 소스 NFSv4 내보내기를 읽기 전용 모드로 설정하는 것이 좋습니다.</block>
  <block id="f120bcab91519def54b7b66ee0fbecfe" category="list-text">타겟 ONTAP 시스템의 NFSv4 내보내기에 소스 NFSv4 내보내기를 복제합니다.</block>
  <block id="39ff9cab7c62e62bf182a632271eb700" category="list-text">'복제'가 완료된 후 소스 및 대상 NFSv4 내보내기에 동일한 데이터가 있는지 확인합니다. xCP Verify 명령을 실행합니다.</block>
  <block id="977c8a5f0f7f70041a1c6359c72cb1cd" category="paragraph">만약 원본과 대상 데이터의 차이를 발견한다면, 요약에는 '해당 파일 또는 디렉토리 없음' 오류가 보고된다. 이 문제를 해결하려면 'xCP sync' 명령을 실행하여 소스 변경 내용을 대상에 복사합니다.</block>
  <block id="29aee025cf0bcad3c355bd0aad4516e6" category="admonition">이 작업의 경우 이전 복제 인덱스 이름 또는 번호가 필요합니다.</block>
  <block id="ee0fd4f8758695ad7502bee81363478a" category="list-text">이전에 중단된 '복사' 작업을 다시 시작하려면 xCP resume 명령을 실행합니다.</block>
  <block id="cdc35fb8de987dae3f48c142ffcb0686" category="section-title">CIFS 데이터를 위한 7-Mode SMB 스토리지를 ONTAP로 전환</block>
  <block id="74efc43b80fa7a84f709780789176e0d" category="paragraph">이 섹션에서는 소스 7-Mode SMB 공유를 ONTAP 시스템으로 전환하기 위한 단계별 절차를 다룹니다.</block>
  <block id="f6f758220d5d00061aaa03b99e14785b" category="admonition">NetApp은 7-Mode 및 ONTAP 시스템에 SMB 라이센스가 있다고 가정합니다. 타겟 SVM이 생성되고, 소스 및 타겟 SMB 공유가 내보내지고, XCP가 설치 및 라이센스가 부여됩니다.</block>
  <block id="281c766457d5499048f9440f61957421" category="list-text">SMB 공유에서 파일 및 디렉토리를 검색합니다.</block>
  <block id="95c490ed8cb5d13c961fc2c50c372940" category="list-text">소스에서 대상 SMB 공유로 파일(ACL 포함 또는 제외)을 복사합니다. 다음 예제에서는 ACL이 포함된 복제본을 보여 줍니다.</block>
  <block id="dc056263ce0a29568cee559ae8ec35dc" category="admonition">데이터 Aggregate가 없으면 storage 'aggr create' 명령을 사용하여 새 Aggregate를 생성합니다.</block>
  <block id="7c34f7c35c71ba790649c5563408e77e" category="list-text">소스와 대상의 파일을 동기화합니다.</block>
  <block id="974c1ef10ec8fef5b3ff19989555d061" category="list-text">파일이 올바르게 복사되었는지 확인합니다.</block>
  <block id="8ae319b52e88ea41e78a01efdaab2143" category="inline-link-macro">다음: 소스 스토리지 상자에서 ONTAP로 ACL을 사용한 CIFS 데이터 마이그레이션</block>
  <block id="b6ea874ca7f1192a99c58fa3ff1199ba" category="paragraph"><block ref="b6ea874ca7f1192a99c58fa3ff1199ba" category="inline-link-macro-rx"></block></block>
  <block id="7ed4381f9a10813d06ebeaf5c947c2c1" category="summary">NetApp XCP 파일 분석 GUI는 백엔드에서 XCP를 사용하여 파일 시스템 검사를 실행하고 모든 NAS(NFS, SMB) 파일 시스템에 대한 그래프 및 보기와 같은 통계를 시각화하는 데 도움이 됩니다.</block>
  <block id="250a5d043009990eb69a399d7c630462" category="doc">파일 분석</block>
  <block id="47461303c8b8cbeb3e7558e2a9a1ca70" category="inline-link-macro">이전: 마이그레이션 워크플로우.</block>
  <block id="685a7e894721315c196897b76f95b8ce" category="paragraph"><block ref="685a7e894721315c196897b76f95b8ce" category="inline-link-macro-rx"></block></block>
  <block id="0f2604fbc18e6e91ba050460e6557361" category="paragraph">NetApp XCP 파일 분석 GUI는 백엔드에서 XCP를 사용하여 파일 시스템 검사를 실행하고 모든 NAS(NFS, SMB) 파일 시스템에 대한 그래프 및 보기와 같은 통계를 시각화하는 데 도움이 됩니다. 1.6에서 시작하는 xCP는 구성 및 systemctl 옵션을 사용하여 간단한 배포 단계를 통해 서비스로 실행할 수 있습니다. xCP 구성 옵션은 Postgres 및 웹 서버를 설치 및 구성하고 자격 증명을 수집하는 방법을 안내합니다. systemctl 옵션은 GUI의 REST API 통신을 위한 서비스로 xCP를 실행합니다.</block>
  <block id="914cb171c700c273306e8265b56f4973" category="paragraph">다음 그림에서는 xCP 파일 분석 흐름을 보여 줍니다.</block>
  <block id="538e51b99e800ab65e133b5d57b2dc7f" category="paragraph"><block ref="538e51b99e800ab65e133b5d57b2dc7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bcdbf2b32a87f7efd13f706d43954d5" category="inline-link">NetApp XCP 1.6은 개방형 파일 분석 및 인프라 개선을 제공합니다</block>
  <block id="46742b2c1e11cf6a3e230ec3da7e6800" category="admonition">xCP 파일 분석의 상위 수준 아키텍처, 통계 보기와 같은 GUI 기반 대시보드 보기, 파일 배포 보기 세부 정보에 대한 자세한 내용은 블로그 게시물 을 참조하십시오<block ref="924a0428223d35821b584a5368c0e3e5" category="inline-link-rx"></block>.</block>
  <block id="21bd6427119f8d9a06a7c5bce95d28ac" category="paragraph">XCP 1.6에는 사용자 지정 그래프를 위한 GUI가 제한되어 있습니다. 필요한 그래프를 생성하려면 CLI를 사용하여 일치하는 필터로 'xCP' 스캔 명령을 실행할 수 있습니다. 다음 예를 참조하십시오.</block>
  <block id="168c81694a3b19988d829a9baeda23fd" category="list-text">xCP 스캔, -match 필터를 사용한 후 1년 이상 수정된 파일 목록을 생성합니다.</block>
  <block id="de615506a73ca5960be54d36ba7fcd5b" category="list-text">1년 이상 된 파일이 사용하는 공간을 찾습니다.</block>
  <block id="d2d1f03d5f19a1229103a85cc9224a61" category="list-text">1년 전에 수정된 데이터의 총 크기 및 그래픽 보기를 찾습니다.</block>
  <block id="d706f3d28ee3e74f9a6829c882169af8" category="paragraph">다음 보고서는 1년 전에 수정된 파일의 사용자 지정 예제 스캔입니다.</block>
  <block id="4d614048a495643d1c641a86e53b78d3" category="paragraph"><block ref="4d614048a495643d1c641a86e53b78d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59a703e67b19adc4bdb1373c25fbca94" category="inline-link-macro">다음: 배포 단계.</block>
  <block id="54e4262e01c029cac8932a431c7e3d3f" category="paragraph"><block ref="54e4262e01c029cac8932a431c7e3d3f" category="inline-link-macro-rx"></block></block>
  <block id="945407c0c602d0c34ead1ebb5427a84b" category="summary">NetApp XCP를 사용하여 GPFS에서 NFS로 데이터를 마이그레이션하여 GPU에서 데이터를 처리할 수 있습니다. AI는 일반적으로 네트워크 파일 시스템의 데이터를 처리합니다.</block>
  <block id="1f797a3a419cdffd442fc4b662974908" category="doc">고성능 컴퓨팅에서 ONTAP NFS로</block>
  <block id="95160fc4cfa09139af600f92561c7ef9" category="inline-link-macro">이전: 데이터 레이크에서 ONTAP NFS로,</block>
  <block id="9d82d327cabd66bd4cccb55cb5ed28ec" category="paragraph"><block ref="9d82d327cabd66bd4cccb55cb5ed28ec" category="inline-link-macro-rx"></block></block>
  <block id="a4a4d9553ba807d3f28f8f25ea56cfec" category="paragraph">이 사용 사례는 현장 조직의 요청을 기반으로 합니다. 일부 NetApp 고객은 고성능 컴퓨팅 환경에서 데이터를 가지고 있으며, 교육 모델을 위한 데이터 분석을 제공하고 연구 조직에서 대량의 디지털 데이터를 통찰하고 이해할 수 있도록 지원합니다. NetApp 현장 엔지니어는 IBM의 GPFS에서 NFS로 데이터를 추출하기 위한 자세한 절차가 필요합니다. NetApp XCP를 사용하여 GPFS에서 NFS로 데이터를 마이그레이션하여 GPU에서 데이터를 처리할 수 있습니다. AI는 일반적으로 네트워크 파일 시스템의 데이터를 처리합니다.</block>
  <block id="409f476aa8c516a92f8d6a42e21db5a0" category="inline-link">XCP를 사용하여 데이터 레이크와 고성능 컴퓨팅에서 ONTAP NFS로 데이터를 이동합니다</block>
  <block id="0ce008ed1a75e69e9f21d1ad29ed23dd" category="paragraph">ONTAP NFS 활용 사례에 대한 고성능 컴퓨팅, 녹화된 데모 및 테스트 결과에 대한 자세한 내용은 를 참조하십시오<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> 블로그:</block>
  <block id="6cef4abedb8153458ee404a47b193489" category="inline-link">TR-4732: 인공 지능에 대한 빅 데이터 분석 데이터</block>
  <block id="fb64727a5df67d0ceff6f0a11b531ab5" category="paragraph">NetApp XCP를 사용하여 MapR-FS 데이터를 ONTAP NFS로 이동하는 방법에 대한 자세한 내용은 부록 A: GPFS에서 NFS로 GPFS를 참조하십시오. 자세한 단계는 에 나와 있습니다<block ref="e760c508aca9c545c45aba81e95e5593" category="inline-link-rx"></block>.</block>
  <block id="1b5c563b4edac6a7e8566fac62f90b34" category="inline-link-macro">다음으로 xCP Data Mover를 사용하여 수백만 개의 작은 파일을 유연한 스토리지로 마이그레이션합니다.</block>
  <block id="0461d449643091f3bbb27cfbb215c6f2" category="paragraph"><block ref="0461d449643091f3bbb27cfbb215c6f2" category="inline-link-macro-rx"></block></block>
  <block id="0706a8a70e2892183b45c55ef1394714" category="summary">이 섹션에서는 NFS용 100만 개의 다른 파일 크기로 XCP 복사 및 XCP 동기화 작업을 수행하는 대략적인 시간을 제공합니다.</block>
  <block id="137e4d3e0bc5586af6fc7ca9441511e1" category="doc">사이징 지침</block>
  <block id="f688414f56f567909ca9a570f161016e" category="inline-link-macro">이전: 배포 단계.</block>
  <block id="fb58e731328976afe8beac53cbe55ee7" category="paragraph"><block ref="fb58e731328976afe8beac53cbe55ee7" category="inline-link-macro-rx"></block></block>
  <block id="5224a4cb1d59edb5630ae27e640409e9" category="section-title">테스트에 따른 예상 시간</block>
  <block id="7e9b65699b01d35aeff9dc16008da7a5" category="paragraph">xCP 복사 및 동기화 작업에 대한 테스트에서는 구축에 사용된 것과 동일한 테스트 베드를 사용했습니다. 8K, 16K, 1MB 파일 3개 세트로 100만 개의 파일을 만들어 실시간으로 변경을 수행했습니다. xCP 동기화 기능은 소스에서 파일 레벨의 타겟으로 차등 증가분 업데이트를 수행했습니다. 증분 업데이트 작업은 기존 파일 및 폴더 이름 바꾸기, 기존 파일에 데이터 추가, 파일 및 폴더 삭제, 추가 하드, 소프트 및 멀티링크 포함 등 네 가지 작업 중 하나 이상을 수행합니다. 테스트를 위해 이름 바꾸기, 추가, 삭제 및 링크 작업에 초점을 맞추었습니다. 즉, 100만 개 파일에서 10% ~ 90%의 변경률로 이름 바꾸기, 추가, 삭제 등의 수정 작업을 수행했습니다.</block>
  <block id="1112334374c9149cc8ad8e80a76f2e56" category="paragraph">다음 그림에서는 xCP 복사 작업의 결과를 보여 줍니다.</block>
  <block id="d6852faef2642951731c8d64e3009dbe" category="paragraph"><block ref="d6852faef2642951731c8d64e3009dbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58fe8c2d511caf443cb23313cb89181b" category="paragraph">다음 그림에서는 xCP Sync 이름 바꾸기 및 링크 작업의 결과를 보여 줍니다.</block>
  <block id="319b9e8dee4108359b7ef17af2fb492d" category="paragraph"><block ref="319b9e8dee4108359b7ef17af2fb492d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2186640ac8cac7be2b0f3940d871bf04" category="paragraph">파일 크기는 이름이 바뀐 소스 파일을 전송하는 xCP 동기화 완료 시간과 일치하지 않으며, 그래프가 선형입니다.</block>
  <block id="de54b82b6e27abb7d6f924e14d40a351" category="paragraph">링크 유형은 소프트 링크, 하드 링크 및 멀티 링크입니다. 소프트 링크는 일반 파일로 간주됩니다. xCP 동기화 작업을 완료하는 데 소요되는 시간은 파일 크기와 관련이 없습니다.</block>
  <block id="db3eb29ec347d79a716c6235063b1955" category="paragraph">다음 그림은 XCP 동기화 추가 및 삭제 작업의 결과를 보여 줍니다.</block>
  <block id="feeff6134484088b1b404089dc5f92d9" category="paragraph"><block ref="feeff6134484088b1b404089dc5f92d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64c7d081568c95905b16364c19e1be1" category="paragraph">추가 및 삭제 작업의 경우 작은 파일 크기에 비해 파일 크기가 크면 시간이 더 오래 걸립니다. 작업을 완료하는 데 걸리는 시간은 추가 및 삭제 변경 비율에 비례합니다.</block>
  <block id="ecc8d4faf16ec3b08a8badd1d71421d3" category="section-title">xCP 1.6.1 과 xCP 1.5 비교</block>
  <block id="f599c9e924e3b854abd0ab58126fed43" category="paragraph">이전 버전에 비해 XCP 1.6.3 및 1.7은 향상된 성능을 제공합니다. 다음 섹션에서는 XCP 1.6.3 및 1.7(8K, 16K 및 1MB 파일)의 동기화 성능 비교를 보여 줍니다.</block>
  <block id="b53776fdc2fd9fc721aaa6f03fd3d6a0" category="paragraph">다음 그림은 XCP 1.6.3의 XCP 동기화 성능과 1.7(100만 개 파일의 8K 크기)의 결과를 보여 줍니다.</block>
  <block id="ded6c17dda87ca50a7ecde2418543075" category="paragraph"><block ref="ded6c17dda87ca50a7ecde2418543075" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09a0804a78587affdd9192afd0f8c80c" category="paragraph">다음 그림은 XCP 1.6.1 및 1.5의 XCP 동기화 성능(1백만 개 파일의 16K 크기)의 결과를 보여 줍니다.</block>
  <block id="b2733f54373c0149b19c3b37afbcb7da" category="paragraph"><block ref="b2733f54373c0149b19c3b37afbcb7da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b201508f1de849d630f98c0001fdc29" category="paragraph">다음 그림은 XCP 1.6.1에 대한 XCP 동기화 성능 결과와 1백만 개 파일의 1MB 크기의 1.5를 비교한 결과를 보여 줍니다.</block>
  <block id="e7770abf0d9a0789407ea0a0e81cc5a6" category="paragraph"><block ref="e7770abf0d9a0789407ea0a0e81cc5a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71c6a3c1c59fc41b371a18011d1d5c9b" category="paragraph">xCP 1.7의 성능은 평균적으로 xCP 1.6.3에서 'xCP 동기화' 차등 증분 업데이트의 XCP 1.6.3과 비슷했습니다. 즉, 100만 개 파일의 1MB 크기로 이름 바꾸기, 추가, 링크 및 삭제 작업을 수행할 수 있었습니다.</block>
  <block id="61b90da0c91ea6cb7c16bfaca41b4920" category="paragraph">이러한 성능 검증을 기반으로 사내 및 클라우드에서 데이터 마이그레이션에 XCP 1.7을 사용하는 것이 좋습니다.</block>
  <block id="dd6275237d7504aabd0c206384365206" category="inline-link-macro">다음: 성능 조정.</block>
  <block id="cb619c90f7b537d24a1473acda746a47" category="paragraph"><block ref="cb619c90f7b537d24a1473acda746a47" category="inline-link-macro-rx"></block></block>
  <block id="69f55c7d7266874ad1ed57caf459c979" category="summary">이 사용 사례는 우리가 수행한 가장 큰 재무 고객 개념 증명(CPOC)을 기반으로 합니다. 역사적으로 우리는 NetApp NIPAM(In-Place 분석 모듈)을 사용하여 분석 데이터를 NetApp ONTAP AI로 이동시켰습니다. 하지만 최근 NetApp XCP의 향상된 기능과 향상된 성능, 고유한 NetApp Data Mover 솔루션 접근 방식 덕분에 NetApp XCP를 사용하여 데이터 마이그레이션을 다시 수행할 수 있게 되었습니다.</block>
  <block id="5084e1c3bd53b6115df08f4c40aadbe6" category="doc">데이터 레이크에서 ONTAP NFS로</block>
  <block id="ae8dcf06c5337995ca840fbd543188fc" category="inline-link-macro">이전: 고객 시나리오.</block>
  <block id="82f418da831bb7ca7897e30f8bc5525a" category="paragraph"><block ref="82f418da831bb7ca7897e30f8bc5525a" category="inline-link-macro-rx"></block></block>
  <block id="b1a11a01b3bdf3150e0240a1f037cdf5" category="section-title">고객의 당면 과제 및 요구사항</block>
  <block id="9ed16d5ac47c336caaf9ca2b75930d78" category="paragraph">주목해야 할 고객 과제 및 요구사항은 다음과 같습니다.</block>
  <block id="b6976e1a47e217f1a7c746e8f57e327c" category="list-text">정형, 비정형, 준정형 데이터, 로그, 데이터, 데이터 등 다양한 데이터 유형을 그리고 데이터 레이크에 있는 머신 간 데이터를 활용하여 AI 시스템을 사용하면 예측 작업을 위해 이러한 모든 유형의 데이터를 처리할 수 있습니다. 데이터가 데이터 레이크 네이티브 파일 시스템에 있으면 프로세스가 어렵습니다.</block>
  <block id="d85cb5080a9e99841f0ff6c36abdadad" category="list-text">고객의 AI 아키텍처는 HDFS(Hadoop Distributed File System) 및 HCFS(Hadoop Compatible File System)의 데이터에 액세스할 수 없으므로 AI 작업에 데이터를 사용할 수 없습니다. AI에는 NFS와 같이 이해하기 쉬운 파일 시스템 형식의 데이터가 필요합니다.</block>
  <block id="982b6c87ace8f5b95c0523bd0557f4e2" category="list-text">대량의 데이터와 높은 처리량으로 인해 데이터 레이크에서 데이터를 이동하려면 일부 특별한 프로세스가 필요하며, 데이터를 AI 시스템으로 이동하는 데 비용 효율적인 방법이 필요합니다.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="section-title">Data Mover 솔루션</block>
  <block id="b0a9a6f2387f2a23e13931f68fc509c1" category="paragraph">이 솔루션에서 MapR 파일 시스템(MapR-FS)은 MapR 클러스터의 로컬 디스크에서 생성됩니다. MapR NFS 게이트웨이는 가상 IP가 있는 각 데이터 노드에서 구성됩니다. 파일 서버 서비스는 MapR-FS 데이터를 저장하고 관리합니다. NFS 게이트웨이는 가상 IP를 통해 NFS 클라이언트에서 Map-FS 데이터에 액세스할 수 있도록 합니다. MapR 데이터 노드당 XCP 인스턴스가 실행되고 지도 NFS 게이트웨이에서 NetApp ONTAP NFS로 데이터를 전송합니다. 각 xCP 인스턴스는 특정 소스 폴더 세트를 대상 위치로 전송합니다.</block>
  <block id="01e1c2900284f91d77ea71ffd32c6d18" category="paragraph">다음 그림은 XCP를 사용하는 MapR 클러스터용 NetApp Data Mover 솔루션을 보여 줍니다.</block>
  <block id="a7dcdfa2099e01480afb3c060c679f10" category="paragraph"><block ref="a7dcdfa2099e01480afb3c060c679f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4084b5f9c9bab8db38eb6e04a3b3a4cc" category="paragraph">고객 사용 사례, 녹화된 데모 및 테스트 결과에 대한 자세한 내용은 를 참조하십시오<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> 블로그:</block>
  <block id="520ef13ea64298a652262e37756b6bd4" category="paragraph">NetApp XCP를 사용하여 MapR-FS 데이터를 ONTAP NFS로 이동하는 방법에 대한 자세한 내용은 의 부록 B를 참조하십시오<block ref="c952a09d2ff4403056a594c41db26c8d" category="inline-link-rx"></block>.</block>
  <block id="b4dd66db226c58dbbcc8455a7576d491" category="inline-link-macro">다음: ONTAP NFS에 대한 고성능 컴퓨팅.</block>
  <block id="9ebf542ce4a3a8a997eb85e5b6e086ed" category="paragraph"><block ref="9ebf542ce4a3a8a997eb85e5b6e086ed" category="inline-link-macro-rx"></block></block>
  <block id="7776aec966d5a0c71bd4e8230f9470b8" category="summary">이 사용 사례는 TV 네트워크 고객을 기반으로 합니다. 고객은 Oracle RMAN(Recovery Manager) 백업 파일을 클라우드로 마이그레이션하고 심장박동기 소프트웨어가 설치된 Azure NetApp Files를 사용하여 Oracle EBS(E-Business Suite) 애플리케이션을 실행하려고 했습니다. 또한 고객은 데이터베이스 백업 파일을 주문형 클라우드 스토리지로 마이그레이션하고 대용량 파일(각각 25GB~50GB 범위)을 Azure로 전송하길 원했습니다.</block>
  <block id="8108bac490ceb375198c578e8a439026" category="doc">xCP Data Mover를 사용하여 대용량 파일을 마이그레이션합니다</block>
  <block id="adec666d077f4afe1b4f2b8720ed1247" category="inline-link-macro">이전: XCP Data Mover를 사용하여 수백만 개의 작은 파일을 유연한 스토리지로 마이그레이션합니다.</block>
  <block id="d6be3aed77745a993a24266eaf05084d" category="paragraph"><block ref="d6be3aed77745a993a24266eaf05084d" category="inline-link-macro-rx"></block></block>
  <block id="06470d7a09a56d555bad98bdf38a6cad" category="paragraph">다음 그림에서는 대용량 파일의 경우 사내에서 Azure NetApp Files으로 데이터를 마이그레이션하는 방법을 보여 줍니다.</block>
  <block id="1b95efe3eae02043da6528de3cf9caf8" category="inline-link-macro">다음: 파일을 복제합니다.</block>
  <block id="76fdb34470826293aaf52b30bf98fce0" category="paragraph"><block ref="76fdb34470826293aaf52b30bf98fce0" category="inline-link-macro-rx"></block></block>
  <block id="24992328317a5b7b3c00507eb27776df" category="paragraph"><block ref="24992328317a5b7b3c00507eb27776df" category="inline-link-macro-rx"></block></block>
  <block id="d4f4c40bd169a262676284f5da7a191a" category="cell">2020년 10월</block>
  <block id="035fe4f74f99e66d6525774bf40236f9" category="summary">이 섹션에서는 NetApp XCP를 사용하여 데이터를 마이그레이션하기 위한 모범 사례, 지침 및 권장 사항을 다룹니다.</block>
  <block id="52f7ac44cac2d8d1a3f005648d7521e3" category="doc">모범 사례 지침 및 권장사항</block>
  <block id="b5a13e4f32bf69c6814808ff6a11eb9b" category="inline-link-macro">이전: 소스 스토리지 상자에서 ONTAP로 ACL을 사용한 CIFS 데이터 마이그레이션</block>
  <block id="a930ea4d6e07241178b9fe2f3c054fd2" category="paragraph"><block ref="a930ea4d6e07241178b9fe2f3c054fd2" category="inline-link-macro-rx"></block></block>
  <block id="1cce79308861dd86d5e56af13afefaf2" category="list-text">IMT에서 지원하는 XCP 클라이언트 운영 체제를 사용합니다. IMT 지원 클라이언트는 NetApp의 검증을 받았습니다.</block>
  <block id="ec653488c4b3b9bb00702a4fb937f5b4" category="list-text">Linux 운영 체제에서 루트 사용자로 xCP를 실행하여 마이그레이션을 수행합니다. sudo 사용자로 xCP 명령을 실행할 수 있지만 xCP에서는 지원되지 않습니다.</block>
  <block id="8c8f6415908fe0a235f0850d80a398a4" category="list-text">클라이언트당 한 개의 xCP 인스턴스만 실행합니다. 기술적으로 동일한 호스트에서 여러 XCP를 다른 위치에서 실행할 수 있지만 이는 지원되지 않습니다. 실제로 많은 인스턴스를 실행하면 오류가 발생할 수 있습니다.</block>
  <block id="cac486281cae3e805e89a64673c47eb3" category="list-text">현재 XCP 버전에서는 라이브 소스가 지원되지 않습니다. 소스 NetApp 볼륨이 활성 상태이고 애플리케이션 및 사용자가 지속적으로 변경하는 경우 소스 볼륨의 스냅샷을 생성하여 마이그레이션을 수행해야 합니다.</block>
  <block id="c1f9797ffa66b762cf07348c6bc4a005" category="list-text">모든 증분 동기화에 대해 다른 이름을 사용하여 새 스냅샷을 생성하는 것이 가장 좋습니다. 이렇게 하면 장애 발생 시 스냅샷 이름을 기반으로 증분 마이그레이션 경로를 쉽게 생성할 수 있습니다.</block>
  <block id="1309895bb5c78406c77a6cc2800160eb" category="list-text">스냅샷 기반 마이그레이션을 수행하는 경우에는 컷오버가 완료될 때까지 스냅샷 기반 마이그레이션을 계속하는 것이 좋습니다.</block>
  <block id="cc9954d8dc3e80c40af9d0a7ca3de005" category="list-text">천만 개 이상의 파일이 있고 50% 이상의 증분 데이터 변경이 있는 경우 설치 및 관리 가이드에서 권장하는 최소 구성보다 더 많은 코어 수와 메모리를 사용하는 것이 좋습니다.</block>
  <block id="f6cb936ed9c08627956daed52c6c3323" category="inline-link-macro">다음: 문제 해결.</block>
  <block id="58c815a6f6adf3657aa40f96cb5f2d08" category="paragraph"><block ref="58c815a6f6adf3657aa40f96cb5f2d08" category="inline-link-macro-rx"></block></block>
  <block id="a01ed8ff3f6e9e3ac0c0068a083281f2" category="summary">이 섹션에서는 NetApp XCP를 사용한 데이터 마이그레이션에 대한 문제 해결 지침을 제공합니다.</block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">문제 해결</block>
  <block id="ae638a1049211e9956348a48a85bd359" category="inline-link-macro">이전: 모범 사례 지침 및 권장 사항</block>
  <block id="e19cdddb31b62a88048cfee77eb96e9d" category="paragraph"><block ref="e19cdddb31b62a88048cfee77eb96e9d" category="inline-link-macro-rx"></block></block>
  <block id="95109c432d89e67182659615993ba75d" category="section-title">오류 1: xCP가 NFS3 오류와 함께 실패했습니다. 70: xcp.log 파일의 오래된 파일 오류입니다</block>
  <block id="99b1b0e3547443c29793187326a64dbc" category="paragraph">* 이유 및 지침. *</block>
  <block id="0774d3e8b775fcc34e680b302e85f3c1" category="paragraph">소스 폴더를 마운트하고 폴더가 있는지 확인합니다. 파일이 없거나 제거된 경우 '파일 핸들 표시' 오류가 발생하며, 이 경우 오류를 무시할 수 있습니다.</block>
  <block id="8fefb715a66a069c9e9318a58ecfdaee" category="section-title">오류 2: NetApp NFS 대상 볼륨에 공간이 있지만 xCP NFS 오류 28: 장치에 공간이 남아 있지 않습니다</block>
  <block id="bba52daa861e8093e201c3939f43057f" category="list-text">df 명령을 실행하거나 스토리지를 확인하여 NFS 대상 볼륨의 공간을 확인합니다.</block>
  <block id="20183145becc54cc822a80107f92f13d" category="list-text">스토리지 컨트롤러의 inode를 확인합니다.</block>
  <block id="fe3a96130e3ec3092026a84e4dd12e50" category="list-text">inode를 사용하는 경우 다음 명령을 실행하여 inode 수를 늘립니다.</block>
  <block id="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="paragraph"><block ref="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="inline-link-macro-rx"></block></block>
  <block id="1357196e1dc18c4ad43fe26a6c1b30ad" category="inline-link-macro">이전: 성능 조정.</block>
  <block id="33672b776ede62bd1269689ea61e45aa" category="paragraph"><block ref="33672b776ede62bd1269689ea61e45aa" category="inline-link-macro-rx"></block></block>
  <block id="1ebf7a1cb4f3826913a58c19018c694e" category="paragraph">이 섹션에서는 고객 시나리오 및 아키텍처에 대해 설명합니다.</block>
  <block id="b58464d62b5399c457b8a1fcf6bbcd27" category="inline-link-macro">다음: ONTAP NFS로 데이터 레이크 전환</block>
  <block id="a24139c6a89df9b0694c3ea695639ace" category="paragraph"><block ref="a24139c6a89df9b0694c3ea695639ace" category="inline-link-macro-rx"></block></block>
  <block id="c4e9391c8d60f1f326246cd6b6705492" category="summary">NetApp은 단일 볼륨 또는 여러 볼륨에서 중복 파일을 찾기 위한 요청을 받았습니다. NetApp은 다음과 같은 솔루션을 제공했습니다.</block>
  <block id="2e4e5fbe1f8f460b943ac3ed031c9dcf" category="doc">중복 파일</block>
  <block id="f89d6874c6cf2c5de0dae9564728c7cf" category="inline-link-macro">이전: XCP Data Mover를 사용하여 대용량 파일을 마이그레이션합니다.</block>
  <block id="6c8f161effcb72b9425f626e8733146b" category="paragraph"><block ref="6c8f161effcb72b9425f626e8733146b" category="inline-link-macro-rx"></block></block>
  <block id="dc4b36d55f5f1f0af63ed899a010c8f1" category="paragraph">단일 볼륨의 경우 다음 명령을 실행합니다.</block>
  <block id="2d2f31777cf3433071b9bcd33f39279a" category="paragraph">여러 볼륨의 경우 다음 명령을 실행합니다.</block>
  <block id="fdefb3eaaab41fef36db24700d399ef2" category="inline-link-macro">다음: 특정 날짜 기반 스캔 및 데이터 복사.</block>
  <block id="769f411db097d478d8d10a821946e501" category="paragraph"><block ref="769f411db097d478d8d10a821946e501" category="inline-link-macro-rx"></block></block>
  <block id="485f9678c52b78d051ddff564d873eb9" category="summary">이 섹션의 명령은 CSV 형식으로 데이터를 덤프합니다. 크기 열의 합계를 합산하여 데이터의 총 크기를 구할 수 있습니다.</block>
  <block id="92f6d6878e37105d20e75151b95d4e6a" category="doc">SMB/CIFS 공유에서 CSV 파일 생성</block>
  <block id="bab825782f37e3f0cd908b20bc8aa74c" category="inline-link-macro">이전: 특정 날짜 기반 스캔 및 데이터 복사.</block>
  <block id="ad80673543d1d2744f55966060c4579b" category="paragraph"><block ref="ad80673543d1d2744f55966060c4579b" category="inline-link-macro-rx"></block></block>
  <block id="d122031c67144a65ca4721f8324ae0b3" category="paragraph">다음 명령을 실행하면 데이터가 CSV 형식으로 덤프됩니다. 크기 열의 합계를 합산하여 데이터의 총 크기를 구할 수 있습니다.</block>
  <block id="1bed902c0754e4abc7598b7f1a0450e0" category="paragraph">출력은 다음 예와 비슷해야 합니다.</block>
  <block id="f7c322db5a6c805aed8a38858c7ba770" category="paragraph">하위 디렉토리 세 개를 심층 검색하고 정렬 순서를 제공하려면 xCP -du 명령을 실행하여 각 디렉토리 수준에서 하위 디렉토리 세 개의 깊이까지 크기를 덤프합니다.</block>
  <block id="7c12bd6fa64456eb3a61460a4bbb98e6" category="paragraph">정렬하려면 정보를 CSV 파일로 덤프하고 정보를 정렬합니다.</block>
  <block id="d0ecdc77c2c944d380e9fef0e01eb119" category="paragraph">이것은 '-FMT' 명령을 사용하는 사용자 정의 보고서입니다. 모든 디렉토리를 검색하여 디렉토리 이름, 경로 및 디렉토리 크기를 CSV 파일로 덤프합니다. 스프레드시트 응용 프로그램에서 크기 열을 정렬할 수 있습니다.</block>
  <block id="c2e9a8d6d376247b10a1ab4624bd2610" category="inline-link-macro">다음: 7-Mode에서 ONTAP로 데이터 마이그레이션</block>
  <block id="7155e60f207d105fa4db5d15efdce133" category="paragraph"><block ref="7155e60f207d105fa4db5d15efdce133" category="inline-link-macro-rx"></block></block>
  <block id="2246a929033f1d77a86efa97dda42849" category="inline-link-macro">이전: 문제 해결.</block>
  <block id="49c4600bab96ae4bda03f252b43985b4" category="paragraph"><block ref="49c4600bab96ae4bda03f252b43985b4" category="inline-link-macro-rx"></block></block>
  <block id="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link"><block ref="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link-rx"></block></block>
  <block id="eba010943793fb5b647ad292a452b3ff" category="list-text">NetApp XCP 블로그<block ref="2639c38af267ba997fc1d85740cfc9a6" category="inline-link-rx"></block></block>
  <block id="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link"><block ref="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link-rx"></block></block>
  <block id="fb8d9f206204f9562c2a67c6b37a7d1b" category="list-text">NetApp XCP 사용자 가이드<block ref="05f41a166d52148335e3a0df2eafec23" category="inline-link-rx"></block></block>
  <block id="e2c2bd378a3ae3740034d637754af7e2" category="inline-link"><block ref="e2c2bd378a3ae3740034d637754af7e2" category="inline-link-rx"></block></block>
  <block id="79b44e54a5eac82beac2de86249cd862" category="list-text">bigdata Analytics 데이터를 인공 지능으로 분석 – AI용 Data Mover 솔루션<block ref="79ced727b5c9638c0385a25671803fba" category="inline-link-rx"></block></block>
  <block id="9ebf058ce7a44ad4517e7033db8a90a7" category="paragraph"><block ref="9ebf058ce7a44ad4517e7033db8a90a7" category="inline-link-macro-rx"></block></block>
  <block id="3d5c39f585b0e679dbfe0855d556f0af" category="summary">NetApp XCP는 멀티스레드와 맞춤형 기능을 사용하여 데이터를 전송합니다. 데이터 이동 또는 마이그레이션, 파일 시스템 분석, 빠른 디렉토리 트리 삭제와 같은 세 가지 주요 활용 사례에 맞게 설계되었습니다.</block>
  <block id="211c181ce8e8cb0472af3095c66dc5eb" category="paragraph"><block ref="211c181ce8e8cb0472af3095c66dc5eb" category="inline-link-macro-rx"></block></block>
  <block id="6416bf9c9c9445fbe2e15f69fa8371d2" category="paragraph">NetApp XCP는 멀티스레드와 맞춤형 기능을 사용하여 데이터를 전송합니다. 데이터 이동 또는 마이그레이션, 파일 시스템 분석, 빠른 디렉토리 트리 삭제의 세 가지 주요 활용 사례에 맞게 설계되었습니다.</block>
  <block id="7817bd783e8db0557909483f54288eae" category="section-title">데이터 이동 또는 마이그레이션</block>
  <block id="a7786f240f16aadfd675c46be438f64e" category="paragraph">NetApp XCP는 모든 NAS에서 NetApp NAS로 데이터를 전송합니다. 이 프로세스는 스캔, 복사, 동기화 및 검증의 네 가지 주요 작업으로 구성됩니다. 데이터 모니터링 및 전송에 도움이 되는 몇 가지 추가 기능이 있습니다.</block>
  <block id="1c026a57d7676d346dd0d44a2f595c1d" category="list-text">* 스캔. * NAS 및 MapR/HDFS 데이터의 상위 레벨 레이아웃을 제공합니다.</block>
  <block id="59e4194e1b171063beeb99722a68e7af" category="list-text">* Copy. * 기준 데이터 전송을 수행합니다.</block>
  <block id="a75ddee1308f2f19e478595122434544" category="list-text">* Sync. * 증분 데이터 전송을 수행합니다.</block>
  <block id="ae4ab572ec7de44b385c01df54f00d17" category="list-text">* verify. * 대상에 대한 철저한 검증을 수행합니다.</block>
  <block id="8ddbaa98ade9dcd56d4960b7abd22525" category="list-text">* Show (선택 사항). * NAS 공유를 검색합니다.</block>
  <block id="4f4544fb0f8ed8f32e27a8b8651a46e6" category="paragraph">다음 그림에서는 xCP 데이터 마이그레이션 및 복제 작업을 보여 줍니다.</block>
  <block id="6d97d3e510fc0fba449ece8ddd3f3d10" category="paragraph"><block ref="6d97d3e510fc0fba449ece8ddd3f3d10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="657bad21acd4ceb926477ced53a4ec55" category="section-title">파일 시스템 분석</block>
  <block id="65424b0dc0515cfa3b67e71712012db0" category="paragraph">NetApp XCP는 기본적으로 비정형 데이터를 식별, 조사 및 분석하여 통찰력을 향상합니다. 이 인사이트를 활용하여 더 나은 계획을 세우고, 높은 가치의 디지털 자산을 운영하며, 보고 및 평가를 통해 데이터 거버넌스를 구현하려는 엔터프라이즈 고객에게 중요한 요구사항입니다.</block>
  <block id="03c5a03e8b03794f5fa193e72245496c" category="paragraph">중요한 데이터를 처리하는 고객은 NetApp XCP를 사용하여 다음과 같은 일반적인 운영 질문에 답변할 수 있습니다.</block>
  <block id="6ad28c778baa08cff585599e160c12c8" category="list-text">내 데이터는 어디에 있습니까?</block>
  <block id="5eccfafcfad0fb3dcd5f4f1036fed9f9" category="list-text">보유한 데이터의 양과 파일 형식은 무엇입니까?</block>
  <block id="b1c54971a6211d7b7e3d074bff16b4c9" category="list-text">어떤 데이터가 활발히 사용되고 있으며 얼마나 휴면 상태입니까?</block>
  <block id="6b2c974b2ada5fba492b8dcda598b1f9" category="paragraph">다음 그림에서는 GUI에서 제공되는 NetApp XCP 파일 분석 통신을 보여 줍니다.</block>
  <block id="81ff19b428c80049b09f8e1e6e55cfde" category="paragraph"><block ref="81ff19b428c80049b09f8e1e6e55cfde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a6c498fb90ee345d997f888fce3b18" category="section-title">삭제</block>
  <block id="4125c56415a1c3b98b49ee7f8c2ebfc3" category="paragraph">스토리지 팀과 EDA(Electronic Design Automation) 워크로드에서는 오래된 데이터나 스토리지 공간 복구를 위해 청소해야 하는 테스트 데이터 등 큰 디렉토리를 정리하는 데 매우 어려울 수 있습니다. xCP는 전체 디렉토리 트리를 삭제할 수 있는 빠른 삭제 기능을 제공합니다. NetApp XCP 삭제 기능은 지정된 NAS 경로에서 파일과 폴더를 제거합니다. 일치 필터를 사용하여 특정 파일 및 폴더 집합을 삭제할 수 있습니다. 많은 수의 파일 및 폴더의 경우 삭제를 확인하는 데 필요 없는 강제 옵션을 사용할 수 있습니다.</block>
  <block id="ecfd5328aaeaeb8ab72037598049a32c" category="section-title">라이브 소스 마이그레이션 지원</block>
  <block id="2d3aa3941d30870beb3abde613ce14b1" category="paragraph">xCP 1.7에 포함된 라이브 소스 마이그레이션 지원을 통해 사용 중인 데이터 소스(읽기 및 쓰기 작업)에서 마이그레이션할 수 있습니다. xCP는 복사 및 동기화 실행 등 마이그레이션 작업 중에 사용 중인 파일을 삭제하며, 건너뛴 파일 정보는 xCP 로그에 캡처됩니다.</block>
  <block id="286a0f56c729672b0709605c558d0008" category="paragraph">이 기능은 소스의 변경 사항을 지원하지만 대상의 변경 사항은 지원하지 않습니다. 마이그레이션 중에는 대상이 활성 상태가 아니어야 합니다. 라이브 소스 마이그레이션 지원은 NFS 마이그레이션에만 사용할 수 있습니다.</block>
  <block id="2c346a482fcf83bd03d1d51f65d58b8d" category="admonition">라이브 소스 마이그레이션에는 특별한 설정이 필요하지 않습니다.</block>
  <block id="ba41152bc4991a294ab26fbe691d52e3" category="section-title">xCP 사전 요구 사항</block>
  <block id="010e3e2a3d44100784dac368cdb601c0" category="paragraph">NetApp XCP를 구축하려면 다음과 같은 사전 요구사항이 충족되어야 합니다.</block>
  <block id="b76760dcfae800f7180ec4e8c57a8e2f" category="list-text">다음 명령을 실행하여 NFS 서버가 사용하는 NFS 포트를 확인합니다.</block>
  <block id="a9a9fca38da059af5a55e2fc58ef3851" category="list-text">사내 또는 클라우드 인스턴스(예: Azure, AWS 또는 Google 가상 머신[VM] 인스턴스)와 같은 XCP 작업을 실행하는 위치에 액세스하려면 NFS 포트의 방화벽 포트를 엽니다.</block>
  <block id="b22a57ce186f512ec584f5aac1d3de34" category="list-text">텔넷 명령 "&lt;온프레미스 NFS 데이터 LIF IP 또는 NAS IP&gt;2049"를 사용하여 XCP 서버에서 NFS 포트에 액세스할 수 있는지 확인합니다. 기본 포트는 2049입니다. 환경에 다른 포트가 있는 경우 해당 IP를 사용하십시오.</block>
  <block id="e54a7adb3b7e28ed3d693d972fc48fd0" category="list-text">NFS의 경우 'howmount -e &lt;nas ip&gt;' 명령을 사용하여 xCP 서버에서 공유에 액세스할 수 있는지 확인하십시오.</block>
  <block id="da7f6a983e12f3b14b965ea651990ca9" category="list-text">대상 볼륨의 inode 수를 소스 파일의 파일 수(파일 수)보다 많이 늘립니다.</block>
  <block id="71858e85f290ec0f6955841bab9f3aef" category="inline-link">NetApp XCP 라이센스 포털</block>
  <block id="14324adbfb79ad4b6832f6a02a1275db" category="list-text">에서 xCP 라이센스를 다운로드합니다<block ref="eab886d42d2df7a710066e6d9bf6f5f5" category="inline-link-rx"></block>.</block>
  <block id="7481213bd7173438d06de418474e428b" category="list-text">mysupport.netapp.com 에 NetApp 계정이 있어야 하며, 그렇지 않은 경우 무료로 등록할 수 있습니다.</block>
  <block id="d25e9f08475ddf6a2701e7cfbd67ff06" category="list-text">라이센스를 다운로드하여 준비하십시오.</block>
  <block id="b9611b870758eac97bd0c3bcb3fc8026" category="list-text">XCP 카탈로그용 클라우드에서 각 Azure NetApp 볼륨 또는 Cloud Volume Service(프리미엄 서비스 수준)에 대해 온프레미스에 NFS 공유를 하나 만드십시오.</block>
  <block id="3d19c697861d11cce0f1d78d41cfea64" category="list-text">NAS 볼륨을 생성하고 데이터 대상에 대한 공유를 구성합니다.</block>
  <block id="4f2a304b9680876edc7cb61b5c4c7134" category="list-text">여러 xCP 인스턴스의 경우 여러 소스 폴더 또는 파일에서 대상으로 데이터를 전송하려면 하나 이상의 서버 또는 클라우드 인스턴스가 있어야 합니다.</block>
  <block id="adc4e34febc2f5919cfa03870630c2fc" category="list-text">maxdir 크기(기본값은 308MB)는 단일 폴더에서 최대 파일 수(약 100만)를 정의합니다. 파일 수를 늘리려면 maxdir 크기 값을 늘리십시오. 값을 늘리면 추가 CPU 사이클에 영향을 줍니다.</block>
  <block id="a1552408599f6e2171495d55ae375802" category="list-text">클라우드에서 ExpressRoute(Azure), Direct Connect(AWS), Cloud Interconnect(GCP) 등을 사용하는 것이 좋습니다.</block>
  <block id="fb41b0ab70237465636fc4267d1c00dd" category="inline-link-macro">다음: 마이그레이션 워크플로우.</block>
  <block id="7480aca6b5f94dc27cc94b015284d5e9" category="paragraph"><block ref="7480aca6b5f94dc27cc94b015284d5e9" category="inline-link-macro-rx"></block></block>
  <block id="7e0710b4cb48030b7a4c065128b88194" category="summary">이 섹션에서는 소스에서 타겟 ONTAP 시스템으로 보안 정보가 포함된 CIFS 데이터를 마이그레이션하는 단계별 절차에 대해 설명합니다.</block>
  <block id="82f0875c37eacadc40a7a7fb2a6b6313" category="doc">소스 스토리지 상자에서 ONTAP로 ACL을 사용한 CIFS 데이터 마이그레이션</block>
  <block id="0f17f55a868185c28a66d0817a780f53" category="inline-link-macro">이전: 7-Mode에서 ONTAP로 데이터 마이그레이션</block>
  <block id="99b2c0d3f328317650f8748e47c7bedb" category="paragraph"><block ref="99b2c0d3f328317650f8748e47c7bedb" category="inline-link-macro-rx"></block></block>
  <block id="c55bb6c3381ca2d8a4016e387cc62883" category="list-text">데이터 LIF를 생성하여 SMB 클라이언트 요청을 처리합니다.</block>
  <block id="5368b7f480b92b4a2a9b475e6e9cf953" category="list-text">SVM 네임스페이스에서 타겟 데이터 볼륨을 마운트합니다.</block>
  <block id="18f8848c17d02fd34b293885d5d3a215" category="list-text">타겟 SVM에서 CIFS 서비스를 시작합니다.</block>
  <block id="cf1269d629dc2110f2ae65edf8662b79" category="list-text">기본 엑스포트 정책이 타겟 SVM에 적용되는지 확인합니다.</block>
  <block id="74e1ca9e0b551a7349207f3d546b9f51" category="list-text">CIFS 클라이언트에 대한 액세스를 허용하도록 엑스포트 정책 규칙을 수정합니다.</block>
  <block id="3c19a2ac394a25f9ace05db18ad86c8b" category="paragraph">정책 규칙이 수정되었는지 확인합니다.</block>
  <block id="876afc73f4771f46cfc9dba7fb687744" category="list-text">xCP가 설치된 Windows 클라이언트 시스템에 연결합니다. xCP 설치 경로로 이동합니다.</block>
  <block id="e73a44af938fa16a4816d3639d2f3b69" category="list-text">xCP Windows 클라이언트 호스트 시스템에서 'xCP show' 명령을 실행하여 소스 노드 SMB 내보내기를 쿼리합니다.</block>
  <block id="7132ef955ec5e0151ccd0790da2551d7" category="list-text">복사에 대한 도움말 명령을 실행합니다.</block>
  <block id="268b71a144890a49d97f8ca062fd48f9" category="list-text">대상 ONTAP 시스템에서 fallback-user와 fallback-group 인수 경로 값으로 제공해야 하는 로컬 사용자 및 로컬 그룹 이름 목록을 가져옵니다.</block>
  <block id="ac9ad1198db0fb6f730a1f3aa97c35ab" category="list-text">소스에서 ACL이 포함된 CIFS 데이터를 타겟으로 마이그레이션하려면 '-acl' 및 '-fallback-user/group' 옵션을 사용하여 'xCP copy' 명령을 실행합니다.</block>
  <block id="a53e836d6264ad1778a4e1a7ae34f58c" category="paragraph">'fallback-user/group' 옵션의 경우 Active Directory 또는 로컬 사용자/그룹에서 대상 시스템으로 찾을 수 있는 사용자 또는 그룹을 지정합니다.</block>
  <block id="9aa080e55cad2c9968cc50de60a3f88e" category="list-text">xCP copy로 인해 'fallback security principal을 가져오지 못했습니다'라는 오류 메시지가 나타나면 hosts 파일('C:\Windows\System32\drivers\etc\hosts')에 대상 상자를 추가합니다.</block>
  <block id="b7ceaa0e08e9de5bf76572a50529f752" category="paragraph">NetApp 스토리지 대상 상자 항목에 대해 다음 형식을 사용합니다.</block>
  <block id="569ccf25ad533b79cf2f639f0326d943" category="list-text">호스트 파일에 대상 상자 항목을 추가한 후에도 "오류 FAILED FAILED FAILED FAILED FALLBACK SURITY"라는 오류 메시지가 계속 표시되면 대상 시스템에 사용자/그룹이 존재하지 않는 것입니다.</block>
  <block id="4a909d1b3a171fdcddc8da070e839ecc" category="list-text">루트 폴더를 사용하거나 사용하지 않고 ACL을 사용하여 CIFS 데이터를 마이그레이션하려면 "xCP 복제본"을 사용합니다.</block>
  <block id="a4ebb620bc1fbff4f93249967cd47f4b" category="paragraph">루트 폴더가 없으면 다음 명령을 실행합니다.</block>
  <block id="f6c1a65a9150853333bf43b4a6dc9e5b" category="paragraph">루트 폴더에서 다음 명령을 실행합니다.</block>
  <block id="154ef40d43f003733406aef6be0ada62" category="inline-link-macro">다음: 모범 사례 지침 및 권장 사항</block>
  <block id="7fd167e59284838d9e36c5c99e4d2943" category="paragraph"><block ref="7fd167e59284838d9e36c5c99e4d2943" category="inline-link-macro-rx"></block></block>
  <block id="d82dd9b3245382b365106db0568113e8" category="summary">NetApp 솔루션 자동화를 통해 고객은 수많은 일반 인프라 및 애플리케이션 작업의 구축, 구성, 실행을 자동화할 수 있습니다.</block>
  <block id="a123daaac5749e4d0965aca160f0adfd" category="doc">NetApp 솔루션 자동화</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="section-title">절차를 참조하십시오</block>
  <block id="3a4a7ee7a634fc42372d6601867f823b" category="paragraph">CLI를 통해 Ansible 플레이북을 사용하여 Mellanox 스위치를 구성하려면 다음 절차를 따르십시오.</block>
  <block id="79a78778ec74f6df31c269176e191684" category="list-text">Mellanox ONYX Ansible 컬렉션을 다운로드하십시오</block>
  <block id="0683792c4baa09a201f802cc69019f56" category="list-text">Mellanox 스위치를 구성하는 데 필요한 Ansible 콘텐츠를 다운로드하십시오</block>
  <block id="f66ab36e28c2c6596efcfb05cd259e98" category="list-text">디렉토리를 필요한 솔루션으로 변경합니다</block>
  <block id="90836ed3d621851397e3c2c972da4408" category="list-text">제공된 권장 사항/제안 사항을 바탕으로 아래 변수를 입력하십시오. 모든 변수가 요구 사항에 따라 채워지면 맨 위에 있는 '복사' 버튼을 클릭하여 콘텐츠를 복사합니다.</block>
  <block id="2215f9dffda399b7920ce8d09198668a" category="list-text">현재 디렉토리(플레이북과 동일한 디렉토리)에 새 변수 파일(yml 파일)을 생성하고 복사한 변수를 파일에 붙여 넣고 저장합니다.</block>
  <block id="8157b13d4a5832aba2c45730d1b1db60" category="list-text">아래의 Mellanox 스위치의 IP 주소/호스트 이름을 입력하고 콘텐츠를 복사합니다. HOSTS 파일을 열고 있는 모든 정보를 지우고 복사한 내용을 붙여 넣습니다.</block>
  <block id="e245e21fae9b0617e20295e709d2eed3" category="list-text">가변 파일과 Mellanox 스위치 사용자 이름을 전달하여 플레이북을 실행합니다. 메시지가 나타나면 Mellanox 스위치의 암호를 입력합니다.</block>
  <block id="5287ad47faa9ddb98ee2c477d7df683c" category="admonition">위의 명령을 사용하여 플레이북을 실행하기 전에 Mellanox 스위치에 로그인하기 위한 적절한 사용자 이름으로 Mellanox_switch_username 을 대체합니다.</block>
  <block id="d9a06854085afcd104157eb7f0b66c3a" category="summary">NetApp 솔루션 자동화는 구성 및 관리를 위해 RedHat Ansible을 활용합니다.</block>
  <block id="d1029167179320d8b6d70b11c3d01bd3" category="list-text">Ansible 제어 노드 요구사항:</block>
  <block id="9ced761647f5d80fe615526ffff63937" category="list-text">다음 패키지가 설치된 Ubuntu/Debian 시스템:</block>
  <block id="ca60b3698dd3d27a5f91e4dc0a1a2546" category="list-text">3장</block>
  <block id="4ce3ea126bb844d4f8c4ce1a65cbe3ae" category="list-text">Pip3</block>
  <block id="881cbd1ce3fdb52f73a82f8674a2a364" category="list-text">Ansible(버전 2.10.0 이상)</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="list-text">기트</block>
  <block id="6e3d8a0ff7934b777031953fe936bac8" category="paragraph">위 요구 사항이 설치되지 않은 새 Ubuntu/Debian 시스템이 있는 경우 다음 단계에 따라 해당 시스템을 Ansible 제어 노드로 설정합니다.</block>
  <block id="532d3723890df934cc5c2c39477405a2" category="list-text">sh 파일을 만듭니다</block>
  <block id="e95a2c08843a70246648b7107a26cec4" category="list-text">파일에 아래 내용을 붙여 넣습니다</block>
  <block id="86c8310d98a974adb7ac7c4025dd8b5c" category="list-text">파일을 실행 파일로 만듭니다</block>
  <block id="22db3e24628482683b9bf06c38e497ee" category="list-text">스크립트를 루트로 실행합니다.</block>
  <block id="b9b07f10c0ce1735548942e3abaa3447" category="summary">이 페이지에서는 NetApp Cloud Manager를 통해 CVO 및 Cloud Manager Connector 구축에 필요한 업데이트 토큰 및 액세스/비밀 키를 수집하는 데 필요한 자세한 정보를 제공합니다.</block>
  <block id="bcc03f70ea2e77a98ddb6e8267e4892f" category="paragraph">AWX/Ansible Tower를 통해 Ansible 플레이북을 사용하여 CVO 및 커넥터의 자동 배포를 구성하려면 다음 정보가 필요합니다.</block>
  <block id="193fc1c355935356ecd5d07811792512" category="section-title">AWS에서 액세스/비밀 키 획득</block>
  <block id="60b6439418495e0d1821d169b7d4b885" category="list-text">Cloud Manager에 CVO 및 Connector를 구축하려면 AWS 액세스/암호 키가 필요합니다. IAM --&gt; 사용자 --&gt; 사용자 이름 --&gt; 보안 자격 증명 --&gt; 액세스 키 생성을 실행하여 AWS 콘솔에서 키를 획득합니다.</block>
  <block id="ad1cc06192440312813c412c9cf08bc5" category="list-text">액세스 키를 복사하여 Connector 및 CVO 구축에 사용하도록 안전하게 보관합니다.</block>
  <block id="4ba9f13f5b12512f3651d5ea2d3ffa05" category="admonition">키를 분실한 경우 다른 액세스 키를 생성하고 분실한 키를 삭제할 수 있습니다</block>
  <block id="ad35fbaef240a8ec1f43e8a0d5e15099" category="image-alt">토큰 새로 고침</block>
  <block id="89d8fe92eb33da3c73df38422c3fa73e" category="section-title">NetApp Cloud Central에서 업데이트 토큰 획득</block>
  <block id="3d7e1d21530a3a98c74b0b7484c84516" category="list-text">에서 계정 자격 증명을 사용하여 Cloud Central 계정에 로그인합니다<block ref="ddbd83acb6424bbb7fa6878eff0976a1" category="inline-link-rx"></block></block>
  <block id="a95c6d24569073e45c394bcbd6a2c0e4" category="list-text">새로 고침 토큰을 생성하고 배포를 위해 저장합니다.</block>
  <block id="ecd636681b83fa2697020594594aea14" category="section-title">클라이언트 ID를 가져오는 중입니다</block>
  <block id="2a1ed6ca97aeb484a26d6e0d625af96b" category="list-text">API 페이지에 액세스하여 에서 클라이언트 ID를 복사합니다<block ref="06324b77583872f7e211b3e7ec3f882f" category="inline-link-rx"></block>.</block>
  <block id="1093ef7993a1f3824edbf581bb54b571" category="list-text">오른쪽 위 모서리에 있는 "인증 방법 알아보기"를 클릭합니다.</block>
  <block id="622dcb1fafb9f30d36b32341e23ae7a0" category="list-text">로그인 시 사용자 이름/암호가 필요한 경우 나타나는 인증 창에서 일반 액세스에서 클라이언트 ID를 복사합니다. SSO를 사용하는 페더레이션 사용자는 "토큰 새로 고침 탭"에서 클라이언트 ID를 복사해야 합니다.</block>
  <block id="76525f0f34b48475e5ca33f71d296f3b" category="image-alt">클라이언트 ID입니다</block>
  <block id="6090065e2462d5f96ebac132568bdf46" category="section-title">AWS에서 키 쌍 획득</block>
  <block id="294b903c23e96b98876b04f51502cec4" category="list-text">AWS 콘솔에서 "키 쌍"을 검색하고 "PEM"이 있는 키 쌍을 생성합니다. KEY_PAIR의 이름을 기억하시고, 이 이름을 사용하여 커넥터를 전개해 보겠습니다.</block>
  <block id="ddb20e807acdf5ddf189dd213ff6d0cf" category="image-alt">키 쌍</block>
  <block id="3ce1d7d6e1b4509256dd2574b6b5d290" category="section-title">계정 ID를 획득하는 중입니다</block>
  <block id="8f19980a36fbde35540547e8f630c9e5" category="list-text">Cloud Manager에서 계정 -&gt; 계정 관리 를 클릭한 다음 AWX 변수에 사용할 계정 ID를 복사합니다.</block>
  <block id="5c263f30899f93ff7ccd457ad3eb956f" category="list-text">다음 패키지가 설치된 RHEL/CentOS 시스템:</block>
  <block id="7b643b0eef9cf1199195fa05b77fc3c8" category="paragraph">위의 요구사항을 설치하지 않은 새로운 RHEL/CentOS 시스템을 사용하는 경우 다음 단계를 따라 해당 시스템을 Ansible 제어 노드로 설정하십시오.</block>
  <block id="d2052f202108defaf6afc7831ba59362" category="list-text">RHEL-8/RHEL-7용 Ansible 리포지토리를 지원합니다</block>
  <block id="61fbc2f21db84f17551fda6893429d16" category="list-text">RHEL-8의 경우(아래 명령을 루트로 실행)</block>
  <block id="77cd42f765e6b40764459a64a979f90c" category="list-text">RHEL-7의 경우(아래 명령을 루트로 실행)</block>
  <block id="c155d814eba0c89f7e4d7dde346e7ff8" category="paragraph">AWX/Ansible 타워를 통해 Ansible 플레이북을 사용하여 Mellanox 스위치를 구성하려면 다음 절차를 따르십시오.</block>
  <block id="59ea0dd3e785a6eff57ce16a49e0721b" category="list-text">설명서에 따라 AWX/Tower 매개변수를 구성합니다 <block ref="6dc8a9c13444a748151c0dc2cdfaf9ed" category="inline-link-macro-rx"></block></block>
  <block id="7007f95e98fc7408e8a7209ff06ba5d7" category="list-text">AWX/타워에 로그인하고 '리소스'-&gt;'템플릿'으로 이동한 다음 해당 Mellanox 작업 템플릿에 대한 '시작' 버튼을 클릭합니다.</block>
  <block id="1855f1f392261a9199b1e7394d52641b" category="list-text">메시지가 표시된 변수 필드에 복사된 내용을 붙여넣고 '다음'을 클릭한 다음 '시작'을 클릭하여 작업 템플릿을 실행합니다.</block>
  <block id="d78228187c1a83d3bb4d8e97cd657807" category="paragraph">자동화를 통해 NetApp 솔루션의 소비가 단순화됩니다.</block>
  <block id="88b11dbb43daa1023e1e0eac175e0e04" category="section-title">Ansible Control 노드 설정</block>
  <block id="cc720ba6fbd83dd2b0c222e5b1d4419c" category="paragraph">Ansible은 에이전트가 없는 자동화 도구이므로 하나의 시스템(Ansible 제어 노드)에만 설치하면 됩니다. 제어 노드를 통해 추가 구성 없이 전체 원격 장비를 관리할 수 있습니다.</block>
  <block id="1fd37248272971c6b09693c66e545794" category="inline-link-macro">RHEL8/CentOS8</block>
  <block id="62cb08c48fa7398e2b2fbf365a240e90" category="inline-link-macro">RHEL7/CentOS7</block>
  <block id="7eaf289636bc8d4f8b29b333a0f32dc2" category="inline-link-macro">Ubuntu/Debian</block>
  <block id="e10dea45c0463fb061f253f8deef6de6" category="paragraph">Ansible을 설치하려는 OS 유형에 따라 다음 링크 중 하나를 클릭하여 제어 노드를 설정하는 자세한 단계를 확인하십시오. <block ref="7dc121073254da4302fc5dcbe0722747" category="inline-link-macro-rx"></block>. <block ref="965292dac53abeffbcc140f60ed9445a" category="inline-link-macro-rx"></block>. <block ref="9c83d13c300fc83e32dbf47b4d277c36" category="inline-link-macro-rx"></block></block>
  <block id="90305bb6fba97091f683e8b82f9bf805" category="summary">NetApp 솔루션 자동화를 통해 고객은 많은 일반 인프라 및 애플리케이션 작업의 구축, 구성 및 실행을 자동화할 수 있습니다.</block>
  <block id="544c3a861d86ce6658187399d91aaa44" category="paragraph">솔루션 검증 및 설계 목표 중 하나는 솔루션을 쉽게 사용할 수 있도록 만드는 것입니다. 따라서 NetApp 솔루션을 통해 제공되는 인프라 및/또는 애플리케이션의 구축과 구성을 자동화를 통해 간소화하는 것이 무엇보다 중요합니다. NetApp은 RedHat Ansible을 사용하여 자동화를 통해 솔루션 소비를 단순화하기 위해 노력하고 있습니다.</block>
  <block id="9043d5bb11e7b216a7308f7a9761d9fd" category="paragraph">Ansible은 IT 팀이 애플리케이션 구축, 클라우드 프로비저닝, 구성 관리 및 기타 IT 요구사항을 자동화할 수 있도록 지원하는 오픈 소스 자동화 엔진입니다. Ansible은 에이전트가 없기 때문에 맞춤형 보안 인프라가 필요하지 않습니다. SSH를 통해 제어 시스템에서 원격으로 여러 시스템의 자동화를 관리할 수 있으므로 IT 팀은 지루하고 반복적인 IT 요구 사항을 자동화하고자 하는 강력한 솔루션을 구축할 수 있습니다.</block>
  <block id="8d9887ce2700536b12e7847e2163026e" category="paragraph">NetApp 솔루션 자동화를 처음 사용하는 경우 다음 섹션을 사용하여 Ansible 컨트롤러를 설정할 수 있습니다.</block>
  <block id="6061668c9cb1cddb071099d0e9da5444" category="paragraph">RedHat Ansible에 대한 자세한 내용은 설명서를 참조하십시오<block ref="228582a93333b3e21d695cbcfe7060d2" category="inline-link-rx"></block>.</block>
  <block id="4d3d20acde2dac77a5502c201323aa01" category="doc">NetApp 솔루션 자동화</block>
  <block id="2aa17d37bd2483f97468ab7653396786" category="paragraph">이 섹션에서는 NetApp 자동화 솔루션을 사용하는 환경을 준비하기 위해 AWX/Ansible 타워에서 매개 변수를 구성하는 데 필요한 단계를 설명합니다.</block>
  <block id="0fb1db9928d7fc107d96c13f1918b639" category="list-text">Resources(리소스) → Inventory(인벤토리) → Add(추가) 로 이동하여 Add Inventory(재고 추가) 를 클릭합니다.</block>
  <block id="2623b8eb8fcaecc009c3b78cc6e7d391" category="list-text">이름 및 조직 세부 정보를 입력하고 저장 을 클릭합니다.</block>
  <block id="cc243ac3e015aef331656a4bff40241c" category="list-text">인벤토리 페이지에서 방금 만든 인벤토리 리소스를 클릭합니다.</block>
  <block id="b0ddb214e9aa4a84bc80e6af8c6b2adf" category="list-text">재고 변수가 있는 경우 변수 필드에 붙여 넣습니다.</block>
  <block id="5d7863780eab69b6b968cfc9dc6e66bc" category="list-text">그룹 하위 메뉴로 이동하여 추가 를 클릭합니다.</block>
  <block id="ec51931bb91bc912d609f2099974dfd9" category="list-text">그룹 이름을 입력하고 그룹 변수에 복사한 다음(필요한 경우) 저장 을 클릭합니다.</block>
  <block id="8f9cbdc13fdcb31ff345f10ba333ac59" category="list-text">생성된 그룹을 클릭하고 Hosts 하위 메뉴로 이동한 다음 Add New Host를 클릭합니다.</block>
  <block id="98e7a99b463b825a87899d25486e46ea" category="list-text">호스트의 호스트 이름과 IP 주소를 입력하고 필요한 경우 호스트 변수를 붙여 넣은 다음 Save(저장) 를 클릭합니다.</block>
  <block id="3caf9a56384a30eb8dee819e3abc14d6" category="list-text">자격 증명 유형을 만듭니다. ONTAP, Element, VMware 또는 기타 HTTPS 기반 전송 연결과 관련된 솔루션의 경우 자격 증명 유형을 사용자 이름 및 암호 항목과 일치하도록 구성해야 합니다.</block>
  <block id="615b6214c17105ae4915a8c8a632025b" category="list-text">Administration → Credential Types로 이동하여 Add를 클릭합니다.</block>
  <block id="846bb9303e5cc4395e96eba0d4c7d50a" category="list-text">다음 내용을 입력 구성에 붙여 넣습니다.</block>
  <block id="333a40c5632e0507a83f6a191f0b69b3" category="list-text">다음 내용을 주입기 구성에 붙여넣습니다.</block>
  <block id="e31908e83a96aee8550446309c4ef7e0" category="list-text">자격 증명을 구성합니다.</block>
  <block id="de06c7b54d4158f81a8c4d4a02b61eb0" category="list-text">Resources → Credentials 로 이동하고 Add 를 클릭합니다.</block>
  <block id="e5b5f57b6910910a3f9a486e88088608" category="list-text">올바른 자격 증명 유형을 선택합니다. 표준 SSH 로그인을 사용하려면 Machine 유형을 선택하거나 직접 생성한 사용자 지정 자격 증명 유형을 선택합니다.</block>
  <block id="9256ee926473942ba849050ef0450b7f" category="list-text">다른 해당 세부 정보를 입력하고 저장 을 클릭합니다.</block>
  <block id="29d192f714134f2e257058cfcf763722" category="list-text">프로젝트를 구성합니다.</block>
  <block id="1b892b7661c6a3ae2b57cbf4233c3af5" category="list-text">Resources → Projects 로 이동한 후 Add 를 클릭합니다.</block>
  <block id="936784ca62c93ca666e77fd10733247c" category="list-text">소스 제어 자격 증명 유형 으로 Git 를 선택합니다.</block>
  <block id="9f4fd9b4a4c75c02d1b469e8dd75d9fb" category="list-text">특정 솔루션에 해당하는 소스 제어 URL(또는 git 클론 URL)을 붙여 넣습니다.</block>
  <block id="95acbbc0424478165cdbe3a62849cbc3" category="list-text">필요한 경우 Git URL이 액세스를 제어하는 경우 소스 제어 자격 증명 에서 해당 자격 증명을 만들고 연결합니다.</block>
  <block id="a934d780fa0cb0e8495a0a1cabd0f501" category="list-text">작업 템플릿을 구성합니다.</block>
  <block id="10c610c9225adcc92ca1b284b5bbb04b" category="list-text">이름과 설명을 입력합니다.</block>
  <block id="e33edf61d02fc69c2087dcc3c42177e1" category="list-text">작업 유형을 선택합니다. Run은 Playbook을 기반으로 시스템을 구성하고 Check는 실제로 시스템을 구성하지 않고 Playbook을 건조하게 실행합니다.</block>
  <block id="57cf64ce7890d12e5a41d18b83979ffd" category="list-text">Playbook의 해당 인벤토리, 프로젝트 및 자격 증명을 선택합니다.</block>
  <block id="fc6b15b1dd73bb25477aed453b9a02f2" category="list-text">작업 템플릿의 일부로 실행할 플레이북을 선택합니다.</block>
  <block id="9a7d90740af07bcdd2c628a6f6ae966c" category="list-text">일반적으로 런타임에는 변수를 붙여 넣습니다. 따라서 런타임 중에 변수를 채우라는 프롬프트를 표시하려면 변수 필드에 해당하는 시작 시 프롬프트 확인란을 선택합니다.</block>
  <block id="3454f07e6f81a48099e0d144ca38ec7a" category="list-text">필요에 따라 다른 세부 정보를 입력하고 Save(저장) 를 클릭합니다.</block>
  <block id="0b55c84dbc04b54418b0d507f7b8f669" category="list-text">실행 시 메시지가 표시되면 변수를 입력하고 다시 시작 을 클릭합니다.</block>
  <block id="56b4cb3c337694fdafc2164dddad87fa" category="summary">GPU는 일반적으로 반복적인 산술 계산을 수행하여 그래픽 시각화(렌더링)에 사용됩니다. 이 반복적 컴퓨팅 기능은 AI 및 딥 러닝 사용 사례에 자주 사용됩니다.</block>
  <block id="ca32c5a534baaf5f6dc3e6e6fed62450" category="doc">GPU 고려 사항</block>
  <block id="ceeb28ce3b9ce753f02856fffb7ba66c" category="paragraph">그래픽 집약적 애플리케이션의 경우, Microsoft Azure는 VM당 1~4개의 GPU가 장착된 NVIDIA Tesla M60 카드 기반의 NV 시리즈를 제공합니다. 각 NVIDIA Tesla M60 카드에는 각각 8GB의 GDDR5 메모리가 탑재된 Maxwell 기반 GPU 2개가 포함되어 있습니다(총 16GB).</block>
  <block id="cb433c3099845f0ac8f3ba53d162db7b" category="admonition">NVIDIA 라이센스는 NV 시리즈에 포함됩니다.</block>
  <block id="0f0c98cc175dc7cda319a35afcd199e5" category="paragraph"><block ref="0f0c98cc175dc7cda319a35afcd199e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ead26a90008a32871b53cb37bbe8431a" category="paragraph">NetApp HCI 사용 시 H615C GPU에는 NVIDIA Tesla T4 카드 3개가 포함되어 있습니다. 각 NVIDIA Tesla T4 카드에는 16GB GDDR6 메모리가 탑재된 Touring 기반 GPU가 있습니다. VMware vSphere 환경에서 사용할 경우 가상 머신은 전용 프레임 버퍼 메모리가 있는 각 VM과 GPU를 공유할 수 있습니다. NetApp HCI H615C의 GPU에서 광선 트레이싱을 사용하여 빛 반사를 포함한 사실적인 이미지를 생성할 수 있습니다. GPU 기능에 대한 라이센스가 있는 NVIDIA 라이센스 서버가 필요합니다.</block>
  <block id="148811d448421f6a42c549400b7201c0" category="paragraph"><block ref="148811d448421f6a42c549400b7201c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc6992cca0b3d14a85c456d0890f3e37" category="paragraph">GPU를 사용하려면 NVIDIA 라이센스 포털에서 다운로드할 수 있는 적절한 드라이버를 설치해야 합니다. Azure 환경에서는 NVIDIA 드라이버를 GPU 드라이버 확장으로 사용할 수 있습니다. 다음으로, 원격 데스크톱 서비스 세션에 GPU 하드웨어를 사용하려면 다음 스크린샷의 그룹 정책을 업데이트해야 합니다. H.264 그래픽 모드의 우선 순위를 지정하고 인코더 기능을 활성화해야 합니다.</block>
  <block id="5b0ff68b017720dd46aa6d1923fdfa95" category="paragraph"><block ref="5b0ff68b017720dd46aa6d1923fdfa95" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7d3d3d6dd94c69620cd3edfb005691c" category="paragraph">WebGL 샘플을 실행할 때 작업 관리자 또는 NVIDIA-SMI CLI를 사용하여 GPU 성능 모니터링을 검증합니다. GPU, 메모리 및 인코더 리소스가 사용되고 있는지 확인합니다.</block>
  <block id="d13ca37d387c1bb473c0343278d0477d" category="paragraph"><block ref="d13ca37d387c1bb473c0343278d0477d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f2b53ac98ef55a900849ead654ca636" category="paragraph">가상 데스크톱 서비스를 통해 NetApp HCI H615C에 가상 머신을 배포하려면 H615C 호스트가 있는 vCenter 클러스터 리소스를 사용하여 사이트를 정의합니다. VM 템플릿에는 필요한 vGPU 프로필이 첨부되어 있어야 합니다.</block>
  <block id="818fad61fba48977b2293819f37e950a" category="paragraph">공유 다중 세션 환경의 경우 여러 동종 vGPU 프로필을 할당하는 것이 좋습니다. 하지만 고급 전문가용 그래픽 애플리케이션의 경우 각 VM을 격리하도록 사용자 전용으로 유지하는 것이 더 좋습니다.</block>
  <block id="a2db30df8af33b0e661aaed00ce2c1d3" category="paragraph">GPU 프로세서는 QoS 정책에 따라 제어할 수 있으며, 각 vGPU 프로필은 전용 프레임 버퍼를 가질 수 있습니다. 그러나 인코더 및 디코더는 각 카드에 대해 공유됩니다. GPU 카드에 vGPU 프로필을 배치하는 작업은 vSphere 호스트 GPU 할당 정책에 의해 제어되며, 이는 성능(VM 분산) 또는 통합(그룹 VM)을 강조할 수 있습니다.</block>
  <block id="9411dea29d318927759a55cff454b3dd" category="inline-link-macro">다음은 업계를 위한 솔루션입니다.</block>
  <block id="ee3f381f10f3f075a22913a348a89edf" category="paragraph"><block ref="ee3f381f10f3f075a22913a348a89edf" category="inline-link-macro-rx"></block></block>
  <block id="7d37fde7375502ef1013412159477502" category="summary">NetApp은 Azure NetApp Files와의 신속한 통합을 포함하여 WVD 또는 원격 애플리케이션을 사용한 가상 데스크톱의 빠른 프로비저닝을 포함하여 많은 클라우드 서비스를 제공합니다.</block>
  <block id="28850fd0c108cc5f990fc4b4b52ab60d" category="doc">NetApp 가상 데스크톱 서비스 개요</block>
  <block id="c70675dc3857ae45ab2475f60c0f1f85" category="paragraph">NetApp은 WVD 또는 원격 애플리케이션을 사용한 가상 데스크톱의 빠른 프로비저닝, Azure NetApp Files과의 신속한 통합을 포함하여 다양한 클라우드 서비스를 제공합니다.</block>
  <block id="8b32dee3fc7d9223248420cb828c5527" category="paragraph">기존에는 고객에게 원격 데스크톱 서비스를 제공하고 제공하는 데 몇 주가 소요되었습니다. 프로비저닝 외에도 애플리케이션, 사용자 프로필, 공유 데이터 및 그룹 정책 객체를 관리하는 것이 어려워 정책을 적용하기가 어려울 수 있습니다. 방화벽 규칙은 복잡성을 높이고 별도의 기술 집합 및 도구가 필요합니다.</block>
  <block id="0276a1f5f692f2e9635f3733b371cf70" category="paragraph">Microsoft Azure Windows Virtual Desktop 서비스를 통해 Microsoft는 원격 데스크톱 서비스 구성 요소에 대한 유지 관리를 수행하므로 고객은 클라우드에서 작업 공간을 프로비저닝하는 데 집중할 수 있습니다. 고객은 VDI 환경을 관리하기 위한 특별한 기술이 필요한 전체 스택을 프로비저닝하고 관리해야 합니다.</block>
  <block id="51db16f7b26a08952beb43836ad3f31d" category="paragraph">NetApp VDS를 사용할 경우 고객은 브로커, 게이트웨이, 에이전트 등과 같은 아키텍처 구성 요소를 설치할 위치를 걱정하지 않고 가상 데스크톱을 빠르게 구축할 수 있습니다. 환경을 완벽하게 제어해야 하는 고객은 프로페셔널 서비스 팀과 협력하여 목표를 달성할 수 있습니다. 고객은 VDS를 서비스로 소비하므로 주요 비즈니스 과제에 집중할 수 있습니다.</block>
  <block id="139562ef7df2deed82d586ebe297a082" category="paragraph">NetApp VDS는 AWS, Azure, GCP 또는 프라이빗 클라우드 환경에서 다중 배포를 중앙에서 관리할 수 있는 서비스형 소프트웨어 오퍼링입니다. Microsoft Windows Virtual Desktop은 Microsoft Azure에서만 사용할 수 있습니다. NetApp VDS는 다른 환경에서 Microsoft 원격 데스크톱 서비스를 조정합니다.</block>
  <block id="fd9a0083b0a0e084ce6fb8d2ca64272f" category="paragraph">Microsoft는 Azure에서 Windows Virtual Desktop 환경에서만 Windows 10에 대한 다중 세션을 제공합니다. 인증 및 ID는 가상 데스크톱 기술에 의해 처리됩니다. WVD는 Active Directory와 동기화된 Azure Active Directory(AD Connect 포함) 및 Active Directory에 연결된 세션 VM이 필요합니다. RDS에는 사용자 ID 및 인증과 VM 도메인 연결 및 관리를 위한 Active Directory가 필요합니다.</block>
  <block id="416feb9f77def2ffedaab40a538d47e5" category="paragraph">다음 그림에 샘플 구축 토폴로지가 나와 있습니다.</block>
  <block id="e377917f3505cdb9fc72b74164df5928" category="paragraph"><block ref="e377917f3505cdb9fc72b74164df5928" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d271ca257d56879fcc9ed95d82aabaa7" category="paragraph">각 배포는 Active Directory 도메인과 연결되며 작업 영역 및 응용 프로그램에 대한 액세스 진입점을 클라이언트에 제공합니다. Active Directory 도메인이 여러 개인 서비스 공급자 또는 엔터프라이즈에는 일반적으로 더 많은 구축이 있습니다. 여러 지역에 걸쳐 있는 단일 Active Directory 도메인에는 일반적으로 여러 사이트를 포함하는 단일 배포가 있습니다.</block>
  <block id="9ea3c4f34057d91531ae286e3efe62c3" category="paragraph">Azure의 WVD에 대해 Microsoft는 NetApp VDS에서 소비되는 서비스형 플랫폼을 제공합니다. 다른 환경의 경우 NetApp VDS가 Microsoft 원격 데스크톱 서비스의 구현 및 구성을 조정합니다. NetApp VDS는 WVD Classic 및 WVD 암을 모두 지원하며 기존 버전을 업그레이드할 때에도 사용할 수 있습니다.</block>
  <block id="3e8cd47ad0ab71d0b3891f85212ccdbc" category="paragraph">각 배포에는 Cloud Workspace Manager(REST API 엔드포인트), HTML 5 게이트웨이(VDS 관리 포털에서 VM에 연결), RDS 게이트웨이(클라이언트의 액세스 지점) 및 도메인 컨트롤러로 구성된 자체 플랫폼 서비스가 있습니다. 다음 그림은 RDS 구현을 위한 VDS Control Plane 아키텍처를 보여 줍니다.</block>
  <block id="38606818aeffd06d174e51013afc23a1" category="paragraph"><block ref="38606818aeffd06d174e51013afc23a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58cad6a2c8c8ff1a585bf8d6ca94560" category="paragraph">RDS 구현의 경우 NetApp VDS는 고객 로고 및 이미지를 포함하도록 커스터마이징할 수 있는 클라이언트 소프트웨어를 사용하여 Windows 및 브라우저에서 쉽게 액세스할 수 있습니다. 사용자 자격 증명을 기반으로 승인된 작업 공간 및 애플리케이션에 대한 사용자 액세스를 제공합니다. 게이트웨이 세부 정보를 구성할 필요가 없습니다.</block>
  <block id="c2dcf4d443be38a737d1e580fb4b86ec" category="paragraph">다음 그림은 NetApp VDS 클라이언트를 보여 줍니다.</block>
  <block id="8e7d56f1d99fdc8080a747bf8b1eda75" category="paragraph"><block ref="8e7d56f1d99fdc8080a747bf8b1eda75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71110c8ffc8b198bc951f6e587fbcddf" category="paragraph">Azure WVD 구현에서 Microsoft는 클라이언트의 액세스 진입점을 처리하며 다양한 OS에 기본적으로 제공되는 Microsoft WVD 클라이언트에서 사용할 수 있습니다. 웹 기반 포털에서 액세스할 수도 있습니다. 클라이언트 소프트웨어의 구성은 GPO(그룹 정책 개체)나 고객이 선호하는 다른 방법으로 처리해야 합니다.</block>
  <block id="9e4318c1c6ae62544ba67e7c0fe55649" category="paragraph">다음 그림은 Azure WVD 구현을 위한 VDS Control Plane 아키텍처를 보여 줍니다.</block>
  <block id="ba9e4c82a95db68279bffa8ca8a8803f" category="paragraph"><block ref="ba9e4c82a95db68279bffa8ca8a8803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d648a5d4acf66674fb86cc7be05bd5e" category="paragraph">NetApp VDS는 필요한 구성 요소의 배포 및 구성 외에도 사용자 관리, 응용 프로그램 관리, 리소스 확장 및 최적화를 처리합니다.</block>
  <block id="3ea30729e0e7f0d666400ccc1a6f7bc3" category="paragraph">NetApp VDS는 사용자를 생성하거나 기존 사용자 계정에 클라우드 작업 공간 또는 응용 프로그램 서비스에 대한 액세스 권한을 부여할 수 있습니다. 이 포털은 암호 재설정 및 구성 요소 하위 집합 관리 위임에도 사용할 수 있습니다. 헬프데스크 관리자 또는 레벨 3 기술자는 문제 해결을 위해 사용자 세션을 섀도잉하거나 포털 내에서 서버에 연결할 수 있습니다.</block>
  <block id="061d5215d4dd8b8e2b7d9f2498a4a8c3" category="paragraph">NetApp VDS는 사용자가 만든 이미지 템플릿을 사용하거나 클라우드 기반 프로비저닝을 위해 시장에서 기존 템플릿을 사용할 수 있습니다. 관리할 이미지 수를 줄이려면 기본 이미지를 사용할 수 있으며, 필요한 추가 응용 프로그램을 제공된 프레임워크를 사용하여 쇼콜라티, MSIX 앱 연결, PowerShell 등과 같은 명령줄 도구를 포함하도록 프로비저닝할 수 있습니다. 사용자 정의 스크립트도 기계 수명 주기 이벤트의 일부로 사용할 수 있습니다.</block>
  <block id="91d75bd7e517ef4b563021e6d23d8cb9" category="inline-link-macro">다음: NetApp HCI 개요</block>
  <block id="3806ab54895f78b6c34b626314f84e6e" category="paragraph"><block ref="3806ab54895f78b6c34b626314f84e6e" category="inline-link-macro-rx"></block></block>
  <block id="a3af49b9146a6a36e8bea4c525797782" category="summary">이 페이지에서는 DCConfig Tool, TestVdc Tools 및 로그 파일에 대해 설명합니다.</block>
  <block id="d56ee3058d1c4ab634cd3e1e606f2064" category="doc">도구 및 로그</block>
  <block id="626b1761e15913fc6f955e1d76a0ac10" category="section-title">DCConfig 도구</block>
  <block id="65bbb1c25836b86f699bd2141a545958" category="paragraph">DCCconfig 도구는 사이트를 추가하기 위해 다음과 같은 하이퍼바이저 옵션을 지원합니다.</block>
  <block id="2c76e52255da65e5fcf88143f91aa431" category="paragraph"><block ref="2c76e52255da65e5fcf88143f91aa431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da2595b668536baaea606e674ade5181" category="paragraph"><block ref="da2595b668536baaea606e674ade5181" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2eb34c5311117b56d2c8eb33494052a3" category="paragraph">공유 데이터에 대한 작업 영역별 드라이브 문자 매핑은 GPO를 사용하여 처리할 수 있습니다. Professional Services 또는 지원 팀은 고급 탭을 사용하여 Active Directory OU 이름, FSLogix 배포를 설정하거나 해제하는 옵션, 다양한 시간 초과 값 등의 설정을 사용자 지정할 수 있습니다.</block>
  <block id="8688a5dde644921ea673f5bc2dde55c3" category="paragraph"><block ref="8688a5dde644921ea673f5bc2dde55c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6c93f3609bb3be799ed32b6a601d5fc" category="section-title">Command Center(이전 테스트 VDC 도구)</block>
  <block id="46433f623976c5af8ebdc7ab92816a48" category="inline-link-macro">Command Center 개요</block>
  <block id="bf69b43c185864d35a461d8f1c3ea56e" category="paragraph">Command Center 및 필요한 역할을 시작하려면 을 참조하십시오 <block ref="d7ce3bd63a8a34b9b1630abb82acb951" category="inline-link-macro-rx"></block>.</block>
  <block id="b425cca2998cc4a7041a0baf7681e912" category="paragraph">다음 작업을 수행할 수 있습니다.</block>
  <block id="b462233b13790bce7e4c6449d02cf930" category="list-text">작업 영역의 SMB 경로를 변경합니다.</block>
  <block id="ee347a7998de9774369e6853f1ed7bcc" category="paragraph"><block ref="ee347a7998de9774369e6853f1ed7bcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c524c01ee30f2f1597bb3e90c721dd8c" category="list-text">컬렉션 프로비저닝을 위해 사이트를 변경합니다.</block>
  <block id="ccb9931a262a0b169576103526fa2ab2" category="paragraph"><block ref="ccb9931a262a0b169576103526fa2ab2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af6ba12de0b8c93d5f768c83143c7d99" category="section-title">로그 파일</block>
  <block id="017b9aa293da801da252c728736f02db" category="inline-link-macro">자동화 로그</block>
  <block id="580acc766c3f0e464b462d271028dc32" category="paragraph"><block ref="5f6615a18cd0f2f0bcfb7578db5d1c9e" category="inline-image-macro-rx" type="image"></block>확인합니다 <block ref="11597d7347faee3da56e0e01d5ba1de2" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="881784d32d0ec795e6fd477e7c0fe8f7" category="paragraph"><block ref="881784d32d0ec795e6fd477e7c0fe8f7" category="inline-link-macro-rx"></block></block>
  <block id="7b0f97bc4856c6b0645650d13b53acb5" category="summary">사내 리소스와 클라우드 리소스 간에 연결이 존재하는 경우 NetApp Virtual Desktop Service를 온프레미스로 확장할 수 있습니다. 엔터프라이즈는 Express Route 또는 사이트 간 IPsec VPN 연결을 사용하여 Microsoft Azure에 대한 링크를 설정할 수 있습니다. 전용 링크를 사용하거나 IPsec VPN 터널을 사용하여 다른 클라우드에 대한 링크를 만들 수도 있습니다.</block>
  <block id="995d0ae58fc48c0007c3a45046221736" category="doc">하이브리드 클라우드 환경</block>
  <block id="610e3513c7222cae8d2a7c450741211a" category="paragraph">솔루션 검증을 위해 다음 그림에 나와 있는 환경을 사용했습니다.</block>
  <block id="0d9e9a129d4eb3389af12248eb017ef1" category="paragraph"><block ref="0d9e9a129d4eb3389af12248eb017ef1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60ca94382604fd3deb8a198feed31f1b" category="paragraph">사내에서 관리, 원격 데스크톱 세션 호스트 등을 위해 여러 VLAN을 구성했습니다. 172.21.146-150.0/24 서브넷에 있었으며 Microsoft 원격 라우팅 액세스 서비스를 사용하여 회사 네트워크로 라우팅되었습니다. 또한 다음 작업도 수행했습니다.</block>
  <block id="b613a58cb27d96b09550b74a616e43d8" category="list-text">Microsoft 라우팅 및 원격 액세스 서버(RRAS, IPchicken.com 식별)의 공용 IP를 확인했습니다.</block>
  <block id="b0aa9d967a62cfeb9427c31c3968fb31" category="list-text">Azure Subscription에 가상 네트워크 게이트웨이 리소스(경로 기반 VPN)를 만들었습니다.</block>
  <block id="2db3e884a3b1d82162c06df081b8e8f0" category="list-text">Microsoft RRAS 서버의 공용 IP에 대한 로컬 네트워크 게이트웨이 주소를 제공하는 연결을 만들었습니다.</block>
  <block id="ac7b5e31749488bdca809cc69e83bcec" category="list-text">RRAS에서 VPN 구성을 완료하여 VPN 게이트웨이를 만드는 동안 제공된 사전 공유 인증을 사용하여 가상 인터페이스를 만들었습니다. 올바르게 구성된 경우 VPN은 연결됨 상태여야 합니다. Microsoft RRAS 대신 pfSense 또는 기타 관련 도구를 사용하여 사이트 간 IPsec VPN 터널을 만들 수도 있습니다. 이 터널은 경로 기반이므로, 구성된 특정 서브넷에 따라 트래픽을 리디렉션합니다.</block>
  <block id="064b2713bd54ad7c04715d629ea8d77e" category="paragraph">Microsoft Azure Active Directory는 OAuth를 기반으로 ID 인증을 제공합니다. 엔터프라이즈 클라이언트 인증에는 일반적으로 NTLM 또는 Kerberos 기반 인증이 필요합니다. Microsoft Azure Active Directory 도메인 서비스는 ADConnect를 사용하여 Azure Active Directory와 사내 도메인 컨트롤러 간에 암호 해시 동기화를 수행합니다.</block>
  <block id="c9ced395d02e614104c13dc687b8d960" category="paragraph">이 하이브리드 VDS 솔루션 검증을 위해 NetApp은 처음에 Microsoft Azure에 구축되었고 vSphere에 추가 사이트를 추가했습니다. 이 접근 방식의 장점은 플랫폼 서비스가 Microsoft Azure에 배포되어 포털을 통해 즉시 백업된다는 것입니다. 사이트 사이트 사이트 VPN 링크가 다운된 경우에도 어디서나 서비스에 쉽게 액세스할 수 있습니다.</block>
  <block id="759e5787427ba679d146727a04400c46" category="paragraph">다른 사이트를 추가하기 위해 DCConfig라는 도구를 사용했습니다. 해당 애플리케이션의 바로 가기는 클라우드 작업 공간 관리자(CWMgr) VM의 데스크톱에서 사용할 수 있습니다. 이 응용 프로그램을 시작한 후 데이터센터 사이트 탭으로 이동하여 새 데이터센터 사이트를 추가하고 아래 표시된 대로 필요한 정보를 입력합니다. URL이 vCenter IP를 가리킵니다. 구성을 추가하기 전에 CWMgr VM이 vCenter와 통신할 수 있는지 확인합니다.</block>
  <block id="ae5bd963078c278284e2aabaefb99232" category="admonition">VMware vSphere 환경과의 통신을 활성화하려면 CloudWorkspace Manager에 vSphere PowerCLI 5.1이 설치되어 있어야 합니다.</block>
  <block id="e0072a2f037098ba3ee9ec9e1113f1ee" category="paragraph">다음 그림에서는 사내 데이터 센터 사이트 구성을 보여 줍니다.</block>
  <block id="30efb5f8dd999c0f737bf30327346d6f" category="paragraph"><block ref="30efb5f8dd999c0f737bf30327346d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f823fddfaa31c0b2b910c651849fe1e0" category="paragraph">특정 클러스터, 호스트 이름 또는 사용 가능한 RAM 공간을 기반으로 컴퓨팅 리소스에 사용할 수 있는 필터링 옵션이 있습니다. 스토리지 리소스의 필터링 옵션에는 데이터 저장소의 최소 여유 공간 또는 데이터 저장소당 최대 VM이 포함됩니다. 정규식을 사용하여 데이터 저장소를 제외할 수 있습니다. 저장 버튼을 클릭하여 구성을 저장합니다.</block>
  <block id="40cf95c01dfbdb8adc110507697330bf" category="paragraph">구성을 검증하려면 테스트 버튼을 클릭하거나 하이퍼바이저 로드 를 클릭하고 vSphere 섹션 아래의 드롭다운을 선택합니다. 적절한 값으로 채워야 합니다. 기본 프로비저닝 사이트에 대해 기본 하이퍼바이저를 yes로 설정하는 것이 가장 좋습니다.</block>
  <block id="b081b97ab471a870119bb85e196c0d63" category="paragraph">VMware vSphere에서 생성된 VM 템플릿은 VDS에서 프로비저닝 컬렉션으로 사용됩니다. 프로비저닝 컬렉션은 공유 및 VDI의 두 가지 형태로 제공됩니다. 공유 프로비저닝 수집 유형은 모든 서버에 단일 리소스 정책이 적용되는 원격 데스크톱 서비스에 사용됩니다. VDI 유형은 리소스 정책이 개별적으로 할당된 WVD 인스턴스에 사용됩니다. 프로비저닝 컬렉션의 서버에는 다음 세 가지 역할 중 하나를 할당할 수 있습니다.</block>
  <block id="9a0b479d2d7eaed435c14e20818841d9" category="list-text">* TSDATA. * 터미널 서비스와 데이터 서버 역할의 조합.</block>
  <block id="286b69ba39f77189135fbf4c39786e12" category="list-text">* TS. * 터미널 서비스(세션 호스트)</block>
  <block id="0b39ab3df8d28606b4bb8f5891022692" category="list-text">데이터. * 파일 서버 또는 데이터베이스 서버. 서버 역할을 정의할 때는 VM 템플릿 및 스토리지(데이터 저장소)를 선택해야 합니다. 선택한 데이터 저장소를 특정 데이터 저장소로 제한하거나 데이터 사용량을 기준으로 데이터 저장소를 선택하는 최소 사용 옵션을 사용할 수 있습니다.</block>
  <block id="fb89cc64fafb0e1626269bc00c07ae73" category="paragraph">각 배포에는 활성 사용자, 고정, 서버 로드 또는 사용자 수를 기준으로 클라우드 리소스 할당에 대한 VM 리소스 기본값이 있습니다.</block>
  <block id="d00f03f39f8119980cb5240353d345b1" category="inline-link-macro">다음: Login VSI를 사용한 단일 서버 로드 테스트</block>
  <block id="af5c949297d5415f4710bd1af3f1e7a7" category="paragraph"><block ref="af5c949297d5415f4710bd1af3f1e7a7" category="inline-link-macro-rx"></block></block>
  <block id="0581202e42d61d6dfe4875c70d00cdac" category="summary">NetApp 가상 데스크톱 서비스는 비즈니스 과제를 해결하기 위해 가상 데스크톱과 애플리케이션 환경을 손쉽게 제공합니다. VDS를 NetApp HCI로 확장하여 인라인 중복제거, 컴팩션, 씬 프로비저닝 및 압축을 비롯한 VDS 환경에서 강력한 NetApp 기능을 사용할 수 있습니다.</block>
  <block id="33491606222aecbfbdfa3fc8f13ffded" category="paragraph">NetApp 가상 데스크톱 서비스는 비즈니스 과제를 해결하기 위해 가상 데스크톱과 애플리케이션 환경을 손쉽게 제공합니다. VDS 환경을 온프레미스 ONTAP 환경으로 확장하여 VDS 환경에서 빠른 복제, 인라인 중복제거, 컴팩션, 씬 프로비저닝 등 강력한 NetApp 기능을 사용할 수 있습니다. 제공합니다. 이러한 기능으로 All-Flash 스토리지를 통해 스토리지 비용을 절감하고 성능을 향상할 수 있습니다. VMware vSphere 하이퍼바이저를 사용하면 가상 볼륨 및 vSphere API for Array 통합을 통해 서버 프로비저닝 시간을 최소화할 수 있습니다. 고객은 하이브리드 클라우드를 사용하여 까다로운 워크로드에 적합한 환경을 선택하고 비용을 절감할 수 있습니다. 온-프레미스를 실행하는 데스크톱 세션은 정책에 따라 클라우드 리소스에 액세스할 수 있습니다.</block>
  <block id="df6f0981c6f92ef3adb9059f5b387e4a" category="paragraph"><block ref="df6f0981c6f92ef3adb9059f5b387e4a" category="inline-link-macro-rx"></block></block>
  <block id="48a2bc9c10adbea95074594015793272" category="summary">작업 공간은 온프레미스 또는 모든 지원 클라우드 환경에서 호스팅되는 원격 데스크톱 세션을 공유할 수 있는 데스크톱 환경으로 구성되어 있습니다. Microsoft Azure를 사용하면 Windows Virtual Desktops에서 데스크톱 환경을 영구적으로 구축할 수 있습니다. 각 작업 영역은 특정 조직 또는 클라이언트와 연결됩니다.</block>
  <block id="1da2374b50f497e208c8dab11e6b2c98" category="doc">작업 영역 관리</block>
  <block id="fb67e63246489555a7e8929a138ced4c" category="paragraph">작업 공간은 데스크톱 환경으로 구성되며, 온프레미스 또는 지원되는 클라우드 환경에서 호스팅되는 원격 데스크톱 세션을 공유할 수 있습니다. Microsoft Azure를 사용하면 Windows Virtual Desktops에서 데스크톱 환경을 영구적으로 구축할 수 있습니다. 각 작업 영역은 특정 조직 또는 클라이언트와 연결됩니다. 새 작업 영역을 만들 때 사용할 수 있는 옵션은 다음 그림에 나와 있습니다.</block>
  <block id="42a6c6312ce8b92836d9e74d89998e89" category="paragraph"><block ref="42a6c6312ce8b92836d9e74d89998e89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d49083c2604eac2881e01b4acea428e" category="admonition">각 작업 영역은 특정 배포와 연결됩니다.</block>
  <block id="2a1fdca12b05c0f5292a8670b24cb478" category="paragraph">작업 영역에는 관련 앱 및 앱 서비스, 공유 데이터 폴더, 서버 및 WVD 인스턴스가 포함됩니다. 각 작업 영역은 암호 복잡성 적용, 다단계 인증, 파일 감사 등과 같은 보안 옵션을 제어할 수 있습니다.</block>
  <block id="f29490b04a344e19674ee8d1db337d14" category="paragraph">작업 영역은 추가 서버의 전원을 켜거나, 서버당 사용자 수를 제한하거나, 특정 기간(항상 켜짐/꺼짐)에 사용 가능한 리소스에 대한 일정을 설정할 수 있는 작업 부하 일정을 제어할 수 있습니다. 필요에 따라 리소스를 구성할 수도 있습니다.</block>
  <block id="5a70681d968007936b9d092ba1a93313" category="paragraph">필요한 경우 작업 공간에서 배포 VM 리소스 기본값을 재정의할 수 있습니다. WVD, WVD 호스트 풀(세션 호스트 및 앱 그룹 포함) 및 WVD 작업 공간은 클라우드 작업 공간 관리 제품군 포털에서 관리할 수도 있습니다. WVD 호스트 풀에 대한 자세한 내용은 다음을 참조하십시오<block ref="283c24f69dac0d05b60b041138870b19" category="inline-link-rx"></block>.</block>
  <block id="ff13351bb4dc0c877064ec1672d6723f" category="inline-link-macro">다음: 애플리케이션 관리</block>
  <block id="bb974af58c318849f0fce8f7c3ecdf37" category="paragraph"><block ref="bb974af58c318849f0fce8f7c3ecdf37" category="inline-link-macro-rx"></block></block>
  <block id="868ab86f19065016e9a2f077c5ec1ede" category="summary">작업 작업자는 사용 가능한 응용 프로그램 목록에서 응용 프로그램을 빠르게 시작할 수 있습니다. 앱 서비스는 원격 데스크톱 서비스 세션 호스트에서 애플리케이션을 게시합니다. WVD를 통해 앱 그룹은 다중 세션 Windows 10 호스트 풀에서 유사한 기능을 제공합니다.</block>
  <block id="c775b248c55d253008c58d1ecd60e66f" category="doc">EUC(End User Computing)/VDI(Virtual Desktop Infrastructure) 솔루션</block>
  <block id="599725d881295777d3740ac33e953ced" category="paragraph">온프레미스 또는 클라우드에서 가상 데스크톱을 구축하려는 경우 NetApp은 다양한 EUC/VDI 솔루션을 통해 고객의 요구사항을 해결할 수 있습니다.</block>
  <block id="75fc33fcc3ef968fd3bf30c8da19bf9b" category="section-title">NetApp VDS(가상 데스크톱 서비스)</block>
  <block id="0593c3151fa252cdb4e997dd1255c608" category="paragraph">NetApp VDS(가상 데스크톱 서비스)는 주요 퍼블릭 클라우드 및 프라이빗 클라우드에서 RDS(원격 데스크톱 서비스)를 조정합니다.</block>
  <block id="3b96d802308faf1d6ff7e5563ea3d29b" category="paragraph">VDS에 사용 가능한 솔루션:</block>
  <block id="dede82866780d163734b443c5f4d484e" category="inline-link-macro">NetApp 가상 데스크톱 서비스 기반의 하이브리드 클라우드 VDI</block>
  <block id="2ccf8775db4706ac42c0a600eca82163" category="list-text"><block ref="2ccf8775db4706ac42c0a600eca82163" category="inline-link-macro-rx"></block></block>
  <block id="d4a0768ddf4ac449658ace06000fa76e" category="section-title">VMware Horizon을 통한 최종 사용자 컴퓨팅</block>
  <block id="959f3d9cc20e0e9bfbc01c2d36cdc894" category="paragraph">NetApp은 다양한 컴퓨팅 구성을 포괄하는 VMware Horizon용 아키텍처를 검증했습니다. 사용 가능한 솔루션은 다음과 같습니다.</block>
  <block id="3acc5e85d752378c6f1b9154f379b475" category="inline-link-macro">VMware를 통한 최종 사용자 컴퓨팅(설계 가이드)</block>
  <block id="01606c27121f18cf231b4700ddf252e1" category="list-text"><block ref="01606c27121f18cf231b4700ddf252e1" category="inline-link-macro-rx"></block></block>
  <block id="87e25a8d0e462ac8d7158e587f376605" category="inline-link-macro">VMware 및 NVIDIA GPU를 이용하는 최종 사용자 컴퓨팅(설계 가이드)</block>
  <block id="4e5b466ff852e362d888b555cdcf62b7" category="list-text"><block ref="4e5b466ff852e362d888b555cdcf62b7" category="inline-link-macro-rx"></block></block>
  <block id="d840a196af6c9e07c3ac3b20b15fb724" category="inline-link-macro">VMware 및 NVIDIA GPU를 이용하는 최종 사용자 컴퓨팅(구축 가이드)</block>
  <block id="06e0780100d16763670aed1df8526b2e" category="list-text"><block ref="06e0780100d16763670aed1df8526b2e" category="inline-link-macro-rx"></block></block>
  <block id="f93781578174ca3309bd3ac126884af4" category="inline-link-macro">3D 그래픽용 VMware를 통한 최종 사용자 컴퓨팅</block>
  <block id="128fc080215971e783f68c8be31bd85d" category="list-text"><block ref="128fc080215971e783f68c8be31bd85d" category="inline-link-macro-rx"></block></block>
  <block id="18dbdef148da0fb68861cf1b6aeeeb40" category="summary">서비스 공급자와 엔터프라이즈 가상 데스크톱 관리자는 NetApp VDS가 포함된 하이브리드 VDI를 통해 사용자에게 영향을 주지 않으면서 리소스를 다른 클라우드 환경으로 쉽게 확장할 수 있습니다. NetApp HCI에 사내 리소스가 있다면 GPU 리소스를 더 효과적으로 제어할 수 있으며, 필요에 따라 컴퓨팅 또는 스토리지 노드를 확장할 수 있습니다.</block>
  <block id="0fe8a299bf61a0d1bbca5d975dc94fcc" category="paragraph">서비스 공급자와 엔터프라이즈 가상 데스크톱 관리자는 NetApp VDS가 포함된 하이브리드 VDI를 통해 사용자에게 영향을 주지 않으면서 리소스를 다른 클라우드 환경으로 쉽게 확장할 수 있습니다. 사내 리소스의 효율적인 제어를 통해 리소스를 더욱 효율적으로 관리하고 다양한 선택 옵션(컴퓨팅, GPU, 스토리지, 네트워크)을 제공하여 요구사항을 충족할 수 있습니다.</block>
  <block id="f9bfa55b1c8ab8884a1452fa3c9cb975" category="list-text">클라우드 환경으로 전환하여 원격 데스크톱 및 애플리케이션에 대한 수요 급증</block>
  <block id="6b53dc409ecc50a533e93345ddf1f2ee" category="list-text">플래시 스토리지 및 GPU 리소스로 사내에서 원격 데스크톱 및 애플리케이션을 호스팅하여 장시간 실행되는 동안 TCO 절감</block>
  <block id="f1de7e15d0b0c3caaafa1a47204338c7" category="list-text">클라우드 환경 전반에서 원격 데스크톱 및 애플리케이션의 관리 용이성</block>
  <block id="f9ce5b54f5428c82364a39f17156cc4f" category="list-text">사내 리소스와 함께 서비스형 소프트웨어 모델을 사용하여 원격 데스크톱 및 애플리케이션을 경험해 보십시오</block>
  <block id="675ee473db5bbe3911c19a4e43f8ec3f" category="list-text">하이브리드 VDS의 요구사항을 이해하려는 EUC/VDI 설계자</block>
  <block id="a7f381741a2ff77b61bc4b7bc2e3d04f" category="list-text">원격 데스크톱 및 애플리케이션 요구를 지원하는 NetApp 파트너</block>
  <block id="efa648658230830c2b9ac1a0647002d7" category="list-text">원격 데스크톱 및 애플리케이션 요구를 해결하려는 기존 NetApp HCI 고객</block>
  <block id="2fa4089eb34d18d2b64eaab8eed9692d" category="inline-link-macro">다음으로, NetApp 가상 데스크탑 서비스 개요를 살펴보겠습니다</block>
  <block id="bf817f81e35d1d9f2620def86f22dcc3" category="paragraph"><block ref="bf817f81e35d1d9f2620def86f22dcc3" category="inline-link-macro-rx"></block></block>
  <block id="0ccea8702c360d2d159b0e8477fe81d6" category="summary">H610C 또는 H615C를 사용하는 경우 라이센스를 재판매할 수 있는 NVIDIA 파트너로부터 GPU 라이센스를 구입해야 합니다.</block>
  <block id="1f26c520bd4eba393348dedea38da7b7" category="doc">NVIDIA 라이센싱</block>
  <block id="b548ee560d6fa4ee980d777df0300d09" category="inline-link">파트너 로케이터</block>
  <block id="72d760f4e8266e660fa7126e42f63bbe" category="paragraph">H610C 또는 H615C를 사용하는 경우 라이센스를 재판매할 수 있는 NVIDIA 파트너로부터 GPU 라이센스를 구입해야 합니다. NVIDIA 파트너는 을(를) 통해 확인할 수 있습니다<block ref="32da44153625c96a28e5bf10161bbc42" category="inline-link-rx"></block>. 가상 GPU(vGPU) 또는 Tesla와 같은 역량을 검색합니다.</block>
  <block id="7709fb92e99b3458d440c5212792a0de" category="paragraph">NVIDIA vGPU 소프트웨어는 다음 4가지 버전으로 제공됩니다.</block>
  <block id="31473f257c4cfabfcba0c506fefcf4ca" category="list-text">NVIDIA GRID Virtual PC(GRID vPC)</block>
  <block id="75cc5be2167cc23ca9d32aa78a164907" category="list-text">NVIDIA GRID 가상 애플리케이션(GRID vApp)</block>
  <block id="53b933a69a5adecaa6c8c8817d2d87a5" category="list-text">NVIDIA Quadro 가상 데이터 센터 워크스테이션(Quadro vDWS)</block>
  <block id="2d655109b3aad5a539482617b4aa3b6b" category="list-text">NVIDIA 가상 컴퓨팅 서버(vComputeServer)</block>
  <block id="38f26d9fb2d58dd577140e84010a059d" category="section-title">그리드 가상 PC</block>
  <block id="e43876de331b666ca7fd1c7bbb8a844d" category="paragraph">이 제품은 Microsoft Windows 응용 프로그램, 브라우저, 고화질 비디오 및 다중 모니터 지원을 위한 뛰어난 사용자 환경을 제공하는 가상 데스크톱을 원하는 사용자에게 적합합니다. NVIDIA GRID Virtual PC는 가상 환경에서 기본 경험을 제공하여 모든 PC 애플리케이션을 최대 성능으로 실행할 수 있도록 지원합니다.</block>
  <block id="06a4851adc711a27ef53d0577d69e210" category="section-title">그리드 가상 애플리케이션</block>
  <block id="2c20bf668630521a8f76995b0c04c398" category="paragraph">Grid vApps는 RDSH(Remote Desktop Session Host) 또는 기타 애플리케이션 스트리밍 또는 세션 기반 솔루션을 배포하는 조직을 위한 것입니다. Microsoft Windows 응용 프로그램을 최대 성능으로 제공하도록 설계된 Windows Server 호스팅 RDSH 데스크톱은 GRID vApp에서도 지원됩니다.</block>
  <block id="5de115addc6579e1d30075a2a92c9ae7" category="section-title">Quadro 가상 데이터 센터 워크스테이션</block>
  <block id="74fec534073fb87750193748093ada5a" category="paragraph">이 에디션은 Dassault CATIA, SOLIDWORKS, 3Dexeite, Siemens NX, PTC Creo, Schlumberger Petrel 또는 Autodesk Maya. NVIDIA Quadro vDWS를 사용하면 사용자는 모든 장치에서 모든 기능과 성능을 갖춘 전문가용 그래픽 응용 프로그램에 액세스할 수 있습니다.</block>
  <block id="fb5cc5533386fd1b00e6b986dec8cba1" category="section-title">NVIDIA 가상 컴퓨팅 서버</block>
  <block id="087877c8284ea313c79d65cb22d48329" category="paragraph">많은 조직에서 인공 지능(AI), 딥 러닝(DL), 데이터 과학과 같은 컴퓨팅 집약적인 서버 워크로드를 실행합니다. 이러한 사용 사례에서 NVIDIA vComputeServer 소프트웨어는 NVIDIA GPU를 가상화하여 오류 수정 코드, 페이지 폐기, NVLink를 통한 P2P, 다중 vGPU 등의 기능을 통해 컴퓨팅 집약적인 서버 워크로드를 가속화합니다.</block>
  <block id="e1f54ed77362f191ac08c4db8d9c44cd" category="admonition">Quadro vDWS 라이센스를 사용하면 GRID vPC 및 NVIDIA vComputeServer를 사용할 수 있습니다.</block>
  <block id="d685cba160011e42327272678904bcbc" category="inline-link-macro">다음: 배포</block>
  <block id="fed95bc65003dcb3d5ee273e3926bb25" category="paragraph"><block ref="fed95bc65003dcb3d5ee273e3926bb25" category="inline-link-macro-rx"></block></block>
  <block id="bf6d8e47240024519d1dbb6f5582ce66" category="summary">그래픽 워크스테이션은 일반적으로 제조, 의료, 에너지, 미디어 및 엔터테인먼트, 교육, 아키텍처 등 그래픽 집약적 애플리케이션의 경우 이동성이 제한되는 경우가 많습니다.</block>
  <block id="942cd85feff07ce32d619d2f724254a8" category="doc">솔루션을 제공합니다</block>
  <block id="fb987436787e4263bfee440b93703026" category="paragraph">이동성 문제를 해결하기 위해 가상 데스크톱 서비스는 유연한 GPU 구성 옵션을 포함하여 작업 근로자, 전문 사용자, 클라우드 또는 NetApp HCI에서 하드웨어 리소스를 사용하는 등 모든 유형의 근로자를 위한 데스크톱 환경을 제공합니다. VDS를 사용하면 랩톱, 태블릿 및 기타 모바일 장치를 통해 어디에서나 작업 환경에 액세스할 수 있습니다.</block>
  <block id="68ae3286d2356ff8dd51c2a397ca20eb" category="paragraph">ANSYS Fluent, ANSYS Mechanical, Autodesk AutoCAD, Autodesk Inventor, Autodesk 3DS Max, Dassault Systèmes SOLIDWORKS, Dassault Systèmes CATIA, PTC Creo, Siemens PLM NX 등 2021년 1월 기준 다양한 클라우드에서 사용할 수 있는 GPU가 다음 표에 나열되어 있습니다.</block>
  <block id="f5168df5bb95078acdfb440f5975a601" category="cell">GPU 모델</block>
  <block id="1668ca1bd914c1d847f23b491319ac91" category="cell">Microsoft Azure를 참조하십시오</block>
  <block id="b314ebdba178173db01ffda8d3a5af67" category="cell">Google Compute(GCP)</block>
  <block id="943ca3782b28d89aff2f86a50b332b3c" category="cell">AWS(Amazon Web Services)</block>
  <block id="8df8a98ff17d4d77329f5da80da051e8" category="cell">사내(NetApp HCI)</block>
  <block id="aaba9e920b39aa997c69800a9e589cd4" category="cell">NVIDIA M60</block>
  <block id="e095ad80d900786110d53ecd5cbd3e3e" category="cell">NVIDIA T4</block>
  <block id="c909ed1507c6d5537f0cc0966e83d3f1" category="cell">NVIDIA P100</block>
  <block id="c015c1cc95335d3b867c145c056df10b" category="cell">NVIDIA P4</block>
  <block id="e8130bb14c9382769c22861fb54683b3" category="paragraph">다른 사용자 및 전용 개인 데스크톱과의 공유 데스크톱 세션도 사용할 수 있습니다. 가상 데스크톱은 GPU를 1~4개 가질 수 있거나 NetApp HCI를 통해 부분 GPU를 활용할 수 있습니다. NVIDIA T4는 광범위한 사용자 워크로드의 요구사항을 충족할 수 있는 다기능 GPU 카드입니다. NetApp HCI H615C의 각 GPU 카드에는 서버당 16GB의 프레임 버퍼 메모리와 3개의 카드가 있습니다. 단일 H615C 서버에서 호스팅할 수 있는 사용자 수는 사용자 워크로드에 따라 다릅니다.</block>
  <block id="4d8b78a5288c49df59136421211718c9" category="cell">사용자/서버</block>
  <block id="704316eb872cbca84a8b30d74c2708a4" category="cell">표시등(4GB)</block>
  <block id="6f3a945a32dd8eba9f2fae42715f7246" category="cell">보통(8GB)</block>
  <block id="adb5e5b63d256f3854fc7276b3e8d14a" category="cell">중량지(16GB)</block>
  <block id="bd40934d28717a37aa4087f1622d8f0b" category="cell">H615C</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="8938ba807f25f2cd88559b9f84bbc3de" category="paragraph">사용자 유형을 확인하려면 사용자가 일반적인 작업을 수행하는 응용 프로그램으로 작업하는 동안 GPU 프로파일러 도구를 실행합니다. GPU 프로파일러는 메모리 요구 사항, 디스플레이 수 및 사용자가 요구하는 해상도를 캡처합니다. 그런 다음 요구 사항을 충족하는 vGPU 프로필을 선택할 수 있습니다.</block>
  <block id="1b014a2b6e4c329b9696aae7afac88db" category="paragraph">GPU가 장착된 가상 데스크톱은 최대 8K의 디스플레이 해상도를 지원할 수 있으며, nView 유틸리티는 단일 모니터를 여러 영역으로 분할하여 여러 데이터 세트에서 작업할 수 있습니다.</block>
  <block id="30f1a84c728d67b9606115a1531aa9c3" category="paragraph">ONTAP 파일 스토리지를 사용하면 다음과 같은 이점을 실현할 수 있습니다.</block>
  <block id="826f3d14d0c34cd0f8ced37e07a1537d" category="list-text">관리 입력 없이도 4천억 개의 파일로 스토리지를 최대 20PB까지 확장할 수 있는 단일 네임스페이스입니다</block>
  <block id="1d7ab3c9a162bc81b216bdc0948094f2" category="list-text">글로벌 파일 캐시로 전 세계를 확장할 수 있는 네임스페이스</block>
  <block id="2d4169e0cb52db60fd11576990b38a54" category="list-text">관리되는 NetApp 스토리지를 통한 안전한 멀티 테넌시</block>
  <block id="a44c13ec320997e84b87b0fef150c39f" category="list-text">NetApp FabricPool를 사용하여 콜드 데이터를 오브젝트 저장소로 마이그레이션</block>
  <block id="3749fba0ca78e5e5c70f899da89be2c3" category="list-text">파일 시스템 분석을 통한 빠른 파일 통계</block>
  <block id="63d0ec819ea12b4e83e0ef4a1cd2bb1c" category="list-text">스토리지 클러스터를 최대 24노드로 확장하여 용량과 성능 향상</block>
  <block id="818a13118ddb0908ba00c1b7ca18dc2c" category="list-text">할당량을 통해 스토리지 공간을 제어하고 QoS 제한을 통해 성능을 보장할 수 있습니다</block>
  <block id="ef94cd0a62341c72316393b1044582f8" category="list-text">암호화를 통한 데이터 보호</block>
  <block id="c1e36bb7dca3b0da98164eb5956e3f0f" category="list-text">데이터 보호 및 규정 준수에 대한 광범위한 요구사항 충족</block>
  <block id="6a632279908ad5d56ab46a826de6c9f2" category="list-text">유연한 비즈니스 연속성 옵션 제공</block>
  <block id="3c2622109ae4dc55b73e9bb6516e5616" category="paragraph"><block ref="3c2622109ae4dc55b73e9bb6516e5616" category="inline-link-macro-rx"></block></block>
  <block id="2cdacde3c74a59c779ff64324954b86f" category="summary">NetApp VDS(가상 데스크톱 서비스)는 주요 퍼블릭 클라우드 및 프라이빗 클라우드에서 RDS(원격 데스크톱 서비스)를 조정합니다. VDS는 Microsoft Azure에서 WVD(Windows Virtual Desktop)를 지원합니다. VDS는 SMB 파일 공유 설정(사용자 프로필, 공유 데이터 및 사용자 홈 드라이브의 경우), Windows 기능, 응용 프로그램 및 에이전트 설치, 방화벽 및 정책 등을 포함하여 WVD 또는 RDS 배포 후 수행해야 하는 많은 작업을 자동화합니다.</block>
  <block id="acb7add6e3cf0ca01c52e60466c321ca" category="doc">TR-4861: 가상 데스크탑 서비스를 지원하는 하이브리드 클라우드 VDI</block>
  <block id="3d564c1c20cf4265a5094ead9dc937f6" category="paragraph">NetApp, Suresh Thoppay</block>
  <block id="bb6a5b934db24610665e58e743983ae4" category="paragraph">사용자는 전용 데스크톱, 공유 데스크톱 및 원격 응용 프로그램에 대해 VDS를 사용합니다. VDS는 데스크톱의 응용 프로그램 관리를 자동화하기 위한 스크립트 이벤트를 제공하며 관리할 이미지 수를 줄입니다.</block>
  <block id="38e3c8e108e8e361d0712cdfe23e0b38" category="paragraph">VDS는 퍼블릭 및 프라이빗 클라우드 환경 전반의 배포를 처리하기 위한 단일 관리 포털을 제공합니다.</block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">고객 가치</block>
  <block id="07d07e20c1ad9bd1a3e99e2303879ff9" category="paragraph">2020년에 원격 인력이 급증함에 따라 비즈니스 연속성 요구사항이 달라졌습니다. IT 부서는 가상 데스크톱을 신속하게 프로비저닝해야 하는 새로운 과제에 직면하여 프로비저닝 민첩성과 원격 관리, 그리고 사내 및 클라우드 리소스를 손쉽게 프로비저닝할 수 있는 하이브리드 클라우드의 TCO 이점을 필요로 합니다. 다음과 같은 기능을 갖춘 하이브리드 클라우드 솔루션이 필요합니다.</block>
  <block id="44ff202cbab5f506b48c6021b19c4b1c" category="list-text">COVID 이후 작업 공간의 현실을 해결하고 글로벌 역학으로 유연한 작업 모델을 지원합니다</block>
  <block id="53f994926861d0a62f2893b66d8b2025" category="list-text">작업 근로자부터 고급 사용자에 이르기까지 모든 직원의 작업 환경 배포를 단순화하고 가속화함으로써 교대 근무 환경을 지원합니다</block>
  <block id="831955bd9eabf6724f4e4b01acbb833c" category="list-text">물리적 위치에 관계없이 풍부하고 안전한 VDI 리소스를 제공하여 인력을 모바일화합니다</block>
  <block id="ab02aa4712e65c237e92874eeef51ecd" category="list-text">하이브리드 클라우드의 구축 간소화</block>
  <block id="074890ea8810b95d9b381027ff9baef2" category="list-text">위험 감소 관리를 자동화 및 단순화합니다</block>
  <block id="5eed1e48d8861a1192e8694a3d24021b" category="inline-link-macro">다음으로, 사용 사례를 살펴보겠습니다</block>
  <block id="60e1de201d0c183e889577e990975f1a" category="paragraph"><block ref="60e1de201d0c183e889577e990975f1a" category="inline-link-macro-rx"></block></block>
  <block id="53cf9d36e61cc97b118ae4cc9589bac3" category="summary">NetApp VDS Cloud Workspace Management Suite 포털을 사용하면 사내, 관리 사용자, 애플리케이션 카탈로그 및 스크립트 이벤트에 대해 정의된 사이트를 비롯한 다양한 VDS 배포를 중앙에서 관리할 수 있습니다. 이 포털은 필요한 경우 응용 프로그램을 수동으로 프로비저닝하고 문제 해결을 위해 모든 시스템에 연결할 수 있도록 관리자가 사용합니다.</block>
  <block id="e68a6dedaba6faaba6e7afd9197edc4f" category="doc">관리 포털</block>
  <block id="76368893e7696218fc60d77f96235f35" category="paragraph">NetApp VDS Cloud Workspace Management Suite 포털을 사용할 수 있습니다<block ref="1640f4040bca8395064a2ee51cb5f0ae" category="inline-link-rx"></block> 및 다음 버전을 사용할 수 있습니다<block ref="b6375c31f2253ef964d998b5762ba440" category="inline-link-rx"></block>.</block>
  <block id="02655da204b103696191f5d52c33427f" category="paragraph">이 포털을 사용하면 온프레미스, 관리 사용자, 애플리케이션 카탈로그 및 스크립트 이벤트가 정의된 사이트를 비롯한 다양한 VDS 배포를 중앙에서 관리할 수 있습니다. 이 포털은 필요한 경우 응용 프로그램을 수동으로 프로비저닝하고 문제 해결을 위해 모든 시스템에 연결할 수 있도록 관리자가 사용합니다.</block>
  <block id="0499b0532cd51452b57a028f3973d9fa" category="paragraph">서비스 공급자는 이 포털을 사용하여 자신의 채널 파트너를 추가하고 자신의 클라이언트를 관리할 수 있습니다.</block>
  <block id="8af19d014b76fa90ffc0c0477bd47be5" category="inline-link-macro">다음: 사용자 관리</block>
  <block id="631d677d75a0b47f9fe24a201cc8cb85" category="paragraph"><block ref="631d677d75a0b47f9fe24a201cc8cb85" category="inline-link-macro-rx"></block></block>
  <block id="91af64270656f51ceebeabc4b79ecb07" category="summary">NetApp VDS는 필요한 코드베이스에 따라 사용 가능한 설정 앱을 사용하여 Microsoft Azure에 배포할 수 있습니다.</block>
  <block id="29707848401dd26f02baed07b9a416c1" category="paragraph">NetApp VDS는 필요한 코드베이스에 따라 사용 가능한 설정 앱을 사용하여 Microsoft Azure에 배포할 수 있습니다. 현재 릴리스를 사용할 수 있습니다<block ref="deb5bc0c1293f06a53a77d04b921abbd" category="inline-link-rx"></block> 출시 예정인 제품의 미리 보기를 사용할 수 있습니다<block ref="b5073644bfe6db36c388c6bdbca64b49" category="inline-link-rx"></block>.</block>
  <block id="201e09e85ad81db8a19ef9f20c05d1a5" category="inline-link">이 비디오</block>
  <block id="c4e1987e3c1416cefd772fd61f28dfb4" category="paragraph">을 참조하십시오<block ref="f8270911b627accef36841f0608bc58d" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="4c9affd9b517fc81a601ea0861dc5399" category="inline-link-macro">다음: 하이브리드 클라우드 환경</block>
  <block id="2045518eb8a77a5284f073d0387f9a58" category="paragraph"><block ref="2045518eb8a77a5284f073d0387f9a58" category="inline-link-macro-rx"></block></block>
  <block id="b5ed404fa434aeee227f550cddf89892" category="inline-link">NetApp 클라우드</block>
  <block id="d823edbaf98641c5959f3a596de3df66" category="list-text"><block ref="d823edbaf98641c5959f3a596de3df66" category="inline-link-rx"></block></block>
  <block id="b1eb0510d1bc6ffab71faa53637ecde2" category="inline-link">NetApp VDS 제품 설명서</block>
  <block id="c5b41ed257411dffc1cc80a4c00cf17c" category="list-text"><block ref="c5b41ed257411dffc1cc80a4c00cf17c" category="inline-link-rx"></block></block>
  <block id="272427e7f4e6650df3749f83086acde6" category="inline-link">VPN 게이트웨이를 사용하여 온프레미스 네트워크를 Azure에 연결합니다</block>
  <block id="c460b4e40e6d4709ed15a2e8dba39833" category="list-text"><block ref="c460b4e40e6d4709ed15a2e8dba39833" category="inline-link-rx"></block></block>
  <block id="440e11297e8634c052b1bfd29a90309c" category="inline-link">Azure 포털</block>
  <block id="8284aff5fcde6ba43a0ca21712739cae" category="list-text"><block ref="8284aff5fcde6ba43a0ca21712739cae" category="inline-link-rx"></block></block>
  <block id="8867b143d669949d3948e3816324ec75" category="inline-link">Microsoft Windows 가상 데스크톱</block>
  <block id="0db816b3393ed224b26131285b4e3dff" category="list-text"><block ref="0db816b3393ed224b26131285b4e3dff" category="inline-link-rx"></block></block>
  <block id="7c033f9cfba6e06ff2ee6cb852ce10f4" category="inline-link">Azure NetApp Files 등록</block>
  <block id="aff481c4855a001492901fbefcab7d17" category="list-text"><block ref="aff481c4855a001492901fbefcab7d17" category="inline-link-rx"></block></block>
  <block id="57eae0e26c1c0bbaec9110d010f68f7a" category="summary">NetApp HCI는 스토리지 노드와 컴퓨팅 노드의 혼합으로 구성된 하이브리드 클라우드 인프라입니다. 모델에 따라 2랙 유닛 또는 단일 랙 유닛으로 사용할 수 있습니다. VM 배포에 필요한 설치 및 구성은 NDE(NetApp Deployment Engine)를 통해 자동으로 수행되며 컴퓨팅 클러스터는 VMware vCenter를 통해 관리되며 스토리지 클러스터는 NDE를 사용하여 구축된 vCenter 플러그인을 통해 관리됩니다.</block>
  <block id="855faa205a8f23993f1a0fe1ac2cde2f" category="doc">NetApp HCI 개요</block>
  <block id="95404d16cb98456e438a61d79a0a31d9" category="paragraph">NetApp HCI는 스토리지 노드와 컴퓨팅 노드의 혼합으로 구성된 하이브리드 클라우드 인프라입니다. 모델에 따라 2랙 유닛 또는 단일 랙 유닛으로 사용할 수 있습니다. VM 배포에 필요한 설치 및 구성은 NDE(NetApp Deployment Engine)를 통해 자동으로 수행되며 컴퓨팅 클러스터는 VMware vCenter를 통해 관리되며 스토리지 클러스터는 NDE를 사용하여 구축된 vCenter 플러그인을 통해 관리됩니다. mNode라는 관리 VM은 NDE의 일부로 구축됩니다.</block>
  <block id="b6ab683d50d83f639ae697569117a54b" category="paragraph">NetApp HCI는 다음 기능을 처리합니다.</block>
  <block id="d15278d453245d004f8fd55cff421171" category="list-text">버전 업그레이드</block>
  <block id="b783caf332f2c3190dcb6ced64290f5a" category="list-text">이벤트를 vCenter에 푸시하는 중입니다</block>
  <block id="79adeb760f6909dd746e1e7adae6cd58" category="list-text">vCenter 플러그인 관리</block>
  <block id="a45e04274259a13dff2a10641a0fd97f" category="list-text">지원을 위한 VPN 터널</block>
  <block id="227590ca6f7ff3f3cc72e49cf277625f" category="list-text">NetApp Active IQ 수집기</block>
  <block id="b0088ee645cccd0951013eb53d0b3816" category="list-text">NetApp Cloud Services를 온프레미스로 확장하여 하이브리드 클라우드 인프라를 지원합니다. 다음 그림은 HCI 구성 요소를 보여줍니다.</block>
  <block id="1a811712e3bea62b6f5bd1851b149fc3" category="paragraph"><block ref="1a811712e3bea62b6f5bd1851b149fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4725a4744390b735ea1bb4e3fc99b686" category="section-title">스토리지 노드</block>
  <block id="65f0d96af236e344bd739fd20df1fa5d" category="paragraph">스토리지 노드는 반폭 또는 전폭 랙 유닛으로 사용할 수 있습니다. 처음에는 최소 4개의 스토리지 노드가 필요하며, 클러스터는 최대 40개 노드까지 확장될 수 있습니다. 스토리지 클러스터를 여러 컴퓨팅 클러스터에서 공유할 수 있습니다. 모든 스토리지 노드에는 쓰기 성능을 향상시키기 위한 캐시 컨트롤러가 포함되어 있습니다. 단일 노드는 4K 블록 크기로 50K 또는 100K IOPS를 제공합니다.</block>
  <block id="d31f04e865057f7055f2d8287b92ba2d" category="paragraph">NetApp HCI 스토리지 노드는 최소, 최대 및 버스트 QoS 제한을 제공하는 NetApp Element 소프트웨어를 실행합니다. 스토리지 노드 하나는 총 용량의 1/3을 초과할 수 없지만 스토리지 클러스터는 스토리지 노드 혼합을 지원합니다.</block>
  <block id="0f66538edca95cf4d42667cfa5d6a362" category="section-title">컴퓨팅 노드</block>
  <block id="449aaf51a6dfa9c0e17423ae5938d674" category="inline-link">VMware 호환성 가이드 를 참조하십시오</block>
  <block id="1046a3e2377d26c40f75eb2cd2f268da" category="admonition">NetApp은 에 나열된 모든 컴퓨팅 서버에 연결된 스토리지를 지원합니다<block ref="72cc7e3e2b2d7f777e05aa309ef5f733" category="inline-link-rx"></block>.</block>
  <block id="bc1a52314ab38efacf0a83e9df0b01cc" category="paragraph">컴퓨팅 노드는 반폭, 전폭 및 2개의 랙 유닛 크기로 제공됩니다. NetApp HCI H410C 및 H610C는 확장 가능한 인텔 Skylake 프로세서를 기반으로 합니다. H615C는 확장 가능한 2세대 인텔 Cascade Lake 프로세서를 기반으로 합니다. GPU를 포함하는 두 가지 컴퓨팅 모델이 있습니다. H610C에는 NVIDIA M10 카드 2개가 포함되어 있으며 H615C에는 NVIDIA T4 카드 3개가 포함되어 있습니다.</block>
  <block id="683876986e8fe1045fa768b4a8675ea9" category="paragraph"><block ref="683876986e8fe1045fa768b4a8675ea9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9667ae1b4be7e4c088e175844fd675e6" category="paragraph">NVIDIA T4에는 실시간 광선 추적을 제공하는 데 필요한 계산 능력을 제공하는 40개의 RT 코어가 있습니다. 이제 디자이너와 엔지니어가 사용하는 동일한 서버 모델을 사용하여 실제 작업에서와 마찬가지로 표면에서 가볍게 튀어 나오는 실사적 이미지를 만들 수 있습니다. 이 RTX 가능 GPU는 초당 최대 5기가파이의 실시간 광선 추적 성능을 제공합니다. NVIDIA T4를 Quadro vDWS(Quadro Virtual Data Center Workstation) 소프트웨어와 함께 사용하면 아티스트가 위치와 상관없이 모든 장치에서 정확한 그림자, 반사 및 굴절 기능을 갖춘 실사적 설계를 만들 수 있습니다.</block>
  <block id="bee5034948808ff859affdc8ba03b52c" category="paragraph">Tensor 코어를 사용하여 딥 러닝 추론 워크로드를 실행할 수 있습니다. 이러한 워크로드를 실행할 때 Quadro vDWS 기반 NVIDIA T4는 CPU 전용 서버로 구동되는 VM보다 최대 25배 빠른 성능을 제공합니다. 랙 유닛 하나에 NVIDIA T4 카드 3개를 장착한 NetApp H615C는 그래픽 및 컴퓨팅 집약적인 워크로드에 이상적인 솔루션입니다.</block>
  <block id="1f99f286804bf2f5a91a1cdd1733decf" category="paragraph">다음 그림은 NVIDIA GPU 카드를 나열하고 이러한 카드를 비교합니다.</block>
  <block id="67c0c3f98979352a9ed10f0de3d551f3" category="paragraph"><block ref="67c0c3f98979352a9ed10f0de3d551f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b4fc2931642829391b479ea5fb1e9d" category="paragraph">M10 GPU는 지식 근로자 사용 사례에 가장 적합한 TCO 솔루션입니다. 하지만 가상 워크스테이션, 그래픽 성능, 실시간 대화형 렌더링, 추론 등 다양한 사용 사례에서 사용할 수 있는 GPU로 표준화가 필요한 경우 T4를 사용하면 좋습니다. T4를 사용하면 IT 부서는 동일한 GPU 리소스를 활용하여 혼합 워크로드를 실행할 수 있습니다. 예를 들어, 낮 동안에는 VDI를 실행하고 야간에는 컴퓨팅 워크로드를 실행하기 위해 리소스를 다른 용도로 재활용할 수 있습니다.</block>
  <block id="bdced20c33601e0149aecb44114cfdc5" category="paragraph">H610C 컴퓨팅 노드는 크기가 두 개의 랙 유닛이며 H615C는 크기가 한 개의 랙 유닛으로, 전력을 더 적게 소모합니다. H615C는 H.264 및 H.265(High Efficiency Video Coding[HEVC]) 4:4:4 인코딩 및 디코딩을 지원합니다. 또한 점점 더 많은 주요 instrean VP9 디코더를 지원합니다. YouTube에서 제공하는 WebM 컨테이너 패키지에서도 비디오에 VP9 코덱을 사용합니다.</block>
  <block id="fe046fc197d12a64da1ea78423a2a809" category="paragraph">컴퓨팅 클러스터의 노드 수는 VMware에서 결정하며, 현재 96개의 VMware vSphere 7.0 Update 1이 사용되고 있습니다. EVC(Enhanced vMotion Compatibility)가 활성화된 경우 클러스터에서 서로 다른 컴퓨팅 노드 모델을 혼합할 수 있습니다.</block>
  <block id="f0bee2b90db3a99440b1a724c49ce1a2" category="inline-link-macro">다음은 NVIDIA 라이센싱입니다</block>
  <block id="e0bca2831f4cccfcaebc75e9555a1719" category="paragraph"><block ref="e0bca2831f4cccfcaebc75e9555a1719" category="inline-link-macro-rx"></block></block>
  <block id="c6aaad7e04b9605d83a2a2aa661fc1b4" category="summary">NetApp VDS를 사용하면 관리자가 작업을 다른 사용자에게 위임할 수 있습니다. 배포된 서버에 연결하여 문제를 해결하고, 로그를 보고, 감사 보고서를 실행할 수 있습니다. 고객 지원, 헬프데스크 또는 레벨 3 기술자는 사용자 세션을 섀도잉하고, 프로세스 목록을 보고, 필요한 경우 프로세스를 종료할 수 있습니다.</block>
  <block id="d1c59e5cbf684efb4f69f300e72a4ac9" category="doc">운영 관리</block>
  <block id="787e198d8fa4e242ef62df0a63fc0f5d" category="inline-link">실패한 VDA 작업 문제 해결 페이지</block>
  <block id="8086a7a818fcf045c7b05845b97629ed" category="paragraph">VDS 로그 파일에 대한 자세한 내용은 를 참조하십시오<block ref="0ecc734e7dc5f9a5685babbaab9faaa5" category="inline-link-rx"></block>.</block>
  <block id="88a80237ffcd0c20f5f4d4e7f9eda875" category="inline-link">VDA 구성 요소 및 사용 권한 페이지</block>
  <block id="000ea3efdd5a83f774a0c189fa2dcdc3" category="paragraph">필요한 최소 권한에 대한 자세한 내용은 를 참조하십시오<block ref="573c5bde2dc73c6cb4f63bbc5571c0e2" category="inline-link-rx"></block>.</block>
  <block id="81bb80b99b1ba5d80f9ba049cbd0c42f" category="inline-link">가상 머신 클론 생성 페이지</block>
  <block id="91aa73f3df8edb27ce6b20c984ff5d3e" category="paragraph">서버를 수동으로 복제하려면 를 참조하십시오<block ref="837d5521d53fff809b7ef3ad6b17ecfa" category="inline-link-rx"></block>.</block>
  <block id="7d71ba8ea6767ea10d7cd61cbd787f89" category="inline-link">디스크 공간 자동 증가 기능 페이지</block>
  <block id="abf872062b9eb23bdf6d671c27508d96" category="paragraph">VM 디스크 크기를 자동으로 늘리려면 를 참조하십시오<block ref="627eb07506141f4255cfbedd7fe89646" category="inline-link-rx"></block>.</block>
  <block id="cc6d8546c611bac5ab11fa1a5948ac1d" category="inline-link">최종 사용자 요구 사항 페이지</block>
  <block id="e148ddcb2ae92c77834ae7f48df04786" category="paragraph">클라이언트를 수동으로 구성할 게이트웨이 주소를 식별하려면 를 참조하십시오<block ref="3a5e891ac91af8fef1ca1458249fe76e" category="inline-link-rx"></block>.</block>
  <block id="b4f83b03956523a39e8bbbd0895f0f29" category="section-title">Cloud Insights</block>
  <block id="efb9afc2e01262d41bf1fa60ddc36414" category="paragraph">NetApp Cloud Insights는 NetApp 및 기타 타사 인프라 구성 요소에서 실행되는 인프라 및 애플리케이션에 대한 완벽한 가시성을 제공하는 웹 기반 모니터링 툴입니다. Cloud Insights은 프라이빗 클라우드와 퍼블릭 클라우드를 모두 지원하여 리소스 모니터링, 문제 해결 및 최적화를 지원합니다.</block>
  <block id="4894eb73d4d2ad7eaebb0968e871cb70" category="paragraph">에이전트 없이 데이터 수집기로부터 메트릭을 수집하려면 인수 단위 VM(Windows 또는 Linux)만 프라이빗 클라우드에 설치해야 합니다. 에이전트 기반 데이터 수집기를 사용하면 Windows 성능 모니터 또는 텔레그라프가 지원하는 모든 입력 에이전트에서 사용자 지정 메트릭을 가져올 수 있습니다.</block>
  <block id="32e49e2645f559763ede8e346bbcb816" category="paragraph">다음 그림은 Cloud Insights VDS 대시보드를 보여 줍니다.</block>
  <block id="cb9ecf4f0010c9ec12b73a00e06a9237" category="paragraph"><block ref="cb9ecf4f0010c9ec12b73a00e06a9237" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bd1406c323c740b5b2f2a7615ad62ca" category="paragraph">NetApp Cloud Insights에 대한 자세한 내용은 를 참조하십시오<block ref="5fdb6e8524eb99916602753c65f2f24e" category="inline-link-rx"></block>.</block>
  <block id="8a883bd6e43add9d94d923704bc177a7" category="inline-link-macro">다음: 도구 및 로그</block>
  <block id="28f1e69837c0c21f4dcb8260d6ab5e97" category="paragraph"><block ref="28f1e69837c0c21f4dcb8260d6ab5e97" category="inline-link-macro-rx"></block></block>
  <block id="60ece3fee8421729100872ec44f1cda9" category="summary">배포의 일부로 파일 서비스 방법을 선택하여 사용자 프로필, 공유 데이터 및 홈 드라이브 폴더를 호스팅할 수 있습니다. 사용 가능한 옵션은 파일 서버, Azure 파일 또는 Azure NetApp Files입니다. 그러나 배포 후에는 Command Center 툴을 사용하여 SMB 공유를 가리키도록 이 선택 사항을 수정할 수 있습니다. NetApp ONTAP을 사용하여 호스팅하면 여러 가지 이점이 있습니다.</block>
  <block id="568483e9bd85504f3c9dcef24ecd3235" category="doc">데이터 관리</block>
  <block id="1b8c33cc721641b8b0555f2d7b5c2773" category="inline-link-macro">NetApp ONTAP을 사용하여 호스팅하면 여러 가지 이점이 있습니다</block>
  <block id="ef9fd867f3eaed93e0806bd027825218" category="inline-link">데이터 계층 변경</block>
  <block id="698e77d7e678617a2ae27ca2525bfbf7" category="paragraph">배포의 일부로 파일 서비스 방법을 선택하여 사용자 프로필, 공유 데이터 및 홈 드라이브 폴더를 호스팅할 수 있습니다. 사용 가능한 옵션은 파일 서버, Azure 파일 또는 Azure NetApp Files입니다. 그러나 배포 후에는 Command Center 툴을 사용하여 SMB 공유를 가리키도록 이 선택 사항을 수정할 수 있습니다. <block ref="50056d02f0a90e2e837160c093f1b22b" category="inline-link-macro-rx"></block>. SMB 공유를 변경하는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="336429df384a16f14c12cbc8dba62525" category="inline-link-rx"></block>.</block>
  <block id="24e6e2f6171b43a847fe194a9a9b5cd0" category="section-title">글로벌 파일 캐시</block>
  <block id="ce29b83c61cdf6a56b49dbde9a4d57e0" category="paragraph">사용자가 글로벌 네임스페이스 내의 여러 사이트에 분산되어 있는 경우 글로벌 파일 캐시를 사용하면 자주 액세스하는 데이터의 지연 시간을 줄일 수 있습니다. 글로벌 파일 캐시 구축은 프로비저닝 수집 및 스크립트 기반 이벤트를 사용하여 자동화할 수 있습니다. 글로벌 파일 캐시는 읽기 및 쓰기 캐시를 로컬에서 처리하며 여러 위치에 걸쳐 파일 잠금을 유지합니다. 글로벌 파일 캐시는 Azure NetApp Files를 비롯한 모든 SMB 파일 서버에서 사용할 수 있습니다.</block>
  <block id="87db7a122a37ab4a28f2223fa123a5be" category="paragraph"><block ref="87db7a122a37ab4a28f2223fa123a5be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d726de6a27bb533c6c8c44ea508dffa8" category="paragraph">글로벌 파일 캐시를 사용하려면 다음이 필요합니다.</block>
  <block id="2f28046ff208122796d51bafd8d4bc9c" category="list-text">관리 서버(License Management Server)</block>
  <block id="83168e6cb289d732cc78427b51f93153" category="list-text">코어</block>
  <block id="e7704357fe6a312ecafae725be93b8c2" category="list-text">데이터를 캐시할 디스크 용량이 충분한 에지</block>
  <block id="d70c88e6a13ca1af40b966d8d7d831c4" category="inline-link">GFC 설명서</block>
  <block id="154c48fd725e7207d36baa74bba5fd7a" category="paragraph">소프트웨어를 다운로드하고 Edge의 디스크 캐시 용량을 계산하려면 을 참조하십시오<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="1afc494dd7d35016d9524e06b68dbf2a" category="paragraph">검증을 위해 NetApp HCI의 에지 리소스와 Azure의 동일한 VM에 핵심 및 관리 리소스를 배포했습니다. 코어는 대용량 데이터 액세스가 필요하고 에지는 코어의 서브셋이라는 점에 유의하십시오. 소프트웨어를 설치한 후 사용하기 전에 활성화된 라이센스를 활성화해야 합니다. 이렇게 하려면 다음 단계를 완료하십시오.</block>
  <block id="70366038f1d44fef6c71f615b677b9cf" category="list-text">라이센스 구성 섹션에서 여기를 클릭 링크를 사용하여 라이센스 활성화를 완료합니다. 그런 다음 코어를 등록합니다.</block>
  <block id="a51a182b58a11b12770fbd2bd9643852" category="paragraph"><block ref="a51a182b58a11b12770fbd2bd9643852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d666527802938c89b9f895300aea220b" category="list-text">글로벌 파일 캐시에 사용할 서비스 계정을 제공합니다. 이 계정에 필요한 사용 권한은 를 참조하십시오<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="ab698dd081619e8f6dc264df6c99b73e" category="paragraph"><block ref="ab698dd081619e8f6dc264df6c99b73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b1486d5cfb9e0c5394a50e2515b53c" category="list-text">새 백엔드 파일 서버를 추가하고 파일 서버 이름 또는 IP를 제공합니다.</block>
  <block id="ffeac1f6b14ca75f608539cb6c673f37" category="paragraph"><block ref="ffeac1f6b14ca75f608539cb6c673f37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="643c94b6eb5664ed3cca98d31d7dbd39" category="list-text">가장자리에서 캐시 드라이브에는 드라이브 문자 D가 있어야 합니다 그렇지 않으면 diskpart.exe 를 사용하여 볼륨을 선택하고 드라이브 문자를 변경합니다. 라이센스 서버에 Edge로 등록합니다.</block>
  <block id="e9b41aa1ac49113064748a9c6e0f48a9" category="paragraph"><block ref="e9b41aa1ac49113064748a9c6e0f48a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="156666d997fd17a94bed67fe95334273" category="paragraph">코어 자동 구성이 활성화된 경우 라이센스 관리 서버에서 핵심 정보가 자동으로 검색됩니다.</block>
  <block id="891d862f33aaeafcd8ecc43e102febd3" category="paragraph"><block ref="891d862f33aaeafcd8ecc43e102febd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2184b1f206fd35eeb448e9937bdabe7" category="paragraph">클라이언트 컴퓨터에서 파일 서버의 공유에 액세스하는 데 사용한 관리자는 UNC 경로 "\\&lt;edge server name&gt;\FASTDATA\&lt;core server name&gt;\&lt;backend file server name&gt;\&lt;share name&gt;"을 사용하여 GFC 에지를 사용하여 액세스할 수 있습니다. 관리자는 에지 위치에서 사용자 드라이브 매핑을 위한 사용자 로그로ontscript 또는 GPO에 이 경로를 포함할 수 있습니다.</block>
  <block id="a08e5ca253097ac5ad7741e20d9dd090" category="paragraph">전 세계 사용자에게 투명한 액세스를 제공하기 위해 관리자는 파일 서버 공유 및 에지 위치를 가리키는 링크를 사용하여 DFS(Microsoft Distributed Filesystem)를 설정할 수 있습니다.</block>
  <block id="0c9f570b7b5b34f0fbdab873e122d432" category="paragraph"><block ref="0c9f570b7b5b34f0fbdab873e122d432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9e8ad2bf50c8da3a637a8858d3a1391" category="paragraph">사용자가 사이트에 연결된 서브넷을 기반으로 Active Directory 자격 증명을 사용하여 로그인하면 DFS 클라이언트가 해당 링크를 사용하여 데이터에 액세스합니다.</block>
  <block id="6a6b2107f2b5daadfd13df04f769a587" category="paragraph"><block ref="6a6b2107f2b5daadfd13df04f769a587" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8aabec6a7d3f54b83478824808357c91" category="paragraph">파일 아이콘은 파일이 캐시되었는지 여부에 따라 달라집니다. 캐시되지 않은 파일은 아이콘의 왼쪽 아래 모서리에 회색 X가 표시됩니다. 에지 위치의 사용자가 파일에 액세스하면 해당 파일이 캐시되고 아이콘이 변경됩니다.</block>
  <block id="1014b6d5d432758e9041c845e4da7830" category="paragraph"><block ref="1014b6d5d432758e9041c845e4da7830" category="inline-image-macro-rx" type="image"></block></block>
  <block id="610eee89db61eda57b4b6da39d799845" category="paragraph">파일이 열려 있고 다른 사용자가 모서리 위치에서 같은 파일을 열려고 하면 다음과 같은 선택 메시지가 표시됩니다.</block>
  <block id="5a31b6c180e91d3c3d3c1053bbab642c" category="paragraph"><block ref="5a31b6c180e91d3c3d3c1053bbab642c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c6f3b21447f91b42ceee404afc53720" category="paragraph">사용자가 원본 사본을 사용할 수 있을 때 알림을 받는 옵션을 선택하면 사용자에게 다음과 같은 알림이 표시됩니다.</block>
  <block id="922c6f30fa0f74f32df2fac11a3bf378" category="paragraph"><block ref="922c6f30fa0f74f32df2fac11a3bf378" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b9bc3a03a8ae9cef2c5a66238e5ab25" category="inline-link">Talon 및 Azure NetApp Files 배포에 대한 비디오</block>
  <block id="e725329a19c23f541a0bdbead9c9b1e7" category="paragraph">자세한 내용은 다음을 참조하십시오<block ref="92818ea025c5b78ace999366164c2c46" category="inline-link-rx"></block>.</block>
  <block id="fc95bd8bc19564339fe05c7bad1b7662" category="section-title">SaaS 백업</block>
  <block id="482cadbeebfa6f9c4f062c1f2724d546" category="paragraph">NetApp VDS는 Exchange, SharePoint 및 Microsoft OneDrive를 포함하여 Salesforce 및 Microsoft Office 365에 대한 데이터 보호를 제공합니다. 다음 그림은 NetApp VDS가 이러한 데이터 서비스에 SaaS Backup을 제공하는 방식을 보여줍니다.</block>
  <block id="0e3aff181138166393e5e5e698c994d2" category="paragraph"><block ref="0e3aff181138166393e5e5e698c994d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cde65566156674196c087d89ded5c3b" category="paragraph">Microsoft Office 365 데이터 보호 데모를 보려면 을 참조하십시오<block ref="158107d7e819a2ef8c2e8f24519fc9a9" category="inline-link-rx"></block>.</block>
  <block id="a067b7082c28e7dbf856ab55b29d1acb" category="paragraph">Salesforce 데이터 보호 데모를 보려면 를 참조하십시오<block ref="dd6e5767407887626a36af7b68defda9" category="inline-link-rx"></block>.</block>
  <block id="2cb2b89213bccd89f81cfbb17b2e070b" category="inline-link-macro">다음: 작업 관리</block>
  <block id="1f3d3eae36241941c6f7a1eaf3615eac" category="paragraph"><block ref="1f3d3eae36241941c6f7a1eaf3615eac" category="inline-link-macro-rx"></block></block>
  <block id="64241e0b33fb869cb12ff8e1ec74f806" category="summary">NetApp VDS는 ID 인증을 위해 Azure Active Directory를 사용하고 NTLM/Kerberos 인증을 위해 Azure Active Directory 도메인 서비스를 사용합니다. ADConnect 도구를 사용하여 온프레미스 Active Directory 도메인을 Azure Active Directory와 동기화할 수 있습니다.</block>
  <block id="92726ab5faeb2cb9208eaac9af0346bd" category="doc">사용자 관리</block>
  <block id="c758de7e1477d6707c6709441d41a5e9" category="paragraph">포털에서 새 사용자를 추가하거나 기존 사용자에 대해 클라우드 작업 영역을 활성화할 수 있습니다. 작업 영역 및 응용 프로그램 서비스에 대한 사용 권한은 개별 사용자 또는 그룹별로 제어할 수 있습니다. 관리 포털에서 관리 사용자를 정의하여 포털, 작업 영역 등에 대한 권한을 제어할 수 있습니다.</block>
  <block id="b1bb3db86aec5efef6f7cc0d0d7c6331" category="paragraph">다음 그림은 NetApp VDS의 사용자 관리를 보여 줍니다.</block>
  <block id="ed5018356119de97fa1ab09c0eeab65a" category="paragraph"><block ref="ed5018356119de97fa1ab09c0eeab65a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1350c851c78a6cdb31c6fe46ddb499c2" category="paragraph">각 작업 영역은 다음 그림과 같이 Cloud Workspace OU 아래의 고유한 Active Directory 조직 단위(OU)에 있습니다.</block>
  <block id="a5484d6de39aa020af1aa382d6d52c5e" category="paragraph"><block ref="a5484d6de39aa020af1aa382d6d52c5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3fad2f68853fae9ef870ed5535896790" category="paragraph">자세한 내용은 을 참조하십시오<block ref="b5d59c719b42a4e7d2b711482aa2f54d" category="inline-link-rx"></block> NetApp VDS의 사용자 권한 및 사용자 관리</block>
  <block id="48a8649f1ce9d97848d70480ce7fea9c" category="paragraph">데이터 센터에 대한 API 호출을 사용하여 Active Directory 그룹을 CRAUserGroup으로 정의하면 해당 그룹의 모든 사용자가 UI를 사용하여 관리할 수 있도록 CloudWorkspace로 가져옵니다. 클라우드 작업 영역이 사용자에 대해 활성화되면 VDS는 사용자 홈 폴더, 설정 권한, 사용자 속성 업데이트 등을 만듭니다.</block>
  <block id="9e30d1bf5e5278a123ad0ddab43066b7" category="paragraph">VDI User Enabled(VDI 사용자 활성화) 가 선택된 경우 VDS는 해당 사용자 전용의 단일 세션 RDS 시스템을 생성합니다. 프로비저닝할 템플릿과 데이터 저장소를 묻는 메시지가 표시됩니다.</block>
  <block id="093d2ddf98cacaf853b6f986ca9bd647" category="paragraph"><block ref="093d2ddf98cacaf853b6f986ca9bd647" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46bccf4889fab263d6edc63e631883a7" category="inline-link-macro">다음: 작업 영역 관리</block>
  <block id="e98fdb0b8697a2cf005527be51872d0d" category="paragraph"><block ref="e98fdb0b8697a2cf005527be51872d0d" category="inline-link-macro-rx"></block></block>
  <block id="aaca2e6fe88c6861582a8d1a20acfd4f" category="summary">가상 데스크톱 서비스용 ONTAP 기능.</block>
  <block id="bc9c47c8423d4537fdbf118b09a80084" category="doc">가상 데스크톱 서비스용 ONTAP 기능</block>
  <block id="472986236003195075a1428fe6103f4c" category="paragraph">다음 ONTAP 기능을 사용하면 가상 데스크톱 서비스에 적합합니다.</block>
  <block id="6128a47ce6baa55dbad9293234f2f65c" category="list-text">* 스케일아웃 파일 시스템. * ONTAP FlexGroup 볼륨은 20PB 이상으로 확장할 수 있으며 단일 네임스페이스 내에서 4천억 개 이상의 파일을 포함할 수 있습니다. 클러스터는 최대 24개의 스토리지 노드를 포함할 수 있으며, 각 노드는 사용된 모델에 따라 유연하게 네트워크 인터페이스 카드 수를 지정할 수 있습니다.</block>
  <block id="960f11687b64143d44db7f4ffcb33ef2" category="paragraph">사용자의 가상 데스크톱, 홈 폴더, 사용자 프로필 컨테이너, 공유 데이터 등을 필요에 따라 확장할 수 있으며 파일 시스템 제한에 대한 우려 없이 확장할 수 있습니다.</block>
  <block id="ab7ad572d2251b9b27fa0213fde8531f" category="list-text">* 파일 시스템 분석 * XCP 툴을 사용하여 공유 데이터에 대한 통찰력을 얻을 수 있습니다. ONTAP 9.8+ 및 ActiveIQ Unified Manager 를 사용하면 파일 메타데이터 정보를 쉽게 쿼리하고 검색하고 콜드 데이터를 식별할 수 있습니다.</block>
  <block id="885f3e34ca03dc8ff35c0bac51b384f7" category="list-text">* 클라우드 계층화. * 콜드 데이터를 클라우드의 오브젝트 저장소 또는 데이터 센터의 S3 호환 스토리지로 마이그레이션하고</block>
  <block id="fb38ee94b865e67571a08316a3baac38" category="list-text">* 파일 버전. * 사용자는 NetApp ONTAP 스냅샷 복사본으로 보호되는 파일을 복구할 수 있습니다. ONTAP 스냅샷 복사본은 변경된 블록만 기록하므로 매우 공간 효율적입니다.</block>
  <block id="9b7db1dd6f422e5f07ded1d3b7b04d90" category="list-text">* 글로벌 네임스페이스. * ONTAP FlexCache 기술을 사용하면 파일 스토리지를 원격 캐싱할 수 있으므로 ONTAP 스토리지 시스템이 포함된 여러 위치에서 공유 데이터를 보다 쉽게 관리할 수 있습니다.</block>
  <block id="827aa7cb1ad6ddbf99e040efe34725a8" category="list-text">* 시큐어 멀티 테넌시 지원. * 단일 물리적 스토리지 클러스터는 각각 고유한 볼륨, 스토리지 프로토콜, 논리적 네트워크 인터페이스, ID 및 인증 도메인, 관리 사용자 등을 갖춘 여러 가상 스토리지 어레이로 제공할 수 있습니다. 따라서 테스트, 개발, 운영 등과 같은 여러 사업부와 환경 간에 스토리지 어레이를 공유할 수 있습니다.</block>
  <block id="6c36afe01468d888b334a4432dcac4b2" category="paragraph">성능을 보장하기 위해 적응형 QoS를 사용하여 사용된 공간 또는 할당된 공간에 따라 성능 수준을 설정하고 할당량을 사용하여 스토리지 용량을 제어할 수 있습니다.</block>
  <block id="b1a678f5f86de8ff8a5b9b1c4b3772b8" category="list-text">* VMware 통합. * VMware vSphere용 ONTAP 툴은 데이터 저장소 프로비저닝, vSphere 호스트 모범 사례 구현 및 ONTAP 리소스 모니터링을 위한 vCenter 플러그인을 제공합니다.</block>
  <block id="9b12997ae1d332c9003c444a6ff8918a" category="paragraph">ONTAP는 SCSI/파일 작업을 스토리지 시스템으로 오프로드하기 위해 VAAI(vStorage APIs for Array Integration)를 지원합니다. ONTAP는 또한 블록 및 파일 프로토콜에 대해 VASA(vStorage APIs for Storage Awareness) 및 가상 볼륨을 지원합니다.</block>
  <block id="025e05e390f2d7ef7708bb42d81e1eeb" category="paragraph">VMware vSphere용 SnapCenter 플러그인을 사용하면 스토리지 시스템의 Snapshot 기능을 사용하여 가상 머신을 쉽게 백업 및 복원할 수 있습니다.</block>
  <block id="3452f822915108b5d640f3288959e7fd" category="paragraph">ActiveIQ Unified Manager는 vSphere 환경에서 완벽한 스토리지 네트워크 가시성을 제공합니다. 관리자는 ONTAP에서 호스팅되는 가상 데스크톱 환경에서 발생할 수 있는 지연 시간 문제를 쉽게 식별할 수 있습니다.</block>
  <block id="c9559fb9abb51cf76cc973d06c7e730c" category="list-text">* 보안 규정 준수. * ActiveIQ Unified Manager 를 사용하면 모든 정책 위반에 대한 알림을 통해 여러 ONTAP 시스템을 모니터링할 수 있습니다.</block>
  <block id="875c0a88cb08e888c642bbcc19cb33a2" category="list-text">* 멀티 프로토콜 지원. * ONTAP는 블록(iSCSI, FC, FCoE 및 NVMe/FC), 파일(NFSv3, NFSv4.1, SMB2.x, SMB3.x) 및 오브젝트(S3) 스토리지 프로토콜</block>
  <block id="4ac79aa8e1431a96a08ba58c1e17a104" category="list-text">* 자동화 지원. * ONTAP는 VDS 관리 포털을 통해 작업을 자동화하는 REST API, Ansible 및 PowerShell 모듈을 제공합니다.</block>
  <block id="ba5e495048f0fa35302184aa505386a9" category="inline-link-macro">다음: 데이터 관리</block>
  <block id="51688bc4609022e20e8c1cb051fb4489" category="paragraph"><block ref="51688bc4609022e20e8c1cb051fb4489" category="inline-link-macro-rx"></block></block>
  <block id="aa08bd8b0522ea3a5e9ace598db7162c" category="doc">애플리케이션 관리</block>
  <block id="f83a66a518ff3f3f44725a09d9666710" category="paragraph">사무실 근로자가 파워 유저를 위해 서비스 보드를 사용하여 필요한 애플리케이션을 수동으로 프로비저닝하거나 NetApp VDS의 스크립트 기반 이벤트 기능을 사용하여 자동으로 프로비저닝할 수 있습니다.</block>
  <block id="546d3f7d3bb8a664a6ba4a3fb2f68c30" category="inline-link">NetApp Application Entitlement 페이지</block>
  <block id="175ba74f5b7d0ecd3f531c5fce21a240" category="paragraph">자세한 내용은 를 참조하십시오<block ref="03e02ecfc967e94041a86f599e14ac44" category="inline-link-rx"></block>.</block>
  <block id="fd324b11a163d2dae6bf3f9654381d16" category="inline-link-macro">다음: 가상 데스크탑 서비스를 위한 ONTAP 기능</block>
  <block id="25838148a81bcaa2b7e931ef8cd65a13" category="paragraph"><block ref="25838148a81bcaa2b7e931ef8cd65a13" category="inline-link-macro-rx"></block></block>
  <block id="3a1e041969ddc2d8e0e399260d9159a7" category="doc">Login VSI를 사용한 단일 서버 로드 테스트</block>
  <block id="12d80b6f529069c8b2bc8d45947a0379" category="paragraph">NetApp 가상 데스크톱 서비스는 Microsoft 원격 데스크톱 프로토콜을 사용하여 가상 데스크톱 세션 및 애플리케이션에 액세스하고 Login VSI 툴은 특정 서버 모델에서 호스팅할 수 있는 최대 사용자 수를 결정합니다. Login VSI는 특정 간격으로 사용자 로그인을 시뮬레이션하고 문서 열기, 메일 읽기 및 작성, Excel 및 PowerPoint 작업, 문서 인쇄, 파일 압축, 임의 나누기 등의 사용자 작업을 수행합니다. 그런 다음 응답 시간을 측정합니다. 서버 사용률이 낮으면 사용자 응답 시간이 낮고 사용자 세션이 더 추가되면 시간이 늘어납니다. Login VSI는 초기 사용자 로그인 세션을 기준으로 기준을 결정하며 사용자 응답이 기준으로부터 2초를 초과할 경우 최대 사용자 세션을 보고합니다.</block>
  <block id="4be1d7a9b1a8d85ed7d1cf5c72b23928" category="paragraph">NetApp 가상 데스크톱 서비스는 Microsoft 원격 데스크톱 프로토콜을 활용하여 가상 데스크톱 세션 및 애플리케이션에 액세스합니다. 특정 서버 모델에서 호스팅할 수 있는 최대 사용자 수를 결정하기 위해 Login VSI 툴을 사용했습니다. Login VSI는 특정 간격으로 사용자 로그인을 시뮬레이션하고 문서 열기, 메일 읽기 및 작성, Excel 및 PowerPoint 작업, 문서 인쇄, 파일 압축, 임의 나누기 등의 사용자 작업을 수행합니다. 응답 시간도 측정합니다. 서버 사용률이 낮으면 사용자 응답 시간이 낮고 사용자 세션이 더 추가되면 시간이 늘어납니다. Login VSI는 초기 사용자 로그인 세션을 기준으로 기준을 결정하며 사용자 응답이 기준으로부터 2초를 초과할 경우 최대 사용자 세션을 보고합니다.</block>
  <block id="481e9968651d6bd0d36d67a776a0f32a" category="paragraph">다음 표에는 이 검증에 사용된 하드웨어가 나와 있습니다.</block>
  <block id="e93f994f01c537c4e2f7d8528c3eb5e9" category="cell">카운트</block>
  <block id="8417ade953d75aa6fa3c64813e005e17" category="cell">NetApp HCI H610C</block>
  <block id="ec1d568aa57f1e1231acef5759640fc6" category="cell">런처, AD, DHCP 등을 위한 클러스터 내 3개. 부하 테스트용 서버 1대</block>
  <block id="5b68b81817d64cfa84c65e2e185efe97" category="cell">NetApp HCI H615C</block>
  <block id="c36af9ab64be0b8bd4d5097f58b8a5ba" category="cell">2x24C Intel Xeon Gold 6282 @ 2.1GHz. 1.5TB RAM</block>
  <block id="825c03a9f78635bec804883dde1bd6bf" category="paragraph">다음 표에는 이 검증에 사용된 소프트웨어가 나와 있습니다.</block>
  <block id="f5bf48aa40cad7891eb709fcf1fde128" category="cell">제품</block>
  <block id="f80ee94fe4a9c10f8d85e442e7521687" category="cell">NetApp VDS 5.4</block>
  <block id="d9cc1f843ea62c12a3e59afbbdc2f9ce" category="cell">오케스트레이션</block>
  <block id="bb15f84d3b96a9b33719b8a71bc62207" category="cell">VM 템플릿 Windows 2019 1809</block>
  <block id="f6a3c0d463e2ae697b02a9893e2062a3" category="cell">RDSH용 서버 OS</block>
  <block id="5a264c4e5b7b75d4ead67bf3ff7988bc" category="cell">Login VSI</block>
  <block id="5227da0541209a94c7dc0a07cf3e0740" category="cell">4.1.32.1</block>
  <block id="123995603a5e237810bf85a8e3c73f2e" category="cell">VMware vSphere 6.7 업데이트 3</block>
  <block id="1b21b0d71706897b69f108572c444d40" category="cell">하이퍼바이저</block>
  <block id="2752fcc90cb7cc7439b827d762e89166" category="cell">VMware vCenter 6.7 업데이트 3F</block>
  <block id="436bc441be68b676a199df5c1ea02263" category="cell">VMware 관리 툴</block>
  <block id="9ad541af6dac1be0c6655522128a386c" category="paragraph">Login VSI 테스트 결과는 다음과 같습니다.</block>
  <block id="17126aef3e415713552604218f448967" category="cell">VM 구성</block>
  <block id="084abcce930cefa047af15fc0836639a" category="cell">Login VSI 기준</block>
  <block id="8bb9799dff9f679e2305879f7dc1a9f0" category="cell">Login VSI 최대</block>
  <block id="e49775052ecbe49b489c84d0b09e916e" category="cell">H610C</block>
  <block id="a9cc7da7b66d8162a44a176bb1109440" category="cell">vCPU 8개, 48GB RAM, 75GB 디스크, 8Q vGPU 프로파일</block>
  <block id="28267ab848bcf807b2ed53c3a8f8fc8a" category="cell">799</block>
  <block id="8f85517967795eeef66c225f7883bdcb" category="cell">178</block>
  <block id="4052d2c7017812dc33333a4dc7e83dc9" category="cell">vCPU 12개, 128GB RAM, 75GB 디스크</block>
  <block id="eefc9e10ebdc4a2333b42b2dbb8f27b6" category="cell">763</block>
  <block id="7a614fd06c325499f1680b9896beedeb" category="cell">272</block>
  <block id="71c62dd6d64bb960471819c829a777fd" category="paragraph">하위 NUMA 경계 및 하이퍼스레딩을 고려할 때 VM 테스트 및 구성에 선택된 8개의 VM은 호스트에서 사용 가능한 코어에 의존했습니다.</block>
  <block id="0f57e9c52f3aa2d44da0de48ac87443a" category="paragraph">H610C에서는 RDP 프로토콜을 사용하여 사용자 세션에 연결하는 10개의 시작 관리자 VM을 사용했습니다. 다음 그림에서는 Login VSI 연결 정보를 보여 줍니다.</block>
  <block id="ad1351ac01d5fe0ac5546c8a2fd2d170" category="paragraph"><block ref="ad1351ac01d5fe0ac5546c8a2fd2d170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dba4e8b5ffc06c0ccce673fd6f48159" category="paragraph">다음 그림에서는 H610C의 활성 세션과 Login VSI 응답 시간을 비교하여 보여 줍니다.</block>
  <block id="8d58d21e6be9e4be37d3c42935a380b5" category="paragraph"><block ref="8d58d21e6be9e4be37d3c42935a380b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65f671ed80b2c6f0cc371ab295230a3a" category="paragraph">다음 그림에서는 H615C에 대한 Login VSI 응답 시간과 활성 세션을 비교하여 보여 줍니다.</block>
  <block id="72cce33d21386089f9a521f893c14d41" category="paragraph"><block ref="72cce33d21386089f9a521f893c14d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c29ae1e9123280c1975dbc407f3eca3" category="paragraph">다음 그림에서는 H615C vSphere 호스트 및 VM에 대한 Login VSI 테스트 중에 Cloud Insights의 성능 메트릭을 보여 줍니다.</block>
  <block id="d64755ae2a4094876fbaf88a161ddec2" category="paragraph"><block ref="d64755ae2a4094876fbaf88a161ddec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ab628831ed501803e9da2a64f12dd6e" category="inline-link-macro">다음: 관리 포털</block>
  <block id="20fcc4e371ed448b0d5ffee3f4aecb43" category="paragraph"><block ref="20fcc4e371ed448b0d5ffee3f4aecb43" category="inline-link-macro-rx"></block></block>
  <block id="373f503ebd19225995680383c6e2d54a" category="summary">비즈니스 응용 프로그램 및 엔터프라이즈 데이터베이스 솔루션 기능을 설명하는 블로그 시리즈</block>
  <block id="e4f724bc105592da045b6dd008770bbf" category="doc">비즈니스 애플리케이션 및 엔터프라이즈 데이터베이스 블로그</block>
  <block id="034233dab82dddd28f950b8d4198499e" category="paragraph">비즈니스 응용 프로그램 및 엔터프라이즈 데이터베이스 솔루션의 특정 기능을 강조하는 블로그의 개요</block>
  <block id="8e90e89b52f60feebe2c0df72ca0f424" category="section-title">비즈니스 애플리케이션 블로그</block>
  <block id="9149421bcec7ca7e29560cd7fc83c4d0" category="section-title">엔터프라이즈 데이터베이스 블로그</block>
  <block id="c4ff33edf6e94fb434fb59e4ad2c286b" category="inline-link-macro">SnapCenter 기반의 하이브리드 클라우드 데이터베이스 솔루션</block>
  <block id="dcf8c21fbb1d22c97f20ace5649e8918" category="list-text"><block ref="dcf8c21fbb1d22c97f20ace5649e8918" category="inline-link-macro-rx"></block></block>
  <block id="fc25c016a8fb35a621842044a8d4f2e7" category="inline-link-macro">하이브리드 클라우드에서 Oracle 데이터베이스 인프라를 자동화합니다</block>
  <block id="59a4cf9e5720080358e0622f3c948571" category="list-text"><block ref="59a4cf9e5720080358e0622f3c948571" category="inline-link-macro-rx"></block></block>
  <block id="ec9f29e2bd26bf4a641b2964f3e3cf52" category="summary">NetApp 솔루션의 자동화 기능을 설명하는 블로그 시리즈</block>
  <block id="6d64ee49cfa68e79b6fc189f1f83eef9" category="doc">솔루션 자동화 블로그</block>
  <block id="6380d01fb740985eb6892589e7579224" category="paragraph">NetApp 솔루션의 특정 자동화 기능을 강조하는 블로그 개요</block>
  <block id="b4a5303e0fac342c604f2250a077e3be" category="summary">AI 및 최신 데이터 분석 솔루션 자료에 최신 내용이 추가되었습니다</block>
  <block id="3d94edd87fc615dfe301c7233c56c6c3" category="doc">AI 및 최신 데이터 분석의 새로운 기능</block>
  <block id="6c359c33f91503466661c814919afe18" category="paragraph">최신 AI 및 최신 데이터 분석 솔루션 및 솔루션 자료 개요</block>
  <block id="b16e2e1566ba0fc14f6e0eb77d99cf93" category="cell">* NVIDIA DGX A100 Systems * 의 NetApp ONTAP AI</block>
  <block id="e7f098b026755d10f2c3f16d0ff0b1db" category="inline-link-macro">설계 가이드</block>
  <block id="1027b152cc3e8165ce099ede9548be95" category="cell"><block ref="1027b152cc3e8165ce099ede9548be95" category="inline-link-macro-rx"></block></block>
  <block id="dfb1e9c5f4c5835e6e1a4173130a49c9" category="inline-link-macro">구축 가이드</block>
  <block id="983044e3ba861493c43c08b9285c3125" category="cell"><block ref="983044e3ba861493c43c08b9285c3125" category="inline-link-macro-rx"></block></block>
  <block id="70163cee23a15a309e4f1ec48b6928a8" category="cell">* NVIDIA DGX A100 시스템과 Mellanox Spectrum 이더넷 스위치 * 가 포함된 NetApp ONTAP AI</block>
  <block id="d91f70a15d40fe5795af6ded9555e095" category="cell"><block ref="d91f70a15d40fe5795af6ded9555e095" category="inline-link-macro-rx"></block></block>
  <block id="8e9465b5d4318c8ef9039dfe684619d5" category="cell"><block ref="8e9465b5d4318c8ef9039dfe684619d5" category="inline-link-macro-rx"></block></block>
  <block id="0c70e09b2805fac4fb509aee9132fa97" category="cell">* NetApp DataOps 툴킷 *</block>
  <block id="9004ee13f10e4aa331cdbb0e05878d3f" category="inline-link-macro">GitHub에서 툴킷에 액세스하십시오</block>
  <block id="604c2d197444e12a03e7c1ba2830e768" category="cell"><block ref="604c2d197444e12a03e7c1ba2830e768" category="inline-link-macro-rx"></block></block>
  <block id="4810ca62a9687605d0a9c7471e75ec69" category="cell">* 데이터 분석 솔루션 개요 *</block>
  <block id="7cc3c71ee2fdbff1fd2efbfcded89f90" category="inline-link-macro">서로 다른 분석 전략을 위한 다양한 솔루션</block>
  <block id="478906eb475a111b93606dc484113cdc" category="cell"><block ref="478906eb475a111b93606dc484113cdc" category="inline-link-macro-rx"></block></block>
  <block id="0f984f9309c692c61a7fc7cc418f3aaf" category="summary">BData Protection and Security 솔루션 자료에 최신 내용이 추가되었습니다</block>
  <block id="d035e5417fa83f8b48e9410b914d70ed" category="doc">데이터 보호 및 보안 솔루션의 새로운 기능</block>
  <block id="d6aa2099009bf5a43f1d5210308a91de" category="paragraph">최신 데이터 보호 및 보안 솔루션 및 솔루션 자료 개요</block>
  <block id="1e1fe2d30ed5bb9c5276dddb65f4ce65" category="cell">* 보안 *</block>
  <block id="44516140f9860119a65bb3fc45b9ff39" category="inline-link-macro">PCI-DSS용 NetApp HCI 검증 아키텍처</block>
  <block id="5b03dcf0205060a9490f1d572aee619e" category="cell"><block ref="5b03dcf0205060a9490f1d572aee619e" category="inline-link-macro-rx"></block></block>
  <block id="e59c383143e849c3183725256fd9a923" category="summary">하이브리드 클라우드, 데스크톱 가상화 및 컨테이너 솔루션 기능에 대해 설명하는 비디오 및 데모 시리즈</block>
  <block id="abcf24668eda72956736ac7e0d4363b2" category="doc">하이브리드 클라우드, 데스크톱 가상화 및 컨테이너 비디오 및 데모</block>
  <block id="45ab5f50e70c77a29d7191bf77c1ea15" category="paragraph">하이브리드 클라우드, 데스크톱 가상화 및 컨테이너 솔루션의 특정 기능을 소개하는 다음 비디오 및 데모를 참조하십시오.</block>
  <block id="e96910160219339e97abaf85c4323aaa" category="section-title">NetApp 및 VMware Tanzu 비디오 시리즈</block>
  <block id="c232cfc0ae9806d3ad6d34a51df58229" category="section-title">NetApp의 Red Hat OpenShift</block>
  <block id="796fae61e057ed3cc6ad68fe313088d7" category="inline-link-macro">비디오: Astra Control을 사용한 워크로드 마이그레이션 - NetApp의 Red Hat OpenShift</block>
  <block id="bbb36afc119fa1244c89e23e3f5599dc" category="list-text"><block ref="bbb36afc119fa1244c89e23e3f5599dc" category="inline-link-macro-rx"></block></block>
  <block id="8893b40d0413bdee0d28539b7201b89c" category="summary">AI 및 최신 데이터 분석 솔루션 기능에 대해 설명하는 비디오 및 데모 시리즈</block>
  <block id="d14e8dc770c2ede214d6db5eeb5d5167" category="doc">AI 및 최신 데이터 분석 비디오 및 데모</block>
  <block id="4696a661acac2c10910848bfebf30d2d" category="paragraph">AI 및 최신 데이터 분석 솔루션의 특정 기능을 소개하는 비디오 및 데모를 소개합니다.</block>
  <block id="bd86b07883a3c2983a874d3a11359cde" category="section-title">YouTube의 데모/비디오</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="inline-link-macro">NetApp AI 솔루션</block>
  <block id="f4016f882c8544b575d00a8cb6a17809" category="list-text"><block ref="f4016f882c8544b575d00a8cb6a17809" category="inline-link-macro-rx"></block></block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps를 참조하십시오</block>
  <block id="7cd0e3a75573824e7933841074476cbe" category="list-text"><block ref="7cd0e3a75573824e7933841074476cbe" category="inline-link-macro-rx"></block></block>
  <block id="9480fd8950471a46e6b29b165ba7ae41" category="summary">NetApp Astra Control Center는 NetApp의 신뢰할 수 있는 데이터 보호 기술을 기반으로 하는 온프레미스 환경에 구축된 상태 저장 Kubernetes 작업 부하를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스를 제공합니다.</block>
  <block id="3d210170d7f07fe3c907e8ac619f003a" category="doc">NetApp Astra Control Center 개요</block>
  <block id="9b0d9ae1197ded2c7d52147e5056475d" category="paragraph">NetApp Astra Control Center는 사내 환경에 구축되어 NetApp 데이터 보호 기술을 기반으로 하는 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공합니다.</block>
  <block id="c4a7756da710a87248298a14bd0c21e6" category="paragraph"><block ref="c4a7756da710a87248298a14bd0c21e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0358bd53d50b55aa0509189dd381ca9" category="paragraph">NetApp Astra Control Center는 NetApp ONTAP 스토리지 시스템에 스토리지 클래스 및 스토리지 백엔드를 구축하고 구성하는 Astra Trident 스토리지 오케스트레이터가 구축된 Red Hat OpenShift 클러스터에 설치할 수 있습니다.</block>
  <block id="8cc4d72a7129322eb1f39ea9b9cfb2f6" category="inline-link-macro">이 문서는 여기 에서 확인할 수 있습니다</block>
  <block id="1c2ddd920580e1a7860afb96d7ac352e" category="paragraph">Astra Control Center를 지원하는 Astra Trident의 설치 및 구성은 를 참조하십시오 <block ref="a581b27b235a239b8b186164c4dbebd1" category="inline-link-macro-rx"></block>.</block>
  <block id="876ae62d75901b9ef80277fd884aa5e9" category="paragraph">클라우드 연결 환경에서 Astra Control Center는 Cloud Insights를 사용하여 고급 모니터링 및 원격 측정 기능을 제공합니다. Cloud Insights 연결이 없을 경우 제한된 모니터링 및 원격 측정(7일 메트릭)을 사용할 수 있으며 개방형 메트릭 엔드포인트를 통해 Kubernetes 기본 모니터링 툴(Prometheus 및 Grafana)으로 내보낼 수 있습니다.</block>
  <block id="54a5ba4de846d3c3ba8c0322f5139893" category="paragraph">Astra Control Center는 NetApp AutoSupport 및 Active IQ 에코시스템에 완전히 통합되어 사용자를 지원하고, 문제 해결을 지원하며, 사용 통계를 표시합니다.</block>
  <block id="34610c3089a79a0b0e58bcc24da4c16c" category="paragraph">Astra Control Center의 유료 버전 외에 90일 평가판 라이센스가 제공됩니다. 평가 버전은 이메일과 커뮤니티(Slack 채널)를 통해 지원됩니다. 고객은 이러한 기술 자료 및 기타 기술 자료 문서와 제품 내 지원 대시보드에서 제공되는 문서에 액세스할 수 있습니다.</block>
  <block id="b3d5fa878980b3f5b771ced3fa94111a" category="inline-link-macro">Astra 웹 사이트</block>
  <block id="83d307afe7b187cee5d096f65402182f" category="paragraph">NetApp Astra Control Center를 시작하려면 을 방문하십시오 <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="7f9648de128837be473a3b24e53ff823" category="section-title">Astra Control Center 설치 필수 구성 요소</block>
  <block id="8ffc0d45ec909884b280603fd2556021" category="list-text">하나 이상의 Red Hat OpenShift 클러스터 버전 4.6 EUS 및 4.7이 현재 지원됩니다.</block>
  <block id="526a5a0f546838d61791ded926113f71" category="list-text">각 Red Hat OpenShift 클러스터에 이미 Astra Trident가 설치 및 구성되어 있어야 합니다.</block>
  <block id="e7a6c3c568d213db46836511343c4965" category="list-text">ONTAP 9.5 이상을 실행 중인 NetApp ONTAP 스토리지 시스템 하나 이상</block>
  <block id="7433dd0f15704f71764248a0ca105fad" category="admonition">단일 사이트에 OpenShift를 설치할 때마다 전용 SVM을 설치하여 영구 스토리지로 사용하는 것이 가장 좋습니다. 다중 사이트 배포에는 추가 스토리지 시스템이 필요합니다.</block>
  <block id="c927c560df09d5ca001f99cd07b14700" category="list-text">Trident 스토리지 백엔드는 각 OpenShift 클러스터에서 ONTAP 클러스터에서 지원하는 SVM과 함께 구성해야 합니다.</block>
  <block id="67a56d728807272d2a01df50c6548f4f" category="list-text">스토리지 프로비저닝자로 Astra Trident가 있는 각 OpenShift 클러스터에 구성된 기본 StorageClass입니다.</block>
  <block id="dda5c1363ac68168c83f72fc2645f51f" category="list-text">부하 분산 및 OpenShift 서비스 노출을 위해 각 OpenShift 클러스터에 로드 밸런서를 설치하고 구성해야 합니다.</block>
  <block id="e32d2cb3312c2c7797ca52bd8d6ff26f" category="admonition">링크를 참조하십시오 <block ref="0065297854ca0573913043e80b99a2d1" category="inline-link-macro-rx"></block> 이 목적을 위해 검증된 로드 밸런서에 대한 정보를 제공합니다.</block>
  <block id="7dbcc72cc3a693b8f89b064e38ed7a23" category="list-text">NetApp Astra Control Center 이미지를 호스팅하도록 프라이빗 이미지 레지스트리를 구성해야 합니다.</block>
  <block id="aa32c16385a1b749687956188e4f0d9a" category="admonition">링크를 참조하십시오 <block ref="9d2000c3bba4885fe5f36ed192264583" category="inline-link-macro-rx"></block> 이를 위해 OpenShift 전용 레지스트리를 설치하고 구성합니다.</block>
  <block id="3123a26626e19f387157faf3a8e35e86" category="list-text">Red Hat OpenShift 클러스터에 대한 Cluster Admin 액세스 권한이 있어야 합니다.</block>
  <block id="537f97bbcef0e2e67d6840aa5845aa65" category="list-text">NetApp ONTAP 클러스터에 대한 관리 액세스 권한이 있어야 합니다.</block>
  <block id="0507b40de1fbd59b7a77b9054689e92b" category="list-text">Docker 또는 podman, tridentctl 및 OC 또는 kubtl 도구가 설치되어 있고 $PATH에 추가된 관리 워크스테이션입니다.</block>
  <block id="abfe00e88b26a267771078e0295b1573" category="admonition">Docker 설치는 20.10 이상의 Docker 버전이 있어야 하며, 팟맨 설치에는 3.0 이상의 팟맨 버전이 있어야 합니다.</block>
  <block id="8c7c70cb991e0295e289054b79308c5d" category="section-title">Astra Control Center를 설치합니다</block>
  <block id="121c2592ea226f655d357a8ecd8caf2e" category="inline-link">Astra 등록 사이트입니다</block>
  <block id="ba6df9237a2774d7ca28cdf134cf9314" category="admonition">Astra Control 평가판 라이센스를 시작하려면 를 방문하십시오<block ref="dd61f8f3fbfa8ca8b0a268b985d55b0e" category="inline-link-rx"></block>.</block>
  <block id="ccab5cf8842d06d8d4e2f7f778657c4b" category="list-text">tar ball의 압축을 풀고 작업 디렉토리를 결과 폴더로 변경합니다.</block>
  <block id="29fc4f6574f437e623e4eb9d47136931" category="list-text">설치를 시작하기 전에 Astra Control Center 이미지를 이미지 레지스트리로 밀어 넣으십시오.</block>
  <block id="25b4e951c048e2ae39554f36af8824b9" category="admonition">Docker 또는 Podman에서 이 작업을 수행할 수 있습니다. 두 가지 모두에 대한 지침은 이 단계에서 제공합니다.</block>
  <block id="abe31bcfb59f2265c2fb97dde407366c" category="open-title">포더맨</block>
  <block id="e83d8437c3befea11906e730883605bf" category="list-text">조직/네임스페이스/프로젝트 이름을 사용하여 레지스트리 FQDN을 환경 변수 '궤도'로 내보냅니다.</block>
  <block id="9acf317cba8637e151b8daae04e3e998" category="list-text">레지스트리에 로그인합니다.</block>
  <block id="e2f745ac603721ed9903b0acea00d059" category="admonition">kubadmin 사용자를 사용하여 개인 레지스트리에 로그인하는 경우 암호 대신 토큰을 사용하십시오. podman login -u odman login -u opp -user -p token- TLS -verify=false astra-registry.apps.ocp-vmw.cie.netapp.com`</block>
  <block id="e4b91f5b748fa6ef8813d2871257b134" category="admonition">또는 서비스 계정을 만들고, 레지스트리 편집기 및/또는 레지스트리 뷰어 역할(푸시/풀 액세스 필요 여부에 따라)을 할당하고, 서비스 계정의 토큰을 사용하여 레지스트리에 로그인할 수 있습니다.</block>
  <block id="a53846d7be2355a59af69a47e2cf4637" category="list-text">쉘 스크립트 파일을 작성하고 다음 내용을 붙여 넣습니다.</block>
  <block id="ad3318a786149147666e961c291c6875" category="admonition">레지스트리에 신뢰할 수 없는 인증서를 사용하는 경우 셸 스크립트를 편집하고 podman 푸시 명령 "podman push $registry/$(echo$astraImage|SED's/^\////')--tls-verify=false"를 사용하십시오.</block>
  <block id="326c4e96ff06709dede5c03038f00e78" category="list-text">파일을 실행 파일로 만듭니다.</block>
  <block id="ed85c18933b4b240788294af279f8624" category="list-text">쉘 스크립트를 실행합니다.</block>
  <block id="05b6053c41a2130afd6fc3b158bda4e6" category="open-title">Docker 를 참조하십시오</block>
  <block id="ad533c54cadd80fbf8f60e58b7d3abd6" category="admonition">kubadmin 사용자를 사용하여 개인 레지스트리에 로그인하는 경우 암호 대신 토큰(docker login -u OCP -user -p token astra-registry.apps.ocp-vmw.cie.netapp.com` 대신 토큰을 사용합니다.</block>
  <block id="f39d61476380fc033f45c2d744596b00" category="list-text">그런 다음 이미지 레지스트리 TLS 인증서를 OpenShift 노드에 업로드합니다. 이렇게 하려면 TLS 인증서를 사용하여 OpenShift-config 네임스페이스에 configmap을 만들고 이를 클러스터 이미지 구성에 패치하여 인증서를 신뢰할 수 있도록 합니다.</block>
  <block id="508ca0ca5ae419c052d9a8487bb0b2d0" category="admonition">경로를 사용하여 수신 운영자의 기본 TLS 인증서가 있는 OpenShift 내부 레지스트리를 사용하는 경우 이전 단계를 따라 인증서를 경로 호스트 이름에 패치해야 합니다. 수신 운영자로부터 인증서를 추출하기 위해 'OC extract secret/router-ca--keys=tls.crt-n openshift-ingrator' 명령어를 사용할 수 있다.</block>
  <block id="6589da0279dd02b9b1d177e0ff5f457b" category="list-text">Astra Control Center Operator 설치를 위한 Namespace 'NetApp-acc-operator'를 생성합니다.</block>
  <block id="e3990b0b892faaf03261a0a1bcd00b9b" category="list-text">"NetApp-acc-operator" 네임스페이스에서 자격 증명을 사용하여 이미지 레지스트리에 로그인하기 위한 암호를 만듭니다.</block>
  <block id="4324c8f0a70a221bdde33868774e5a76" category="list-text">Astra Control Center의 모든 자료 집합인 Astra Control Center Operator CR "Astra_control_center_operator_deploy.YAML"을 편집합니다. 운영자 CR에서 "acc-operator-controller-manager"의 배포 정의를 찾아 이미지를 레지스트리에 푸시하는 동안 제공된 조직 이름과 함께 레지스트리의 FQDN을 입력합니다(이 예에서는 astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra`). 'Astra_image_registry'라는 텍스트를 바꾸고 'imagePullSecrets' 섹션에서 방금 만든 비밀의 이름을 입력합니다. 조작자의 기타 세부 사항을 확인하고 저장하고 닫습니다.</block>
  <block id="a27cc132b2f3001f3e9df9c40dad4bfb" category="list-text">다음 명령어를 실행해 운용자를 생성한다.</block>
  <block id="685fe82295261a8902e709081b6c9599" category="list-text">모든 Astra Control Center 리소스를 설치하기 위한 전용 네임스페이스를 만듭니다.</block>
  <block id="6d71c41a686bcfc0b0866044afd43f2b" category="list-text">해당 네임스페이스에서 이미지 레지스트리에 액세스하기 위한 암호를 만듭니다.</block>
  <block id="25eb68598d15a49d385089020950412c" category="list-text">Astra Control Center CRD 파일 "Astra_control_center_min YAML"을 편집하여 FQDN, 이미지 레지스트리 세부 정보, 관리자 이메일 주소 및 기타 세부 정보를 입력합니다.</block>
  <block id="d689979a6af0f5660231db187d212950" category="list-text">이를 위해 생성된 네임스페이스에서 Astra Control Center CRD를 생성합니다.</block>
  <block id="42b9bde28896d6478a324770641ac301" category="admonition">이전 파일 Astra_control_center_min YAML은 Astra Control Center CRD의 최소 버전이다. PVC 생성을 위한 기본값 이외의 스토리지 클래스 정의 또는 메일 알림에 대한 SMTP 세부 정보 제공 등 더 많은 제어 권한을 가진 CRD를 생성하려면 "Astra_control_center.YAML" 파일을 편집하고 필요한 세부 정보를 입력한 후 CRD 생성에 사용합니다.</block>
  <block id="e3cd33ca69b8e508c973939783f528db" category="list-text">설치가 완료되는 데 몇 분 정도 걸릴 수 있습니다. NetApp-Astra-cc 네임스페이스의 모든 Pod와 서비스가 실행 중인지 확인합니다.</block>
  <block id="9904a774f242f31a5ae37c8f75bda92b" category="list-text">설치가 완료되었는지 확인하려면 'acc-operator-controller-manager' 로그를 확인하십시오.</block>
  <block id="4af39dbe40f8a0467bbdd739a971f0ea" category="admonition">다음 메시지는 Astra Control Center가 성공적으로 설치되었음을 나타냅니다.</block>
  <block id="c27deb19babf146e6377dce25b1e70e7" category="list-text">Astra Control Center에 로그인하기 위한 사용자 이름은 CRD 파일에 제공된 관리자의 이메일 주소이며 암호는 Astra Control Center UUID에 추가된 문자열 ACC- 입니다. 다음 명령을 실행합니다.</block>
  <block id="57a7aa2eaf00ddaa73ef6b49299ade6e" category="admonition">이 예에서 암호는 'ACC-345c55a5-bf2e-21f0-84b8-b6f2bce5e95f'입니다.</block>
  <block id="5946314197ad84982efa6561d9da8302" category="list-text">traefik 서비스 로드 밸런서 IP를 가져옵니다.</block>
  <block id="298a1e8781e536e60684ab1700c60962" category="list-text">Astra Control Center CRD 파일에서 제공하는 FQDN을 가리키는 DNS 서버의 entry를 traefik 서비스의 'external-ip'에 추가한다.</block>
  <block id="0c64767e085896708adcbcc1c32c55fe" category="inline-image-macro">ACC GUI에 대한 DNS 항목을 추가합니다</block>
  <block id="1c278e58c0255ae1f09fc4fa520160b6" category="paragraph"><block ref="1c278e58c0255ae1f09fc4fa520160b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f436b7e192eae471d7abf1265bb4c02" category="list-text">FQDN을 검색하여 Astra Control Center GUI에 로그인합니다.</block>
  <block id="cc2ba6bb5620162b64bafdca9f089718" category="inline-image-macro">Astra Control Center 로그인</block>
  <block id="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="paragraph"><block ref="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19bae630567610f1955167595b8daae3" category="list-text">CRD에 제공된 관리자 이메일 주소를 사용하여 처음으로 Astra Control Center GUI에 로그인할 경우 비밀번호를 변경해야 합니다.</block>
  <block id="90fbead2d113af1a2680805778908d98" category="inline-image-macro">Astra Control Center 필수 암호 변경</block>
  <block id="247e9fd0170ec4d9550de59ebd54787b" category="paragraph"><block ref="247e9fd0170ec4d9550de59ebd54787b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c62383e1115b208212b5a634214ae37" category="list-text">Astra Control Center에 사용자를 추가하려면 계정 &gt; 사용자 로 이동하여 추가 를 클릭하고 사용자 세부 정보를 입력한 다음 추가 를 클릭합니다.</block>
  <block id="0dd5915bd7ca0f5d34df18bf7a183d50" category="inline-image-macro">Astra Control Center에서 사용자를 생성합니다</block>
  <block id="0ea309ed2f56bdc52dd6184b9043e683" category="paragraph"><block ref="0ea309ed2f56bdc52dd6184b9043e683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a37ba7c36c036650f5e1e7ded5232245" category="list-text">Astra Control Center를 사용하려면 모든 IT 기능에 대한 라이센스가 필요합니다. 라이센스를 추가하려면 계정 &gt; 라이센스 로 이동하고 라이센스 추가 를 클릭한 다음 라이센스 파일을 업로드합니다.</block>
  <block id="54936e9fda3da1e56a25c0056f054bce" category="inline-image-macro">Astra Control Center에서 라이센스를 추가합니다</block>
  <block id="02fd0244de299d20dfbaf9113b883030" category="paragraph"><block ref="02fd0244de299d20dfbaf9113b883030" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2044ecf5033cd4a7b9530b83075af99e" category="admonition">NetApp Astra Control Center의 설치 또는 구성 관련 문제가 발생할 경우 알려진 문제에 대한 기술 자료를 이용할 수 있습니다<block ref="d775d2705bd260971e4d33c3d1094402" category="inline-link-rx"></block>.</block>
  <block id="9204faa817ce36107d052d3cd7c886c7" category="inline-link-macro">다음: Red Hat OpenShift Clusters: NetApp과 함께 Red Hat OpenShift를 등록하십시오.</block>
  <block id="8d167505bef11e381036abf56e79f457" category="paragraph"><block ref="8d167505bef11e381036abf56e79f457" category="inline-link-macro-rx"></block></block>
  <block id="344aeea955e7674b99b8e8db2354133d" category="doc">Astra Control Center를 사용한 워크로드 마이그레이션: NetApp의 Red Hat OpenShift</block>
  <block id="8fe3ce682e72fe87e56e5b11e1c2cd36" category="inline-link-macro">다음: 추가 정보: NetApp의 Red Hat OpenShift</block>
  <block id="5dbd13d011610e2b4d57bd4ca3fd685f" category="paragraph"><block ref="5dbd13d011610e2b4d57bd4ca3fd685f" category="inline-link-macro-rx"></block></block>
  <block id="eed1ab12478f3384bfca66e2b382aefc" category="doc">NetApp ONTAP를 사용하여 Red Hat OpenShift Virtualization 배포</block>
  <block id="7dc3a10e876dbab2b177f35c0b436f3a" category="list-text">RHCOS 작업자 노드가 있는 베어 메탈 인프라에 설치된 Red Hat OpenShift 클러스터(버전 4.6 이상</block>
  <block id="b5762731ee8c7a3d9a7ce9abe3804cf0" category="list-text">설치 관리자가 제공한 인프라(IPI)를 통해 OpenShift 클러스터를 설치해야 합니다.</block>
  <block id="7ed0bc09bfa62b64806b6b5c2f4378c7" category="list-text">VM에 대한 HA를 유지하기 위해 시스템 상태 점검을 구축합니다</block>
  <block id="43b1ab0e04b8f87e603cc790967d2886" category="list-text">NetApp ONTAP 클러스터</block>
  <block id="dc7ec0964c3d39892e26bbe1593a79e2" category="list-text">OpenShift 클러스터에 설치된 Astra Trident</block>
  <block id="d4c321b9edd8d817bdc7ca442e71e3af" category="list-text">ONTAP 클러스터에서 SVM으로 구성된 Trident 백엔드</block>
  <block id="e909486a42368b2659780687c3b4a31b" category="list-text">OpenShift 클러스터에 구성된 StorageClass로, Astra Trident를 프로비저닝자로 사용합니다</block>
  <block id="cfcf3a62902e36f3d966271cc090b65c" category="list-text">Red Hat OpenShift 클러스터에 대한 클러스터 관리자 액세스</block>
  <block id="af91af16b4791d61bb2e9206807a658d" category="list-text">NetApp ONTAP 클러스터에 대한 관리 액세스</block>
  <block id="e281839ef9ef6cb1eadcc2aa7d6d63be" category="list-text">tridentctl 및 OC 도구가 설치되고 $PATH에 추가된 관리 워크스테이션</block>
  <block id="314f04ff1024e623d43e0cda9a9df410" category="paragraph">OpenShift Virtualization은 OpenShift 클러스터에 설치된 운영자에 의해 관리되기 때문에 클러스터에 대한 하드웨어 요구 사항을 계획하는 동안 메모리, CPU 및 스토리지에 추가적인 오버헤드를 부과합니다. 설명서를 참조하십시오<block ref="f9421eaa4175c3e9f421a9acaf6f00d6" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="be51a7d8687b0a6254a274c1e0100052" category="paragraph">필요한 경우 노드 배치 규칙을 구성하여 OpenShift 가상화 운영자, 컨트롤러 및 VM을 호스팅하는 OpenShift 클러스터 노드의 하위 집합을 지정할 수도 있습니다. OpenShift 가상화를 위한 노드 배치 규칙을 구성하려면 설명서를 참조하십시오<block ref="325820076f9012df5bb7261c397a527f" category="inline-link-rx"></block>.</block>
  <block id="a805b74dbb589c916a1ebf0e08601665" category="paragraph">OpenShift 가상화를 지원하는 스토리지의 경우 전용 StorageClass를 사용하여 특정 Trident 백엔드의 스토리지를 요청한 다음, 전용 SVM을 통해 지원하는 것이 좋습니다. 이를 통해 OpenShift 클러스터에서 VM 기반 워크로드에 제공되는 데이터와 관련하여 멀티 테넌시의 수준을 유지할 수 있습니다.</block>
  <block id="adb787dc1bae0d1c8dee5bd61d49c235" category="inline-link-macro">다음: 연산자를 통해 배포합니다.</block>
  <block id="6166597c75dc82b2cc8c50a0d5d74400" category="paragraph"><block ref="6166597c75dc82b2cc8c50a0d5d74400" category="inline-link-macro-rx"></block></block>
  <block id="d55adbfc40b7bcdb0606eb0bd4d88cae" category="summary">이 섹션은 Astra Trident에서 제공하는 영구 저장소를 사용하여 개인 이미지 레지스트리를 만들고 구성하는 데 사용됩니다.</block>
  <block id="8252479af4b1df9b77ceaf67fa8cd07d" category="doc">개인 이미지 레지스트리 만들기</block>
  <block id="9c864113b9e4202e111b818a53d4f506" category="inline-link">키.오</block>
  <block id="4b4141875f954447d204e6f73d93e2a0" category="inline-link">DockerHub를 참조하십시오</block>
  <block id="508888fd9f92f35e5edd97bd8083e289" category="paragraph">같은 공용 레지스트리를 사용하여 대부분의 Red Hat OpenShift 배포에 사용됩니다<block ref="b9eeebbe4a68a648d570ea2173e5ef99" category="inline-link-rx"></block> 또는<block ref="0252a6b70cc5017fa1445a78532155b6" category="inline-link-rx"></block> 고객의 대부분의 요구사항을 충족합니다. 그러나 고객이 자신의 개인 또는 사용자 지정 이미지를 호스팅하려는 경우가 있습니다.</block>
  <block id="00a3f196d7f27a1f41f5d6a7f48759d0" category="paragraph">이 절차에서는 Astra Trident 및 NetApp ONTAP에서 제공하는 영구 볼륨의 지원을 받는 개인 이미지 레지스트리 만들기에 대해 설명합니다.</block>
  <block id="d9d5e29b1b83dd9c215f5ea158ca2475" category="admonition">Astra Control Center에는 Astra 컨테이너에 필요한 이미지를 호스팅하기 위한 레지스트리가 필요합니다. 다음 섹션에서는 Red Hat OpenShift 클러스터에 비공개 레지스트리를 설정하고 Astra Control Center 설치를 지원하는 데 필요한 이미지를 푸시하는 단계를 설명합니다.</block>
  <block id="3434f6853d017037506e47f83a18c3eb" category="section-title">개인 이미지 레지스트리를 만드는 중입니다</block>
  <block id="8b2aacc194c3dc4c36ce93a57e31685c" category="list-text">현재 기본 스토리지 클래스에서 기본 주석을 제거하고 OpenShift 클러스터의 기본값으로 Trident 지원 스토리지 클래스에 주석을 추가합니다.</block>
  <block id="9b1c6f527a1a481b925397807f319e71" category="list-text">'sepec' 부분에 다음과 같은 저장 매개변수를 입력하여 Imageregfollection 연산자를 편집합니다.</block>
  <block id="9ef71cd5ccaeb28206cd64b1d184019c" category="list-text">사용자 지정 호스트 이름을 사용하여 OpenShift 경로를 생성하기 위해 'sepec' 섹션에 다음 매개 변수를 입력합니다. 저장하고 종료합니다.</block>
  <block id="e0b23bc469102cf89472e5734da92a23" category="admonition">위 라우트 구성은 루트에 대한 사용자 지정 호스트 이름을 원하는 경우에 사용됩니다. OpenShift가 기본 호스트 이름을 사용하여 경로를 만들도록 하려면 'sepec' 섹션 ddefaultRoute: true'에 다음 매개 변수를 추가할 수 있습니다.</block>
  <block id="625bd6ae5e3ac822b187b90d50edb553" category="sidebar-title">사용자 지정 TLS 인증서</block>
  <block id="08e414328e39f86009287c06a5f23d23" category="paragraph">루트에 사용자 지정 호스트 이름을 사용하는 경우 기본적으로 OpenShift Ingress 연산자의 기본 TLS 구성을 사용합니다. 그러나 루트에 사용자 지정 TLS 구성을 추가할 수 있습니다. 이렇게 하려면 다음 단계를 완료하십시오.</block>
  <block id="60d14675c3111738a4ed19528764a7b1" category="list-text">루트의 TLS 인증서 및 키로 암호를 만듭니다.</block>
  <block id="47f7f890b5c1bcb52ae163771dbf35b0" category="list-text">Imageregfollerator를 편집하고 다음 파라미터를 'sepec' 섹션에 추가합니다.</block>
  <block id="9199ff34349c38138ad0275e447e6588" category="list-text">상상의 궤변운영자를 다시 편집하고 운영자의 관리상태를 마노화 상태로 변경합니다. 저장하고 종료합니다.</block>
  <block id="2bc42a1a9a963d9a3ff2118466e5db07" category="list-text">모든 전제 조건이 충족되면 개인 이미지 레지스트리에 대해 PVC, POD 및 서비스가 생성됩니다. 몇 분 후에 레지스트리가 가동되어야 합니다.</block>
  <block id="1f3713e339193dd15865ca74785eaa2c" category="list-text">수신 운영자 OpenShift 레지스트리 경로에 기본 TLS 인증서를 사용하는 경우 다음 명령을 사용하여 TLS 인증서를 가져올 수 있습니다.</block>
  <block id="295132dd97e1047a7c09e6a48054c469" category="list-text">OpenShift 노드가 레지스트리에 액세스하여 이미지를 가져올 수 있도록 하려면 OpenShift 노드의 Docker 클라이언트에 인증서를 추가합니다. TLS 인증서를 사용하여 OpenShift-config 네임스페이스에 configmap을 만들고 이를 클러스터 이미지 구성에 패치하여 인증서를 신뢰할 수 있도록 합니다.</block>
  <block id="98f3e484001465a59149c551e8d88cf0" category="list-text">OpenShift 내부 레지스트리는 인증에 의해 제어됩니다. 모든 OpenShift 사용자는 OpenShift 레지스트리에 액세스할 수 있지만 로그인한 사용자가 수행할 수 있는 작업은 사용자 권한에 따라 다릅니다.</block>
  <block id="561d4c8140016564eee98ecbc20f9add" category="list-text">사용자 또는 사용자 그룹이 레지스트리에서 이미지를 가져올 수 있도록 하려면 사용자에게 레지스트리 뷰어 역할이 할당되어 있어야 합니다.</block>
  <block id="88167e36ea0f872788407d0e01fc1382" category="list-text">사용자 또는 사용자 그룹이 이미지를 쓰거나 푸시할 수 있도록 하려면 사용자에게 레지스트리 편집기 역할이 할당되어 있어야 합니다.</block>
  <block id="5ba9e8f3c64be4c82249856cac87a071" category="list-text">OpenShift 노드가 레지스트리에 액세스하고 이미지를 푸시 또는 풀려면 풀 비밀을 구성해야 합니다.</block>
  <block id="86e93d266c168d718105c402f43fc91e" category="list-text">그런 다음 이 풀 암호는 serviceaccount에 패치하거나 해당 pod 정의에서 참조할 수 있습니다.</block>
  <block id="fe2033a9e377624583baa802ffd9ce6d" category="list-text">서비스 계정에 패치를 적용하려면 다음 명령을 실행합니다.</block>
  <block id="59bd1dbdd3278e23e67bcabffbc4d55a" category="list-text">POD 정의의 Pull Secret을 참조하려면, 'sepec' 부분에 다음 파라미터를 추가한다.</block>
  <block id="c0c3b4069e9a2e249507f67a6a2a3b07" category="list-text">OpenShift 노드 이외의 워크스테이션에서 이미지를 푸시하거나 풀려면 다음 단계를 완료하십시오.</block>
  <block id="18f8bf05a7a278e63d921de74d2a5966" category="list-text">Docker 클라이언트에 TLS 인증서를 추가합니다.</block>
  <block id="312eaa3acf94b813cfe857f63a602724" category="list-text">OC 로그인 명령을 사용하여 OpenShift에 로그인합니다.</block>
  <block id="cb4744e00672fbf6eba33b1b86d23ae0" category="list-text">podman/docker 명령을 사용하여 OpenShift 사용자 자격 증명을 사용하여 레지스트리에 로그인합니다.</block>
  <block id="53557215e4d209eda16495dbe5f7c505" category="paragraph">+참고: kubadmin 사용자를 사용하여 개인 레지스트리에 로그인하는 경우 암호 대신 토큰을 사용합니다.</block>
  <block id="aa20d170f1ff336ec9079cf6dd1ccee3" category="list-text">이미지를 밀거나 당깁니다.</block>
  <block id="7f3417590f5bba5cf5eb34fb288135f1" category="inline-link-macro">다음으로: 솔루션 검증/사용 사례: NetApp 및 Red Hat OpenShift</block>
  <block id="7a38916784a7216f98837f315958c175" category="paragraph"><block ref="7a38916784a7216f98837f315958c175" category="inline-link-macro-rx"></block></block>
  <block id="b1a934cbded2602c4186fb43d7c8a986" category="paragraph">특정 사용 사례에 따라 컨테이너 및 가상 머신(VM)이 서로 다른 유형의 애플리케이션에 대한 최적의 플랫폼 역할을 할 수 있습니다. 따라서 많은 조직에서 일부 워크로드를 컨테이너와 VM에서 실행합니다. 조직에서는 VM용 하이퍼바이저 및 애플리케이션용 컨테이너 오케스트레이터라는 별도의 플랫폼을 관리해야 하기 때문에 추가적인 과제에 직면하게 됩니다.</block>
  <block id="7652dcfa1608f7891f4e5c9b462354be" category="paragraph">이러한 과제를 해결하기 위해 Red Hat은 OpenShift 버전 4.6부터 OpenShift Virtualization(이전의 컨테이너 네이티브 가상화)을 도입했습니다. OpenShift Virtualization 기능을 사용하면 동일한 OpenShift Container Platform 설치에서 컨테이너와 함께 가상 시스템을 실행 및 관리할 수 있으므로, 하이브리드 관리 기능을 통해 운영자를 통해 VM의 배포 및 관리를 자동화할 수 있습니다. OpenShift에서 VM을 생성하는 것 외에도 Red Hat은 OpenShift 가상화를 통해 VMware vSphere, Red Hat 가상화 및 Red Hat OpenStack Platform 배포에서 VM 가져오기를 지원합니다.</block>
  <block id="269bac1ed5128eacc45c06318333642a" category="image-alt">OpenShift 가상화</block>
  <block id="bf4e72937ad57bd2f780561c81d25d53" category="paragraph">NetApp ONTAP에서 지원하는 ACstra Trident의 도움을 받아 실시간 VM 마이그레이션, VM 디스크 클로닝, VM 스냅샷 등의 특정 기능도 OpenShift Virtualization에서 지원됩니다. 이러한 각 워크플로의 예는 이 문서의 뒷부분에서 해당 섹션에서 설명합니다.</block>
  <block id="8a5bcb32f7cb878beee68d6f84b3ada7" category="paragraph">Red Hat OpenShift Virtualization에 대한 자세한 내용은 설명서를 참조하십시오<block ref="3339eb5909b80aa35681f9f3f9478c17" category="inline-link-rx"></block>.</block>
  <block id="2bd77ae4e72f37c837a2da8cfa83e210" category="inline-link-macro">다음: 배포 전제 조건.</block>
  <block id="3a86ddb85761278fa813d15edecbc2b1" category="paragraph"><block ref="3a86ddb85761278fa813d15edecbc2b1" category="inline-link-macro-rx"></block></block>
  <block id="35be109b995061abd3392d1b01fd0e9a" category="summary">Red Hat OpenStack Platform은 안전하고 안정적인 프라이빗 OpenStack 클라우드를 생성, 배포 및 확장할 수 있는 통합 기반을 제공합니다.</block>
  <block id="5f6a8f3661e7319797d4eab6792350e6" category="doc">Red Hat OpenStack Platform의 OpenShift</block>
  <block id="639813d9aa126816c3f9e9de2a45ce17" category="paragraph">OSP는 컴퓨팅, 스토리지 및 네트워킹 리소스를 관리하는 제어 서비스 모음을 통해 구현된 서비스형 인프라(IaaS) 클라우드입니다. 이 환경은 관리자와 사용자가 OpenStack 리소스를 제어, 프로비저닝 및 자동화할 수 있는 웹 기반 인터페이스를 통해 관리됩니다. 또한, OpenStack 인프라는 광범위한 명령줄 인터페이스와 API를 통해 관리자 및 최종 사용자를 위한 전체 자동화 기능을 지원합니다.</block>
  <block id="dc34aa9761794ceabad79dc29944976e" category="paragraph">OpenStack 프로젝트는 6개월마다 업데이트된 릴리즈를 제공하는, 빠르게 개발된 커뮤니티 프로젝트입니다. 초기 Red Hat OpenStack Platform은 모든 업스트림 릴리스와 함께 새 릴리스를 게시하고 모든 3차 릴리스에 대한 장기적인 지원을 제공함으로써 이 릴리스 주기를 따라가고 있습니다. 최근, OSP 16.0 릴리스(OpenStack Train 기반)를 통해 Red Hat은 릴리즈 번호를 따라가지 않고 새로운 기능을 하위 릴리즈로 백포팅했습니다. 최신 릴리즈는 Red Hat OpenStack Platform 16.1로, Ussuri 및 Victoria의 업스트림 릴리스에서 지원되는 고급 기능을 포함합니다.</block>
  <block id="737c38dd225185612ac8fa148ae9583e" category="inline-link">Red Hat OpenStack Platform 웹 사이트</block>
  <block id="19fb2090425be8f78441166e8f1d8d6f" category="paragraph">OSP에 대한 자세한 내용은 를 참조하십시오<block ref="9c79780f89511512bd5bf54ce21d04de" category="inline-link-rx"></block>.</block>
  <block id="e2ab8aafc6151adfa655ffd5d2425e7d" category="section-title">OpenStack 서비스</block>
  <block id="ffd7a6889e6ea6965969472250235082" category="paragraph">OpenStack 플랫폼 서비스는 컨테이너로 구축되며, 상호 서비스를 격리하고 간편하게 업그레이드할 수 있습니다. OpenStack 플랫폼은 Kolla로 구축 및 관리되는 컨테이너 세트를 사용합니다. 서비스 배포는 Red Hat Custom Portal에서 컨테이너 이미지를 가져와 수행합니다. 이러한 서비스 컨테이너는 Podman 명령을 사용하여 관리되며 Red Hat OpenStack Director를 통해 배포, 구성 및 관리됩니다.</block>
  <block id="f5fdcf6d68d437c59942a35d79b8c7b1" category="paragraph"><block ref="f5fdcf6d68d437c59942a35d79b8c7b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2ba7e785c49050f48da9aacc45c2b85" category="cell">서비스</block>
  <block id="7adea0d9c77aabccd8bb67ae0a832d59" category="cell">프로젝트 이름</block>
  <block id="2938c7f7e560ed972f8a4f68e80ff834" category="cell">대시보드</block>
  <block id="85fb7708d989f936cb51ef53a8af080f" category="cell">수평선</block>
  <block id="d5a9efab6df20a9e132b774795775dde" category="cell">OpenStack 서비스를 관리하는 데 사용하는 웹 브라우저 기반 대시보드</block>
  <block id="c9c5c65fb4af9cf90eb99b3b84424189" category="cell">아이덴티티</block>
  <block id="1ce2096c300f78bbb8389ca2603e6dd9" category="cell">키스톤</block>
  <block id="91c68681aadba9c0e8308f7d0b3cc416" category="cell">OpenStack 서비스의 인증 및 권한 부여와 사용자, 프로젝트, 역할 관리를 위한 중앙 집중식 서비스</block>
  <block id="e7a39f4cb0dd0ffaaffe8fb0319dec67" category="cell">OpenStack 네트워킹</block>
  <block id="88fac409baf592beb25e285d8663edcb" category="cell">중성자</block>
  <block id="0283e46fd80198d441eb742b88cf96f1" category="cell">OpenStack 서비스의 인터페이스 간 연결을 제공합니다.</block>
  <block id="4f0550f066ae72bb8c24fc3f59c323bf" category="cell">블록 스토리지</block>
  <block id="a7173cc5cdd0e31df00cd34f058b1d33" category="cell">신더</block>
  <block id="597dab3a2b3c74e3c266b2f65ec28619" category="cell">가상 머신(VM)에 대한 영구 블록 스토리지 볼륨을 관리합니다.</block>
  <block id="a623a8d0366bf079411aa30be45b2d10" category="cell">컴퓨팅</block>
  <block id="6e747c4965495f2e26bf17e647aa0083" category="cell">노바</block>
  <block id="f13c04e9c49274cd31bd8092c8f50304" category="cell">컴퓨팅 노드에서 실행 중인 VM을 관리하고 프로비저닝합니다.</block>
  <block id="10ec3a0506fab7073649337ca7be7979" category="cell">살펴보기</block>
  <block id="d9ff71ddcb6bbbe8ad48ae8b678369d4" category="cell">VM 이미지 및 볼륨 스냅샷과 같은 리소스를 저장하는 데 사용되는 레지스트리 서비스입니다.</block>
  <block id="670aaecb1a526fbed439dad3ec353a96" category="cell">오브젝트 스토리지</block>
  <block id="ae832e9b5bda2699db45f3fa6aa8c556" category="cell">스위프트</block>
  <block id="41c380458dfcdc118ef573a2d98c6acb" category="cell">사용자가 파일과 임의 데이터를 저장 및 검색할 수 있습니다.</block>
  <block id="aa96a21412def0d916f43b639424f8e4" category="cell">원격 측정</block>
  <block id="8fb4b5e28f192236eaa9e4972f810dbd" category="cell">Ceilometer를 참조하십시오</block>
  <block id="ed622b9c64858cc66a01c58893b5d39d" category="cell">클라우드 리소스의 사용량을 측정합니다.</block>
  <block id="7d486371bb65b0633535ceba4189d8ed" category="cell">열</block>
  <block id="abaa6ebae60b74638c54a43f3341db8e" category="cell">리소스 스택의 자동 생성을 지원하는 템플릿 기반 오케스트레이션 엔진입니다.</block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">네트워크 설계</block>
  <block id="5ddbd3cec63b14995bf6a5823b692de7" category="paragraph">NetApp OpenShift with NetApp 솔루션은 두 개의 데이터 스위치를 사용하여 25Gbps의 기본 데이터 연결을 제공합니다. 또한 스토리지 노드의 대역 내 관리를 위해 1Gbps에서 연결을 제공하는 두 개의 추가 관리 스위치와 IPMI 기능의 대역 외 관리를 사용합니다.</block>
  <block id="b81a67bf2ab52e16a62a9c71454c90ee" category="paragraph">IPMI 기능은 Red Hat OpenStack Director에서 아이러닉 베어 메탈 프로비저닝 서비스를 사용하여 Red Hat OpenStack Platform을 배포하는 데 필요합니다.</block>
  <block id="f1744781b12c15ad3b748bea44d9582b" category="section-title">VLAN 요구 사항</block>
  <block id="c546b983b02d8654c5b245147d99dcf0" category="paragraph">NetApp의 Red Hat OpenShift는 가상 VLAN(Local Area Network)을 사용하여 네트워크 트래픽을 논리적으로 다른 용도로 분리할 수 있도록 설계되었습니다. 이 구성은 고객의 요구에 맞게 확장하거나 특정 네트워크 서비스에 대한 추가 격리를 제공할 수 있습니다. 다음 표에는 NetApp 솔루션의 유효성을 검사하는 동안 솔루션을 구현하는 데 필요한 VLAN이 나와 있습니다.</block>
  <block id="87495e311a3944910e3cc0c7bee3d754" category="cell">VLAN</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="cell">목적</block>
  <block id="05808f0e86c04c2a062c2e041f9e0827" category="cell">VLAN ID입니다</block>
  <block id="b7dff125c9fce628900142990708436f" category="cell">대역외 관리 네트워크</block>
  <block id="414b4843c124e72b43bccf2948a53a41" category="cell">물리적 노드 관리 및 아론용 IPMI 서비스에 사용되는 네트워크.</block>
  <block id="567f5ee3e60ecdd5338b39cab0006510" category="cell">향상시킵니다</block>
  <block id="e8cbca2d71bd2aeff622a07b4ffad6c2" category="cell">컨트롤러 노드에서 볼륨을 직접 매핑하여 Swift와 같은 인프라 서비스를 지원하는 데 사용되는 네트워크입니다.</block>
  <block id="757b505cfd34c64c85ca5b5690ee5293" category="cell">201</block>
  <block id="e103375dfc18f23e4fc072903e894fe9" category="cell">스토리지 Cinder</block>
  <block id="0bdfa6389eb47674a02f6049f342785d" category="cell">블록 볼륨을 매핑하고 환경에 구축된 가상 인스턴스에 직접 연결하는 데 사용되는 네트워크입니다.</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="772d9a23b79ccb504fa0590644934c3b" category="cell">내부 API</block>
  <block id="e44f5f63400b0975b884dc2980ee3a61" category="cell">API 통신, RPC 메시지 및 데이터베이스 통신을 사용하여 OpenStack 서비스 간의 통신에 사용되는 네트워크.</block>
  <block id="34ed066df378efacc9b924ec161e7639" category="cell">301</block>
  <block id="6252d0571760e3d285e2e41a2b1e7743" category="cell">테넌트</block>
  <block id="ea414c629935302b115bf3dabf5f827c" category="cell">Neutron은 VXLAN을 통한 터널링을 통해 각 테넌트에 자체 네트워크를 제공합니다. 네트워크 트래픽은 각 테넌트 네트워크 내에서 격리됩니다. 각 테넌트 네트워크에는 연결된 IP 서브넷이 있으며, 네트워크 네임스페이스는 여러 테넌트 네트워크에서 충돌을 일으키지 않고 동일한 주소 범위를 사용할 수 있음을 의미합니다.</block>
  <block id="577bcc914f9e55d5e4e4f82f9f00e7d4" category="cell">302)를 참조하십시오</block>
  <block id="bfd15aa26ba0ced782240c4a8b7e517e" category="cell">스토리지 관리</block>
  <block id="cdc529b5e11a981e4597195c5f1c53b5" category="cell">OpenStack Object Storage(Swift)는 이 네트워크를 사용하여 참여하는 복제본 노드 간에 데이터 객체를 동기화합니다. 프록시 서비스는 사용자 요청과 기본 스토리지 계층 간의 중간 인터페이스 역할을 합니다. 프록시는 들어오는 요청을 수신하고 요청된 데이터를 검색하는 데 필요한 복제본을 찾습니다.</block>
  <block id="11b9842e0a271ff252c1903e7132cd68" category="cell">303</block>
  <block id="5214f1e2490f3878e307fd6f81f9f77f" category="cell">PXE 를 참조하십시오</block>
  <block id="16d856c79e739181f35adfe5b791c650" category="cell">OpenStack Director는 OSP Overcloud 설치를 조율하기 위해 아이러니한 베어 메탈 프로비저닝 서비스의 일부로 PXE 부팅을 제공합니다.</block>
  <block id="966b6dfb6b0819cc10644bea3115cf20" category="cell">3484</block>
  <block id="b206a1b4ea1097761f78e8876f6da779" category="cell">외부</block>
  <block id="f2feccaa3f5d086f0b16010ff463e369" category="cell">공개적으로 제공되는 네트워크로, 그래픽 관리용 OpenStack Dashboard(Horizon)를 호스팅하고 퍼블릭 API를 사용하여 OpenStack 서비스를 관리할 수 있습니다.</block>
  <block id="dfeb9598fbfb97cc6bbcc0aff2c785d6" category="cell">3485</block>
  <block id="7b9993fac4b9a60605aa2884eb40f4a3" category="cell">대역내 관리 네트워크</block>
  <block id="32223320445c4cf46444e40ebde18b7e" category="cell">SSH 액세스, DNS 트래픽 및 NTP(Network Time Protocol) 트래픽과 같은 시스템 관리 기능에 대한 액세스를 제공합니다. 이 네트워크는 컨트롤러 노드가 아닌 노드의 게이트웨이 역할도 합니다.</block>
  <block id="ab4f2b5fd96ca65349119909c1eada2d" category="cell">3486</block>
  <block id="35b5078b5953437a59ffd4f77c464800" category="section-title">네트워크 인프라 지원 리소스</block>
  <block id="0bad9231e1bf61bc343a986739f155c1" category="paragraph">OpenShift Container Platform을 배포하기 전에 다음 인프라를 구축해야 합니다.</block>
  <block id="f2260a90424f1d412334d1b3467abd22" category="list-text">전체 호스트 이름 확인을 제공하는 DNS 서버가 하나 이상 있어야 합니다.</block>
  <block id="d70672769aa84f2a999291a645e67355" category="list-text">솔루션의 서버에 대해 시간을 동기화할 수 있는 NTP 서버가 3개 이상 있습니다.</block>
  <block id="478a3526bd6097c6b7a330fd6aae410e" category="list-text">(선택 사항) OpenShift 환경을 위한 아웃바운드 인터넷 연결</block>
  <block id="a181412a291a7d0ae8a71300abf746b8" category="section-title">운영 구축 모범 사례</block>
  <block id="0f19aa91cffca51fd061e34dee1e5c79" category="paragraph">이 섹션에는 이 솔루션을 운영 환경에 구축하기 전에 고려해야 하는 몇 가지 모범 사례가 나와 있습니다.</block>
  <block id="9a14258452ea5da50d562e08e5b9291c" category="section-title">최소 3개의 컴퓨팅 노드를 포함하는 OSP 프라이빗 클라우드에 OpenShift를 배포합니다</block>
  <block id="493fd05bc58266bcd8394072cbe81748" category="paragraph">이 문서에 설명된 검증된 아키텍처는 OSP 컨트롤러 노드 3개와 OSP 컴퓨팅 노드 2개를 구축하여 HA 운영에 적합한 최소 하드웨어 구축을 보여줍니다. 이 아키텍처는 두 컴퓨팅 노드가 가상 인스턴스를 시작하고 구축된 VM이 두 하이퍼바이저 간에 마이그레이션할 수 있는 내결함성 구성을 보장합니다.</block>
  <block id="ebe803a768c48af52bca59e6ab7df9bf" category="paragraph">Red Hat OpenShift는 처음에 3개의 마스터 노드와 함께 배포되기 때문에 2노드 구성으로 인해 같은 노드를 차지하는 마스터가 2개 이상 생길 수 있으며, 이로 인해 특정 노드를 사용할 수 없게 되면 OpenShift에 장애가 발생할 수 있습니다. 따라서 OpenShift 마스터를 균등하게 배포하고 솔루션에서 추가적인 내결함성을 얻을 수 있도록 최소 3개의 OSP 컴퓨팅 노드를 구축하는 것이 Red Hat의 모범 사례입니다.</block>
  <block id="7a595c63e0ebc069af3da46e3d1c8fee" category="section-title">가상 머신/호스트 선호도를 구성합니다</block>
  <block id="bbfdc160550acbcdb4791a961a165d5d" category="paragraph">VM/호스트 선호도를 활성화하여 여러 하이퍼바이저 노드에 OpenShift 마스터를 분산시킬 수 있습니다.</block>
  <block id="cb346122cae28dfb1fcf0811f46296a2" category="paragraph">유사성은 VM 및/또는 호스트 세트에 대한 규칙을 정의하는 방법으로, VM이 그룹의 동일한 호스트 또는 호스트에서 함께 실행되는지 아니면 다른 호스트에서 실행되는지를 결정합니다. VM 및/또는 동일한 매개 변수와 조건 집합을 가진 호스트로 구성된 선호도 그룹을 생성하여 VM에 적용됩니다. 선호도 그룹의 VM이 그룹의 동일한 호스트에서 실행되는지, 아니면 다른 호스트에서 개별적으로 실행되는지에 따라 선호도 그룹의 매개 변수는 양의 선호도 또는 음의 선호도를 정의할 수 있습니다. Red Hat OpenStack Platform에서는 서버 그룹을 생성하고 필터를 구성하여 호스트 친화성 및 반유사성 규칙을 생성하고 적용할 수 있으므로 서버 그룹의 Nova에서 구축한 인스턴스가 서로 다른 컴퓨팅 노드에 배포됩니다.</block>
  <block id="9c0af999b760fac2aa82d9d105fa7a7e" category="paragraph">서버 그룹에는 배치를 관리할 수 있는 최대 10개의 가상 인스턴스가 기본적으로 있습니다. Nova에 대한 기본 할당량을 업데이트하여 이 할당량을 수정할 수 있습니다.</block>
  <block id="de5bd213c3df23736df75636241f96de" category="admonition">OSP 서버 그룹에 대해 특정 하드 선호도/반선호도 제한이 있습니다. 별도의 노드에 구축할 리소스가 충분하지 않거나 노드 공유를 허용하는 리소스가 충분하지 않으면 VM이 부팅되지 않습니다.</block>
  <block id="8aea038e418642b1735131358c24a866" category="inline-link">OpenStack 인스턴스에 대해 선호도 및 반유사성을 구성하려면 어떻게 합니까?</block>
  <block id="d90e13a49726d9175649113d81f4caa7" category="paragraph">선호도 그룹을 구성하려면 을 참조하십시오<block ref="f5b5be16184c5362a1ca218025e91581" category="inline-link-rx"></block>.</block>
  <block id="ed3ecd4254cc054c70ddee702d7ed519" category="section-title">OpenShift 배포에 사용자 지정 설치 파일을 사용합니다</block>
  <block id="5e059b05dcf86db414d6b8cdd66bcf0f" category="paragraph">IPI를 사용하면 이 문서 앞부분에서 설명한 대화형 마법사를 통해 OpenShift 클러스터를 쉽게 배포할 수 있습니다. 그러나 클러스터 배포의 일부로 일부 기본값을 변경해야 할 수도 있습니다.</block>
  <block id="47a822101acb11c74a4877a3d0b77093" category="inline-link">Red Hat OpenShift 사용자 지정을 통해 OpenStack에 클러스터 설치</block>
  <block id="42bb5e38e5b1c611bdce679410b24d67" category="paragraph">이 경우 클러스터를 즉시 배포하지 않고 wizardarder를 실행하고 작업을 수행할 수 있습니다. 대신 나중에 클러스터를 배포할 수 있는 구성 파일이 생성됩니다. IPI 기본값을 변경해야 하거나 다중 테넌시와 같은 다른 용도로 환경에 여러 동일한 클러스터를 배포하려는 경우 매우 유용합니다. OpenShift에 대한 사용자 지정 설치 구성을 만드는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="05810b34cd92ddfe8fd049160cb24f72" category="inline-link-rx"></block>.</block>
  <block id="f5b3b6b5d5a71b2934abd61ddb561ce2" category="inline-link-macro">다음은 NetApp 스토리지 개요입니다.</block>
  <block id="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="paragraph"><block ref="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="inline-link-macro-rx"></block></block>
  <block id="43288d8129021b1fe8b4bc6784e65b32" category="doc">기능: NetApp OpenShift에서 Kubernetes용 고급 클러스터 관리</block>
  <block id="de59be6e44d20d9dd12412571b745c5f" category="section-title">애플리케이션 라이프사이클 관리</block>
  <block id="fa19c463235a810b3a93333d6ee51d6c" category="paragraph">애플리케이션을 생성하고 클러스터 세트 전반에서 관리하려면,</block>
  <block id="920db239cf01c8ded4b7f364194ab540" category="list-text">측면 표시줄에서 애플리케이션 관리 로 이동하고 애플리케이션 생성 을 클릭합니다. 만들려는 응용 프로그램의 세부 정보를 입력하고 저장 을 클릭합니다.</block>
  <block id="6b41f909eb299f214abfb15580583456" category="image-alt">응용 프로그램을 만듭니다</block>
  <block id="bcb3e5b76f189a87ea350550f86de83f" category="list-text">응용 프로그램 구성 요소가 설치되면 응용 프로그램이 목록에 나타납니다.</block>
  <block id="d70fc022d09a33f4044c81cd670a71b6" category="image-alt">응용 프로그램 목록</block>
  <block id="672d326704c3be4bebf6c816a48495e7" category="list-text">이제 콘솔에서 애플리케이션을 모니터링 및 관리할 수 있습니다.</block>
  <block id="0787d747a308cc786b50363313ccf714" category="inline-link-macro">다음: 기능 - 거버넌스 및 위험.</block>
  <block id="f4c7ffc89dab76d5a6dccad54114c204" category="paragraph"><block ref="f4c7ffc89dab76d5a6dccad54114c204" category="inline-link-macro-rx"></block></block>
  <block id="1630dbfdd4887ce201ea82c71cde3d11" category="doc">Kubernetes용 고급 클러스터 관리 구축</block>
  <block id="39d08ecbb9add7bd87659df206457a73" category="list-text">허브 클러스터용 Red Hat OpenShift 클러스터(버전 4.5 이상</block>
  <block id="f41043c73a62a435944d8abfb45094cb" category="list-text">관리되는 클러스터를 위한 Red Hat OpenShift 클러스터(버전 4.4.3보다 큼</block>
  <block id="d60c66eb778a488709534045787b6a26" category="list-text">Red Hat OpenShift 클러스터에 대한 클러스터 관리자 액세스</block>
  <block id="374185e020d06ceed3f020af518a1c14" category="list-text">Kubernetes용 Advanced Cluster Management에 대한 Red Hat 서브스크립션</block>
  <block id="9afcd045ce0197d71ba631e3fbe43095" category="paragraph">Advanced Cluster Management는 OpenShift 클러스터를 위한 추가 기능으로, 허브 및 관리 클러스터에서 사용되는 기능을 기반으로 하드웨어 리소스에 대한 특정 요구 사항과 제한이 있습니다. 클러스터를 사이징할 때는 이러한 문제를 고려해야 합니다. 설명서를 참조하십시오<block ref="a5d2b81b971715f092f7296621743e22" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="65a62318377ddbc5fe3f73548dc3d677" category="paragraph">선택적으로 허브 클러스터에 인프라 구성 요소를 호스팅하는 전용 노드가 있고 해당 노드에만 고급 클러스터 관리 리소스를 설치하려면 해당 노드에 내약성과 선택기를 추가해야 합니다. 자세한 내용은 설명서를 참조하십시오<block ref="df4d7b25534e8f26e8ab3acc1c646101" category="inline-link-rx"></block>.</block>
  <block id="3f71071db67a1d6b5b63e2d9cc6b0e93" category="inline-link-macro">다음: 설치.</block>
  <block id="2a9cc50366c16ec40c1a5132f8fe5533" category="paragraph"><block ref="2a9cc50366c16ec40c1a5132f8fe5533" category="inline-link-macro-rx"></block></block>
  <block id="ad3a2e9007d848afd0c15ffc402781bb" category="doc">워크플로우: NetApp ONTAP 기반의 Red Hat OpenShift 가상화</block>
  <block id="4b6826f4f20a8e7e7a3b42ccb81d514f" category="section-title">VM 클로닝</block>
  <block id="4a56de086437c8a56c22bccd4e7ed9ba" category="paragraph">OpenShift에서 기존 VM의 복제는 Astra Trident의 Volume CSI 클로닝 기능을 통해 이루어집니다. CSI 볼륨 클로닝은 기존 PVC를 PV를 복제하여 데이터 소스로 사용하여 새로운 PVC를 생성할 수 있습니다. 새 PVC가 생성된 후, 별도의 요소로 작동하며 원본 PVC에 대한 링크 또는 종속성 없이 작동합니다.</block>
  <block id="0ea820e58acf3d0c3acac3f64518c517" category="image-alt">VM 클로닝 아키텍처</block>
  <block id="a1dbf280b3b5da141010127710d68ba7" category="paragraph">CSI 볼륨 클로닝에는 다음과 같은 몇 가지 제한 사항이 있습니다.</block>
  <block id="7f8cb9ac957166d3d134bf9df8861f5b" category="list-text">원본 PVC와 대상 PVC는 동일한 프로젝트에 있어야 합니다.</block>
  <block id="058d8141e417cb514573ba1a70e2e0cd" category="list-text">클론 복제는 동일한 스토리지 클래스 내에서 지원됩니다.</block>
  <block id="611b1b227968093cc5c73e69f7ac0fda" category="list-text">클론 복제는 소스 볼륨과 타겟 볼륨이 동일한 볼륨 모드 설정을 사용하는 경우에만 수행할 수 있습니다. 예를 들어 블록 볼륨은 다른 블록 볼륨에만 클론을 생성할 수 있습니다.</block>
  <block id="557d036c1a69ab0889c0820deb1e88de" category="paragraph">OpenShift 클러스터의 VM은 두 가지 방법으로 클론을 생성할 수 있습니다.</block>
  <block id="e1230e5b1f51d793ea14fb31df500399" category="list-text">소스 VM을 종료합니다</block>
  <block id="29ec5d7b455e19c4f8141df877a9af0a" category="list-text">소스 VM을 활성 상태로 유지합니다</block>
  <block id="84d19f7437a8329c49099517eccd37dc" category="section-title">소스 VM을 종료합니다</block>
  <block id="9057e692817874e4c563dec1fa8c1700" category="paragraph">VM을 종료하여 기존 VM을 복제하는 것은 Astra Trident의 지원을 통해 구현되는 네이티브 OpenShift 기능입니다. VM을 클론 복제하려면 다음 단계를 완료하십시오.</block>
  <block id="ea1abad541ee7994705555d53c0281c3" category="list-text">워크로드 &gt; 가상화 &gt; 가상 머신 으로 이동하고 복제할 가상 머신 옆에 있는 줄임표를 클릭합니다.</block>
  <block id="375000776ee4694734b1d066c46e7096" category="list-text">Clone Virtual Machine을 클릭하고 새 VM에 대한 세부 정보를 제공합니다.</block>
  <block id="b22c43b0906ef8ba78f3fbb7d5b1ff20" category="image-alt">VM을 복제합니다</block>
  <block id="cf702a835a3fd4b019603d29ec402106" category="list-text">Clone Virtual Machine을 클릭합니다. 그러면 소스 VM이 종료되고 클론 VM이 생성됩니다.</block>
  <block id="82cfb538b52ee01d4a9901d4d2cfad4d" category="list-text">이 단계가 완료된 후 복제된 VM의 컨텐츠를 액세스하고 확인할 수 있습니다.</block>
  <block id="3c7aa222cd4c9ee079b31567a347c05f" category="paragraph">기존 VM은 소스 VM의 기존 PVC를 클로닝한 다음 복제된 PVC를 사용하여 새 VM을 생성하여 복제할 수도 있습니다. 이 방법을 사용하면 소스 VM을 종료할 필요가 없습니다. 다음 단계를 완료하여 VM을 종료하지 않고 클론을 생성합니다.</block>
  <block id="81ab8abf2317781c0eb6f4deeaeea5a5" category="list-text">Storage &gt; PersistentVolumeClaims 로 이동하고 소스 VM에 연결된 PVC 옆에 있는 줄임표를 클릭합니다.</block>
  <block id="545ce69617c1c157be6073dcc63bfbae" category="list-text">Clone PVC(PVC 복제) 를 클릭하고 새 PVC에 대한 세부 정보를 제공합니다.</block>
  <block id="e659422cf737778a2fb1cdd50cc8003e" category="image-alt">PVC 복제</block>
  <block id="07c24ffdbaf9583216cca9f030058c11" category="list-text">그런 다음 클론 을 클릭합니다. 그러면 새 VM에 대한 PVC가 생성됩니다.</block>
  <block id="5ba8ff3c009683ee423b0884c25360d0" category="list-text">워크로드 &gt; 가상화 &gt; 가상 시스템으로 이동하고 생성 &gt; YAML을 클릭합니다.</block>
  <block id="cd32f6b0aebb29494cbc9cc21a10c926" category="list-text">SPEC&gt;template&gt;SPEC&gt;volumes 섹션에서 컨테이너 디스크 대신 복제된 PVC를 연결합니다. 요구 사항에 따라 새 VM에 대한 기타 모든 세부 정보를 제공합니다.</block>
  <block id="75b0d3500d81c7799a5b84eca57d6d04" category="list-text">생성 을 클릭하여 새 VM을 생성합니다.</block>
  <block id="19e005e0709674157e554800d5ea7ef9" category="list-text">VM이 성공적으로 생성된 후 새 VM이 소스 VM의 클론인지 액세스하고 확인합니다.</block>
  <block id="fdbfc131399a8776fecd30fa821de4d0" category="inline-link-macro">다음: 워크플로우: 스냅샷으로부터 VM을 생성하십시오.</block>
  <block id="c5c4205f35e83d4dc33cfa7821ceb5a7" category="paragraph"><block ref="c5c4205f35e83d4dc33cfa7821ceb5a7" category="inline-link-macro-rx"></block></block>
  <block id="c12328be87e4d79e79b3db80bd6ff03f" category="list-text">NetApp ONTAP 문서 센터</block>
  <block id="1b214ce6b630c9ad822fc984e20f3675" category="inline-link"><block ref="1b214ce6b630c9ad822fc984e20f3675" category="inline-link-rx"></block></block>
  <block id="91fe04078e98f81bd39430c985bba713" category="paragraph"><block ref="91fe04078e98f81bd39430c985bba713" category="inline-link-rx"></block></block>
  <block id="0b98c026ddf9e406d439373d2dab724b" category="inline-link"><block ref="0b98c026ddf9e406d439373d2dab724b" category="inline-link-rx"></block></block>
  <block id="63d46b0efa85a58196faf13e5aa20d7d" category="paragraph"><block ref="63d46b0efa85a58196faf13e5aa20d7d" category="inline-link-rx"></block></block>
  <block id="3c572f7c92d4b91543f94621d03cf993" category="list-text">Google Cloud의 Anthos</block>
  <block id="712cab3570d004ba67a47d7ff8df208b" category="inline-link"><block ref="712cab3570d004ba67a47d7ff8df208b" category="inline-link-rx"></block></block>
  <block id="a5526c10a9a8b42f6aab833b33a57eaf" category="paragraph"><block ref="a5526c10a9a8b42f6aab833b33a57eaf" category="inline-link-rx"></block></block>
  <block id="aa69ca65720dd2e4eef99ebfb7816268" category="list-text">Anthos의 Bare Metal</block>
  <block id="a3df86c144842761b9bcb0b540edbefe" category="inline-link"><block ref="a3df86c144842761b9bcb0b540edbefe" category="inline-link-rx"></block></block>
  <block id="8d3014f959efddffaea116898b063218" category="paragraph"><block ref="8d3014f959efddffaea116898b063218" category="inline-link-rx"></block></block>
  <block id="8921c6e9843ba7487c77f4dce1467111" category="summary">NetApp Element 소프트웨어는 모듈식의 확장 가능한 성능을 제공하며, 각 스토리지 노드는 환경에 보장된 용량과 처리량을 제공합니다. NetApp Element 시스템은 단일 클러스터에서 4개 노드에서 100개 노드로 확장할 수 있으며 다양한 고급 스토리지 관리 기능을 제공합니다.</block>
  <block id="5d77fe4a6bb4c5e88c5c18510b3c4749" category="doc">NetApp Element: NetApp의 Red Hat OpenShift</block>
  <block id="53c583e55a36ad49234df678a2dbcf45" category="paragraph">NetApp Element 소프트웨어는 모듈식의 확장 가능한 성능을 제공하며, 각 스토리지 노드는 환경에 보장된 용량과 처리량을 제공합니다. NetApp Element 시스템은 단일 클러스터에서 4개 노드에서 100개 노드로 확장할 수 있으며 다양한 고급 스토리지 관리 기능을 제공합니다.</block>
  <block id="22f48c519a73ce4759edffb196331422" category="paragraph"><block ref="22f48c519a73ce4759edffb196331422" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27765508a97a89684590658c3465fb70" category="inline-link">NetApp SolidFire 웹 사이트</block>
  <block id="d37eaafbb6dfb29673d63ff988ff4f41" category="paragraph">NetApp Element 스토리지 시스템에 대한 자세한 내용은 를 참조하십시오<block ref="0d1d77e6774527457304fa15f73899a1" category="inline-link-rx"></block>.</block>
  <block id="bd4ffcaabbe4a4f83fbfaaa2e34dc8a3" category="section-title">iSCSI 로그인 리디렉션 및 자동 복구 기능</block>
  <block id="dbafa7c074ef7efc3c778b69c0ad31b5" category="paragraph">NetApp Element 소프트웨어는 기존 TCP/IP 네트워크에서 SCSI 명령을 캡슐화하는 표준 방법인 iSCSI 스토리지 프로토콜을 활용합니다. SCSI 표준이 바뀌거나 이더넷 네트워크의 성능이 향상되면 iSCSI 스토리지 프로토콜이 아무런 변경 없이 이점을 제공합니다.</block>
  <block id="23e6b910b28346537f5696478fffe779" category="paragraph">모든 스토리지 노드에 관리 IP와 스토리지 IP가 있지만 NetApp Element 소프트웨어는 클러스터의 모든 스토리지 트래픽에 단일 스토리지 가상 IP 주소(SVIP 주소)를 알립니다. iSCSI 로그인 프로세스의 일환으로, 스토리지는 타겟 볼륨이 다른 주소로 이동되었다는 응답을 할 수 있으므로 협상 프로세스를 진행할 수 없습니다. 그런 다음 호스트는 호스트 측 재구성이 필요 없는 프로세스에서 새 주소로 로그인 요청을 다시 실행합니다. 이 프로세스를 iSCSI 로그인 리디렉션이라고 합니다.</block>
  <block id="b8603f3d585261d0005c7c5e51108d19" category="paragraph">iSCSI 로그인 리디렉션은 NetApp Element 소프트웨어 클러스터의 핵심 부분입니다. 호스트 로그인 요청이 수신되면 노드는 IOPS 및 볼륨의 용량 요구 사항에 따라 트래픽을 처리할 클러스터 구성원을 결정합니다. 볼륨은 NetApp Element 소프트웨어 클러스터에 분산되며, 단일 노드에서 해당 볼륨에 대해 너무 많은 트래픽을 처리하고 있거나 새 노드를 추가한 경우 재배포됩니다. 지정된 볼륨의 여러 복사본이 스토리지 전체에 할당됩니다.</block>
  <block id="772db62cf9ecb837ed4f0a91a5963492" category="paragraph">이러한 방식으로 노드 장애 후 볼륨 재배포가 수행되면 로그아웃 이후에 호스트 연결에 영향을 주지 않고 새 위치로 리디렉션하여 로그인할 수 있습니다. iSCSI 로그인 리디렉션을 사용하는 NetApp Element 소프트웨어 클러스터는 무중단 업그레이드 및 운영이 가능한 자동 복구, 스케일아웃 아키텍처입니다.</block>
  <block id="5c8e89de2b8e6e2f103d858b59e5aca0" category="section-title">NetApp Element 소프트웨어 클러스터 QoS</block>
  <block id="16600c3602f9acbaa2286f34135f6bb8" category="paragraph">NetApp Element 소프트웨어 클러스터를 사용하면 볼륨별로 QoS를 동적으로 구성할 수 있습니다. 볼륨당 QoS 설정을 사용하면 정의한 SLA에 따라 스토리지 성능을 제어할 수 있습니다. 다음과 같이 구성 가능한 세 가지 매개 변수는 QoS를 정의합니다.</block>
  <block id="d91a826908d0c27cf5d21d2152292ab0" category="list-text">* 최소 IOPS. * NetApp Element 소프트웨어 클러스터가 볼륨에 제공하는 최소 유지 IOPS 수입니다. 볼륨에 대해 구성된 최소 IOPS는 볼륨의 보장된 성능 수준입니다. 볼륨당 성능이 이 수준 아래로 떨어지지 않습니다.</block>
  <block id="f8cd3dfe225577e230dc2699ebbbfe34" category="list-text">* 최대 IOPS. * NetApp Element 소프트웨어 클러스터가 특정 볼륨에 제공하는 최대 지속 IOPS 수입니다.</block>
  <block id="827b5871d6ce8f2203a567ef3024f072" category="list-text">* 버스트 IOPS. * 짧은 버스트 시나리오에서 허용되는 최대 IOPS 수입니다. 버스트 지속 시간 설정은 기본 1분으로 구성할 수 있습니다. 볼륨이 최대 IOPS 레벨 미만으로 실행 중인 경우 버스트 크레딧이 누적됩니다. 성능 수준이 매우 높고 푸시되면 볼륨에서 최대 IOPS를 초과하는 짧은 IOPS 버스트가 허용됩니다.</block>
  <block id="e95bb6f1e85d1ffe0eb983fd5e0fbde8" category="section-title">멀티 테넌시</block>
  <block id="086d1eacd91102f734387f0266326344" category="paragraph">보안 멀티 테넌시는 다음과 같은 기능을 통해 구현됩니다.</block>
  <block id="97bee3e8d0db89b2cd19eba861763e7a" category="list-text">* 보안 인증. * CHAP(Challenge-Handshake Authentication Protocol)는 보안 볼륨 액세스에 사용됩니다. LDAP(Lightweight Directory Access Protocol)는 관리 및 보고를 위해 클러스터에 안전하게 액세스하는 데 사용됩니다.</block>
  <block id="3918507b16aa3cc38274c29da446d90f" category="list-text">* 볼륨 액세스 그룹(VAG). * 선택적으로 VAG를 인증 대신 사용하여 iSCSI 이니시에이터 관련 IQN(iSCSI 정규화된 이름)을 하나 이상의 볼륨에 매핑할 수 있습니다. vag의 볼륨에 액세스하려면 볼륨 그룹에 대해 이니시에이터 IQN이 허용된 IQN 목록에 있어야 합니다.</block>
  <block id="28328e0db9c18c9ada207997f806124f" category="list-text">* VLAN(Tenant Virtual LAN). * 네트워크 수준에서 VLAN을 사용하면 iSCSI 초기자와 NetApp Element 소프트웨어 클러스터 간의 엔드 투 엔드 네트워크 보안을 쉽게 유지할 수 있습니다. 워크로드 또는 테넌트를 격리하기 위해 생성된 모든 VLAN에 대해 NetApp Element 소프트웨어는 특정 VLAN을 통해서만 액세스할 수 있는 별도의 iSCSI 대상 SVIP 주소를 생성합니다.</block>
  <block id="5fec85270e969240cc769f429b9c8cdc" category="list-text">* VRF 지원 VLAN. * 데이터 센터의 보안 및 확장성을 더욱 지원하기 위해 NetApp Element 소프트웨어를 사용하면 VRF와 유사한 기능에 대한 테넌트 VLAN을 활성화할 수 있습니다. 이 기능은 다음과 같은 두 가지 주요 기능을 추가합니다.</block>
  <block id="fca8436836d48525b8d98babbfd68518" category="list-text">* 테넌트 SVIP 주소로 L3 라우팅 * 이 기능을 사용하면 NetApp Element 소프트웨어 클러스터의 VLAN 또는 별도의 네트워크에서 iSCSI 초기자를 설정할 수 있습니다.</block>
  <block id="eaea554ececf5b64515f0833c56b3de4" category="list-text">중복 또는 중복 IP 서브넷.* 이 기능을 사용하면 테넌트 환경에 템플릿을 추가할 수 있으므로 각 테넌트 VLAN에 동일한 IP 서브넷의 IP 주소를 할당할 수 있습니다. 이 기능은 IPspace의 규모 및 보존이 중요한 서비스 공급자 환경에 유용할 수 있습니다.</block>
  <block id="c08531651ee4977d5020da1b84003631" category="section-title">엔터프라이즈 스토리지 효율성</block>
  <block id="78712bd6b2d8e5531e122b5e849fb842" category="paragraph">NetApp Element 소프트웨어 클러스터는 전반적인 스토리지 효율성과 성능을 높여줍니다. 다음 기능은 인라인으로 수행되며 항상 켜져 있으며 사용자가 수동으로 구성할 필요가 없습니다.</block>
  <block id="6893566c26b28e197cebdefdcc6af3ae" category="list-text">* 데이터 중복 제거. * 이 시스템은 고유한 4K 블록만 저장합니다. 중복된 4K 블록이 이미 저장된 데이터 버전에 자동으로 연결됩니다. 데이터는 블록 드라이브에 있으며 NetApp Element 소프트웨어 Helix 데이터 보호를 사용하여 미러링됩니다. 이 시스템을 사용하면 시스템 내에서 용량 소비 및 쓰기 작업이 크게 줄어듭니다.</block>
  <block id="2e5dd3a69ccb3f04d7814fc742318204" category="list-text">* 압축. * 압축은 데이터를 NVRAM에 쓰기 전에 인라인으로 수행됩니다. 데이터가 압축되어 4K 블록으로 저장되고 시스템에서 압축된 상태로 유지됩니다. 이 압축을 통해 클러스터 전체의 용량 소비, 쓰기 작업 및 대역폭 사용량이 크게 줄어듭니다.</block>
  <block id="215de8162cb5ac909005881f92812fb0" category="list-text">* 씬 프로비저닝. * 이 기능은 필요한 시간에 적절한 양의 스토리지를 제공하여 오버프로비저닝된 볼륨 또는 충분히 활용되지 않는 볼륨으로 인한 용량 소비를 제거합니다.</block>
  <block id="95f1b89c8e9c330fcfdc8ec84633bfe6" category="list-text">* Helix. * 개별 볼륨의 메타데이터는 메타데이터 드라이브에 저장되며 이중화를 위해 보조 메타데이터 드라이브로 복제됩니다.</block>
  <block id="da9c9b2b4164632e569069fe1e7c53ee" category="admonition">요소는 자동화를 위해 설계되었습니다. 모든 스토리지 기능은 API를 통해 사용할 수 있습니다. 이러한 API는 UI에서 시스템을 제어하는 데 사용하는 유일한 방법입니다.</block>
  <block id="28bbba0205a8bfd9f8f2da8b73522dc7" category="inline-link-macro">다음으로, NetApp 스토리지 통합 개요를 살펴보겠습니다.</block>
  <block id="d61c98dcb4bec6f3e1213776ebb1e6c3" category="paragraph"><block ref="d61c98dcb4bec6f3e1213776ebb1e6c3" category="inline-link-macro-rx"></block></block>
  <block id="aa9095c5ba77e3549672e5c4fae1fedc" category="doc">베어 메탈 기반 OpenShift</block>
  <block id="a62e902f0d244d960eddf2f14d3afa6f" category="paragraph">베어 메탈 기반 OpenShift는 상용 서버에 OpenShift Container Platform을 자동으로 배포하는 기능을 제공합니다.</block>
  <block id="0e05c6235b67ae8e5b743c9ca77358fa" category="paragraph">베어 메탈 기반 OpenShift는 OpenShift의 가상 배포와 유사하며 컨테이너화 준비가 되지 않은 애플리케이션에 대해 가상화된 워크로드를 지원하는 동시에 OpenShift 클러스터의 간편한 배포, 신속한 프로비저닝 및 확장을 제공합니다. 베어 메탈에 배포하면 OpenShift 환경 외에도 호스트 하이퍼바이저 환경을 관리하는 데 필요한 추가 오버헤드가 필요하지 않습니다. 베어 메탈 서버에 직접 배포하면 호스트와 OpenShift 환경 간에 리소스를 공유하는 데 따른 물리적 오버헤드 제한도 줄일 수 있습니다.</block>
  <block id="67a3852a946bc539243cc1e5f8982d03" category="section-title">Bare Metal의 OpenShift는 다음과 같은 기능을 제공합니다.</block>
  <block id="9a3c3034787ddbd4af974d73f795c75a" category="list-text">IPI 또는 보조 설치 프로그램 배포.* 설치 관리자 프로비저닝 인프라(IPI)에 의해 배포된 OpenShift 클러스터를 베어메탈 서버에 배포하면 고객은 하이퍼바이저 계층을 관리할 필요 없이 다재다능하고 쉽게 확장 가능한 OpenShift 환경을 상용 서버에 직접 배포할 수 있습니다.</block>
  <block id="bf995f5252e568d22b265ec62c16914c" category="list-text">* 컴팩트 클러스터 설계. * 하드웨어 요구 사항을 최소화하기 위해 베어 메탈의 OpenShift를 사용하면 OpenShift 컨트롤 플레인 노드가 작업자 노드 및 호스트 컨테이너 역할을 할 수 있도록 하여 단 3개의 노드로 구성된 클러스터를 배포할 수 있습니다.</block>
  <block id="13442dfd439ae0a377b0a2d2d9df1709" category="list-text">OpenShift 가상화 * OpenShift는 OpenShift 가상화를 사용하여 컨테이너 내에서 가상 머신을 실행할 수 있습니다. 이 컨테이너 네이티브 가상화는 컨테이너 내부의 KVM 하이퍼바이저를 실행하며 VM 스토리지용 영구 볼륨을 연결합니다.</block>
  <block id="6e6a5272d3c6f8eceb96e3c19f0faaf6" category="list-text">* AI/ML 최적화 인프라 * GPU 기반 작업자 노드를 OpenShift 환경에 통합하고 OpenShift Advanced Scheduling을 활용하여 머신 러닝 애플리케이션을 위한 Kubeflow와 같은 애플리케이션을 배포합니다.</block>
  <block id="6bc136fcf409560a1029f6f323619bbf" category="paragraph">NetApp 기반 Red Hat OpenShift 솔루션은 2개의 데이터 스위치를 사용하여 25Gbps의 기본 데이터 연결을 제공합니다. 또한 스토리지 노드의 대역 내 관리를 위해 1Gbps의 접속 기능을 제공하는 관리 스위치 2개와 IPMI 기능의 대역 외 관리를 사용합니다.</block>
  <block id="17fea9675576fc9c72deb9501a5fd16a" category="paragraph">OpenShift Bare-Metal IPI 배포의 경우 별도의 네트워크에 네트워크 인터페이스가 연결되어 있어야 하는 Red Hat Enterprise Linux 8 시스템인 공급자 노드를 만들어야 합니다.</block>
  <block id="2f42f99315e0171a6e5c61957ae4689c" category="list-text">* 프로비저닝 네트워크. * 이 네트워크는 베어 메탈 노드를 부팅하고 OpenShift 클러스터를 배포하는 데 필요한 이미지와 패키지를 설치하는 데 사용됩니다.</block>
  <block id="aba727a2dc3dd836a33a2022bb2a9c3f" category="list-text">* 베어 메탈 네트워크. * 이 네트워크는 구축된 클러스터의 공용 통신에 사용됩니다.</block>
  <block id="7633522f66aaba6bc4bb2c25d299d287" category="paragraph">고객은 공급자 노드를 설정하기 위해 배포 목적으로 프로비저닝되는 부트스트랩 VM과 노드 자체에서 트래픽을 제대로 라우팅할 수 있도록 브리지 인터페이스를 생성합니다. 클러스터를 구축한 후에는 API 및 수신 VIP 주소가 부트스트랩 노드에서 새로 구축된 클러스터로 마이그레이션됩니다.</block>
  <block id="963d7d04e1f1692a7fc49ae899123dbd" category="paragraph">다음 이미지는 IPI 배포 중 및 배포 완료 후 환경을 보여줍니다.</block>
  <block id="096e71732ebcd1f43544a7159596cb17" category="paragraph"><block ref="096e71732ebcd1f43544a7159596cb17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb18861dc375756df1a31b7ed3c03f38" category="paragraph"><block ref="bb18861dc375756df1a31b7ed3c03f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a0639a1bbc3695e0ebaf4c3affe363" category="paragraph">NetApp OpenShift의 경우 가상 LAN(VLAN)을 사용하여 네트워크 트래픽을 논리적으로 다른 용도로 분리할 수 있도록 설계되었습니다.</block>
  <block id="3d9073c9e531118eb3aff0f20647c86f" category="cell">베어 메탈 노드 및 IPMI에 대한 관리</block>
  <block id="f53272342c85041784b2d5136e6eaa7d" category="cell">베어 메탈 네트워크</block>
  <block id="44a94f76baabd05ab407f76c946326c8" category="cell">클러스터를 사용할 수 있게 되면 OpenShift 서비스를 위한 네트워크가 형성됩니다</block>
  <block id="fc221309746013ac554571fbd180e1c8" category="cell">181</block>
  <block id="11405696f0e53417a3847f430a7b8ed0" category="cell">네트워크 프로비저닝</block>
  <block id="846325c36d78e7582d8bfcab277ca67a" category="cell">IPI를 통한 PXE 부팅 및 베어 메탈 노드 설치를 위한 네트워크</block>
  <block id="eb5f501445f81cb1f7f4cf290565f9c8" category="admonition">이러한 각 네트워크는 VLAN에 의해 가상으로 분리되지만 PXE 부팅 시퀀스 중에 VLAN 태그를 전달할 방법이 없으므로 각 물리적 포트는 기본 VLAN이 할당된 액세스 모드에서 설정해야 합니다.</block>
  <block id="3ab0ae61b5256f874297403903fd5afc" category="paragraph">OpenShift 컨테이너 플랫폼을 배포하기 전에 다음 인프라를 구축해야 합니다.</block>
  <block id="06a9d12a76441fd395abeba7bf0d7b91" category="list-text">대역내 관리 네트워크 및 VM 네트워크에서 액세스할 수 있는 전체 호스트 이름 확인을 제공하는 DNS 서버가 하나 이상 있어야 합니다.</block>
  <block id="905a394004d9055ec4708e53880cac66" category="list-text">대역내 관리 네트워크 및 VM 네트워크에서 액세스할 수 있는 NTP 서버가 하나 이상 있어야 합니다.</block>
  <block id="447cb4a01965e3df01476db3576e0399" category="list-text">(선택 사항) 대역내 관리 네트워크와 VM 네트워크 모두에 대한 아웃바운드 인터넷 연결.</block>
  <block id="b611590ed189a9cbc27648402168f00a" category="inline-link-macro">다음은 NetApp 스토리지 개요입니다.</block>
  <block id="2be0276ec05c9b03a47573ad9795095a" category="paragraph"><block ref="2be0276ec05c9b03a47573ad9795095a" category="inline-link-macro-rx"></block></block>
  <block id="25d77826c061b84a0c036f43e02aa129" category="doc">OpenShift Virtualization 설치: NetApp과 함께 Red Hat OpenShift의 설치</block>
  <block id="60423d24e49c8db4836be0abd09fb78d" category="doc">NetApp ONTAP iSCSI 구성</block>
  <block id="8e0bd613649f232fe1f718134898ea21" category="paragraph">NetApp ONTAP 스토리지 시스템과의 Trident 통합을 활성화하려면 스토리지 시스템과의 통신을 지원하는 백엔드를 생성해야 합니다.</block>
  <block id="3ca99f0e09d3b1ea097a113dd72c9317" category="list-text">다운로드한 설치 아카이브에서 사용할 수 있는 예제 백엔드 파일이 'ample-input' 폴더 계층에 있습니다. iSCSI를 지원하는 NetApp ONTAP 시스템의 경우 'backend-ontap-san.json' 파일을 작업 디렉토리에 복사하고 파일을 편집합니다.</block>
  <block id="fa346018b8222fdc195d0b73016cf5a0" category="list-text">이 파일에서 관리 LIF, dataLIF, svm, 사용자 이름 및 암호 값을 편집합니다.</block>
  <block id="38ace6c607c7db13cd4cc319f9b0225b" category="list-text">이 백엔드 파일을 배치하고 다음 명령을 실행하여 첫 번째 백엔드를 생성합니다.</block>
  <block id="d8f188eff4c16fa87dd87f51db847f73" category="list-text">백엔드가 생성되면 다음 번에 스토리지 클래스를 생성해야 합니다. 백엔드와 마찬가지로 샘플 입력 폴더에서 사용 가능한 환경에 대해 편집할 수 있는 샘플 스토리지 클래스 파일이 있습니다. 작업 디렉토리에 복사하고 생성된 백엔드를 반영하기 위해 필요한 편집을 수행합니다.</block>
  <block id="eb22c0d536e50f388da6dfd91ba4c0b6" category="list-text">이 파일에 대해 편집해야 하는 유일한 방법은 새로 생성된 백엔드에서 스토리지 드라이버의 이름으로 'backendType' 값을 정의하는 것입니다. 또한 이름 필드 값을 기록해 둡니다. 이 값은 나중에 참조해야 합니다.</block>
  <block id="3ae96676432caea17595a22525bd9660" category="admonition">이 파일에 정의된 fschType이라는 선택적 필드가 있습니다. iSCSI 백엔드에서 이 값은 특정 Linux 파일 시스템 유형(XFS, ext4 등)으로 설정하거나, OpenShift가 사용할 파일 시스템을 결정할 수 있도록 삭제할 수 있습니다.</block>
  <block id="7183f006fd74d941c838f003380f3f46" category="list-text">"OC" 명령을 실행하여 스토리지 클래스를 생성합니다.</block>
  <block id="71cb54ab06aa16af27a0ec2157972648" category="list-text">스토리지 클래스를 생성한 후 첫 번째 영구 볼륨 클레임(PVC)을 생성해야 합니다. 샘플 입력에도 이 작업을 수행하는 데 사용할 수 있는 PVC-BASIC.YAML 파일이 있습니다.</block>
  <block id="afc499f2f95809cedce5c8922067065f" category="list-text">이 파일에 대해 편집해야 하는 유일한 내용은 'torageClassName' 필드가 방금 만든 필드와 일치한다는 것입니다. PVC 정의는 프로비저닝할 작업 부하에 따라 필요에 따라 추가로 사용자 정의할 수 있습니다.</block>
  <block id="02eb9c3824b0b8eae9723daa7a2912d1" category="list-text">OC 명령을 실행하여 PVC를 생성한다. 생성 중인 백업 볼륨의 크기에 따라 생성 시간이 다소 걸릴 수 있으므로 완료 시 프로세스를 확인할 수 있습니다.</block>
  <block id="90dc29cb8c225faef816aefeaad3027d" category="inline-link-macro">다음으로 솔루션 검증/사용 사례를 살펴보겠습니다.</block>
  <block id="99632a9c8a0d8380e77d9d11f96edfdc" category="paragraph"><block ref="99632a9c8a0d8380e77d9d11f96edfdc" category="inline-link-macro-rx"></block></block>
  <block id="8b14fb34f5313442bf2fdc4d80edc389" category="summary">이 섹션에서는 NetApp 배포를 통해 Red Hat OpenShift를 사용자 지정하려는 사용자를 위한 로드 밸런싱 장치 옵션을 탐구하는 데 사용됩니다.</block>
  <block id="87beaa6eff6159cd7270b2a4e71c10a4" category="doc">로드 밸런싱 장치 옵션 알아보기: NetApp의 Red Hat OpenShift</block>
  <block id="a802e9436bb9bcbfa2b88bb549e28503" category="paragraph">대부분의 경우 Red Hat OpenShift는 경로를 통해 외부 세계에 애플리케이션을 제공합니다. 외부에서 연결할 수 있는 호스트 이름을 제공하여 서비스가 노출됩니다. 정의된 라우트와 서비스로 식별되는 엔드포인트는 OpenShift 라우터에서 외부 클라이언트에 명명된 연결을 제공하기 위해 사용될 수 있습니다.</block>
  <block id="0aa971b4d33bdc82c500a35166e588c8" category="paragraph">그러나 경우에 따라 적절한 서비스를 제공하기 위해 응용 프로그램에서 사용자 지정 로드 밸런싱 장치를 구축하고 구성해야 하는 경우도 있습니다. 한 가지 예로는 NetApp Astra Control Center가 있습니다. 이러한 요구 사항을 충족하기 위해 다양한 사용자 지정 로드 밸런서 옵션을 평가했습니다. 설치 및 구성에 대한 자세한 내용은 이 섹션을 참조하십시오.</block>
  <block id="6914d9014ff3e2cb99cabff26b55a0bc" category="paragraph">다음 페이지에서는 NetApp OpenShift에서 검증된 로드 밸런서 옵션에 대한 추가 정보를 제공합니다.</block>
  <block id="2b545f7c547a71eaeda9dcb451aea0c5" category="inline-link-macro">메탈리스</block>
  <block id="eaefba36e93c0d0177c3de1143bd08dd" category="list-text"><block ref="eaefba36e93c0d0177c3de1143bd08dd" category="inline-link-macro-rx"></block></block>
  <block id="10a93051f49f4080568cecc5ec30cd99" category="inline-link-macro">F5 BIG-IP</block>
  <block id="886218e92c071e06819887a13189b4e6" category="list-text"><block ref="886218e92c071e06819887a13189b4e6" category="inline-link-macro-rx"></block></block>
  <block id="0f07e63979900ab2abf6d2d578850a47" category="inline-link-macro">다음으로: 솔루션 검증/사용 사례: NetApp 및 Red Hat OpenShift</block>
  <block id="3a29a96f08f4066b544db012326464ed" category="paragraph"><block ref="3a29a96f08f4066b544db012326464ed" category="inline-link-macro-rx"></block></block>
  <block id="3605e05aa598ff405b5edffc1bf474f1" category="summary">NetApp과 함께 Red Hat OpenShift에서 멀티 테넌시 구성</block>
  <block id="13148717f8faa9037f37d28971dfc219" category="doc">검증</block>
  <block id="286c0d2f200233e63709210881b700c4" category="paragraph">이전 단계에서 구성한 멀티테넌트 아키텍처를 확인하려면 다음 단계를 수행하십시오.</block>
  <block id="627fd2c5e0310dc7409ea377e5d13045" category="section-title">할당된 프로젝트에서 PVC 또는 POD를 생성하기 위한 액세스를 검증합니다</block>
  <block id="f4da6475fc7e97756adf2751840e077d" category="list-text">PROJECT-1의 개발자인 OCP-PROJECT-1-USER로 로그인합니다.</block>
  <block id="2d7fbbcee3114769610fea6ef6f4cdf0" category="list-text">새 프로젝트를 만들려면 액세스 권한을 확인하십시오.</block>
  <block id="12cdc5f68c3a0ca10544c0a57e866249" category="list-text">PROJECT-1에 할당된 storageclass를 사용하여 PROJECT-1에서 PVC를 생성한다.</block>
  <block id="145d2249af633a497182f76e714d1f2e" category="list-text">PVC와 관련된 PV를 확인한다.</block>
  <block id="d424ec829e7a6f56de4d74835b97103a" category="list-text">PV 및 해당 볼륨이 NetApp ONTAP의 PROJECT-1 전용 SVM에서 생성되었는지 확인합니다.</block>
  <block id="a345b6be662b316a3b3e3cfbc7566b31" category="list-text">PROJECT-1에서 POD를 생성하고 이전 단계에서 만든 PVC를 마운트합니다.</block>
  <block id="7b929f9e235c85c6b73ed2ee867c5514" category="list-text">POD가 실행 중이고 볼륨이 마운트되어 있는지 확인합니다.</block>
  <block id="8c9885c86a67cc4c47a30d7e8d14badb" category="section-title">다른 프로젝트에서 PVC 또는 POD를 생성하거나 다른 프로젝트 전용 리소스를 사용하도록 액세스를 검증합니다</block>
  <block id="8e27501b578972bd7b65468deaa482ca" category="list-text">PROJECT-2에 할당된 storageclass를 사용하여 PROJECT-1에서 PVC를 생성한다.</block>
  <block id="71bc5a6f1f0141981e0034b388233917" category="list-text">PROJECT-2에서 PVC를 작성합니다.</block>
  <block id="1149bf04288dfa82d0e3b713a6e66aa1" category="list-text">PVC의 TEST-PVC-PROJECT-1-SC-2, TEST-PVC-PROJECT-2-SC-1이 생성되지 않았는지 확인한다.</block>
  <block id="0d843e91c3b8f62457e19b2d32ecace3" category="list-text">PROJECT-2에서 POD를 작성합니다.</block>
  <block id="83aa0a39007c30e71adde6fbf8180d9f" category="section-title">프로젝트, 리소스 할당량 및 StorageClasses를 보고 편집하려면 액세스 권한을 확인합니다</block>
  <block id="43700888cdcd166f379f95bd1751ae63" category="list-text">새 프로젝트를 만들려면 액세스 권한을 선택합니다.</block>
  <block id="32579947c29f341292c3ce775140178b" category="list-text">프로젝트 보기에 대한 액세스 권한 확인</block>
  <block id="9e97a1398bb4a0499bb69bf1c9e67d6a" category="list-text">사용자가 PROJECT-1에서 ResourceQuotas를 보거나 편집할 수 있는지 확인합니다.</block>
  <block id="17a658c4329ed475a82d2e02c0406118" category="list-text">사용자가 스토리지 시스템을 볼 수 있는 액세스 권한이 있는지 확인합니다.</block>
  <block id="aa177e49bfc4cc0182f57218ce6bdd4d" category="list-text">스토리지 풀 설명을 위한 액세스를 확인하십시오.</block>
  <block id="997cef2cfb8ccc12d8739c63e69794f3" category="list-text">스토리지 풀 편집을 위한 사용자 액세스 권한 검증</block>
  <block id="9eb6f7c0e27dd8274a30b43a4aee8d53" category="inline-link-macro">다음: 확장.</block>
  <block id="acd8a990c476bd6cb45a9044361ba723" category="paragraph"><block ref="acd8a990c476bd6cb45a9044361ba723" category="inline-link-macro-rx"></block></block>
  <block id="e690fa655ec589e6d0abb58164d5ccfd" category="doc">추가 정보: NetApp의 Red Hat OpenShift</block>
  <block id="1be465260df7c846768e06c988594a6a" category="paragraph">이 문서에 설명된 정보에 대한 자세한 내용은 다음 웹 사이트를 참조하십시오.</block>
  <block id="6f4e4d9fbe846fd8bf7decf7dcffbd63" category="list-text">NetApp 문서</block>
  <block id="1497398039e94eb756be9a3cff5649c7" category="inline-link"><block ref="1497398039e94eb756be9a3cff5649c7" category="inline-link-rx"></block></block>
  <block id="f2d3084aa0f70da5e15757ee3292cda7" category="paragraph"><block ref="f2d3084aa0f70da5e15757ee3292cda7" category="inline-link-rx"></block></block>
  <block id="824bd84e05db30b27e73f839dae3b8e5" category="list-text">Astra Trident 문서</block>
  <block id="fe549ebd8a3f0fea1803cbaa947ef198" category="list-text">NetApp Astra Control Center 문서</block>
  <block id="ad837604b59ea6a89754d8e75f595c7b" category="inline-link"><block ref="ad837604b59ea6a89754d8e75f595c7b" category="inline-link-rx"></block></block>
  <block id="4af69e66dd3d513168080d177919dd21" category="paragraph"><block ref="4af69e66dd3d513168080d177919dd21" category="inline-link-rx"></block></block>
  <block id="21b11dbf6ab3c6d36a76f280fe8ec75d" category="list-text">Red Hat OpenShift 설명서</block>
  <block id="74201863479cf5c9b89330c920283301" category="inline-link"><block ref="74201863479cf5c9b89330c920283301" category="inline-link-rx"></block></block>
  <block id="3e10ed3875c45f9dc9064324660fc2b1" category="paragraph"><block ref="3e10ed3875c45f9dc9064324660fc2b1" category="inline-link-rx"></block></block>
  <block id="06fd33ae9f869a89e860634ec94b9793" category="list-text">Red Hat OpenStack 플랫폼 문서</block>
  <block id="647d438a62673b6a6c9830682f6bc128" category="inline-link"><block ref="647d438a62673b6a6c9830682f6bc128" category="inline-link-rx"></block></block>
  <block id="705a39bc1a12c50103a847633c3f7493" category="paragraph"><block ref="705a39bc1a12c50103a847633c3f7493" category="inline-link-rx"></block></block>
  <block id="8d79e9650a1f62f89d77743225e203c0" category="list-text">Red Hat 가상화 문서</block>
  <block id="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link"><block ref="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link-rx"></block></block>
  <block id="6d6038842b529e3d97aa9a8a9d81d866" category="paragraph"><block ref="6d6038842b529e3d97aa9a8a9d81d866" category="inline-link-rx"></block></block>
  <block id="4666fc2f640685636f115f8b2b6b8ce0" category="list-text">VMware vSphere 설명서</block>
  <block id="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link"><block ref="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link-rx"></block></block>
  <block id="71aa41fc980571d5a324adedae614f9c" category="paragraph"><block ref="71aa41fc980571d5a324adedae614f9c" category="inline-link-rx"></block></block>
  <block id="e38be1dc20a2b358b917b60fe2677b39" category="doc">NetApp Element iSCSI 구성</block>
  <block id="dc5fa659e0452a77d6006f5b72f8b334" category="paragraph">NetApp Element 스토리지 시스템과의 Trident 통합을 활성화하려면 iSCSI 프로토콜을 사용하여 스토리지 시스템과의 통신을 지원하는 백엔드를 생성해야 합니다.</block>
  <block id="05ca7295321cb9b417a251e75557c6c5" category="list-text">다운로드한 설치 아카이브에서 사용할 수 있는 예제 백엔드 파일이 'ample-input' 폴더 계층에 있습니다. iSCSI를 지원하는 NetApp Element 시스템의 경우 'backend-solidfire.json' 파일을 작업 디렉토리로 복사하고 파일을 편집합니다.</block>
  <block id="27ef1192cd037c8978195be045fa054e" category="list-text">끝점 줄에서 사용자, 암호, MVIP 값을 편집합니다.</block>
  <block id="d1b7418d19df7144a98dfde725db068c" category="list-text">VIP 값을 편집합니다.</block>
  <block id="dd7f72325e6f60ea7163b071e4d5e2cc" category="list-text">이 백엔드 파일을 배치하고 다음 명령을 실행하여 첫 번째 백엔드를 생성합니다.</block>
  <block id="b73d05719d0ea2964c963f6f83a34d3d" category="admonition">이 파일에 정의된 fschType이라는 선택적 필드가 있습니다. iSCSI 백엔드에서 이 값은 특정 Linux 파일 시스템 유형(XFS, ext4 등)으로 설정하거나 OpenShift가 사용할 파일 시스템을 결정할 수 있도록 삭제할 수 있습니다.</block>
  <block id="fb12e7f50899cc1254f9a6f1e0341423" category="summary">Astra Control Center를 사용하여 사후 분석 애플리케이션을 복제하고 CI/CD 파이프라인에서 애플리케이션을 복원합니다</block>
  <block id="bc42bbaf219349a2ba37dfd4709b2003" category="doc">NetApp Astra Control을 활용하여 사후 분석 및 애플리케이션 복원을 수행합니다</block>
  <block id="4e42a1e911325b5048e50f7b5ea73d1f" category="section-title">VM 실시간 마이그레이션</block>
  <block id="7df52e0f8b2cb2af1e107fde51d06945" category="paragraph">실시간 마이그레이션은 다운타임 없이 OpenShift 클러스터에서 한 노드에서 다른 노드로 VM 인스턴스를 마이그레이션하는 프로세스입니다. OpenShift 클러스터에서 라이브 마이그레이션을 사용하려면 공유 ReadWriteMany 액세스 모드를 사용하여 VM을 PVC에 바인딩해야 합니다. NFS 프로토콜에 사용하도록 설정된 NetApp ONTAP 클러스터의 SVM으로 구성된 Astra Trident 백엔드는 PVC에 대한 공유 ReadWriteMany 액세스를 지원합니다. 따라서 Trident가 NFS 지원 SVM에서 프로비저닝한 StorageClasses에서 PVC가 있는 VM을 다운타임 없이 마이그레이션할 수 있습니다.</block>
  <block id="09e113cd46b4487f140ee07899ea3359" category="image-alt">VM 실시간 마이그레이션 아키텍처</block>
  <block id="660b7fa756d01df7c4338afb9050abb1" category="paragraph">공유된 ReadWriteMany 액세스를 사용하여 PVC에 바인딩된 VM을 생성하려면 다음을 수행합니다.</block>
  <block id="842f7d4793f116332f5b12b648dfd539" category="list-text">워크로드 &gt; 가상화 &gt; 가상 시스템 으로 이동하고 생성 &gt; 마법사 사용 을 클릭합니다.</block>
  <block id="416d6e9d0df33a74dd38603be60453c1" category="list-text">원하는 운영 체제를 선택하고 Next(다음) 를 클릭합니다. 선택한 OS에 이미 부팅 소스가 구성되어 있다고 가정하겠습니다.</block>
  <block id="e1b595d3037639bdea165dde4b1f3906" category="list-text">검토 및 생성 창에서 VM을 생성할 프로젝트를 선택하고 VM 세부 정보를 제공합니다. 선택한 OS에 적합한 PVC를 지정하여 부트 소스를 클론으로 선택하고 CD-ROM에서 부팅하십시오.</block>
  <block id="998a8df469c318f9cd606b44664cea5d" category="list-text">가상 시스템 사용자 지정 을 클릭한 다음 저장소 를 클릭합니다.</block>
  <block id="ae024d48dbfaaf4badad7bf9c812a98f" category="list-text">rootdisk 옆에 있는 줄임표를 클릭하고 Trident를 사용하여 프로비저닝된 스토리지 클래스를 선택합니다. 고급 을 확장하고 액세스 모드로 공유 액세스(rwx) 를 선택합니다. 저장을 클릭합니다.</block>
  <block id="ef44ba6bf4a3e677b41b361628554b88" category="image-alt">디스크 rwx에 액세스할 수 있도록 합니다</block>
  <block id="2ae6b586f76075c7d71faff7ba9d2a41" category="list-text">검토 및 확인 을 클릭한 다음 가상 시스템 생성 을 클릭합니다.</block>
  <block id="18c830e61a7a92c60804118ef362933c" category="paragraph">OpenShift 클러스터의 다른 노드로 VM을 수동으로 마이그레이션하려면 다음 단계를 완료하십시오.</block>
  <block id="289f346dbeb0185de2648a24955ca887" category="list-text">워크로드 &gt; 가상화 &gt; 가상 시스템으로 이동합니다.</block>
  <block id="cc58a226305ad2362de0317c1fd8261b" category="list-text">마이그레이션할 VM의 경우 줄임표를 클릭한 다음 가상 시스템 마이그레이션 을 클릭합니다.</block>
  <block id="b5839595a4132807edfc858d9f6d90ad" category="list-text">메시지가 나타나면 마이그레이션 을 클릭하여 확인합니다.</block>
  <block id="d0f501bd9588700bc91fe10b7d3f761a" category="admonition">devictionStrategy 가 LiveMigrate 로 설정된 경우 원래 노드를 유지 관리 모드로 전환하면 OpenShift 클러스터의 VM 인스턴스가 다른 노드로 자동 마이그레이션됩니다.</block>
  <block id="ca77161ad6ca11bca347f347b181c25f" category="inline-link-macro">다음으로, 워크플로우: VM 클로닝</block>
  <block id="294f8e986041208286bb2300b191a2ff" category="paragraph"><block ref="294f8e986041208286bb2300b191a2ff" category="inline-link-macro-rx"></block></block>
  <block id="c48db988cd283c11f89d4dd85803ec0a" category="doc">NetApp과 함께 Red Hat OpenShift에서 멀티 테넌시를 구성합니다</block>
  <block id="6d72da55d82cdd434045ba5df1a959b6" category="paragraph">컨테이너에서 여러 애플리케이션 또는 워크로드를 실행하는 많은 조직에서는 애플리케이션 또는 작업 부하당 하나의 Red Hat OpenShift 클러스터를 배포하는 경향이 있습니다. 이를 통해 애플리케이션 또는 워크로드에 대한 엄격한 격리를 구현하고 성능을 최적화하며 보안 취약점을 줄일 수 있습니다. 그러나 각 애플리케이션에 대해 별도의 Red Hat OpenShift 클러스터를 배포하면 자체 문제가 발생합니다. 또한 각 클러스터를 단독으로 모니터링 및 관리해야 하는 운영 오버헤드가 늘어나고, 다양한 애플리케이션을 위한 전용 리소스로 비용이 증가하며, 효율적인 확장성을 저해합니다.</block>
  <block id="332dcd535fa9ce865f462efb80829a35" category="paragraph">이러한 문제를 해결하기 위해 단일 Red Hat OpenShift 클러스터에서 모든 애플리케이션 또는 워크로드를 실행하는 것을 고려할 수 있습니다. 그러나 이러한 아키텍처에서 리소스 격리 및 애플리케이션 보안 취약점은 주요 과제 중 하나입니다. 한 워크로드의 보안 취약점이 다른 작업 부하로 자연스럽게 유출되어 영향 영역이 증가할 수 있습니다. 또한 한 응용 프로그램에서 갑자기 제어되지 않는 리소스 사용률은 기본적으로 리소스 할당 정책이 없기 때문에 다른 응용 프로그램의 성능에 영향을 줄 수 있습니다.</block>
  <block id="14a9bacc4b197037f54eb0c4c7e1970c" category="paragraph">따라서 조직에서는 단일 클러스터에서 모든 워크로드를 실행하면서 각 워크로드별로 전용 클러스터의 이점을 제공하는 동시에 두 환경 모두에서 최상의 솔루션을 찾는 것이 좋습니다.</block>
  <block id="73c1b26ace2fc5fca6e6e78c00a61837" category="paragraph">이러한 효과적인 솔루션 중 하나는 Red Hat OpenShift에서 멀티 테넌시를 구성하는 것입니다. 멀티 테넌시는 리소스, 보안 등을 적절하게 격리하여 동일한 클러스터에서 여러 테넌트를 함께 사용할 수 있는 아키텍처입니다. 이 컨텍스트에서 테넌트는 특정 사용자 그룹이 단독으로 사용하도록 구성된 클러스터 리소스의 하위 집합으로 볼 수 있습니다. Red Hat OpenShift 클러스터에서 멀티 테넌시를 구성하면 다음과 같은 이점이 있습니다.</block>
  <block id="cde9f9f8fcae0cdc6624895868803d60" category="list-text">클러스터 리소스를 공유하여 CapEx 및 OpEx 절감</block>
  <block id="943a49720e6c85fa9692af2a5ebd8829" category="list-text">운영 및 관리 오버헤드 감소</block>
  <block id="f51a58b3ab19c778652fcff9dd39ca55" category="list-text">보안 침해의 교차 오염으로부터 워크로드를 보호합니다</block>
  <block id="181cfddfdb055879df4d55323a14c473" category="list-text">리소스 경합으로 인해 예기치 않은 성능 저하로부터 워크로드 보호</block>
  <block id="f3ff3f5b3c67fb47bb8ec0f2f688b97d" category="paragraph">완전히 실현된 멀티테넌트 OpenShift 클러스터의 경우 컴퓨팅, 스토리지, 네트워킹, 보안 등과 같은 다양한 리소스 버킷에 속하는 클러스터 리소스에 대해 할당량 및 제한을 구성해야 합니다. 이 솔루션에서 모든 리소스 버킷의 특정 측면을 다루지만, NetApp은 NetApp ONTAP가 지원하는 Astra Trident에 의해 동적으로 할당된 스토리지 리소스에서 멀티테넌시를 구성하여 동일한 Red Hat OpenShift 클러스터에서 여러 워크로드에서 제공 또는 소비되는 데이터를 격리하고 보호하는 모범 사례에 초점을 맞춥니다.</block>
  <block id="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="paragraph"><block ref="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="inline-link-macro-rx"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="doc">구성</block>
  <block id="44b1200b793638d4a3aebd1bee591e12" category="paragraph">모든 멀티테넌트 솔루션의 경우 사용자는 필요한 것보다 더 많은 클러스터 리소스에 액세스할 수 없습니다. 따라서 다중 테넌시 구성의 일부로 구성할 전체 리소스 세트는 클러스터 관리자, 스토리지 관리자 및 각 프로젝트를 작업하는 개발자가 구성합니다.</block>
  <block id="1ceba10f8902735a18e8c3bb3e8a3052" category="paragraph">다음 표에는 여러 사용자가 수행해야 하는 여러 작업이 정리되어 있습니다.</block>
  <block id="064dceba374668ef0734be5f9e182682" category="cell">* 클러스터 관리자 *</block>
  <block id="445b72f2cbecd97022bb6636eda3cbc7" category="cell">다양한 애플리케이션 또는 워크로드를 위한 프로젝트를 생성합니다</block>
  <block id="e033ab3bea3b8a20afb5852070df0203" category="cell">storage-admin에 대한 ClusterRoles 및 RoleBindings를 생성합니다</block>
  <block id="293d08622718634a8518b6fcc6376617" category="cell">특정 프로젝트에 대한 액세스를 할당하는 개발자를 위한 역할 및 RoleBindings를 만듭니다</block>
  <block id="3e97e469255cd3686174c371f50961f9" category="cell">[선택 사항] 특정 노드에서 Pod를 예약하도록 프로젝트를 구성합니다</block>
  <block id="93ffd2b1215bc47cc78b020f89e922ef" category="cell">* 스토리지 - 관리자 *</block>
  <block id="043ab42cdcbdacc4691c26ee52ed8ccd" category="cell">NetApp ONTAP에서 SVM을 생성합니다</block>
  <block id="be09a24f118a66330a40633e9d5ebfca" category="cell">Trident 백엔드를 생성합니다</block>
  <block id="55995e8c220e05b3e75252cccf5752be" category="cell">StorageClasses를 생성합니다</block>
  <block id="2a5eb41b2d7fd04d01836f89ab790852" category="cell">스토리지 리소스 할당량을 생성합니다</block>
  <block id="4e00898ecc4e6640083ccff8d85fbe87" category="cell">개발자 *</block>
  <block id="bfc5fb8ef5464441bc8b3ca7eda2892d" category="cell">할당된 프로젝트에서 PVC 또는 POD를 생성하거나 패치하기 위한 액세스를 검증합니다</block>
  <block id="9e95c94350b2b7b51176ad958deb1388" category="cell">다른 프로젝트에서 PVC 또는 POD를 생성하거나 패치하기 위한 액세스를 검증합니다</block>
  <block id="8c0b7954d326b4bcf2f42a57ef00eead" category="cell">프로젝트, 리소스 할당량 및 StorageClasses를 보거나 편집하려면 액세스 유효성을 검사합니다</block>
  <block id="4edd9914739183e9cb724a222261a01f" category="inline-link-macro">다음: 필수 구성 요소.</block>
  <block id="8013a47a037d25fa6d9671120cfc1ee5" category="paragraph"><block ref="8013a47a037d25fa6d9671120cfc1ee5" category="inline-link-macro-rx"></block></block>
  <block id="482f4dddd14a12f4ece48aef54de313c" category="summary">Red Hat OpenShift Container Platform은 온프레미스 인프라와 하이브리드 클라우드 인프라 전반에서 개발 및 IT 운영을 단일 플랫폼에서 통합하여 애플리케이션을 일관되게 개발, 배포 및 관리합니다. Red Hat OpenShift는 컨테이너 기반 워크로드를 위해 설계된 세계 최고의 엔터프라이즈 Linux 배포판인 Kubernetes 및 Red Hat Enterprise Linux CoreOS를 비롯한 오픈 소스 혁신과 업계 표준을 기반으로 구축되었습니다.</block>
  <block id="f122078c68f20c36897fec8a7c4a23e8" category="doc">OpenShift 개요</block>
  <block id="e68e90b5707502c9f2fc1361ac071b3d" category="paragraph">Red Hat OpenShift Container Platform은 온프레미스 인프라와 하이브리드 클라우드 인프라 전반에서 개발 및 IT 운영을 단일 플랫폼에서 통합하여 애플리케이션을 일관되게 개발, 배포 및 관리합니다. Red Hat OpenShift는 컨테이너 기반 워크로드를 위해 설계된 세계 최고의 엔터프라이즈 Linux 배포판인 Kubernetes 및 Red Hat Enterprise Linux CoreOS를 비롯한 오픈 소스 혁신과 업계 표준을 기반으로 구축되었습니다. OpenShift는 CNCF(Cloud Native Computing Foundation) 인증 Kubernetes 프로그램의 일부로, 컨테이너 워크로드의 이동성과 상호 운용성을 제공합니다.</block>
  <block id="b2b7104a419a54dcb2763bddc6a0a47c" category="section-title">Red Hat OpenShift는 다음과 같은 기능을 제공합니다.</block>
  <block id="d383250f88949df87bac7768b697ccb6" category="list-text">* 셀프 서비스 프로비저닝. * 개발자는 가장 많이 사용하는 툴을 사용하여 필요에 따라 애플리케이션을 쉽고 빠르게 만들 수 있으며, 운영 환경은 전체 환경을 완벽하게 제어할 수 있습니다.</block>
  <block id="df45d857ed72e8e5ed370c6fdfd1e305" category="list-text">* 영구 스토리지. * OpenShift Container Platform은 영구 스토리지를 지원하므로 상태 저장 애플리케이션과 클라우드 네이티브 상태 비저장 애플리케이션을 모두 실행할 수 있습니다.</block>
  <block id="29ee9790b817110f2303080d5b295946" category="list-text">* CI/CD(Continuous Integration and Continuous Development). * 이 소스 코드 플랫폼은 규모에 따라 빌드 및 배포 이미지를 관리합니다.</block>
  <block id="a0f0997dded25d9aa9c767f29c17c249" category="list-text">* 오픈 소스 표준. * 이러한 표준은 컨테이너 오케스트레이션을 위한 오픈 컨테이너 이니셔티브(OCI)와 Kubernetes를 기타 오픈 소스 기술과 통합합니다. 귀사는 특정 공급업체의 기술 로드맵 또는 비즈니스 로드맵에 제한되지 않습니다.</block>
  <block id="7dc3d12ecda66373091607ba18ef4434" category="list-text">CI/CD 파이프라인 * OpenShift는 CI/CD 파이프라인에 대한 기본 지원을 제공하므로 개발 팀이 애플리케이션 제공 프로세스의 모든 단계를 자동화하고 애플리케이션의 코드 또는 구성에 대한 모든 변경 사항을 실행할 수 있습니다.</block>
  <block id="95e4c6a8e27cc92068d97ef795477714" category="list-text">* 역할 기반 액세스 제어(RBAC). * 이 기능은 대규모 개발자 그룹을 구성하는 데 도움이 되는 팀 및 사용자 추적 기능을 제공합니다.</block>
  <block id="d565eddf8e07af916519ec07f8712204" category="list-text">* 자동 구축 및 배포. * OpenShift는 개발자가 컨테이너화된 애플리케이션을 구축하거나 애플리케이션 소스 코드 또는 바이너리에서 컨테이너를 구축할 수 있는 플랫폼을 제공합니다. 그런 다음, 이 플랫폼은 애플리케이션에 대해 정의된 특성을 기반으로 인프라 전반에서 이러한 애플리케이션을 자동으로 구축합니다. 예를 들어, 할당되어야 하는 리소스의 양과 타사 라이센스를 준수하기 위해 구축해야 하는 인프라스트럭처의 위치 등을 예로 들 수 있습니다.</block>
  <block id="4fe0bdfd5a2ae34ba1a93860fd91d2fd" category="list-text">* 일관된 환경 * OpenShift는 개발자와 애플리케이션 라이프사이클 전반에 걸쳐 운영 체제, 라이브러리, 런타임 버전(예: Java 런타임), 또한 일관성 없는 환경에서 발생한 위험을 제거하기 위해 사용 중인 응용 프로그램 런타임(예: tomcat)도 마찬가지입니다.</block>
  <block id="64f8957eb1a3bb6a1e9ebd391e76925a" category="list-text">* 구성 관리. * 구성 및 중요 데이터 관리는 플랫폼에 내장되어 있어 응용 프로그램을 빌드하는 데 사용되는 기술이나 배포된 환경에 관계 없이 일관성 있고 환경 제한이 없는 응용 프로그램 구성이 응용 프로그램에 제공되도록 합니다.</block>
  <block id="5efb308bdb8052c1aa3fe8333f459fe5" category="list-text">* 응용 프로그램 로그 및 메트릭 * 신속한 피드백은 응용 프로그램 개발의 중요한 요소입니다. OpenShift의 통합 모니터링 및 로그 관리 기능을 통해 개발자에게 즉각적인 메트릭을 제공하여 애플리케이션이 변경 내용 전반에 걸쳐 어떻게 동작하는지 연구하고 애플리케이션 수명 주기 동안 가능한 한 빨리 문제를 해결할 수 있도록 합니다.</block>
  <block id="8c2b388bd42b0b6bae19890633c98a8d" category="list-text">* 보안 및 컨테이너 카탈로그. * OpenShift는 멀티 테넌시를 제공하고 SELinux(Security-Enhanced Linux), CGroup, seccomp(Secure Computing Mode)와 함께 보안 설정을 사용하여 컨테이너를 격리 및 보호함으로써 유해한 코드 실행으로부터 사용자를 보호합니다. 또한 다양한 하위 시스템에 대한 TLS 인증서를 통한 암호화 및 Red Hat 인증 컨테이너(access.redhat.com/containers 액세스할 수 있습니다. 이 컨테이너는 보안 강화, 신뢰 및 보안 애플리케이션 컨테이너를 최종 사용자에게 제공하기 위해 스캔 및 등급이 정해졌습니다.</block>
  <block id="16c321ec2744799f0acef92ce84d06ca" category="paragraph"><block ref="16c321ec2744799f0acef92ce84d06ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe8c2f8039053e077a0ca678496b72aa" category="section-title">Red Hat OpenShift의 배포 방법</block>
  <block id="9c2dd02f13d452b4422ac6c864933f01" category="paragraph">Red Hat OpenShift 4부터 OpenShift를 위한 배포 방법에는 고도의 맞춤형 배포를 위한 UPI(User Provisioned Infrastructure)를 사용한 수동 배포 또는 IPI(Installer Provisioned Infrastructure)를 사용한 완전 자동화된 배포가 포함됩니다.</block>
  <block id="68dc46cb39cdfc93e4593bbdd5c218cf" category="paragraph">IPI 설치 방법은 대부분의 경우 개발, 테스트 및 생산 환경에 OCP 클러스터를 신속하게 배포할 수 있기 때문에 선호되는 방법입니다.</block>
  <block id="ec55e5ffb2376dada4b2eb066c1fd9fd" category="section-title">Red Hat OpenShift의 IPI 설치</block>
  <block id="a91a379e59fea6610134af1efa3dfe87" category="paragraph">OpenShift의 설치 관리자 프로비저닝 인프라(IPI) 배포에는 다음과 같은 고급 단계가 포함됩니다.</block>
  <block id="d1befa03c79ca0b84ecc488dea96bc68" category="inline-link">웹 사이트</block>
  <block id="a07879007b1202a533ff3ef18bc0d197" category="list-text">Red Hat OpenShift를 방문하십시오<block ref="36af4d1b80928d398e137421c95a1013" category="inline-link-rx"></block> SSO 자격 증명을 사용하여 로그인합니다.</block>
  <block id="66f8ff89bd2c9146cb3273d416c60fd2" category="list-text">Red Hat OpenShift를 배포할 환경을 선택하십시오.</block>
  <block id="cc66c30273a9be504b88d3239e65516b" category="paragraph"><block ref="cc66c30273a9be504b88d3239e65516b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5806bcee67fc8f13f0255068a186e42" category="list-text">다음 화면에서 설치 관리자, 고유한 풀 암호 및 관리용 CLI 툴을 다운로드합니다.</block>
  <block id="86b43786316d35748685c4f7abc4145b" category="paragraph"><block ref="86b43786316d35748685c4f7abc4145b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9a2aa5906b4dad4a982c3a9c51d31f3" category="list-text">를 따릅니다<block ref="04512308a1627dc41acfeed51ef16ba3" category="inline-link-rx"></block> Red Hat이 선택한 환경에 배포할 수 있도록 제공합니다.</block>
  <block id="220887aee59c37fa79fc366cba7dad4e" category="section-title">NetApp은 OpenShift 구축을 검증했습니다</block>
  <block id="d711fd24836980dd490f3c01dd3ee8de" category="paragraph">NetApp은 다음과 같은 각 데이터 센터 환경에서 IPI(Installer provisioned Infrastructure) 배포 방법을 사용하여 랩에서 Red Hat OpenShift의 배포를 테스트하고 검증했습니다.</block>
  <block id="fecab6277bc7322982f127ce83dee308" category="list-text"><block ref="fecab6277bc7322982f127ce83dee308" category="inline-link-macro-rx"></block></block>
  <block id="ff3de63c4917b45d20525986d5b29962" category="list-text"><block ref="ff3de63c4917b45d20525986d5b29962" category="inline-link-macro-rx"></block></block>
  <block id="f88eb30a75027b557910958c7306cb4e" category="inline-link-macro">Red Hat Virtualization의 OpenShift</block>
  <block id="92fb5c16a9f212d49c0c5fb48ebc9144" category="list-text"><block ref="92fb5c16a9f212d49c0c5fb48ebc9144" category="inline-link-macro-rx"></block></block>
  <block id="2772c11e552b243e60a34490c4174ff9" category="inline-link-macro">VMware vSphere의 OpenShift입니다</block>
  <block id="83fc4dbe543f82a9e50bc1bd4c74fb70" category="list-text"><block ref="83fc4dbe543f82a9e50bc1bd4c74fb70" category="inline-link-macro-rx"></block></block>
  <block id="d10b633b8bd8d022c66a52d93e0ed6ce" category="section-title">클러스터 라이프사이클 관리</block>
  <block id="8b9449bdfc859a900fc4da7c79420145" category="paragraph">다양한 OpenShift 클러스터를 관리하기 위해 클러스터를 생성하거나 Advanced Cluster Management로 가져올 수 있습니다.</block>
  <block id="0ef06ef8df800cf71fb95c66e0e08f1a" category="list-text">먼저 인프라 &gt; 클러스터를 자동화하십시오.</block>
  <block id="0becde0fcfda03aec9c722d042326324" category="list-text">새 OpenShift 클러스터를 생성하려면 다음 단계를 완료하십시오.</block>
  <block id="e056bb6efa17796fc810edad8410280d" category="list-text">공급자 연결 만들기: 공급자 연결로 이동하여 연결 추가 를 클릭하고 선택한 공급자 형식에 해당하는 모든 세부 정보를 제공한 다음 추가 를 클릭합니다.</block>
  <block id="50dfc508091b37338da8357e63e6a405" category="image-alt">공급자 연결을 추가합니다</block>
  <block id="401b252566122602a82ff66bc7ed3e6c" category="list-text">새 클러스터를 생성하려면 클러스터 로 이동하고 클러스터 추가 &gt; 클러스터 생성 을 클릭합니다. 클러스터 및 해당 공급자에 대한 세부 정보를 제공하고 Create를 클릭합니다.</block>
  <block id="2984cab36bd51d5446963e671e808f5d" category="image-alt">클러스터 추가</block>
  <block id="2da6eeb34cf16de43ab8fa2f939d81c7" category="list-text">클러스터가 생성되면 클러스터 목록에 Ready 상태로 표시됩니다.</block>
  <block id="e6d9a6b38dd36fd9870260249ba5fc1f" category="list-text">기존 클러스터를 가져오려면 다음 단계를 수행하십시오.</block>
  <block id="f52ae06380cfd00cae7839562f550e87" category="list-text">클러스터 로 이동하고 클러스터 추가 &gt; 기존 클러스터 가져오기 를 클릭합니다.</block>
  <block id="63b7276dd1b569babc28304e786e2041" category="list-text">클러스터의 이름을 입력하고 가져오기 저장 및 코드 생성 을 클릭합니다. 기존 클러스터를 추가하는 명령이 표시됩니다.</block>
  <block id="be87809a27ab2944f89ccaebd89b7596" category="list-text">Copy Command 를 클릭하고 허브 클러스터에 추가할 클러스터에서 명령을 실행합니다. 그러면 클러스터에 필요한 에이전트 설치가 시작되고, 이 프로세스가 완료되면 클러스터가 준비 상태로 클러스터 목록에 나타납니다.</block>
  <block id="9a618414b83afe67c19abcf935be6dbd" category="image-alt">기존 클러스터 가져오기</block>
  <block id="c812d1382d834648706b3bf1e6848135" category="list-text">여러 클러스터를 생성하고 가져온 후에는 단일 콘솔에서 클러스터를 모니터링하고 관리할 수 있습니다.</block>
  <block id="068e5ec1cc0eaa7c2596be7eb1b40194" category="inline-link-macro">다음: 기능 - 응용 프로그램 수명 주기 관리</block>
  <block id="0405bd6ea905b8d563fd501d933a3e51" category="paragraph"><block ref="0405bd6ea905b8d563fd501d933a3e51" category="inline-link-macro-rx"></block></block>
  <block id="d008c60ddb28c0bbad1dfabdd77327fc" category="doc">구성: 스토리지 관리 작업</block>
  <block id="6c0ed744c737f30af364d229639c8288" category="paragraph">스토리지 관리자가 다음 리소스를 구성해야 합니다.</block>
  <block id="64244866ddff81ded5e6aaa49055c6aa" category="list-text">NetApp ONTAP 클러스터에 admin으로 로그인합니다.</block>
  <block id="85ca996063b5ec233e56a20ba93c5f44" category="list-text">Storage &gt; Storage VMs 로 이동하고 Add 를 클릭합니다. 필요한 세부 정보를 제공하여 프로젝트-1과 프로젝트-2에 각각 필요한 SVM 2개를 생성합니다. SVM 및 리소스를 관리하는 vsadmin 계정도 생성합니다.</block>
  <block id="3f8bc17bf8dd138aa2915235f0a9c0d3" category="image-alt">ONTAP에서 SVM 생성</block>
  <block id="b436e7799d01413277e05983e509574a" category="list-text">스토리지 관리자로 Red Hat OpenShift 클러스터에 로그인합니다.</block>
  <block id="c9bd46366e9fb78552566f1e7a13633a" category="list-text">프로젝트-1의 백엔드를 생성하여 프로젝트 전용 SVM에 매핑합니다. ONTAP 클러스터 관리자를 사용하는 대신 SVM의 vsadmin 계정을 사용하여 백엔드를 SVM에 연결하는 것이 좋습니다.</block>
  <block id="f934b433773b966e5ebe0c7172decda4" category="admonition">이 예에서는 ONTAP-NAS 드라이버를 사용하고 있습니다. 사용 사례에 따라 백엔드를 생성할 때 적절한 드라이버를 사용하십시오.</block>
  <block id="8628ed29313534f54f01e0da36e66ab7" category="admonition">트리덴트 프로젝트에 Trident가 설치되어 있다고 가정합니다.</block>
  <block id="4a6c648106c1ff38316705bf986de601" category="list-text">마찬가지로, project-2를 위한 Trident 백엔드를 생성한 다음 project-2 전용 SVM에 매핑합니다.</block>
  <block id="9a45d41277a2e8ce29709826a31fb482" category="list-text">그런 다음 스토리지 클래스를 생성합니다. storagePools 매개 변수를 설정하여 project-1용 스토리지 클래스를 생성하고 backend 전용 스토리지 풀을 project-1에 사용하도록 구성합니다.</block>
  <block id="4350d40426f8c94f6ca046609969adb2" category="list-text">마찬가지로, project-2에 대한 스토리지 클래스를 생성하고 백엔드에서 project-2에 대한 스토리지 풀을 사용하도록 구성합니다.</block>
  <block id="2ee847ebe129ae778860d6dd2da21cf6" category="list-text">ResourceQuota를 생성하여 다른 프로젝트 전용 스토리지로부터 스토리지를 요청하는 Project-1의 리소스를 제한합니다.</block>
  <block id="c689ae18a0f5e47541dcec4afb6e187a" category="list-text">마찬가지로, ResourceQuota를 생성하여 다른 프로젝트 전용 스토리지로부터 스토리지를 요청하는 Project-2의 리소스를 제한합니다.</block>
  <block id="7f9ddc8224f28e1481299160807c876d" category="inline-link-macro">다음: 검증.</block>
  <block id="93a1440c4dcba82f234a9305a9445144" category="paragraph"><block ref="93a1440c4dcba82f234a9305a9445144" category="inline-link-macro-rx"></block></block>
  <block id="501195b19cb60bfec4c2e4899a2a460c" category="summary">Red Hat OpenShift 클러스터를 등록하면 Astra Control Center를 통해 배포 및 관리하는 애플리케이션을 검색할 수 있습니다.</block>
  <block id="d19de154f02438c6d6918a4e016c7c62" category="doc">보호할 애플리케이션을 선택하십시오</block>
  <block id="a022d74e2b8b62dd9f1caa37a51aa3f3" category="section-title">애플리케이션 관리</block>
  <block id="d8c780951f3271e7d72b116e5f41d46b" category="list-text">OpenShift 클러스터와 ONTAP 백엔드가 Astra Control Center에 등록된 후, 컨트롤 센터는 지정된 ONTAP 백엔드로 구성된 스토리지 클래스 스토리지를 사용하는 모든 네임스페이스에서 애플리케이션을 자동으로 검색하기 시작합니다.</block>
  <block id="3b5963749d054f288f27dfb2f20d0370" category="inline-image-macro">Astra Control Center 애플리케이션이 검색되었습니다</block>
  <block id="a78e618a70881e5c5dda311aaa61c250" category="paragraph"><block ref="a78e618a70881e5c5dda311aaa61c250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c46442de8c982973aeee99a9441b746" category="list-text">앱 &gt; 검색됨 으로 이동한 후 Astra를 사용하여 관리하려는 애플리케이션 옆에 있는 드롭다운 메뉴를 클릭합니다. 관리 를 클릭합니다.</block>
  <block id="22d84cdf10d4c1059d68b1ab7da5b375" category="inline-image-macro">Astra Control Center에서 애플리케이션을 관리합니다</block>
  <block id="4afca1ab36db499d54b08ff38dff8a5c" category="paragraph"><block ref="4afca1ab36db499d54b08ff38dff8a5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d694cfe5907a4790ea939388a8cfd25" category="list-text">응용 프로그램이 사용 가능 상태로 전환되고 앱 섹션의 관리 탭에서 볼 수 있습니다.</block>
  <block id="dc496d6799e0c6ab3bdfdbdc6a086b48" category="inline-image-macro">Astra Control Center 애플리케이션을 사용할 수 있습니다</block>
  <block id="872adedc4ac847cec0aa8fb9299d32e5" category="paragraph"><block ref="872adedc4ac847cec0aa8fb9299d32e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2c2a82496277a88b32b0e8d27249d3d" category="inline-link-macro">다음: 응용 프로그램을 보호합니다.</block>
  <block id="d5be948b8a7fea6618eb171c64927be2" category="paragraph"><block ref="d5be948b8a7fea6618eb171c64927be2" category="inline-link-macro-rx"></block></block>
  <block id="4d4480c77d84881f85763c51fb0a0ebb" category="doc">비디오 및 데모: NetApp의 Red Hat OpenShift</block>
  <block id="f64f81d4393ab1fc9545c35c8eb9f74d" category="paragraph">다음 비디오에서는 이 문서에 설명되어 있는 몇 가지 기능을 설명합니다.</block>
  <block id="051525dd6e814133d477a1812a4164c2" category="inline-link-macro">비디오: Red Hat 가상화 배포 기반의 Red Hat OpenShift용 NetApp HCI</block>
  <block id="817cc3ec794caf508075034f1fa54315" category="list-text"><block ref="817cc3ec794caf508075034f1fa54315" category="inline-link-macro-rx"></block></block>
  <block id="5e217c79c499978721e658f868053d3f" category="inline-link-macro">다음: 추가 정보: NetApp의 Red Hat OpenShift</block>
  <block id="d2fb587a433995783f0688b22359272d" category="paragraph"><block ref="d2fb587a433995783f0688b22359272d" category="inline-link-macro-rx"></block></block>
  <block id="114856cfc010d937269afe29138175fc" category="doc">OpenShift Virtualization을 통한 가상 시스템 배포: NetApp과 Red Hat OpenShift</block>
  <block id="b2f35a84b813ef160b585d350d2fcd58" category="summary">베어 메탈 기반 Anthos의 하드웨어 독립적 기능을 사용하면 사용 사례에 최적화된 컴퓨팅 플랫폼을 선택할 수 있습니다. 따라서 는 기존 인프라를 일치시키고 자본 지출을 줄일 수 있습니다.</block>
  <block id="5f95fbda20eeb9ce0859afe2ac6f42fa" category="doc">솔루션 요구 사항</block>
  <block id="7d4009b9254a61f6afd71a2656a3a78f" category="section-title">컴퓨팅: 자체 서버를 사용합니다</block>
  <block id="dee41946d9d6ca32131352cb4374f12b" category="paragraph">다음 표에는 이 솔루션을 구현하는 데 필요한 최소 컴퓨팅 하드웨어 구성 요소의 수가 나와 있습니다. 단, 사용되는 하드웨어 모델은 고객 요구 사항에 따라 다를 수 있습니다.</block>
  <block id="c64518704ce0c0d5501a45763f464276" category="cell">사용</block>
  <block id="602f72fff77475a16eff159759656261" category="cell">하드웨어 및 모델</block>
  <block id="06e9950a2c1bb489cf54d03d4547e913" category="cell">관리 노드</block>
  <block id="b349dcffed4594674c8ce6c91e72e42f" category="cell">Cisco UCS B200</block>
  <block id="fcb81a84511da525a1581c4ccc00d0fb" category="cell">작업자 노드</block>
  <block id="4867cc2ab4385d91c3a36d6ace67a984" category="cell">HP ProLiant DL360</block>
  <block id="2c0b20f0fbc047d58ca10a50c6a32bc7" category="section-title">스토리지: NetApp ONTAP</block>
  <block id="604e83a5a6c4302c60ee5e331dcd342c" category="paragraph">다음 표에는 솔루션을 구현하는 데 필요한 최소 스토리지 하드웨어 구성 요소의 수가 나와 있습니다. 단, 사용되는 하드웨어 모델은 고객 요구 사항에 따라 다를 수 있습니다.</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF를 참조하십시오</block>
  <block id="eb8440af98c502b8095408e970297e6b" category="cell">NetApp AFF A300</block>
  <block id="e8d610d6c2d243856beaade33b5aa123" category="cell">2개(HA 쌍 1개)</block>
  <block id="b6ce11f078022a4ab598b8016db52a13" category="paragraph">다음 표에 명시된 소프트웨어 버전은 NetApp과 파트너가 NetApp 솔루션을 검증하는 데 사용되었으며 소프트웨어 구성 요소는 고객 요구 사항에 따라 다를 수 있습니다.</block>
  <block id="128b9c7509f09d8ff4b08e87def0ac74" category="cell">3명의 관리자가 있는 OS</block>
  <block id="7cd95c816f8a04ff858a857e3e5a484d" category="cell">20.04</block>
  <block id="836a05a21ac6df3b6bcf9838895b017e" category="cell">Worker4의 OS</block>
  <block id="bbd243e896202aa0eb00ce19d8a7fea8" category="cell">Worker3의 OS</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="aaad0494526f271ca02ebd06a79e7382" category="cell">Worker2의 OS</block>
  <block id="2a568439f8e6ff92daa9925ce8a03adf" category="cell">8.2</block>
  <block id="c73bbd3786350b0a8d3577d82afdf489" category="cell">Red Hat Enterprise Linux</block>
  <block id="7ac53708026d8515ce15cc154e95f46b" category="cell">Worker1의 OS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="7cf4fea896dee61293d729d9985621d7" category="cell">컨테이너 오케스트레이션</block>
  <block id="ca9f0d77f73d954e88e6ab43539ac7cb" category="cell">1.6.0</block>
  <block id="ea704238343d48baa3a08f039015185f" category="cell">스토리지 OS</block>
  <block id="f33749dd101d316dcf2e6953732629f9" category="cell">9.7P8</block>
  <block id="8fe1ffd8f7dcf339dd4f34aabb6e1c99" category="cell">컨테이너 스토리지 관리</block>
  <block id="a84024ce06ef98519b3b51300b2c8fbf" category="cell">20.10</block>
  <block id="37979dccdf7857a1abffb7df7c837853" category="admonition">이 멀티 OS 환경은 베어 메탈 솔루션에서 Anthos의 지원되는 OS 버전과의 상호 운용성을 보여줍니다. 우리는 고객이 구축을 위해 하나 또는 일부 운영 체제를 표준화할 것으로 예상하고 있습니다.</block>
  <block id="d94e09dc1956d9513e690f8d24852f05" category="inline-link">Anthos의 Bare Metal 문서</block>
  <block id="dea0bcd20b41ad5a5b5830e0facf5d5d" category="paragraph">베어 메탈 하드웨어 및 소프트웨어 요구 사항에 대한 Anthos는 를 참조하십시오<block ref="39597b4f74e08019db4cace51500cfd6" category="inline-link-rx"></block> 페이지.</block>
  <block id="71196ec10a92c76a666a93f55523b96e" category="inline-link-macro">다음: 배포 요약.</block>
  <block id="1b8d67e147d4d9c532832778cca5fee8" category="paragraph"><block ref="1b8d67e147d4d9c532832778cca5fee8" category="inline-link-macro-rx"></block></block>
  <block id="58c0d00b6ee4c263f1fbe431b41eebf4" category="summary">Astra Control Center에서 애플리케이션 워크로드를 관리하고 나면 해당 워크로드에 대한 보호 설정을 구성할 수 있습니다.</block>
  <block id="16dcf1808fc3c9a6f8342f97305d2ad6" category="doc">애플리케이션 보호</block>
  <block id="59af79c7ab060b4cca322301a4729f0c" category="section-title">애플리케이션 스냅샷 생성</block>
  <block id="c0cf3c0162d106c6ee24b7afa9b79575" category="paragraph">애플리케이션의 스냅샷은 해당 스냅샷 복사본을 기반으로 애플리케이션을 특정 시점으로 복원하거나 클론 복제하는 데 사용할 수 있는 ONTAP 스냅샷 복사본을 생성합니다.</block>
  <block id="9101281f33d55e682b1a47a44251fa0e" category="list-text">응용 프로그램의 스냅샷을 만들려면 앱 &gt; 관리 탭으로 이동하여 스냅샷 복사본을 만들 응용 프로그램을 클릭합니다. 응용 프로그램 이름 옆의 드롭다운 메뉴를 클릭하고 스냅샷 을 클릭합니다.</block>
  <block id="c01290a8a623e36f9bcae85b910a3410" category="inline-image-macro">Astra Control Center 스냅샷 버튼</block>
  <block id="f40e241f10f15eb6887acbc81fec81b0" category="inline-image-macro">Astra Control Center에서 스냅샷을 생성합니다</block>
  <block id="1853746a915bea325b8b576237c24427" category="section-title">애플리케이션 백업 생성</block>
  <block id="91796648d42dbd448c6cbb2044cb92ba" category="paragraph">애플리케이션 백업에서는 애플리케이션의 활성 상태와 애플리케이션 리소스의 구성을 캡처하여 파일로 저장한 다음 원격 오브젝트 스토리지 버킷에 저장합니다.</block>
  <block id="72e328bb06195897c7a644970c61d3a2" category="paragraph">Astra Control Center에서 관리 대상 애플리케이션을 백업 및 복구하려면 백업 ONTAP 시스템에 대한 고급 사용자 설정을 사전 요구 사항으로 구성해야 합니다. 이렇게 하려면 다음 명령을 입력합니다.</block>
  <block id="6db82a24b17137378420e9fc7961d961" category="list-text">Astra Control Center에서 관리 대상 응용 프로그램의 백업을 생성하려면 Apps &gt; Managed 탭으로 이동하여 백업할 응용 프로그램을 클릭합니다. 응용 프로그램 이름 옆의 드롭다운 메뉴를 클릭하고 백업을 클릭합니다.</block>
  <block id="bc230776554b8a63af328cf9f01124e1" category="inline-image-macro">Astra Control Center 백업 버튼</block>
  <block id="e10781941ccd98298d2856b437b3fb4b" category="inline-image-macro">Astra Control Center에서 백업을 생성합니다</block>
  <block id="92955527b375720b2a586155a776c0ac" category="inline-image-macro">Astra Control Center 클론 버튼</block>
  <block id="c4293ef1955d52694e7d2288b637df1a" category="inline-image-macro">Astra Control Center 복구</block>
  <block id="c501040965cb5ca97cc675347e9ebfdf" category="list-text">새 애플리케이션은 검색 상태로 전환되지만, Astra Control Center는 선택한 클러스터에 애플리케이션을 생성합니다. 응용 프로그램의 모든 리소스가 Astra에 의해 설치 및 감지되면 응용 프로그램은 사용 가능 상태로 전환됩니다.</block>
  <block id="9ff3c5458e4a8facc6e7c25656a3baf7" category="inline-image-macro">Astra Control Center에서 새로운 앱이 검색되었습니다</block>
  <block id="abd6754aa5a185ca83b3f00c5da68534" category="inline-link-macro">다음으로 솔루션 검증/사용 사례를 살펴보겠습니다.</block>
  <block id="8bfe62be82a77570753936203ee020ca" category="paragraph"><block ref="8bfe62be82a77570753936203ee020ca" category="inline-link-macro-rx"></block></block>
  <block id="7c613b296892d4712b9041d3081282f8" category="summary">NetApp OpenShift를 사용한 Kubernetes용 고급 클러스터 관리</block>
  <block id="78e1aefe2bbb2518f1156636e761e479" category="paragraph">OpenShift 클러스터에 Kubernetes용 Advanced Cluster Management를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="b17056cdbd9ec695d4348e1ad799ace4" category="list-text">허브 클러스터로 OpenShift 클러스터를 선택하고 클러스터 관리자 권한으로 로그인합니다.</block>
  <block id="bc2ab7a7550cebeb52a08cf830b5ecf6" category="list-text">Operators &gt; Operators Hub로 이동하여 Kubernetes용 Advanced Cluster Management를 검색합니다.</block>
  <block id="2e5d3941e033e96d5317cc2bbd1da914" category="image-alt">ACM 타일</block>
  <block id="c4ab802b80978ba1c5de3922d546bdb7" category="list-text">Kubernetes용 고급 클러스터 관리 를 선택하고 설치 를 클릭합니다.</block>
  <block id="cc5a9dd5971b8369354db684e5dbfe2b" category="image-alt">ACM 타일 세부 정보</block>
  <block id="c972585d6241c4f2ed2604bcc8706358" category="list-text">Install Operator(사용자 설치) 화면에서 필요한 세부 정보를 제공하고(NetApp은 기본 매개 변수를 유지할 것을 권장) Install(설치)을 클릭합니다.</block>
  <block id="72b342ddabad6a9ec11df82389c40b88" category="image-alt">ACM 작업자 타일을 장착하십시오</block>
  <block id="11458c333e4903e54ca46f822ba6a3b6" category="list-text">작업자 설치가 완료될 때까지 기다립니다.</block>
  <block id="64524f91c2fdfcd54b4bbcab35392908" category="image-alt">ACM 사용자 설치 진행 중</block>
  <block id="7bf3d0678c48be5730f20005e6f88aa1" category="list-text">연산자가 설치된 후 Create MultiClusterHub 를 클릭합니다.</block>
  <block id="e0d84ec6a5b8f92909a7a3bef11455c1" category="image-alt">ACM 운영자 Multiclusterhub</block>
  <block id="95f29f27e373a9759cf065e1fde23e28" category="list-text">Create MultiClusterHub 화면에서 세부 정보를 입력하고 Create를 클릭합니다. 그러면 다중 클러스터 허브의 설치가 시작됩니다.</block>
  <block id="344f0cb43d1b2e7a719bea808fe7c5bf" category="image-alt">다중 클러스터 허브 생성 화면</block>
  <block id="a50aa5e8249109d6f4902945e968ad7d" category="list-text">모든 Pod가 개방형 클러스터 관리 네임스페이스에서 실행 상태로 이동하고 운영자가 Succeeded 상태로 이동하면 Kubernetes용 Advanced Cluster Management가 설치됩니다.</block>
  <block id="851548d1ad843a23609f325e8b54e72d" category="image-alt">ACM 작업자가 장착됨</block>
  <block id="391dd52c88201d377f1572062e22c43e" category="list-text">허브 설치를 완료하는 데 약간의 시간이 걸리며, 작업이 완료되면 MultiCluster 허브가 실행 상태로 이동합니다.</block>
  <block id="c7aa79f0c31ac15d728ee47c7e6eaee2" category="image-alt">멀티클러스터 허브가 준비되었습니다</block>
  <block id="eef36825efd5d2d40e4f833635cd19da" category="list-text">또한 오픈 클러스터 관리 네임스페이스에 경로를 생성합니다. 경로의 URL에 연결하여 고급 클러스터 관리 콘솔에 액세스합니다.</block>
  <block id="f761fad3f1c25e94d5f46ebd9e23a901" category="image-alt">ACM 콘솔 경로</block>
  <block id="4488e277b96ae08def5eb77c2d8c6e74" category="inline-link-macro">다음: 기능 - 클러스터 수명 주기 관리</block>
  <block id="8a4d50965d8a3c708bdb16a716d64246" category="paragraph"><block ref="8a4d50965d8a3c708bdb16a716d64246" category="inline-link-macro-rx"></block></block>
  <block id="4e92dab2ab2bbe684f09a2aca58c9e44" category="list-text">NetApp ONTAP 클러스터</block>
  <block id="b645e117fe786bf56128cde2dec3971a" category="list-text">Red Hat OpenShift 클러스터</block>
  <block id="f675b3d5e1e137870f481a742a3ec0af" category="list-text">클러스터에 설치된 Trident</block>
  <block id="1db1a9d97c708824712706fc4267ec25" category="list-text">tridentctl 및 OC 도구가 설치되고 $PATH에 추가된 관리 워크스테이션</block>
  <block id="7cf4175762acfbabf9178d34f2504b28" category="list-text">ONTAP에 대한 관리자 액세스</block>
  <block id="10a540d0ed57154e8676c5725af53935" category="list-text">OpenShift 클러스터에 대한 클러스터 관리자 액세스</block>
  <block id="6340f6ab1111f349228595ebceb8f6db" category="list-text">클러스터가 ID 공급자와 통합됩니다</block>
  <block id="9e110c19bb79322a0b76199795550dea" category="list-text">ID 공급자는 서로 다른 팀의 사용자를 효율적으로 구분하도록 구성되어 있습니다</block>
  <block id="b917a2bfe0dd0160c3ad88751f355f5d" category="inline-link-macro">다음: 클러스터 관리자 작업.</block>
  <block id="7a9f102fda0e3438bff54da4acdbccbb" category="paragraph"><block ref="7a9f102fda0e3438bff54da4acdbccbb" category="inline-link-macro-rx"></block></block>
  <block id="810a039d1a8524388b75a0fe8d837afc" category="summary">Astra Control Center에서 워크로드를 관리할 수 있도록 하려면 먼저 Red Hat OpenShift 클러스터를 등록해야 합니다.</block>
  <block id="3557f7a93216446476c40d54e0426c40" category="doc">Astra Control Center에 Red Hat OpenShift 클러스터를 등록합니다</block>
  <block id="349c99fe6f384da92e5b8289b828791c" category="section-title">Red Hat OpenShift 클러스터를 등록합니다</block>
  <block id="c179429ab818c9d0cca3d1db55f788bf" category="list-text">첫 번째 단계는 OpenShift 클러스터를 Astra Control Center에 추가하고 관리하는 것입니다. 클러스터 로 이동하고 클러스터 추가 를 클릭하고 OpenShift 클러스터에 대한 kubecon무화과 파일을 업로드한 다음 저장소 선택 을 클릭합니다.</block>
  <block id="8dfc7d6b819f8c17b51391e3b3159add" category="inline-image-macro">Astra Control Center 클러스터 생성</block>
  <block id="7470624615914e8e3d5fdf4ea1aa31de" category="paragraph"><block ref="7470624615914e8e3d5fdf4ea1aa31de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7d9a690231a2d896f69e9b45c9ff4a1" category="admonition">kubecon무화과 파일은 사용자 이름 및 암호 또는 토큰으로 인증하기 위해 생성할 수 있습니다. 토큰은 제한된 시간 후에 만료되며 등록된 클러스터에 연결할 수 없는 상태로 유지될 수 있습니다. NetApp은 OpenShift 클러스터를 Astra Control Center에 등록하려면 사용자 이름과 암호를 사용하여 kubeconfig 파일을 사용하는 것이 좋습니다.</block>
  <block id="2fb91f8695d5dc9db4bf5a7ef710ec73" category="list-text">Astra Control Center가 적합한 스토리지 클래스를 감지합니다. 이제 NetApp ONTAP에서 SVM이 지원하는 Trident를 사용하여 스토리지 글라스의 볼륨 프로비저닝 방법을 선택하고 검토를 클릭합니다. 다음 창에서 세부 정보를 확인하고 Add Cluster를 클릭합니다.</block>
  <block id="cab7d2cb072914c0a5a89baab41d38e8" category="inline-image-macro">Astra Control Center 클러스터 선택 스토리지를 생성합니다</block>
  <block id="68ac91074dd3b4e5514e5f56a6c9c756" category="paragraph"><block ref="68ac91074dd3b4e5514e5f56a6c9c756" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3edb3c83eb1bede6778cc1960a651973" category="list-text">1단계에서 설명한 대로 두 OpenShift 클러스터를 모두 등록합니다. 추가된 클러스터는 검색 상태로 이동하고 Astra Control Center는 이를 검사하고 필요한 에이전트를 설치합니다. 성공적으로 등록되면 클러스터 상태가 실행 중으로 변경됩니다.</block>
  <block id="420b9c40f78cc4825914319af51801b9" category="inline-image-macro">Astra Control Center 클러스터를 사용할 수 있습니다</block>
  <block id="1b017a62213661e1ed3c5c581fcf74a2" category="paragraph"><block ref="1b017a62213661e1ed3c5c581fcf74a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed5c1a60b8165b8bc691cbdf1b0d122c" category="admonition">Astra Control Center에서 관리하는 모든 Red Hat OpenShift 클러스터는 관리되는 클러스터에 설치된 에이전트가 해당 레지스트리에서 이미지를 가져올 때 설치에 사용된 이미지 레지스트리에 액세스할 수 있어야 합니다.</block>
  <block id="8d01de34ef9b9b934d18009a1e3273a9" category="list-text">Astra Control Center에서 백엔드를 관리할 스토리지 리소스로 ONTAP 클러스터를 가져옵니다. OpenShift 클러스터를 Astra에 추가하고 storageclass를 구성하면 ONTAP 클러스터를 자동으로 검색하고 검사하여 스토리지 클래스를 백업하지만 관리 대상 Astra Control Center로 가져오지 않습니다.</block>
  <block id="781ffd1df517a65b302412f53de974da" category="inline-image-macro">Astra Control Center 백엔드 검색</block>
  <block id="1fcc7977dffdc8fd8fc53582c67da895" category="paragraph"><block ref="1fcc7977dffdc8fd8fc53582c67da895" category="inline-image-macro-rx" type="image"></block></block>
  <block id="feab1371530d1ef069d928e811bcb08b" category="list-text">ONTAP 클러스터를 가져오려면 백엔드에서 드롭다운을 클릭하고 관리할 ONTAP 클러스터 옆에 있는 관리를 선택합니다. ONTAP 클러스터 자격 증명을 입력하고 정보 검토 를 클릭한 다음 스토리지 백엔드 가져오기 를 클릭합니다.</block>
  <block id="4da0c23c38cf0da34e1e6660ff74542b" category="inline-image-macro">Astra Control Center에서 백엔드를 생성합니다</block>
  <block id="69dbaffc2661024ee0b5095bc3674f60" category="paragraph"><block ref="69dbaffc2661024ee0b5095bc3674f60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edb4425c04926a17b6ff9a4a2ecdc669" category="list-text">백엔드가 추가되면 상태가 사용 가능으로 변경됩니다. 이러한 백엔드는 이제 OpenShift 클러스터의 영구 볼륨과 ONTAP 시스템의 해당 볼륨에 대한 정보를 갖게 됩니다.</block>
  <block id="92c130f9be24925c7dee36f7580ea347" category="inline-image-macro">Astra Control Center 백엔드를 사용할 수 있습니다</block>
  <block id="e9f487b0aad6779edbf50c6092477bd5" category="paragraph"><block ref="e9f487b0aad6779edbf50c6092477bd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2d10d92dc9d83e3cf3514e8e883e5cb" category="list-text">Astra Control Center를 사용하여 OpenShift 클러스터 전체에서 백업 및 복원을 수행하려면 S3 프로토콜을 지원하는 오브젝트 스토리지 버킷을 프로비저닝해야 합니다. 현재 지원되는 옵션은 ONTAP S3, StorageGRID 및 AWS S3입니다. 이 설치를 위해 AWS S3 버킷을 구성하려고 합니다. Bucket 으로 이동하여 Bucket 추가 를 클릭하고 Generic S3 를 선택합니다. S3 버킷에 대한 세부 정보와 액세스할 자격 증명을 입력하고 "이 버킷을 클라우드의 기본 버킷으로 설정" 확인란을 클릭한 다음 추가를 클릭합니다.</block>
  <block id="6910cb9051734be0129cb1e7dd84ce5c" category="inline-image-macro">Astra Control Center는 버킷을 만듭니다</block>
  <block id="2786d0b632389f7cbd6c4e67fba0061f" category="paragraph"><block ref="2786d0b632389f7cbd6c4e67fba0061f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5a9f831c51dc05a9b40eae2850329fc" category="inline-link-macro">다음: 보호할 응용 프로그램을 선택합니다.</block>
  <block id="74dd157086250792afa856d5a6c32777" category="paragraph"><block ref="74dd157086250792afa856d5a6c32777" category="inline-link-macro-rx"></block></block>
  <block id="06fdae3f02fee5cbe172f1574564c925" category="doc">Kubernetes용 고급 클러스터 관리: NetApp의 Red Hat OpenShift</block>
  <block id="30c15b5a84f4fb26cd25b38dc787b22d" category="paragraph">개발 환경에서 운영 환경으로 컨테이너화된 애플리케이션으로 전환함에 따라 많은 조직에서는 해당 애플리케이션의 테스트 및 배포를 지원하기 위해 여러 Red Hat OpenShift 클러스터가 필요합니다. 이와 함께 조직은 일반적으로 OpenShift 클러스터에서 여러 애플리케이션 또는 워크로드를 호스팅합니다. 따라서 각 조직은 클러스터 세트를 관리해야 하며, OpenShift 관리자는 사내 데이터 센터와 퍼블릭 클라우드가 혼합된 다양한 환경에서 여러 클러스터를 관리하고 유지 관리해야 하는 추가적인 과제를 해결해야 합니다. 이러한 과제를 해결하기 위해 Red Hat은 Kubernetes용 Advanced Cluster Management를 도입했습니다.</block>
  <block id="1cf7b9db4d7fe091bd1bbb685e5beea8" category="paragraph">Kubernetes용 Red Hat Advanced Cluster Management를 사용하면 다음 작업을 수행할 수 있습니다.</block>
  <block id="808c579683377aa7bd89b8e4d76ba220" category="list-text">데이터 센터와 퍼블릭 클라우드 전반에서 여러 클러스터를 생성, 임포트, 관리합니다</block>
  <block id="7fe0555145a586e3fb769f86902ccc72" category="list-text">단일 콘솔에서 여러 클러스터의 애플리케이션 또는 워크로드를 구축하고 관리합니다</block>
  <block id="416434625b0f2158d99a4af37f233805" category="list-text">여러 클러스터 리소스의 상태 및 상태 모니터링 및 분석</block>
  <block id="fed6fdd49a1e6adda0ea12a93e74ea2d" category="list-text">여러 클러스터에서 보안 규정 준수 모니터링 및 적용</block>
  <block id="a7516c278242a08b85090e24cbf67218" category="paragraph">Kubernetes용 Red Hat Advanced Cluster Management는 Red Hat OpenShift 클러스터에 대한 애드온으로 설치되며, 모든 작업을 위한 중앙 컨트롤러로 이 클러스터를 사용합니다. 이 클러스터를 허브 클러스터라고 하며, 사용자가 고급 클러스터 관리에 연결할 수 있는 관리 영역을 노출합니다. Advanced Cluster Management 콘솔을 통해 가져오거나 생성되는 다른 모든 OpenShift 클러스터는 허브 클러스터에서 관리되며 관리되는 클러스터라고 합니다. 관리 대상 클러스터에 Klusterlet이라는 에이전트를 설치하여 허브 클러스터에 연결하고 클러스터 라이프사이클 관리, 애플리케이션 라이프사이클 관리, 관찰 가능성 및 보안 준수와 관련된 다양한 활동에 대한 요청을 처리합니다.</block>
  <block id="b1000f23e43dfac19b53c74d7ebe66c8" category="image-alt">ACM 아키텍처</block>
  <block id="a376445fd812a7fa27714e6b11bc6163" category="paragraph">자세한 내용은 설명서를 참조하십시오<block ref="50c0dc50e188cf3a7847d9a813fd829e" category="inline-link-rx"></block>.</block>
  <block id="a99137a02f570225903b02b175e289a4" category="paragraph"><block ref="a99137a02f570225903b02b175e289a4" category="inline-link-macro-rx"></block></block>
  <block id="86c2cc4630e619e2c08c32f54e844297" category="section-title">여러 클러스터에 리소스를 생성합니다</block>
  <block id="bc2397695676d1a63e489d4c80c8cd91" category="paragraph">Kubernetes의 고급 클러스터 관리를 사용하면 콘솔에서 하나 이상의 관리되는 클러스터에 리소스를 동시에 생성할 수 있습니다. 예를 들어, 서로 다른 NetApp ONTAP 클러스터로 백업된 여러 사이트에 OpenShift 클러스터를 사용하고 두 사이트에서 PVC를 프로비저닝하고 싶은 경우 상단 표시줄에서 (+) 기호를 클릭할 수 있습니다. 그런 다음 PVC를 생성할 클러스터를 선택하고 YAML 리소스를 붙여 넣은 다음 생성 을 클릭합니다.</block>
  <block id="24800112d59462f8ea9ff03f5dd456a7" category="image-alt">리소스를 생성합니다</block>
  <block id="ec22e01e7cd5087ef746b3db5852da6e" category="doc">확장: 더 많은 프로젝트 추가</block>
  <block id="0e4136a9f4ad3204c07db26d3c28a546" category="paragraph">멀티 테넌트 구성에서는 스토리지 리소스로 새 프로젝트를 추가하려면 멀티 테넌시가 위반되지 않도록 추가적인 구성이 필요합니다. 멀티 테넌트 클러스터에 프로젝트를 더 추가하려면 다음 단계를 완료하십시오.</block>
  <block id="c8acb1fa89b1ec9d78799a2dd4aa8b59" category="list-text">NetApp ONTAP 클러스터에 스토리지 관리자로 로그인합니다.</block>
  <block id="d0ed0d7b81278233c852e4a0d8aa123b" category="list-text">스토리지 -&gt; 스토리지 VM으로 이동한 후 추가 를 클릭합니다. PROJECT-3 전용 SVM을 새로 생성합니다. SVM 및 리소스를 관리하는 vsadmin 계정도 생성합니다.</block>
  <block id="5790e2b8b367726e78500054d959d6f7" category="image-alt">확장을 위한 SVM 생성</block>
  <block id="b0c67e9a89c7ece3169ab5849bb0e411" category="list-text">Red Hat OpenShift 클러스터에 클러스터 관리자로 로그인합니다.</block>
  <block id="c9e86337c7483c8d45e5e535829d2163" category="list-text">새 프로젝트를 만듭니다.</block>
  <block id="1c01b62cc887329b006a88e9f959b5d4" category="list-text">PROJECT-3의 사용자 그룹이 IDP에서 생성되고 OpenShift 클러스터와 동기화되었는지 확인합니다.</block>
  <block id="46c82384780a492254c43d461363d9ac" category="list-text">PROJECT-3의 개발자 역할을 만듭니다.</block>
  <block id="21ac9e9bbb2cfc707143311f4601af1c" category="admonition">이 섹션에 제공된 역할 정의는 예일 뿐입니다. 개발자 역할은 최종 사용자 요구 사항에 따라 정의되어야 합니다.</block>
  <block id="8efa8222e644f71e636f98917439566d" category="list-text">개발자를 위한 RoleBinding 만들기 project-3에서 developer-project-3 역할을 프로젝트-3의 해당 그룹(OCP-PROJECT-3)에 바인딩합니다.</block>
  <block id="e1f01c3341da15c9079bf5996c059811" category="list-text">Red Hat OpenShift 클러스터에 스토리지 관리자로 로그인합니다</block>
  <block id="2ca2d57f42208b6e7e9026b491595f41" category="list-text">Trident 백엔드를 생성하여 PROJECT-3 전용 SVM에 매핑합니다. ONTAP 클러스터 관리자를 사용하는 대신 SVM의 vsadmin 계정을 사용하여 백엔드를 SVM에 연결하는 것이 좋습니다.</block>
  <block id="c4dcda95616fac9215b5dac3cde37220" category="admonition">이 예에서는 ONTAP-NAS 드라이버를 사용하고 있습니다. 사용 사례에 따라 백엔드를 생성하는 데 적합한 드라이버를 사용하십시오.</block>
  <block id="55da75937cfedfe97c220c1e9d556d84" category="list-text">PROJECT-3의 스토리지 클래스를 생성하고 PROJECT-3 전용 백엔드에서 스토리지 풀을 사용하도록 구성합니다.</block>
  <block id="6efdcf6ed405066371d23375541816a1" category="list-text">ResourceQuota를 생성하여 다른 프로젝트 전용 스토리지로부터 스토리지를 요청하는 Project-3의 리소스를 제한합니다.</block>
  <block id="1dea1d57247580b530335ec2d484f8a5" category="list-text">다른 프로젝트의 ResourceQuotas를 패치하여 해당 프로젝트의 리소스가 project-3 전용 스토리지 클래스에서 스토리지에 액세스하는 것을 제한합니다.</block>
  <block id="3a724344bfc1b086a678d66814f20dd7" category="summary">이 섹션에서는 Jenkins와 지속적인 통합 및 지속적인 제공 또는 배포 파이프라인을 구축하여 솔루션 운영을 검증하는 단계를 제공합니다.</block>
  <block id="b830a759b7bbee23da50f11979fb8f27" category="doc">영구 스토리지로 Jenkins CI/CD 파이프라인 구축: NetApp과의 Red Hat OpenShift</block>
  <block id="ff587ce314d6f90660779e9d75cafe53" category="paragraph">이 섹션에서는 Jenkins와 지속적인 통합/지속적인 공급 또는 배포(CI/CD) 파이프라인을 구축하여 솔루션 운영을 검증하는 단계를 제공합니다.</block>
  <block id="9eb8af4dd2c3557a24b914601b6ae465" category="section-title">Jenkins 배포에 필요한 리소스를 생성합니다</block>
  <block id="93b3852e5c67975dd33b1769b24a4a85" category="paragraph">Jenkins 응용 프로그램 배포에 필요한 리소스를 생성하려면 다음 단계를 수행하십시오.</block>
  <block id="9fd493573e73cb0e5e55e97306249596" category="list-text">Jenkins라는 새 프로젝트를 만듭니다.</block>
  <block id="5690195262fb589b6021733b4a5a4432" category="paragraph"><block ref="5690195262fb589b6021733b4a5a4432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d256abce3dbdfed83e337956e42f60f" category="list-text">이 예에서는 영구 스토리지에 Jenkins를 구축했습니다. Jenkins 빌드를 지원하려면 PVC를 만듭니다. 저장소 &gt; 영구 볼륨 클레임 으로 이동하고 영구 볼륨 클레임 생성 을 클릭합니다. 생성된 스토리지 클래스를 선택하고 영구 볼륨 클레임 이름이 Jenkins 인지 확인하고 적절한 크기 및 액세스 모드를 선택한 다음 만들기 를 클릭합니다.</block>
  <block id="f9db9f308c8ed7f5d0ed0851d8d605cb" category="paragraph"><block ref="f9db9f308c8ed7f5d0ed0851d8d605cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9272f40a21ca3dad814c4e3886b40776" category="section-title">영구 스토리지로 Jenkins를 배포합니다</block>
  <block id="939a7b51bfb262627185af768c3c1024" category="paragraph">영구 스토리지로 Jenkins를 배포하려면 다음 단계를 수행하십시오.</block>
  <block id="d31d340fd6b135cac2cfac7b04a34c10" category="list-text">왼쪽 위 모서리에서 역할을 관리자 에서 개발자 로 변경합니다. Add(추가) 를 클릭하고 Catalog(카탈로그) 에서 선택합니다. 키워드별 필터 표시줄에서 Jenkins를 검색합니다. 영구 저장소를 사용하는 Jenkins Service 를 선택합니다.</block>
  <block id="bc5512ef7a17a0cfb58cb1ede30a6137" category="paragraph"><block ref="bc5512ef7a17a0cfb58cb1ede30a6137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6baa4bd25992de2d17278ade0d3090ad" category="list-text">"인스턴스화 템플릿"을 클릭합니다.</block>
  <block id="949381804bf1e16ca04ba9ac5fabc6a4" category="paragraph"><block ref="949381804bf1e16ca04ba9ac5fabc6a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7b4a6da6ab2733552de61d67b38a39e" category="list-text">기본적으로 Jenkins 응용 프로그램의 세부 정보가 채워집니다. 요구 사항에 따라 매개 변수를 수정하고 생성 을 클릭합니다. 이 프로세스는 OpenShift에서 Jenkins를 지원하는 데 필요한 모든 리소스를 생성합니다.</block>
  <block id="cc9a211dac876290bd6ed039cf1afdcf" category="paragraph"><block ref="cc9a211dac876290bd6ed039cf1afdcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb86f2dea9912af1bb1677c9cf33e619" category="list-text">Jenkins Pod는 Ready 상태로 들어가려면 약 10~12분이 걸립니다.</block>
  <block id="274c247b7612630006e3d87d5ed5d46f" category="paragraph"><block ref="274c247b7612630006e3d87d5ed5d46f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da33835bff86a0b0c8be6c67dcf677bb" category="list-text">포드가 인스턴스화된 후 네트워킹 &gt; 라우트로 이동합니다. Jenkins 웹 페이지를 열려면 Jenkins 루트에 제공된 URL을 클릭합니다.</block>
  <block id="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="paragraph"><block ref="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d59d1324dea050a2c0ffc376de411aa0" category="list-text">Jenkins 앱을 만드는 동안 OpenShift OAuth가 사용되었기 때문에 OpenShift로 로그인 을 클릭합니다.</block>
  <block id="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="paragraph"><block ref="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70a742210f3e3599821b3a11b682144c" category="list-text">Jenkins 서비스 계정을 인증하여 OpenShift 사용자에게 액세스합니다.</block>
  <block id="9359288fc248319fa9acef62e4686d1c" category="paragraph"><block ref="9359288fc248319fa9acef62e4686d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b07934b6023389a7e3e183b45e3b7448" category="list-text">Jenkins 시작 페이지가 표시됩니다. Maven 빌드를 사용하기 때문에 Maven 설치를 먼저 완료하십시오. Manage Jenkins &gt; Global Tool Configuration 으로 이동한 다음 Maven 하위 헤드에서 Add Maven 을 클릭합니다. 선택한 이름을 입력하고 자동 설치 옵션이 선택되어 있는지 확인합니다. 저장 을 클릭합니다.</block>
  <block id="00713894c16827219fd5ab50c5fc3794" category="paragraph"><block ref="00713894c16827219fd5ab50c5fc3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fd32305bf380bf893ef2407eae75f5d" category="list-text">이제 CI/CD 워크플로우를 시연하기 위한 파이프라인을 생성할 수 있습니다. 홈 페이지의 왼쪽 메뉴에서 새 작업 만들기 또는 새 항목 만들기를 클릭합니다.</block>
  <block id="24f99be3c7033ab08c3baec1cdf32702" category="paragraph"><block ref="24f99be3c7033ab08c3baec1cdf32702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b6fc174a3fad5c396413febe1d4ba50" category="list-text">항목 만들기 페이지에서 선택한 이름을 입력하고 파이프라인을 선택한 다음 확인을 클릭합니다.</block>
  <block id="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="paragraph"><block ref="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd55d787cacfb25983e0a24b58ba6d48" category="list-text">Pipeline 탭을 선택합니다. 샘플 파이프라인 시험 사용 드롭다운 메뉴에서 GitHub + Maven 을 선택합니다. 코드가 자동으로 채워집니다. 저장 을 클릭합니다.</block>
  <block id="dedbf53849830e8b275b69e9b98159ce" category="paragraph"><block ref="dedbf53849830e8b275b69e9b98159ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0191ad3b841f8db403ec4749d571eb4b" category="list-text">지금 구축을 클릭하여 준비, 빌드 및 테스트 단계를 통해 개발을 시작합니다. 전체 빌드 프로세스를 완료하고 빌드 결과를 표시하는 데 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="1d11f84feef51515ab9fdaafb3f02f3a" category="paragraph"><block ref="1d11f84feef51515ab9fdaafb3f02f3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b04b355d9fc6a2e23965649ebdd0aa31" category="list-text">코드 변경 사항이 있을 때마다 파이프라인을 재구축하여 새로운 소프트웨어 버전을 패치할 수 있으므로 지속적인 통합 및 지속적인 제공이 가능합니다. 최근 변경 내용 을 클릭하여 이전 버전의 변경 내용을 추적합니다.</block>
  <block id="43d9a2fc4d89e82c869a466778811ab3" category="paragraph"><block ref="43d9a2fc4d89e82c869a466778811ab3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b41ceffa053ec5210732b1f8d0f0c5d" category="inline-link-macro">다음: 비디오 및 데모.</block>
  <block id="232b127190e97018e70ee81d28e36117" category="paragraph"><block ref="232b127190e97018e70ee81d28e36117" category="inline-link-macro-rx"></block></block>
  <block id="55c7e45b50d0b012faf4bce31b6ad05d" category="section-title">스냅샷으로부터 VM을 생성하십시오</block>
  <block id="9e5a59ca9aef030e74a725dab3fb6dcf" category="paragraph">Astra Trident와 Red Hat OpenShift를 사용하면 IT에서 프로비저닝한 스토리지 클래스에서 영구 볼륨의 스냅샷을 생성할 수 있습니다. 이 기능을 사용하면 사용자는 볼륨의 시점 복사본을 만들어 새 볼륨을 생성하거나 동일한 볼륨을 이전 상태로 복원할 수 있습니다. 이를 통해 롤백에서 클론, 데이터 복원에 이르기까지 다양한 활용 사례를 지원하거나 지원할 수 있습니다.</block>
  <block id="f991e1a54e399d272c7d968dcdfdb690" category="paragraph">OpenShift의 스냅샷 작업의 경우 VolumeSnapshotClass, VolumeSnapshot 및 VolumeSnapshotContent 리소스를 정의해야 합니다.</block>
  <block id="0e2d1628ef03c4400cd293c3143cabb3" category="list-text">VolumeSnapshotContent는 클러스터의 볼륨에서 생성된 실제 스냅샷입니다. 이 리소스는 스토리지용 PersistentVolume과 유사한 클러스터 차원의 리소스입니다.</block>
  <block id="8ca4876558d3675f7a3e2c452c62a215" category="list-text">VolumeSnapshot은 볼륨의 스냅샷을 생성하기 위한 요청입니다. PersistentVolumeClaim과 유사합니다.</block>
  <block id="7f9fbed02a61699d31f7d9a0eb11bc81" category="list-text">VolumeSnapshotClass를 사용하면 관리자가 VolumeSnapshot에 대해 서로 다른 속성을 지정할 수 있습니다. 동일한 볼륨에서 생성된 서로 다른 스냅샷에 대해 서로 다른 속성을 가질 수 있습니다.</block>
  <block id="7f7858938c48bb9f08341c0e41c9162d" category="image-alt">VM을 생성할 수 있습니다</block>
  <block id="99bf6e1ad41f7875d5b7ec9f857c4f0f" category="paragraph">VM의 스냅샷을 생성하려면 다음 단계를 완료합니다.</block>
  <block id="5dc14d36063086387d2eb7cf012544aa" category="list-text">VolumeSnapshot을 생성하는 데 사용할 수 있는 VolumeSnapshotClass를 생성합니다. Storage &gt; VolumeSnapshotClasses 로 이동하고 Create VolumeSnapshotClass 를 클릭합니다.</block>
  <block id="52f0977d1e65469f01e2f290e637a8f1" category="list-text">스냅샷 클래스의 이름을 입력하고 드라이버에 csi.trident.netapp.io 를 입력한 다음 생성 을 클릭합니다.</block>
  <block id="508073b07367d898823f1841627451d4" category="image-alt">스냅샷 클래스를 생성합니다</block>
  <block id="2bde7e02152796551174ea391bda0b60" category="list-text">소스 VM에 연결된 PVC를 확인한 다음 해당 PVC의 스냅샷을 생성합니다. 'Storage &gt; VolumeSnapshots'로 이동하여 Create VolumeSnapshots을 클릭합니다.</block>
  <block id="b9513caba1fba7b4291a9e22bc512de5" category="list-text">스냅샷을 생성할 PVC를 선택하고 스냅샷 이름을 입력하거나 기본값을 적용한 다음 적절한 VolumeSnapshotClass를 선택합니다. 그런 다음 만들기 를 클릭합니다.</block>
  <block id="a7a384e6f13cae2ef877b4dd78fd48ad" category="image-alt">스냅샷 생성</block>
  <block id="d8ae3e40f0f0dba0b7c7ba5b8eea845a" category="list-text">그러면 해당 시점에 PVC의 스냅샷이 생성됩니다.</block>
  <block id="e9b3b34ca8f917d1968a106e682f1a97" category="section-title">스냅샷으로부터 새 VM을 생성합니다</block>
  <block id="3ffbaa72c8e63f0ec3ced08d8ebf9f72" category="list-text">먼저 스냅샷을 새 PVC로 복구합니다. Storage &gt; VolumeSnapshots로 이동하고 복원하려는 스냅샷 옆에 있는 줄임표를 클릭한 다음 Restore as new PVC(새 PVC로 복원) 를 클릭합니다.</block>
  <block id="5160cd070df38f982551c5fea6f1c844" category="list-text">새 PVC의 세부 정보를 입력하고 Restore(복원) 를 클릭합니다. 이렇게 하면 새 PVC가 생성됩니다.</block>
  <block id="0d695454ca10516a832452b6123c5bb5" category="image-alt">스냅샷을 새 PVC로 복원합니다</block>
  <block id="8a4d1acf8df9931b5c42b3253f943d79" category="list-text">다음으로 이 PVC에서 새 VM을 생성합니다. 워크로드 &gt; 가상화 &gt; 가상 시스템으로 이동하고 생성 &gt; YAML을 클릭합니다.</block>
  <block id="91b9a57ab88a6942f692f9f393549f6e" category="list-text">spec &gt; template &gt; spec &gt; volumes 섹션에서 컨테이너 디스크 대신 스냅샷에서 생성된 새 PVC를 지정합니다. 요구 사항에 따라 새 VM에 대한 기타 모든 세부 정보를 제공합니다.</block>
  <block id="57dc3c96f32e4895e89eab4a248088f5" category="list-text">VM이 성공적으로 생성된 후 스냅샷이 생성된 시점에 스냅샷을 생성하는 데 PVC를 사용한 VM의 상태와 새 VM의 상태가 동일한지 액세스 및 확인합니다.</block>
  <block id="50465c19760e2a5476479f1f4a464119" category="summary">NetApp의 Bare Metal Anthos는 배포된 인프라의 사용자 지정을 가능하게 하여 컨테이너 기반 워크로드를 효율적으로 실행할 수 있는 강력한 플랫폼을 제공합니다.</block>
  <block id="f887fad1ad196c388701d07189696570" category="paragraph">NetApp의 Bare Metal Anthos는 배포된 인프라의 사용자 지정을 가능하게 하여 컨테이너 기반 워크로드를 효율적으로 실행할 수 있는 강력한 플랫폼을 제공합니다. 고객은 원하는 서버 인프라와 지원되는 운영 체제를 사용하거나 기존 인프라에 솔루션을 배포할 수도 있습니다. NetApp ONTAP 및 NetApp Trident를 통합하여 컨테이너용 영구 스토리지를 효율적으로 프로비저닝 및 관리하여 상태 저장 애플리케이션 워크로드를 지원함으로써 이러한 환경의 성능과 유연성을 크게 높여줍니다. Google Cloud의 잠재력을 NetApp이 제공하는 데이터 센터로 확장함으로써, 고객은 애플리케이션 워크로드를 개발 및 프로덕션하기 위해 완벽하게 지원되고 가용성이 높고 쉽게 확장 가능하며 완벽하게 관리되는 Kubernetes 솔루션의 이점을 실현할 수 있습니다.</block>
  <block id="3ae752a47170fdc4f7ff5ed3204c1fb5" category="paragraph"><block ref="3ae752a47170fdc4f7ff5ed3204c1fb5" category="inline-link-macro-rx"></block></block>
  <block id="31fd0c2c8d388a4cd2c6459234743476" category="section-title">관찰 가능성</block>
  <block id="e98511d60f9850de86f096614f447322" category="paragraph">Kubernetes용 고급 클러스터 관리를 사용하면 모든 클러스터에서 노드, 포드, 애플리케이션 및 워크로드를 모니터링할 수 있습니다.</block>
  <block id="36aff44ed429ca86d182dc7ee3dfdbb1" category="list-text">환경 관찰 &gt; 개요 로 이동합니다.</block>
  <block id="7a6ccefec75a946583cffdd0a8a47e09" category="image-alt">관찰 가능성 홈 페이지</block>
  <block id="c9904a9276a489fc238c999d2ddd633f" category="list-text">모든 클러스터에 있는 모든 Pod 및 워크로드는 다양한 필터를 기준으로 모니터링 및 정렬됩니다. 해당 데이터를 보려면 Pod를 클릭합니다.</block>
  <block id="4a973ae1a908770e354f949d3c0592f8" category="image-alt">포드 관찰</block>
  <block id="7cd1c61051d3647bc47d839e0efee222" category="list-text">다양한 데이터 요소를 기반으로 클러스터 전체의 모든 노드를 모니터링하고 분석합니다. 노드를 클릭하여 해당 세부 정보를 자세히 확인합니다.</block>
  <block id="8a373f777de729c082b5be2d80b7eca6" category="image-alt">노드를 관찰합니다</block>
  <block id="4e7f54a0ebc5cd69209a17181d477e4c" category="list-text">모든 클러스터는 다양한 클러스터 리소스 및 매개 변수를 기반으로 모니터링 및 구성됩니다. 클러스터 세부 정보를 보려면 클러스터 를 클릭합니다.</block>
  <block id="2ececa2c251a851a85e976daae558c81" category="image-alt">클러스터 관찰</block>
  <block id="a883982d5f8961021329c238318d4e2b" category="inline-link-macro">다음: 기능 - 리소스 생성</block>
  <block id="5ca146f2101c14a961df161060f86cb9" category="paragraph"><block ref="5ca146f2101c14a961df161060f86cb9" category="inline-link-macro-rx"></block></block>
  <block id="a0c55f3c40b8bb2d3e26f8d11ca73cbc" category="summary">이 참조 문서는 NetApp에서 검증한 바와 같이 여러 데이터 센터 환경에서 IPI(Installer provisioned Infrastructure)를 통해 배포된 Red Hat OpenShift 솔루션의 배포 검증을 제공합니다. 또한, 영구 스토리지 관리를 위한 Astra Trident 스토리지 오케스트레이터를 사용하여 NetApp 스토리지 시스템과의 스토리지 통합에 대해서도 자세히 설명합니다. 마지막으로, 다양한 솔루션 검증 및 실제 사용 사례를 살펴보고 문서화합니다.</block>
  <block id="a0e01d06503f271c1de7acc0acd01733" category="doc">NVA-1160: NetApp 기반의 Red Hat OpenShift</block>
  <block id="3f4b17e041e63192875c654812122484" category="paragraph">NetApp의 Alan Cowles와 Nikhil M Kulkarni입니다</block>
  <block id="4711a0fd2fa3c3625080f399e5261ecd" category="paragraph">NetApp OpenShift with NetApp 솔루션은 다음과 같은 사용 사례를 통해 고객에게 뛰어난 가치를 제공하도록 설계되었습니다.</block>
  <block id="44815e873492015d6a8ab6362de8da6c" category="list-text">베어 메탈, Red Hat OpenStack Platform, Red Hat Virtualization 및 VMware vSphere에 IPI(Installer Provisioned Infrastructure)를 사용하여 배포된 Red Hat OpenShift를 쉽게 배포 및 관리할 수 있습니다.</block>
  <block id="03bb323d052d033ea0b5b2cab17f1219" category="list-text">OSP, RHV, vSphere 또는 OpenShift Virtualization을 통해 가상 배포된 Red Hat OpenShift를 사용하여 엔터프라이즈 컨테이너 및 가상화된 워크로드의 성능을 합친 것입니다.</block>
  <block id="a2ac5b8f3de7c17418af38c828121a15" category="list-text">NetApp 스토리지와 Kubernetes용 오픈 소스 스토리지 오케스트레이터인 Astra Trident의 Red Hat OpenShift의 기능을 설명하는 실제 구성 및 사용 사례</block>
  <block id="f08561bbd831bfa1923e6acf045ef13a" category="section-title">비즈니스 가치</block>
  <block id="932ba7da1da9b241bfc5ddbb10e49da2" category="paragraph">기업은 새로운 제품을 만들고, 릴리즈 주기를 단축하며, 새로운 기능을 빠르게 추가하기 위해 DevOps 사례를 점점 더 채택하고 있습니다. 컨테이너 및 마이크로서비스는 타고난 애자일 특성상 DevOps 사례를 지원하는 데 중요한 역할을 합니다. 그러나 엔터프라이즈 환경에서 운영 환경에서 DevOps를 수행하는 것은 그 자체로 문제가 되며 다음과 같은 기본 인프라에서 특정 요구사항을 부과합니다.</block>
  <block id="43ee156205e7f74e32a02d556537fe90" category="list-text">스택의 모든 계층에서 고가용성 보장</block>
  <block id="b59807af538b77fee1fb3d1d3c81f9a8" category="list-text">간편한 구축 절차</block>
  <block id="2748d7182409b378e23f62724be778fd" category="list-text">무중단 운영 및 업그레이드</block>
  <block id="1a4af279491c72d7c36b4c9767ae712f" category="list-text">마이크로서비스 민첩성을 유지하기 위한 API 기반 및 프로그래밍 가능한 인프라</block>
  <block id="0cdff7d38ef496f6b5510c5034fedf15" category="list-text">성능 보장이 포함된 멀티 테넌시</block>
  <block id="8ca11bfd783c730b04c0c77fc7574406" category="list-text">가상화 워크로드 및 컨테이너화된 워크로드를 동시에 실행할 수 있습니다</block>
  <block id="0111977afdb7fa380f806edbe8438163" category="list-text">워크로드 요구사항에 따라 인프라를 독립적으로 확장할 수 있는 능력</block>
  <block id="42c487483a8feee3cc0365881a4cc265" category="paragraph">NetApp의 Red Hat OpenShift는 이러한 문제를 인식하고 고객이 선택한 데이터 센터 환경에 RedHat OpenShift IPI를 완전히 자동으로 배포하여 각 문제를 해결하는 솔루션을 제시합니다.</block>
  <block id="d3d8eb53a347d6ffc9fb157d9ac8398b" category="paragraph">NetApp OpenShift의 경우 NetApp 솔루션은 다음과 같은 주요 구성요소로 이루어져 있습니다.</block>
  <block id="fd89bb4228981d3b22187eb451421cd6" category="section-title">Red Hat OpenShift Container Platform</block>
  <block id="2b8932b35916e8cecb6216546111322e" category="paragraph">Red Hat OpenShift Container Platform은 완전히 지원되는 엔터프라이즈 Kubernetes 플랫폼입니다. Red Hat은 컨테이너화된 애플리케이션을 구축, 배포 및 관리하기 위해 모든 구성 요소가 완벽하게 통합된 애플리케이션 플랫폼을 제공하기 위해 오픈 소스 Kubernetes를 몇 가지 개선하였습니다.</block>
  <block id="70240bc0debcb080aa08dbd9e7b9a525" category="paragraph">자세한 내용은 OpenShift 웹 사이트를 참조하십시오<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="81f74b2a02db97d708bd7cbf08d2463a" category="section-title">NetApp 스토리지 시스템을 나타냅니다</block>
  <block id="660d073f0987fac312dc40bd5dc868bd" category="paragraph">NetApp은 엔터프라이즈 데이터 센터 및 하이브리드 클라우드 구축에 적합한 여러 스토리지 시스템을 보유하고 있습니다. NetApp 포트폴리오에는 NetApp ONTAP, NetApp Element, NetApp E-Series 스토리지 시스템이 포함되어 있으며, 컨테이너식 애플리케이션을 위한 영구 스토리지를 제공할 수 있습니다.</block>
  <block id="aa4193984de53d2a6d8fcc2d77c09bda" category="paragraph">자세한 내용은 NetApp 웹 사이트를 참조하십시오<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="069b087e8e1e69cc928f18a85f683523" category="section-title">NetApp 스토리지 통합</block>
  <block id="b4186621511a622be24ad982b0a8ec32" category="paragraph">NetApp Astra Control Center는 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공하며, 온프레미스 환경에 구축되어 신뢰할 수 있는 NetApp 데이터 보호 기술을 기반으로 합니다.</block>
  <block id="947496ade2e4a2c8e929d9aa9f00be04" category="paragraph">자세한 내용은 NetApp Astra 웹 사이트를 참조하십시오<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="05cd0cf0962d29806df78d956f772deb" category="paragraph">Astra Trident는 Red Hat OpenShift를 포함한 컨테이너 및 Kubernetes 배포를 위한 오픈 소스 및 완전 지원 스토리지 오케스트레이터입니다.</block>
  <block id="0bc570c518e7c4f356ebceb14fa8372f" category="section-title">고급 구성 옵션</block>
  <block id="aa44798f04a58b33c3699abd02a59c57" category="paragraph">이 섹션에서는 전용 개인 이미지 레지스트리를 만들거나 사용자 지정 로드 밸런서 인스턴스를 배포하는 등 실제 사용자가 이 솔루션을 운영 환경에 배포할 때 수행해야 할 사용자 지정 작업에 대해 설명합니다.</block>
  <block id="382742bb5fff6a719c144a0a01cd17e3" category="section-title">검증된 릴리즈에 대한 최신 지원 매트릭스</block>
  <block id="e7e767d7c0e58b16e57d3ab16150db80" category="cell">제공합니다</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">소프트웨어 버전</block>
  <block id="bd4a2d19c5168aa8c2b89b4affba2402" category="cell">9.8, 9.9.1</block>
  <block id="fcda5b98e8c212807dc088477e802757" category="cell">NetApp Element</block>
  <block id="601712ded7a71b0842984ad41b6aad39" category="cell">12.3</block>
  <block id="12c17259bf3f3b36e970c9e3abbc6b43" category="cell">NetApp Astra Control Center를 참조하십시오</block>
  <block id="8d96276332b02a2ef892828c1d4fbab4" category="cell">애플리케이션 인식 데이터 관리</block>
  <block id="8de59ec369b10820d0dd336b9765c79b" category="cell">NetApp Astra Trident</block>
  <block id="765bb3744268ca0de607208bfdc8a37a" category="cell">스토리지 오케스트레이션</block>
  <block id="b175d08ac03101cd40f077848d436e1f" category="cell">Red Hat OpenShift</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">컨테이너 오케스트레이션</block>
  <block id="2454407b9991c6c5f417a2feb8ea7970" category="cell">4.6 EUS, 4.7</block>
  <block id="9c4e78a1b7e7b4981aced1e10d037c6d" category="cell">Red Hat OpenStack 플랫폼</block>
  <block id="de45aa336111dfa1825c54726464307c" category="cell">프라이빗 클라우드 인프라</block>
  <block id="3c5825a0d4bdb85c67182ef89bc9c7eb" category="cell">16.1</block>
  <block id="80e910f35b12e9c61335fa88de36edd0" category="cell">Red Hat 가상화</block>
  <block id="e3024b13494086daa1b9813a799ba41a" category="cell">데이터 센터 가상화</block>
  <block id="f9a97ed4e88eeab44f2693afa0eb2089" category="cell">4.4</block>
  <block id="8887a9a417a1629326acdb917d224337" category="cell">VMware vSphere를 참조하십시오</block>
  <block id="9c295b8302ac546bb93a346b68089f50" category="cell">6.7U3</block>
  <block id="aacc79f269e716528198eabb064b216b" category="inline-link-macro">다음은 Red Hat OpenShift 개요입니다.</block>
  <block id="62857c2aca7eeae2c1f44104c3fc7dde" category="paragraph"><block ref="62857c2aca7eeae2c1f44104c3fc7dde" category="inline-link-macro-rx"></block></block>
  <block id="472d13eb415cd6107aeef3a1ae6cd705" category="summary">NetApp은 Red Hat OpenShift와 같은 컨테이너 기반 환경에서 지속적인 데이터를 오케스트레이션하고 관리할 수 있도록 고객을 지원하는 다양한 제품을 제공합니다.</block>
  <block id="2515fbef39d57544723402c683215c64" category="doc">NetApp 스토리지 통합 개요</block>
  <block id="689ca76b61ed9331405d36eb5ded709d" category="paragraph">NetApp은 Red Hat OpenShift와 같은 컨테이너 기반 환경에서 영구 데이터를 오케스트레이션하고 관리하는 데 도움이 되는 다양한 제품을 제공합니다.</block>
  <block id="ebfc0e639726a366f8eb5ac86bb7cc43" category="paragraph"><block ref="ebfc0e639726a366f8eb5ac86bb7cc43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c3fd18fbca2ec11aa1ef250cf79f2e5" category="paragraph">NetApp Astra Control은 NetApp 데이터 보호 기술을 기반으로 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공합니다. Astra Control Service는 클라우드 네이티브 Kubernetes 구축에서 상태 저장 워크로드를 지원할 수 있습니다. Astra Control Center는 Red Hat OpenShift와 같은 온프레미스 배포에서 상태 저장 워크로드를 지원할 수 있습니다. 자세한 내용은 NetApp Astra Control 웹 사이트를 참조하십시오<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="cd351007d4a671a321b6881f730d0dc3" category="paragraph">다음 페이지는 NetApp OpenShift with NetApp 솔루션에서 애플리케이션 및 영구 스토리지 관리를 위해 검증된 NetApp 제품에 대한 추가 정보를 제공합니다.</block>
  <block id="afa49872fb8ae001174e4c8f2cc47208" category="inline-link-macro">다음은 NetApp Astra Control Center의 개요입니다</block>
  <block id="22fd530ae76b4bbe50669b9a4d5b72d7" category="paragraph"><block ref="22fd530ae76b4bbe50669b9a4d5b72d7" category="inline-link-macro-rx"></block></block>
  <block id="f79c612e785ac74789a25e8dda9e8731" category="doc">Astra Trident 개요</block>
  <block id="78c43863df60a7808264e8659cfa6b54" category="paragraph">Astra Trident는 Red Hat OpenShift를 포함하여 컨테이너 및 Kubernetes 배포를 위한 오픈 소스 및 완전 지원되는 스토리지 오케스트레이터입니다. Trident는 NetApp ONTAP 및 Element 스토리지 시스템을 포함한 전체 NetApp 스토리지 포트폴리오와 연동되며 NFS 및 iSCSI 연결도 지원합니다. Trident는 최종 사용자가 스토리지 관리자의 개입 없이 NetApp 스토리지 시스템에서 스토리지를 프로비저닝 및 관리할 수 있도록 하여 DevOps 워크플로우를 가속합니다.</block>
  <block id="a4957cf974ce20219897bbbf5b131cb8" category="paragraph">관리자는 특정 수준의 성능을 보장하는 압축, 특정 디스크 유형 또는 QoS 수준을 비롯한 고급 스토리지 기능을 지원하는 스토리지 시스템 모델과 프로젝트 요구사항에 따라 여러 스토리지 백엔드를 구성할 수 있습니다. 이러한 백엔드를 정의한 후, 개발자는 프로젝트의 이러한 백엔드를 사용하여 지속적인 PVC(Volume Claim)를 생성하고 필요에 따라 컨테이너에 영구 저장소를 연결할 수 있습니다.</block>
  <block id="ecfb2402c181e98da49a5d763378b116" category="paragraph"><block ref="ecfb2402c181e98da49a5d763378b116" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0626021388a8dcc9b1e26b1209550b8d" category="paragraph">Astra Trident는 빠른 개발 주기를 제공하며, Kubernetes와 마찬가지로 1년에 4회 릴리즈됩니다.</block>
  <block id="b62bb4786ef52ad76706950add6991dd" category="paragraph">20.04 릴리즈부터 Trident 운영자가 Trident 설정을 수행합니다. 운영자는 대규모 구축을 용이하게 하고 Trident 설치의 일부로 배포된 Pod에 대한 자동 복구를 포함한 추가 지원을 제공합니다.</block>
  <block id="4a85fdd5a26454abc330a5ec2a46a326" category="paragraph">21.01 릴리즈를 통해 Trident Operator의 설치를 용이하게 하는 제어 차트를 사용할 수 있게 되었습니다.</block>
  <block id="4281e618126caa3d322e78eafddba1b2" category="section-title">Astra Trident를 다운로드하십시오</block>
  <block id="f95d0437e813349fa018b7f0e68e9a7d" category="paragraph">구축된 사용자 클러스터에 Trident를 설치하고 영구 볼륨을 프로비저닝하려면 다음 단계를 완료하십시오.</block>
  <block id="422269f9bb560b76869cbd586b8370d5" category="list-text">다운로드한 번들에서 Trident 설치를 추출합니다.</block>
  <block id="52d012c119e8e080d08f6a1592f8f9ec" category="section-title">Hrom을 사용하여 Trident 연산자를 설치합니다</block>
  <block id="68602d0447fae81afa9d0528ef0c6420" category="list-text">먼저 사용자 클러스터의 "kubecononfig" 파일 위치를 환경 변수로 설정하여 Trident에 이 파일을 전달할 수 있는 옵션이 없으므로 참조할 필요가 없습니다.</block>
  <block id="449774824d889f1d6ebc0bbcc4920493" category="list-text">Helm 명령을 실행하여 사용자 클러스터에 삼중덴트 네임스페이스를 생성하는 동안 Helm 디렉토리의 tarball에서 Trident 연산자를 설치합니다.</block>
  <block id="64e437a845e5de3c8e50925ebdfce295" category="list-text">네임스페이스에서 실행 중인 포드를 확인하거나 tridentctl 바이너리를 사용하여 설치된 버전을 확인하여 Trident가 성공적으로 설치되었는지 확인할 수 있습니다.</block>
  <block id="3ce67d5de6974f67e0048e6fdbf89498" category="admonition">경우에 따라 고객 환경에 Trident 구축의 사용자 지정이 필요할 수 있습니다. 이러한 경우 Trident 연산자를 수동으로 설치하고 포함된 매니페스트를 업데이트하여 배포를 사용자 지정할 수도 있습니다.</block>
  <block id="8bd534d3b6bc8d2541df052e053ed65d" category="section-title">Trident 연산자를 수동으로 설치합니다</block>
  <block id="1315b42a551dafb715ab654d8eb5af40" category="list-text">먼저, Trident에 이 파일을 전달할 수 있는 옵션이 없기 때문에 사용자 클러스터의 "kubecononfig" 파일을 참조할 필요가 없도록 환경 변수로 설정합니다.</block>
  <block id="5d710ec7d521df428edd75c1885ee89b" category="list-text">트리덴트 설치 프로그램 디렉토리에는 필요한 모든 리소스를 정의하기 위한 매니페스트가 들어 있습니다. 적절한 매니페스트를 사용하여 '트리엔오케스트레이터' 사용자 지정 리소스 정의를 만듭니다.</block>
  <block id="0ac11186fb38b2e9d4acd38d03f61b5c" category="list-text">Trident 네임스페이스가 없으면 제공된 매니페스트를 사용하여 클러스터에 Trident 네임스페이스를 만듭니다.</block>
  <block id="004c51fe71b5c654f88a31270ec6c8e9" category="list-text">연산자에 대한 'erviceAccount', 'clusterRole', 'ClusterRoleBinding', 'erviceAccount', 'PodSecurityPolicy', 또는 연산자 자체에 대한 'erviceAccount' 등 Trident 운용자 구축에 필요한 리소스를 생성한다.</block>
  <block id="f7b9c678b684e969a3ee5ac971514f48" category="list-text">다음 명령을 사용하여 운영자 배포 후 상태를 확인할 수 있습니다.</block>
  <block id="b34dd67c198ad4cf0088bd29c7ef4658" category="list-text">운영자가 구축되었으므로 이제 Trident를 설치할 수 있습니다. 이를 위해서는 '트리엔오케스트레이터'를 만들어야 합니다.</block>
  <block id="e32d70a13ba1767d9a373fe9a0535531" category="section-title">스토리지에 대한 작업자 노드 준비</block>
  <block id="4b4d60be85b0c53c72ae4b8a05deacef" category="paragraph">대부분의 Kubernetes 배포판에는 Red Hat OpenShift를 포함하여 기본적으로 설치된 NFS 백엔드를 마운트하는 패키지와 유틸리티가 함께 제공됩니다.</block>
  <block id="693642fbb464db49c22715a536e99c3f" category="paragraph">iSCSI 프로토콜을 통해 블록 스토리지 볼륨을 매핑할 수 있도록 작업자 노드를 준비하려면 해당 기능을 지원하는 데 필요한 패키지를 설치해야 합니다.</block>
  <block id="cccb85b5e6a9a19187087f71254d1fb2" category="paragraph">Red Hat OpenShift에서는 MCO(Machine Config Operator)를 배포된 후 클러스터에 적용하여 처리됩니다.</block>
  <block id="7b8e6ef8272a81ebcc108ee3fcf4eac8" category="list-text">OCP 웹 콘솔에 로그인하여 Compute(컴퓨팅) &gt; Machine Configs(장비 구성) 로 이동합니다. Create Machine Config 를 클릭합니다. YAML 파일을 복사하여 붙여넣은 다음 생성 을 클릭합니다.</block>
  <block id="c25282bfd8c140d1f79c25362637f744" category="paragraph">다중 경로를 사용하지 않는 경우:</block>
  <block id="541c76e8762c84e3e0488f91c8062e08" category="paragraph">다중 경로 사용 시:</block>
  <block id="d9f036d3b9f84b626f8a777480066cab" category="list-text">구성을 생성한 후 작업자 노드에 구성을 적용하고 다시 로드하는 데 약 20~30분이 걸립니다. 'OC Get MCP'를 사용하여 기계 설정이 적용되었는지 확인하고 작업자에 대한 기계 구성 풀이 업데이트되었는지 확인합니다. 작업자 노드에 로그인하여 iscsid 서비스가 실행 중인지 확인할 수도 있습니다(다중 경로를 사용하는 경우 multipathd 서비스가 실행 중인지 확인).</block>
  <block id="6e16409ed6038c106c7fa1dfbfb9da0f" category="admonition">또한 MachineConfig가 성공적으로 적용되고 서비스가 예상대로 시작되었는지 확인할 수 있는 것은 적절한 플래그를 사용하여 OC debug 명령을 실행하는 것입니다.</block>
  <block id="b09d268106fd9cbfffd1dc848382a150" category="section-title">스토리지 시스템 백엔드를 생성합니다</block>
  <block id="f71051465199267cbb540658a51e2957" category="paragraph">Astra Trident Operator 설치를 완료한 후에는 사용 중인 특정 NetApp 스토리지 플랫폼에 대한 백엔드를 구성해야 합니다. Astra Trident의 설정 및 구성을 계속하려면 아래 링크를 따라가십시오.</block>
  <block id="615767b52353571ac174e22f1a984aa3" category="inline-link-macro">NetApp ONTAP NFS 를 참조하십시오</block>
  <block id="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="list-text"><block ref="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="inline-link-macro-rx"></block></block>
  <block id="c93e7ef2934826b1393251e9f7d9e331" category="inline-link-macro">NetApp ONTAP iSCSI를 참조하십시오</block>
  <block id="d7b539d4bc16fbdf1477adddfda6c802" category="list-text"><block ref="d7b539d4bc16fbdf1477adddfda6c802" category="inline-link-macro-rx"></block></block>
  <block id="d0e0904111acb167badbf5f196ad1205" category="inline-link-macro">NetApp Element iSCSI 를 참조하십시오</block>
  <block id="2e5d36490241211379006b7f6934bf06" category="list-text"><block ref="2e5d36490241211379006b7f6934bf06" category="inline-link-macro-rx"></block></block>
  <block id="122aacda8785e42ca8fd7bd6ebce84f8" category="summary">VMware vSphere는 ESXi 하이퍼바이저에서 실행되는 다수의 가상 서버 및 네트워크를 중앙에서 관리하기 위한 가상화 플랫폼입니다.</block>
  <block id="68bc8529d7c57946fe13e6b3399ee287" category="inline-link">VMware vSphere 웹 사이트</block>
  <block id="80888e73d00a224bebfc22e8e4539b6d" category="paragraph">VMware vSphere에 대한 자세한 내용은 를 참조하십시오<block ref="8e822bbeb5824c0a05189bf9ff98da5c" category="inline-link-rx"></block>.</block>
  <block id="cb4d59b9004b7c584811a3d656f78bc5" category="paragraph">VMware vSphere는 다음과 같은 기능을 제공합니다.</block>
  <block id="a542faac65568ba146d392d835d7fb33" category="list-text">* VMware vCenter Server. * VMware vCenter Server는 단일 콘솔에서 모든 호스트와 VM에 대한 통합 관리를 제공하고 클러스터, 호스트 및 VM의 성능 모니터링을 집계합니다.</block>
  <block id="413563ec6c2672beb7df15f465cb4a48" category="list-text">* VMware vSphere vMotion * VMware vCenter를 사용하면 요청 시 중단 없이 클러스터 내의 노드 간에 VM을 핫 마이그레이션할 수 있습니다.</block>
  <block id="e6583703b8777be27f8db85d741711b4" category="list-text">* vSphere High Availability. * 호스트 장애 시 운영 중단을 방지하기 위해 VMware vSphere를 사용하면 호스트를 클러스터링하고 고가용성을 구성할 수 있습니다. 호스트 장애로 인해 중단된 VM은 클러스터의 다른 호스트에서 곧 재부팅되어 서비스가 복구됩니다.</block>
  <block id="46b35ead34118cb2c50327c71e4aa640" category="list-text">* DRS(Distributed Resource Scheduler). * VMware vSphere 클러스터는 호스팅 중인 VM의 리소스 요구 사항을 로드 밸런싱하도록 구성할 수 있습니다. 리소스 경합 상태의 VM은 클러스터의 다른 노드로 핫 마이그레이션할 수 있으므로 충분한 리소스를 사용할 수 있습니다.</block>
  <block id="cfb123c76f1c7a506310e1162d7ae235" category="paragraph"><block ref="cfb123c76f1c7a506310e1162d7ae235" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c6371faa8d72dee8337811921707a4b" category="paragraph">NetApp 기반 Red Hat OpenShift 솔루션은 2개의 데이터 스위치를 사용하여 25Gbps의 기본 데이터 연결을 제공합니다. 또한 스토리지 노드의 대역 내 관리를 위해 1Gbps에서 연결을 제공하는 두 개의 추가 관리 스위치와 IPMI 기능의 대역 외 관리를 사용합니다. OCP는 VMware vSphere에서 클러스터 관리를 위해 VM 논리 네트워크를 사용합니다. 이 섹션에서는 솔루션에 사용되는 각 가상 네트워크 세그먼트의 배열 및 용도에 대해 설명하고 솔루션 구축을 위한 사전 요구 사항을 설명합니다.</block>
  <block id="e75b582a8823d532f6022b43ac209538" category="paragraph">VMware vSphere의 Red Hat OpenShift는 VLAN(Virtual Local Area Network)을 사용하여 서로 다른 목적으로 네트워크 트래픽을 논리적으로 분리하도록 설계되었습니다. 이 구성은 고객의 요구에 맞게 확장하거나 특정 네트워크 서비스에 대한 추가 격리를 제공할 수 있습니다. 다음 표에는 NetApp 솔루션의 유효성을 검사하는 동안 솔루션을 구현하는 데 필요한 VLAN이 나와 있습니다.</block>
  <block id="3c8c5d8387f173924ffeb2bf88084dba" category="cell">물리적 노드 및 IPMI에 대한 관리</block>
  <block id="c61d980d5248923d65a5dfe7f8818011" category="cell">VM 네트워크</block>
  <block id="f33bd5bca507f2b59fc0a43383ade71b" category="cell">가상 게스트 네트워크 액세스</block>
  <block id="cd3718e8610b820344c9a0284fe84f90" category="cell">스토리지 네트워크</block>
  <block id="c846a1f843522d592b784a66368abed3" category="cell">ONTAP NFS용 스토리지 네트워크</block>
  <block id="6cdd60ea0045eb7a6ec44c54d29ed402" category="cell">184</block>
  <block id="5e6094f6f2176409f469ee445fcf3f50" category="cell">ONTAP iSCSI용 스토리지 네트워크</block>
  <block id="eecca5b6365d9607ee5a9d336962c534" category="cell">185</block>
  <block id="45cf0331a91fdc3679a78fdd8f7c60a7" category="cell">ESXi 노드, vCenter Server, ONTAP Select에 대한 관리</block>
  <block id="e8e0dd181e4ee545195120626098bfba" category="cell">3480</block>
  <block id="11967d5f57969ea4713204eace8fbf4e" category="cell">NetApp Element iSCSI용 스토리지 네트워크</block>
  <block id="3fb04953d95a94367bb133f862402bce" category="cell">3481</block>
  <block id="3de18ffc25309bd0755d8543a30ded78" category="cell">마이그레이션 네트워크</block>
  <block id="c87f7de78a1912f53050e58df90e1445" category="cell">가상 게스트 마이그레이션을 위한 네트워크</block>
  <block id="b7fede84c2be02ccb9c77107956560eb" category="cell">3482</block>
  <block id="9335616a8b7dc0e6f94fd0c6aa720efe" category="list-text">대역 내 관리 네트워크 및 VM 네트워크에서 액세스할 수 있는 전체 호스트 이름 확인을 제공하는 DNS 서버가 하나 이상 있어야 합니다.</block>
  <block id="bd690c49b77b8274786240fa94d9d880" category="section-title">최소 3개의 노드로 구성된 ESXi 클러스터에 OpenShift를 배포합니다</block>
  <block id="3500f2194985ef1b586c649fbe519d8d" category="paragraph">이 문서에 설명된 검증된 아키텍처는 2개의 ESXi 하이퍼바이저 노드를 구축하고 VMware vSphere HA 및 VMware vMotion을 활성화하여 내결함성 구성을 보장하여 HA 작업에 적합한 최소 하드웨어 구축을 제공합니다. 이 구성을 사용하면 배포된 VM이 두 하이퍼바이저 간에 마이그레이션되고 하나의 호스트를 사용할 수 없게 될 경우 재부팅됩니다.</block>
  <block id="e79fa01ec6b411cfda4f8baad9f95cb0" category="paragraph">Red Hat OpenShift는 처음에 3개의 마스터 노드와 함께 배포되기 때문에 일부 환경에서는 2노드 구성의 최소 2개의 마스터가 동일한 노드를 차지할 수 있으며, 이로 인해 특정 노드를 사용할 수 없게 될 경우 OpenShift에 장애가 발생할 수 있습니다. 따라서 OpenShift 마스터를 균등하게 배포하여 내결함성을 한층 더 높일 수 있도록 ESXi 하이퍼바이저 노드를 3개 이상 구축해야 하는 것이 Red Hat의 모범 사례입니다.</block>
  <block id="9dc31e1598f94b9476a025632cee3e19" category="section-title">가상 머신 및 호스트 선호도를 구성합니다</block>
  <block id="f5428382aa8b44d7ef6ca71195afc8ca" category="paragraph">VM 및 호스트 친화성을 활성화하여 여러 하이퍼바이저 노드에 OpenShift 마스터를 배포할 수 있습니다.</block>
  <block id="c23c2371397ad3490af42526283948a4" category="paragraph">유사성 또는 반유사성은 VM 및/또는 호스트 세트에 대한 규칙을 정의하는 방법으로, VM이 그룹의 동일한 호스트 또는 호스트에서 함께 실행되는지 아니면 다른 호스트에서 실행되는지를 결정합니다. VM 및/또는 동일한 매개 변수와 조건 집합을 가진 호스트로 구성된 선호도 그룹을 생성하여 VM에 적용됩니다. 선호도 그룹의 VM이 그룹의 동일한 호스트에서 실행되는지, 아니면 다른 호스트에서 개별적으로 실행되는지에 따라 선호도 그룹의 매개 변수는 양의 선호도 또는 음의 선호도를 정의할 수 있습니다.</block>
  <block id="9934283c0bf98610b4be1803b9ad3430" category="inline-link">vSphere 6.7 설명서: DRS 선호도 규칙 사용</block>
  <block id="291f24f63dc31f9f921b09c567fc963f" category="paragraph">선호도 그룹을 구성하려면 을 참조하십시오<block ref="4b14049244eae7b3d11ef8e44785dd4e" category="inline-link-rx"></block>.</block>
  <block id="7b65abec68958867d7dd5f43b3b06e08" category="inline-link">Red Hat OpenShift 사용자 지정과 함께 vSphere에 클러스터 설치</block>
  <block id="6e7315bf45cda77f0a1477ed6f712eb6" category="paragraph">이 경우 즉시 클러스터를 배포하지 않고도 마법사를 실행하고 작업을 수행할 수 있지만 마법사는 나중에 클러스터를 배포할 수 있는 구성 파일을 만듭니다. IPI 기본값을 변경해야 하거나 다중 테넌시와 같은 다른 용도로 환경에 여러 동일한 클러스터를 배포하려는 경우 매우 유용합니다. OpenShift에 대한 사용자 지정 설치 구성을 만드는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="fc4239653f75b84dd3ca03fe8b28dd64" category="inline-link-rx"></block>.</block>
  <block id="4d7f7f28f54da25e8386b6cfbcbda861" category="summary">이 솔루션의 현재 배포는 Google Cloud 팀이 제공하는 도구를 사용하여 두 가지 엄격한 검증 프로세스를 거쳤습니다.</block>
  <block id="9fc7e91d0cfa196bee652e5b3ab8991b" category="doc">솔루션 검증</block>
  <block id="1bee22d71e0dda5649b05ac8074a7994" category="paragraph">이 솔루션의 현재 배포는 Google Cloud 팀이 제공하는 도구를 사용하여 두 가지 엄격한 검증 프로세스를 거쳤습니다. 이러한 검증에는 다음 테스트의 하위 집합이 포함됩니다.</block>
  <block id="9ce4b6121b9169f9a57e370bc063e43a" category="list-text">Anthos 지원 플랫폼에 대한 파트너 검증:</block>
  <block id="b490ae83108f0a60d2d464f37aed5b33" category="list-text">베어 메탈 플랫폼 서비스의 모든 Anthos가 설치 및 실행 중인지 확인합니다.</block>
  <block id="132b0b7921ef1247c2db8a06ebb68fa0" category="list-text">베어 메탈 클러스터의 물리적 Anthos를 4개의 작업자 노드에서 3개로 확장하고 4개로 다시 확장합니다.</block>
  <block id="5d80842c7c4c549fffd35b71989523c6" category="list-text">사용자 지정 네임스페이스를 만들고 삭제합니다.</block>
  <block id="bd4534ff45d2d6e71d15c4133153f039" category="list-text">Nginx 웹 서버 배포를 생성하여 복제 수를 늘려 배포를 확장합니다.</block>
  <block id="afdfab7c351a97a8f8e386c8c07eead0" category="list-text">Nginx 응용 프로그램에 대한 침투를 생성하고 index.html을 말하여 연결을 확인합니다.</block>
  <block id="e093cbb18731dc9a857dff2a5a9c5b0d" category="list-text">모든 테스트 제품군 작업을 성공적으로 정리하고 클러스터를 사전 테스트 상태로 되돌립니다.</block>
  <block id="6c91e0c5fc919c3ee9adc7909c3331b7" category="list-text">Anthos 지원 스토리지에 대한 파트너 검증:</block>
  <block id="5aacb1c1d8ec3130c7bfc91d7678968c" category="list-text">영구 볼륨 클레임을 사용하여 구축을 생성합니다.</block>
  <block id="1f8b95da3c7377c3616667d09bfbcf96" category="list-text">NetApp Trident를 사용하여 NetApp ONTAP에서 요청된 영구 볼륨을 프로비저닝하고 연결합니다.</block>
  <block id="5fac429b30f448d8149f93a83869e87f" category="list-text">영구 볼륨의 분리 및 다시 연결 기능을 확인합니다.</block>
  <block id="5a1ed343aaa28f6d14745016b7c06cf7" category="list-text">노드의 다른 Pod에서 영구 볼륨의 멀티 연결 읽기 전용 액세스를 검증합니다.</block>
  <block id="7c14d31217a85dc93c1505315501ef24" category="list-text">오프라인 볼륨 크기 조정 작업을 확인합니다.</block>
  <block id="b6ab6f9d0bc58a79facf618d65db092c" category="list-text">영구 볼륨이 클러스터 확장 작업을 수행하는지 확인합니다.</block>
  <block id="fa789d11a4863ab2ab7271940566105a" category="paragraph"><block ref="fa789d11a4863ab2ab7271940566105a" category="inline-link-macro-rx"></block></block>
  <block id="fe70522102670f75ed2fff361701d056" category="paragraph">이 참조 문서는 NetApp에서 검증한 바와 같이 여러 데이터 센터 환경에서 IPI(Installer provisioned Infrastructure)를 통해 배포된 Red Hat OpenShift 솔루션의 배포 검증을 제공합니다. 또한 영구 스토리지 관리를 위한 Astra Trident 스토리지 오케스트레이터와 상태 저장 애플리케이션의 관리 및 보호를 위한 NetApp Astra Control Center를 사용하여 NetApp 스토리지 시스템과의 스토리지 통합에 대해 자세히 설명합니다. 마지막으로, 다양한 솔루션 검증 및 실제 사용 사례를 살펴보고 문서화합니다.</block>
  <block id="2c65eb4e4300c763b9d8ffcdc45660fc" category="paragraph">OpenShift 가상화를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="bb761e1ed8ef4412cddb399e81488f83" category="list-text">클러스터 관리자 권한으로 Red Hat OpenShift 베어 메탈 클러스터에 로그인합니다.</block>
  <block id="3f4b86cf3e8a535371d3937bd126d789" category="list-text">원근 표시 드롭다운에서 관리자 를 선택합니다.</block>
  <block id="bbb49986c10d9b599ce8b72ea09d5261" category="list-text">Operators &gt; OperatorHub로 이동하여 OpenShift Virtualization을 검색합니다.</block>
  <block id="78146e6a44100deebbe276c19e6c437a" category="image-alt">OpenShift Operator Hub를 참조하십시오</block>
  <block id="016a229c1180d24870be44f7391c5678" category="list-text">OpenShift Virtualization 타일을 선택하고 Install을 클릭합니다.</block>
  <block id="fe87c9ebb6d1db5af643c2101dd83c2d" category="image-alt">OpenShift Virtualization Operator Tile</block>
  <block id="d2770f20a312c7d906cf3d8a97d335a2" category="list-text">Install Operator(사용자 설치) 화면에서 모든 기본 매개변수를 그대로 두고 Install(설치) 을 클릭합니다.</block>
  <block id="66b5ae84d6c0a470bb131b7aeb63f734" category="image-alt">OpenShift 가상화 운영자 세부 정보</block>
  <block id="5f27d84a5a158e75ab7ac4543ca7c1be" category="image-alt">OpenShift Virtualization Operator 설치</block>
  <block id="49598c5badb95e31a9894d5dc277f301" category="list-text">운영자가 설치되면 HyperConverged 생성 을 클릭합니다.</block>
  <block id="f63ea68253a91a92e8afb2e42bf0fb36" category="image-alt">OpenShift Virtualization Operator - Hyperconverged를 만듭니다</block>
  <block id="0e4308133099865567bc6a19f0abcb88" category="list-text">Create HyperConverged(HyperConverged 생성) 화면에서 Create(생성) 를 클릭하여 모든 기본 매개 변수를 수락합니다. 이 단계에서는 OpenShift Virtualization 설치를 시작합니다.</block>
  <block id="c57b56755457ec355801b1e17915fc47" category="image-alt">OpenShift Virtualization Operator - 하이퍼컨버지드 세부 정보</block>
  <block id="ee0ffac6ee8f4e224a044d95e68aa30d" category="list-text">모든 Pod가 OpenShift-CNV 네임스페이스에서 실행 상태로 이동하고 OpenShift Virtualization 연산자가 SUCEEDED 상태가 되면 운영자를 사용할 준비가 된 것입니다. 이제 OpenShift 클러스터에서 VM을 생성할 수 있습니다.</block>
  <block id="423e88e20ace3dbca3f9d5bd3b109cef" category="image-alt">OpenShift Virtualization Operator 설치가 완료되었습니다</block>
  <block id="46af5002087f682df1feb9b3339d1f68" category="inline-link-macro">다음: 워크플로우: VM을 생성합니다.</block>
  <block id="066b9e10038ca1d47643166f151f910c" category="paragraph"><block ref="066b9e10038ca1d47643166f151f910c" category="inline-link-macro-rx"></block></block>
  <block id="1d45b25ba986072287aaf72b6cf94130" category="paragraph">NetApp ONTAP에서 지원하는 Red Hat OpenShift 및 Astra Trident는 기본적으로 워크로드 간 격리를 제공하지 않지만 멀티 테넌시를 구성하는 데 사용할 수 있는 다양한 기능을 제공합니다. NetApp ONTAP가 지원하는 Astra Trident가 있는 Red Hat OpenShift 클러스터에서 멀티테넌트 솔루션을 설계하는 방법을 잘 이해하기 위해 일련의 요구 사항이 있는 예제를 고려하고 이 솔루션에 대한 구성을 개략적으로 설명합니다.</block>
  <block id="385df0e95c28430fb792ec836529f371" category="paragraph">한 조직이 Red Hat OpenShift 클러스터에서 두 개의 다른 팀이 진행 중인 두 프로젝트의 일부로 두 개의 워크로드를 실행하는 것으로 가정해 보겠습니다. 이러한 워크로드의 데이터는 NetApp ONTAP NAS 백엔드의 Astra Trident가 동적으로 프로비저닝한 PVC에 있습니다. 조직은 이러한 두 워크로드를 위한 멀티테넌트 솔루션을 설계하고 이러한 프로젝트에 사용되는 리소스를 격리하여 보안 및 성능이 유지되도록 해야 합니다. 이러한 애플리케이션은 주로 해당 애플리케이션을 지원하는 데이터에 초점을 맞춥니다.</block>
  <block id="9c965c0beb472bc9265925ebbc55507e" category="paragraph">다음 그림은 NetApp ONTAP가 지원하는 Astra Trident가 있는 Red Hat OpenShift 클러스터의 멀티 테넌트 솔루션을 보여줍니다.</block>
  <block id="2ed5156911e542a4d3d64a6e160f6446" category="image-alt">NetApp ONTAP에서 지원하는 Astra Trident와 Red Hat OpenShift 클러스터의 멀티 테넌시</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">기술 요구 사항</block>
  <block id="ff94444190436ee7694d15be2dde0f29" category="list-text">NetApp ONTAP 스토리지 클러스터</block>
  <block id="086e6c16e3fe8e13c336612ef636aa02" category="list-text">아스트라 트리덴트</block>
  <block id="0d46ef98dfe52c8d01c0c5ace93d8165" category="section-title">Red Hat OpenShift – 클러스터 리소스</block>
  <block id="72710b926f57dad99b29203c63f4e3fd" category="paragraph">Red Hat OpenShift 클러스터의 관점에서 볼 때 가장 먼저 해야 할 리소스는 프로젝트입니다. OpenShift 프로젝트는 전체 OpenShift 클러스터를 여러 가상 클러스터로 분할하는 클러스터 리소스로 볼 수 있습니다. 따라서 프로젝트 수준에서 격리하면 다중 임차를 구성할 수 있는 기반이 제공됩니다.</block>
  <block id="20e1834bb9396599a6dcf7d743aa1b36" category="paragraph">다음으로, 클러스터에서 RBAC를 구성합니다. 가장 좋은 방법은 모든 개발자가 IDP(Identity Provider)에서 단일 프로젝트 또는 작업 부하를 단일 사용자 그룹으로 구성하도록 하는 것입니다. Red Hat OpenShift는 IDP 통합 및 사용자 그룹 동기화를 지원하므로 IDP의 사용자 및 그룹을 클러스터로 가져올 수 있습니다. 이렇게 하면 클러스터 관리자가 프로젝트 전용 클러스터 리소스의 액세스를 해당 프로젝트에서 작업하는 사용자 그룹 또는 그룹으로 분리하여 모든 클러스터 리소스에 대한 무단 액세스를 제한할 수 있습니다. Red Hat OpenShift와의 IDP 통합에 대한 자세한 내용은 설명서를 참조하십시오<block ref="213cff8958909b80a9514e0c8321d8ef" category="inline-link-rx"></block>.</block>
  <block id="6d4e96186b1f4267def393ec42bf2d9e" category="paragraph">각 프로젝트에 대해 스토리지에서 생성된 볼륨이 별도의 스토리지에 생성된 것처럼 호스트에 나타나도록 하기 위해 Red Hat OpenShift 클러스터의 영구 스토리지 공급자 역할을 하는 공유 스토리지를 격리하는 것이 중요합니다. 이를 위해 프로젝트나 작업 부하가 있는 것처럼 NetApp ONTAP에 SVM(스토리지 가상 시스템)을 최대한 많이 생성하고 각 SVM을 작업 부하에 전용으로 사용합니다.</block>
  <block id="c4ff2177ae2f8ed9c3e5353068cf2195" category="section-title">Red Hat OpenShift – 스토리지 리소스</block>
  <block id="76245f392269db8492c3610e325b1963" category="paragraph">스토리지 클래스는 이름이 같은 리소스가 아니므로 다른 네임스페이스나 프로젝트의 Pod를 통해 한 프로젝트의 스토리지 클래스에 대한 스토리지 클레임이 거부되도록 하려면 어떻게 해야 합니까? 리소스 할당량을 사용하면 됩니다. ResourceQuotas 는 프로젝트당 리소스의 총 사용량을 제어하는 개체입니다. 프로젝트의 개체에서 사용할 수 있는 총 리소스 양뿐만 아니라 수를 제한할 수 있습니다. 리소스 할당량을 사용하면 프로젝트의 거의 모든 리소스를 제한할 수 있으며, 이러한 리소스를 효율적으로 사용하면 리소스 오버 프로비저닝 또는 과소비로 인한 비용 및 운영 중단을 줄일 수 있습니다. 설명서를 참조하십시오<block ref="9b2bb9683c8f6144876bed616f252527" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="5402bb91006fe391aea122e11c3607db" category="paragraph">이 활용 사례에서는 특정 프로젝트의 포드를 해당 프로젝트 전용이 아닌 스토리지 클래스에서 스토리지를 청구하는 것을 제한해야 합니다. 이렇게 하려면 "&lt;storage-class-name&gt;.storageclass.storage.k8s.io/persistentvolumeclaims"를 0으로 설정하여 다른 스토리지 클래스에 대한 영구 볼륨 클레임을 제한해야 합니다. 또한 클러스터 관리자는 프로젝트의 개발자가 리소스 할당량을 수정할 수 있는 액세스 권한이 없어야 합니다.</block>
  <block id="6c7eefdca8e3859011afa00995879a32" category="inline-link-macro">다음: 구성.</block>
  <block id="0c86c0f2c0ad5b82864ef1b20a904132" category="paragraph"><block ref="0c86c0f2c0ad5b82864ef1b20a904132" category="inline-link-macro-rx"></block></block>
  <block id="a38830c0aa781c889eeb5910f47be6ea" category="summary">Astra Control Center를 통해 CI/CD 파이프라인에서 데이터 보호를 활성화합니다</block>
  <block id="dc0365ad4c92bc3f8973ff5616cd6830" category="doc">Astra Control Center를 통한 CI/CD 파이프라인의 데이터 보호</block>
  <block id="5568d55567785f154c987872c1684bfa" category="doc">워크로드 마이그레이션: NetApp의 Red Hat OpenShift</block>
  <block id="9f9077091d74fb2c701c8c8c4a837c16" category="summary">이 솔루션의 초기 검증을 위해 NetApp은 WWT(World Wide Technology)와 협력하여 WWT의 ATC(Advanced Technology Center)에서 환경을 구축했습니다. Anthos는 Google Cloud에서 제공하는 bmctl 도구를 사용하여 베어 메탈 인프라에 배포되었습니다. 다음 섹션에서는 유효성 검사를 위해 사용되는 배포에 대해 자세히 설명합니다.</block>
  <block id="06dc93ff20817f0d5fb8a07f8e43d6cb" category="doc">구축 요약</block>
  <block id="195d9c1693fc10788ad8da5d4d9d2402" category="paragraph">NetApp 솔루션을 사용한 베어 메탈 기반 Anthos는 3개의 Anthos 제어 플레인 노드와 4개의 Anthos 작업자 노드로 구성된 고가용성 하이브리드 클러스터로 구축되었습니다.</block>
  <block id="d0236eb3bd180706e0eaca7d726c66e6" category="paragraph">사용되는 제어 플레인 노드는 Cisco UCS B200M3 블레이드 서버로서 섀시에서 호스팅되며 각 서버에 vNIC(단일 가상 네트워크 인터페이스 카드)가 구성되어 있어 내결함성을 위해 Cisco UCS 플랫폼 레벨에서 A/B 페일오버를 허용합니다. Cisco UCS 섀시는 패브릭 A와 패브릭 B를 따라 트래픽을 분리할 수 있는 서로 다른 경로를 제공하는 Cisco UCS 6248 패브릭 상호 연결 쌍에 업스트림을 연결합니다 WWT의 핵심 네트워크에 다시 연결되는 Cisco Nexus 5548 데이터 센터 스위치 쌍으로 업스트림에 연결된 패브릭 상호 연결망을 통해 연결됩니다.</block>
  <block id="3753f99ef321c354828532bad11422ec" category="paragraph">작업자 노드는 HP ProLiant DL360 노드로서, 각각 Red Hat Enterprise Linux 8.2, CentOS 8.2, Ubuntu 20.04 LTS 또는 Ubuntu 18.04 LTS의 Anthos에 대해 지원되는 Linux 배포판 중 하나를 실행합니다. Red Hat Enterprise Linux 8 및 CentOS 8 노드는 LACP 모드에서 실행되는 NIC 팀으로 구성되어 있으며 내결함성을 위해 2개의 Nexus 9k C93180YC-FX 스위치에 케이블로 연결되어 있었습니다. Ubuntu 서버는 LACP 모드에서 네트워크 연결을 위해 구성되었으며 내결함성을 위해 동일한 쌍의 Nexus 9k 스위치에 케이블로 연결되었습니다.</block>
  <block id="a847089866aa2e6d9077cdc08cce930b" category="paragraph">ONTAP 9.7 소프트웨어를 실행하는 NetApp AFF A300 스토리지 시스템은 Anthos 작업자 노드와 동일한 Nexus 9k 스위치 쌍에 물리적으로 설치 및 연결되었습니다. 이러한 네트워크 업링크는 인터페이스 그룹(a0a)에 통합되었으며, 작업자 노드가 스토리지 시스템과 상호 작용할 수 있도록 적절한 데이터 네트워크 VLAN 태그가 지정되었습니다. SVM(Storage Virtual Machine)은 NFS 프로토콜을 지원하는 데이터 LIF와 Trident를 위한 스토리지 운영 전용으로 생성되어, 베어 메탈 클러스터의 Anthos에 구축된 컨테이너에 영구 스토리지를 제공합니다. 이러한 영구 볼륨은 Kubernetes용 NetApp 오픈 소스 스토리지 오케스트레이터의 최신 릴리즈인 NetApp Trident 20.10에서 제공됩니다.</block>
  <block id="e5b1fecda3d68cda9e216e0e73b26dec" category="paragraph">다음 그림은 랙 데이터 센터 스위치 상단에 대한 솔루션의 물리적 케이블 연결 다이어그램을 보여 줍니다.</block>
  <block id="aa5914d8b6d8a27fd4df86fef0c0395a" category="paragraph"><block ref="aa5914d8b6d8a27fd4df86fef0c0395a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7a105940efa6ed6c71004ff40b8347" category="paragraph">다음 그림은 NetApp 파트너 WWT의 연구실에서 하드웨어에 구축 및 검증된 솔루션을 논리적으로 나타낸 것입니다.</block>
  <block id="ff8f4395cfa334d6d144e3a2426e7b96" category="paragraph"><block ref="ff8f4395cfa334d6d144e3a2426e7b96" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8d3f61f51562ad245b65242dc92c0da" category="inline-link-macro">다음: 솔루션 검증.</block>
  <block id="b1d15269d6e9cabdf17337c73e6a5f07" category="paragraph"><block ref="b1d15269d6e9cabdf17337c73e6a5f07" category="inline-link-macro-rx"></block></block>
  <block id="cb8e8e87ec9c630a0a27910fe29abceb" category="summary">RHV는 RHEL(Red Hat Enterprise Linux)에서 실행되고 KVM 하이퍼바이저를 사용하는 엔터프라이즈 가상 데이터 센터 플랫폼입니다.</block>
  <block id="932e95da8a59703292a426466e703c7a" category="paragraph">Red Hat Virtualization(RHV)은 RHEL(Red Hat Enterprise Linux)에서 실행되고 KVM 하이퍼바이저를 사용하는 엔터프라이즈 가상 데이터 센터 플랫폼입니다.</block>
  <block id="603bc85f6f6f4d9e5095745d9252f1d3" category="inline-link">Red Hat 가상화 웹 사이트</block>
  <block id="8a961382f0c47dc86706f0aa8bb93fb4" category="paragraph">RHV에 대한 자세한 내용은 를 참조하십시오<block ref="ac07861257bcab0c21d310fa00cb324b" category="inline-link-rx"></block>.</block>
  <block id="7adf04762320f012179ffe68fb0aeb9f" category="paragraph">RHV는 다음과 같은 기능을 제공합니다.</block>
  <block id="0178ef6806a57586f6c66dde7e0e86d2" category="list-text">* VM 및 호스트의 중앙 집중식 관리 * RHV Manager는 배포 시 물리적 또는 가상 머신(VM)으로 실행되며 중앙 인터페이스에서 솔루션 관리를 위한 웹 기반 GUI를 제공합니다.</block>
  <block id="c29d3f9be705e3dcf947c6d2464cb090" category="list-text">* 자체 호스팅된 엔진. * RHV를 사용하면 하드웨어 요구 사항을 최소화하기 위해 게스트 VM을 실행하는 동일한 호스트에 RHV Manager(RHV-M)를 VM으로 배포할 수 있습니다.</block>
  <block id="e2545c34b3a35dbcd93423b539eae91a" category="list-text">* 고가용성. * 호스트 장애 시 중단을 방지하기 위해 RHV를 사용하면 VM을 고가용성을 구성할 수 있습니다. 고가용성 VM은 복구 정책을 사용하여 클러스터 레벨에서 제어됩니다.</block>
  <block id="8f91b3a5c6d176cad584bb5f06c53684" category="list-text">* 높은 확장성 * RHV 클러스터 하나에는 최대 200개의 하이퍼바이저 호스트가 있어 대규모 VM의 요구 사항을 지원하여 리소스 탐욕스러운 엔터프라이즈급 워크로드를 호스팅할 수 있습니다.</block>
  <block id="a175fea9b8830c0cdbe1b268cb114738" category="list-text">* 보안 강화. * RHV, 보안 가상화(sVirt) 및 보안 강화 Linux(SELinux) 기술은 호스트 및 VM에 대한 보안 강화 및 보안 강화를 위해 RHV에 사용됩니다. 이러한 기능을 통해 얻을 수 있는 주요 이점은 VM과 관련 리소스의 논리적 격리가 있다는 것입니다.</block>
  <block id="01b0ee840ef208c283c3f4e959aa9427" category="paragraph"><block ref="01b0ee840ef208c283c3f4e959aa9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd4c83df745cf56330120fb3ac308da2" category="paragraph">NetApp 기반 Red Hat OpenShift 솔루션은 2개의 데이터 스위치를 사용하여 25Gbps의 기본 데이터 연결을 제공합니다. 또한 스토리지 노드의 대역 내 관리를 위해 1Gbps에서 연결을 제공하는 두 개의 추가 관리 스위치와 IPMI 기능을 위한 대역 외 관리를 사용합니다. OCP는 클러스터 관리를 위해 RHV의 가상 머신 논리 네트워크를 사용합니다. 이 섹션에서는 솔루션에 사용되는 각 가상 네트워크 세그먼트의 배열 및 용도에 대해 설명하고 솔루션 구축을 위한 사전 요구 사항을 설명합니다.</block>
  <block id="2d7e48e226974692ed3f522a2baef6db" category="paragraph">RHV 기반 Red Hat OpenShift는 VLAN(Virtual Local Area Network)을 사용하여 네트워크 트래픽을 논리적으로 서로 다른 목적으로 분리할 수 있도록 설계되었습니다. 이 구성은 고객의 요구에 맞게 확장하거나 특정 네트워크 서비스에 대한 추가 격리를 제공할 수 있습니다. 다음 표에는 NetApp 솔루션의 유효성을 검사하는 동안 솔루션을 구현하는 데 필요한 VLAN이 나와 있습니다.</block>
  <block id="36a1694bce9815b7e38a9dad05ad42e0" category="cell">1172</block>
  <block id="c347686b0750301dfca053b321126bcc" category="cell">RHV-H 노드, RHV-Manager 및 ovirmgmt 네트워크를 위한 관리</block>
  <block id="21c5bba1dd6aed9ab48c2b34c1a0adde" category="cell">3343</block>
  <block id="3083202a936b7d0ef8b680d7ae73fa1a" category="cell">3344</block>
  <block id="38a77aa456fc813af07bb428f2363c8d" category="cell">3345</block>
  <block id="7e4be32047fe5b09a23fd956cd4e82f0" category="section-title">3개 이상의 노드가 포함된 RHV 클러스터에 OpenShift를 배포합니다</block>
  <block id="de4e964e7be880b328384cfedd5873d9" category="paragraph">이 문서에 설명된 검증된 아키텍처는 2개의 RHV-H 하이퍼바이저 노드를 배포하고 두 호스트가 호스팅된 엔진과 구축된 VM을 관리할 수 있는 내결함성 구성을 보장하여 HA 운영에 적합한 최소 하드웨어 구축을 제공합니다.</block>
  <block id="4a3fe6077a529bcbe033bbb7d13027d6" category="paragraph">Red Hat OpenShift는 처음에 3개의 마스터 노드와 함께 배포되기 때문에 2노드 구성에서 최소한 2개의 마스터가 동일한 노드를 차지하게 되므로 특정 노드를 사용할 수 없게 되면 OpenShift의 운영 중단을 초래할 수 있습니다. 따라서 Red Hat 모범 사례는 OpenShift 마스터를 균등하게 배포하고 솔루션에서 추가적인 내결함성을 얻을 수 있도록 솔루션의 일부로 RHV-H 하이퍼바이저 노드를 3개 이상 배포하는 것입니다.</block>
  <block id="b98f17dd49fc6d1c2a9b58922fae2686" category="paragraph">VM/호스트 선호도를 활성화하여 여러 하이퍼바이저 노드에 OpenShift 마스터를 배포할 수 있습니다.</block>
  <block id="df1b58247681ba5f974a572d530dbdf9" category="paragraph">유사성은 VM 및/또는 호스트 세트에 대한 규칙을 정의하는 방법으로, VM이 그룹의 동일한 호스트 또는 호스트에서 함께 실행되는지 아니면 다른 호스트에서 실행되는지를 결정합니다. VM 및/또는 동일한 매개 변수와 조건 집합을 가진 호스트로 구성된 선호도 그룹을 생성하여 VM에 적용됩니다. 선호도 그룹의 VM이 그룹의 동일한 호스트에서 실행되는지, 아니면 다른 호스트에서 개별적으로 실행되는지에 따라 선호도 그룹의 매개 변수는 양의 선호도 또는 음의 선호도를 정의할 수 있습니다.</block>
  <block id="02d7502b2b132a675665088322fde9b0" category="paragraph">매개 변수에 대해 정의된 조건은 강제 적용이나 소프트 적용일 수 있습니다. 강제 적용은 선호도 그룹의 VM이 항상 외부 조건과 상관 없이 긍정 또는 부정적인 선호도를 따르도록 합니다. 소프트 적용은 선호도 그룹의 VM에 대해 더 높은 선호도를 설정하여 가능한 경우 긍정 또는 부정적 선호도를 따르도록 합니다. 이 문서에 설명된 2개 또는 3개의 하이퍼바이저 구성에서 소프트 선호도 설정이 권장됩니다. 대규모 클러스터에서는 하드 친화성이 OpenShift 노드를 올바르게 배포할 수 있습니다.</block>
  <block id="5c00bc5cb1bdae240d18551e77806abd" category="inline-link">Red Hat 6.11. Affinity Group 설명서</block>
  <block id="f38d8cd9caeb9a037c470b7d061392a0" category="paragraph">선호도 그룹을 구성하려면 을 참조하십시오<block ref="eb1587f3cb611d53dba5bde41d49122a" category="inline-link-rx"></block>.</block>
  <block id="2b083bcbbb2d2208e64c13cb183af44f" category="paragraph">IPI를 사용하면 이 문서 앞부분에서 설명한 대화형 마법사를 통해 OpenShift 클러스터를 쉽게 배포할 수 있습니다. 그러나 클러스터 배포의 일부로 변경해야 할 수 있는 몇 가지 기본값이 있을 수 있습니다.</block>
  <block id="1050f3dc9e3ee559789e3b25f2e4f77e" category="inline-link">Red Hat OpenShift Customizations를 사용하여 RHV에 클러스터 설치</block>
  <block id="a5867d73fa54e5b850ff2642c45ade52" category="paragraph">이 경우 클러스터를 즉시 배포하지 않고도 마법사를 실행하고 작업을 수행할 수 있습니다. 대신 나중에 클러스터를 구축할 수 있는 구성 파일이 생성됩니다. IPI 기본값을 변경하거나 멀티 테넌시와 같은 다른 용도로 환경에 여러 개의 동일한 클러스터를 배포하려는 경우 매우 유용합니다. OpenShift에 대한 사용자 지정 설치 구성을 만드는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="15427a9f842d7a49b872cf64115f33bc" category="inline-link-rx"></block>.</block>
  <block id="9d312703c40c2d87b835076063682d59" category="summary">NetApp ONTAP는 직관적인 GUI, 자동화 통합을 지원하는 REST API, AI 정보에 기반한 예측 분석 및 수정 조치, 무중단 하드웨어 업그레이드, 교차 스토리지 가져오기 등의 기능을 갖춘 강력한 스토리지 소프트웨어 툴입니다.</block>
  <block id="48235fec2427a785c4a09d7150fc11fc" category="inline-link">NetApp ONTAP 웹 사이트</block>
  <block id="e65027864c84a42fc0799d878ffa0005" category="paragraph">NetApp ONTAP 스토리지 시스템에 대한 자세한 내용은 를 참조하십시오<block ref="be9464a7a83e639a645a801fff2791d9" category="inline-link-rx"></block>.</block>
  <block id="3716516b242be48f15f8cbce6557a296" category="paragraph">ONTAP는 다음과 같은 기능을 제공합니다.</block>
  <block id="3e23168685787e9deffccb3bdb29d98a" category="list-text">NFS, CIFS, iSCSI, FC, FCoE 및 iSCSI의 동시 데이터 액세스 및 관리를 지원하는 유니파이드 스토리지 시스템 NVMe 프로토콜을 지원합니다.</block>
  <block id="11927aa24f71bc959d85115c8dd8c3a9" category="list-text">다양한 구축 모델에는 All-Flash 기반 온프레미스, 하이브리드, All-HDD 하드웨어 구성, ONTAP Select와 같은 지원되는 하이퍼바이저 기반 VM 기반 스토리지 플랫폼, Cloud Volumes ONTAP와 같은 클라우드 등이 있습니다.</block>
  <block id="65c42edcb28a34e276f92dd9b2172613" category="list-text">자동 데이터 계층화, 인라인 데이터 압축, 중복제거, 컴팩션을 지원하여 ONTAP 시스템의 데이터 스토리지 효율성을 높입니다.</block>
  <block id="f0a8a62c8d7ea4d12a7f1c95b40d3cb3" category="list-text">워크로드 기반, QoS 제어 스토리지</block>
  <block id="1e16ebc829d46d68a51d55ac22293b1e" category="list-text">퍼블릭 클라우드와 원활하게 통합하여 데이터를 계층화 및 보호합니다. ONTAP는 또한 어떤 환경에서든 강력한 데이터 보호 기능을 제공합니다.</block>
  <block id="613db5a747bd15eeccbcbedce5bd8888" category="list-text">* NetApp Snapshot 복사본 * 추가 성능 오버헤드 없이 최소한의 디스크 공간을 사용하여 데이터를 신속하게 시점 백업해 줍니다.</block>
  <block id="8f666d296151faf9c472110831227243" category="list-text">* NetApp SnapMirror. * 스토리지 시스템 간에 데이터의 스냅샷 복사본을 미러링합니다. ONTAP는 다른 물리적 플랫폼과 클라우드 네이티브 서비스에 대한 데이터 미러링을 지원합니다.</block>
  <block id="5685b3f13393b751231ff096f77e6747" category="list-text">NetApp SnapLock. * 지정된 기간 동안 덮어쓰거나 지울 수 없는 특수 볼륨에 데이터를 기록하여 재기록할 수 없는 데이터를 효율적으로 관리</block>
  <block id="dff1063d1e007396b7fb75f266dd48b7" category="list-text">* NetApp SnapVault. * 여러 스토리지 시스템의 데이터를 중앙 스냅샷 복사본으로 백업하여 지정된 모든 시스템에 대한 백업 기능을 제공합니다.</block>
  <block id="779cb4084f09228e9562ca3bedc5555c" category="list-text">NetApp SyncMirror. * 는 동일한 컨트롤러에 물리적으로 연결된 두 개의 서로 다른 플렉스에 데이터를 실시간 RAID 레벨 미러링 기능을 제공합니다.</block>
  <block id="929a0581ca4b2982313e21e51effbc10" category="list-text">* NetApp SnapRestore. * Snapshot 복사본에서 백업된 데이터를 필요에 따라 신속하게 복원합니다.</block>
  <block id="4e3f9a03501932f914205c4ad0e682ea" category="list-text">* NetApp FlexClone. * 은 Snapshot 복사본을 기반으로 NetApp 볼륨의 읽기 가능하고 쓰기 가능한 복사본을 즉각적으로 프로비저닝합니다.</block>
  <block id="96f474208f638efbbd85fac3a46a2ed4" category="paragraph">ONTAP에 대한 자세한 내용은 를 참조하십시오<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="c389369b80a8ce8ead607b4c7088682e" category="admonition">NetApp ONTAP는 사내, 가상화 또는 클라우드에서 사용할 수 있습니다.</block>
  <block id="81bf516f5b38ea41d503a2670a9dc144" category="paragraph"><block ref="81bf516f5b38ea41d503a2670a9dc144" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e80842c9211bc376ee42d583c70ae408" category="section-title">NetApp 플랫폼</block>
  <block id="5a69e0f8303b40f9f4d56038d3d260c9" category="section-title">NetApp AFF/FAS</block>
  <block id="f4fc33973424c12639f93790b1c6f370" category="paragraph">NetApp은 짧은 지연 시간, 통합 데이터 보호, 멀티 프로토콜 지원으로 강력한 AFF(All-Flash) 및 FAS(스케일아웃 하이브리드) 스토리지 플랫폼을 제공합니다.</block>
  <block id="d4c312c600a949fb72436c2d10568a90" category="paragraph">두 시스템 모두 NetApp ONTAP 데이터 관리 소프트웨어를 기반으로 합니다. 이 소프트웨어는 고가용성, 클라우드 통합, 간소화된 스토리지 관리를 위한 업계 최고의 데이터 관리 소프트웨어로 Data Fabric에 필요한 엔터프라이즈급 속도, 효율성 및 보안을 제공합니다.</block>
  <block id="992c24be8f66e4259b38ce763c115251" category="paragraph">NetApp AFF/FAS 플랫폼에 대한 자세한 내용을 보려면 클릭하십시오<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="3a3a5cd068731551120f43f37950768b" category="section-title">ONTAP Select</block>
  <block id="b008e805d13d953ddb5cbb220d8ef9b6" category="paragraph">ONTAP Select는 NetApp ONTAP의 소프트웨어 정의 배포로, 사용자 환경의 하이퍼바이저에 구축할 수 있습니다. VMware vSphere 또는 KVM에 설치할 수 있으며 하드웨어 기반 ONTAP 시스템의 모든 기능과 환경을 제공합니다.</block>
  <block id="3f0bbee5abf3eed060d4147cb0d060b9" category="paragraph">ONTAP Select에 대한 자세한 내용을 보려면 을 클릭합니다<block ref="7c1424ed7be035c303f12b0763e38ece" category="inline-link-rx"></block>.</block>
  <block id="f0f4b6de2040d7dc57e7f4f6baee7ec3" category="paragraph">NetApp Cloud Volumes ONTAP는 클라우드 구축 버전의 NetApp ONTAP로, Amazon AWS, Microsoft Azure, Google Cloud를 비롯한 다양한 퍼블릭 클라우드에 구축할 수 있습니다.</block>
  <block id="c7fa0d52c3955385f084d0e67c59f963" category="paragraph">Cloud Volumes ONTAP에 대한 자세한 내용을 보려면 을 클릭합니다<block ref="75c9b0075008bbe40ac851ad7f6dda6a" category="inline-link-rx"></block>.</block>
  <block id="a5369d9ec76321542413da21642ecc74" category="inline-link-macro">다음으로, NetApp 스토리지 통합 개요를 살펴보겠습니다</block>
  <block id="1a9b0bf11ebe49684776b9ffad6b4022" category="paragraph"><block ref="1a9b0bf11ebe49684776b9ffad6b4022" category="inline-link-macro-rx"></block></block>
  <block id="3fc5f6755312b7edeef9542bd55ef639" category="section-title">기대치를 설정합니다</block>
  <block id="9d7264067197bc9ff368288f98750fd6" category="paragraph">이 기능을 사용하면 여러 클러스터에 대한 규정 준수 정책을 정의하고 클러스터가 규정을 준수하도록 할 수 있습니다. 규칙 위반 또는 위반 사항을 알리거나 수정하기 위해 정책을 구성할 수 있습니다.</block>
  <block id="87f4e127e0ecf99187b35830ca7e78aa" category="list-text">측면 표시줄에서 거버넌스 및 위험 으로 이동합니다.</block>
  <block id="0ecc505d3375f8bb3bd959aaaf7e710a" category="list-text">규정 준수 정책을 생성하려면 정책 생성 을 클릭하고 정책 표준의 세부 정보를 입력한 다음 이 정책을 준수할 클러스터를 선택합니다. 이 정책의 위반 사항을 자동으로 해결하려는 경우 적용 확인란을 선택하고 생성 을 클릭합니다.</block>
  <block id="f6262e5369e2b989638aaa9d4f333d91" category="image-alt">규정 준수 정책을 수립합니다</block>
  <block id="0a1575621f2b12d5216e6d1c95eed2e6" category="list-text">필요한 모든 정책을 구성한 후 고급 클러스터 관리에서 정책 또는 클러스터 위반을 모니터링하고 해결할 수 있습니다.</block>
  <block id="38c080ff2128a92954fb61942ea497c0" category="image-alt">정책 모니터링</block>
  <block id="465d1c9d2d9ea711e43e2e20077e10f9" category="inline-link-macro">다음: 기능 - 관찰 가능성.</block>
  <block id="056789fad8ccaddf0ac3b4ef0a68b61a" category="paragraph"><block ref="056789fad8ccaddf0ac3b4ef0a68b61a" category="inline-link-macro-rx"></block></block>
  <block id="b6bd3694e26914bcad3a91cd2d709e12" category="summary">NetApp과 Google Cloud는 수년간 긴밀한 관계를 유지하고 있었으며, NetApp은 Cloud Volumes ONTAP과 Cloud Volumes Service를 통해 Google Cloud에 클라우드 데이터 서비스를 최초로 도입했습니다. 그런 다음 NetApp HCI 플랫폼을 검증하여 VMware vSphere에 구축된 하이퍼바이저 기반 하이브리드 멀티 클라우드 Kubernetes 솔루션인 Google Cloud Anthos On-Premises와 함께 사용할 수 있도록 했습니다. NetApp은 그런 다음 NetApp Trident, ONTAP 및 NFS 프로토콜을 위한 Anthos Ready 자격을 통과해 컨테이너에 동적 영구 스토리지를 제공했습니다.</block>
  <block id="6de80120fa9469d052fc37775d89d5ca" category="doc">WP-7337: 베어 메탈(Bare Metal)의 Anthos</block>
  <block id="3e2875179d9d16600aa48cbb428cefbb" category="paragraph">NetApp과 Google Cloud는 수년간 긴밀한 관계를 유지하고 있었으며, NetApp은 Cloud Volumes ONTAP 및 Cloud Volumes Service를 통해 Google Cloud용 클라우드 데이터 서비스를 최초로 도입했습니다. 그런 다음 NetApp HCI 플랫폼을 검증하여 VMware vSphere에 구축된 하이퍼바이저 기반 하이브리드 멀티 클라우드 Kubernetes 솔루션인 Google Cloud Anthos On-Premises와 함께 사용할 수 있도록 했습니다. NetApp은 그런 다음 NetApp Trident, ONTAP 및 NFS 프로토콜을 위한 Anthos Ready 자격을 통과해 컨테이너에 동적 영구 스토리지를 제공했습니다.</block>
  <block id="edb5855aa73d26775d73760286fad940" category="paragraph">Anthos는 이제 고객 환경의 베어 메탈 서버에 직접 설치할 수 있으며, 이를 통해 고객은 하이퍼바이저가 없는 로컬 데이터 센터로 Google Cloud를 확장할 수 있는 추가 옵션을 추가할 수 있습니다. 또한 NetApp ONTAP 스토리지 운영 체제 및 NetApp Trident의 기능을 활용하여 컨테이너용 영구 스토리지를 통합하여 플랫폼의 기능을 확장할 수 있습니다.</block>
  <block id="8310f10ba877c17b561c1119aa03a750" category="paragraph">이러한 결합을 통해 서버, 스토리지 및 네트워킹의 모든 잠재력을 Google Cloud가 제공하는 지원, 서비스 수준, 월별 청구 및 온디맨드 유연성과 결합하여 실현할 수 있습니다. 자체 하드웨어, 네트워크 및 스토리지를 사용하고 있기 때문에 애플리케이션 규모, 보안 및 네트워크 지연 시간을 직접 제어할 수 있을 뿐 아니라 베어 메탈에서 Anthos와 함께 관리 및 컨테이너화된 애플리케이션의 이점을 누릴 수 있습니다.</block>
  <block id="5cb451e1c66a533348d9c913d8c630e3" category="inline-link-macro">다음: 솔루션 개요</block>
  <block id="7133ec6c94c3cb3dd5d77dce10f8fd70" category="paragraph"><block ref="7133ec6c94c3cb3dd5d77dce10f8fd70" category="inline-link-macro-rx"></block></block>
  <block id="943dbb8750d636d9918af903ac016c0e" category="summary">NetApp은 Trident Storage Orchestrator를 사용하여 Red Hat OpenShift에 구축된 애플리케이션용 스토리지를 프로비저닝할 수 있는 여러 스토리지 플랫폼을 제공합니다.</block>
  <block id="77caa49b32b4fc8ce3276158f57f9229" category="doc">NetApp 스토리지 개요</block>
  <block id="3dbb1adfd571e8b44af1259f287d723f" category="paragraph">NetApp은 Astra Trident Storage Orchestrator를 사용하여 Red Hat OpenShift에 구축된 애플리케이션용 스토리지를 프로비저닝할 수 있는 여러 스토리지 플랫폼을 보유하고 있습니다.</block>
  <block id="0186ffea1bd2c7ff6458a3a619d01ea2" category="paragraph"><block ref="0186ffea1bd2c7ff6458a3a619d01ea2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bc4bb14f0d89a22c593112574d0fb3" category="list-text">AFF 및 FAS 시스템에서 NetApp ONTAP를 실행하고 파일 기반(NFS) 및 블록 기반(iSCSI) 사용 사례에 대한 스토리지를 제공합니다.</block>
  <block id="bf3bfadca5040d5a50a8703c7dbb7ef1" category="list-text">Cloud Volumes ONTAP와 ONTAP Select는 각각 클라우드 및 가상 공간에서도 동일한 이점을 제공합니다.</block>
  <block id="3cc957c67b836ddc993931d8d2253032" category="list-text">NetApp Cloud Volumes Service(AWS/GCP) 및 Azure NetApp Files는 클라우드에서 파일 기반 스토리지를 제공합니다.</block>
  <block id="faad8e024544c328d584c28118fb4102" category="list-text">NetApp Element 스토리지 시스템은 확장성이 뛰어난 환경에서 블록 기반(iSCSI) 사용 사례를 제공합니다.</block>
  <block id="cb050b8fb8c2102a0ab337119eb19f0f" category="admonition">NetApp 포트폴리오의 각 스토리지 시스템은 온프레미스 사이트와 클라우드 간에 데이터 관리와 이동을 모두 쉽게 하여 데이터가 애플리케이션의 위치에 있도록 보장합니다.</block>
  <block id="85a240011ba49404bf70606e37c41c96" category="paragraph">다음 페이지는 NetApp OpenShift에서 검증된 NetApp 스토리지 시스템에 대한 추가 정보를 제공합니다.</block>
  <block id="3a374bfcdd912b5071f863e2b9f0eefa" category="list-text"><block ref="3a374bfcdd912b5071f863e2b9f0eefa" category="inline-link-macro-rx"></block></block>
  <block id="70b44fe3d3567f3f2a5ccd67ff8ac852" category="list-text"><block ref="70b44fe3d3567f3f2a5ccd67ff8ac852" category="inline-link-macro-rx"></block></block>
  <block id="93e14ba37d069eff22130cf694c451c1" category="summary">NetApp AFF는 짧은 지연 시간, 통합 데이터 보호, 멀티 프로토콜 지원 및 무중단 운영을 제공하는 강력한 All-Flash 스토리지 플랫폼입니다. NetApp ONTAP 데이터 관리 소프트웨어를 기반으로 하는 NetApp AFF는 유지보수, 업그레이드, 스토리지 시스템의 전체 교체에 이르기까지 무중단 운영을 보장합니다.</block>
  <block id="9ecccbf5710194af15cca545b567957a" category="section-title">NetApp AFF/FAS 기반 NetApp ONTAP</block>
  <block id="13a74472f5a5018f40319d30a728d03e" category="paragraph">NetApp ONTAP는 직관적인 GUI, 자동화 통합을 지원하는 REST API, AI 정보에 기반한 예측 분석 및 수정 조치, 무중단 하드웨어 업그레이드, 교차 스토리지 가져오기 등의 기능을 갖춘 강력한 스토리지 소프트웨어 툴입니다.</block>
  <block id="fce4095b40c80c8632028b9837563736" category="list-text">* NetApp FlexClone. * 은 Snapshot 복사본을 기반으로 NetApp 볼륨의 읽기 가능하고 쓰기 가능한 복사본을 즉각적으로 프로비저닝합니다. ONTAP에 대한 자세한 내용은 를 참조하십시오<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="75714c8168a0c2a2594249ece5acf44c" category="paragraph"><block ref="75714c8168a0c2a2594249ece5acf44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0694d53b19f7a5e452e776ee3d2e9a4" category="paragraph">NetApp Trident는 Google Cloud Anthos를 비롯한 컨테이너 및 Kubernetes 배포를 위한 오픈 소스 및 완벽하게 지원되는 스토리지 오케스트레이터입니다. NetApp ONTAP 소프트웨어를 비롯한 전체 NetApp 스토리지 포트폴리오와 연동됩니다. Trident는 CSI를 완벽히 지원하므로 스토리지 관리자의 개입 없이 NetApp 스토리지 시스템에서 스토리지를 프로비저닝 및 관리할 수 있어 DevOps 워크플로우를 가속화합니다. Trident는 Kubernetes API 엔드포인트와 직접 통신하여 NetApp 스토리지 시스템에서 볼륨을 생성 및 관리하여 컨테이너의 스토리지 요청을 PVC(영구적 볼륨 클레임)의 형태로 제공하는 운영자로 구축됩니다.</block>
  <block id="dad787ba7494eee7d6dbd3cef7e5900e" category="paragraph">영구 볼륨(PVS)은 Kubernetes 환경에 정의된 스토리지 클래스를 기반으로 프로비저닝됩니다. 스토리지 관리자가 생성한 스토리지 백엔드(프로젝트 요구에 따라 사용자 지정 가능)와 스토리지 시스템 모델을 사용하여 압축, 특정 디스크 유형 또는 성능을 보장하는 QoS 수준과 같은 다양한 고급 스토리지 기능을 사용할 수 있습니다.</block>
  <block id="73cdbc9c6537713844b52fa7c0f1e655" category="paragraph">NetApp Trident에 대한 자세한 내용은 를 참조하십시오<block ref="9f564c4a71f7ad715885fb9db4485dda" category="inline-link-rx"></block> 페이지.</block>
  <block id="3068002de1b5d66a6a163ddc9883ad94" category="paragraph">Trident는 NetApp 포트폴리오에서 각 시스템 및 서비스에서 스토리지를 조정합니다.</block>
  <block id="6d906f4c160e6416d4f0c02a0fb9696c" category="paragraph"><block ref="6d906f4c160e6416d4f0c02a0fb9696c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="885a32398324f13cbf847894ab05bb41" category="paragraph">Google Cloud의 Anthos는 조직이 최신 하이브리드 클라우드 인프라를 구축 및 관리하는 동시에 애플리케이션 개발에 중점을 둔 민첩한 워크플로우를 채택할 수 있는 클라우드 기반 Kubernetes 데이터 센터 솔루션입니다. 베어 메탈 기반의 Anthos는 Anthos의 기능을 확장하여 하이퍼바이저 계층 없이 물리적 서버에서 직접 온프레미스(on-premise)을 실행하고 Google Cloud의 Anthos GKE 클러스터와 상호 운용합니다.</block>
  <block id="581adec598400d9d02114736724b28d3" category="paragraph">컨테이너, 서비스 메시 및 기타 혁신적인 기술을 채택하는 조직은 로컬 및 클라우드 기반 환경에서 일관된 애플리케이션 개발 사이클과 운영 지원 워크로드를 경험할 수 있습니다.</block>
  <block id="ea2625d89edeb5ba9cb41ca58df54e93" category="paragraph">Anthos는 다음과 같은 기능을 제공합니다.</block>
  <block id="c10e0a21a04a29dfca9609b3ec4bab76" category="list-text">* Anthos 구성 관리. * 하이브리드 Kubernetes 배포의 정책 및 보안을 자동화합니다.</block>
  <block id="e8c4d5cbaf3932ffa3fa7a097bff923e" category="list-text">* Anthos Service Mesh. * Istio 기반 서비스 메쉬로 애플리케이션 가시성, 보안 및 제어를 개선합니다.</block>
  <block id="b7fd1509ff5472f08e8216f563c9c8af" category="list-text">* Kubernetes 애플리케이션용 Google Cloud Marketplace * 손쉬운 구축을 위해 선별된 컨테이너 애플리케이션의 카탈로그</block>
  <block id="5204c290ae3b1ebca311a7ca7d447791" category="list-text">* Migrate for Anthos. * 물리적 서비스 및 VM을 사내에서 클라우드로 자동 마이그레이션. 그림 3은 Anthos 솔루션과 사내 데이터 센터 내의 배포가 클라우드의 인프라와 상호 연결하는 방법을 보여 줍니다.</block>
  <block id="608fd0ec5cdb56ad3d3e6d9595ec6f19" category="inline-link">Anthos 웹 사이트</block>
  <block id="1192e096cd21e1aa81d806fe9e5d2213" category="paragraph">Anthos에 대한 자세한 내용은 를 참조하십시오<block ref="717e02fd176ae4981315950f42bdf0a6" category="inline-link-rx"></block>.</block>
  <block id="70f64e61deea67473fb9951b8f5888b3" category="paragraph">다음 그림은 Google Cloud의 Anthos 아키텍처를 보여줍니다.</block>
  <block id="99d1b69697dd97e963c0a8145277719d" category="paragraph"><block ref="99d1b69697dd97e963c0a8145277719d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761fffea4910d62111da90337e75abb5" category="paragraph">Anthos on Bare Metal은 고객의 사설 데이터 센터에 배포되는 GKE의 확장입니다. 조직은 사내 Anthos 클러스터의 Google Cloud에서 컨테이너에서 실행되도록 설계된 동일한 애플리케이션을 배포할 수 있습니다. 베어 메탈(Bare Metal)의 Anthos는 사용자가 선택한 기본 Linux 운영 체제를 사용하여 물리적 서버에서 직접 실행되며 데이터 센터의 코어 또는 에지에서 실행할 수 있는 기능을 갖춘 완전한 하이브리드 클라우드 환경을 고객에게 제공합니다.</block>
  <block id="9eb2eb227133ada575ae959b570e545c" category="paragraph">베어 메탈(Bare Metal)의 Anthos는 다음과 같은 이점을 제공합니다.</block>
  <block id="d966dba0352f5bc4bd7cec115bb0f6f4" category="list-text">*하드웨어에 구애 받지 않습니다.* 고객은 기존 데이터 센터에서 최적화된 하드웨어 플랫폼을 선택한 Anthos를 실행할 수 있습니다.</block>
  <block id="69dd75c781331ee9a4c6b2b30d065262" category="list-text">* 비용 절감. * Google Cloud 환경에서 리소스를 프로비저닝하지 않고 애플리케이션 배포에 자체 물리적 리소스를 사용하여 상당한 비용 절감을 실현할 수 있습니다.</block>
  <block id="22c97b10f741190427f7bf14aaa217c3" category="list-text">* 개발 후 게시 * 응용 프로그램이 개발 중인 동안 온프레미스 배포를 사용할 수 있습니다. 이를 통해 로컬 데이터 센터의 개인 정보 보호 환경에서 응용 프로그램을 테스트한 후 클라우드에서 공개적으로 사용할 수 있습니다.</block>
  <block id="0f9f68e8f2e2599804f40d8fc0861b6d" category="list-text">* 더 나은 성능. * 짧은 지연 시간과 최고 수준의 성능을 필요로 하는 집약적인 애플리케이션을 하드웨어에 더 가깝게 실행할 수 있습니다.</block>
  <block id="844236b21d302f8c93eda00636abfff8" category="list-text">* 보안 요구 사항 * 보안 문제가 발생하거나 퍼블릭 클라우드에 저장할 수 없는 민감한 데이터 세트가 있는 고객은 자체 데이터 센터의 보안으로부터 애플리케이션을 실행하여 조직의 요구 사항을 충족할 수 있습니다.</block>
  <block id="895cc29ffb809aaf615d5db487a23c7c" category="list-text">* 관리 및 운영. * 베어 메탈 기반 Anthos는 내장 네트워킹, 수명 주기 관리, 진단, 상태 점검, 로깅, 모니터링 기능을 제공합니다.</block>
  <block id="04b942b754be5e16fc9d5b114dd70bb7" category="inline-link-macro">다음은 솔루션 요구 사항입니다.</block>
  <block id="dea54f5c884510a9da9977e2655c0a5a" category="paragraph"><block ref="dea54f5c884510a9da9977e2655c0a5a" category="inline-link-macro-rx"></block></block>
  <block id="a003986254b5a6c136733113505348da" category="doc">F5 BIG-IP 로드 밸런서 설치</block>
  <block id="048600e045fd4c5afe58ec9d65aa4b19" category="paragraph">F5 BIG-IP는 광범위한 고급 프로덕션 등급 트래픽 관리 및 L4-L7 로드 밸런싱, SSL/TLS 오프로드, DNS, 방화벽 등의 보안 서비스를 제공하는 ADC(Application Delivery Controller)입니다. 이러한 서비스는 애플리케이션의 가용성, 보안 및 성능을 크게 향상시킵니다.</block>
  <block id="5c47e8322efb7f77c0aa515fec29477e" category="paragraph">F5 BIG-IP는 전용 하드웨어, 클라우드 또는 온프레미스 가상 어플라이언스로 다양한 방식으로 구축 및 사용할 수 있습니다. 요구 사항에 따라 F5 BIG-IP를 탐색 및 배포하려면 여기 설명서를 참조하십시오.</block>
  <block id="16a275a8b38f9c5211732c331edb7135" category="paragraph">F5 BIG-IP 서비스와 Red Hat OpenShift의 효율적인 통합을 위해 F5는 BIG-IP Container Ingress Service(CIS)를 제공합니다. CI는 특정 CRD(Custom Resource Definitions)에 대한 OpenShift API를 감시하고 F5 BIG-IP 시스템 구성을 관리하는 컨트롤러 포드로 설치됩니다. F5 BIG-IP CIS는 OpenShift에서 서비스 유형 로드 밸런서 및 경로를 제어하도록 구성할 수 있습니다.</block>
  <block id="e3ce824a7aff01576faaac58df9e0b18" category="paragraph">또한 로드 밸런서를 서비스하기 위한 자동 IP 주소 할당의 경우 F5 IPAM 컨트롤러를 사용할 수 있습니다. F5 IPAM 컨트롤러는 사전 구성된 풀에서 IP 주소를 할당하는 ipamLabel 주석이 있는 loadbalancer 서비스용 OpenShift API를 감시하는 컨트롤러 포드로 설치됩니다.</block>
  <block id="3b08b142099d42d5280d7b493288bf63" category="paragraph">이 페이지에는 F5 BIG-IP CIS 및 IPAM 컨트롤러에 대한 설치 및 구성 지침이 나와 있습니다. 사전 요구 사항으로 F5 BIG-IP 시스템을 배포하고 라이센스를 받아야 합니다. 또한 빅-IP VE 기본 라이센스와 함께 기본적으로 포함되는 SDN 서비스에 대한 라이센스가 필요합니다.</block>
  <block id="5fb7b483d0c9fa099945579d826691b8" category="admonition">F5 BIG-IP는 독립 실행형 또는 클러스터 모드로 구축할 수 있습니다. 이러한 검증을 위해 F5 BIG-IP는 독립 실행형 모드로 구축되었지만, 생산 목적상 단일 장애 지점을 방지하기 위해 대규모 IP 클러스터를 사용하는 것이 좋습니다.</block>
  <block id="0d3e8be481c0c23fd0a68da9a9340ef7" category="admonition">F5 BIG-IP 시스템은 전용 하드웨어, 클라우드 또는 12.x 이상의 버전이 있는 가상 어플라이언스로 구축할 수 있으며 F5 CIS와 통합할 수 있습니다. 이 문서의 목적에 따라 F5 BIG-IP 시스템은 예를 들어 BIG-IP VE 버전을 사용하는 가상 어플라이언스로 검증되었습니다.</block>
  <block id="39bc153685f2a0c6d56db4227295a3b0" category="section-title">검증된 릴리즈</block>
  <block id="00d0a06cc7c922b3bc62b22524723ff8" category="cell">F5 BIG-IP VE 버전</block>
  <block id="5bd03f916d1e7b0410d0d3b2d12c6366" category="cell">16.1.0</block>
  <block id="c6f7874f49f685ffdf1b5a8aad8875c4" category="cell">F5 컨테이너 침투 서비스</block>
  <block id="21f47a5b35d016c2f0f8f57704079407" category="cell">2.5.1</block>
  <block id="9635118f932e26e24f0ca315d3843379" category="cell">F5 IPAM 컨트롤러</block>
  <block id="5256eb2d6e3cf80e003a290e63843800" category="cell">0.1.4</block>
  <block id="088afeececf092d5a406e0f5022a9638" category="cell">F5 AS3</block>
  <block id="425b0ca2d1d9d5c75555116fcd1614bf" category="cell">3.30.0</block>
  <block id="7cd8fb6e31cc946c078d2740c76a9899" category="section-title">설치</block>
  <block id="b9a4064fa117596b59fb18df84df74df" category="inline-link">F5 AS3 GitHub 리포지토리</block>
  <block id="6463cf716c052865ec9f4716ff0b5d3f" category="list-text">필수 명령 대신 BIG-IP 시스템이 JSON의 구성을 수락할 수 있도록 F5 Application Services 3 확장을 설치합니다. 로 이동합니다<block ref="0d4e47593b830323684cdec40cb60c71" category="inline-link-rx"></block>최신 RPM 파일을 다운로드합니다.</block>
  <block id="4c0802ebd79a8c6e5ea4aed829f023c9" category="list-text">F5 BIG-IP 시스템에 로그인하고 iApps &gt; 패키지 관리 LX 로 이동한 다음 가져오기 를 클릭합니다.</block>
  <block id="3536ed517a711f49cfe64071db031cf5" category="list-text">파일 선택 을 클릭하고 다운로드한 AS3 RPM 파일을 선택한 다음 확인 을 클릭하고 업로드 를 클릭합니다.</block>
  <block id="2a90f793207a5a0c028d8ccc45e943fd" category="inline-image-macro">iApps 업로드</block>
  <block id="7a3eaac0605c201c339e116a475c0bf6" category="paragraph"><block ref="7a3eaac0605c201c339e116a475c0bf6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="caedd771b59d267eda8f88d329e8784f" category="list-text">AS3 확장 프로그램이 성공적으로 설치되었는지 확인합니다.</block>
  <block id="c434efeb83b6dc500ea7893f1ad4236b" category="inline-image-macro">AS3 설치 검증</block>
  <block id="eb52ccb2be126d28d17e4383ae6ea6cf" category="paragraph"><block ref="eb52ccb2be126d28d17e4383ae6ea6cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97e9e05bfde432cfa7291b1e55a52ba7" category="list-text">그런 다음 OpenShift와 BIG-IP 시스템 간의 통신에 필요한 리소스를 구성합니다. 먼저 OpenShift SDN용 BIG-IP 시스템에서 VXLAN 터널 인터페이스를 생성하여 OpenShift와 BIG-IP 서버 간에 터널을 생성합니다. 네트워크 &gt; 터널 &gt; 프로필 로 이동하고 생성 을 클릭한 다음 부모 프로필을 VXLAN 으로 설정하고 플러딩 유형 을 멀티캐스트 로 설정합니다. 프로파일 이름을 입력하고 마침 을 클릭합니다.</block>
  <block id="faaca798da0468a250bf3c3bffc26681" category="inline-image-macro">VXLAN 프로필을 생성합니다</block>
  <block id="bddf6bed69a1a2234f15cefc27853c50" category="paragraph"><block ref="bddf6bed69a1a2234f15cefc27853c50" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45ae0c96657fdc5a20e83839c2386c1e" category="list-text">네트워크 &gt; 터널 &gt; 터널 목록 으로 이동하고 생성 을 클릭한 다음 터널의 이름과 로컬 IP 주소를 입력합니다. 이전 단계에서 만든 터널 프로필을 선택하고 마침 을 클릭합니다.</block>
  <block id="1497a4f92d416d6c80392ec3467ff140" category="inline-image-macro">VXLAN 터널을 생성합니다</block>
  <block id="53ce9cdf8cf7f6cb09991e817df94959" category="paragraph"><block ref="53ce9cdf8cf7f6cb09991e817df94959" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc5e5bc480b39177b8cb8c9c3a2266ae" category="list-text">클러스터 관리자 권한으로 Red Hat OpenShift 클러스터에 로그인합니다.</block>
  <block id="986e63a308b4bebd3f531e38fa5a06c7" category="list-text">OpenShift에서 F5 BIG-IP 서버용 hostsubnet을 생성합니다. 그러면 서브넷이 OpenShift 클러스터에서 F5 BIG-IP 서버로 확장됩니다. 호스트 서브넷 YAML 정의를 다운로드합니다.</block>
  <block id="fd4475e12938f5f51ba3f312b42cdd39" category="list-text">호스트 서브넷 파일을 편집하고 OpenShift SDN용 BIG-IP VTEP(VXLAN 터널) IP를 추가합니다.</block>
  <block id="2e6d8a8db3c4d4a2227ffa0571be2a86" category="admonition">사용자 환경에 맞게 호스트 팁 및 기타 세부 정보를 변경합니다.</block>
  <block id="7f9916ee1bc520d892dfbbb1e06e2732" category="list-text">HostSubnet 리소스를 생성합니다.</block>
  <block id="7a46b2d02d466dda0cc67b215cb80bff" category="list-text">F5 BIG-IP 서버에 대해 생성된 호스트 서브넷의 클러스터 IP 서브넷 범위를 가져옵니다.</block>
  <block id="4f6c1fea3654c07f1606c0c76509d0b0" category="list-text">F5 BIG-IP 서버에 해당하는 OpenShift의 호스트 서브넷 범위에서 IP를 사용하여 OpenShift VXLAN에서 셀프 IP를 생성합니다. F5 BIG-IP 시스템에 로그인하고 네트워크 &gt; Self IP 로 이동한 다음 생성 을 클릭합니다. F5 BIG-IP 호스트 서브넷용으로 생성된 클러스터 IP 서브넷의 IP를 입력하고 VXLAN 터널을 선택한 다음 다른 세부 정보를 입력합니다. 그런 다음 마침 을 클릭합니다.</block>
  <block id="5c241806c0dd5ebb7030904151cb78ef" category="inline-image-macro">VXLAN에 대한 셀프 IP를 생성합니다</block>
  <block id="ffad9e123d8b7013e7d4553570644879" category="paragraph"><block ref="ffad9e123d8b7013e7d4553570644879" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d094b7d82871afb601d2f30d416ba8d" category="list-text">CIS에서 구성 및 사용할 F5 BIG-IP 시스템에 파티션을 생성합니다. 시스템 &gt; 사용자 &gt; 파티션 목록 으로 이동하고 생성 을 클릭한 다음 세부 정보를 입력합니다. 그런 다음 마침 을 클릭합니다.</block>
  <block id="4d81871723233ec21ed69ab80e638779" category="inline-image-macro">BIG-IP 파티션을 생성합니다</block>
  <block id="b83428617c6ed29213f89e68f142bd18" category="paragraph"><block ref="b83428617c6ed29213f89e68f142bd18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37397397fa66431e2fa681b97126c399" category="admonition">F5는 CIS에서 관리하는 파티션에서 수동 구성을 수행하지 않을 것을 권장합니다.</block>
  <block id="81e4a49e9dbe0b55256fe5abf1b94fa4" category="list-text">OperatorHub의 연산자를 사용하여 F5 BIG-IP CIS를 설치합니다. 클러스터 관리자 권한으로 Red Hat OpenShift 클러스터에 로그인하고 F5 BIG-IP 시스템 로그인 자격 증명을 사용하여 암호를 생성합니다. 이는 운영자의 필수 조건입니다.</block>
  <block id="5de4ac005898cabf55523098c40c549b" category="list-text">F5 CIS CRD를 설치합니다.</block>
  <block id="0eddace1b16ed738fe1be181481c71b6" category="list-text">Operators &gt; OperatorHub 로 이동하고 키워드 F5 를 검색한 다음 F5 Container Ingress Service 타일을 클릭합니다.</block>
  <block id="07543409cb05595e273df71050b9a9c0" category="inline-image-macro">OperatorHub의 F5 CIS</block>
  <block id="334a7bbf4711d93b48b93c2b81d84a71" category="paragraph"><block ref="334a7bbf4711d93b48b93c2b81d84a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c25b2a3d320d6d02584fde4190d05d91" category="list-text">운영자 정보를 읽고 설치를 클릭하십시오.</block>
  <block id="60d3353ed1910ad5c7bd352d0c1bea85" category="inline-image-macro">OperatorHub의 F5 CIS 정보 타일</block>
  <block id="1aa79507d413f19135716c8006afa423" category="paragraph"><block ref="1aa79507d413f19135716c8006afa423" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637a1bc658defc200d903b27828aa8fb" category="list-text">Install operator(설치 작업자) 화면에서 모든 기본 매개변수를 그대로 두고 Install(설치) 을 클릭합니다.</block>
  <block id="ccf254d7c8b666c9c127ec12fe14804b" category="inline-image-macro">F5 CIS 연산자를 설치합니다</block>
  <block id="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="paragraph"><block ref="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="636d8318702bc67a1613ceadf7ce9d00" category="list-text">운전자를 설치하는 데 시간이 걸립니다.</block>
  <block id="dffa3077bcff43536afd75bd61b11c0c" category="inline-image-macro">F5 CIS 작동자 설치 진행</block>
  <block id="b1be0ed9469d2ced1f6283b49735f5c1" category="paragraph"><block ref="b1be0ed9469d2ced1f6283b49735f5c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="197a0a4cc4a45ec9a62fe2b7335d8dfc" category="list-text">운용자 설치 후 Installation Successful 메시지가 출력된다.</block>
  <block id="5bf83e99bfa132430d0b690181334933" category="list-text">Operators &gt; Installed Operators 로 이동하고 F5 Container Ingress Service 를 클릭한 다음 F5BigIpCtlr 타일에서 Create instance 를 클릭합니다.</block>
  <block id="a5f584f06c59c2cf4a4a4e8b42d495a2" category="inline-image-macro">F5BigIpCtlr을 생성합니다</block>
  <block id="a2574a02e64888de32a5a277ed05f668" category="paragraph"><block ref="a2574a02e64888de32a5a277ed05f668" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5ce9a4ef68c16a3ab5d0dd555305872" category="list-text">YAML View(YAML 보기) 를 클릭하고 필요한 매개변수를 업데이트한 후 다음 내용을 붙여 넣습니다.</block>
  <block id="2e2beb899f89156ed06287fe6f78e6cf" category="admonition">콘텐츠를 복사하기 전에 설정 값을 반영하도록 아래의 매개 변수 'bigip_partition', 'openshift_sdn_name', 'bigip_url' 및 'bigip_login_secret'을 업데이트합니다.</block>
  <block id="50a17348dc3f981a95001edcc80a428f" category="list-text">이 콘텐츠를 붙여 넣은 후 만들기 를 클릭합니다. 그러면 kubbe-system 네임스페이스에 CIS 포드가 설치됩니다.</block>
  <block id="72003ce6faa67d172e943ddd74fab63b" category="inline-image-macro">F5 CIS Pod를 확인합니다</block>
  <block id="ef76b6b9f85ff0ec00e48f565e13eff9" category="paragraph"><block ref="ef76b6b9f85ff0ec00e48f565e13eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc8632c05e82ccafb395157ccae4f5c3" category="admonition">기본적으로 Red Hat OpenShift는 L7 로드 밸런싱을 위해 경로를 통해 서비스를 노출하는 방법을 제공합니다. 내장된 OpenShift 라우터는 이러한 경로의 트래픽을 광고 및 처리하는 역할을 합니다. 그러나 F5 CIS를 구성하여 외부 F5 BIG-IP 시스템을 통한 라우트를 지원할 수도 있습니다. 이 시스템은 보조 라우터로 실행하거나 자체 호스팅된 OpenShift 라우터에 대한 대체 라우터로 실행할 수 있습니다. CI는 OpenShift 라우트의 라우터 역할을 하는 BIG-IP 시스템에 가상 서버를 생성하고 BIG-IP는 광고 및 트래픽 라우팅을 처리합니다. 이 기능을 활성화하는 매개변수에 대한 자세한 내용은 여기 에서 설명서를 참조하십시오. 이러한 매개 변수는 APPS/v1 API의 OpenShift 배포 리소스에 대해 정의됩니다. 따라서 F5BigIpCtlr 리소스 cis.f5.com/v1 API와 함께 사용할 경우 매개변수 이름에 대한 하이픈(-)을 밑줄(_)으로 바꿉니다.</block>
  <block id="a6e55fc1fe932b26a294a0f2880478aa" category="list-text">CIS 자원 생성에 전달되는 인자는 IPAM:TRUE, CUSTOM_RESOURCE_MODE:TRUE입니다. 이러한 매개변수는 IPAM 컨트롤러와 CIS 통합을 활성화하는 데 필요합니다. F5 IPAM 리소스를 생성하여 CIS가 IPAM 통합을 활성화했는지 확인합니다.</block>
  <block id="84ac0b78989fa6595723d5541b8ec470" category="list-text">F5 IPAM 컨트롤러에 필요한 서비스 계정, 역할 및 rolebinding을 만듭니다. YAML 파일을 생성하고 다음 내용을 붙여 넣습니다.</block>
  <block id="670c1074ae74616731a63f6b9462b94e" category="list-text">리소스를 생성합니다.</block>
  <block id="b7802bea6dc04d06b63232b6301621bb" category="list-text">YAML 파일을 생성하고 아래에 제공된 F5 IPAM 배포 정의를 붙여 넣습니다.</block>
  <block id="6a1491ddca525bea3293eca6ea8019d0" category="admonition">아래 SPEC.template.spec.containers[0].args의 IP 범위 매개 변수를 업데이트하여 설정에 해당하는 ipamLabels 및 IP 주소 범위를 반영합니다.</block>
  <block id="642252b62fe47e95caa77e3b06a7dbaf" category="admonition">IPAM 컨트롤러가 정의된 범위에서 IP 주소를 검색하고 할당하기 위해서는 ipamlabels ["range1" 및 "range2"(아래 예의 경우)에 부하 분산 장치 유형의 서비스에 대한 주석을 달아야 합니다.</block>
  <block id="8f253132259909c28624117b3476a672" category="list-text">F5 IPAM 컨트롤러 배포를 생성합니다.</block>
  <block id="43946dccec13f46420eb559911e4c526" category="list-text">F5 IPAM 컨트롤러 포드가 실행 중인지 확인합니다.</block>
  <block id="1362b3e7985b4f24d6c2ef4438ee1f0e" category="list-text">F5 IPAM 스키마를 만듭니다.</block>
  <block id="52b8ffce119fe77b28034f2fdd35eb5f" category="section-title">검증</block>
  <block id="32172ccfad6e7060b8f5e091e296f09c" category="list-text">loadbalancer 형식의 서비스를 생성합니다</block>
  <block id="0847be44e618094bc81c848c7d131399" category="list-text">IPAM Controller가 외부 IP를 할당하는지 확인한다.</block>
  <block id="0e51a0606ba7833099aa57bd61c62ba6" category="list-text">배포를 생성하고 생성된 로드 밸런서 서비스를 사용합니다.</block>
  <block id="5f905cb56a4d1b364cab7fc57f4de4e5" category="list-text">Pod가 실행 중인지 확인합니다.</block>
  <block id="51b4d723f0434284233dab97982b185d" category="list-text">OpenShift에서 loadbalancer 유형의 서비스를 위해 BIG-IP 시스템에 해당 가상 서버가 생성되었는지 확인한다. Local Traffic &gt; Virtual Servers &gt; Virtual Server List로 이동합니다.</block>
  <block id="91193cea3335c4666b7dc31ca767030c" category="inline-image-macro">해당 서비스 유형 로드 밸런싱 장치에 대한 BIG-IP 가상 서버 생성을 확인합니다</block>
  <block id="879dfaa1de924ed5e9ccb98da9ac95cd" category="paragraph"><block ref="879dfaa1de924ed5e9ccb98da9ac95cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad8905a47eb465223ebe7acf569732b1" category="doc">구성: 클러스터 관리 작업</block>
  <block id="552eab1d1ea09d0d1733b97dee6609a1" category="paragraph">Red Hat OpenShift cluster-admin은 다음과 같은 작업을 수행합니다.</block>
  <block id="8a4ffd494b5e8af3ac1be2cd9ab254fb" category="list-text">Red Hat OpenShift 클러스터에 cluster-admin으로 로그인합니다.</block>
  <block id="7ccd4d72e4addf5c27c53bafaeb3fdbd" category="list-text">서로 다른 프로젝트에 해당하는 두 개의 프로젝트를 작성합니다.</block>
  <block id="6c98bfb16f2e9bbebd943c1f8592306d" category="list-text">PROJECT-1의 개발자 역할을 만듭니다.</block>
  <block id="14bd8c5f1032dd20f94d4434365c6530" category="admonition">이 섹션에 제공된 역할 정의는 예일 뿐입니다. 개발자 역할은 최종 사용자 요구 사항에 따라 정의되어야 합니다.</block>
  <block id="3c73122271c9219b54ca745b732adc28" category="list-text">마찬가지로 project-2에 대한 개발자 역할을 만듭니다.</block>
  <block id="7428df2e0e503f4cabb43a4667bc1983" category="list-text">모든 OpenShift 및 NetApp 스토리지 리소스는 일반적으로 스토리지 관리자가 관리합니다. 스토리지 관리자를 위한 액세스는 Trident가 설치될 때 생성되는 덴트 운영자 역할에 의해 제어됩니다. 또한 스토리지 관리자는 리소스 할당량에 대한 액세스 권한이 있어야 스토리지 소비 방식을 제어할 수 있습니다.</block>
  <block id="cf17c458ea3abaad557d7cfc69886dbe" category="list-text">클러스터의 모든 프로젝트에서 리소스 할당량을 관리하는 역할을 생성하여 스토리지 관리자에게 연결합니다.</block>
  <block id="db99ab183aa8f56c951cf20e25e7465c" category="list-text">클러스터가 조직의 ID 공급자와 통합되었으며 사용자 그룹이 클러스터 그룹과 동기화되었는지 확인합니다. 다음 예제에서는 ID 공급자가 클러스터와 통합되고 사용자 그룹과 동기화되었음을 보여 줍니다.</block>
  <block id="36e36b60ddb8f46fe0b9b4e8f4dce56f" category="list-text">스토리지 관리자용 ClusterRoleBindings를 구성합니다.</block>
  <block id="38f22acd9ae9c74099644738d613baaa" category="admonition">스토리지 관리자의 경우 세 가지 역할, 즉 세 가지 운영자 및 리소스 할당량이 바인딩되어야 합니다.</block>
  <block id="ced38b1f1c19446862c601754b82b94c" category="list-text">Developer-project-1 역할을 project-1의 해당 그룹(OCP-project-1)에 바인딩하는 개발자를 위한 RoleBindings를 만듭니다.</block>
  <block id="2aa292f2ff8b13fe141ca55c27bc29c2" category="list-text">마찬가지로 개발자 역할을 프로젝트 2의 해당 사용자 그룹에 바인딩하는 개발자를 위한 RoleBindings 를 만듭니다.</block>
  <block id="7d03daab3e74958fc08ebc0c90e0a6a2" category="inline-link-macro">다음: 스토리지 관리자 작업.</block>
  <block id="f3d9bb76442ab5c11e6af4dd328b2559" category="paragraph"><block ref="f3d9bb76442ab5c11e6af4dd328b2559" category="inline-link-macro-rx"></block></block>
  <block id="7eba670f1ea5a6e2fba9cff6b6399064" category="summary">이 페이지에서는 MetalLB 로드 밸런서에 대한 설치 및 구성 지침을 자세히 설명합니다.</block>
  <block id="79a2d2fa50d2b47d02c0e9dbdfadc07f" category="doc">MetalLB 로드 밸런서 설치: NetApp과 Red Hat OpenShift</block>
  <block id="0b2da9b5fe81e13e88c9a05981a95a9e" category="paragraph">이 페이지에는 MetalLB 로드 밸런서에 대한 설치 및 구성 지침이 나와 있습니다.</block>
  <block id="d719c733d0cd8753c048c8c3a025fd51" category="paragraph">MetalLB는 OpenShift 클러스터에 설치되는 자체 호스팅 네트워크 로드 밸런서로서, 클라우드 공급자에서 실행되지 않는 클러스터에서 유형 로드 밸런서의 OpenShift 서비스를 생성할 수 있습니다. 로드 밸런서 서비스를 지원하기 위해 함께 작동하는 MetalLB의 두 가지 주요 기능은 주소 할당과 외부 안내입니다.</block>
  <block id="28a4ce0a0514d0f6a6596fc7a9c5e725" category="section-title">MetalLB 구성 옵션</block>
  <block id="04c22d763ca95631f9c8789eb2c6e68f" category="paragraph">MetalLB가 OpenShift 클러스터 외부의 로드 밸런서 서비스에 할당된 IP 주소를 알려 주면 두 가지 모드로 작동합니다.</block>
  <block id="92f98c10e5e0c86bcae2e9cb58b700e3" category="list-text">* Layer 2 모드 * 이 모드에서는 OpenShift 클러스터의 한 노드가 서비스 소유권을 가져와 해당 IP에 대한 ARP 요청에 응답하여 OpenShift 클러스터 외부에서 해당 IP에 연결할 수 있도록 합니다. 노드만 IP를 광고하기 때문에 대역폭 병목 현상 및 느린 페일오버 제한이 있습니다. 자세한 내용은 설명서를 참조하십시오 <block ref="4a1d14cac7ed68a2326a050e0f1fed80" category="inline-link-macro-rx"></block>.</block>
  <block id="13f78a1c753a58b3786e5664e7b01344" category="list-text">* BGP mode. * 이 모드에서 OpenShift 클러스터의 모든 노드는 라우터와 BGP 피어링 세션을 설정하고 트래픽을 서비스 IP로 전달하기 위한 경로를 광고합니다. 이를 위해서는 MetalLB를 해당 네트워크의 라우터에 통합해야 합니다. BGP의 해싱 메커니즘으로 인해 서비스에 대한 IP-노드 매핑이 변경될 때 특정 제한이 있습니다. 자세한 내용은 설명서를 참조하십시오 <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe238de20fea7c5ec86dde0a98c5841" category="admonition">이 문서에서는 MetalLB를 Layer-2 모드로 구성합니다.</block>
  <block id="32333b5f74abf17bffedb6e7abeb7b5f" category="section-title">MetalLB 로드 밸런서 설치</block>
  <block id="70bd399edc6825961c98dc29c2a49299" category="list-text">MetalLB 리소스를 다운로드합니다.</block>
  <block id="d95ae9e4bae10f240e5577110ccbd7e6" category="list-text">파일 Metallb.YAML을 편집하고 컨트롤러 배포 및 스피커 DemonSet에서 pec.template.spec.securityContext` 파일을 제거합니다.</block>
  <block id="39bb715a16a6f4c1ab16bc3ad3654f0b" category="paragraph">삭제할 줄: *</block>
  <block id="803519c541b237245faa09039c50dcaa" category="list-text">'metallb-system' 네임스페이스를 만듭니다.</block>
  <block id="980aff973ca30f65ec180530f40def06" category="list-text">MetalLB CR을 만듭니다.</block>
  <block id="f87be5542b64a7f94a807699fd549479" category="list-text">MetalLB 스피커를 구성하기 전에, 로드 밸런서가 작동하는 데 필요한 네트워킹 구성을 수행할 수 있도록 스피커 DemonSet Elevated 권한을 부여합니다.</block>
  <block id="53747915d8e79873876b08edb1ce3671" category="list-text">MetalLB는 metallb-system 네임스페이스에서 ConfigMap을 만들어 구성합니다.</block>
  <block id="2b1e829362de1a86eeb131cdc4619908" category="list-text">이제 로드 밸런서 서비스가 생성되면 MetalLB는 서비스에 외부 IP를 할당하고 ARP 요청에 응답하여 IP 주소를 알립니다.</block>
  <block id="234ce2b9b198f2acf2193cbd06120ff2" category="admonition">BGP 모드에서 MetalLB를 구성하려면 위의 6단계를 건너뛰고 MetalLB 설명서의 절차를 따르십시오 <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="eeaa3ef2816f113fd1978b036eefc4a4" category="doc">솔루션 검증 및 사용 사례: NetApp 기반 Red Hat OpenShift</block>
  <block id="9e766e668731b912ea84be747f0d6b4b" category="paragraph">이 페이지에서 제공되는 예는 NetApp 기반의 Red Hat OpenShift에 대한 솔루션 검증 및 사용 사례입니다.</block>
  <block id="6f60a8e202d6d4f297230695ffa9c1a6" category="inline-link-macro">영구 스토리지로 Jenkins CI/CD 파이프라인을 구축합니다</block>
  <block id="20b131c747c2ab8c4c617107b04dfe76" category="list-text"><block ref="20b131c747c2ab8c4c617107b04dfe76" category="inline-link-macro-rx"></block></block>
  <block id="e85b6a5686bf01c916e1c3b442e8db44" category="inline-link-macro">NetApp과 함께 Red Hat OpenShift에서 멀티 테넌시를 구성합니다</block>
  <block id="29a3155f4e27ac61f0e6d1e00866c981" category="list-text"><block ref="29a3155f4e27ac61f0e6d1e00866c981" category="inline-link-macro-rx"></block></block>
  <block id="781cf19a6329e508987456098cde8c79" category="list-text"><block ref="781cf19a6329e508987456098cde8c79" category="inline-link-macro-rx"></block></block>
  <block id="ddb9608f0f25d56d00a539a63333efa0" category="list-text"><block ref="ddb9608f0f25d56d00a539a63333efa0" category="inline-link-macro-rx"></block></block>
  <block id="0d1d64b47559f0c28c883e7e790b8363" category="summary">이 섹션에서는 실제 사용자가 전용 이미지 레지스트리 만들기 또는 사용자 지정 로드 밸런서 인스턴스 배포와 같이 이 솔루션을 운영 환경에 배포할 때 수행해야 할 사용자 지정 작업에 대해 설명합니다.</block>
  <block id="b432301f7ba469598e6ea2eb86e4859a" category="paragraph">일반적으로 가장 쉽게 배포할 수 있는 솔루션이 가장 좋지만, 경우에 따라 특정 애플리케이션 또는 솔루션이 배포되는 환경의 요구 사항 또는 사양을 충족하기 위해 고급 사용자 지정이 필요합니다. 이를 위해 NetApp 기반의 Red Hat OpenShift 솔루션은 이러한 요구사항을 충족하기 위해 다음과 같은 사용자 정의를 지원합니다.</block>
  <block id="2642cf401e87de575eae139953f87134" category="admonition">이 섹션에서는 타사 로드 밸런서 사용 또는 맞춤형 컨테이너 이미지 호스팅을 위한 프라이빗 레지스트리 생성 등 NetApp Astra Control Center 설치를 위한 사전 요구 사항과 같은 몇 가지 고급 구성 옵션을 문서화했습니다.</block>
  <block id="02b655f637212514780af2795fd74fc4" category="paragraph">다음 페이지에서는 NetApp OpenShift에서 검증된 고급 구성 옵션에 대한 자세한 정보를 제공합니다.</block>
  <block id="becc5334b7f3d2f4f57fc42cd287fd54" category="inline-link-macro">로드 밸런서 옵션 탐색</block>
  <block id="22651dd64b4cd4c6d2742d1f8b126ae6" category="list-text"><block ref="22651dd64b4cd4c6d2742d1f8b126ae6" category="inline-link-macro-rx"></block></block>
  <block id="261bdcc1d2c24d15c43c5947e69ea9e6" category="inline-link-macro">개인 이미지 레지스트리 구성</block>
  <block id="c8db11b008075455562a8b598b31753c" category="list-text"><block ref="c8db11b008075455562a8b598b31753c" category="inline-link-macro-rx"></block></block>
  <block id="91286d4add9b720fd5ff3bb121e12b2f" category="paragraph">이 문서에서는 Kubernetes용 오픈 소스 스토리지 오케스트레이터인 NetApp Trident를 사용하여 베어 메탈 플랫폼에서 Google Cloud의 Anthos를 기반으로 NetApp ONTAP 스토리지 플랫폼의 구성 및 검증을 개략적으로 설명하고 상태 저장 애플리케이션 컨테이너용 영구 스토리지를 배포 및 관리하는 방법을 소개합니다.</block>
  <block id="f913f3c8b073438c23eb36c9cf8237ac" category="section-title">VM을 생성합니다</block>
  <block id="71dd19ec5a595517b0b57750ad1a6568" category="paragraph">VM은 운영 체제 및 데이터를 호스트하기 위해 볼륨이 필요한 상태 저장 배포입니다. CNV에서는 VM이 Pod로 실행되므로 Trident를 통해 NetApp ONTAP에서 호스팅되는 PVS를 통해 VM을 지원합니다. 이러한 볼륨은 디스크로 연결되며 VM의 부팅 소스를 비롯한 전체 파일 시스템을 저장합니다.</block>
  <block id="e01cb9126428f7417091e42362dcb6cb" category="image-alt">VM 아키텍처를 생성합니다</block>
  <block id="51f24796fdd958a7a4ab9fb9a1086c9a" category="paragraph">OpenShift 클러스터에서 가상 머신을 생성하려면 다음 단계를 수행하십시오.</block>
  <block id="eaeef52618dbbd29ca52633c93abcbb4" category="list-text">원하는 운영 체제를 선택하고 Next(다음) 를 클릭합니다.</block>
  <block id="6befc3ce0d5cbd575434f0d5e1ec1125" category="list-text">선택한 운영 체제에 구성된 부팅 소스가 없는 경우 해당 소스를 구성해야 합니다. 부트 소스의 경우, URL에서 또는 레지스트리에서 OS 이미지를 가져올 것인지 선택하고 해당 세부 정보를 제공합니다. Advanced 를 확장하고 Trident-backed StorageClass 를 선택합니다. 다음 을 클릭합니다.</block>
  <block id="9b992d4161d9af3e77a9c4e35f9d7652" category="image-alt">VM의 부팅 소스를 생성합니다</block>
  <block id="fe46fcd3bb2eadd55896f6a4e9af5b05" category="list-text">선택한 운영 체제에 이미 구성된 부팅 소스가 있는 경우 이전 단계를 건너뛸 수 있습니다.</block>
  <block id="c119644bb97e69cc47555d48ff5ead07" category="list-text">가상 머신을 사용자 지정하려면 가상 머신 사용자 지정 을 클릭하고 필요한 매개 변수를 수정합니다.</block>
  <block id="8b2c60e63de0927cca5bd9401cdd4647" category="list-text">가상 머신 생성을 클릭하여 가상 머신을 생성합니다. 그러면 백그라운드에서 해당 포드가 회전합니다.</block>
  <block id="ba7734e1db4ae3c0a25330f01ced054d" category="paragraph">URL이나 레지스트리에서 템플릿이나 운영 체제에 대해 부트 소스를 구성하면 OpenShift-virtualization-OS-images' 프로젝트에서 PVC를 생성하고 KVM 게스트 이미지를 PVC로 다운로드합니다. 템플릿 PVC에 해당 OS에 대한 KVM 게스트 이미지를 수용할 수 있는 충분한 공간이 있는지 확인해야 합니다. 그런 다음 이러한 PVC는 프로젝트의 각 템플릿을 사용하여 생성될 때 가상 머신에 루트디스크로 복제되고 첨부됩니다.</block>
  <block id="2188a3011c4ccaa5490bcaca14a05579" category="inline-link-macro">다음: 워크플로: VM 실시간 마이그레이션.</block>
  <block id="a997d50e238a53b066824f32046c10ab" category="paragraph"><block ref="a997d50e238a53b066824f32046c10ab" category="inline-link-macro-rx"></block></block>
  <block id="92637d8d513510f7c1f5bfac6e1cce9b" category="summary">NetApp ONTAP 스토리지 시스템과의 Trident 통합을 활성화하려면 스토리지 시스템과의 통신을 지원하는 백엔드를 생성해야 합니다.</block>
  <block id="cbaa3aa588b8aa5c85dca443c15a0195" category="doc">NetApp ONTAP NFS 구성</block>
  <block id="89441fb0b16307f49090afa2b479b9fa" category="list-text">다운로드한 설치 아카이브에서 사용할 수 있는 예제 백엔드 파일이 'ample-input' 폴더 계층에 있습니다. NFS를 지원하는 NetApp ONTAP 시스템의 경우 'backend-ontap-nas.json' 파일을 작업 디렉토리에 복사하고 파일을 편집하십시오.</block>
  <block id="87f6ff6bf74013e1dfe6df49a1cf1986" category="list-text">backendName, managedLIF, dataLIF, svm, 사용자 이름, 및 암호 값을 입력합니다.</block>
  <block id="f897eefba2c59919d6493db4825e2db2" category="admonition">사용자 지정 backendName 값을 storageDriverName 과 NFS를 함께 사용하여 쉽게 식별할 수 있도록 하는 데이터 LIF를 함께 정의하는 것이 좋습니다.</block>
  <block id="00d6947fd6a153943286b857dcd0f339" category="admonition">이 파일에 정의된 fschType이라는 선택적 필드가 있습니다. 이 라인은 NFS 백엔드에서 삭제할 수 있습니다.</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">이 사용 사례는 클라우드 기반 분석 데이터를 사내 데이터 센터에 백업해야 하는 브로드캐스트 고객을 기반으로 합니다.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">사용 사례 2: 클라우드에서 사내로 백업 및 재해 복구</block>
  <block id="d05b5b5452aa966fcd3c8947a172f44a" category="inline-link-macro">이전: 활용 사례 1 - Hadoop 데이터 백업</block>
  <block id="d6b3b64a2054103914910c4432cc9e18" category="paragraph"><block ref="d6b3b64a2054103914910c4432cc9e18" category="inline-link-macro-rx"></block></block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">이 사용 사례는 아래 그림과 같이 클라우드 기반 분석 데이터를 사내 데이터 센터에 백업해야 하는 브로드캐스트 고객을 기반으로 합니다.</block>
  <block id="063e138ba69a95a99bd2f908b540e210" category="paragraph"><block ref="063e138ba69a95a99bd2f908b540e210" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">시나리오</block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">이 시나리오에서는 IoT 센서 데이터가 클라우드로 수집되고 AWS 내의 오픈 소스 Apache Spark 클러스터를 사용하여 분석됩니다. 따라서 클라우드에서 처리된 데이터를 사내로 백업해야 합니다.</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="section-title">요구사항 및 당면 과제</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">이 사용 사례의 주요 요구사항과 과제는 다음과 같습니다.</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">데이터 보호를 사용하도록 설정하면 클라우드의 운영 Spark/Hadoop 클러스터에 성능 영향이 미치지 않습니다.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">클라우드 센서 데이터를 효율적이고 안전한 방식으로 이동하고 사내로 보호해야 합니다.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">온디맨드, 즉각적인, 낮은 클러스터 로드 시간 등 다양한 조건에서 데이터를 클라우드로 유연하게 전송할 수 있습니다.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">해결 방법</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">이 고객은 Spark 클러스터 HDFS 스토리지에 AWS EBS(Elastic Block Store)를 사용하여 Kafka를 통해 원격 센서에서 데이터를 수신 및 수집했습니다. 따라서 HDFS 스토리지는 백업 데이터의 소스 역할을 합니다.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">이러한 요구사항을 충족하기 위해 NetApp ONTAP Cloud를 AWS에 구축하고 NFS 공유를 생성하여 Spark/Hadoop 클러스터의 백업 타겟 역할을 수행합니다.</block>
  <block id="c260f0b6bfdb6eff1473aafbf5bd075a" category="paragraph">NFS 공유가 생성된 후 데이터 이동 없는 분석 모듈을 활용하여 HDFS EBS 스토리지에서 ONTAP NFS 공유로 데이터를 복제합니다. ONTAP 클라우드의 NFS에 데이터가 상주한 후에는 SnapMirror 기술을 사용하여 필요에 따라 클라우드에서 사내 스토리지로 데이터를 안전하고 효율적으로 미러링할 수 있습니다.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">이 이미지는 클라우드에서 사내 솔루션으로 백업 및 재해 복구를 보여줍니다.</block>
  <block id="94c7a6b63152038de5e8b2763cdef06c" category="paragraph"><block ref="94c7a6b63152038de5e8b2763cdef06c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bbd6a10b63926b84e9a28da6d4214925" category="inline-link-macro">다음: 사용 사례 3 - 기존 Hadoop 데이터에 대해 DevTest를 설정합니다.</block>
  <block id="e0f915fb1893e398d54abc6f9d00ca57" category="paragraph"><block ref="e0f915fb1893e398d54abc6f9d00ca57" category="inline-link-macro-rx"></block></block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">NetApp은 NetApp StorageGRID 설정을 통해 생산 및 소비자 워크로드를 위한 3~4개의 노드로 계층형 스토리지 테스트를 수행했습니다.</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">확장성을 갖춘 성능 테스트</block>
  <block id="ef1ee9d1f1e9874aca751251bbce31bf" category="inline-link-macro">이전: Confluent verification.</block>
  <block id="6d08115c54837de983d3ddc9dcd8f038" category="paragraph"><block ref="6d08115c54837de983d3ddc9dcd8f038" category="inline-link-macro-rx"></block></block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">NetApp StorageGRID 설정을 통해 생산자 및 소비자 워크로드를 위한 3~4개의 노드로 계층형 스토리지 테스트를 수행했습니다. 이 테스트에 따르면 완료 시간과 성능 결과는 StorageGRID 노드 수에 정비례합니다. StorageGRID를 설치하려면 최소 3개의 노드가 필요합니다.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">스토리지 노드의 수가 증가했을 때 생산 및 소비자 작업을 완료하는 데 걸리는 시간이 선형적으로 감소했습니다.</block>
  <block id="544baf869b5baa766e8839cd33697872" category="paragraph"><block ref="544baf869b5baa766e8839cd33697872" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">S3 검색 작업의 성능은 StorageGRID 노드 수에 따라 선형으로 증가합니다. StorageGRID는 최대 200개의 StorgeGRID 노드를 지원합니다.</block>
  <block id="2cd319a657a7fccb8f747dab6f102dcc" category="paragraph"><block ref="2cd319a657a7fccb8f747dab6f102dcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8105fbc386e60a03fe0cf5390eb0ce" category="inline-link-macro">다음: Confluent S3 커넥터.</block>
  <block id="40acd085e3c223b35d81906b1c904f46" category="paragraph"><block ref="40acd085e3c223b35d81906b1c904f46" category="inline-link-macro-rx"></block></block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">이 섹션에서는 이 솔루션에 사용된 기술에 대해 설명합니다.</block>
  <block id="d7023badac36eeb28bf29785a97c493c" category="inline-link-macro">이전: 솔루션 아키텍처 세부 정보.</block>
  <block id="258ee3f437d6a20985ccf4e13065a097" category="paragraph"><block ref="258ee3f437d6a20985ccf4e13065a097" category="inline-link-macro-rx"></block></block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID는 비용 효율적인 고성능 오브젝트 스토리지 플랫폼입니다. 계층형 스토리지를 사용하면 중개인의 로컬 스토리지 또는 SAN 스토리지에 저장된 Confluent Kafka의 데이터 대부분이 원격 오브젝트 저장소로 오프로드됩니다. 이 구성은 클러스터 재조정, 확장 또는 축소 또는 실패한 브로커 교체에 드는 시간과 비용을 줄여 운영 효율성을 크게 개선합니다. 오브젝트 스토리지는 오브젝트 저장소 계층에 있는 데이터를 관리하는 데 중요한 역할을 합니다. 따라서 적합한 오브젝트 스토리지를 선택하는 것이 중요합니다.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID는 분산된 노드 기반 그리드 아키텍처를 사용하여 정책 중심의 지능형 글로벌 데이터 관리를 제공합니다. 정교한 데이터 관리 기능과 결합된 유비쿼터스 글로벌 오브젝트 네임스페이스를 통해 페타바이트 단위의 비정형 데이터와 수십억 개의 오브젝트 관리를 간소화합니다. 단일 호출 개체 액세스는 사이트 간에 확장되고 고가용성 아키텍처를 단순화하는 동시에 사이트 또는 인프라 중단과 관계없이 지속적인 개체 액세스를 보장합니다.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">멀티 테넌시를 사용하면 동일한 그리드 내에서 여러 비정형 클라우드 및 엔터프라이즈 데이터 애플리케이션을 안전하게 서비스할 수 있으므로 NetApp StorageGRID의 ROI 및 사용 사례가 증가합니다. 여러 지역에서 내구성, 보호, 성능, 인접성을 최적화하여 메타데이터 기반 오브젝트 라이프사이클 정책을 통해 여러 서비스 레벨을 생성할 수 있습니다. 사용자는 데이터 관리 정책을 조정하고 트래픽 제한을 모니터링 및 적용하여 끊임없이 변화하는 IT 환경에서 요구 사항이 변경됨에 따라 데이터 환경을 중단 없이 다시 조정할 수 있습니다.</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Grid Manager를 통한 간편한 관리</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID 그리드 관리자는 브라우저 기반의 그래픽 인터페이스로, 단일 창에서 전세계에 분산된 위치에 걸쳐 StorageGRID 시스템을 구성, 관리 및 모니터링할 수 있습니다.</block>
  <block id="a96dbd2aff4998074bc0ca48dc4817d5" category="paragraph"><block ref="a96dbd2aff4998074bc0ca48dc4817d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">StorageGRID 그리드 관리자 인터페이스를 사용하여 다음 작업을 수행할 수 있습니다.</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">이미지, 비디오, 레코드 등 전 세계에 분산된 페타바이트 규모의 오브젝트 저장소를 관리합니다.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">그리드 노드 및 서비스를 모니터링하여 개체 가용성을 보장합니다.</block>
  <block id="52134209a1824af49cd06b67ca3aedc7" category="list-text">ILM(정보 수명 주기 관리) 규칙을 사용하여 시간이 지남에 따라 오브젝트 데이터의 배치를 관리합니다. 이러한 규칙은 수집된 개체의 데이터, 데이터가 손실되지 않도록 보호하는 방법, 오브젝트 데이터가 저장되는 위치 및 기간에 대해 적용됩니다.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">시스템 내의 트랜잭션, 성능 및 운영을 모니터링합니다.</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">정보 수명 주기 관리 정책</block>
  <block id="a1d8b1b1990901cd5a97dd0f3dee2da9" category="inline-link-macro">ILM 정책</block>
  <block id="37e0a993cc0a3c5aacb623e412befc5b" category="inline-link-macro">ILM 규칙</block>
  <block id="0beeefc6ac257658ea119788351ad268" category="paragraph">StorageGRID는 오브젝트의 복제본 보존 및 특정 성능 및 데이터 보호 요구사항에 따라 오브젝트를 저장할 수 있도록 2+1 및 4+2(특히 다른)와 같은 EC(삭제 코딩) 스키마를 사용하는 등의 유연한 데이터 관리 정책을 제공합니다. 시간에 따라 워크로드와 요구사항이 달라지날수록 ILM 정책도 시간에 따라 바뀌어야 합니다. ILM 정책을 수정하는 것은 핵심 기능이므로 StorageGRID 고객은 끊임없이 변화하는 환경에 빠르고 쉽게 적응할 수 있습니다. 를 확인하십시오 <block ref="b2ddd4069e5288685e27e7989fb1a613" category="inline-link-macro-rx"></block> 및 <block ref="7593bc4c70a5537fc14593339f7e6540" category="inline-link-macro-rx"></block> StorageGRID에서 설정.</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 또는 SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID는 VM, 베어 메탈 또는 특수 제작된 어플라이언스 등 스토리지 노드를 추가하여 성능을 확장합니다 <block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>. 이 테스트에서는 SGF6024 어플라이언스를 사용하는 최소 크기의 3노드 그리드로 Apache Kafka의 주요 성능 요구사항을 초과했습니다. 고객이 추가 브로커로 Kafka 클러스터를 확장함에 따라 스토리지 노드를 추가하여 성능과 용량을 확장할 수 있습니다.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">부하 분산 장치 및 엔드포인트 구성</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">StorageGRID의 관리 노드는 StorageGRID 시스템을 보고, 구성하고, 관리할 수 있는 그리드 관리자 UI(사용자 인터페이스) 및 REST API 엔드포인트와 시스템 작업을 추적할 수 있는 감사 로그를 제공합니다. Confluent Kafka 계층형 스토리지에 가용성이 높은 S3 엔드포인트를 제공하기 위해 관리 노드와 게이트웨이 노드에서 서비스로 실행되는 StorageGRID 로드 밸런서를 구현했습니다. 또한 로드 밸런서는 로컬 트래픽을 관리하고 GSLB(Global Server Load Balancing)에 연결하여 재해 복구를 지원합니다.</block>
  <block id="ebe4bf9f44a65ad044fdede621409388" category="paragraph">엔드포인트 구성을 더욱 개선하기 위해 StorageGRID는 관리 노드에 내장된 트래픽 분류 정책을 제공하고, 워크로드 트래픽을 모니터링하고, 워크로드에 다양한 QoS(서비스 품질) 제한을 적용할 수 있도록 지원합니다. 트래픽 분류 정책은 게이트웨이 노드 및 관리 노드에 대한 StorageGRID 부하 분산 서비스의 끝점에 적용됩니다. 이러한 정책은 트래픽 제한 및 모니터링을 지원할 수 있습니다.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">StorageGRID의 트래픽 분류</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID에는 QoS 기능이 내장되어 있습니다. 트래픽 분류 정책은 클라이언트 애플리케이션에서 들어오는 다양한 유형의 S3 트래픽을 모니터링하는 데 도움이 될 수 있습니다. 그런 다음 정책을 생성하여 적용하여 In/Out 대역폭, 읽기/쓰기 동시 요청 수 또는 읽기/쓰기 요청 속도에 따라 이 트래픽에 제한을 적용할 수 있습니다.</block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="section-title">아파치 카프카</block>
  <block id="611f69baa46f691eeeb33645e83f0fcb" category="paragraph">Apache Kafka는 Java 및 Scala로 작성된 스트림 처리를 사용하는 소프트웨어 버스의 프레임워크입니다. 이 제품은 실시간 데이터 피드 처리를 위한 높은 처리량의 짧은 대기 시간을 갖춘 통합 플랫폼을 제공하기 위해 마련되었습니다. Kafka는 데이터 내보내기 및 가져오기를 위해 Kafka Connect를 통해 외부 시스템에 연결할 수 있으며 Java 스트림 처리 라이브러리인 Kafka 스트림을 제공합니다. Kafka는 효율성을 위해 최적화된 바이너리 TCP 기반 프로토콜을 사용하며, 네트워크를 통한 왕복 작업의 오버헤드를 줄이기 위해 자연스럽게 메시지를 그룹화하는 "메시지 세트" 추상화에 의존합니다. 이렇게 하면 순차 디스크 작업, 더 큰 네트워크 패킷 및 연속 메모리 블록이 증가하므로 Kafka는 랜덤 메시지 쓰기의 폭주 스트림을 선형 쓰기로 전환할 수 있습니다. 다음 그림은 Apache Kafka의 기본 데이터 흐름을 보여 줍니다.</block>
  <block id="d1675da945892e06b2f84c42c32b7074" category="paragraph"><block ref="d1675da945892e06b2f84c42c32b7074" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka는 생산자라는 임의의 수의 프로세스에서 가져온 키 값 메시지를 저장합니다. 데이터는 여러 주제 내의 서로 다른 파티션으로 분할될 수 있습니다. 파티션 내에서 메시지는 해당 오프셋(파티션 내의 메시지 위치)에 의해 엄격하게 정렬되고 타임 스탬프와 함께 인덱싱되고 저장됩니다. 소비자라고 하는 다른 프로세스는 파티션에서 메시지를 읽을 수 있습니다. 스트림 처리를 위해 Kafka는 Kafka의 데이터를 사용하는 Java 애플리케이션을 작성하고 결과를 Kafka에 다시 쓸 수 있는 스트림 API를 제공합니다. Apache Kafka는 Apache Apex, Apache Flink, Apache Spark, Apache Storm, Apache nifi 등의 외부 스트림 처리 시스템과도 작동합니다.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka는 하나 이상의 서버(브로커)로 구성된 클러스터에서 실행되며 모든 항목의 파티션이 클러스터 노드에 분산됩니다. 또한 파티션이 여러 브로커에 복제됩니다. 이 아키텍처를 통해 Kafka는 내결함성이 있는 방식으로 대규모 메시지 스트림을 전달할 수 있으며 JMS(Java Message Service), AMQP(Advanced Message Queuing Protocol) 등의 기존 메시징 시스템을 대체할 수 있습니다. Kafka는 0.11.0.0 릴리스 이후 트랜잭션 쓰기를 제공하여 스트림 API를 사용하여 정확히 한 번의 스트림 처리를 제공합니다.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka는 일반과 컴팩션이라는 두 가지 유형의 주제를 지원합니다. 정규 주제는 보존 시간 또는 공간 바인딩으로 구성할 수 있습니다. 지정된 보존 시간보다 오래된 레코드가 있거나 파티션에 대해 바인딩된 공간이 초과된 경우 Kafka는 사용 가능한 저장소 공간을 확보하기 위해 이전 데이터를 삭제할 수 있습니다. 기본적으로 항목은 보존 기간이 7일로 구성되지만 데이터를 무기한 저장할 수도 있습니다. 압축된 항목의 경우 시간 또는 공간 범위에 따라 레코드가 만료되지 않습니다. 대신 Kafka는 나중에 받은 메시지를 동일한 키를 사용하는 이전 메시지의 업데이트로 취급하며 키당 최신 메시지를 삭제하지 않도록 보장합니다. 사용자는 특정 키에 대해 null 값을 갖는 소위 tombstone 메시지를 작성하여 메시지를 완전히 삭제할 수 있습니다.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Kafka에는 다음과 같은 5가지 주요 API가 있습니다.</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">* Producer API. * 응용 프로그램에서 레코드 스트림을 게시할 수 있도록 허용합니다.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">* 소비자 API. * 응용 프로그램에서 항목 및 레코드 스트림 프로세스를 구독할 수 있도록 허용합니다.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">* Connector API. * 항목을 기존 응용 프로그램에 연결할 수 있는 재사용 가능한 프로듀서 및 소비자 API를 실행합니다.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">* Streams API. * 이 API는 입력 스트림을 출력으로 변환하고 결과를 생성합니다.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">* Admin API. * Kafka 주제, 브로커 및 기타 Kafka 객체를 관리하는 데 사용됩니다.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">소비자 및 생산자 API는 Kafka 메시징 프로토콜을 기반으로 하며 Java의 Kafka 소비자 및 생산자 클라이언트에 대한 참조 구현을 제공합니다. 기본 메시징 프로토콜은 개발자가 프로그래밍 언어로 소비자 또는 생산자 클라이언트를 작성하는 데 사용할 수 있는 이진 프로토콜입니다. 이렇게 하면 JVM(Java Virtual Machine) 에코시스템에서 Kafka가 잠금 해제됩니다. 사용 가능한 비 Java 클라이언트 목록은 Apache Kafka wiki에서 유지 관리됩니다.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Apache Kafka 사용 사례</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka는 메시징, 웹 사이트 활동 추적, 메트릭, 로그 집계, 스트림 처리, 이벤트 소싱 및 로깅 커밋</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka는 향상된 처리량, 내장 파티셔닝, 복제 및 내결함성 기능을 제공하므로 대규모 메시지 처리 애플리케이션에 적합한 솔루션입니다.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka는 실시간 게시 구독 피드 집합으로 추적 파이프라인에서 사용자의 활동(페이지 보기, 검색)을 재구축할 수 있습니다.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka는 운영 모니터링 데이터에 자주 사용됩니다. 이를 위해서는 분산된 애플리케이션에서 통계를 집계하여 운영 데이터의 중앙 집중식 피드를 생성하는 작업이 필요합니다.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">많은 사람들이 Kafka를 로그 집계 솔루션의 대안으로 사용합니다. 로그 집계는 일반적으로 서버에서 물리적 로그 파일을 수집하여 처리를 위해 중앙 위치(예: 파일 서버 또는 HDFS)에 배치합니다. Kafka는 파일 세부 정보를 추상화하고 로그 또는 이벤트 데이터를 메시지 스트림으로 추상화합니다. 따라서 대기 시간이 짧아지며 여러 데이터 소스 및 분산된 데이터 사용을 더욱 쉽게 지원할 수 있습니다.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Kafka의 많은 사용자는 여러 스테이지로 구성된 처리 파이프라인에서 원시 입력 데이터가 Kafka 주제에서 소비된 후 추가 소비 또는 후속 처리를 위해 새로운 주제로 집계, 강화 또는 기타 방식으로 변환되는 데이터를 처리합니다. 예를 들어 뉴스 기사를 추천하기 위한 처리 파이프라인은 RSS 피드에서 기사 콘텐츠를 크롤링하여 "기사" 항목에 게시할 수 있습니다. 추가 처리에서는 이 콘텐츠를 정규화하거나 중복 제거하고 정리된 문서 콘텐츠를 새 주제에 게시하며 최종 처리 단계에서 사용자에게 이 콘텐츠를 추천하려고 할 수 있습니다. 이러한 처리 파이프라인은 개별 주제를 기반으로 실시간 데이터 플로우의 그래프를 작성합니다.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">이벤트 수그리기는 상태 변경이 시간 순서 기록 시퀀스로 기록되는 응용 프로그램 디자인의 스타일입니다. Kafka는 매우 큰 저장 로그 데이터를 지원하므로 이 스타일로 구축된 애플리케이션에 대한 탁월한 백엔드로 활용할 수 있습니다.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka는 분산 시스템에 대한 일종의 외부 커밋 로그 역할을 할 수 있습니다. 이 로그는 노드 간 데이터를 복제하고 장애가 발생한 노드가 데이터를 복원할 수 있도록 재동기화 메커니즘 역할을 합니다. Kafka의 로그 컴팩션 기능은 이 활용 사례를 지원하는 데 도움이 됩니다.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="section-title">유창하게</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform은 Kafka를 완성하는 엔터프라이즈급 플랫폼으로, 애플리케이션 개발 및 연결 속도를 높이고, 스트림 처리를 통해 혁신을 지원하고, 규모에 따라 엔터프라이즈 운영을 간소화하고, 엄격한 아키텍처 요구 사항을 충족하도록 설계된 고급 기능을 제공합니다. Apache Kafka를 처음 개발한 Confluent는 Kafka 관리 또는 모니터링의 부담을 덜면서 엔터프라이즈급 기능을 통해 Kafka의 이점을 확장해 줍니다. 현재 Fortune 100대 기업 중 80% 이상이 데이터 스트리밍 기술을 사용하고 있으며 대부분 Confluent를 사용하고 있습니다.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">왜 Confluent인가?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Confluorent는 기록 데이터와 실시간 데이터를 단일 중앙 데이터 소스에 통합하여 완전히 새로운 범주의 최신 이벤트 기반 애플리케이션을 쉽게 구축하고, 범용 데이터 파이프라인을 구축하며, 완전한 확장성, 성능, 안정성으로 강력한 새 사용 사례를 활용할 수 있도록 지원합니다.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">Contfluent는 어떤 용도로 사용됩니까?</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent Platform을 사용하면 데이터가 다른 시스템 간에 어떻게 전송 또는 통합되는지 등의 기본 메커니즘을 걱정하지 않고 데이터에서 비즈니스 가치를 창출하는 방법에 집중할 수 있습니다. 특히 Confluent Platform은 데이터 소스를 Kafka에 연결하고 스트리밍 애플리케이션을 구축하며 Kafka 인프라의 보안, 모니터링 및 관리를 간소화합니다. 현재 Confluent Platform은 금융 서비스, 옴니채널 소매, 자율 자동차, 사기 탐지 등 다양한 산업 전반의 다양한 사용 사례에 사용됩니다. 마이크로서비스, IoT</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">다음 그림에서는 Confluent Kafka 플랫폼 구성 요소를 보여 줍니다.</block>
  <block id="a4eaf48584aaa7df975a9275a8b4ee24" category="paragraph"><block ref="a4eaf48584aaa7df975a9275a8b4ee24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0693822e07a3206c53912f33e3d67758" category="section-title">Confluent의 이벤트 스트리밍 기술 개요</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Confluent Platform의 핵심은 입니다<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>가장 널리 사용되는 오픈 소스 분산 스트리밍 플랫폼입니다. Kafka의 주요 기능은 다음과 같습니다.</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">레코드 스트림을 게시하고 구독합니다.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">내결함성이 있는 방식으로 레코드 스트림을 저장합니다.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">레코드 스트림을 처리합니다.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">즉시 사용할 수 있는 Confluorent Platform에는 스키마 레지스트리, REST 프록시, 총 100개 이상의 사전 구축된 Kafka 커넥터 및 ksqlDB도 포함되어 있습니다.</block>
  <block id="55be5d4d3f7143137050de9374d03f6f" category="section-title">Confluent 플랫폼의 엔터프라이즈 기능 개요</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">* Confluent Control Center. * Kafka 관리 및 모니터링을 위한 GUI 기반 시스템. Kafka Connect를 쉽게 관리하고 다른 시스템에 대한 연결을 생성, 편집 및 관리할 수 있습니다.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">Kubernetes를 위한 * Contfluent. * Kubernetes를 위한 Confluent는 Kubernetes 운영자입니다. Kubernetes 운영자는 특정 플랫폼 애플리케이션에 대한 고유한 기능과 요구 사항을 제공하여 Kubernetes의 오케스트레이션 기능을 확장합니다. Confluent Platform의 경우, Kubernetes에서 Kafka의 구축 프로세스를 크게 간소화하고 일반적인 인프라 라이프사이클 작업을 자동화할 수 있습니다.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">* Kafka * 커넥터에 대한 Confluent 커넥터 Kafka Connect API를 사용하여 Kafka를 데이터베이스, 키 값 저장소, 검색 인덱스 및 파일 시스템과 같은 다른 시스템에 연결합니다. Confluorent Hub에는 가장 널리 사용되는 데이터 소스 및 싱크에 대한 다운로드 가능한 커넥터가 있습니다. 여기에는 Confluorent Platform이 포함된 이러한 커넥터의 전체 테스트 및 지원 버전이 포함됩니다. 자세한 내용은 을 참조하십시오<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">* 자체 밸런싱 클러스터 * 는 자동화된 로드 밸런싱, 장애 감지 및 자동 복구를 제공합니다. 필요에 따라 브로커를 추가하거나 해체할 수 있도록 지원하며 수동 튜닝이 필요하지 않습니다.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">* 연결 클러스터. * 직접 클러스터를 연결하고 링크 브리지를 통해 클러스터 간에 주제를 미러링합니다. 클러스터 링크를 사용하면 멀티 데이터 센터, 멀티 클러스터, 하이브리드 클라우드 구축을 간편하게 설정할 수 있습니다.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">* Confluorent auto data balancer. * 브로커 수, 파티션 크기, 파티션 수 및 클러스터 내의 리더 수에 대한 클러스터를 모니터링합니다. 균형 조정을 통해 트래픽을 재조정함으로써 운영 워크로드에 미치는 영향을 최소화하면서 클러스터 전체에서 짝수 워크로드를 생성할 수 있습니다.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">* Confluent Replicator. * 여러 데이터 센터에서 여러 Kafka 클러스터를 훨씬 쉽게 유지 관리할 수 있습니다.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">* 계층형 스토리지. * 즐겨 사용하는 클라우드 공급자를 사용하여 대량의 Kafka 데이터를 저장할 수 있는 옵션을 제공하므로 운영 부담과 비용이 줄어듭니다. 계층형 스토리지를 사용하면 비용 효율적인 오브젝트 스토리지에 데이터를 보관하고 더 많은 컴퓨팅 리소스가 필요할 때만 브로커를 확장할 수 있습니다.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">* Confluent JMS 클라이언트. * Confluent Platform에는 Kafka용 JMS 호환 클라이언트가 포함되어 있습니다. 이 Kafka 클라이언트는 Kafka 브로커를 백엔드로 사용하여 JMS 1.1 표준 API를 구현합니다. JMS를 사용하는 레거시 애플리케이션이 있고 기존 JMS 메시지 브로커를 Kafka로 교체하려는 경우 유용합니다.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">* Confluent MQTT proxy. * 중간에 MQTT 브로커가 없어도 MQTT 장치 및 게이트웨이에서 Kafka에 직접 데이터를 게시할 수 있는 방법을 제공합니다.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">* Confluent 보안 플러그인 * Confluent 보안 플러그인은 다양한 Confluent 플랫폼 도구 및 제품에 보안 기능을 추가하는 데 사용됩니다. 현재 Confluent REST 프록시에 사용할 수 있는 플러그인이 있어 수신 요청을 인증하고 인증된 보안 주체를 Kafka에 요청에 전파할 수 있습니다. 이렇게 하면 Confluent REST 프록시 클라이언트가 Kafka 브로커의 멀티테넌트 보안 기능을 활용할 수 있습니다.</block>
  <block id="4f9143a5adb8a0385a1c660d201ef274" category="inline-link-macro">다음: Confluent verification</block>
  <block id="d566a24bfcb09090b96a073132a83173" category="paragraph"><block ref="d566a24bfcb09090b96a073132a83173" category="inline-link-macro-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">이 문서에서는 NetApp 스토리지 컨트롤러에서 Kafka를 사용하기 위한 모범 사례 지침을 설명합니다.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="doc">TR-4912: NetApp을 통해 Confluent Kafka 계층형 스토리지를 위한 모범 사례 지침</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthkeyan Nagalingam, Joseph Kandatillarambil, NetApp Rankesh Kumar, Confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka는 매일 수조 건의 이벤트를 처리할 수 있는 커뮤니티 분산 이벤트 스트리밍 플랫폼입니다. 처음에 메시징 큐로 구상된 Kafka는 분산 커밋 로그의 추상화를 기반으로 합니다. Kafka는 2011년 LinkedIn에서 제작 및 오픈 소스를 통해 메시지 큐에서 완전한 이벤트 스트리밍 플랫폼으로 발전했습니다. Confluent는 Apache Kafka를 Confluent Platform과 함께 배포할 수 있도록 합니다. Confluent Platform은 Kafka를 보완하는 추가적인 커뮤니티 및 상용 기능을 제공하여 대규모 생산 환경에서 운영자와 개발자 모두의 스트리밍 경험을 개선하도록 설계되었습니다.</block>
  <block id="e1c012d650a6912ddb72ab0ee914d169" category="paragraph">이 문서에서는 다음 내용을 제공하여 NetApp의 오브젝트 스토리지 제품에서 Confluent Tiered Storage를 사용하기 위한 모범 사례 지침을 설명합니다.</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">NetApp 오브젝트 스토리지를 위한 Confluent 검증 – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">계층형 스토리지 성능 테스트</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">NetApp 스토리지 시스템에 대한 Confluent의 모범 사례 지침</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">ContFluent Tiered Storage를 선택해야 하는 이유</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">이 기사는 Confluent에 의해 작성되었습니다</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent는 많은 애플리케이션, 특히 빅데이터, 분석 및 스트리밍 워크로드를 위한 기본 실시간 스트리밍 플랫폼이 되었습니다. 계층적 스토리지를 사용하면 사용자가 Confluent 플랫폼의 스토리지에서 컴퓨팅을 분리할 수 있습니다. Data Fabric을 활용하면 데이터를 보다 경제적으로 저장하고, 사실상 무한대의 데이터를 저장하고, 필요 시 워크로드를 스케일업(또는 스케일다운) 할 수 있으며, 데이터 및 테넌트 재조정과 같은 관리 작업을 더 쉽게 수행할 수 있습니다. S3 호환 스토리지 시스템은 이러한 모든 기능을 활용하여 모든 이벤트의 데이터를 한 곳에서 대중화할 수 있으며, 복잡한 데이터 엔지니어링이 필요하지 않습니다. Kafka에 계층형 스토리지를 사용해야 하는 이유에 대한 자세한 내용은 을 참조하십시오 <block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>.</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">NetApp StorageGRID를 계층형 스토리지로 선택해야 하는 이유</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID은 NetApp에서 제공하는 업계 최고의 오브젝트 스토리지 플랫폼입니다. StorageGRID은 Amazon S3(Simple Storage Service) API를 비롯한 업계 표준 오브젝트 API를 지원하는 소프트웨어 정의 오브젝트 기반 스토리지 솔루션입니다. StorageGRID는 비정형 데이터를 대규모로 저장 및 관리하여 안전하고 내구성 있는 오브젝트 스토리지를 제공합니다. 콘텐츠가 적절한 위치, 적합한 시간 및 적합한 스토리지 계층에 배치되어 전 세계적으로 분산된 다양한 미디어의 워크플로우를 최적화하고 비용을 줄입니다.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">StorageGRID의 가장 큰 차별화 요소는 정책 기반 데이터 라이프사이클 관리를 지원하는 ILM(정보 라이프사이클 관리) 정책 엔진입니다. 정책 엔진은 메타데이터를 사용해 수명 주기 동안 데이터가 저장되는 방식을 관리하여 처음에 성능을 최적화하고 데이터 사용 기간에 따라 비용 및 내구성을 자동으로 최적화할 수 있습니다.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">ContFluent Tiered Storage 활성화</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">계층형 스토리지의 기본 개념은 데이터 스토리지와 데이터 처리 작업을 분리하는 것입니다. 이와 같은 분리 덕분에 데이터 스토리지 계층과 데이터 처리 계층이 독립적으로 확장하는 것이 훨씬 쉬워졌습니다.</block>
  <block id="e963c7bc15c18e21f60a9969d876e3e8" category="paragraph">Confluent를 위한 계층형 스토리지 솔루션은 두 가지 요소를 고려해야 합니다. 먼저, 목록 작업의 일관성 오류, 간헐적인 개체 가용성 손실 등과 같은 일반적인 개체 저장소의 일관성 및 가용성 속성을 문제를 해결 또는 방지해야 합니다. 두 번째로, 이 제품은 계층형 스토리지와 Kafka의 복제 및 내결함성 모델 간의 상호 작용을 올바르게 처리해야 하며, 이러한 상호 작용에는 좀비 리더가 계속해서 오프셋 범위를 계층화할 수 있는 가능성이 포함됩니다. NetApp 오브젝트 스토리지는 일관된 오브젝트 가용성과 HA 모델을 모두 제공하므로 피로한 스토리지를 계층 오프셋 범위에 사용할 수 있습니다. NetApp 오브젝트 스토리지는 일관된 오브젝트 가용성과 HA 모델을 제공하여 지친 스토리지를 계층 오프셋 범위에 사용할 수 있도록 합니다.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">계층형 스토리지를 사용하면 스트리밍 데이터의 지연 시간이 짧은 읽기 및 쓰기 작업에 고성능 플랫폼을 사용할 수 있으며, 처리량이 높은 내역 읽기를 위해 NetApp StorageGRID와 같은 경제적이고 확장 가능한 오브젝트 저장소를 사용할 수도 있습니다. NetApp은 Spark with NetApp 스토리지 컨트롤러 및 세부 정보를 위한 기술 솔루션도 갖추고 있습니다. 다음 그림은 Kafka가 실시간 분석 파이프라인에 어떻게 부합하는지를 보여줍니다.</block>
  <block id="c7e421673ed217d2262c482dc24d0995" category="paragraph"><block ref="c7e421673ed217d2262c482dc24d0995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66b784e6401c98dcf152747d22976bf7" category="paragraph">다음 그림은 NetApp StorageGRID가 Confluent Kafka의 오브젝트 스토리지 계층으로 적합한 방식을 보여줍니다.</block>
  <block id="f4e981d58b1468737da82402b3cce7f1" category="paragraph"><block ref="f4e981d58b1468737da82402b3cce7f1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c3dbe3ccb3831e313d1d072656fa861" category="inline-link-macro">다음은 솔루션 아키텍처 세부 정보입니다.</block>
  <block id="adcb27f49e58936cf868bc3cc2726dd7" category="paragraph"><block ref="adcb27f49e58936cf868bc3cc2726dd7" category="inline-link-macro-rx"></block></block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">NetApp StorageGRID의 계층형 스토리지를 위해 Kafka와 Confluent Platform으로 인증을 수행했습니다.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Confluent 검증</block>
  <block id="0a569fd987814c0464300156b2e26414" category="paragraph"><block ref="0a569fd987814c0464300156b2e26414" category="inline-link-macro-rx"></block></block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">NetApp StorageGRID에서 Confluent Platform 6.2 계층형 스토리지를 사용하여 검증을 수행했습니다. NetApp과 Confluent 팀은 이 검증을 함께 수행하여 검증에 필요한 테스트 사례를 실행했습니다.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Confluent 플랫폼 설정</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">검증을 위해 다음 설정을 사용했습니다.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">검증을 위해 3대의 zookeers, 5개의 브로커, 5개의 테스트 스크립트 실행 서버, 256GB RAM이 장착된 명명된 도구 서버, 16개의 CPU를 사용했습니다. NetApp 스토리지의 경우 SGF6024s 4개로 SG1000 로드 밸런서와 함께 StorageGRID를 사용했습니다. 스토리지와 브로커는 100GbE 연결을 통해 연결되었습니다.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">다음 그림은 Confluent 확인에 사용되는 구성의 네트워크 토폴로지를 보여줍니다.</block>
  <block id="82dc8b1c8f1a6f08261f17b764e74bf4" category="paragraph"><block ref="82dc8b1c8f1a6f08261f17b764e74bf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">도구 서버는 Confluent 노드에 요청을 보내는 애플리케이션 클라이언트의 역할을 합니다.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Confluent 계층형 스토리지 구성</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">계층화된 스토리지 구성에는 Kafka에서 다음 매개 변수가 필요합니다.</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">검증을 위해 StorageGRID를 HTTP 프로토콜과 함께 사용했지만 HTTPS도 작동합니다. 액세스 키와 비밀 키는 confluent.tier.s3.cred.file.path 매개 변수에 제공된 파일 이름에 저장됩니다.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">NetApp 오브젝트 스토리지 - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">StorageGRID에서 정화를 위해 단일 사이트 구성을 구성했습니다.</block>
  <block id="1ba0fc45020f864c62328d58df2351ef" category="paragraph"><block ref="1ba0fc45020f864c62328d58df2351ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">검증 테스트</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">검증을 위해 다음 5가지 테스트 사례를 완료했습니다. 이러한 검사는 Trogor 프레임워크에서 실행됩니다. 첫 번째 두 테스트는 기능 테스트이고 나머지 세 가지는 성능 테스트입니다.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">객체 저장소 정확도 테스트</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">이 테스트에서는 오브젝트 저장소 API의 모든 기본 작업(예: get/put/delete)이 계층적 스토리지의 요구에 따라 잘 작동하는지 여부를 확인합니다. 모든 오브젝트 저장소 서비스가 다음 테스트보다 먼저 통과해야 하는 기본 테스트입니다. 통과 또는 실패한 단정적인 테스트입니다.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">계층화 기능 정확도 테스트</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">이 테스트에서는 종단 간 계층형 스토리지 기능이 통과 또는 실패한 적극적 테스트와 잘 작동하는지 여부를 확인합니다. 이 테스트에서는 기본적으로 계층화를 사용하도록 구성되고 핫 세트 크기가 크게 줄어든 테스트 항목을 생성합니다. 새로 만든 테스트 항목으로 이벤트 스트림을 생성하고 브로커가 세그먼트를 개체 저장소에 아카이빙할 때까지 대기한 다음 이벤트 스트림을 사용하여 소비된 스트림이 생성된 스트림과 일치하는지 확인합니다. 이벤트 스트림에 생성되는 메시지 수를 구성할 수 있으므로 테스트 요구에 따라 충분한 크기의 워크로드를 생성할 수 있습니다. 줄어든 핫세트 크기는 소비자가 활성 세그먼트 밖에 있는 페치를 개체 저장소에서만 제공되도록 합니다. 이렇게 하면 읽기에 대한 개체 저장소의 정확성을 테스트하는 데 도움이 됩니다. 객체 저장소 결함 주입 여부와 관계없이 이 테스트를 수행했습니다. StorageGRID의 노드 중 하나에서 서비스 관리자 서비스를 중지하고 엔드 투 엔드 기능이 오브젝트 스토리지에서 작동하는지 확인하여 노드 장애를 시뮬레이션했습니다.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">계층 가져오기 벤치마크</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">이 테스트에서는 계층형 오브젝트 스토리지의 읽기 성능을 검증하고 벤치마크에 의해 생성된 세그먼트에서 과부하된 읽기 요청 범위를 검사했습니다. 이 벤치마크에서 Confluent는 계층 가져오기 요청을 처리하기 위해 사용자 지정 클라이언트를 개발했습니다.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">생산 - 워크로드 벤치마크 소비</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">이 테스트에서는 세그먼트 아카이브를 통해 오브젝트 저장소에서 쓰기 워크로드를 간접적으로 생성했습니다. 소비자 그룹이 세그먼트를 가져올 때 객체 스토리지에서 읽기 워크로드(세그먼트 읽기)가 생성되었습니다. 이 워크로드는 테스트 스크립트에 의해 생성되었습니다. 이 테스트에서는 오브젝트 저장소에서 병렬 스레드의 읽기 및 쓰기 성능을 확인했습니다. 계층화 기능 정확도 테스트에서 보았듯이, 객체 저장소 결함 주입을 사용하여 테스트했으며 포함하지 않았습니다.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">보존 워크로드 벤치마크</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">이 테스트에서는 무거운 주제 보존 워크로드 하에서 오브젝트 저장소의 삭제 성능을 검사했습니다. 보존 워크로드는 테스트 주제와 동시에 많은 메시지를 생성하는 테스트 스크립트를 사용하여 생성되었습니다. 테스트 주제는 공격적인 크기 기반 및 시간 기반 보존 설정으로 구성되었으며, 이로 인해 이벤트 스트림이 개체 저장소에서 지속적으로 제거됩니다. 그런 다음 세그먼트가 아카이브되었습니다. 이로 인해 오브젝트 저장소 삭제 작업의 수행 중개 및 컬렉션에 의해 오브젝트 저장소에서 많은 삭제가 수행되었습니다.</block>
  <block id="b2ce010f52b23eb40ba6b51b92837acb" category="inline-link-macro">다음: 확장성의 성능 테스트.</block>
  <block id="4a94c930da0f9f0974ad6d4f2d17726b" category="paragraph"><block ref="4a94c930da0f9f0974ad6d4f2d17726b" category="inline-link-macro-rx"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">본 문서는 NetApp AFF 및 FAS 스토리지 시스템, NetApp Cloud Volumes ONTAP, NetApp 연결형 스토리지, Spark 및 Hadoop용 NetApp FlexClone 기술을 사용하는 하이브리드 클라우드 데이터 솔루션에 대해 설명합니다. 이러한 솔루션 아키텍처를 통해 고객은 자신의 환경에 적합한 데이터 보호 솔루션을 선택할 수 있습니다. NetApp은 고객과의 상호 작용 및 비즈니스 사용 사례를 기반으로 이러한 솔루션을 설계했습니다.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="doc">TR-4657: NetApp 하이브리드 클라우드 데이터 솔루션 - 고객 사용 사례를 기반으로 Spark 및 Hadoop</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">NetApp의 Karthikeyan Nagalingam 및 Sathish Thyagarajan</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">본 문서는 NetApp AFF 및 FAS 스토리지 시스템, NetApp Cloud Volumes ONTAP, NetApp 연결형 스토리지, Spark 및 Hadoop용 NetApp FlexClone 기술을 사용하는 하이브리드 클라우드 데이터 솔루션에 대해 설명합니다. 이러한 솔루션 아키텍처를 통해 고객은 자신의 환경에 적합한 데이터 보호 솔루션을 선택할 수 있습니다. NetApp은 고객과의 상호 작용 및 비즈니스 사용 사례를 기반으로 이러한 솔루션을 설계했습니다. 이 문서에서는 다음과 같은 자세한 정보를 제공합니다.</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Spark 및 Hadoop 환경 및 고객의 당면 과제를 해결하기 위해 데이터 보호가 필요한 이유</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">NetApp 비전 및 구성 요소와 서비스를 기반으로 하는 Data Fabric</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">이러한 구성 요소를 사용하여 유연한 데이터 보호 워크플로우를 구축하는 방법</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">실제 고객 사용 사례를 기반으로 한 여러 아키텍처의 장단점을 설명합니다. 각 활용 사례는 다음과 같은 구성 요소를 제공합니다.</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">고객 시나리오</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">해결하세요</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">솔루션 요약</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Hadoop 데이터 보호를 선택해야 하는 이유</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">Hadoop 및 Spark 환경에서는 다음과 같은 문제를 해결해야 합니다.</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">* 소프트웨어 또는 사용자 오류. * Hadoop 데이터 작업을 수행하는 동안 소프트웨어 업데이트에 사람의 실수가 발생할 수 있으며, 이로 인해 작업에 예상치 못한 결과가 발생할 수 있습니다. 이 경우 오류나 부당한 결과를 방지하려면 데이터를 보호해야 합니다. 예를 들어, 소프트웨어 업데이트가 제대로 실행되지 않아 트래픽 신호 데이터를 일반 텍스트 형식으로 제대로 분석하지 못하는 새로운 기능이 추가되었습니다. 이 소프트웨어는 JSON 및 기타 비 텍스트 파일 형식을 분석하여 실시간 트래픽 제어 분석 시스템을 통해 데이터 포인트가 누락된 예측 결과를 생성합니다. 이 상황은 출력 결함을 초래하여 교통 신호에서 사고를 일으킬 수 있습니다. 데이터 보호는 이전 작업 중인 응용 프로그램 버전으로 빠르게 롤백할 수 있는 기능을 제공하여 이 문제를 해결할 수 있습니다.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">* 규모와 확장성 * 데이터 소스와 볼륨의 수가 계속 증가함에 따라 분석 데이터의 크기가 매일 증가하고 있습니다. 소셜 미디어, 모바일 앱, 데이터 분석 및 클라우드 컴퓨팅 플랫폼은 현재 빅데이터 시장의 주요 데이터 소스로서 빠르게 증가하고 있으며, 따라서 정확한 데이터 운영을 위해 데이터를 보호해야 합니다.</block>
  <block id="80908b4b31d37977701d3694fbc636ac" category="list-text">* Hadoop의 기본 데이터 보호. * Hadoop에는 데이터를 보호하는 기본 명령이 있지만 이 명령은 백업 중에 데이터의 일관성을 제공하지 않습니다. 디렉토리 레벨 백업만 지원합니다. Hadoop에서 생성된 스냅샷은 읽기 전용이며 백업 데이터를 직접 재사용하는 데 사용할 수 없습니다.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Hadoop 및 Spark 고객의 데이터 보호 당면 과제</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Hadoop 및 Spark 고객의 일반적인 과제는 데이터 보호 중에 운영 클러스터의 성능에 부정적인 영향을 주지 않고 백업 시간을 단축하고 백업 안정성을 높이는 것입니다.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">또한 고객은 RPO(복구 시점 목표) 및 RTO(복구 시간 목표) 다운타임을 최소화하고 사내 및 클라우드 기반 재해 복구 사이트를 제어하여 비즈니스 연속성을 최적화해야 합니다. 이 제어 기능은 일반적으로 엔터프라이즈급 관리 툴을 사용하는 데서 비롯됩니다.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Hadoop과 Spark 환경은 데이터 볼륨이 엄청나며 증가하기 때문에 복잡합니다. 하지만 데이터가 도착하는 속도는 점점 증가하고 있습니다. 이 시나리오를 통해 소스 데이터에서 효율적인 최신 DevTest 및 QA 환경을 빠르게 생성하기가 어렵습니다. NetApp은 이러한 과제를 인식하고 이 백서에 제공된 솔루션을 제공합니다.</block>
  <block id="1f60e9ce60971dc2129b30c8820ff343" category="inline-link-macro">다음 단계로: NetApp에서 제공하는 빅데이터 아키텍처 관련 Data Fabric</block>
  <block id="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="paragraph"><block ref="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="inline-link-macro-rx"></block></block>
  <block id="69efde21ccf40f1dda4d665f81bacefe" category="summary">이 시나리오에서는 NetApp NFS 스토리지 솔루션을 사용하여 대형 금융 서비스 및 투자 은행의 분석 플랫폼을 현대화함으로써 자산 관리 및 정량적 사업부의 투자 위험 및 파생물 분석에 상당한 개선을 이루었습니다.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">사용 사례 5: 분석 워크로드 가속화</block>
  <block id="c8ea1eda8e0ac121148ac86dee9649a7" category="inline-link-macro">이전: 사용 사례 4 - 데이터 보호 및 멀티 클라우드 연결</block>
  <block id="87fb2a1eb3f12014af6e5dd36ba66e5e" category="paragraph"><block ref="87fb2a1eb3f12014af6e5dd36ba66e5e" category="inline-link-macro-rx"></block></block>
  <block id="24b0e878b8196875cd088397ac8312a9" category="paragraph">고객의 기존 환경에서 분석 플랫폼에 사용되는 Hadoop 인프라는 Hadoop 서버의 내부 스토리지를 활용했습니다. JBOD 환경의 독점 특성으로 인해 조직 내의 많은 내부 고객은 실시간 데이터의 반복 샘플에 의존하는 시뮬레이션인 Monte Carlo 정량 모델을 활용할 수 없었습니다. 시장 이동이 불확실성의 영향을 이해하는 데 있어 최적화되지 않은 능력은 정량적 자산 관리 사업부에 비호의적으로 작용했습니다.</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">이 은행의 정량적 사업부는 정확하고 시기 적절한 예측을 얻기 위한 효율적인 예측 방법을 원했습니다. 이를 위해 IT 팀에서는 인프라를 현대화하고, 기존 I/O 대기 시간을 줄이며, Hadoop, Spark와 같은 분석 애플리케이션의 성능을 개선하여 투자 모델을 효율적으로 시뮬레이션하고, 잠재적인 이익을 측정하고, 위험을 분석해야 한다는 사실을 깨달았습니다.</block>
  <block id="5ff37557b096819452a25d129a312360" category="paragraph">고객은 기존 Spark 솔루션에 대한 JBOD를 가지고 있었습니다. 그런 다음 NetApp ONTAP, NetApp StorageGRID 및 MinIO Gateway to NFS를 활용하여 잠재적인 이익과 위험을 평가하는 투자 모델에 대한 시뮬레이션 및 분석을 실행하는 금융 그룹의 정량적 대기 시간을 줄였습니다. 이 이미지는 NetApp 스토리지의 Spark 솔루션을 보여줍니다.</block>
  <block id="095ba715431845442ef6bf2f4283ad1c" category="paragraph"><block ref="095ba715431845442ef6bf2f4283ad1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">위 그림과 같이 StorageGRID A800, A700 시스템 및 AFF는 Spark가 있는 6노드 Hadoop 클러스터 및 데이터 분석 작업을 위한 YARN 및 Hive 메타데이터 서비스의 NFS 및 S3 프로토콜을 통해 쪽모이 세공 파일에 액세스하기 위해 구축되었습니다.</block>
  <block id="bc12facb8aa0a34db56b00fdbc21c351" category="paragraph">고객의 기존 환경에서 DAS(직접 연결 스토리지) 솔루션을 사용할 경우 컴퓨팅과 스토리지를 독립적으로 확장한다는 단점이 있었습니다. Spark용 NetApp ONTAP 솔루션을 통해 은행의 재무 분석 사업부에서 스토리지를 컴퓨팅에서 분리하여 필요에 따라 인프라 리소스를 보다 효율적으로 제공할 수 있게 되었습니다.</block>
  <block id="582c4aa65d1bd005ddc785db8b807fca" category="paragraph">NFS와 함께 ONTAP를 사용함으로써 컴퓨팅 서버 CPU는 Spark SQL 작업에 거의 전적으로 활용되었고 I/O 대기 시간이 약 70% 감소되어 스파크 워크로드에 더 나은 컴퓨팅 성능과 성능 향상을 제공했습니다. 또한 CPU 활용률을 높임으로써 고객이 GPUDirect와 같은 GPU를 활용하여 플랫폼을 더욱 현대화할 수 있도록 했습니다. 또한 StorageGRID는 스파크 워크로드를 위한 저렴한 스토리지 옵션을 제공하며 MinIO 게이트웨이는 S3 프로토콜을 통해 NFS 데이터에 대한 안전한 액세스를 제공합니다. 클라우드의 데이터에 대해 NetApp은 Cloud Volumes ONTAP, Azure NetApp Files 및 NetApp Cloud Volumes Service를 권장합니다.</block>
  <block id="6e362ed6e741056d737b93021ab2f3f9" category="paragraph"><block ref="6e362ed6e741056d737b93021ab2f3f9" category="inline-link-macro-rx"></block></block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">이 문서에서는 Confluent Kafka 인증 테스트, 성능 결과, 조정, Kafka 커넥터 및 자체 재조정 기능을 포함하여 NetApp 스토리지에서 Kafka를 사용하는 모범 사례 지침을 제공합니다.</block>
  <block id="0c7a4422707cf3f11c73c66ea0d5d215" category="inline-link-macro">이전: 사이징.</block>
  <block id="f902aefc255b4eb6b31c283ad42816de" category="paragraph"><block ref="f902aefc255b4eb6b31c283ad42816de" category="inline-link-macro-rx"></block></block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">이 문서에서는 검증 테스트, 계층형 스토리지 성능 결과, 튜닝, Confluent S3 커넥터 및 셀프 밸런싱 기능을 포함하여 NetApp 스토리지와 함께 Contuent Tiered Storage를 사용하기 위한 모범 사례 지침을 제공합니다. ILM 정책, 검증을 위한 다양한 성능 테스트 및 산업 표준 S3 API를 통한 유창한 성능을 고려할 때 NetApp StorageGRID 오브젝트 스토리지는 유창한 계층형 스토리지를 위한 최적의 선택입니다.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">아파치 카프카란</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3 싱크 매개 변수 세부 정보</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Confluent 플랫폼의 무한 스토리지</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">ContFluent Tiered Storage - 모범 사례 및 사이징</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Confluent 플랫폼용 Amazon S3 싱크 커넥터</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Kafka 사이징</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRID 사이징</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Kafka 활용 사례</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">confluent platform 6.0의 자체 균형 조정 Kafka 클러스터</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="a5091aedd97daf7c5a5297fa5d73a469" category="cell">2021년 12월</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">이 사용 사례에서 고객은 DevTest와 보고 목적으로 동일한 데이터 센터와 원격 위치에서 대량의 분석 데이터를 포함하는 기존 Hadoop 클러스터를 기반으로 새로운 Hadoop/Spark 클러스터를 신속하고 효율적으로 구축해야 합니다.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">사용 사례 3: 기존 Hadoop 데이터에 대해 DevTest 활성화</block>
  <block id="aeab228f25b5fbe0b00f83117579246e" category="inline-link-macro">이전: 사용 사례 2 - 클라우드에서 사내로 백업 및 재해 복구</block>
  <block id="cf44ed74ea7e07a8e4478e43d9537e07" category="paragraph"><block ref="cf44ed74ea7e07a8e4478e43d9537e07" category="inline-link-macro-rx"></block></block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">이 시나리오에서는 사내 및 재해 복구 위치에 대규모 Hadoop 데이터 레이크를 구축하고 Spark/Hadoop 클러스터를 여러 개 구축했습니다.</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">DevTest, QA 또는 동일한 운영 데이터에 액세스해야 하는 기타 목적으로 여러 Hadoop 클러스터를 생성합니다. 여기서 문제는 매우 큰 Hadoop 클러스터를 공간 효율적인 방식으로 여러 번 즉시 클론 복제해야 한다는 것입니다.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">운영 효율성을 위해 Hadoop 데이터를 DevTest 및 보고 팀에 동기화합니다.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">운영 클러스터와 새 클러스터 간에 동일한 자격 증명을 사용하여 Hadoop 데이터를 배포합니다.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">예약된 정책을 사용하여 운영 클러스터에 영향을 주지 않고 QA 클러스터를 효율적으로 생성합니다.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">FlexClone 기술은 방금 설명한 요구 사항에 응답하는 데 사용됩니다. FlexClone 기술은 스냅샷 복사본의 읽기/쓰기 복사본입니다. 이 기능은 상위 스냅샷 복사본 데이터에서 데이터를 읽고 새 블록/수정된 블록에 대해 추가 공간만 사용합니다. 빠르고 공간 효율적입니다.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">먼저, NetApp 일관성 그룹을 사용하여 기존 클러스터의 스냅샷 복사본을 생성했습니다.</block>
  <block id="4b481b20e942087b64c5bb7b07d9dca9" category="paragraph">NetApp System Manager 또는 스토리지 관리 프롬프트 내의 Snapshot 복사본 일관성 그룹 스냅샷 복사본은 애플리케이션 정합성이 보장된 그룹 스냅샷 복사본이며, FlexClone 볼륨은 일관성 그룹 스냅샷 복사본을 기반으로 생성됩니다. FlexClone 볼륨이 상위 볼륨의 NFS 엑스포트 정책을 상속한다는 점을 언급하는 것이 좋습니다. 스냅샷 복사본이 생성된 후에는 아래 그림과 같이 DevTest 및 보고를 위해 새 Hadoop 클러스터를 설치해야 합니다. In-Place Analytics Module은 NFS 데이터에 대한 In-Place Analytics Module 사용자 및 그룹 인증을 통해 새 Hadoop 클러스터에서 클론 생성된 NFS 볼륨에 액세스합니다.</block>
  <block id="4c490dfedbcc5a021b8a4c823e337d41" category="paragraph">적절한 액세스 권한을 가지려면 새 클러스터에 현재 위치 분석 모듈 사용자 및 그룹 구성에서 구성된 사용자에 대해 동일한 UID와 GUID가 있어야 합니다.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">이 이미지는 DevTest용 Hadoop 클러스터를 보여 줍니다.</block>
  <block id="4157075925c8c1518cc71d1d0abab403" category="paragraph"><block ref="4157075925c8c1518cc71d1d0abab403" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e10ad11fd299ee6f161f17d772a78a48" category="inline-link-macro">다음: 사용 사례 4 - 데이터 보호 및 멀티 클라우드 연결</block>
  <block id="8109e574f349ced8f667b9389c9189a4" category="paragraph"><block ref="8109e574f349ced8f667b9389c9189a4" category="inline-link-macro-rx"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">이 테스트는 클러스터 토폴로지 변경 또는 불균등한 로드를 기반으로 재조정을 자동화하는 셀프 밸런싱 클러스터 기능을 기반으로 합니다.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Confluent Self-Balancing 클러스터</block>
  <block id="6dec1258fbcccbfaa7098758abb00055" category="inline-link-macro">이전: Kafka S3 커넥터.</block>
  <block id="6e3bea5fe8473b6e884edafaf7fcf1d4" category="paragraph"><block ref="6e3bea5fe8473b6e884edafaf7fcf1d4" category="inline-link-macro-rx"></block></block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">이전에 Kafka 클러스터를 관리했다면 수동으로 파티션을 다른 브로커에 재할당하여 클러스터 전체에서 워크로드가 균형 있게 조정되도록 하는 데 따르는 문제에 익숙할 것입니다. Kafka가 대규모로 구축된 조직의 경우 대량의 데이터를 개각하는 일은 까다롭고 번거로우며 위험할 수 있습니다. 특히 클러스터 위에 미션 크리티컬 애플리케이션을 구축하는 경우에는 더욱 그렇습니다. 그러나 가장 작은 Kafka 사용 사례에서도 이 프로세스는 시간이 많이 걸리며 오류가 발생하기 쉽습니다.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">이 실습에서는 Confluent Self-Balancing 클러스터 기능을 테스트하여 클러스터 토폴로지 변경 또는 불균등한 로드를 기반으로 재조정을 자동화했습니다. Confluent rebalance 테스트는 노드 장애 또는 확장 노드에서 브로커 간의 데이터 재조정이 필요한 경우 새 브로커를 추가하는 시간을 측정하는 데 도움이 됩니다. 기존 Kafka 구성에서는 클러스터의 증가에 따라 재조정할 데이터의 양이 증가하지만 계층형 스토리지에서는 소량의 데이터로 제한됩니다. NetApp의 검증을 바탕으로, 계층화된 스토리지에서 재조정은 기존 Kafka 아키텍처에서 몇 초 또는 몇 분 만에 이루어지게 되며, 클러스터의 확장에 따라 선형으로 증가합니다.</block>
  <block id="c9e4cfc44588cc591252c88cad0a3a09" category="paragraph">자체 밸런싱 클러스터에서는 파티션 재조정이 완전히 자동화되어 Kafka의 처리량을 최적화하고 브로커 확장을 가속화하며 대규모 클러스터를 실행하는 데 따른 운영 부담을 줄일 수 있습니다. 안정적인 상태에서 자체 균형 조정 클러스터는 브로커 전체의 데이터 불균형을 모니터링하고 지속적으로 파티션을 재할당하여 클러스터 성능을 최적화합니다. 플랫폼을 확장하거나 축소할 때 자체 균형 조정 클러스터는 새로운 브로커의 존재 또는 이전 브로커의 제거를 자동으로 인식하고 후속 파티션 재할당을 트리거합니다. 이를 통해 브로커를 쉽게 추가하고 해체할 수 있으므로 Kafka 클러스터의 유연성이 근본적으로 높아집니다. 이러한 이점은 수동 개입, 복잡한 수학 또는 재할당을 분할하는 데 수반되는 인적 오류의 위험 없이 제공됩니다. 따라서 데이터 재조정이 훨씬 더 빠르게 완료되고, 클러스터를 지속적으로 감독해야 하는 대신 더 가치 있는 이벤트 스트리밍 프로젝트에 집중할 수 있습니다.</block>
  <block id="cc87abc70119e2ad833c42a865a33659" category="inline-link-macro">다음은 모범 사례 지침입니다.</block>
  <block id="caf8da5a9482899a1495e1e052a4b287" category="paragraph"><block ref="caf8da5a9482899a1495e1e052a4b287" category="inline-link-macro-rx"></block></block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp는 대규모 클러스터 간 및 클러스터 간 복제에 사용되는 기본 툴입니다. Hadoop DistCp 기본 프로세스는 MapReduce와 같은 Hadoop 네이티브 툴을 사용하여 Hadoop 데이터를 HDFS 소스에서 해당 타겟으로 복제하는 일반적인 백업 워크플로우입니다.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoop 데이터 보호 및 NetApp</block>
  <block id="9445444fbd9e863564ea85ad226c0e80" category="inline-link-macro">이전: NetApp의 빅데이터 아키텍처 기반 Data Fabric</block>
  <block id="e30c587da81860e05b3f8ecfb5b9965b" category="paragraph"><block ref="e30c587da81860e05b3f8ecfb5b9965b" category="inline-link-macro-rx"></block></block>
  <block id="5f45c95989226891db648114a547a6bd" category="paragraph">Hadoop DistCp는 대규모 클러스터 간 및 클러스터 간 복제에 사용되는 기본 툴입니다. 아래 그림에 표시된 Hadoop DistCp 기본 프로세스는 MapReduce와 같은 Hadoop 기본 툴을 사용하여 HDFS 소스에서 해당 타겟으로 Hadoop 데이터를 복제하는 일반적인 백업 워크플로우입니다. NetApp NFS 직접 액세스를 통해 고객은 NFS를 Hadoop DistCp 툴의 타겟 타겟으로 설정하여 MapReduce를 통해 HDFS 소스에서 NFS 공유로 데이터를 복사할 수 있습니다. NetApp NFS 직접 액세스는 DistCp 툴을 위한 NFS 드라이버 역할을 합니다.</block>
  <block id="6369c8cb38b142174d2f84d12d2f0420" category="paragraph"><block ref="6369c8cb38b142174d2f84d12d2f0420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4849340a20db94ed712aca71c30b915" category="inline-link-macro">다음: Hadoop 데이터 보호 활용 사례 개요</block>
  <block id="817c6593a9a8efc031ec597b5d11d605" category="paragraph"><block ref="817c6593a9a8efc031ec597b5d11d605" category="inline-link-macro-rx"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">이 섹션에서는 Confluent 인증에 사용되는 하드웨어 및 소프트웨어에 대해 다룹니다. 이 정보는 NetApp 스토리지를 사용하는 Kafka 구축에 적용할 수 있습니다.</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">사이징</block>
  <block id="5ffdfbbb428796f516e072e038d107b0" category="inline-link-macro">이전: 모범 사례 지침.</block>
  <block id="49575973ec85e64724d2a45d401f32b3" category="paragraph"><block ref="49575973ec85e64724d2a45d401f32b3" category="inline-link-macro-rx"></block></block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Kafka 사이징은 단순, 세분화, 역방향 및 파티션의 4가지 구성 모드로 수행할 수 있습니다.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">단순함</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">단순 모드는 최초 Apache Kafka 사용자 또는 초기 상태 사용 사례에 적합합니다. 이 모드에서는 처리량 MBps, 읽기 팬아웃, 보존 및 리소스 사용률(기본값 60%)과 같은 요구 사항을 제공합니다. 또한 온프레미스(베어 메탈, VMware, Kubernetes 또는 OpenStack) 또는 클라우드와 같은 환경에 진입할 수 있습니다. 이 정보를 바탕으로 Kafka 클러스터의 크기를 조정하면 브로커, zookeeper, Apache Kafka 연결 작업자, 스키마 레지스트리, REST 프록시, ksqlDB 및 Confluorent 제어 센터에 필요한 서버 수가 제공됩니다.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">계층형 스토리지의 경우 Kafka 클러스터의 크기를 조정할 수 있는 세분화된 구성 모드를 고려해 보십시오. 세밀한 모드는 숙련된 Apache Kafka 사용자나 잘 정의된 사용 사례에 적합합니다. 이 섹션에서는 생산자, 스트림 프로세서 및 소비자를 위한 크기를 조정하는 방법에 대해 설명합니다.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">프로듀서</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Apache Kafka의 생산자(예: 네이티브 클라이언트, REST 프록시 또는 Kafka 커넥터)를 설명하기 위해 다음 정보를 제공합니다.</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">* 이름. * Spark.</block>
  <block id="0ae6d6b48753e01bf1ae73bb86ee6276" category="list-text">* Producer type. * 응용 프로그램 또는 서비스, 프록시(RDBMS, MQTT, 기타) 및 기존 데이터베이스(RDBMS, NoSQL, 기타). "모름"을 선택할 수도 있습니다.</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">* 초당 이벤트 수 평균 처리량 * (예: 1,000,000).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">* 최대 처리량 * 초당 이벤트 수(예: 4,000,000).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">* 평균 메시지 크기. * (바이트), 압축되지 않음(예: 최대 1MB, 1000).</block>
  <block id="dd6d45bc2ad71619bde2260f1776e9b2" category="list-text">* 메시지 형식. * 옵션은 Avro, JSON, 프로토콜 버퍼, 바이너리, 텍스트, “잘 모르겠군요.” 및 기타.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">* 복제 계수. * 옵션은 1, 2, 3(Confluent recommendation), 4, 5, 또는 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">* 보존 시간. * 1일(예:) 데이터를 Apache Kafka에 얼마나 오랫동안 저장하기를 원하십니까? 무한 시간 동안 임의의 단위로 -1을 입력합니다. 이 계산기는 보존 기간이 10년으로 무한 경우를 가정합니다.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">"Enable Tiered Storage to Decrease Broker Count and Allow for Infinite Storage?" 확인란을 선택합니다.</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">계층형 스토리지를 사용하는 경우 보존 필드는 브로커에 로컬로 저장된 데이터의 핫 세트를 제어합니다. 아카이브 보존 필드는 아카이브 오브젝트 스토리지에 데이터가 저장되는 기간을 제어합니다.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">* 아카이브 스토리지 보존. * 1년(예:) 아카이브 스토리지에 데이터를 얼마나 오랫동안 저장하려는 경우 무한 기간 동안 임의의 단위로 -1을 입력합니다. 이 계산기는 무한 보존을 위해 10년을 유지하는 것으로 가정합니다.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">* Growth Multiplier. * 1(예:) 이 매개 변수의 값이 현재 처리량을 기반으로 하는 경우 1로 설정합니다. 추가 성장에 따라 크기를 조정하려면 이 매개 변수를 성장 배수로 설정합니다.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">* 생산자 인스턴스 수. * 10(예:) 얼마나 많은 프로듀서 인스턴스가 실행됩니까? 이 입력은 CPU 부하를 사이징 계산에 통합하기 위해 필요합니다. 빈 값은 CPU 로드가 계산에 포함되지 않았음을 나타냅니다.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">이 예제 입력에 따라 크기를 조정하면 생산자에 다음과 같은 영향을 줍니다.</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">압축되지 않은 바이트의 평균 처리량: 1Gbps. 압축되지 않은 바이트 단위의 최대 처리량: 4Gbps. 압축된 바이트의 평균 처리량: 400Mbps 압축된 바이트 단위의 최대 처리량: 1.6GBps. 이 값은 기본 60% 압축률을 기반으로 합니다(이 값은 변경할 수 있음).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">필요한 총 온브로커 핫 세트 스토리지 수: 31,104TB(복제 포함), 압축. 총 비브로커 아카이브 스토리지 필요: 378,432TB, 압축. 사용 <block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> StorageGRID 사이징:</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">스트림 프로세서는 아파치 Kafka로부터 데이터를 소비하고 아파치 Kafka로 다시 생산하는 애플리케이션 또는 서비스를 설명해야 합니다. 대부분의 경우 ksqlDB 또는 Kafka 스트림에 빌드됩니다.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">* 이름. * Spark streamer.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">* 처리 시간. * 이 프로세서는 단일 메시지를 처리하는 데 얼마나 걸립니까?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1ms(단순한 상태 비저장 변환) [예], 10ms(Stateful 인메모리 작업).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100ms(stateful 네트워크 또는 디스크 작동), 1000ms(타사 REST 호출)</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">이 매개 변수를 벤치마킹하고 시간이 얼마나 걸리는지 정확히 알고 있습니다.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">* 출력 보존. * 1일(예) 스트림 프로세서는 Apache Kafka로 출력을 다시 생성합니다. 이 출력 데이터를 Apache Kafka에 얼마나 오랫동안 저장하기를 원하십니까? 무한 기간 동안 임의의 단위로 -1을 입력합니다.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">"계층 스토리지를 사용하여 브로커 수를 줄이고 무한 확장 스토리지를 허용하시겠습니까?" 확인란을 선택합니다.</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">* 아카이브 스토리지 보존. * 1년(예:) 아카이브 스토리지에 데이터를 얼마나 오랫동안 저장하려는 경우 무한 기간 동안 임의의 단위로 -1을 입력합니다. 이 계산기는 무한 보존을 위해 10년을 유지하는 것으로 가정합니다.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">* 출력 통과 백분율. * 100(예:) 스트림 프로세서는 Apache Kafka로 출력을 다시 생성합니다. Apache Kafka로 다시 출력되는 인바운드 처리량의 비율은 얼마입니까? 예를 들어, 인바운드 처리량이 20Mbps이고 이 값이 10이면 출력 처리량은 2Mbps입니다.</block>
  <block id="d1a6a4732f959b58cd8c77edcf10b31b" category="list-text">어떤 응용 프로그램에서 이 정보를 읽습니까? 프로듀서 유형 기반 사이징에 사용되는 이름인 “Spark”를 선택합니다. 위의 입력을 기반으로 스트림 프로세스 인스턴스 및 주제 파티션 예상에 대한 사이징의 영향을 예상할 수 있습니다.</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">이 스트림 프로세서 응용 프로그램에는 다음과 같은 수의 인스턴스가 필요합니다. 들어오는 항목에는 이러한 많은 파티션이 필요할 수 있습니다. 이 매개 변수를 확인하려면 Confluent에 문의하십시오.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">성장 승수가 없는 평균 처리량에 대해 1,000개</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">최대 처리량에 대해 4,000(성장 승수 없음)</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">성장 승수가 포함된 평균 처리량의 경우 1,000개</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">최대 처리량에 대해 4,000(성장 승수 포함)</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">소비자</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Apache Kafka의 데이터를 사용하고 Apache Kafka로 다시 생성하지 않는 애플리케이션 또는 서비스(예: 네이티브 클라이언트 또는 Kafka Connector)에 대해 설명하십시오.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">* 이름. * Spark 소비자.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">* 처리 시간. * 이 소비자는 단일 메시지를 처리하는 데 얼마나 걸립니까?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1ms(예: 로깅 같은 간단하고 상태 비저장 작업)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10ms(데이터 저장소에 대한 빠른 쓰기)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100ms(데이터 저장소에 대한 느린 쓰기)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000ms(타사 휴면 통화)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">알려진 기간의 다른 벤치마크 프로세스</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">* 소비자 유형. * 기존 데이터 저장소(RDBMS, NoSQL, 기타)에 대한 애플리케이션, 프록시 또는 싱크</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">어떤 응용 프로그램에서 이 정보를 읽습니까? 이 매개 변수를 이전에 결정된 생산자 및 스트림 사이징에 연결합니다.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">위의 입력 내용에 따라 소비자 인스턴스 및 주제 파티션 추정치에 대한 사이징을 결정해야 합니다. 소비자 응용 프로그램에는 다음과 같은 수의 인스턴스가 필요합니다.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">평균 처리량에 대해 2,000개, 성장 승수 없음</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">최대 처리량에 대해 8,000개, 성장 승수 없음</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">성장 승수를 포함한 평균 처리량에 대해 2,000개</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">성장 승수를 포함한 최대 처리량에 대해 8,000개</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">들어오는 주제에는 이 수의 파티션도 필요할 것입니다. 확인하려면 Confluent에 문의하십시오.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">생산자, 스트림 프로세서 및 소비자에 대한 요구 사항 외에도 다음과 같은 추가 요구 사항을 제공해야 합니다.</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">* 재생성 시간. * 예: 4시간. Apache Kafka 브로커 호스트에 장애가 발생하고 데이터가 손실되며 장애가 발생한 호스트를 대체하기 위해 새 호스트를 프로비저닝하는 경우 이 새 호스트 재구축 속도는 얼마나 빨라야 합니까? 값을 알 수 없는 경우 이 매개 변수를 비워 둡니다.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">* 리소스 활용률 목표(백분율) * 예: 60. 평균 처리량 중에 호스트를 얼마나 활용하기를 원하십니까? Confluent는 Confluent 셀프 밸런싱 클러스터를 사용하고 있지 않는 한 60%의 사용률을 권장합니다. 이 경우 활용률이 더 높을 수 있습니다.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">환경에 대해 설명하십시오</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">* 클러스터가 어떤 환경에서 실행됩니까? * Amazon Web Services, Microsoft Azure, Google 클라우드 플랫폼, 베어 메탈 온프레미스, VMware 온프레미스, 사내에 OpenStack 또는 온프레미스에 Kubernates가 있습니까?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">* 호스트 세부 정보. * 코어 수: 48(예:), 네트워크 카드 유형(10GbE, 40GbE, 16GbE, 1GbE 또는 다른 유형).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">* 스토리지 볼륨. * 호스트: 12(예:) 호스트당 지원되는 하드 드라이브 또는 SSD 수는 몇 개입니까? Confluent는 호스트당 12개의 하드 드라이브를 권장합니다.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">* 스토리지 용량/볼륨(GB). * 1000(예:) 단일 볼륨에서 몇 기가바이트의 스토리지를 저장할 수 있습니까? Confluent에서는 1TB 디스크를 권장합니다.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">* 스토리지 구성. * 스토리지 볼륨은 어떻게 구성됩니까? Confluent는 Raid10에서 모든 Confluent 기능을 이용할 것을 권장합니다. JBOD, SAN, RAID 1, RAID 0, RAID 5, 및 기타 유형도 지원됩니다.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">* 단일 볼륨 처리량(Mbps). * 125(예:) 단일 스토리지 볼륨이 초당 메가바이트 단위로 읽거나 쓸 수 있는 속도는 얼마나 됩니까? Confluent는 일반적으로 125MBps 처리량의 표준 하드 드라이브를 권장합니다.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">* 메모리 용량(GB). * 64(예:)</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">환경 변수를 결정한 후 클러스터 크기를 선택합니다. 위에 표시된 예시 매개 변수를 토대로 Confluent Kafka에 대한 다음 사이징을 결정했습니다.</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">* 아파치 Kafka. * 브로커 수: 22. 클러스터가 스토리지에 바인딩되어 있습니다. 호스트 수를 줄이고 무한 스토리지를 허용하도록 계층형 스토리지를 설정하는 것이 좋습니다.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">* Apache ZooKeeper. * Count:5; Apache Kafka Connect 작업자: Count:2; Schema Registry: Count:2; REST Proxy: Count:2; ksqlDB:Count:2; Confluorent Control Center: Count:1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">사용 사례를 염두에 두고 플랫폼 팀에 리버스 모드를 사용합니다. 파티션 모드를 사용하여 단일 항목에 필요한 파티션 수를 계산합니다. 을 참조하십시오<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> 역 및 파티션 모드에 따른 크기 조정.</block>
  <block id="4127d3e6d7b548701a1cf83ef1d7a922" category="paragraph"><block ref="4127d3e6d7b548701a1cf83ef1d7a922" category="inline-link-macro-rx"></block></block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">이 섹션에서는 이 인증에서 얻은 교훈을 설명합니다.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">모범 사례 지침</block>
  <block id="524a5aa4f422c84af378b5418bb1539b" category="inline-link-macro">이전: Confluent 자체 재조정 클러스터</block>
  <block id="ae7f441436d5c9a5dc4278e4ea2b87e8" category="paragraph"><block ref="ae7f441436d5c9a5dc4278e4ea2b87e8" category="inline-link-macro-rx"></block></block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">NetApp의 검증을 기반으로 S3 오브젝트 스토리지는 데이터를 유창하게 유지하는 데 가장 적합합니다.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">처리량이 높은 SAN(특히 FC)을 사용하여 브로커의 핫 데이터 또는 로컬 디스크를 유지할 수 있습니다. 왜냐하면, ContFluent 계층형 스토리지 구성에서 브로커 데이터 디렉토리에 있는 데이터의 크기는 데이터가 오브젝트 스토리지로 이동되는 세그먼트 크기 및 보존 시간을 기준으로 합니다.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">오브젝트 저장소는 세그먼트일 때 더 나은 성능을 제공합니다. 바이트 수는 더 높고 512MB를 테스트했습니다.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">Kafka에서는 해당 주제에 대해 생성된 각 레코드에 대한 키 또는 값(바이트)의 길이가 length.key.value 매개 변수에 의해 제어됩니다. StorageGRID의 경우 S3 오브젝트 수집 및 검색 성능이 더 높은 값으로 향상되었습니다. 예를 들어, 512바이트는 5.8GBps 검색, 1024바이트는 7.5GBps S3 검색, 2048바이트는 10Gbps 가까이 제공</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">다음 그림은 length.key.value를 기준으로 S3 오브젝트 수집 및 조회 결과를 나타낸 것이다.</block>
  <block id="b50ee24368ac624f2816b9e550167cb9" category="paragraph"><block ref="b50ee24368ac624f2816b9e550167cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">* Kafka 튜닝. * 계층형 스토리지의 성능을 향상시키려면 TierFetcherNumThreads 및 TierArchivernumThreads를 늘릴 수 있습니다. 일반적으로 TierFetchernumThreads를 물리적 CPU 코어 수와 일치하도록 늘리고 TierArchivernumThreads를 CPU 코어 수의 절반으로 늘리고자 합니다. 예를 들어, 서버 속성에서 8개의 물리적 코어가 있는 컴퓨터를 사용하는 경우 confluent.tier.fetcher.num.threads=8 및 confluent.tier.Archiver.num.threads=4를 설정합니다.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">* 항목 삭제에 대한 시간 간격 * 주제가 삭제되면 객체 저장소에서 로그 세그먼트 파일 삭제가 즉시 시작되지 않습니다. 대신 이 파일을 삭제하기 전에 기본값이 3시간인 시간 간격이 있습니다. confluent.tier.topic.delete.check.interval.ms 구성을 수정하여 이 간격의 값을 변경할 수 있습니다. 주제 또는 클러스터를 삭제하는 경우 해당 버킷의 오브젝트도 수동으로 삭제할 수 있습니다.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">* 계층형 스토리지 내부 항목에 대한 ACL. * 온-프레미스 배포의 권장 모범 사례는 계층형 스토리지에 사용되는 내부 항목에 대해 ACL 허가자를 활성화하는 것입니다. 이 데이터에 대한 액세스를 브로커 사용자에게만 제한하려면 ACL 규칙을 설정합니다. 이렇게 하면 내부 항목이 안전하게 보호되며 계층형 스토리지 데이터 및 메타데이터에 대한 무단 액세스가 방지됩니다.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">사용자 '&lt;Kafka&gt;'를 배포의 실제 브로커 교장으로 바꿉니다.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">예를 들어, "confluent-tier-state" 명령은 계층형 스토리지의 내부 항목에 대한 ACL을 설정합니다. 현재 계층형 스토리지와 관련된 내부 주제는 하나뿐입니다. 이 예제에서는 내부 항목의 모든 작업에 대해 Kafka의 주요 권한을 제공하는 ACL을 만듭니다.</block>
  <block id="c7aa1f1ea2c8ad1712056dd97321d808" category="inline-link-macro">다음: 사이징.</block>
  <block id="de8a38c4c90ce81d8c4b82c44500e504" category="paragraph"><block ref="de8a38c4c90ce81d8c4b82c44500e504" category="inline-link-macro-rx"></block></block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">NetApp이 제공하는 Data Fabric은 클라우드 및 사내 환경에서 데이터 관리를 단순화하고 통합하여 디지털 전환을 가속합니다. NetApp이 제공하는 Data Fabric은 데이터 가시성 및 통찰력, 데이터 액세스 및 제어, 데이터 보호 및 보안을 위해 일관되고 통합된 데이터 관리 서비스 및 애플리케이션(구성 요소)을 제공합니다.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">NetApp에서 제공하는 빅데이터 아키텍처 관련 Data Fabric</block>
  <block id="32e0d2b797e6706a73e8146d103572c7" category="inline-link-macro">이전: 솔루션 개요</block>
  <block id="45af7a946606481f9e2b5f0434aa0484" category="paragraph"><block ref="45af7a946606481f9e2b5f0434aa0484" category="inline-link-macro-rx"></block></block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">NetApp이 제공하는 Data Fabric은 클라우드 및 사내 환경에서 데이터 관리를 단순화하고 통합하여 디지털 전환을 가속합니다.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">NetApp이 제공하는 Data Fabric은 데이터 가시성과 통찰력, 데이터 액세스 및 제어, 데이터 보호 및 보안을 위한 일관성 있는 통합 데이터 관리 서비스 및 애플리케이션(구성 요소)을 제공합니다(아래 그림 참조).</block>
  <block id="22313f8779f9135c9b421ac0d4b320fb" category="paragraph"><block ref="22313f8779f9135c9b421ac0d4b320fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">검증된 Data Fabric 고객 사용 사례</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">NetApp이 제공하는 Data Fabric은 고객에게 다음과 같은 9가지 검증된 사용 사례를 제공합니다.</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">분석 워크로드 가속화</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">DevOps 혁신 가속</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">클라우드 호스팅 인프라 구축</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">클라우드 데이터 서비스 통합</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">데이터 보호 및 보안</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">비정형데이터의 최적화</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">데이터 센터의 효율성 확보</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">데이터 통찰력 및 제어 제공</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">단순화 및 자동화</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">본 문서는 9가지 사용 사례 중 2가지(솔루션 포함)를 다룹니다.</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">NetApp NFS 직접 액세스</block>
  <block id="233060aa11b5715000c000e94576cca9" category="paragraph">아래 그림에 표시된 NetApp NFS 직접 액세스(이전의 NetApp In-Place Analytics Module)를 사용하면 데이터를 이동하거나 복사하지 않고도 기존 또는 새로운 NFSv3 또는 NFSv4 데이터에 대해 빅데이터 분석 작업을 실행할 수 있습니다. 여러 데이터 복제본을 방지하고 소스와 데이터를 동기화할 필요가 없습니다. 예를 들어 금융 부문에서 데이터를 한 위치에서 다른 위치로 이동하는 것은 쉬운 일이 아닌 법적 의무를 준수해야 합니다. 이 시나리오에서는 NetApp NFS 직접 액세스가 원래의 위치에서 재무 데이터를 분석합니다. 또 다른 주요 이점은 NetApp NFS 직접 액세스를 사용하여 기본 Hadoop 명령을 사용하여 Hadoop 데이터를 간편하게 보호하고 NetApp의 강력한 데이터 관리 포트폴리오를 활용하여 데이터 보호 워크플로우를 활성화할 수 있다는 것입니다.</block>
  <block id="96e1e6bac181280c42ba5de56a8ef4c2" category="paragraph"><block ref="96e1e6bac181280c42ba5de56a8ef4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">NetApp NFS 직접 액세스에서는 Hadoop/Spark 클러스터에 다음과 같은 두 가지 유형의 구축 옵션을 제공합니다.</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">기본적으로 Hadoop/Spark 클러스터는 데이터 스토리지와 기본 파일 시스템에 HDFS(Hadoop Distributed File System)를 사용합니다. NetApp NFS 직접 액세스는 기본 HDFS를 NFS 스토리지로 대체하여 NFS 데이터에 대한 직접 분석 작업을 지원합니다.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">다른 구축 옵션에서 NetApp NFS 직접 액세스는 NFS를 단일 Hadoop/Spark 클러스터의 HDFS와 함께 추가 스토리지로 구성할 수 있도록 지원합니다. 이 경우 고객은 NFS 내보내기를 통해 데이터를 공유하고 HDFS 데이터와 함께 동일한 클러스터에서 데이터를 액세스할 수 있습니다.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">NetApp NFS 직접 액세스를 사용할 때의 주요 이점은 다음과 같습니다.</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">현재 위치의 데이터를 분석하여 분석 데이터를 HDFS와 같은 Hadoop 인프라스트럭처로 이동하는 데 시간과 성능이 많이 소모되는 작업을 방지합니다.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">복제본 수를 3개부터 1개로 줄입니다.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">사용자가 컴퓨팅 및 스토리지를 분리하여 독립적으로 확장할 수 있습니다.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">ONTAP의 강력한 데이터 관리 기능을 활용하여 엔터프라이즈 데이터 보호 기능을 제공합니다.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Hortonworks 데이터 플랫폼에서 인증되었습니다.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">하이브리드 데이터 분석을 구축할 수 있습니다.</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">동적 다중 스레드 기능을 활용하여 백업 시간을 단축합니다.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">빅 데이터를 위한 구성 요소</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">NetApp 기반의 Data Fabric은 아래 그림과 같이 데이터 액세스, 제어, 보호 및 보안을 위한 데이터 관리 서비스와 애플리케이션(구성 요소)을 통합합니다.</block>
  <block id="f0a67f0f8f389fb239ce107f693a7e68" category="paragraph"><block ref="f0a67f0f8f389fb239ce107f693a7e68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">위 그림의 구성 요소는 다음과 같습니다.</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* NetApp NFS 직접 액세스 * 는 추가 소프트웨어 또는 드라이버 요구사항 없이 최신 Hadoop 및 Spark 클러스터를 NetApp NFS 볼륨에 직접 액세스할 수 있도록 지원합니다.</block>
  <block id="2867a490011894512662b9423698d0e0" category="list-text">* NetApp Cloud Volumes ONTAP 및 클라우드 볼륨 서비스. * Microsoft Azure 클라우드 서비스의 AWS(Amazon Web Services) 또는 ANF(Azure NetApp Files)에서 실행되는 ONTAP를 기반으로 하는 소프트웨어 정의 연결형 스토리지.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">NetApp SnapMirror 기술 *. 사내 및 ONTAP 클라우드 또는 NPS 인스턴스 간에 데이터 보호 기능을 제공합니다.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">* 클라우드 서비스 공급자 * 이러한 공급자에는 AWS, Microsoft Azure, Google Cloud 및 IBM Cloud가 포함됩니다.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">* PaaS. * AWS의 EMR(Amazon Elastic MapReduce) 및 Databricks와 같은 클라우드 기반 분석 서비스와 Microsoft Azure HDInsight 및 Azure Databricks</block>
  <block id="35848dde21e4a5f344385ead6dec9a43" category="inline-link-macro">이제 Hadoop 데이터 보호와 NetApp이 모두 필요합니다.</block>
  <block id="149584f581a09d835c88f233c514412e" category="paragraph"><block ref="149584f581a09d835c88f233c514412e" category="inline-link-macro-rx"></block></block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">솔루션 아키텍처 세부 정보</block>
  <block id="40328f8a932f8ae1964c73c1f2eca76b" category="paragraph"><block ref="40328f8a932f8ae1964c73c1f2eca76b" category="inline-link-macro-rx"></block></block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">이 섹션에서는 Confluent 검증에 사용된 하드웨어 및 소프트웨어에 대해 다룹니다. 이 정보는 NetApp 스토리지를 사용하는 Confluent Platform 구축에 적용할 수 있습니다. 다음 표에서는 테스트를 거친 솔루션 아키텍처 및 기본 구성 요소에 대해 설명합니다.</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka 버전 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">세 명의 주키퍼입니다</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">브로커 서버 5대</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">5개의 도구 서버</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">하나의 Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">제어 센터 1개</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux(Ubuntu 18.04)</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">모든 서버</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">계층형 스토리지를 위한 NetApp StorageGRID</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRID 소프트웨어</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">SG1000(로드 밸런서) 1개</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">SGF6024 4개</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">24 x 800 SSD 4개</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3 프로토콜</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100GbE(브로커와 StorageGRID 인스턴스 간 네트워크 연결)</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 Fujitsu Primergy RX2540 서버</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">각 장착 사양: * CPU 2개, 물리적 코어 16개 * Intel Xeon * 256GB 물리적 메모리 * 100GbE 듀얼 포트</block>
  <block id="c88aa001e26103d0ebe4894b3c9ab9f5" category="paragraph"><block ref="c88aa001e26103d0ebe4894b3c9ab9f5" category="inline-link-macro-rx"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">이 사용 사례는 고객의 빅데이터 분석 데이터를 위한 멀티 클라우드 연결을 제공하는 클라우드 서비스 파트너와 관련이 있습니다.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">사용 사례 4: 데이터 보호 및 멀티 클라우드 연결</block>
  <block id="2c8eccdfa6390b1d09b2527f7d7d2cc5" category="inline-link-macro">이전: 사용 사례 3 - 기존 Hadoop 데이터에 대해 DevTest 설정</block>
  <block id="fda5cc5b496f5f7aa6de18740227bc15" category="paragraph"><block ref="fda5cc5b496f5f7aa6de18740227bc15" category="inline-link-macro-rx"></block></block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">이 시나리오에서는 여러 소스에서 AWS로 수신된 IoT 데이터가 NPS의 중앙 위치에 저장됩니다. NPS 스토리지는 AWS 및 Azure에 위치한 Spark/Hadoop 클러스터에 연결되므로, 여러 클라우드에서 실행되는 빅데이터 분석 애플리케이션이 동일한 데이터에 액세스할 수 있습니다.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">고객은 여러 클라우드를 사용하여 동일한 데이터에 대한 분석 작업을 실행하려고 합니다.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">다양한 센서와 허브를 통해 사내, 클라우드와 같은 다양한 소스로부터 데이터를 받아야 합니다.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">솔루션은 효율적이고 비용 효율적이어야 합니다.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">주요 과제는 사내 및 다른 클라우드 간에 하이브리드 분석 서비스를 제공하는 비용 효율적이고 효율적인 솔루션을 구축하는 것입니다.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">이 이미지는 데이터 보호 및 멀티 클라우드 연결 솔루션을 보여줍니다.</block>
  <block id="faaf8e6278dc7a68fd1dd98dfe7f525a" category="paragraph"><block ref="faaf8e6278dc7a68fd1dd98dfe7f525a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14c23633f1ab374f4c801386847ba2f8" category="paragraph">위 그림과 같이 센서의 데이터가 스트리밍되어 Kafka를 통해 AWS Spark 클러스터로 수집됩니다. 이 데이터는 Equinix 데이터 센터 내의 클라우드 공급자 외부에 있는 NPS에 있는 NFS 공유에 저장됩니다. NetApp NPS는 Direct Connect와 Express Route 연결을 통해 Amazon AWS 및 Microsoft Azure에 연결되므로, 고객은 데이터 이동 없는 분석 모듈을 활용하여 Amazon 및 AWS 분석 클러스터 모두에서 데이터에 액세스할 수 있습니다. 이 접근 방식은 여러 하이퍼 스케일러의 클라우드 분석 문제를 해결합니다.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">따라서 사내 스토리지와 NPS 스토리지 모두 ONTAP 소프트웨어를 실행하므로 SnapMirror는 사내 클러스터에 NPS 데이터를 미러링하여 사내 및 여러 클라우드에 하이브리드 클라우드 분석을 제공할 수 있습니다.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">최적의 성능을 위해 일반적으로 여러 네트워크 인터페이스 및 직접 연결/빠른 경로를 사용하여 클라우드 인스턴스에서 데이터에 액세스할 것을 권장합니다.</block>
  <block id="1ef541fe0fa79d247c0f1751629bb504" category="inline-link-macro">다음: 사용 사례 5 - 분석 워크로드 가속화</block>
  <block id="7dfabd0b120fe0403ff107668db4094a" category="paragraph"><block ref="7dfabd0b120fe0403ff107668db4094a" category="inline-link-macro-rx"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">이 시나리오에서는 고객이 대규모 사내 Hadoop 저장소를 보유하고 있으며 재해 복구를 위해 백업하려고 합니다. 그러나 고객의 현재 백업 솔루션은 비용이 많이 들고 24시간 이상의 긴 백업 윈도우에 어려움을 겪고 있습니다.</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">사용 사례 1: Hadoop 데이터 백업</block>
  <block id="8efec9e11b7742f59dbe1af079e1c1d0" category="inline-link-macro">이전: Hadoop 데이터 보호 활용 사례 개요</block>
  <block id="259b434ecfae95df231c879645a98918" category="paragraph"><block ref="259b434ecfae95df231c879645a98918" category="inline-link-macro-rx"></block></block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">소프트웨어 하위 호환성:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">제안된 대체 백업 솔루션은 운영 Hadoop 클러스터에 사용되는 현재 실행 중인 소프트웨어 버전과 호환되어야 합니다.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">확정된 SLA를 충족하기 위해 제안된 대체 솔루션은 매우 낮은 RPO 및 RTO를 달성해야 합니다.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">NetApp 백업 솔루션을 통해 생성된 백업은 데이터 센터에서 로컬로 구축된 Hadoop 클러스터뿐만 아니라 원격 사이트의 재해 복구 위치에서 실행되는 Hadoop 클러스터에서도 사용할 수 있습니다.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">제안된 솔루션은 비용 효율적이어야 합니다.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">제안 솔루션은 백업 시간 동안 현재 실행 중인 운영 중인 분석 작업의 성능 영향을 줄여야 합니다.</block>
  <block id="e3d4f6860e578b28733c41c2c852f821" category="section-title">고객의 기존 백업 솔루션</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">아래 그림은 원래 Hadoop 네이티브 백업 솔루션을 보여 줍니다.</block>
  <block id="2975218bd3c71a4ac4eac95d3529a9cb" category="paragraph"><block ref="2975218bd3c71a4ac4eac95d3529a9cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">운영 데이터는 중간 백업 클러스터를 통해 테이프로 보호됩니다.</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">HDFS1 데이터는 'Hadoop distcp-update&lt;hdfs1&gt;&lt;hdfs2&gt;' 명령을 실행하여 HDFS2에 복사됩니다.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">백업 클러스터는 NFS 게이트웨이 역할을 하며 테이프 라이브러리를 통해 Linux 'CP' 명령을 통해 테이프에 데이터를 수동으로 복사합니다.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">원래 Hadoop 네이티브 백업 솔루션의 이점은 다음과 같습니다.</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">이 솔루션은 Hadoop 기본 명령을 기반으로 하므로 사용자가 새로운 절차를 배울 필요가 없습니다.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">이 솔루션은 업계 표준 아키텍처와 하드웨어를 활용합니다.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">원래 Hadoop 네이티브 백업 솔루션의 단점은 다음과 같습니다.</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">긴 백업 시간이 24시간을 초과하므로 운영 데이터가 취약해집니다.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">백업 시간 동안 클러스터 성능이 크게 저하되었습니다.</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">테이프에 복사하는 것은 수동 프로세스입니다.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">백업 솔루션은 필요한 하드웨어 및 수동 프로세스에 필요한 인력 시간의 측면에서 비용이 많이 듭니다.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">백업 솔루션</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">이러한 당면 과제와 요구 사항을 바탕으로 기존 백업 시스템을 고려하여 세 가지 가능한 백업 솔루션을 제안하였습니다. 다음 하위 섹션에서는 이러한 세 가지 백업 솔루션 각각에 대해 설명합니다. 솔루션 A에서 솔루션 C까지의 레이블이 지정되어 있습니다</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">솔루션 A</block>
  <block id="8ee7b0fbb95cf5b1c98578a7ef03b9eb" category="paragraph">솔루션 A는 아래 그림과 같이 데이터 이동 없는 분석 모듈을 백업 Hadoop 클러스터에 추가하여 NetApp NFS 스토리지 시스템에 대한 보조 백업을 허용함으로써 테이프 요구 사항을 제거합니다.</block>
  <block id="411ee6c684ee720eff303771433e41d6" category="paragraph"><block ref="411ee6c684ee720eff303771433e41d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">솔루션 A에 대한 자세한 작업은 다음과 같습니다.</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">운영 Hadoop 클러스터에는 보호가 필요한 HDFS에 고객의 분석 데이터가 있습니다.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">HDFS가 포함된 백업 Hadoop 클러스터는 데이터의 중간 위치로 작동합니다. JBOD(Just a Bunch of Disks)는 운영 및 백업 Hadoop 클러스터 모두에서 HDFS용 스토리지를 제공합니다.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Hadoop distcp –update –diff &lt;hdfs1&gt;&lt;hdfs2&gt;' 명령을 실행하여 운영 클러스터 HDFS에서 백업 클러스터 HDFS로 Hadoop 운영 데이터를 보호합니다.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Hadoop 스냅샷은 운영 환경에서 백업 Hadoop 클러스터로 데이터를 보호하는 데 사용됩니다.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">NetApp ONTAP 스토리지 컨트롤러는 NFS로 내보낸 볼륨을 제공하며 백업 Hadoop 클러스터에 프로비저닝됩니다.</block>
  <block id="b0e42779d51b21a745cae08f938ec60a" category="list-text">MapReduce와 여러 개의 mapper를 활용하는 "Hadoop distcp" 명령을 실행하면 데이터 이동 없는 분석 모듈을 사용하여 분석 데이터가 백업 Hadoop 클러스터에서 NFS로 보호됩니다.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">NetApp 스토리지 시스템의 NFS에 데이터가 저장된 후 NetApp Snapshot, SnapRestore 및 FlexClone 기술을 사용하여 필요에 따라 Hadoop 데이터를 백업, 복원, 복제할 수 있습니다.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">SnapMirror 기술을 사용하여 Hadoop 데이터를 클라우드뿐 아니라 재해 복구 위치에도 보호할 수 있습니다.</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">솔루션 A의 이점은 다음과 같습니다.</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Hadoop 운영 데이터는 백업 클러스터로부터 보호됩니다.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">HDFS 데이터는 NFS를 통해 보호되므로 클라우드 및 재해 복구 위치에 대한 보호가 가능합니다.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">백업 작업을 백업 클러스터로 오프로드하여 성능을 향상시킵니다.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">수동 테이프 작업이 필요 없습니다</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">NetApp 툴을 통해 엔터프라이즈 관리 기능을 지원합니다.</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">기존 환경을 최소한으로 변경해야 합니다.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">비용 효율적인 솔루션입니다.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">이 솔루션의 단점은 성능을 향상시키기 위해 백업 클러스터와 추가 매퍼가 필요하다는 것입니다.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">이 고객은 단순성, 비용, 전반적인 성능 때문에 최근에 솔루션 A를 배포했습니다.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">이 솔루션에서는 JBOD 대신 ONTAP의 SAN 디스크를 사용할 수 있습니다. 이 옵션은 백업 클러스터 스토리지 로드를 ONTAP로 오프로드하지만, 단점은 SAN 패브릭 스위치가 필요하다는 점입니다.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">해결 방법 B</block>
  <block id="304af2b0b47890c7db8f6097978fdede" category="paragraph">솔루션 B는 운영 Hadoop 클러스터에 데이터 이동 없는 분석 모듈을 추가하여 아래 그림과 같이 백업 Hadoop 클러스터가 필요하지 않습니다.</block>
  <block id="303388aba87d7dcff207a6cd098b0cfe" category="paragraph"><block ref="303388aba87d7dcff207a6cd098b0cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">솔루션 B에 대한 자세한 작업은 다음과 같습니다.</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">NetApp ONTAP 스토리지 컨트롤러는 운영 Hadoop 클러스터에 NFS 내보내기를 프로비저닝합니다.</block>
  <block id="3c321f811c173c1f133bdcc77fc81a33" category="paragraph">Hadoop 네이티브 'Hadoop distcp' 명령은 Hadoop 데이터를 데이터 이동 없는 분석 모듈을 통해 운영 클러스터 HDFS에서 NFS로 보호합니다.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">NetApp 스토리지 시스템의 NFS에 데이터가 저장된 후에는 Snapshot, SnapRestore 및 FlexClone 기술을 사용하여 필요에 따라 Hadoop 데이터를 백업, 복원, 복제할 수 있습니다.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">솔루션 B의 이점은 다음과 같습니다.</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">운영 클러스터는 백업 솔루션에 맞게 약간 수정되어 구축이 간소화되고 추가 인프라스트럭처 비용이 절감됩니다.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">백업 작업을 위한 백업 클러스터는 필요하지 않습니다.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS 운영 데이터는 NFS 데이터 변환 시 보호됩니다.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">이 솔루션을 사용하면 NetApp 툴을 통해 엔터프라이즈 관리 기능을 수행할 수 있습니다.</block>
  <block id="02946730aaff0e3d8abfa986a2fe949d" category="paragraph">이 솔루션의 단점은 프로덕션 클러스터에 구현되어 운영 클러스터에 추가 관리자 작업을 추가할 수 있다는 것입니다.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">솔루션 C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">솔루션 C에서는 아래 그림과 같이 NetApp SAN 볼륨을 HDFS 스토리지용 Hadoop 운영 클러스터에 직접 프로비저닝합니다.</block>
  <block id="dc460b3501caf17186202576855a6d3c" category="paragraph"><block ref="dc460b3501caf17186202576855a6d3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">솔루션 C에 대한 자세한 단계는 다음과 같습니다.</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">NetApp ONTAP SAN 스토리지는 HDFS 데이터 스토리지를 위한 운영 Hadoop 클러스터에서 프로비저닝됩니다.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">NetApp Snapshot 및 SnapMirror 기술은 운영 Hadoop 클러스터의 HDFS 데이터를 백업하는 데 사용됩니다.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">백업이 스토리지 계층에 있기 때문에 스냅샷 복사본 백업 프로세스 중에 Hadoop/Spark 클러스터의 운영에 미치는 성능 영향은 없습니다.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">스냅샷 기술은 데이터 크기에 관계없이 몇 초 내에 백업을 완료합니다.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">솔루션 C의 이점은 다음과 같습니다.</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">스냅샷 기술을 사용하여 공간 효율적인 백업을 생성할 수 있습니다.</block>
  <block id="5788267ffe4023e91b333de591766cca" category="inline-link-macro">다음: 사용 사례 2 - 클라우드에서 사내로 백업 및 재해 복구</block>
  <block id="1619284091911820ebd1407554fb6da7" category="paragraph"><block ref="1619284091911820ebd1407554fb6da7" category="inline-link-macro-rx"></block></block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">이 섹션에서는 이 백서의 초점을 구성하는 데이터 보호 활용 사례에 대해 자세히 설명합니다. 나머지 섹션에서는 고객 문제(시나리오), 요구 사항 및 당면 과제, 솔루션 등 각 사용 사례에 대한 자세한 정보를 제공합니다.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Hadoop 데이터 보호 활용 사례 개요</block>
  <block id="d161097dc6596d3807b21a5635856d71" category="inline-link-macro">이전: Hadoop 데이터 보호 및 NetApp</block>
  <block id="1a5df0b83f496dc00b4a331caac0d5cd" category="paragraph"><block ref="1a5df0b83f496dc00b4a331caac0d5cd" category="inline-link-macro-rx"></block></block>
  <block id="385dae214dc9bab52698dc7cd42632ad" category="paragraph">이 활용 사례에서 In-Place Analytics Module은 대형 금융 기관에서 긴 백업 시간을 24시간 이상으로 단축하면서 몇 시간 미만으로 단축하도록 지원했습니다.</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">NetApp에서 제공하는 Data Fabric을 구성 요소로 사용함으로써 대규모 브로드캐스트 회사는 주문형, 즉각적인 데이터 전송 같은 다양한 데이터 전송 모드에 따라 클라우드 데이터를 사내 데이터 센터에 백업하는 요구사항을 충족시킬 수 있었습니다. 또는 Hadoop/Spark 클러스터 로드를 기반으로 합니다.</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">NetApp 솔루션을 통해 온라인 음악 유통업체는 다양한 지점에서 공간 효율적인 다중 Hadoop 클러스터를 신속하게 구축하여 보고서를 생성하고 예약된 정책을 사용하여 일일 DevTest 작업을 실행할 수 있었습니다.</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">한 대형 서비스 공급자는 NetApp이 제공하는 Data Fabric을 사용하여 다양한 클라우드 인스턴스에서 고객에게 멀티 클라우드 분석을 제공합니다.</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">가장 큰 금융 서비스 및 투자 은행 중 하나는 NetApp 네트워크 연결 스토리지 솔루션을 사용하여 I/O 대기 시간을 줄이고 정량 재무 분석 플랫폼을 가속화했습니다.</block>
  <block id="2afe208a471bf6c54f0ccc97f4c6508d" category="inline-link-macro">다음: 활용 사례 1 - Hadoop 데이터 백업</block>
  <block id="aac250a096aacf9aed26ebbd137818da" category="paragraph"><block ref="aac250a096aacf9aed26ebbd137818da" category="inline-link-macro-rx"></block></block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">이 섹션에서는 다양한 Hadoop 데이터 보호 요구사항을 충족하기 위해 NetApp에서 제공하는 사용 사례 및 솔루션을 요약합니다.</block>
  <block id="23496143e5ca83c13eb4d953786abdcd" category="inline-link-macro">이전: 사용 사례 5 - 분석 워크로드 가속화</block>
  <block id="09b7371b2ae3168a3c54b30e4966e86e" category="paragraph"><block ref="09b7371b2ae3168a3c54b30e4966e86e" category="inline-link-macro-rx"></block></block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">이 섹션에서는 다양한 Hadoop 데이터 보호 요구사항을 충족하기 위해 NetApp에서 제공하는 사용 사례 및 솔루션을 요약합니다. 고객은 NetApp이 제공하는 Data Fabric을 사용하여 다음을 수행할 수 있습니다.</block>
  <block id="ce0bf05854efb234905c751e40774ab5" category="list-text">NetApp의 풍부한 데이터 관리 기능과 Hadoop 기본 워크플로우와의 통합을 활용하여 적합한 데이터 보호 솔루션을 유연하게 선택할 수 있습니다.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Hadoop 클러스터의 백업 윈도우 시간을 약 70% 단축</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Hadoop 클러스터 백업으로 인한 성능 영향을 없앱니다.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">여러 클라우드 공급자로부터 데이터 보호 및 데이터 액세스를 동시에 단일 분석 데이터 소스에 제공</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">FlexClone ® 기술을 사용하여 빠르고 공간 효율적인 Hadoop 클러스터 복사본을 생성합니다.</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">이 문서에 설명된 정보에 대한 자세한 내용은 다음 문서 및/또는 웹 사이트를 참조하십시오.</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">NetApp 빅데이터 분석 솔루션</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">NetApp 스토리지를 사용하는 Apache Spark 워크로드</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Apache Spark용 NetApp 스토리지 솔루션</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">NetApp에서 지원하는 Data Fabric 기반 Apache Hadoop</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="list-text">NetApp 데이터 이동 없는 분석 모듈</block>
  <block id="1d669c79bffe95dd384dffb8309a0d40" category="inline-link"><block ref="1d669c79bffe95dd384dffb8309a0d40" category="inline-link-rx"></block></block>
  <block id="fde1cd76fa73f8065aeb8a97c77b40ec" category="paragraph"><block ref="fde1cd76fa73f8065aeb8a97c77b40ec" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">감사의 말</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, 영업 담당자, ANZ Victoria District Sales, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, NetApp 비즈니스 개발 매니저</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, NetApp MPSG 이사</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, 시스템 엔지니어, ANZ Victoria District SE, NetApp</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">2018년 1월</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">사용 사례 5로 업데이트: 분석 워크로드 가속화</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">이 설정에서는 Kafka S3 싱크 커넥터를 사용하여 바로 Kafka에서 오브젝트 스토리지의 항목을 읽고 쓰는 방법을 보여 줍니다. 이 테스트에서는 독립 실행형 Confluent 클러스터를 사용했지만 이 설정은 분산 클러스터에 적용됩니다.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Confluent S3 커넥터</block>
  <block id="9b154eb37aabb62c75c78bd31457468f" category="inline-link-macro">이전: 확장성의 성능 테스트.</block>
  <block id="aa4f22f43748e77c4fb71f8cb5333c25" category="paragraph"><block ref="aa4f22f43748e77c4fb71f8cb5333c25" category="inline-link-macro-rx"></block></block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Amazon S3 싱크 커넥터는 Apache Kafka 항목의 데이터를 Avro, JSON 또는 바이트 형식의 S3 오브젝트로 내보냅니다. Amazon S3 싱크 커넥터는 주기적으로 Kafka의 데이터를 폴링하여 S3로 업로드합니다. 분할자는 모든 Kafka 파티션의 데이터를 청크로 분할하는 데 사용됩니다. 각 데이터 청크는 S3 오브젝트로 표시됩니다. 키 이름은 주제, Kafka 파티션 및 이 데이터 청크의 시작 오프셋을 인코딩합니다.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Confluent 웹 사이트에서 Confluent Kafka를 다운로드하십시오.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">패키지를 서버의 폴더에 압축을 풉니다.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">두 변수를 내보냅니다.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">독립 실행형 Confluorent Kafka 설정의 경우 클러스터는 "/tmp"에 임시 루트 폴더를 생성합니다. 또한 ZooKeeper, Kafka, 스키마 레지스트리, 연결, ksql-server를 생성합니다. 제어 센터 폴더를 만들고 해당 구성 파일을 '$CONFLUENT_HOME'에서 복사합니다. 다음 예를 참조하십시오.</block>
  <block id="fc1644d2d2819b87443b810d963409fa" category="list-text">ZooKeeper를 구성합니다. 기본 매개 변수를 사용하는 경우 아무것도 변경할 필요가 없습니다.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">위 구성에서 서버를 업데이트했습니다. XXX'재산. 기본적으로 Kafka 리더 선택을 위해서는 Zookeepers가 세 개 필요합니다.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">고유한 ID로 '/tmp/confluent.406980/zookeeper/data'에 myid 파일을 만들었습니다.</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">myid 파일에 대한 마지막 IP 주소 수를 사용했습니다. Kafka, CONNECT, CONTROL-CENTER, Kafka, Kafka-Rest, ksql-server 및 schema-registry 구성.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Kafka 서비스를 시작합니다.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">각 구성에 대한 로그 폴더가 있어 문제를 해결하는 데 도움이 됩니다. 경우에 따라 서비스를 시작하는 데 더 많은 시간이 걸릴 수 있습니다. 모든 서비스가 실행 중인지 확인합니다.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">'confluent-hub'을 이용하여 Kafka CONNECT를 설치한다.</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">confluent-hub install confluentinc/Kafka-connect-S3:10.0.3'을 사용하여 특정 버전을 설치할 수도 있습니다.</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">기본적으로 '/data/confluent/confluent-6.2.0/share/confluent-hub-components/confluentententinc-kafka-connect-s3'에 confluentinc-kafka-connect-s3이 설치됩니다.</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">새로운 'confluentinc-kafka-connect-s3'으로 플러그인 경로를 업데이트합니다.</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Confluent 서비스를 중지하고 다시 시작합니다.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">'/root/.aws/credentials' 파일에서 액세스 ID와 비밀 키를 설정한다.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">버킷에 도달할 수 있는지 확인합니다.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">S3 및 버킷 구성에 대해 S3-싱크 속성 파일을 구성합니다.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">S3 버킷으로 몇 개의 레코드를 가져옵니다.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">S3 싱크 커넥터를 로드합니다.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">S3 싱크 상태를 확인합니다.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">로그를 확인하여 S3 싱크가 항목을 수락할 준비가 되었는지 확인합니다.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Kafka의 주제를 확인하십시오.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">S3 버킷의 오브젝트를 확인합니다.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">내용을 확인하려면 다음 명령을 실행하여 각 파일을 S3에서 로컬 파일 시스템으로 복사합니다.</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">아파치 아카이브</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">레코드를 인쇄하려면 avro-tools-1.11.0.1.jar (에서 사용 가능)를 사용합니다<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="e621a272d292cd32516db52fc07b5855" category="inline-link-macro">다음: ConfFluent 자체 재조정 클러스터.</block>
  <block id="56b9b2115a3169192950ec86c26f6add" category="paragraph"><block ref="56b9b2115a3169192950ec86c26f6add" category="inline-link-macro-rx"></block></block>
  <block id="bf647454e36069fd16f1a7a35cf6a865" category="sidebar">시작하기</block>
  <block id="d1c8b02a1da8ed066c640468ff055a12" category="sidebar">EHC 개요</block>
  <block id="a4dc228188fdd73342ee66658a9afdff" category="sidebar">하이퍼스케일러 클라우드의 NetApp</block>
  <block id="624e816c7f229d54827ad7bc018eb8da" category="sidebar">지원되는 스토리지 옵션</block>
  <block id="40d267fad784266cb59c36d76573e7c6" category="sidebar">AWS 기반 NetApp(VMC)</block>
  <block id="e7060d0555f178d672a4197df38e1d39" category="sidebar">가상화 환경을 구성합니다</block>
  <block id="96e706be9b4668c0923788c6a8905fef" category="sidebar">네이티브 데이터 저장소 옵션</block>
  <block id="2408eed8aca98d53134097e8990c8225" category="sidebar">게스트 연결 스토리지 옵션</block>
  <block id="a64cd881ec955d17faa5e396a891e1e6" category="sidebar">Azure 기반 NetApp(AVS)</block>
  <block id="d1b0ccc0fc426266cf228929d5424ce4" category="sidebar">Google Cloud Platform의 NetApp(GCVE)</block>
  <block id="b84034a4ed4e546b39d5bd268ff06eaa" category="sidebar">시작/모범 사례</block>
  <block id="b0f878715a3d12827d6fb02b0df1f23c" category="sidebar">NetApp 및 VMware: 시작하기</block>
  <block id="690359e9e894d87f3144da561090e3f0" category="sidebar">VMware vSphere 관리자를 위한 NetApp ONTAP의 이점</block>
  <block id="eaf99c5ef6885367fbd51d3ed4d278a9" category="sidebar">ONTAP for VMware vSphere의 새로운 기능</block>
  <block id="c0bf5949fe87e1e5caf42e4746cd0080" category="sidebar">ONTAP를 사용하는 VMware vSphere 모범 사례</block>
  <block id="584132370dee3f2fccd2ca59888bee18" category="sidebar">퍼블릭 클라우드의 VMware</block>
  <block id="b83c823b7beb8bbe271bd6cc3a2353c7" category="sidebar">엔터프라이즈 하이브리드 클라우드</block>
  <block id="631ed8aac33a641d62d751c3abd77c57" category="sidebar">AWS용 NetApp VMC</block>
  <block id="9f5fbecd7c791f090de17716e147c3a5" category="sidebar">NetApp for Azure AVS</block>
  <block id="b2ab132403a71f074bc776eb29725292" category="sidebar">NetApp for Google Cloud Platform GCVE</block>
  <block id="07a2344d318341cbbdb1983d22dc80f0" category="sidebar">보안 데이터 보호</block>
  <block id="10e5369e04057873bcce3de87e2c6187" category="sidebar">NetApp ONTAP 9를 사용하는 VMware 사이트 복구 관리자(SRM</block>
  <block id="9f4b95975f14f6481a322f453e05049c" category="sidebar">VMware vSphere용 ONTAP 툴 - 제품 보안</block>
  <block id="c4f0254bef611d7217287539f6e00feb" category="sidebar">VMware vSphere 자동화</block>
  <block id="ce006038ddc2a04747fe5a2c9c43b8f5" category="sidebar">데모 및 자습서</block>
  <block id="eccb6fc5c04122d7aef60d899a77089e" category="sidebar">추가 리소스</block>
  <block id="5e4af7ed70d1a211f16d528dcdfc6474" category="sidebar">가상 데스크톱 솔루션</block>
  <block id="cf04feec36847ba9c9671b28661cd1fc" category="sidebar">NetApp 솔루션 설명서</block>
  <block id="38d9ffc674675d65fbb8aabd7e47acd3" category="sidebar">FlexPod 솔루션</block>
  <block id="6f4bb0fa6fee4cf4ae1b8b1fc16e17cb" category="sidebar">레거시 NetApp HCI 솔루션</block>
  <block id="3523ec156cfc8217bb64d1273e5663fa" category="sidebar">NetApp 솔루션 정보</block>
  <block id="d648f2a68a54fd1b3329efc3cf24d29c" category="sidebar">법적 고지</block>
  <block id="e799e148c709b216080d260919cc9b9f" category="sidebar">AI 최신 데이터 분석</block>
  <block id="91770f038cd944a1d3b9b347edeb2b10" category="sidebar">새로운 기능</block>
  <block id="17c3771ed0b6c1ae15740eff715e9922" category="sidebar">비디오 및 데모</block>
  <block id="4fdba571bc9e0ee81ec6ad364abe8141" category="sidebar">엔터프라이즈 하이브리드 클라우드(EHC)</block>
  <block id="e673b6ab6c5649a4df8e874aaa9017b9" category="sidebar">지원되는 구성</block>
  <block id="bee43f00a445d11a7c2f9ef81ad0c045" category="sidebar">하이퍼스케일러 클라우드의 VMware Cloud</block>
  <block id="e281a59ee9a608bff3a3a795963fa1b4" category="sidebar">하이퍼스케일러 지정 콘텐츠</block>
  <block id="70321856a2bf47570f50f25e43e23bdf" category="sidebar">가상화, 데스크톱 가상화 컨테이너</block>
  <block id="25a72d771c3846ba4da8732220f7a588" category="sidebar">엔터프라이즈 애플리케이션 데이터베이스</block>
  <block id="0333ddced253ee1c6929eda5612dea92" category="sidebar">자동화 요청</block>
  <block id="bdca592f24222e5064192bb9e2f9af6e" category="sidebar">FlexPod - NetApp Cisco 솔루션</block>
  <block id="0da8a1ebf94a3a1e650dbfbd01c69dd9" category="sidebar">FlexPod 솔루션 기술 콘텐츠</block>
  <block id="32591d046a055939af0d128133dc8606" category="sidebar">FlexPod 영업 페이지</block>
  <block id="9e2c62f406d88ad1ee253efd74f593df" category="sidebar">새 솔루션 제안</block>
  <block id="7fd861566be88364067d817b54a44688" category="sidebar">솔루션 피드백을 제공합니다</block>
  <block id="9a9891facf2fa1c878c0fc18c6638005" category="sidebar">AI 통합 인프라</block>
  <block id="12797522e94d75727dd0a05a4ed9f5ff" category="sidebar">NVIDIA와 함께 ONTAP AI</block>
  <block id="687350c847aefbf978e16be26609d101" category="sidebar">NVIDIA DGX A100 시스템 설계 가이드를 지원하는 ONTAP AI</block>
  <block id="4c7a8c5b878fcdf733694f638b393b6b" category="sidebar">NVIDIA DGX A100 시스템 탑재 ONTAP AI 구축 가이드</block>
  <block id="74c684b866e5fcffcc9c5165a491d5b2" category="sidebar">NVIDIA DGX A100 시스템과 Mellanox Spectrum 이더넷 스위치 설계 가이드를 지원하는 ONTAP AI</block>
  <block id="f8363659ae3ab117a0afa4163ca69fc7" category="sidebar">NVIDIA DGX A100 Systems 및 Mellanox Spectrum 이더넷 스위치 포함 ONTAP AI 구축 가이드 를 참조하십시오</block>
  <block id="0c3efd7c1aae12456ab9935ae5fd15e0" category="sidebar">NVIDIA DGX A100 Systems 및 BeeGFS 지원 EF-Series AI</block>
  <block id="c70e778edabe427cd2db90132a56e456" category="sidebar">NVIDIA DGX A100 Systems 및 BeeGFS 설계를 지원하는 EF-Series AI</block>
  <block id="06aa576b3e3e95c5df800228d146af65" category="sidebar">NVIDIA DGX A100 Systems 및 BeeGFS 구축이 포함된 EF-Series AI</block>
  <block id="2967ab4748573d0cb6f2c4084c4fd70f" category="sidebar">BeeGFS 및 NetApp E-Series 참조 아키텍처</block>
  <block id="1db760587a86f5c1b9ab39aa8cf8cf3d" category="sidebar">NetApp E-Series 스토리지로 IBM Spectrum Scale 구축</block>
  <block id="08479c0355c887a02e772206b0d5d7f5" category="sidebar">AI 및 ML 모델 교육 워크로드용 NetApp ONTAP 및 Lenovo ThinkSystem SR670</block>
  <block id="e648dd2d4df65a903e9c1204d81abaed" category="sidebar">AI 및 ML 모델 교육 워크로드용 NetApp AFF A800 및 Fujitsu Server PRIMERGY GX2570 M5</block>
  <block id="6a571fb799acb43b64f874729f838e2a" category="sidebar">데이터 파이프라인, 데이터 레이크 및 관리</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">자율 주행 워크로드를 위한 NetApp StorageGRID 데이터 레이크</block>
  <block id="fad62e8b886e655813cc4ce635152f62" category="sidebar">Trident 구축</block>
  <block id="8ad188089680179dea816084001d7bf0" category="sidebar">AI 및 분석 워크플로우를 위한 E-Series 및 BeeGFS로 데이터 이동</block>
  <block id="ae270ffdc87820776fadfe121aa13143" category="sidebar">NetApp AI를 통한 감정 분석</block>
  <block id="f74720767a0bf20cfdb6bba5f215d795" category="sidebar">지원 센터 정서 분석 배포</block>
  <block id="1863627f5be51826024a24014fce26ff" category="sidebar">Azure-Click-Through Rate Prediction의 분산 교육</block>
  <block id="7f39827ac712fa5b76b27ff0b267373c" category="sidebar">NetApp DataOps 툴킷을 사용하여 데이터 세트 및 모델 버전 관리</block>
  <block id="458df51beb3b33cfa61bdc8725403f5b" category="sidebar">참고용 Jupyter 노트북</block>
  <block id="70be05b3500f28affc2d048f81c4f7ab" category="sidebar">분산된 Azure 교육 - 차선 감지</block>
  <block id="7767872606b9c99eb656c9568c1fdd83" category="sidebar">차선 감지 – AI를 통한 분산된 교육</block>
  <block id="ce3b746194cb1fb7d96dfe14187115e0" category="sidebar">데이터 캐싱을 지원하는 하이브리드 클라우드 AI 운영 체제</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">빅 데이터 환경에서 AI 환경으로 데이터 이동</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Edge-NetApp에서 Lenovo ThinkSystem을 사용한 AI 추론 - 솔루션 설계</block>
  <block id="f1e7c981dec3bcee348bda96c55363c4" category="sidebar">NVIDIA를 통한 대화형 AI</block>
  <block id="d5c1931461d1e204a84a486796df2cca" category="sidebar">실행 시 NetApp 오케스트레이션 솔루션: AI</block>
  <block id="c0a0f5bbb431dea70000d73b29e50249" category="sidebar">AI 실행을 통한 최적의 클러스터 및 GPU 활용률</block>
  <block id="09c995632f33d1ee4a581eb951793f35" category="sidebar">AI 설치 실행</block>
  <block id="5c9e37e6d7e6f5e3a76854d8343d626b" category="sidebar">AI 대시보드 및 뷰 실행</block>
  <block id="29ebede332931243e314d8a3f333c1a7" category="sidebar">AI CLI 실행 에서 작업 제출</block>
  <block id="2943702718c42a5063e0c70598cebdc6" category="sidebar">자율 주행 워크로드를 위한 NetApp ONTAP AI 솔루션 설계</block>
  <block id="d11813566a7c636e892d384601baf2c3" category="sidebar">의료 서비스를 위한 NetApp ONTAP AI 참조 아키텍처: 진단 이미징</block>
  <block id="ab8526a90cc9cc979ddd23c87fff57bd" category="sidebar">금융 서비스 워크로드를 위한 NetApp ONTAP AI 참조 아키텍처</block>
  <block id="6efd886c994d37b6577e22359be2310e" category="sidebar">NetApp E-Series 및 BeeGFS를 통해 AI 배포</block>
  <block id="3863e8a73e226ce0c0a6ad02b90ee75b" category="sidebar">NetApp E-Series 시스템을 사용한 Quantum StorNext 설계 가이드 를 참조하십시오</block>
  <block id="7891972f4586e6ee183ea541991ebe9f" category="sidebar">NetApp E-Series 시스템을 사용하는 Quantum StorNext 구축 가이드 를 참조하십시오</block>
  <block id="6ff1dafebf930a9c5fef12bf43046987" category="sidebar">엔터프라이즈 애플리케이션 및 데이터베이스</block>
  <block id="e340bc103d02ce2b8e016eb60705029c" category="sidebar">SAP 및 SAP HANA</block>
  <block id="54d2cdd3035ca1cdff5803c30f2ed2e1" category="sidebar">Oracle Database 구축</block>
  <block id="c880b35e02dbb5854452c86028138e2a" category="sidebar">NetApp ONTAP에 Oracle 데이터베이스 구축</block>
  <block id="699700175d80778f1738d906ee9540d5" category="sidebar">시작하기 및 요구 사항</block>
  <block id="210fdbe41d80b2e8690a970de86a7ffb" category="sidebar">Oracle 19c AWX/Tower 구축 자동화</block>
  <block id="13cf6478a61a7904a3062d587248fb75" category="sidebar">자동화된 Oracle 19c CLI 구축</block>
  <block id="12367669ba6a0b6e059b69b5a95f2902" category="sidebar">Oracle 데이터베이스 데이터 보호</block>
  <block id="3e9d3644ee18a66c51ddd16b668eaa5a" category="sidebar">자동화된 Oracle 데이터 보호</block>
  <block id="82be90bcfc8fd03855e030edaa25583a" category="sidebar">AWX/Tower를 위한 자동화된 Oracle 데이터 보호</block>
  <block id="bc113eb23aa0579a5e1d93e97ca13635" category="sidebar">Oracle Databases on NetApp EF-Series 를 참조하십시오</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server를 참조하십시오</block>
  <block id="61def2ac347af2f10fd60cd67052a311" category="sidebar">참조 디자인(실시간 고급 디자인)</block>
  <block id="89447eb7454239e11376250fa04a88f7" category="sidebar">Clustered Data ONTAP을 사용하는 Windows 기반 Microsoft SQL Server와 SAP</block>
  <block id="7c02456b91ace7501ea6f18d1657dcf7" category="sidebar">Microsoft SQL Server 현대화</block>
  <block id="5c008a8422e884d74da1d4b50a7ada55" category="sidebar">Microsoft SQL Server with NetApp EF-Series 모범 사례 가이드 를 참조하십시오</block>
  <block id="30b22b544972f5adb280ca2975099846" category="sidebar">SnapCenter을 사용한 하이브리드 클라우드 데이터베이스 솔루션</block>
  <block id="59f8ae0d5c4ba13dee4828e2727c8859" category="sidebar">온-프레미스로 시작 중입니다</block>
  <block id="ef55a9d1028eac237813e753d20134df" category="sidebar">VMware - 퍼블릭 클라우드</block>
  <block id="27c378e12a7c59dc5aa13b13cc6cecff" category="sidebar">하이퍼스케일러 클라우드의 VMware Cloud</block>
  <block id="452b0b090c1c37a0d467a8df764fd81f" category="sidebar">하이퍼스케일러 클라우드의 NetApp 스토리지</block>
  <block id="2190ab0d2f6281b2f3a73e0fc8e1f560" category="sidebar">요약 및 결론</block>
  <block id="75fcfea0185575f935a7f5f149efd8ca" category="sidebar">VMware 하이브리드 클라우드 사용 사례</block>
  <block id="e251010eb0cac5793d760ab2e5f51473" category="sidebar">사용 사례 개요</block>
  <block id="c2080fddb65ca5c27930e1b56e9001b9" category="sidebar">하이퍼스케일러 클라우드의 NetApp</block>
  <block id="c894f2bd2f75b76c40354457f85448dd" category="sidebar">AWS 기반 VMC를 위한 NetApp</block>
  <block id="7af96168c530ff4f25450ef6ed33bd95" category="sidebar">Azure에서 AVS를 위한 NetApp</block>
  <block id="3c4ca3bb6cded64b5f69a6e81c8b6a65" category="sidebar">Google Cloud 기반 GCVE를 위한 NetApp</block>
  <block id="5d7b876a73a9025080fbf6dd921d1fdd" category="sidebar">데이터 마이그레이션 및 데이터 보호</block>
  <block id="68dfe5056c735db544868f482f9f1d6f" category="sidebar">NetApp XCP의 모범 사례 지침</block>
  <block id="c5071cdf8081474104ef1eee5ec6d784" category="sidebar">소스 스토리지 상자에서 ONTAP로 ACL을 사용한 CIFS 데이터 마이그레이션</block>
  <block id="712d83d9ce8f26363e9bfd1cba104b88" category="sidebar">NetApp E-Series 및 Commvault 데이터 플랫폼 V11</block>
  <block id="aa8156dc9f7aa240e4f412f2f5fedaf5" category="sidebar">Veeam Backup Replication 9.5의 E-Series 및 EF-Series 레퍼런스 아키텍처 및 스토리지 모범 사례</block>
  <block id="74e4bedcc2ff5b37a8770caa0ef72975" category="sidebar">NetApp E-Series 스토리지를 사용한 Veritas NetBackup 구축</block>
  <block id="029f60716c50acd9acf9ce4a9394c91a" category="sidebar">NIST Multitenant Infrastructure용 HyTrust를 사용한 FISMA 보안 제어</block>
  <block id="2a643eb4634917213492cef085506d45" category="sidebar">NetApp 및 VMware 시작하기</block>
  <block id="6c30682e8603121e14abe8bab7bd88f3" category="sidebar">ONTAP용 VMware 가상화</block>
  <block id="cadc483b04d069f993431e3ac64341bf" category="sidebar">가상 볼륨 및 스토리지 정책 기반 관리</block>
  <block id="1918f1bc0ea91d0e5d8e37878d5ab562" category="sidebar">NetApp ONTAP 9가 포함된 VMware 사이트 복구 관리자</block>
  <block id="86fbb5b9292be9b680987addfa410586" category="sidebar">기존 블록 스토리지 용량 할당</block>
  <block id="805a0828a65bce146a58e3556113b017" category="sidebar">VMFS - Fibre Channel</block>
  <block id="26e113624e0cc32cbe2a26e1cde1da24" category="sidebar">VMFS - Fibre Channel over Ethernet</block>
  <block id="8237af9088e8905784b1cb373e3a080d" category="sidebar">VMFS-iSCSI</block>
  <block id="94cab344ef7124917167bd5415b137cf" category="sidebar">VMFS-NVMe over Fabric을 참조하십시오</block>
  <block id="348ee034e8868e5211a6501c09d4b0f0" category="sidebar">기존 파일 스토리지 용량 할당</block>
  <block id="614b997c0fb5abcd68fda0ab9ca05d69" category="sidebar">NFS-v3</block>
  <block id="912655e9dd57ab01b86691021957e61e" category="sidebar">NFS-v4.1</block>
  <block id="a87e5ca19422686ef96f1e6799e9111d" category="sidebar">VDS(가상 데스크톱 서비스)</block>
  <block id="b89c617ff394cc85df3935994baa194b" category="sidebar">Login VSI를 사용한 단일 서버 로드 테스트</block>
  <block id="6abbceca4793ffe4b329045f63b4d219" category="sidebar">운영 관리</block>
  <block id="1b31ca8ddb749644af37aa10b42e6930" category="sidebar">GPU 고려 사항</block>
  <block id="a1da2a2d050a6b61256020afd015a056" category="sidebar">솔루션을 제공합니다</block>
  <block id="739169d2451850e6df7246db70c28cc7" category="sidebar">ESG 기술 검증: NetApp 가상 데스크톱 서비스를 통해 엔터프라이즈 규모의 VDI</block>
  <block id="4725a75839c620bb95363c5f7f2ee9bc" category="sidebar">VMware Horizon을 참조하십시오</block>
  <block id="e2a1b52ebd707739003f77464bbcaa80" category="sidebar">FlexPod 데스크톱 가상화 솔루션</block>
  <block id="9d0be07780aeb437025d4b3420d12540" category="sidebar">NetApp XCP 데이터 마이그레이션</block>
  <block id="645198fb2e03205a7f761aeaff8ef26f" category="sidebar">NetApp 솔루션 자동화 및 Ansible 시작하기</block>
  <block id="8619770bb94b4ac2d3ef4a8639dac91f" category="sidebar">Ansible 제어 노드 설정(CLI 기반 구축용)</block>
  <block id="47ac29a4a2e3c3e4581e035d792ee4ac" category="sidebar">RHEL/CentOS 시스템의 경우</block>
  <block id="d74c216bc36310fb7cb045522918e606" category="sidebar">Ubuntu/Debian 시스템의 경우</block>
  <block id="073616205ad0e6bcb86754e5a151281a" category="sidebar">AWX/Ansible 타워 설치(AWX/Tower 기반 배포용)</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">요청 자동화</block>
  <block id="cdc53c90644739ab9cb455ad8b663d7b" category="sidebar">Red Hat OpenShift 개요</block>
  <block id="82ebdc178ed6bd9adb7b66c2edfb70d0" category="sidebar">NetApp 스토리지 시스템 개요</block>
  <block id="aef2d8db139dd41c9ae6c878ab92ae75" category="sidebar">NetApp 스토리지 통합 개요</block>
  <block id="5f6fc3deb668cb75e9e6c8932620df6a" category="sidebar">NetApp Astra Control Center 개요</block>
  <block id="846665f4ec19bffa9d9a8c3937c2f9fd" category="sidebar">Red Hat OpenShift 클러스터를 등록합니다</block>
  <block id="b1dbcb80c89b000949ef64c6d6d6c42b" category="sidebar">보호할 응용 프로그램을 선택합니다</block>
  <block id="2913361a2ab3fddb4242f1761d4a6e38" category="sidebar">애플리케이션 보호</block>
  <block id="b066abadb76f5e6776aa1e7cfdf56b38" category="sidebar">NetApp Astra Trident 개요</block>
  <block id="938033783443233af5517c828deb6d1e" category="sidebar">OpenShift를 위한 고급 구성 옵션</block>
  <block id="d48e549b4fdcc889e0243c53bbb4dda0" category="sidebar">솔루션 검증 및 사용 사례</block>
  <block id="f99e4eb05e28c150680cb72ca8410d93" category="sidebar">NetApp ONTAP를 사용하여 Red Hat OpenShift에서 멀티 테넌시를 구성합니다</block>
  <block id="51a25aff8c490f11d9be543c7af23a0d" category="sidebar">클러스터 관리자 작업</block>
  <block id="244e9cd91466ef1240c125511568880a" category="sidebar">스토리지 관리자 작업</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">확장</block>
  <block id="d6bf2b10101446c7afd28ff94926fc44" category="sidebar">운영자를 통해 구축</block>
  <block id="e6b088db24ebe67ed0e9567d309387ec" category="sidebar">워크플로우</block>
  <block id="88c506562ebadd679bb16d76a4558619" category="sidebar">VM 클로닝</block>
  <block id="d313887d8fa4b2493a50d1e00bad440e" category="sidebar">응용 프로그램 수명 주기 관리</block>
  <block id="03cae7751c31cc76a90cf5e94e86eb3a" category="sidebar">거버넌스 및 위험</block>
  <block id="f55899cffbf639043209795d5a1af970" category="sidebar">자원 작성</block>
  <block id="1c4dff0a00340691e103ef63154df371" category="sidebar">Google Anthos</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Confluent Kafka 모범 사례</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Confluent 자체 재조정 클러스터</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">NetApp 하이브리드 클라우드 데이터 솔루션 - 고객 사용 사례를 기반으로 Spark 및 Hadoop</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">활용 사례 1 - Hadoop 데이터 백업</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">사용 사례 2 - 클라우드에서 사내까지 백업 및 재해 복구</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">사용 사례 3 - 기존 Hadoop 데이터에 대해 DevTest 설정</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">사용 사례 4 - 데이터 보호 및 멀티 클라우드 연결</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">사용 사례 5 - 분석 워크로드 가속화</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">다양한 분석 전략을 위한 다양한 솔루션 솔루션 솔루션 개요</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">Splunk SmartStore가 포함된 NetApp StorageGRID</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E-Series E5700 및 Splunk Enterprise</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">NetApp 스토리지 솔루션을 이용한 Apache Spark 워크로드(구축 가이드)</block>
  <block id="c4c3630750312520bc4b93c16056bfd7" category="doc">NVIDIA 기반 NetApp EF-Series AI</block>
  <block id="e6ee072aeeb0647d8c0cfe75e4cde51d" category="paragraph">NetApp과 NVIDIA의 EF-Series AI 통합 인프라 솔루션 개요</block>
  <block id="f512fcc18626023378bfe28dce07116d" category="list-text"><block ref="f512fcc18626023378bfe28dce07116d" category="inline-link-macro-rx"></block></block>
  <block id="ae02a3224f15623423f197426c44a26d" category="list-text"><block ref="ae02a3224f15623423f197426c44a26d" category="inline-link-macro-rx"></block></block>
  <block id="8ce1a272bf4c47418ea6d69083f2df4f" category="inline-link-macro">BeeGFS 구축 가이드</block>
  <block id="7991adac41b3f0e292dee61e87c39052" category="list-text"><block ref="7991adac41b3f0e292dee61e87c39052" category="inline-link-macro-rx"></block></block>
  <block id="9d2ca817bb7dd69d6f7dc09932a53524" category="summary">NetApp 인공 지능 솔루션은 AI/ML 영역 전반에서 NetApp 스토리지의 기능을 보여주는 전략적 기술 솔루션 세트입니다.</block>
  <block id="b54a1e289898cf21f63715dfe64025b7" category="doc">NetApp 인공 지능 솔루션</block>
  <block id="2bbac71d034e7a7a1fca44c7500e187b" category="doc">NVIDIA를 통한 NetApp ONTAP AI</block>
  <block id="4618b9225719de309c0b0f5aa4718c7b" category="paragraph">NetApp과 NVIDIA의 ONTAP AI 통합 인프라 솔루션 개요</block>
  <block id="ab9d770eb05e7725141740f508566fce" category="section-title">NVIDIA DGX A100 시스템을 지원하는 NetApp ONTAP AI</block>
  <block id="7c962be0dc8fdf28c1c4279fe5256a22" category="section-title">NVIDIA DGX A100 시스템과 Mellanox Spectrum 이더넷 스위치가 포함된 NetApp ONTAP AI</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">영어</block>
  <block id="37ce0afb395b0346118a74c4f05f20a7" category="list-text"><block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block>&amp;f:@facet_soultion_mktg=[AI, 분석, 인공 지능]++[NetApp.com AI 블로그]</block>
  <block id="706e736fcad235c710eab30a42b219b1" category="cell">NVIDIA DGX A100 Systems 및 BeeGFS * 가 포함된 EF-Series AI</block>
  <block id="ec690c5998518cfa45b178a530da4125" category="cell">Edge-NetApp에서 Lenovo ThinkSystem * 으로 추론을 *</block>
  <block id="b1d14722f1d9c668c677c2c7f22cfcc6" category="cell"><block ref="b1d14722f1d9c668c677c2c7f22cfcc6" category="inline-link-macro-rx"></block></block>
  <block id="aa84da6cfda7179db9bbd5f34addb637" category="cell">* NetApp AI를 통한 감정 분석 *</block>
  <block id="7a25f90f4eb7f4d051b5e2903cea9546" category="cell"><block ref="7a25f90f4eb7f4d051b5e2903cea9546" category="inline-link-macro-rx"></block></block>
  <block id="f48991e4773d2a30dd01c029e22e3f32" category="cell">* 클릭 비율 예측 - Azure * 에서 분산된 교육</block>
  <block id="2b48b8a77ebec6ee8be0f1146585b7c3" category="cell"><block ref="2b48b8a77ebec6ee8be0f1146585b7c3" category="inline-link-macro-rx"></block></block>
  <block id="191ea533aa1478d35c965840430fbfe6" category="summary">NetApp의 최신 데이터 분석 솔루션은 AI 부문에서 NetApp 스토리지의 기능을 입증하는 일련의 전략적 기술 역량을 갖추고 있습니다.</block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="doc">NetApp의 최신 데이터 분석 솔루션</block>
  <block id="22169240c9a4c0ab61a4ed13c981c5ef" category="sidebar">AI 워크로드를 위한 통합 인프라</block>
  <block id="8508ab1994a5679882beb6400778e8ba" category="sidebar">NVIDIA를 통한 EF-Series AI</block>
  <block id="ec820f861118408d42b077dbf109f374" category="sidebar">NetApp E-Series 스토리지를 통한 IBM Spectrum Scale</block>
  <block id="b63ada7ec650c01320cddeda05deb779" category="sidebar">Edge-NetApp에서 Lenovo ThinkSystem을 사용한 AI 추론</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">AI용 NetApp ONTAP 및 Lenovo ThinkSystem SR670</block>
  <block id="e5c3eeefe82172631e21562a8d3672a5" category="sidebar">AI용 NetApp AFF A800 및 Fujitsu Server PRIMERGY GX2570 M5</block>
  <block id="2fa3e2a0ff5682666455eed0a7b1b569" category="sidebar">데이터 레이크 및 데이터 파이프라인</block>
  <block id="6ac39037a7efa2708d15c0e0e20fb188" category="sidebar">자율 주행 워크로드를 위한 StorageGRID 데이터 레이크</block>
  <block id="eeb4980c2a89f07abf1a0b927066b23c" category="sidebar">E-Series 및 BeeGFS for AI로 데이터 이동</block>
  <block id="13f985aafb32ac9e387186e5a437f96e" category="sidebar">데이터 캐싱을 지원하는 하이브리드 클라우드 AI</block>
  <block id="ac82c7a9ef13f3b604553ccfe1a5bd76" category="sidebar">마름 및 관리</block>
  <block id="3cd04d0e6cf45786c9e94148f213b537" category="sidebar">AI 파이프라인 및 밤공간 관리를 위한 NetApp AI 컨트롤 플레인</block>
  <block id="447e8e0102d91009c125adb678cd7fb5" category="sidebar">Iguazio를 사용한 MLRun 파이프라인</block>
  <block id="71e6eb0dc5951ca93effe179d000f534" category="sidebar">감정 분석</block>
  <block id="cfff43e76ea0e95d290a279bdb279a2e" category="sidebar">클릭률 예측 - Azure에서 제공되는 분산 교육</block>
  <block id="29931fafbbc65eabe1029aee9a3a5a85" category="sidebar">차선 감지 - Azure에서 분산된 교육</block>
  <block id="7656ac1f9ee1e1763f07a285578d922a" category="sidebar">NVIDIA Jarvis를 사용하는 대화형 AI</block>
  <block id="8f0148532a5b5382ec4f005c8a96a4fa" category="sidebar">자율 주행</block>
  <block id="f869ce5572b45e50fe014954c4248d60" category="sidebar">의료 - 진단 이미징</block>
  <block id="951b9c6690c2a4c1228ada2a9980d5a8" category="sidebar">신용 카드 사기 감지</block>
  <block id="f0b83f1f7d211bfb4e278dafd2d6b4fa" category="sidebar">NetApp 스토리지 솔루션을 사용한 Apache Spark 워크로드</block>
  <block id="6bf79bc16e8a34cf5698aabd27cecef1" category="sidebar">최신 데이터 분석 솔루션 개요</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="sidebar">모범 사례</block>
  <block id="1bd369d8fc8172d625ac41a1815aa09d" category="sidebar">Confluent Kafka 모범 사례</block>
  <block id="3ed3645b4e41749082a0692a758a3132" category="sidebar">하이브리드 클라우드 솔루션 - Spark 및 Hadoop 사용 사례</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">블로그: Data Lake 및 HPC에서 ONTAP NFS로 XCP for Data Migration을 사용합니다</block>
  <block id="9cb9fe27a24f987a1889d5fc1d5d139e" category="sidebar">BeeGFS 및 NetApp E-Series 구축 가이드</block>
  <block id="d064ecad73d9352507092f40af924057" category="cell">2022년 2월 2일</block>
  <block id="c0598da0ea2338576f8d67854c56e3f6" category="cell">AI 및 최신 데이터 분석을 위한 콘텐츠를 더 효과적으로 구성하기 위한 랜딩 페이지를 생성했습니다</block>
  <block id="84c45df200c907852c1e92875618b432" category="cell">2022년 1월 22일</block>
  <block id="b385810d0a927b9d15a69218e3fb38c4" category="cell">AI 및 분석 워크플로우를 위해 E-Series 및 BeeGFS로 데이터 이동 추가</block>
  <block id="89d5e6802ef5a3ae4296f49d4d6bc447" category="sidebar">추가 리소스</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">블로그:Apache Spark는 NetApp 데이터 분석 운동장에서 실행됩니다</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: 빅데이터 분석 재생 목록</block>
  <block id="0a2866cc3e2ba203c7e2e3ebeca395be" category="sidebar">UNIX 기반의 Oracle과 SAP, NetApp Clustered Data ONTAP 기반의 NFS</block>
  <block id="3fb5798a9396698dabb0ac96950db53b" category="list-text"><block ref="3fb5798a9396698dabb0ac96950db53b" category="inline-link-macro-rx"></block></block>
  <block id="046546ab63b0ca36de368801c6fd8a9e" category="list-text"><block ref="046546ab63b0ca36de368801c6fd8a9e" category="inline-link-macro-rx"></block></block>
  <block id="0027e14144945de23e255b58586424e1" category="list-text"><block ref="0027e14144945de23e255b58586424e1" category="inline-link-macro-rx"></block></block>
  <block id="c2dd14a3829d81f8d6ccd1a2a41e114b" category="list-text"><block ref="c2dd14a3829d81f8d6ccd1a2a41e114b" category="inline-link-macro-rx"></block></block>
  <block id="d70f78589c41399658959afc073dfede" category="list-text"><block ref="d70f78589c41399658959afc073dfede" category="inline-link-macro-rx"></block></block>
  <block id="9f7328009a38e32265481f8305d6aa75" category="list-text"><block ref="9f7328009a38e32265481f8305d6aa75" category="inline-link-macro-rx"></block></block>
  <block id="5ee479af89822c5af943f78689918520" category="list-text"><block ref="5ee479af89822c5af943f78689918520" category="inline-link-macro-rx"></block></block>
  <block id="e858f513baeeed4d0c8f4edb6b0a7ce8" category="doc">Azure/AVS용 NetApp 엔터프라이즈 하이브리드 클라우드 솔루션</block>
  <block id="79fab3fcc59adc540e33fa185069b7ce" category="list-text"><block ref="79fab3fcc59adc540e33fa185069b7ce" category="inline-link-macro-rx"></block></block>
  <block id="85a5820e8da21c627876736be5d694b8" category="list-text"><block ref="85a5820e8da21c627876736be5d694b8" category="inline-link-macro-rx"></block></block>
  <block id="3aa200e6ed258b413d3edac26b75184a" category="list-text"><block ref="3aa200e6ed258b413d3edac26b75184a" category="inline-link-macro-rx"></block></block>
  <block id="236b2a8169de601ff6b72a6a78e1f572" category="list-text"><block ref="236b2a8169de601ff6b72a6a78e1f572" category="inline-link-macro-rx"></block></block>
  <block id="63e6365ca9ee8eced75eccdd9a133b69" category="doc">GCP/GCVE를 위한 NetApp Enterprise Hybrid Cloud Solutions</block>
  <block id="59eb8568bc4ce9e9a49ab2dd5bb08af1" category="doc">AWS/VMC를 위한 NetApp 엔터프라이즈 하이브리드 클라우드 솔루션</block>
  <block id="70b9c790cc4671aad4f8d8322d13161b" category="list-text"><block ref="70b9c790cc4671aad4f8d8322d13161b" category="inline-link-macro-rx"></block></block>
  <block id="2b1b2978337fa95de5057d99307c01aa" category="list-text"><block ref="2b1b2978337fa95de5057d99307c01aa" category="inline-link-macro-rx"></block></block>
  <block id="13dcdfd7bce3161be8066f52b4d2247a" category="cell"><block ref="13dcdfd7bce3161be8066f52b4d2247a" category="inline-link-macro-rx"></block></block>
  <block id="7e2e877818cdb57ef3a43f99102f9d38" category="cell"><block ref="7e2e877818cdb57ef3a43f99102f9d38" category="inline-link-macro-rx"></block></block>
  <block id="5909792f4a0287d5b5f88ee6f430a28f" category="cell"><block ref="5909792f4a0287d5b5f88ee6f430a28f" category="inline-link-macro-rx"></block></block>
  <block id="99643699503906f6a149e103359b31d5" category="cell"><block ref="d35550b71de9d445d0f21340762112d5" category="inline-link-macro-rx"></block>
<block ref="457b0b4c4f040ecdb73aa5b03853579f" category="inline-link-macro-rx"></block></block>
  <block id="7b1ff975fb6d48c12181b30da20dfab0" category="cell"><block ref="3c73250bfc490d47ce28b6cf808148ac" category="inline-link-macro-rx"></block>
<block ref="0f2c04766507e4de89a1d44cbd408339" category="inline-link-macro-rx"></block></block>
  <block id="2a32702602a143372d93bf2d2f395a36" category="cell"><block ref="14800306dfb8ba898026bf23b6a9cfc5" category="inline-link-macro-rx"></block>
<block ref="ef1833f411035de243ce008622899fb9" category="inline-link-macro-rx"></block></block>
  <block id="4e36e97d23b00520e4b573859ee4cb26" category="list-text"><block ref="4e36e97d23b00520e4b573859ee4cb26" category="inline-link-macro-rx"></block></block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">TR-4597: ONTAP용 VMware vSphere<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="c39148c472a0504dc9c52734b79f5125" category="sidebar">게스트 연결 스토리지가 있는 솔루션</block>
  <block id="511ff82335a683184e92371d0c9fe853" category="sidebar">기본 데이터 저장소가 있는 솔루션</block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">이 검증에서 4대의 서버를 NSD(Network Shared Disk) 서버로 사용하여 GPFS에 물리적 디스크를 제공했습니다. GPFS는 NSD 디스크 위에 생성되어 NFS 내보내기로 내보내므로 NFS 클라이언트가 아래 그림과 같이 액세스할 수 있습니다. XCP를 사용하여 GPFS로 내보낸 NFS의 데이터를 NetApp NFS 볼륨으로 복사했습니다.</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS를 NetApp ONTAP NFS로</block>
  <block id="823313a32a4a1131e0469fac26acbdac" category="inline-link-macro">이전: AI용 Data Mover 솔루션</block>
  <block id="c4e4b7ebe157b09b7d1a0db25078dc45" category="paragraph"><block ref="c4e4b7ebe157b09b7d1a0db25078dc45" category="inline-link-macro-rx"></block></block>
  <block id="9a1bdf4376c8448278cf38263e4da8c7" category="paragraph"><block ref="9a1bdf4376c8448278cf38263e4da8c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">GPFS 기본</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">GPFS에 사용되는 노드 유형은 다음과 같습니다.</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">* Admin node. * 관리 명령에서 노드 간 통신에 사용하는 노드 이름을 포함하는 선택적 필드를 지정합니다. 예를 들어, 관리자 노드 mastr-51.netapp.com` 가 클러스터의 다른 모든 노드에 네트워크 검사를 전달할 수 있습니다.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">* 쿼럼 노드. * 쿼럼이 파생되는 노드 풀에 노드가 포함되어 있는지 여부를 확인합니다. 쿼럼 노드로 적어도 하나의 노드가 필요합니다.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">* Manager Node. * 노드가 파일 시스템 관리자 및 토큰 관리자를 선택할 수 있는 노드 풀의 일부인지 여부를 나타냅니다. 둘 이상의 노드를 관리자 노드로 정의하는 것이 좋습니다. 관리자로 지정하는 노드 수는 워크로드와 GPFS 서버 라이센스 수에 따라 다릅니다. 대규모 병렬 작업을 실행 중인 경우 웹 애플리케이션을 지원하는 4노드 클러스터보다 더 많은 관리자 노드가 필요할 수 있습니다.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">* NSD 서버. * GPFS와 함께 사용할 각 물리적 디스크를 준비하는 서버입니다.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">* 프로토콜 노드. * NFS를 통해 모든 SSH(Secure Shell) 프로토콜을 통해 GPFS 데이터를 직접 공유하는 노드입니다. 이 노드에는 GPFS 서버 라이센스가 필요합니다.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">GPFS, NFS 및 XCP의 운영 목록입니다</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">이 섹션은 GPFS를 만들고 GPFS를 NFS 내보내기로 내보낸 후 XCP를 사용하여 데이터를 전송하는 작업 목록을 제공합니다.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">GPFS 생성</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">GPFS를 만들려면 다음 단계를 완료하십시오.</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">서버 중 하나에서 Linux 버전에 대한 스펙트럼 스케일 데이터 액세스를 다운로드하고 설치합니다.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">모든 노드에 필수 구성 요소 패키지(예: Chef)를 설치하고 모든 노드에서 SELinux(Security-Enhanced Linux)를 비활성화합니다.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">설치 노드를 설정하고 클러스터 정의 파일에 관리 노드 및 GPFS 노드를 추가합니다.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">관리자 노드, 쿼럼 노드, NSD 서버 및 GPFS 노드를 추가합니다.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">GUI, 관리 및 GPFS 노드를 추가하고, 필요한 경우 추가 GUI 서버를 추가합니다.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">다른 GPFS 노드를 추가하고 모든 노드 목록을 확인하십시오.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">클러스터 정의 파일의 모든 GPFS 노드에 설정할 클러스터 이름, 프로필, 원격 셸 바이너리, 원격 파일 복사본 바이너리 및 포트 범위를 지정합니다.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">GPFS 구성 설정을 보고 추가 관리 노드를 추가합니다.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">데이터 수집을 비활성화하고 데이터 패키지를 IBM 지원 센터에 업로드합니다.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">NTP를 활성화하고 설치 전에 구성을 미리 확인합니다.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">NSD 디스크를 구성, 생성 및 확인합니다.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">GPFS를 생성합니다.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">GPFS를 마운트합니다.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">GPFS에 필요한 권한을 확인하고 제공하십시오.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">ddd 명령을 실행하여 GPFS 읽기 및 쓰기를 확인합니다.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">GPFS를 NFS로 내보냅니다</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">GPFS를 NFS로 내보내려면 다음 단계를 완료하십시오.</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">'/etc/exports' 파일을 통해 GPFS를 NFS로 내보냅니다.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">필요한 NFS 서버 패키지를 설치합니다.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">NFS 서비스를 시작합니다.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">GPFS에 파일을 나열하여 NFS 클라이언트를 검증합니다.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">NFS 클라이언트를 구성합니다</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">NFS 클라이언트를 구성하려면 다음 단계를 수행하십시오.</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">'/etc/exports' 파일을 통해 GPFS를 NFS로 내보냅니다.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">NFS 클라이언트 서비스를 시작합니다.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">NFS 클라이언트의 NFS 프로토콜을 통해 GPFS를 마운트합니다.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">NFS 마운트 폴더에서 GPFS 파일 목록을 검증합니다.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">XCP를 사용하여 GPFS에서 내보낸 NFS에서 NetApp NFS로 데이터를 이동하십시오.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">NFS 클라이언트에서 GPFS 파일을 검증합니다.</block>
  <block id="ae2b7fcf15ee142a2de2b3ba9573b414" category="inline-link-macro">다음: HDFS 및 MapR-FS에서 ONTAP NFS로.</block>
  <block id="545d9ad8cb56e65641eb4e8083301a39" category="paragraph"><block ref="545d9ad8cb56e65641eb4e8083301a39" category="inline-link-macro-rx"></block></block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">이 섹션은 GPFS를 구성하고 NetApp XCP를 사용하여 NFS로 데이터를 이동하는 데 필요한 세부 단계를 제공합니다.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">GPFS에서 NFS로 - 자세한 단계</block>
  <block id="b523cc107fd56956277d38d32b34c938" category="inline-link-macro">이전: 비즈니스 혜택.</block>
  <block id="c415260b3bf5ed05c37515a8e4e526f3" category="paragraph"><block ref="c415260b3bf5ed05c37515a8e4e526f3" category="inline-link-macro-rx"></block></block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">GPFS 구성</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">서버 중 하나에서 Linux용 Spectrum Scale 데이터 액세스를 다운로드하고 설치합니다.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">모든 노드에 필수 구성 요소 패키지(셰프 및 커널 헤더 포함)를 설치합니다.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">모든 노드에서 SELinux를 해제합니다.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">설치 노드를 설정합니다.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">클러스터 정의 파일에 관리 노드 및 GPFS 노드를 추가합니다.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">관리자 노드 및 GPFS 노드를 추가합니다.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">쿼럼 노드와 GPFS 노드를 추가합니다.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">NSD 서버 및 GPFS 노드를 추가합니다.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">GUI, 관리 및 GPFS 노드를 추가합니다.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">다른 GUI 서버를 추가합니다.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">다른 GPFS 노드를 추가합니다.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">모든 노드를 확인하고 나열합니다.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">클러스터 정의 파일에 클러스터 이름을 지정합니다.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">프로파일을 지정합니다.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">GPFS에서 사용할 원격 셸 바이너리를 지정하고 '-r 인수'를 사용합니다.</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">GPFS에서 사용할 원격 파일 복사 바이너리를 지정하고 '-rc 인수'를 사용하십시오.</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">모든 GPFS 노드에 설정할 포트 범위를 지정하고, '-e argument'를 사용한다.</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">GPFS 구성 설정을 봅니다.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">관리 노드를 추가합니다.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">NTP를 활성화합니다.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">설치하기 전에 구성을 미리 확인합니다.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">NSD 디스크를 구성합니다.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">NSD 디스크를 생성합니다.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">NSD 디스크 상태를 확인합니다.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">GPFS에 필요한 권한을 확인하고 제공하십시오.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">ddd 명령을 실행하여 GPFS 읽기 및 쓰기를 확인합니다.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">GPFS를 NFS로 내보내려면 다음 단계를 완료하십시오.</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">GPFS에 파일을 나열하여 NFS 클라이언트를 검증합니다.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">NFS 클라이언트를 구성합니다</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">NFS 클라이언트에 패키지를 설치합니다.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">NFS 마운트 폴더에서 GPFS 파일 목록을 검증합니다.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">XCP를 사용하여 GPFS로 내보낸 NFS에서 NetApp NFS로 데이터를 이동하십시오.</block>
  <block id="96a4b9abe25ad94a1d4ab8e0d2237ef6" category="inline-link-macro">다음: MapR-FS에서 ONTAP NFS로</block>
  <block id="742eb558b5f30d090f7c3ae58b2a554e" category="paragraph"><block ref="742eb558b5f30d090f7c3ae58b2a554e" category="inline-link-macro-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">이 섹션에서는 이 솔루션의 비즈니스 이점에 대해 설명합니다.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">비즈니스 이점</block>
  <block id="aaff67cd4222a3be5071cf651cab3d48" category="inline-link-macro">이전: HDFS 및 MapR-FS에서 ONTAP NFS로.</block>
  <block id="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="paragraph"><block ref="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="inline-link-macro-rx"></block></block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">데이터를 빅데이터 분석에서 AI로 이동하면 다음과 같은 이점이 있습니다.</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">서로 다른 Hadoop 파일 시스템과 GPFS에서 데이터를 유니파이드 NFS 스토리지 시스템으로 추출하는 기능</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">데이터 전송을 위한 Hadoop 통합 및 자동화 방식</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Hadoop 파일 시스템에서 데이터를 이동하는 데 필요한 라이브러리 개발 비용 절감</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">NIPAM을 사용하여 단일 데이터 소스에서 여러 네트워크 인터페이스의 총 처리량을 통해 최대 성능을 발휘합니다</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">데이터 전송을 위한 예약 방식 및 온디맨드 방식</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">ONTAP 데이터 관리 소프트웨어를 사용하여 유니파이드 NFS 데이터에 대한 스토리지 효율성 및 엔터프라이즈 관리 기능을 제공합니다</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">데이터 전송을 위한 Hadoop 방식을 사용하면 데이터 이동 비용이 전혀 들지 않습니다</block>
  <block id="a3b97091403bff3b38419087acb1c19e" category="inline-link-macro">다음: GPFS에서 NFS로 - 세부 단계.</block>
  <block id="5e982872ec65785f5d685290b9c40026" category="paragraph"><block ref="5e982872ec65785f5d685290b9c40026" category="inline-link-macro-rx"></block></block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">이 섹션에서는 NetApp XCP를 사용하여 MapR-FS 데이터를 ONTAP NFS로 이동하는 데 필요한 자세한 단계를 제공합니다.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS에서 ONTAP NFS로</block>
  <block id="59b0eb4059face89ab060ea59984c8a7" category="inline-link-macro">이전: GPFS에서 NFS로 - 세부 단계.</block>
  <block id="13f1dc977877024b0f36272f1af2b238" category="paragraph"><block ref="13f1dc977877024b0f36272f1af2b238" category="inline-link-macro-rx"></block></block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">각 MapR 노드에 대해 LUN 3개를 프로비저닝하고 모든 MapR 노드에 대한 LUN 소유권을 제공합니다.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">설치 중에 MapR-FS에 사용되는 MapR 클러스터 디스크에 새로 추가된 LUN을 선택합니다.</block>
  <block id="f7dc1a091cd04b392f9a99c5390b9ce2" category="inline-link">MapR 6.1 문서</block>
  <block id="24cb5309ea8c5a7c3244adf133110ecf" category="list-text">에 따라 MapR 클러스터를 설치합니다<block ref="a38d60fa0425a18b5925139ceca806ea" category="inline-link-rx"></block>.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Hadoop Jar xxx와 같은 MapReduce 명령을 사용하여 기본 Hadoop 작업을 확인합니다.</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">고객 데이터를 MapR-FS에 유지 예를 들어, Teragen을 사용하여 MapR-FS에서 약 테라바이트의 샘플 데이터를 생성했습니다.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">MapR-FS를 NFS 내보내기로 구성합니다.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">모든 MapR 노드에서 nlockmgr 서비스를 사용하지 않도록 설정합니다.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">'/opt/mMapR/conf/exports' 파일의 모든 MapR 노드에 MapR-FS에서 특정 폴더를 내보냅니다. 하위 폴더를 내보낼 때 다른 권한이 있는 상위 폴더를 내보내지 마십시오.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">MapR-FS NFS 서비스를 새로 고칩니다.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">MapR 클러스터의 특정 서버 또는 서버 세트에 가상 IP 범위를 할당합니다. 그런 다음 MapR 클러스터는 NFS 데이터 액세스를 위해 특정 서버에 IP를 할당합니다. IP를 통해 고가용성을 구현할 수 있습니다. 즉, 특정 IP를 사용하는 서버 또는 네트워크에 장애가 발생할 경우 IP 범위의 다음 IP를 NFS 액세스에 사용할 수 있습니다.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">모든 MapR 노드에서 NFS 액세스를 제공하려면 각 서버에 가상 IP 세트를 할당하고 NFS 데이터 액세스를 위해 각 MapR 노드의 리소스를 사용할 수 있습니다.</block>
  <block id="fa6899b17d5e71a360316c355d34c8b3" category="paragraph"><block ref="fa6899b17d5e71a360316c355d34c8b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb6de965ede92bf8bb036bb8fea6eba" category="paragraph"><block ref="8cb6de965ede92bf8bb036bb8fea6eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="031b138609c608ed553a74b2a1c439e1" category="paragraph"><block ref="031b138609c608ed553a74b2a1c439e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">각 MapR 노드에 할당된 가상 IP를 확인하고 이를 NFS 데이터 액세스에 사용하십시오.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">NFS 작업을 확인하기 위해 할당된 가상 IP를 사용하여 NFS 내보내기 MapR-FS를 마운트합니다. 하지만 NetApp XCP를 사용하여 데이터를 전송하는 경우 이 단계가 필요하지 않습니다.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">MapR-FS NFS 게이트웨이에서 ONTAP NFS로 데이터를 전송하도록 NetApp XCP를 구성합니다.</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">xCP에 대한 카탈로그 위치를 구성합니다.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">라이센스 파일을 '/opt/netapp/xFiles/xCP/'에 복사합니다.</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">xCP activate 명령을 사용하여 xCP를 활성화합니다.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">NFS 내보내기에 대한 소스를 확인합니다.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">여러 소스 IP 및 여러 대상 IP(ONTAP LIF)에서 여러 MapR 노드에서 XCP를 사용하여 데이터를 전송합니다.</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">스토리지 컨트롤러의 로드 분산을 확인합니다.</block>
  <block id="93a2605b6bf89fdb9970a6dbc77dee03" category="paragraph"><block ref="93a2605b6bf89fdb9970a6dbc77dee03" category="inline-link-macro-rx"></block></block>
  <block id="b446e9930ab89aa25e7b422c4c23d83f" category="inline-link-macro">이전: MapR-FS에서 ONTAP NFS로</block>
  <block id="185bcaf9470b338d9a2b58870d7bd2bd" category="paragraph"><block ref="185bcaf9470b338d9a2b58870d7bd2bd" category="inline-link-macro-rx"></block></block>
  <block id="ca79886b03835c933143f8eb102ac932" category="list-text">NetApp 데이터 이동 없는 분석 모듈 모범 사례</block>
  <block id="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link"><block ref="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link-rx"></block></block>
  <block id="026671d583a546d6b62291e018f78bf7" category="paragraph"><block ref="026671d583a546d6b62291e018f78bf7" category="inline-link-rx"></block></block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">NetApp FlexGroup 볼륨 모범 사례 및 구현 가이드 를 참조하십시오</block>
  <block id="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link"><block ref="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link-rx"></block></block>
  <block id="f473bc55fb079f0338493530316efc6f" category="paragraph"><block ref="f473bc55fb079f0338493530316efc6f" category="inline-link-rx"></block></block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">버전 3.0</block>
  <block id="b9365bb9132d1eb8770275a763fc5d69" category="cell">2022년 1월</block>
  <block id="e4005842db89b4abb778385f9a8a758f" category="cell">NetApp XCP를 사용하여 HDFS 및 MapR-FS에서 NFS로 데이터를 직접 이동합니다.</block>
  <block id="d835981d77534f5f20446d4648ad7e5b" category="cell">2020년 1월</block>
  <block id="637f51ce71f8f8cadc4b75dfda96d45c" category="cell">xCP가 기본 Data Mover로 포함되어 있습니다. NFS 및 GPFS에 MapR-FS를 NFS 데이터 전송에 추가.</block>
  <block id="a10ba827ae758dee0e50d44366fd3d6d" category="cell">2018년 11월</block>
  <block id="4b3608ccf8a7154699127b487cc49627" category="paragraph">이 문서에서는 인공 지능(AI) 워크플로우에 사용할 수 있도록 빅데이터 분석 및 고성능 컴퓨팅(HPC) 시스템에서 데이터를 이동하는 방법에 대해 설명합니다. AI는 일반적으로 NFS 내보내기를 통해 NFS 데이터를 처리합니다. 하지만 AI 데이터를 빅데이터 분석 및 고성능 컴퓨팅(HPC) 플랫폼에 저장할 수 있습니다. HDFS(Hadoop Distributed File System), Blob(Binary Large Object), S3 스토리지 또는 IBM GPFS(General Parallel File System)가 여기에 해당합니다. 이 문서에서는 Hadoop 네이티브 명령, NetApp In-Place Analytics Module(NIPAM), NetApp XCP를 사용하여 빅데이터 분석 플랫폼과 GPFS에서 NFS로 데이터를 이동하는 방법에 대해 설명합니다. 또한 이 문서에서는 빅데이터 및 HPC에서 AI로 데이터를 이동할 때의 비즈니스 이점에 대해 설명합니다.</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">이 페이지에서는 AI 운영을 위한 빅데이터 분석의 데이터에 액세스하려고 할 때 고객이 직면할 수 있는 과제에 대해 설명합니다.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="doc">고객의 당면 과제</block>
  <block id="14fd125cf7cc7e6f58e0a07d30ecda87" category="paragraph"><block ref="14fd125cf7cc7e6f58e0a07d30ecda87" category="inline-link-macro-rx"></block></block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">AI 운영을 위한 빅데이터 분석에서 데이터에 액세스하려고 할 때 고객이 다음과 같은 과제에 직면할 수 있습니다.</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">고객 데이터가 데이터 레이크 저장소에 있습니다. 데이터 레이크는 정형, 비정형, 반정형, 로그, 머신 간 데이터 등 다양한 유형의 데이터를 포함할 수 있습니다. 이러한 모든 데이터 유형은 AI 시스템에서 처리해야 합니다.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">AI는 Hadoop 파일 시스템과 호환되지 않습니다. 일반적인 AI 아키텍처는 HDFS 및 HCFS 데이터에 직접 액세스할 수 없으며, 이 데이터는 AI에 대해 이해할 수 있는 파일 시스템(NFS)으로 이동되어야 합니다.</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">데이터 레이크 데이터를 AI로 이동하는 작업에는 일반적으로 특수 프로세스가 필요합니다. 데이터 레이크의 데이터 양은 매우 클 수 있습니다. 고객은 AI 시스템으로 데이터를 이동할 수 있는 효율적이고 높은 처리량과 비용 효율적인 방법을 가지고 있어야 합니다.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">데이터를 동기화하는 중입니다. 고객이 빅데이터 플랫폼과 AI 간의 데이터를 동기화하려는 경우 AI를 통해 처리된 데이터를 분석 처리에 빅데이터와 함께 사용할 수 있습니다.</block>
  <block id="02c553e123c56e4cba5728b7e83bb80b" category="inline-link-macro">다음: Data Mover 솔루션.</block>
  <block id="205e8a4d3382497ff57947382c577faa" category="paragraph"><block ref="205e8a4d3382497ff57947382c577faa" category="inline-link-macro-rx"></block></block>
  <block id="2ea9ecb649c5974bc03036a15d95f5bf" category="summary">AI용 Data Mover 솔루션은 AI 작업에서 Hadoop 데이터를 처리해야 하는 고객의 요구사항을 기반으로 합니다. NetApp은 NIPAM을 사용하여 HDFS에서 NFS로 데이터를 이동합니다. 한 사용 사례에서 고객은 사내 NFS로 데이터를 이동해야 했고, 또 다른 고객은 클라우드의 GPU 클라우드 인스턴스에서 데이터를 처리하기 위해 Windows Azure Storage Blob에서 Cloud Volumes Service로 데이터를 이동해야 했습니다.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">AI용 Data Mover 솔루션</block>
  <block id="2337521acd1f46c410245430b841caa8" category="inline-link-macro">이전: Data Mover 솔루션</block>
  <block id="ee202fa3d5706f12ab6d57e9cb4b4cba" category="paragraph"><block ref="ee202fa3d5706f12ab6d57e9cb4b4cba" category="inline-link-macro-rx"></block></block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">다음 다이어그램에서는 Data Mover 솔루션 세부 정보를 보여 줍니다.</block>
  <block id="27f83ed51cc554467134084d77b0e050" category="paragraph"><block ref="27f83ed51cc554467134084d77b0e050" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Data Mover 솔루션을 구축하려면 다음 단계가 필요합니다.</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN은 HDFS를 제공하고, NAS는 NIPAM을 통해 NFS 볼륨을 운영 데이터 레이크 클러스터에 제공합니다.</block>
  <block id="0fad6dd0225bf5a5e9c668c30ea5d38a" category="list-text">고객의 데이터는 HDFS 및 NFS에 있습니다. NFS 데이터는 빅데이터 분석 및 AI 운영에 사용되는 다른 애플리케이션의 운영 데이터일 수 있습니다.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">NetApp FlexClone 기술은 운영 NFS 볼륨의 클론을 생성하여 사내 AI 클러스터에 프로비저닝합니다.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">HDFS SAN LUN의 데이터는 NIPAM 및 "Hadoop distcp" 명령을 사용하여 NFS 볼륨으로 복제됩니다. NIPAM은 여러 네트워크 인터페이스의 대역폭을 사용하여 데이터를 전송합니다. 이 프로세스는 더 많은 데이터를 전송할 수 있도록 데이터 복사 시간을 줄입니다.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">두 NFS 볼륨 모두 AI 운영을 위해 AI 클러스터에 프로비저닝됩니다.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">클라우드의 GPU로 사내 NFS 데이터를 처리하기 위해 NFS 볼륨은 NetApp SnapMirror 기술을 사용해 NPS(NetApp Private Storage)로 미러링되고 GPU를 위한 클라우드 서비스 공급자에 마운트됩니다.</block>
  <block id="c590e653cde69438d43731b18edd533c" category="list-text">고객은 클라우드 서비스 공급자의 GPU에서 EC2/EMR, HDInsight 또는 DataProc 서비스의 데이터를 처리하려고 합니다. Hadoop Data Mover는 데이터를 Hadoop 서비스에서 NIPAM 및 'Hadoop distcp' 명령을 사용하여 Cloud Volumes Services로 이동합니다.</block>
  <block id="8cae7d7989a25f83bf9df9952b16ed2b" category="list-text">Cloud Volumes Service 데이터는 NFS 프로토콜을 통해 AI에 프로비저닝됩니다.AI를 통해 처리되는 데이터는 NIPAM, SnapMirror 및 NPS를 통해 NVIDIA 클러스터와 함께 사내 위치에서 빅데이터 분석을 위한 데이터가 전송될 수 있습니다.</block>
  <block id="980894bd0921c687decdf218e89107e2" category="paragraph">이 시나리오에서는 고객이 사내의 NetApp 스토리지 컨트롤러에서 AI 처리를 위해 필요한 원격 위치의 NAS 시스템에 대용량 파일 개수 데이터가 있습니다. 이 시나리오에서는 XCP 마이그레이션 도구를 사용하여 데이터를 더 빠른 속도로 마이그레이션하는 것이 좋습니다.</block>
  <block id="002cfe6c68deff9c2fcb4fbb3820a5ff" category="paragraph">하이브리드 사용 사례 고객은 Cloud Sync를 사용하여 NFS, CIFS, S3 데이터의 사내 데이터를 클라우드로 마이그레이션할 수 있고, 그 반대로도 NVIDIA 클러스터의 GPU를 사용하여 AI를 처리할 수 있습니다. Cloud Sync와 XCP 마이그레이션 툴은 모두 NFS 데이터를 NetApp ONTAP NFS로 마이그레이션하는 데 사용됩니다.</block>
  <block id="22033f5439b399254e73f6f3588b9b9e" category="inline-link-macro">다음: GPFS에서 NetApp ONTAP NFS로.</block>
  <block id="f56cb05715de107bd001dd11a41b0cf6" category="paragraph"><block ref="f56cb05715de107bd001dd11a41b0cf6" category="inline-link-macro-rx"></block></block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">빅데이터 클러스터에서 데이터는 MapR-FS, Windows Azure Storage Blob, S3 또는 Google 파일 시스템과 같은 HDFS 또는 HCFS에 저장됩니다. 우리는 소스에서 Hadoop distcp 명령을 사용하여 NIPAM의 도움을 받아 HDFS, MapR-FS 및 S3를 NetApp ONTAP NFS로 데이터를 복사하는 소스로 사용하여 테스트를 수행했습니다.</block>
  <block id="6d1963202b436934d6b74acc8232dc94" category="inline-link-macro">이전: 고객의 당면 과제.</block>
  <block id="501ee0e125dd4449de2b29015fab6f3e" category="paragraph"><block ref="501ee0e125dd4449de2b29015fab6f3e" category="inline-link-macro-rx"></block></block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">빅데이터 클러스터에서 데이터는 MapR-FS, Windows Azure Storage Blob, S3 또는 Google 파일 시스템과 같은 HDFS 또는 HCFS에 저장됩니다. 우리는 소스에서 'Hadoop distcp' 명령을 사용하여 NIPAM의 도움을 받아 HDFS, MapR-FS 및 S3를 NetApp ONTAP NFS로 데이터를 복사하는 소스로 사용하여 테스트를 수행했습니다.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">다음 다이어그램에서는 HDFS 스토리지를 사용하여 실행되는 Spark 클러스터에서 NetApp ONTAP NFS 볼륨으로 이동하는 일반적인 데이터 이동을 보여 줍니다. 이렇게 하면 NVIDIA에서 AI 작업을 처리할 수 있습니다.</block>
  <block id="d824b1bb9493b5a6c5a2e74871468633" category="paragraph"><block ref="d824b1bb9493b5a6c5a2e74871468633" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">Hadoop distcp 명령은 MapReduce 프로그램을 사용하여 데이터를 복사합니다. NIPAM은 데이터를 복사할 때 MapReduce와 함께 Hadoop 클러스터의 드라이버 역할을 합니다. NIPAM은 단일 내보내기를 위해 여러 네트워크 인터페이스에 로드를 분산할 수 있습니다. 이 프로세스는 HDFS 또는 HCFS에서 NFS로 데이터를 복사할 때 여러 네트워크 인터페이스에 데이터를 분산하여 네트워크 처리량을 극대화합니다.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM은 MapR에서 지원 또는 인증되지 않았습니다.</block>
  <block id="e68fb74f51fcafb391476c585b1e434d" category="inline-link-macro">다음은 AI용 Data Mover 솔루션입니다.</block>
  <block id="1f4c259e626baca3c7947e6f3db323d4" category="paragraph"><block ref="1f4c259e626baca3c7947e6f3db323d4" category="inline-link-macro-rx"></block></block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">이 문서에서는 NetApp XCP 및 NIPAM을 사용하여 빅데이터 분석 데이터와 HPC 데이터를 AI로 이동하는 방법에 대해 설명합니다. 또한 빅데이터 및 HPC에서 AI로 데이터를 이동하면 얻을 수 있는 비즈니스 이점에 대해서도 설명합니다.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732: 인공 지능에 대한 빅 데이터 분석 데이터</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">이 문서에서는 빅데이터 분석 데이터와 HPC 데이터를 AI로 이동하는 방법에 대해 설명합니다. AI는 NFS 엑스포트를 통해 NFS 데이터를 처리하는 한편, 고객은 HDFS, Blob 또는 S3 스토리지와 같은 빅데이터 분석 플랫폼과 GPFS와 같은 HPC 플랫폼에 AI 데이터를 저장할 수 있습니다. 이 문서에서는 NetApp XCP 및 NIPAM을 사용하여 빅데이터 분석 데이터와 HPC 데이터를 AI로 이동하는 방법에 대해 설명합니다. 또한 빅데이터 및 HPC에서 AI로 데이터를 이동하면 얻을 수 있는 비즈니스 이점에 대해서도 설명합니다.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">개념 및 구성 요소</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">빅데이터 분석 스토리지</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">빅데이터 분석은 HDFS를 위한 주요 스토리지 제공업체입니다. 고객은 종종 Windows Azure Blob Storage, MapR-FS(MapR-FS) 및 S3 오브젝트 스토리지와 같은 HCFS(Hadoop 호환 파일 시스템)를 사용합니다.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">일반 병렬 파일 시스템입니다</block>
  <block id="432f31a1b9dc5a8ef1f048ea3f4f98c8" category="paragraph">IBM의 GPFS는 HDFS에 대한 대안을 제공하는 엔터프라이즈 파일 시스템입니다. GPFS는 애플리케이션에 블록 크기 및 복제 레이아웃을 결정할 수 있는 유연성을 제공하여 우수한 성능과 효율성을 제공합니다.</block>
  <block id="2aff401779cc49866458a642f15c0181" category="inline-link">TR-4382: NetApp 데이터 이동 없는 분석 모듈.</block>
  <block id="ae1165a7ed0006d2dae65ea849898810" category="paragraph">NetApp NIPAM(In-Place Analytics Module)은 NFS 데이터에 액세스하기 위한 Hadoop 클러스터의 역할을 합니다. 이 스트림에는 연결 풀, NFS InputStream, 파일 핸들 캐시 및 NFS OutputStream의 네 가지 구성 요소가 있습니다. 자세한 내용은 을 참조하십시오<block ref="aedae5b2590b798973be1ab298f44ab7" category="inline-link-rx"></block></block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Hadoop 분산 복제본</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy(DistCp)는 대규모 클러스터 간 및 클러스터 내 대처 작업에 사용되는 분산 복사 툴입니다. 이 툴은 데이터 배포, 오류 처리 및 보고를 위해 MapReduce를 사용합니다. 파일 및 디렉토리 목록을 확장하고 소스 목록에서 데이터를 복사하기 위한 작업을 매핑하기 위해 파일 및 디렉토리 입력을 수행합니다. 아래 이미지는 HDFS 및 비 HDFS의 DistCp 작업을 보여 줍니다.</block>
  <block id="1a76b3e0f1199267d461c961d30d07a5" category="paragraph"><block ref="1a76b3e0f1199267d461c961d30d07a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp는 추가 드라이버를 사용하지 않고 두 HDFS 시스템 간에 데이터를 이동합니다. NetApp은 비 HDFS 시스템용 드라이버를 제공합니다. NFS 대상의 경우 NIPAM은 데이터를 복사할 때 Hadoop DistCp가 NFS 대상과 통신하는 데 사용하는 데이터를 복사하는 드라이버를 제공합니다.</block>
  <block id="05fc55cae9e8b2a7fb40e978e4971707" category="paragraph">NetApp Cloud Volumes Service는 최고의 성능을 제공하는 클라우드 네이티브 파일 서비스입니다. 고객은 이 서비스를 통해 신속하게 리소스를 가동하고 속도를 낮추며 NetApp 기능을 사용하여 생산성을 높이고 직원 다운타임을 줄임으로써 출시 기간을 단축할 수 있습니다. Cloud Volumes Service는 전체 데이터 센터 설치 공간을 줄이고 기본 퍼블릭 클라우드 스토리지를 덜 사용하기 때문에 재해 복구 및 클라우드 백업을 위한 최적의 대안이 됩니다.</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP는 NetApp 제품 간 및 NetApp 간 데이터 마이그레이션을 빠르고 안정적으로 수행할 수 있는 클라이언트 소프트웨어입니다. 이 툴은 대량의 비정형 NAS 데이터를 NAS 시스템에서 NetApp 스토리지 컨트롤러로 복사하도록 설계되었습니다. xCP 마이그레이션 툴은 데이터 마이그레이션, 파일 또는 디렉토리 목록, 공간 보고 등 여러 요청을 병렬로 처리할 수 있는 멀티코어 다중 채널 I/O 스트리밍 엔진을 사용합니다. 기본 NetApp 데이터 마이그레이션 툴입니다. XCP를 사용하여 Hadoop 클러스터 및 HPC에서 NetApp NFS 스토리지로 데이터를 복사할 수 있습니다. 아래 다이어그램에서는 XCP를 사용하여 Hadoop 및 HPC 클러스터에서 NetApp NFS 볼륨으로 데이터를 전송하는 방법을 보여 줍니다.</block>
  <block id="cd7e68aa30250a331c260fee49ff230e" category="paragraph"><block ref="cd7e68aa30250a331c260fee49ff230e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bce96270b79327e5daf4c0745d66023" category="paragraph">NetApp Cloud Sync는 사내 스토리지와 클라우드 스토리지 간에 NFS, S3 및 CIFS 데이터를 원활하고 안전하게 전송 및 동기화하는 하이브리드 데이터 복제 서비스형 소프트웨어입니다. 이 소프트웨어는 데이터 마이그레이션, 아카이빙, 협업, 분석 등에 사용됩니다. 데이터가 전송된 후 Cloud Sync는 소스와 대상 간의 데이터를 지속적으로 동기화합니다. 그런 다음 델타를 전송합니다. 또한 자체 네트워크, 클라우드 또는 사내 내의 데이터를 보호합니다. 이 소프트웨어는 비용 효율적인 솔루션을 제공하고 데이터 전송을 위한 모니터링 및 보고 기능을 제공하는 용량제 모델을 기반으로 합니다.</block>
  <block id="cbba30a09e75669ecb5b3b2d83a25284" category="inline-link-macro">다음은 고객의 당면 과제입니다.</block>
  <block id="63aa417c654afafebdbdfcaf7a13c8b6" category="paragraph"><block ref="63aa417c654afafebdbdfcaf7a13c8b6" category="inline-link-macro-rx"></block></block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">이 솔루션을 위해 NetApp은 데이터 레이크(HDFS) 및 MapR 클러스터 데이터에서 ONTAP NFS로 데이터 마이그레이션을 검증했습니다. MapR-FS 및 HDFS에 데이터가 상주했습니다. NetApp XCP는 HDFS 및 MapR-FS와 같은 분산 파일 시스템에서 ONTAP NFS로 데이터를 직접 마이그레이션하는 새로운 기능을 소개했습니다.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS 및 MapR-FS를 ONTAP NFS로 설정합니다</block>
  <block id="9577f33e5dfe124ba394a5c90a123928" category="inline-link-macro">이전: GPFS에서 NetApp ONTAP NFS로,</block>
  <block id="a503c5d00affd8b681837e8b44490492" category="paragraph"><block ref="a503c5d00affd8b681837e8b44490492" category="inline-link-macro-rx"></block></block>
  <block id="9c02792070008c1748647d8bdbe24432" category="paragraph">이 솔루션을 위해 NetApp은 데이터 레이크(HDFS) 및 MapR 클러스터 데이터에서 ONTAP NFS로 데이터 마이그레이션을 검증했습니다. MapR-FS 및 HDFS에 데이터가 상주했습니다. NetApp XCP는 HDFS 및 MapR-FS와 같은 분산 파일 시스템에서 ONTAP NFS로 데이터를 직접 마이그레이션하는 새로운 기능을 소개했습니다. xCP는 비동기 스레드 및 HDFS C API 호출을 사용하여 MapR-FS 및 HDFS에서 데이터를 통신 및 전송합니다. 아래 그림은 데이터 레이크(HDFS) 및 MapR-FS에서 ONTAP NFS로 데이터 마이그레이션을 보여 줍니다. 이 새로운 기능을 사용하면 소스를 NFS 공유로 내보낼 필요가 없습니다.</block>
  <block id="4581f9b32af32647aa31b2f9d57f6f1f" category="paragraph"><block ref="4581f9b32af32647aa31b2f9d57f6f1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">고객이 HDFS 및 MapR-FS에서 NFS로 이동하는 이유는 무엇입니까?</block>
  <block id="b075c8e6a9009d582333c59e237e3646" category="paragraph">Cloudera 및 Hortonworks와 같은 Hadoop 배포 대부분은 HDFS 및 MapR 배포판과 같은 자체 파일 시스템 MapR-FS를 사용하여 데이터를 저장합니다. HDFS 및 MapR-FS 데이터는 머신 러닝(ML) 및 딥 러닝(DL)에 활용할 수 있는 데이터 과학자에게 중요한 통찰력을 제공합니다. HDFS 및 MapR-FS의 데이터는 공유되지 않으며 다른 애플리케이션에서 사용할 수 없습니다. 고객은 공유 데이터, 특히 고객의 중요한 데이터가 여러 애플리케이션에서 사용되는 은행 부문에서 데이터를 찾고 있습니다. 최신 버전의 Hadoop(3.x 이상)은 NFS 데이터 소스를 지원하며, 타사 소프트웨어를 추가하지 않고도 이 소스에 액세스할 수 있습니다. 새로운 NetApp XCP 기능을 사용하면 데이터를 HDFS 및 MapR-FS에서 NetApp NFS로 직접 이동하여 여러 애플리케이션에 액세스할 수 있습니다</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">12개의 MapR 노드 및 4개의 NFS 서버를 통해 초기 성능 테스트를 위해 AWS(Amazon Web Services)에서 MapR-FS의 데이터를 NFS로 전송하기 위한 테스트가 완료되었습니다.</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">크기</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">메모리</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">네트워크</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS 서버</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xLarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8x 7500 NVMe SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapR 노드</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xLarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4x 7500 NVMe SSD</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">초기 테스트에 따르면 20Gbps의 처리량을 확보했으며 일일 2PB의 데이터를 전송할 수 있었습니다.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link">TR-4863: NetApp XCP-Data Mover, 파일 마이그레이션 및 분석에 대한 모범 사례 지침 - 4863</block>
  <block id="6371d61614d0beaedb75e85d2c297d8f" category="paragraph">HDFS를 NFS로 내보내지 않고 HDFS 데이터 마이그레이션에 대한 자세한 내용은 의 "배포 단계 - NAS" 섹션을 참조하십시오<block ref="6a602f6a965c96a94215a45f0077e771" category="inline-link-rx"></block>.</block>
  <block id="aa722a0d50c9e3bfe81a7128f0e649d7" category="inline-link-macro">다음: 비즈니스 혜택.</block>
  <block id="4e39bc17db35d21d84b6fb1e9786fdb5" category="paragraph"><block ref="4e39bc17db35d21d84b6fb1e9786fdb5" category="inline-link-macro-rx"></block></block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">인공 지능에 빅 데이터 분석 데이터 활용</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS에서 NFS로 - 자세한 단계</block>
  <block id="a6cac691940e90bb16e306f5d4122c53" category="cell">2021년 3월 1일</block>
  <block id="75afdb5cd8c025ed0681bdb302fcdcda" category="cell">NVA-1160: OperatorHub 및 Ansible을 통해 Astra Control Center 설치 에 새 섹션 추가</block>
  <block id="593fdc7a2167cd2ada3e71219ceb0ecb" category="paragraph">자세한 내용은 Astra Trident 웹 사이트를 참조하십시오<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="3d930ae98e9d9fc9a418d6b8e5e5639f" category="cell">21.12.60</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="2bb7e89d50aed884078c4b7857f5bb39" category="cell">4.6 EUS, 4.7, 4.8</block>
  <block id="1e90637438eb06672159d2998d220e86" category="open-title">OperatorHub 사용</block>
  <block id="bff0144772c74d96da07b6ccefb79f96" category="list-text">NetApp Support 사이트에 로그인하여 NetApp Astra Control Center의 최신 버전을 다운로드하십시오. 그렇게 하려면 NetApp 계정에 연결된 라이센스가 필요합니다. tarball을 다운로드한 후 관리자 워크스테이션으로 전송합니다.</block>
  <block id="baac643870c95006b4243d078606a15d" category="list-text">설치를 시작하기 전에 Astra Control Center 이미지를 이미지 레지스트리로 밀어 넣으십시오. 이 단계에서는 Docker 또는 Podman을 선택하여 이러한 작업을 수행할 수 있습니다. 두 가지 모두에 대한 지침이 제공됩니다.</block>
  <block id="455cbd59356abfa16dcf7666d4ae6c2b" category="list-title">팟맨</block>
  <block id="ee9b41d8a22021826def077c661525f4" category="list-text">공개적으로 신뢰할 수 없는 개인 이미지 레지스트리를 사용하는 경우 이미지 레지스트리 TLS 인증서를 OpenShift 노드에 업로드합니다. 이렇게 하려면 TLS 인증서를 사용하여 OpenShift-config 네임스페이스에 configmap을 만들고 이를 클러스터 이미지 구성에 패치하여 인증서를 신뢰할 수 있도록 합니다.</block>
  <block id="9c656c969a87783fcf4b94b721f34bc9" category="list-text">Astra Control Center의 "NetApp-acc-operator" 네임스페이스를 생성합니다.</block>
  <block id="788e8355bdd3a21f3a9017a0610940f4" category="list-text">클러스터 관리자 권한으로 Red Hat OpenShift GUI 콘솔에 로그인합니다.</block>
  <block id="3d68b5654b778f026ac691bc6ed70cc5" category="list-text">Operators &gt; OperatorHub 로 이동하여 Astra 를 검색합니다.</block>
  <block id="dc7add750562c445f72d8d016a79ae29" category="list-text">'NetApp-acc-operator' 타일을 선택하고 '설치'를 클릭합니다.</block>
  <block id="c80be3093b470ca8092538e58a261952" category="image-alt">ACC 운전자 타일</block>
  <block id="c65c283737dc37cea2358a91588ff272" category="list-text">Install Operator(사용자 설치) 화면에서 모든 기본 매개변수를 그대로 적용하고 Install(설치)을 클릭합니다.</block>
  <block id="3677d31e24a1853c961f3f1a9a39a1d6" category="image-alt">ACC 운전자 세부 정보</block>
  <block id="ba14525c4ccc9b2f692d062104885b19" category="image-alt">ACC 작업자가 설치를 기다립니다</block>
  <block id="fea3120ff933c367a5882d58dbbe8a08" category="list-text">운용자 설치가 성공하면 View Operator를 클릭합니다.</block>
  <block id="a573acc0621ea72a06ce987a341768bf" category="image-alt">ACC 운전자 설치가 완료되었습니다</block>
  <block id="f99196bf6b988223fab800f28cf0323c" category="list-text">그런 다음 운용자의 Astra Control Center 타일에서 Create Instance를 클릭한다.</block>
  <block id="11f7c569d04eecd142ba5989efcc2da3" category="image-alt">ACC 인스턴스 생성</block>
  <block id="02780e148f03f25db76204c23985d753" category="list-text">Create AstraControlCenter 양식 필드에 내용을 입력하고 Create를 클릭합니다.</block>
  <block id="e31f3b85c5179d88bcf0629842c5342f" category="list-text">필요한 경우 Astra Control Center 인스턴스 이름을 편집합니다.</block>
  <block id="3336a2124154da151aecfe1809d7c821" category="list-text">선택적으로 자동 지원을 활성화하거나 비활성화합니다. 자동 지원 기능을 유지하는 것이 좋습니다.</block>
  <block id="14ddbb7fd85c2907073b06492b95191b" category="list-text">Astra Control Center의 FQDN을 입력합니다.</block>
  <block id="fbcd656fecc902b1994e346dc0627266" category="list-text">Astra Control Center 버전을 입력합니다. 최신 버전이 기본적으로 표시됩니다.</block>
  <block id="311a20c50b8e2d72cf9b31eb6339bff4" category="list-text">Astra Control Center의 계정 이름과 이름, 성, 이메일 주소 등의 관리자 세부 정보를 입력합니다.</block>
  <block id="163e6534daeb1cbd7c56b20a9477802f" category="list-text">볼륨 재확보 정책을 입력합니다. 기본값은 유지입니다.</block>
  <block id="5863d7f52b409374d0d80b1bcbba68fd" category="list-text">이미지 레지스트리에서 이미지를 레지스트리로 푸시하는 동안 레지스트리 FQDN과 조직 이름을 입력합니다(이 예에서는 "astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra`).</block>
  <block id="95279718d2829cd5ed7772d6f0a77ca9" category="list-text">인증이 필요한 레지스트리를 사용하는 경우 이미지 레지스트리 섹션에 암호 이름을 입력합니다.</block>
  <block id="b8f9ae819a2d6559f55aed837fdc2a47" category="list-text">Astra Control Center 리소스 제한에 대한 확장 옵션을 구성합니다.</block>
  <block id="3b489b9fd690a8cdf710454d0ccb5288" category="list-text">기본이 아닌 저장 클래스에 PVC를 배치하려면 보관 클래스 이름을 입력합니다.</block>
  <block id="6b9265a82fa5bd326052ec55e040a54a" category="list-text">CRD 처리 기본 설정을 정의합니다.</block>
  <block id="90aa5928482975bc6ff56f0eaf052451" category="open-title">자동화 [Ansible]</block>
  <block id="3937de5e196f2d9062772804e96695b6" category="paragraph">21.12.60 Astra Control Center를 구축하기 위해 Ansible 플레이북을 사용하려면 Ansible이 설치된 Ubuntu/RHEL 시스템이 필요합니다. 설명된 절차를 따르십시오<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Ubuntu 및 이에 대한<block ref="1988083261a6d1d93abe49ae6e6435ae" category="inline-link-rx"></block> RHEL의 경우</block>
  <block id="b8571b33af3335fed61ab0d7985d007f" category="list-text">Ansible 콘텐츠를 호스팅하는 GitHub 저장소의 클론을 생성합니다.</block>
  <block id="5ed95667cae604c0ddee2dbf04f423fe" category="list-text">NetApp Support 사이트에 로그인하여 NetApp Astra Control Center의 최신 버전을 다운로드하십시오. 그렇게 하려면 NetApp 계정에 연결된 라이센스가 필요합니다. 타볼을 다운로드한 후 워크스테이션으로 전송합니다.</block>
  <block id="6238d4091e12ffa6643c0dc68d72ceab" category="list-text">Astra Control Center가 설치될 OpenShift 클러스터에 대한 관리자 액세스 권한이 있는 kubecononfig 파일을 만들거나 얻습니다.</block>
  <block id="b736c713f352ab43e7543fda4589e96f" category="list-text">디렉토리를 na_Astra_control_suite로 변경합니다.</block>
  <block id="4f31682e7040024757006eed6ba0344a" category="list-text">VAR/VAR.yml 파일을 편집하고 변수를 필수 정보로 채웁니다.</block>
  <block id="084d6dacfbcd3e90106780f3cb2699fa" category="list-text">Playbook을 실행하여 Astra Control Center를 구축합니다. 특정 구성에 대한 루트 권한이 Playbook에 필요합니다.</block>
  <block id="1b9af2e27b0d249822ccdef7fe087cfc" category="paragraph">따라서 Playbook을 실행하는 사용자가 root 이거나 암호 없는 sudo가 구성된 경우 아래 명령을 실행하여 플레이북을 실행합니다.</block>
  <block id="9081796e9cbb144a0c6cc05a62c75b37" category="paragraph">사용자에게 암호 기반 sudo 액세스가 구성된 경우 아래 명령을 실행하여 플레이북을 실행한 다음 sudo 암호를 입력합니다.</block>
  <block id="8d1e5f9175948d3e6f932794744cde16" category="section-title">설치 후 단계</block>
  <block id="8b70487815961b708f216595f5817311" category="paragraph">Astra Trident의 최신 버전은 2022년 1월 22.01입니다. Kubernetes 배포를 찾을 수 있는 Trident의 버전에 대한 지원 매트릭스입니다<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="b5d9e69ac9444a6a1cfd78cf106c057e" category="list-text">설치 아카이브를 관리 워크스테이션에 다운로드하고 압축을 풉니다. Trident의 현재 버전은 22.01이며 다운로드할 수 있습니다<block ref="defadeb91446b93776c7f5696677985c" category="inline-link-rx"></block>.</block>
  <block id="89c771069f269704306d4ca7b118cc7d" category="paragraph">그러나 NFSv3의 경우 클라이언트와 서버 간에 동시성을 협상하는 메커니즘이 없습니다. 따라서 서버에서 지원되는 값을 사용하여 수동으로 클라이언트 측 sunrpc 슬롯 테이블 항목의 최대 수를 동기화해야 서버의 창 크기를 줄일 필요 없이 NFS 연결에 대한 최상의 성능을 보장할 수 있습니다.</block>
  <block id="9c2d7353683234845149cb6710dc11f8" category="paragraph">ONTAP의 경우 지원되는 최대 sunrpc 슬롯 테이블 항목 수는 128개입니다. 즉, ONTAP는 한 번에 128개의 동시 NFS 요청을 지원할 수 있습니다. 그러나 기본적으로 Red Hat CoreOS/Red Hat Enterprise Linux는 연결당 최대 65,536개의 sunrpc 슬롯 테이블 항목을 갖습니다. 이 값은 128로 설정해야 하며, OpenShift에서 Machine Config Operator(MCO)를 사용하여 설정할 수 있습니다.</block>
  <block id="88cd6afaae477b942c9ab5d396e43cfb" category="paragraph">OpenShift 작업자 노드에서 최대 sunrpc 슬롯 테이블 항목을 수정하려면 다음 단계를 완료하십시오.</block>
  <block id="e7a7478f209d8b5dcaf38a593ce749b3" category="list-text">MCO를 생성한 후에는 모든 작업자 노드에 구성을 적용하고 하나씩 재부팅해야 합니다. 전체 과정은 약 20-30분 정도 소요됩니다. 'OC Get MCP'를 사용하여 기계 설정이 적용되었는지 확인하고 작업자에 대한 기계 구성 풀이 업데이트되었는지 확인합니다.</block>
  <block id="068d2023b916134a0573aaad841124e4" category="paragraph">작업자 노드가 iSCSI 서비스를 실행하도록 구성하려면 다음 단계를 수행하십시오.</block>
  <block id="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link"><block ref="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link-rx"></block></block>
  <block id="086fce5f74cc93b0516aadec33636e09" category="paragraph"><block ref="086fce5f74cc93b0516aadec33636e09" category="inline-link-rx"></block></block>
  <block id="0611f127a7e1e7ef5bbd782030c2e34a" category="paragraph">NetApp ONTAP에서 생성된 다양한 프로젝트에 대해 서로 다른 SVM을 생성한 후 각 SVM을 다른 Trident 백엔드에 매핑해야 합니다. Trident의 백엔드 구성은 OpenShift 클러스터 리소스에 영구 스토리지를 할당하는 역할을 하므로 SVM에 매핑할 세부 정보가 필요합니다. 이 드라이버는 최소한 백엔드의 프로토콜 드라이버여야 합니다. 선택적으로, 볼륨에 스토리지의 용량을 할당하는 방법을 정의하고 볼륨 크기 또는 애그리게이트 사용량 등에 대한 제한을 설정할 수 있습니다. Trident 백엔드의 정의와 관련된 세부 정보를 찾을 수 있습니다<block ref="47a77763732c6cebe093a4a4d61aaa5b" category="inline-link-rx"></block>.</block>
  <block id="891c9b8b0ce367c5e377a1ec23199619" category="paragraph">Trident 백엔드를 구성한 후 다음 단계는 StorageClasses를 구성하는 것입니다. 백엔드가 있는 만큼 스토리지 클래스를 구성하여 각 스토리지 클래스 액세스 권한을 통해 백엔드에서 볼륨을 한 개만 스핀업할 수 있습니다. 스토리지 클래스를 정의하는 동안 storagePools 매개 변수를 사용하여 StorageClass를 특정 Trident 백엔드에 매핑할 수 있습니다. 스토리지 클래스를 정의하는 세부 정보를 찾을 수 있습니다<block ref="1266deb20a7d7c4814b1225e5e572606" category="inline-link-rx"></block>. 따라서 StorageClass에서 Trident 백엔드로 일대일로 매핑하여 하나의 SVM을 가리키도록 합니다. 이렇게 하면 해당 프로젝트에 할당된 StorageClass를 통해 모든 스토리지 청구가 해당 프로젝트 전용 SVM에서 서비스됩니다.</block>
  <block id="b09383080793dfb527084933760af6ed" category="paragraph"><block ref="b09383080793dfb527084933760af6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f372cf1de9e60f6875a0b24a5c28b07" category="list-text">스냅샷 세부 정보를 입력하고 다음 을 클릭한 다음 스냅샷 을 클릭합니다. 스냅샷을 생성하는 데 약 1분이 소요되며 스냅샷이 성공적으로 생성된 후 상태를 사용할 수 있습니다.</block>
  <block id="42dd75b4fbc849903d5d179a8e68d570" category="paragraph"><block ref="42dd75b4fbc849903d5d179a8e68d570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0929177ba68c50d4dd73a2a3311ac885" category="paragraph"><block ref="0929177ba68c50d4dd73a2a3311ac885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f789c3d3aacfbd2d2f99ba395ddb8bc5" category="list-text">백업 세부 정보를 입력하고 백업 파일을 보관할 객체 스토리지 버킷을 선택한 후 다음 을 클릭하고 세부 정보를 검토한 후 백업 을 클릭합니다. 애플리케이션 및 데이터의 크기에 따라 백업이 몇 분 정도 걸릴 수 있으며 백업이 성공적으로 완료된 후 백업 상태를 사용할 수 있게 됩니다.</block>
  <block id="4ba6af660a8dd39dc1d12fb6ee80ba81" category="paragraph"><block ref="4ba6af660a8dd39dc1d12fb6ee80ba81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b1fda3b0f36b6fd708a9871e1c19c50" category="section-title">응용 프로그램을 복원하는 중입니다</block>
  <block id="344aed2ab37311beed01bbd40d93caed" category="paragraph">버튼을 한 번만 누르면 애플리케이션을 동일한 클러스터의 원래 네임스페이스 또는 애플리케이션 보호 및 재해 복구를 위해 원격 클러스터로 복원할 수 있습니다.</block>
  <block id="8ac352fe46a0c45e744688191b7df581" category="list-text">응용 프로그램을 복원하려면 앱 &gt; 관리 탭으로 이동하여 해당 앱을 클릭합니다. 응용 프로그램 이름 옆의 드롭다운 메뉴를 클릭하고 Restore를 클릭합니다.</block>
  <block id="84eb14028ce6ae6f2bf17b71ebe50c69" category="paragraph"><block ref="84eb14028ce6ae6f2bf17b71ebe50c69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b33d7fda666bdb32a2be1f3783106a3c" category="list-text">복원 네임스페이스의 이름을 입력하고 복원할 클러스터를 선택한 다음 기존 스냅샷이나 응용 프로그램 백업에서 복원할지 여부를 선택합니다. 다음 을 클릭합니다.</block>
  <block id="7bbb08271e6b60bc55d6817c7e100528" category="paragraph"><block ref="7bbb08271e6b60bc55d6817c7e100528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9242e3e5428d2ddbd81dece3073767a" category="list-text">검토 창에서 Restore를 입력하고 세부 정보를 검토한 후 Restore를 클릭합니다.</block>
  <block id="7d6d73878ae09dbfd1e5ee7a0ecab66c" category="inline-image-macro">Astra Control Center 복원 검토</block>
  <block id="b862f033546ae8bdc1bb091ad8b57023" category="paragraph"><block ref="b862f033546ae8bdc1bb091ad8b57023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b86c631d7b3beb0163beee546245df6" category="list-text">새 애플리케이션은 Restoring 상태로, Astra Control Center는 선택한 클러스터의 애플리케이션을 복구합니다. 응용 프로그램의 모든 리소스가 Astra에 의해 설치 및 감지되면 응용 프로그램은 사용 가능 상태로 전환됩니다.</block>
  <block id="81d066be6d2211bf186bc1960361d8e3" category="paragraph"><block ref="81d066be6d2211bf186bc1960361d8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4600d44abb914105737c3d4a802b87c" category="section-title">애플리케이션 클론 생성</block>
  <block id="5394f3451a07ae7dbe101ceb0725a004" category="paragraph">개발/테스트 또는 애플리케이션 보호 및 재해 복구를 위해 애플리케이션을 원래 클러스터 또는 원격 클러스터에 복제할 수 있습니다. 동일한 스토리지 백엔드에서 동일한 클러스터 내에 애플리케이션을 클론 복제하면 NetApp FlexClone 기술이 사용되므로 PVC를 즉시 클로닝하고 스토리지 공간을 절약할 수 있습니다.</block>
  <block id="04783413cee5e3c613efc7939cea3560" category="list-text">응용 프로그램을 복제하려면 앱 &gt; 관리 탭으로 이동하고 해당 앱을 클릭합니다. 애플리케이션 이름 옆의 드롭다운 메뉴를 클릭하고 클론 을 클릭합니다.</block>
  <block id="1cfafd65804d582aac709fefcd3e60cd" category="paragraph"><block ref="1cfafd65804d582aac709fefcd3e60cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="654c7a62842024ed8e405ed0ac9c4377" category="list-text">새 네임스페이스의 세부 정보를 입력하고 복제할 클러스터를 선택한 다음 기존 스냅샷 또는 백업 또는 애플리케이션의 현재 상태에서 클론을 생성할지 여부를 선택합니다. 그런 다음 세부 정보를 검토한 후 Next(다음) 를 클릭하고 Clone on review(검토 시 복제) 창을 클릭합니다.</block>
  <block id="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="paragraph"><block ref="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60bae26bb7c1e8711f1e39a45fc7b6c7" category="paragraph"><block ref="60bae26bb7c1e8711f1e39a45fc7b6c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d656f81a685df3697a812158d0bd2f21" category="paragraph">NetApp Astra Trident는 Red Hat OpenShift를 포함한 컨테이너 및 Kubernetes 배포를 위한 오픈 소스 및 완전 지원 스토리지 오케스트레이터입니다. 자세한 내용은 Astra Trident 웹 사이트를 참조하십시오<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="list-text"><block ref="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="inline-link-macro-rx"></block></block>
  <block id="ea1c9e7b76d8b7cc203b9f6a9633e241" category="list-text"><block ref="ea1c9e7b76d8b7cc203b9f6a9633e241" category="inline-link-macro-rx"></block></block>
</blocks>