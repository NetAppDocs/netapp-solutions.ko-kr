<?xml version="1.0" encoding="UTF-8"?>
<blocks>
  <block id="46b8f9361fae73f13467cd1aaff186ba" category="summary">NetApp 솔루션 자료에 대한 최근 변경 사항 로그</block>
  <block id="679ce0aa9d3d54bfddd37e1b78b802de" category="doc">NetApp 솔루션 변경 로그</block>
  <block id="aceacf14369d872e8cb00f62613f52c6" category="paragraph">NetApp 솔루션 자료에 대한 최근 변경 사항. 가장 최근의 변경 사항이 먼저 나열됩니다.</block>
  <block id="e63695c4dea40eefb2ef481c7b242192" category="open-title">모든 변경 사항</block>
  <block id="5edbe8c55546db896b55871b44a39263" category="cell">* 날짜 *</block>
  <block id="12cd1425f32ad289dba28e35ae9096fb" category="cell">* 솔루션 영역 *</block>
  <block id="b96941ac46daa357b1782f017746a57b" category="cell">* 변경에 대한 설명 *</block>
  <block id="7d131526ee2a04107bbc50d52a29a7d7" category="cell">2021년 12월 21일</block>
  <block id="0db377921f4ce762c62526131097968f" category="cell">일반</block>
  <block id="5382aaf8b3d2fdeb6717f9805b0dd511" category="cell">컨테이너</block>
  <block id="c65463900a520919b522c30b6256e475" category="cell">새로운 비디오 데모 추가: NetApp Astra Control을 활용하여 사후 분석 수행 및 NVA-1160에 애플리케이션 복원</block>
  <block id="f63616bb6a8255ed08089231c746f285" category="cell">2021년 12월 6일</block>
  <block id="16784caec2e047ddf59bd5a51bd35a73" category="cell">2021년 11월 15일</block>
  <block id="1c20ad7a11d1c2856906d55171b50126" category="cell">새 비디오 데모 추가: Astra Control을 사용하여 CI/CD 파이프라인에서 데이터 보호 NVA-1160에 추가</block>
  <block id="b0ac6120dada9135114784db22a59940" category="cell">최신 데이터 분석</block>
  <block id="5cdb842b21b9f980df2b3ab63ee9a9e6" category="cell">새로운 내용: Confluent Kafka 모범 사례</block>
  <block id="38562890365e144b467ec2813a6377f2" category="cell">2021년 11월 2일</block>
  <block id="caea8340e2d186a540518d08602aa065" category="cell">자동화</block>
  <block id="fb0ad99371abb3d02d60add8160c6dd9" category="cell">NetApp Cloud Manager를 사용하여 CVO 및 Connector의 AWS 인증 요구사항</block>
  <block id="dfd39862c9cc158ad7b0e4e1e9a3024a" category="cell">2021년 10월 29일</block>
  <block id="e7c456cd85cc15bd3faf7b65c0833d3e" category="cell">새로운 콘텐츠: TR-4657 - NetApp 하이브리드 클라우드 데이터 솔루션: Spark 및 Hadoop</block>
  <block id="4549cdf15178a5f0535be7f0f86cdb4d" category="cell">엔터프라이즈 데이터베이스</block>
  <block id="63c0320f73b5f4e528bbe1488acc5103" category="cell">Oracle 데이터베이스용 자동화된 데이터 보호</block>
  <block id="815425a7766095190649a3f9ecbc1828" category="cell">2021년 10월 26일</block>
  <block id="8493c4f1797303a6de2524a60adcf058" category="cell">2021년 10월 18일</block>
  <block id="ade15f89ccc27958a743a992cea8c574" category="cell">TR-4908 - SnapCenter를 사용한 하이브리드 클라우드 데이터베이스 솔루션</block>
  <block id="622eda32248f1c4d1fc31dd78ec74c4a" category="cell">2021년 10월 14일</block>
  <block id="ea4c55be196897a16d86999f5c16d582" category="cell">포함되었습니다</block>
  <block id="f6ecd264493db5fac4b21f19be4eb69d" category="cell">VMware VCF 블로그 시리즈를 통해 NetApp의 1-4부 추가</block>
  <block id="83a11da06ed8a3e338b5e8d2991cae0c" category="cell">2021년 4월 10일</block>
  <block id="c95696f6146a5b8b56c74d4349687ec6" category="cell">새로운 비디오 데모 추가: NVA-1160에 Astra Control Center를 사용한 워크로드 마이그레이션</block>
  <block id="4f41bdb2ec81835b66ffbbd18feea656" category="cell">2021년 9월 23일</block>
  <block id="9b699c59be5ba510cd9c430a31843b23" category="cell">데이터 마이그레이션</block>
  <block id="32ff1e0d02ec482c64fdac1af2a49372" category="cell">새로운 콘텐츠: NetApp XCP 모범 사례</block>
  <block id="42246d8ef9280d19cf1326197310630a" category="cell">2021년 9월 21일</block>
  <block id="10c87c454d38afc0644c8c1fb75fa524" category="cell">VMware vSphere 관리자를 위한 새로운 컨텐츠 또는 ONTAP, VMware vSphere 자동화</block>
  <block id="faaef04f2f0bb7bed9504fc3d357ba59" category="cell">2021년 9월 9일</block>
  <block id="80245b1f322b07a9fcd385bb375d8182" category="cell">F5 BIG-IP 로드 밸런서와 OpenShift와의 통합 NVA-1160을 추가했습니다</block>
  <block id="023cd4d7ed373df0d803d414e2e452bf" category="cell">2021년 8월 5일</block>
  <block id="afb6b7f715f1bf6492efb8f3c279ddd7" category="cell">Red Hat OpenShift에 NVA-1160-NetApp Astra Control Center에 새로운 기술 통합 추가</block>
  <block id="2cd99fd0d69d62395a72dc7d4684299c" category="cell">2021년 7월 21일</block>
  <block id="13d13fda6fbfbd83ab30f9a5bee17b08" category="cell">NFS에서 ONTAP용 Oracle19c의 자동 배포</block>
  <block id="e88b179e97a156d13d1c9c4163513205" category="cell">2021년 7월 2일</block>
  <block id="9f99e3ea14c0a44dde0fd7db13fa3bef" category="cell">TR-4897 - Azure NetApp Files의 SQL Server: 실제 배포 보기</block>
  <block id="83d39ff0c36403ca3e183af9ca091a71" category="cell">2021년 6월 16일</block>
  <block id="2891cb0fe31606ff172d0be4ec81732f" category="cell">OpenShift Virtualization 설치: NetApp과 함께 Red Hat OpenShift 라는 새 비디오 데모 추가</block>
  <block id="77d29c989f99997794df55b2d9053ae8" category="cell">OpenShift 가상화를 통한 가상 머신 구축 이라는 새로운 비디오 데모 추가: NetAppp의 Red Hat OpenShift</block>
  <block id="fab25e19f7e186358ed7f1268e7af3b4" category="cell">2021년 6월 14일</block>
  <block id="96da300b5faf4ae3a5ca09afabba4273" category="cell">Azure NetApp Files 기반 Microsoft SQL Server 솔루션 추가</block>
  <block id="67c877d4abd9acdbb0fa62c3720b6d60" category="cell">2021년 6월 11일</block>
  <block id="a14851e0e2cb4c8e9176cdea01500288" category="cell">새로운 비디오 데모 추가: NVA-1160에 Astra Trident 및 SnapMirror를 사용한 워크로드 마이그레이션</block>
  <block id="c5d2015481e39976c67e40778a449a2d" category="cell">2021년 6월 9일</block>
  <block id="c4aad26d0bd9fb92610a1b5b3390bd46" category="cell">NetApp OpenShift에서 NVA-1160-Advanced Cluster Management for Kubernetes에 새로운 사용 사례를 추가했습니다</block>
  <block id="53977250e4a69cab3688fcbede8fb73a" category="cell">2021년 5월 28일</block>
  <block id="9c23aa040a3dc51dbbf59463247f4fec" category="cell">NetApp ONTAP를 사용한 NVA-1160-OpenShift Virtualization에 새로운 사용 사례 추가</block>
  <block id="c02e5ac689072495b8af780302105253" category="cell">2021년 5월 27일</block>
  <block id="f5abcac882b8caa17d3af1c14144f503" category="cell">NetApp ONTAP 기반 OpenShift에서 NVA-1160-Multitenancy에 새 사용 사례를 추가했습니다</block>
  <block id="3202abe9084b2d9ec5b0b162721978e7" category="cell">2021년 5월 26일</block>
  <block id="d58aa75910c54a80c6ba4de7e7f6949f" category="cell">NetApp과 함께 NVA-1160-Red Hat OpenShift 추가</block>
  <block id="a0be3ecb819e8e7215f946964346f547" category="cell">2021년 5월 25일</block>
  <block id="95a74db23b085df59ef6412199e9e791" category="cell">블로그 추가: Red Hat OpenShift에 NetApp Trident 설치 – Docker 'toomanyrequest' 문제를 해결하는 방법!</block>
  <block id="2dec0489948dbe7f63f68743a085e98c" category="cell">2021년 5월 19일</block>
  <block id="9045bfbeff51b83f9752fe549021a181" category="cell">FlexPod 솔루션 링크가 추가되었습니다</block>
  <block id="0a40e3c91a3a55c9a37428c6d194d0e5" category="cell">AI</block>
  <block id="af3192eaae3cb09641db4adcc45ed625" category="cell">AI Control Plane 솔루션을 PDF에서 HTML로 변환했습니다</block>
  <block id="8ff5be8d16e86e5284f8ba8a3428459a" category="cell">2021년 5월 17일</block>
  <block id="a88789a4f83f213b256b57eb0884fd1d" category="cell">기본 페이지에 솔루션 피드백 타일을 추가했습니다</block>
  <block id="027fb9451c491d9dcfb7db05f552788d" category="cell">2021년 5월 11일</block>
  <block id="3e62d5f1a7f1b6907ad1ecaf11282dac" category="cell">NFS에서 Oracle 19c for ONTAP의 자동 구축을 추가했습니다</block>
  <block id="d2422eca0ff6f19afb6e1206b15fbe01" category="cell">2021년 5월 10일</block>
  <block id="85c96a5f13e6dea61e003704f8d456e2" category="cell">새로운 비디오: NetApp 및 VMware Tanzu Basic에서 VVol 사용 방법, 3부</block>
  <block id="29e9b684dbbdf5cc1828da82a146781d" category="cell">2021년 5월 6일</block>
  <block id="c30dd1a85cf86d95b11c1a08f70130ce" category="cell">Oracle 데이터베이스</block>
  <block id="508db167da7d74fc86c3f8024ce04558" category="cell">FC를 통해 Cisco UCS 및 NetApp AFF A800을 사용하여 FlexPod 데이터 센터의 Oracle 19c RAC 데이터베이스에 대한 링크가 추가되었습니다</block>
  <block id="85fbf94a3ecf9a3af4a93f80a3681fe1" category="cell">2021년 5월 5일</block>
  <block id="608f33919f16e9a23bd532ad6bcf480a" category="cell">FlexPod Oracle NVA(1155) 및 자동화 비디오 추가</block>
  <block id="4dc6e14d2ad9dafd2cd72f8c77d22bea" category="cell">2021년 5월 3일</block>
  <block id="3d21a9c32818fc58b044121ce91e053c" category="cell">데스크톱 가상화</block>
  <block id="4174d4c17e4b11e07d8dd581e16ba56c" category="cell">FlexPod 데스크톱 가상화 솔루션 링크가 추가되었습니다</block>
  <block id="b3cae16f1f895f4f9ceae98617a3bf0d" category="cell">2021년 4월 30일</block>
  <block id="2764512d2fc00264d149a6142151aa1a" category="cell">비디오: NetApp 및 VMware Tanzu Basic에서 VVol 사용 방법, 2부</block>
  <block id="4996fa0acf5cc54e889a50e9bdd2e56b" category="cell">2021년 4월 26일</block>
  <block id="9c5316849ca2429400f8979f0ee0d963" category="cell">블로그 추가: ONTAP와 함께 VMware Tanzu를 사용하여 Kubernetes 여정을 가속화하십시오</block>
  <block id="911da11d01e00e9aa94c5b03b2e6e2cc" category="cell">2021년 4월 6일</block>
  <block id="06cfdb63e0660d09f203a21e28520a1e" category="cell">"이 리포지토리 정보" 추가</block>
  <block id="32edd80de3642c58e1a05df5f3e458e1" category="cell">2021년 3월 31일</block>
  <block id="bbb1c8f8182403001f2e1f69085ca2ad" category="cell">Edge에 TR-4886-AI 추론 추가: Lenovo ThinkSystem Solution Design이 포함된 NetApp ONTAP</block>
  <block id="d61c9a3748e1dd56535fbdaaa3e39eab" category="cell">2021년 3월 29일</block>
  <block id="8575a367028bec3e86e25b102a8dced1" category="cell">NetApp 스토리지 솔루션을 사용한 NVA-1157-Apache Spark 워크로드 추가</block>
  <block id="8f10e64b04f6cc56cf66fd4f4eb0f4d9" category="cell">2021년 3월 23일</block>
  <block id="7998f8ad3cabe02af607385cae780ce1" category="cell">비디오: NetApp 및 VMware Tanzu Basic에서 VVol 사용 방법, 1부</block>
  <block id="f86fe8ec70f2003923e4000589747208" category="cell">2021년 3월 9일</block>
  <block id="eea51e9c0dffabdea48ada8f53bbf0f5" category="cell">E-Series 콘텐츠 추가, AI 콘텐츠 분류</block>
  <block id="0b218fa381bfd1c86fff15d165ab23a0" category="cell">2021년 4월 3일</block>
  <block id="932af944058a758da919ca59d1af640b" category="cell">새로운 콘텐츠: NetApp 솔루션 자동화 시작하기</block>
  <block id="4be9c930c1a8a198115d499cb3223d9e" category="cell">2021년 2월 18일</block>
  <block id="0c560038af98c5401dd10202e7937acd" category="cell">ONTAP용 TR-4597-VMware vSphere 추가</block>
  <block id="aa1c3ec5e6dcfb94555ff987f061f1a0" category="cell">2021년 2월 16일</block>
  <block id="3ecf1285a084b58473a7873e3f33e74a" category="cell">AI 에지 추론을 위한 자동화된 배포 단계 추가</block>
  <block id="8138d0c3e613508050b6fec12c4322c7" category="cell">2021년 2월 3일</block>
  <block id="999bc6b18351bbe817d26f559ba408ae" category="cell">제공합니다</block>
  <block id="91171755730ad15e6d79b5cb6682a8f1" category="cell">모든 SAP 및 SAP HANA 콘텐츠에 대한 랜딩 페이지 추가</block>
  <block id="e5099bd65458f8a8556c830ac4759296" category="cell">2021년 2월 1일</block>
  <block id="09689218a7f330554f4e28a18e9e14a6" category="cell">NetApp VDS가 포함된 VDI, GPU 노드의 콘텐츠 추가</block>
  <block id="c487c48f1528e49e3cb129fdbdd79990" category="cell">2021년 6월 1일</block>
  <block id="868f7f9e78f90bcf0597030ffefd449b" category="cell">새로운 솔루션: NVIDIA DGX A100 시스템과 Mellanox Spectrum 이더넷 스위치(설계 및 구축)가 포함된 NetApp ONTAP AI</block>
  <block id="0663765430d1ca93138f13429aef7c37" category="cell">2020년 12월 22일</block>
  <block id="a4aae8f8849c453c6c67080c5d013301" category="cell">NetApp Solutions 저장소의 초기 릴리즈</block>
  <block id="f27edcc7a209983dc37cbcdb0df49ce7" category="open-title">가상 데스크톱</block>
  <block id="6fb2815b4c371ee082a84cc14539d4cb" category="open-title">엔터프라이즈 애플리케이션</block>
  <block id="18a2eb3f7faf7c44e3062e78cbeff089" category="inline-link-macro">SAP 솔루션 저장소</block>
  <block id="412b2ee09f2fbaf8cddb69ee6fe43a2e" category="admonition">SAP 및 SAP HANA 업데이트에 대한 자세한 내용은 의 각 솔루션에 대해 나와 있는 "업데이트 기록" 콘텐츠를 참조하십시오 <block ref="c4ed54a973fb1aa472c2443732d93c13" category="inline-link-macro-rx"></block>.</block>
  <block id="408649df4ac74ae19e47eef7d060c5cb" category="open-title">솔루션 자동화</block>
  <block id="d41d8cd98f00b204e9800998ecf8427e" category="summary"></block>
  <block id="6f8b794f3246b0c1e1780bb4d4d5dc53" category="doc">결론</block>
  <block id="7c0ea3e86521674f72e056d148d4f2ce" category="paragraph">NetApp 및 Run: AI는 이 기술 보고서에서 AI 워크로드 오케스트레이션을 단순화하기 위한 Run:AI 플랫폼과 함께 NetApp ONTAP AI 솔루션의 고유한 기능을 시연했습니다. 이전 단계에서는 딥 러닝을 위한 데이터 파이프라인 및 워크로드 오케스트레이션의 프로세스를 간소화하는 참조 아키텍처를 제공합니다. 이러한 솔루션을 구현하려는 고객은 NetApp 및 Run:AI에 자세한 내용을 문의하도록 권장합니다.</block>
  <block id="f797637684ff1290d12e5495dac050a6" category="inline-link-macro">다음: 섹션 4.8의 테스트 세부 정보</block>
  <block id="bbe251d46ac2a6899a2a4d5d0e331a43" category="paragraph"><block ref="bbe251d46ac2a6899a2a4d5d0e331a43" category="inline-link-macro-rx"></block></block>
  <block id="34d54070f7d06f04159ffbc3d9a3e082" category="doc">작업 환경을 구성합니다</block>
  <block id="8302b607de31151e5500de556070d9b9" category="paragraph">'노트북'의 et_env-example.ipynb를 'et_env.ipynb'로 복사합니다. 'et_env.ipynb'를 열고 편집합니다. 이 노트북은 자격 증명, 파일 위치 및 실행 드라이버에 대한 변수를 설정합니다.</block>
  <block id="3dc3cffc26096b89061a452cc7d16b6a" category="paragraph">위의 지침을 따르면 다음 단계만 변경할 수 있습니다.</block>
  <block id="26448fec50e405fb230427686eeb11f4" category="list-text">이과지오 서비스 대시보드에서 이 값을 'docker_registry'로 얻습니다</block>
  <block id="837784ac15c5cac463a4d016bac63db1" category="paragraph">예: dddocker-registry.default-tenant.app.clusterq.iguaziodev.com:80`</block>
  <block id="04dca9f72f7dfc6f87034c574f821a12" category="list-text">'admin'을 Iguazio 사용자 이름으로 변경합니다.</block>
  <block id="b2dea33f1195135f6905b7dd0ee58713" category="paragraph">''IGZ_container_path='/users/admin''</block>
  <block id="0ddaf8f981ee966dc3533de490c7ee4e" category="paragraph">다음은 ONTAP 시스템 연결 세부 정보입니다. Trident를 설치할 때 생성한 볼륨 이름을 포함합니다. 다음은 온-프레미스 ONTAP 클러스터에 대한 설정입니다.</block>
  <block id="dada97be0cb81e6518d92aa7112fa356" category="paragraph">Cloud Volumes ONTAP에 대한 설정은 다음과 같습니다.</block>
  <block id="586d20125924bc57624aaacc07973d5a" category="section-title">기본 Docker 이미지를 생성합니다</block>
  <block id="0ab24923db4855b821917446711104c9" category="paragraph">ML 파이프라인을 구축하는 데 필요한 모든 것이 Iguazio 플랫폼에 포함되어 있습니다. 개발자는 파이프라인을 실행하고 Jupyter Notebook에서 이미지 생성을 실행하는 데 필요한 Docker 이미지의 사양을 정의할 수 있습니다. 노트북 'create-images.ipynb'를 열고 모든 셀을 실행합니다.</block>
  <block id="3dc4e8abb0e99c6cf29451a16a891524" category="paragraph">이 노트북은 파이프라인에서 사용하는 두 개의 이미지를 만듭니다.</block>
  <block id="5446cc82e4c165e2700af830f8428d63" category="list-text">"iguazio/NetApp. ML 작업을 처리하는 데 사용됩니다.</block>
  <block id="341d84aa26cb4521474864e04ea2a63b" category="inline-image-macro">오류: 그래픽 이미지가 없습니다</block>
  <block id="61145f9d17e187b69bc41525b10aafe6" category="paragraph"><block ref="61145f9d17e187b69bc41525b10aafe6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62e9956426227f62abc9692954a5ad39" category="list-text">'NetApp/파이프라인' NetApp Snapshot 복사본을 처리하는 유틸리티를 포함합니다.</block>
  <block id="4050f795a12d7f83a545999c8a0d1905" category="paragraph"><block ref="4050f795a12d7f83a545999c8a0d1905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6677daf583d4c0cf5860927a024f278d" category="section-title">개별 Jupyter Notebooks를 검토합니다</block>
  <block id="6414e1c23e017075a375d3a531eab90c" category="paragraph">다음 표에는 이 작업을 만드는 데 사용한 라이브러리와 프레임워크가 나와 있습니다. 이러한 모든 구성 요소는 Iguazio의 역할 기반 액세스 및 보안 제어와 완벽하게 통합되어 있습니다.</block>
  <block id="da292beca00e0b352eade7a070855fd3" category="cell">라이브러리/프레임워크</block>
  <block id="b5a7adde1af5c87d7fd797b6245c2a39" category="cell">설명</block>
  <block id="124d604ba0d3fd8e3d31c821b2a332f5" category="cell">MLRun</block>
  <block id="1c1491d01d96c08951ae2ac55fadf443" category="cell">머신 러닝/AI 파이프라인을 조립, 실행 및 모니터링할 수 있도록 Iguazio에서 관리합니다.</block>
  <block id="a2580bd6e044f86f4e39be2f59ee91da" category="cell">뉴클레오</block>
  <block id="2d753cbb7762fe25d15a2cda2ff84790" category="cell">서버를 사용하지 않는 함수 프레임워크가 Iguazio와 통합되었습니다. 이과지오(Iguazio)에서 관리하는 오픈 소스 프로젝트로도 사용할 수 있습니다.</block>
  <block id="bb643a3a76aab569f9245a19f77d4b65" category="cell">Kubeflow</block>
  <block id="0bbee378f2697a1d0c184e76d2b206c6" category="cell">파이프라인을 구축하는 Kubernetes 기반 프레임워크 이과지오가 기여하는 오픈 소스 프로젝트이기도 합니다. 이과지오와 통합되어 나머지 인프라와의 보안 및 통합을 강화합니다.</block>
  <block id="c5fd214cdd0d2b3b4272e73b022ba5c2" category="cell">Docker 를 참조하십시오</block>
  <block id="849efb47ec760eb7c3c6b5848e740c3b" category="cell">Docker 레지스트리는 Iguazio 플랫폼에서 서비스로 실행됩니다. 이 설정을 변경하여 레지스트리에 연결할 수도 있습니다.</block>
  <block id="a38f73277b7341a709cf0cb57ebc4434" category="cell">NetApp Cloud Volumes를 참조하십시오</block>
  <block id="7279bb663993b77e219b4ca813326d77" category="cell">AWS에서 실행되는 Cloud Volumes를 통해 대량의 데이터에 액세스하고 Snapshot 복사본을 교육에 사용되는 데이터 세트의 버전으로 만들 수 있습니다.</block>
  <block id="10f0fa4079121b371145e16713fdbb44" category="cell">트라이던트</block>
  <block id="9953e13b783f3ad45d99187c955cb9f9" category="cell">Trident는 NetApp에서 관리하는 오픈 소스 프로젝트입니다. Kubernetes에서 스토리지 및 컴퓨팅 리소스와 통합할 수 있도록 지원합니다.</block>
  <block id="5fa4506d691373039fd2834939e582b3" category="paragraph">우리는 여러 노트북을 사용하여 ML 파이프라인을 구성하였습니다. 각 노트북은 파이프라인에 함께 들어가기 전에 개별적으로 테스트할 수 있습니다. 이 데모 애플리케이션의 배포 흐름에 따라 각 노트북을 개별적으로 다룹니다.</block>
  <block id="06a86c2506db8ef5fdac675c1352e3cf" category="paragraph">원하는 결과는 데이터의 스냅샷 복사본을 기반으로 모델을 교육하고 추론을 위해 모델을 구축하는 파이프라인입니다. 완료된 MLRun 파이프라인에 대한 블록 다이어그램이 다음 이미지에 나와 있습니다.</block>
  <block id="1d79eb753e06f2122a118408a14d6c51" category="paragraph"><block ref="1d79eb753e06f2122a118408a14d6c51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51b666fe429f998144ea4f2ce818cd60" category="section-title">데이터 생성 기능 구축</block>
  <block id="034015442bf8bf34c0e7e8149d35dae6" category="paragraph">이 섹션에서는 Nuclio 서버리스 기능을 사용하여 네트워크 장치 데이터를 생성하는 방법에 대해 설명합니다. 이 활용 사례는 파이프라인을 구축한 이과지오 클라이언트에서 수정되었으며 이과지오 서비스를 사용하여 네트워크 디바이스 장애를 모니터링하고 예측합니다.</block>
  <block id="2d024dd4dc0601ff2e4d0b81fcaec60a" category="inline-link">Nuclio 웹 사이트</block>
  <block id="59009d367371847f2042c59338282f4b" category="paragraph">네트워크 장치에서 오는 데이터를 시뮬레이션했습니다. Jupyter Notebook data-generator.ipynb를 실행하면 10분마다 실행되는 서버리스 기능이 생성되고 새 데이터가 있는 Parquet 파일이 생성됩니다. 함수를 배포하려면 이 전자 필기장의 모든 셀을 실행합니다. 를 참조하십시오<block ref="a9d48e85369982160b96d90770d878d1" category="inline-link-rx"></block> 이 노트북에서 잘 모르는 구성 요소를 검토합니다.</block>
  <block id="fa0c06ebcd647f13ce81472307615ee3" category="paragraph">함수를 생성할 때 다음 주석이 있는 셀은 무시됩니다. 노트북의 모든 셀은 기능의 일부로 간주됩니다. '%nuclio magic'을(를) 활성화하려면 Nuclio 모듈을 가져옵니다.</block>
  <block id="c2b253a6bc491b37027772dba5f0b4e7" category="paragraph">기능에 대한 사양에서는 함수가 실행되는 환경, 함수가 트리거되는 방식 및 사용되는 리소스를 정의했습니다.</block>
  <block id="95b0eb5f892f7b0bcb3ec7dbb9058c02" category="paragraph">INIT_CONTEXT 함수는 함수 초기화 시 Nuclio Framework에 의해 호출됩니다.</block>
  <block id="1aab9637db54631d95ec5901bfda0947" category="paragraph">함수에 없는 코드는 함수가 초기화될 때 호출됩니다. 이 함수를 호출하면 처리기 함수가 실행됩니다. 처리기의 이름을 변경하고 함수 사양에서 지정할 수 있습니다.</block>
  <block id="94be7a657ecb54ef7337030d9dd78b70" category="paragraph">배포 전에 노트북에서 기능을 테스트할 수 있습니다.</block>
  <block id="01237c05459839293bfcd5a3beb1364f" category="paragraph">이 기능은 노트북에서 배포하거나 CI/CD 파이프라인에서 배포할 수 있습니다(이 코드 조정).</block>
  <block id="c697561ec27606d29683f7fc5fb3846d" category="section-title">파이프라인 노트북</block>
  <block id="83041c5547fb0ad965936febfc41508d" category="paragraph">이 노트북은 이 설정을 위해 개별적으로 실행할 수 없습니다. 이 내용은 각 전자 필기장에 대한 검토일 뿐입니다. 파이프라인을 구성하는 요소로 호출한 것입니다. 개별적으로 실행하려면 MLRun 설명서를 검토하여 Kubernetes 작업으로 실행합니다.</block>
  <block id="c16b208e4ffb938f4008373dea5fb4ec" category="section-title">SNAP_CV.iynb</block>
  <block id="eeb06194a969eee5616e56b449a99306" category="paragraph">이 노트북은 파이프라인의 시작 부분에 있는 Cloud Volume Snapshot 복사본을 처리합니다. 볼륨의 이름을 파이프라인 컨텍스트로 전달합니다. 이 노트북은 스냅샷 복사본을 처리하기 위해 셸 스크립트를 호출합니다. 파이프라인에서 실행되는 동안 실행 컨텍스트에는 실행에 필요한 모든 파일을 찾는 데 도움이 되는 변수가 포함되어 있습니다. 이 코드를 작성하는 동안 개발자는 이 코드를 실행하는 컨테이너의 파일 위치에 대해 걱정할 필요가 없습니다. 나중에 설명했듯이 이 응용 프로그램은 모든 종속성을 포함하여 배포되며 실행 컨텍스트를 제공하는 파이프라인 매개 변수의 정의입니다.</block>
  <block id="dc82b570ec10aa261c20bf4828af24c1" category="paragraph">생성된 스냅샷 복사본 위치는 파이프라인의 단계에서 사용할 MLRun 컨텍스트에 배치됩니다.</block>
  <block id="7f609b3599e86a8f1b83bde97709ba37" category="paragraph">다음 세 개의 노트북은 병렬로 실행됩니다.</block>
  <block id="d1839287f93e09936af234173d03d6b7" category="section-title">데이터 준비 .ipynb</block>
  <block id="dbe6ca7c47e3dc8cbd3a4956e684b761" category="paragraph">원시 메트릭을 기능으로 전환하여 모델 교육을 활성화해야 합니다. 이 노트북은 Snapshot 디렉토리에서 원시 메트릭을 읽고 모델 훈련을 위한 기능을 NetApp 볼륨에 씁니다.</block>
  <block id="dab65fbdf0ed5ce626558d99e83c618f" category="paragraph">파이프라인 컨텍스트에서 실행되는 경우 입력 DATA_DIR에 스냅샷 복사 위치가 포함됩니다.</block>
  <block id="4636df8c7ba383c5f135c7ae8f2ef772" category="section-title">ipynb 설명</block>
  <block id="43099d46867c7c0cc922fdd3e026d029" category="paragraph">수신 메트릭을 시각화하기 위해 Kubeflow 및 MLRun UI를 통해 사용할 수 있는 플롯 및 그래프를 제공하는 파이프라인 단계를 배포합니다. 각 실행에는 이 시각화 도구의 고유 버전이 있습니다.</block>
  <block id="7fd47125b80c0e6241052a47dcb41b98" category="section-title">Deploy-feature-function.ipynb</block>
  <block id="684eb641c7a322c328f8ea91cd482b0d" category="paragraph">NetApp은 이상 징후를 찾기 위한 메트릭을 지속적으로 모니터링합니다. 이 노트북은 들어오는 메트릭에 대한 예측을 실행하는 데 필요한 기능을 생성하는 서버리스 기능을 생성합니다. 이 노트북은 함수 생성을 호출합니다. 기능 코드는 노트북 data-prep.ipynb에 있다. 이러한 목적을 위해 파이프라인에서 한 단계씩 동일한 전자 필기장을 사용합니다.</block>
  <block id="1c475141d16ada0e53ddb14047963024" category="section-title">훈련.iynb</block>
  <block id="43b6984a9b2a7863061833c96be2b851" category="paragraph">피처를 작성한 후 모델 교육을 시작합니다. 이 단계의 출력은 추론을 위해 사용할 모델입니다. 또한 각 실행(실험)을 추적하기 위해 통계를 수집합니다.</block>
  <block id="a6858cae929a8eed6e9c9d6cfa9befac" category="paragraph">예를 들어 다음 명령은 해당 실험의 컨텍스트에 정확도 점수를 입력합니다. 이 값은 Kubeflow 및 MLRun에서 볼 수 있습니다.</block>
  <block id="9d1126b5d7690c0eb46dd7713822680e" category="section-title">deploy-추론-function.ipynb입니다</block>
  <block id="827ebf8bb3ee1798b5394ecd2a8bb3ae" category="paragraph">파이프라인의 마지막 단계는 모델을 서버리스 기능으로 구축하여 연속 추론을 수행하는 것입니다. 이 노트북은 'nuclio-추론-function.ipynb'에 정의된 서버리스 기능의 생성을 호출합니다.</block>
  <block id="4d2c908b5247626d682903dc9527bd05" category="section-title">파이프라인 검토 및 구축</block>
  <block id="6c8673acfb6249793bed69954ca16a9b" category="paragraph">파이프라인에서 모든 노트북을 함께 실행할 경우 실험을 지속적으로 실행하여 새로운 측정 지표를 기준으로 모델의 정확성을 재평가할 수 있습니다. 먼저 파이프라인 iptynb 노트북을 엽니다. NetApp과 Iguazio가 이 ML 파이프라인 구축을 단순화하는 방법을 자세히 설명 드리겠습니다.</block>
  <block id="50d4decae4f0f08e83a1bd8342bd6ef1" category="paragraph">MLRun을 사용하여 컨텍스트를 제공하고 파이프라인의 각 단계에 대한 리소스 할당을 처리합니다. MLRun API 서비스는 Iguazio 플랫폼에서 실행되며 Kubernetes 리소스와 상호 작용하는 지점입니다. 각 개발자는 리소스를 직접 요청할 수 없습니다. API는 요청을 처리하고 액세스 제어를 활성화합니다.</block>
  <block id="c7c5ccf69a87e301b134dcfdf46ab307" category="paragraph">파이프라인은 NetApp Cloud Volumes 및 온프레미스 볼륨과 함께 사용할 수 있습니다. Cloud Volumes를 사용하기 위해 이 데모를 구축했지만 코드에서 온프레미스 실행 옵션을 확인할 수 있습니다.</block>
  <block id="ce16d064e13fffda0ff2a07c50276f33" category="paragraph">Jupyter 노트북을 Kubeflow 단계로 전환하는 데 필요한 첫 번째 작업은 코드를 함수로 전환하는 것입니다. 기능에는 해당 노트북을 실행하는 데 필요한 모든 사양이 있습니다. 전자 필기장을 아래로 스크롤하면 파이프라인의 모든 단계에 대한 기능을 정의하는 것을 볼 수 있습니다.</block>
  <block id="8bbbd384e919f705f071525a96cdfaec" category="cell">노트북의 일부입니다</block>
  <block id="5d75cd50687084d681964f5c6ee8a73a" category="cell">code_to_function&gt; (MLRun 모듈의 일부)</block>
  <block id="eef456f018469b2d403742d05e33a5dd" category="cell">함수 이름: 프로젝트 이름. 모든 프로젝트 아티팩트를 구성하는 데 사용됩니다. 이것은 MLRun UI에서 볼 수 있습니다. 있습니다. 이 경우에는 Kubernetes 작업입니다. 이는 Dask, MPI, 스파크k8s 등이 될 수 있습니다. 자세한 내용은 MLRun 설명서를 참조하십시오. 파일. 전자 필기장의 이름입니다. Git(HTTP)의 위치일 수도 있습니다.</block>
  <block id="78805a221a988e79ef3f42d7c5bfd418" category="cell">이미지</block>
  <block id="d0161cbbc56081c803c919679b76b846" category="cell">이 단계에서 사용 중인 Docker 이미지의 이름입니다. 앞에서 create-image.ipynb 전자 필기장으로 이 기능을 만들었습니다.</block>
  <block id="28bb8862d962b462f621d9098de311cd" category="cell">volume_mounts 및 volume</block>
  <block id="a6841da965bfb59838d367b9fdc30a8c" category="cell">런타임에 NetApp Cloud Volume을 마운트하기 위한 세부 정보</block>
  <block id="5d9261bc63dfeef8d26c807e36a9daa4" category="paragraph">단계에 대한 매개 변수도 정의합니다.</block>
  <block id="fcd242cd0d87d4de3be34f843180bdb0" category="paragraph">모든 단계에 대한 함수 정의가 있으면 파이프라인을 구성할 수 있습니다. 우리는 이 정의를 만들기 위해 'kfp' 모듈을 사용합니다. MLRun을 사용하는 것과 자체적으로 구축하는 것의 차이점은 코딩의 단순화 및 단축입니다.</block>
  <block id="f02b57d2fbd61d7629e76438ba68f7a1" category="paragraph">정의한 기능은 MLRun의 AS_STEP 기능을 이용하여 STEP 부품으로 변한다.</block>
  <block id="8859e75c5bfd3a8ea5a783296d71b795" category="section-title">스냅샷 단계 정의</block>
  <block id="dabb827ac33da3a8d8a2384874221aab" category="paragraph">스냅샷 기능을 시작하고 v3io를 소스로 출력 및 마운트합니다.</block>
  <block id="3225a10b07f1580f10dee4abc3779e6c" category="cell">매개 변수</block>
  <block id="3ec365dd533ddb7ef3d1c111186ce872" category="cell">세부 정보</block>
  <block id="422ac26927e8ad3d6b30617226e26c2a" category="cell">새 작업</block>
  <block id="b954691c9a06ef7281bf4c836e7684f1" category="cell">NewTask 는 함수 실행의 정의입니다.</block>
  <block id="7871261404e7a8d93339696184b243b9" category="cell">(MLRun 모듈)</block>
  <block id="4522319a8fbbe0a85c82e604047dfe6c" category="cell">핸들러. 호출할 Python 함수의 이름입니다. 전자 필기장에서 이름 처리기를 사용했지만 필수 사항은 아닙니다. 매개 변수 실행에 전달된 매개 변수. 코드 안에서 context.get_param('parameter')을 사용하여 값을 가져옵니다.</block>
  <block id="6cebb60f71d9de65143ade7a8388e27a" category="cell">AS_STEP</block>
  <block id="070faabab806ce863279f5bd38452cc4" category="cell">이름. Kubeflow 파이프라인 단계의 이름입니다. 출력. 이 값은 완료 시 단계에서 사전에 추가하는 값입니다. SNAP_CV.iynb 노트북을 살펴보십시오. mount_v3io(). 이를 통해 파이프라인을 실행하는 사용자에 대해 /User를 마운트하는 단계를 구성합니다.</block>
  <block id="a8aff967e1649a1c82ea607c881e8091" category="cell">입력</block>
  <block id="6f1ba99c8ee685047e0fa3c32349a01f" category="cell">이전 단계의 출력을 단계별로 전달할 수 있습니다. 이 경우 snap.outputs ['sapVolumeDetails']는 스냅 단계에서 생성한 스냅샷 복사본의 이름입니다.</block>
  <block id="a399d9e54dd5dc35c6b455d995702175" category="cell">아웃_경로</block>
  <block id="026446ea82508e4c9f41609b3484b4cb" category="cell">MLRun 모듈 log_artifacts를 사용하여 생성하는 아티팩트를 배치할 위치입니다.</block>
  <block id="2fe8889e7fb9545ea383ff3c0451cabf" category="paragraph">pipeline.ipynb는 위에서 아래로 실행할 수 있다. 그런 다음 Iguazio 대시보드에서 Pipelines 탭으로 이동하여 Iguazio 대시보드 파이프라인 탭에 표시된 진행 상황을 모니터링할 수 있습니다.</block>
  <block id="74dec5a93e3c1ccb06f26ebc6f9401fb" category="paragraph"><block ref="74dec5a93e3c1ccb06f26ebc6f9401fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f47db69a9e60b47a1c8f7800753f6b57" category="paragraph">모든 러닝에서 훈련 단계의 정확성을 기록했기 때문에 훈련 정확도 기록에서도 볼 수 있듯이 각 실험마다 정확한 기록을 가지고 있습니다.</block>
  <block id="5bb7a1a5b810ce843cd4d41a7137ce26" category="paragraph"><block ref="5bb7a1a5b810ce843cd4d41a7137ce26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9ebd260b4ed60a239b8228fe68b2dbc" category="paragraph">스냅샷 단계를 선택하면 이 실험을 실행하는 데 사용된 스냅샷 복사본의 이름을 볼 수 있습니다.</block>
  <block id="1d231b2e1da6122607105ce52f87a763" category="paragraph"><block ref="1d231b2e1da6122607105ce52f87a763" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc578a2d3b019d646da18c9172282dc" category="paragraph">설명된 단계에는 우리가 사용한 지표를 탐색할 수 있는 시각적 인공물이 있습니다. 다음 이미지와 같이 전체 플롯을 보기 위해 확장할 수 있습니다.</block>
  <block id="ffb599ed438d33d337e7cca9a1fbaf07" category="paragraph"><block ref="ffb599ed438d33d337e7cca9a1fbaf07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89238f00748675db057567546f67c2c5" category="paragraph">또한 MLRun API 데이터베이스는 프로젝트별로 구성된 각 실행의 입력, 출력 및 아티팩트를 추적합니다. 각 시리즈의 입력, 출력 및 아티팩트의 예는 다음 영상에서 확인할 수 있습니다.</block>
  <block id="a8baa83f88edfb0fceafeda75819cb5f" category="paragraph"><block ref="a8baa83f88edfb0fceafeda75819cb5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c6050fe85d7b5528bc8356c88eab725" category="paragraph">각 직무마다 추가 세부 정보를 저장합니다.</block>
  <block id="8683624a37c6626765321b5cc2f60954" category="paragraph"><block ref="8683624a37c6626765321b5cc2f60954" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f02f72c9470e67a8b3c5f9054b0a32c" category="inline-link">MLRun GitHub 사이트</block>
  <block id="01661b1e0825da7434573266df1672e0" category="paragraph">MLRun에 대한 자세한 내용은 이 문서에서 다룰 수 있는 것보다 많습니다. 단계와 함수의 정의를 비롯한 Al 아티팩트는 API 데이터베이스에 저장하고 버전을 지정한 후 개별 또는 전체 프로젝트로 호출할 수 있습니다. 프로젝트를 저장하고 나중에 사용할 수 있도록 Git에 푸시할 수도 있습니다. 자세한 내용은 에서 확인하시기 바랍니다<block ref="92ae596fd8e402850e22f59a73ed3a44" category="inline-link-rx"></block>.</block>
  <block id="43486dfb907f148e40f3719f314caeb4" category="inline-link-macro">다음: Grafana 대시보드 배포</block>
  <block id="0670d6ac4e77f5862afcc2fde43bcc72" category="paragraph"><block ref="0670d6ac4e77f5862afcc2fde43bcc72" category="inline-link-macro-rx"></block></block>
  <block id="4b737f96f31f513a87adcf43b83ec3a1" category="summary">이 페이지에서는 AKS 클러스터를 설정하는 데 필요한 단계를 설명합니다.</block>
  <block id="a81532d943508d42466c22d8d87bb4b8" category="doc">AKS 클러스터를 설치하고 설정합니다</block>
  <block id="ce3e1770b7ff86cfbc3a30a3e3ea87da" category="inline-link-macro">이전: 클릭률 예측 사용 사례 요약</block>
  <block id="80bf56f9bff31f7459309b983fbf8116" category="paragraph"><block ref="80bf56f9bff31f7459309b983fbf8116" category="inline-link-macro-rx"></block></block>
  <block id="50f7d8213ee52350926ec407074e68f1" category="inline-link">AKS 클러스터를 생성합니다</block>
  <block id="40e1cc9f8d9321cbe9c1ef090f926a2b" category="paragraph">AKS 클러스터를 설치 및 설정하려면 웹 페이지를 참조하십시오<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block> 그런 다음 다음 다음 단계를 완료합니다.</block>
  <block id="ad4af0825dd4979b7f48ae5ba031b23a" category="list-text">노드 유형(시스템 [CPU] 또는 작업자 [GPU] 노드)을 선택할 때 다음을 선택합니다.</block>
  <block id="5a244a81080ee9fc08696fcbd45284e5" category="list-text">기본 시스템 노드는 표준 DS2v2('agentpool' 기본 3개 노드)여야 합니다.</block>
  <block id="f3449ebebbf547282aa0562015bd360d" category="list-text">그런 다음 이름이 "gpupool"인 사용자 그룹(GPU 노드의 경우)에 대해 작업자 노드 Standard_NC6s_v3 풀(최소 3개 노드)을 추가합니다.</block>
  <block id="d3d648c68589ef99efb6ad3ec15d1beb" category="paragraph"><block ref="d3d648c68589ef99efb6ad3ec15d1beb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2efc2b95642d4bcc76c710a3826225c" category="list-text">배포에는 5~10분이 소요됩니다. 완료되면 Connect to Cluster를 클릭합니다.</block>
  <block id="31797d7013400422e5d589ae3d91c79a" category="list-text">새로 생성된 AKS 클러스터에 연결하려면 로컬 환경(랩톱/PC)에서 다음을 설치합니다.</block>
  <block id="87e009e80a344ecb598be4c4bbe01c79" category="inline-link">특정 OS에 대한 지침이 제공됩니다</block>
  <block id="13a6d4f4230d0a1569b719c15884d447" category="list-text">를 사용하는 Kubernetes 명령줄 툴입니다<block ref="ad2337a31b7d16867fc954b03de661bd" category="inline-link-rx"></block></block>
  <block id="24a109d7bba4f8808eeb0bcf64d4357b" category="inline-link">Azure CLI를 설치합니다</block>
  <block id="7feed8a8a6c680e7beeca052b9fc9ed0" category="list-text">문서에 설명된 대로 Azure CLI를 사용할 수 있습니다.<block ref="8e2043d81b680dba324c5a2abbee7b3f" category="inline-link-rx"></block></block>
  <block id="d33a4b8acf4001a4b35a2186fd020432" category="list-text">터미널에서 AKS 클러스터에 액세스하려면 'az login'을 입력하고 자격 증명을 입력합니다.</block>
  <block id="3394029cd334ed00686c86c088d73c24" category="list-text">다음 두 명령을 실행합니다.</block>
  <block id="402ff6cff3671c1f49dc4af765835c14" category="list-text">Azure CLI:kubeck get nodes를 입력합니다.</block>
  <block id="4e5d89028ffbf65df6693ef1affd6573" category="list-text">다음 예와 같이 6개 노드가 모두 가동되어 실행 중인 경우 AKS 클러스터가 로컬 환경에 준비 및 연결됩니다</block>
  <block id="6b935f22371497abfe5378d4446df0da" category="paragraph"><block ref="6b935f22371497abfe5378d4446df0da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e57b7e32f49f0297d6c7524d1da1b3c0" category="inline-link-macro">다음: Azure NetApp Files에 대해 위임된 서브넷을 만듭니다.</block>
  <block id="46b5942a33ef6a130ca5fee3f6017bec" category="paragraph"><block ref="46b5942a33ef6a130ca5fee3f6017bec" category="inline-link-macro-rx"></block></block>
  <block id="ecb81ab37e1d2a7ed6dfce3807622e3d" category="summary">이 섹션에서는 RUN AI Orchestrator를 사용하여 규모에 따라 차선 감지 분산 교육을 수행할 수 있는 플랫폼을 설정하는 방법에 대해 자세히 설명합니다.</block>
  <block id="0714a752696f8feed939bbf52a6214f7" category="doc">차선 감지 – AI를 통한 분산 훈련</block>
  <block id="dbf10b854b8b7fc90297279e7ad0f745" category="paragraph">이 섹션에서는 RUN:AI Orchestrator를 사용하여 규모에 따라 차선 감지 분산 교육을 수행할 수 있는 플랫폼을 설정하는 방법에 대해 자세히 설명합니다. 모든 솔루션 요소의 설치와 해당 플랫폼에서 분산된 교육 작업을 실행하는 방법에 대해 설명합니다. ML 버전 관리는 데이터 및 모델 재현성을 달성하기 위한 Run:AI 실험과 연결된 NetApp SnapshotTM을 사용하여 완료됩니다. ML 버전 관리는 모델 추적, 팀 구성원 간 작업 공유, 결과 재현성, 새로운 모델 버전을 운영 환경에 롤링하며 데이터 관리에 중요한 역할을 합니다. NetApp ML 버전 제어(Snapshot)는 각 실험과 관련된 데이터, 훈련된 모델 및 로그의 시점 버전을 캡처할 수 있습니다. 풍부한 API 지원을 통해 run:AI 플랫폼과 쉽게 통합할 수 있습니다. 교육 상태에 따라 이벤트를 트리거하기만 하면 됩니다. 또한, Kubernetes(K8s) 상에서 실행 중인 코드나 컨테이너의 아무 것도 변경하지 않고 전체 실험의 상태를 포착해야 합니다.</block>
  <block id="25d19977e35c6d286c5b051982ae3f3c" category="paragraph">마지막으로, 이 기술 보고서에서는 AKS의 여러 GPU 지원 노드에 대한 성능 평가를 마무리합니다.</block>
  <block id="1987a7039dccb848f2e8ce693ba3faff" category="section-title">TuSimple 데이터 세트를 사용하여 차선 감지 사용 사례에 대한 분산 교육</block>
  <block id="f75a7cb3d80e7be148c1ce86a4347011" category="paragraph">이 기술 보고서에서 분산된 교육은 차선 감지를 위한 TuSimple 데이터 세트에 대해 수행됩니다. Horovod는 AKS를 통해 Kubernetes 클러스터의 여러 GPU 노드에 대해 동시에 데이터 분산 교육을 수행하기 위한 교육 코드에 사용됩니다. 코드는 TuSimple 데이터 다운로드 및 처리를 위한 컨테이너 이미지로 패키징됩니다. 처리된 데이터는 NetApp Trident 플러그인에서 할당한 영구 볼륨에 저장됩니다. 교육에서는 하나 이상의 컨테이너 이미지가 생성되고 데이터를 다운로드하는 동안 생성된 영구 볼륨에 저장된 데이터를 사용합니다.</block>
  <block id="58b4798157820b4e4415d8136cf60fe9" category="paragraph">데이터 및 교육 작업을 제출하려면 RUN:AI를 사용하여 리소스 할당 및 관리를 오케스트레이션하십시오. Run: AI를 사용하면 Horovod에 필요한 MPI(Message Passing Interface) 작업을 수행할 수 있습니다. 이 레이아웃을 통해 여러 GPU 노드가 서로 통신하여 각 교육 미니 일괄 처리 후 교육 가중치를 업데이트할 수 있습니다. 또한 UI 및 CLI를 통해 교육을 모니터링할 수 있으므로 실험 진행 상황을 쉽게 모니터링할 수 있습니다.</block>
  <block id="ecbeff08f5ec15c6952355b518d4ae02" category="paragraph">NetApp Snapshot은 교육 코드 내에 통합되어 모든 실험에 대한 데이터 상태 및 훈련 모델을 캡처합니다. 이 기능을 사용하면 사용된 데이터 및 코드의 버전과 생성된 관련 교육 모델을 추적할 수 있습니다.</block>
  <block id="63addc90b28c066bd235c900fed65314" category="section-title">AKS 설정 및 설치</block>
  <block id="55b295c729173e8c0c745bb036b03270" category="paragraph">AKS 클러스터의 설정 및 설치는 로 이동하십시오<block ref="77c1c334ebc4c997080bda32aa569d69" category="inline-link-rx"></block>. 그런 다음 다음 다음 일련의 단계를 수행합니다.</block>
  <block id="8f9d847fad9782b080de76b0161b1c45" category="list-text">노드 유형(시스템(CPU) 또는 작업자(GPU) 노드인지 여부)을 선택할 때 다음을 선택합니다.</block>
  <block id="957d1a35f975177c3fd161490f3e2d83" category="list-text">S tandard_DS2_v2 크기의 1차 시스템 노드 agentpool을 추가합니다. 기본 3개 노드를 사용합니다.</block>
  <block id="8853a13db2e2a03cb5b2f1186fbcd0a6" category="list-text">Standard_NC6s_v3 풀 크기로 작업자 노드 'gpupool'을 추가합니다. GPU 노드에 대해 최소 3개의 노드를 사용합니다.</block>
  <block id="5085043d6dea89934a2e516fc46f891a" category="paragraph"><block ref="5085043d6dea89934a2e516fc46f891a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633b880bff72a9f1c1114df31dec55bf" category="admonition">배포에는 5~10분이 소요됩니다.</block>
  <block id="f55bb34768c41f91318fb57b85c1def9" category="inline-link">도구를 설치합니다</block>
  <block id="6369fc9d36c9d56cbebefdeccda5fbff" category="list-text">구축이 완료되면 Connect to Cluster를 클릭합니다. 새로 생성한 AKS 클러스터에 연결하려면 로컬 환경(랩톱/PC)에서 Kubernetes 명령줄 도구를 설치하십시오. 를 방문하십시오<block ref="bcd577f96ff7023ec6fd5c904f040896" category="inline-link-rx"></block> OS에 따라 설치합니다.</block>
  <block id="811c47e56617f97db3579bc32a9085c9" category="inline-link">로컬 환경에 Azure CLI를 설치합니다</block>
  <block id="ea5d45554a3e9cb9cbc0ddea4c228b28" category="list-text"><block ref="2db79c584144175dd0bb69b6c7045fc9" category="inline-link-rx"></block>.</block>
  <block id="825ca3bff78c42ec87920dfbce105fae" category="list-text">터미널에서 AKS 클러스터에 액세스하려면 먼저 'az login'을 입력하고 자격 증명을 입력하십시오.</block>
  <block id="193937b265ce655417f00a79334d3937" category="list-text">Azure CLI에서 다음 명령을 입력합니다.</block>
  <block id="cbf78d8bb0be543834c56e61560773b0" category="admonition">여기에 표시된 대로 6개 노드가 모두 가동되어 실행 중이면 AKS 클러스터가 로컬 환경에 연결되고 준비됩니다.</block>
  <block id="e8085ec7505cfe6f3cfbe2c2628386dc" category="paragraph"><block ref="e8085ec7505cfe6f3cfbe2c2628386dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0143a2caee1b9ab090de587206b65fe6" category="section-title">Azure NetApp Files에 대해 위임된 서브넷을 생성합니다</block>
  <block id="450cf7e7f8262fdaa3454c2e11aad687" category="paragraph">Azure NetApp Files에 대해 위임된 서브넷을 만들려면 다음 단계를 수행하십시오.</block>
  <block id="0ca30ab1eb5e523356720465eb7439c8" category="list-text">Azure 포털 내의 가상 네트워크로 이동합니다. 새로 생성한 가상 네트워크를 찾습니다. 여기에 표시된 대로 AKS-VNET와 같은 접두사가 있어야 합니다. 가상 네트워크의 이름을 클릭합니다.</block>
  <block id="ce0c628aca3577055043c7f8364600d9" category="paragraph"><block ref="ce0c628aca3577055043c7f8364600d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="25157709e5a253560f5ec68b8262563c" category="list-text">서브넷 을 클릭하고 상단 도구 모음에서 + 서브넷 을 선택합니다.</block>
  <block id="d9bf5876b80dbf558587f06630e3915c" category="paragraph"><block ref="d9bf5876b80dbf558587f06630e3915c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a07ef5dbc59d5ba150de82d519fb4f8" category="list-text">서브넷에 ANF.SN과 같은 이름을 입력하고 Subnet Delegation 제목에서 Microsoft.NetApp/volumes 을 선택합니다. 다른 어떤 것도 변경하지 마십시오. 확인 을 클릭합니다.</block>
  <block id="a8ccea52e17d54aea1295a99ab4d5c2e" category="paragraph"><block ref="a8ccea52e17d54aea1295a99ab4d5c2e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d182b62071ada1a29e4f9c26487c1121" category="paragraph">Azure NetApp Files 볼륨은 애플리케이션 클러스터에 할당되며 Kubernetes에서 영구 볼륨 청구(PVC)로 사용됩니다. 또한, 이러한 할당을 통해 볼륨을 Jupyter 노트북, 서버리스 기능 등과 같은 다양한 서비스에 유연하게 매핑할 수 있습니다</block>
  <block id="a74ff852d3b3b8447b0306018a76c4f1" category="paragraph">서비스 사용자는 다양한 방법으로 플랫폼의 스토리지를 사용할 수 있습니다. Azure NetApp Files의 주요 이점은 다음과 같습니다.</block>
  <block id="a7c5a83cc4ccf14374e496bcbb4363f5" category="list-text">사용자에게 스냅샷을 사용할 수 있는 기능을 제공합니다.</block>
  <block id="ea437fe76a4bba5bf335daccbbd24b50" category="list-text">사용자가 Azure NetApp Files 볼륨에 대량의 데이터를 저장할 수 있도록 지원</block>
  <block id="cedebf66380d43f58c07dfb1d4d686a6" category="list-text">대규모 파일 세트에서 모델을 실행할 때 Azure NetApp Files 볼륨의 성능 이점을 확보</block>
  <block id="75ab13308585f62c3cd57a246d0e0c64" category="section-title">Azure NetApp Files 설정</block>
  <block id="8c060d9ae24c7bc4518e54cd5ed13098" category="inline-link">QuickStart: Azure NetApp Files를 설정하고 NFS 볼륨을 생성합니다</block>
  <block id="fd01c32c80d631ed4bebff78fa83b23e" category="paragraph">Azure NetApp Files 설정을 완료하려면 먼저 에 설명된 대로 구성해야 합니다<block ref="2f4e63e538c7dd311b18db058621cef8" category="inline-link-rx"></block>.</block>
  <block id="e26f032bd6f7f5636860d6b94ac84859" category="paragraph">하지만 Trident를 통해 볼륨을 생성하므로 Azure NetApp Files용 NFS 볼륨을 생성하는 단계를 생략할 수 있습니다. 계속하기 전에 다음 사항을 확인하십시오.</block>
  <block id="e953b5e281d40c5db3cc047889eec4f2" category="inline-link">Azure NetApp Files 및 NetApp 리소스 공급자에 등록(Azure 클라우드 셸 이용)</block>
  <block id="3b46d13fb20fe6a92456f742b5732774" category="list-text"><block ref="527fb205c939c551ed93f597562513fb" category="inline-link-rx"></block>.</block>
  <block id="d0652e942d3d4b469179248d72ccaa5c" category="inline-link">Azure NetApp Files에서 계정을 생성했습니다</block>
  <block id="82a51bbfec23ca7366c216813caeacc8" category="list-text"><block ref="874637dbfce24ba5a63adadd91968dc9" category="inline-link-rx"></block>.</block>
  <block id="02209b9e3a221b39bf0ce87641e7afc6" category="inline-link">용량 풀을 설정합니다</block>
  <block id="7b4cb99ad8c150ff95b1a65d0f0524cc" category="list-text"><block ref="0fa33cef09dfad4c8795f42dd9dd5248" category="inline-link-rx"></block> (요구사항에 따라 최소 4TiB 표준 또는 프리미엄).</block>
  <block id="1c7c9057bf4f7aee40c5a117c160c0fd" category="section-title">AKS 가상 네트워크 및 Azure NetApp Files 가상 네트워크 피어링</block>
  <block id="998069ab494c49ade2cc77591c02d9fa" category="paragraph">다음으로 다음 단계를 수행하여 Azure NetApp Files VNET를 사용하여 AKS 가상 네트워크(VNET)를 수행하십시오.</block>
  <block id="bf12dce8dcc6febfeddec5ed2570e7d7" category="list-text">Azure 포털 맨 위의 검색 상자에 가상 네트워크를 입력합니다.</block>
  <block id="3f961f79effdf0aa37042e1733ee53ef" category="list-text">VNET AKS-VNET-NAME을 클릭한 다음 검색 필드에 Pebsearch를 입력합니다.</block>
  <block id="0249aa06ef3e10e8754106189b542be4" category="list-text">추가 를 클릭하고 아래 표에 제공된 정보를 입력합니다.</block>
  <block id="6f16a5f8ff5d75ab84c018adacdfcbb7" category="cell">필드에 입력합니다</block>
  <block id="88645c17102d75583e93db9aa716b012" category="cell">값 또는 설명입니다</block>
  <block id="f80824cb9ab9f704542dec0c71c5f38b" category="cell">피어링 링크 이름</block>
  <block id="5d43607a5a0ebb50f3ea9348485daa15" category="cell">AKS-VNET-NAME_to_anf</block>
  <block id="62912b52e584278e26870d9e5092e723" category="cell">SubscriptionID(하위 스크립트 ID)</block>
  <block id="7d97336a164d9ce685e88a121141b189" category="cell">피어링을 사용하는 Azure NetApp Files VNET의 구독</block>
  <block id="82a60e720574cf435dda0a03976e8323" category="cell">VNET 피어링 파트너</block>
  <block id="d2ade9376eb8b87db099330d20c4f180" category="cell">Azure NetApp Files VNET</block>
  <block id="5b92ad691782a9e4cc701e479c90997f" category="admonition">모든 별표 이외의 섹션은 기본적으로 그대로 둡니다</block>
  <block id="0e5883528161213f3edc02dd718e1693" category="list-text">추가 또는 확인 을 클릭하여 가상 네트워크에 피어링을 추가합니다.</block>
  <block id="12eee9bf8836d675f26602260016f7da" category="inline-link">가상 네트워크 피어링을 생성, 변경 또는 삭제합니다</block>
  <block id="fa1f15d2aebd0592f338ea9f49e06377" category="paragraph">자세한 내용은 를 참조하십시오<block ref="610fa6db13a2eefe4a391b16732fbbf0" category="inline-link-rx"></block>.</block>
  <block id="91d2f55da5f23abbcf1a0656897d101b" category="paragraph">Trident는 NetApp에서 애플리케이션 컨테이너 영구 스토리지를 위해 유지하는 오픈 소스 프로젝트입니다. Trident는 Pod 자체로 실행되는 외부 공급자 컨트롤러로 구축되어 볼륨을 모니터링하고 프로비저닝 프로세스를 완전히 자동화했습니다.</block>
  <block id="4088b2a65b2a3182209479dced5e78c5" category="paragraph">NetApp Trident를 사용하면 교육 데이터 세트 및 교육 받은 모델을 저장하기 위한 영구 볼륨을 생성하여 K8s와 원활하게 통합할 수 있습니다. 이 기능을 사용하면 데이터 과학자와 데이터 엔지니어가 데이터 세트를 수동으로 저장하고 관리해야 하는 번거로움 없이 K8s를 더 쉽게 사용할 수 있습니다. 또한 Trident는 논리적 API 통합을 통해 데이터 관리 관련 작업을 통합하므로 데이터 과학자가 새로운 데이터 플랫폼 관리에 대해 배울 필요가 없습니다.</block>
  <block id="b8b9eab8c1ed7b79387652490f5724ec" category="section-title">Trident를 설치합니다</block>
  <block id="77dc68d199719a4b8f5eba742ecb7056" category="paragraph">Trident 소프트웨어를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="2f2e9ef9449e2f31756b1d3683a207b3" category="inline-link">첫 번째 설치 Helm</block>
  <block id="089f0e488d4e2b1a4b02d6d6b638c9d3" category="list-text"><block ref="b3c10ddb3b7f0e3e121ce123f60cc497" category="inline-link-rx"></block>.</block>
  <block id="e12559703ec38e80de7b94fecc84a043" category="list-text">Trident 21.01.1 설치 프로그램을 다운로드하고 압축을 풉니다.</block>
  <block id="7ee913d1a8b01e1a461f9eb99b0bba74" category="list-text">디렉터리를 '트리덴트 - 설치자'로 변경합니다.</block>
  <block id="8ad5650fb94bff45b328581838d836fd" category="list-text">tridentctl을 시스템 '$path'의 디렉토리에 복사합니다</block>
  <block id="6da8d48465deb31425595b33a9172acf" category="list-text">Helm을 사용하여 K8s 클러스터에 Trident 설치:</block>
  <block id="7b09729551ddb1a7445f559eb1186978" category="list-text">디렉터리를 Helm 디렉토리로 변경합니다.</block>
  <block id="27b4c36cae8d1c4fd515d289942c87cc" category="list-text">Trident를 설치합니다.</block>
  <block id="cea04f1ceb2ba2472ec50de3a03a689c" category="list-text">Trident Pod의 상태를 확인합니다. 일반적인 K8s 방식:</block>
  <block id="6ac3c5fc780260af91dd10523188e6fd" category="list-text">모든 Pod가 가동되어 실행 중이면 Trident가 설치되어 앞으로 이동하기에 좋습니다.</block>
  <block id="7862dabe13bf66a99fcfd3a6b1af4d94" category="section-title">Azure NetApp Files 백엔드 및 스토리지 클래스 설정</block>
  <block id="7e98dce86779e84763b71398d851f7bb" category="paragraph">Azure NetApp Files 백엔드 및 스토리지 클래스를 설정하려면 다음 단계를 수행하십시오.</block>
  <block id="dadab4bead78e450739c0f56bad40cda" category="list-text">홈 디렉토리로 다시 전환합니다.</block>
  <block id="65b8f7db2e9a3793e76d2ec3787f71fa" category="inline-link">프로젝트 리포지토리</block>
  <block id="03636accad716972f761628ea21e43f6" category="list-text">의 클론을 생성합니다<block ref="2b240ffa21ddbdc99d1706dee4302f7e" category="inline-link-rx"></block> 차선 감지 SCNN-horovod.</block>
  <block id="0ea725833b806058fe7810e6be91f9c0" category="list-text">트리덴트-구성 디렉토리로 이동합니다.</block>
  <block id="c51fa2034e7d5d97ec8c31248fc18e98" category="list-text">Azure 서비스 원칙 생성(서비스 원칙은 Trident가 Azure와 통신하여 Azure NetApp Files 리소스에 액세스하는 방법입니다.)</block>
  <block id="7c794fc1e683a6843753158bb92cab75" category="paragraph">출력은 다음 예와 같이 표시되어야 합니다.</block>
  <block id="203565dfd87ac32927ce5a828d45babd" category="list-text">Trident의 백엔드 json 파일을 생성합니다.</block>
  <block id="d7e47f31bf1c921dd5e28ee7e6f5cd34" category="list-text">원하는 텍스트 편집기를 사용하여 아래 표의 "anf-backend.json" 파일 안에 있는 다음 필드를 작성합니다.</block>
  <block id="689202409e48743b914713f96d93947c" category="cell">값</block>
  <block id="8c443e170595ba0feac007ffb92cb49a" category="cell">구독 ID</block>
  <block id="deb6a9aaa10be6bb24feea6a3540128c" category="cell">Azure 구독 ID입니다</block>
  <block id="bc54592d6183695b841c6d1880ec0bf8" category="cell">텐antID</block>
  <block id="b147f00fa948b22faa89aa8044904495" category="cell">Azure 테넌트 ID(이전 단계의 az ad SP 출력에서)</block>
  <block id="93c5bebdea9c94a0740fe6fd9bb250f0" category="cell">클라이언트 ID입니다</block>
  <block id="5760e6800c58c7dc9ee68efdc6db38de" category="cell">appID(이전 단계의 az ad SP 출력에서)</block>
  <block id="2b53761249254ce6b502f521e5cc0683" category="cell">clientSecret</block>
  <block id="0571f76a94493cb2020d6c3b7453a367" category="cell">암호(이전 단계의 az ad SP 출력에서)</block>
  <block id="25e6b7ea847b31b4f88b60acd65052db" category="paragraph">파일은 다음 예제와 같습니다.</block>
  <block id="49356331b94221561b7751ae1f5343a9" category="list-text">다음과 같이 구성 파일로 anf-backend.json을 사용하여 trident 네임스페이스에 Azure NetApp Files 백엔드를 생성하도록 Trident에 지시합니다.</block>
  <block id="bd9c5e9bd5f130a6fbdbcaeb04656652" category="list-text">스토리지 클래스를 생성합니다.</block>
  <block id="a9fa0a3d8bf1bce76ef654f0a047b8fe" category="list-text">K8 사용자는 이름별로 저장소 클래스를 지정하는 PVC를 사용하여 체적을 프로비저닝합니다. K8s에게 다음을 사용하여 이전 단계에서 생성한 Azure NetApp Files 백엔드를 참조하는 스토리지 클래스 "azurenetappfiles"를 생성하도록 지시합니다.</block>
  <block id="5e121b263b32950e629eaf774c12da78" category="list-text">다음 명령을 사용하여 스토리지 클래스가 생성되었는지 확인합니다.</block>
  <block id="202ed88f7ec48eda708f6c062786f474" category="paragraph"><block ref="202ed88f7ec48eda708f6c062786f474" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72611a189b0331f709788d99912a1bd7" category="section-title">AKS에 볼륨 스냅샷 구성 요소를 구축하고 설정합니다</block>
  <block id="3ea90db69187da57e9739e033add6801" category="paragraph">클러스터에서 올바른 볼륨 스냅샷 구성 요소가 사전 설치되지 않은 경우 다음 단계를 실행하여 이러한 구성 요소를 수동으로 설치할 수 있습니다.</block>
  <block id="c3987ca9f11aad20ef5d2ae0dd30f9cb" category="admonition">AKS 1.18.14에는 Snapshot Controller가 사전 설치되어 있지 않습니다.</block>
  <block id="312e34d756f6ef39f0bd74e2f844773f" category="list-text">다음 명령을 사용하여 스냅샷 베타 CRD를 설치합니다.</block>
  <block id="529616f838a47cade6e5fac6f879ce5a" category="list-text">GitHub에서 다음 문서를 사용하여 Snapshot Controller를 설치합니다.</block>
  <block id="90a2427d3a3145723cd2a130c5372865" category="inline-link">볼륨 스냅샷 클래스입니다</block>
  <block id="8f2838f14b6a64dd466dc23bcf7e3c01" category="list-text">K8s 'volumesnapshotclass'를 설정합니다. 볼륨 스냅샷을 생성하기 전에<block ref="cba124de563550c68e57cf9a6641a5d1" category="inline-link-rx"></block> 설정해야 합니다. Azure NetApp Files용 볼륨 스냅샷 클래스를 생성하고 NetApp Snapshot 기술을 사용하여 ML 버전 관리를 달성하는 데 사용합니다. volumesapshotclass NetApp-CSI-snapclass를 생성하고 다음과 같이 기본 'volumesnapshotclass'로 설정합니다.</block>
  <block id="adc3a39a071327998da9cc6708ef4fe8" category="paragraph"><block ref="adc3a39a071327998da9cc6708ef4fe8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="770bec683fa99c1a917babb074d95e66" category="list-text">다음 명령을 사용하여 볼륨 스냅샷 복사본 클래스가 생성되었는지 확인합니다.</block>
  <block id="99b5a364457d91999df6ca6488b800f2" category="paragraph"><block ref="99b5a364457d91999df6ca6488b800f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d9a6cca62c9095cbae70692ef82741c" category="section-title">AI 설치 를 실행하십시오</block>
  <block id="d1d2b81816d977b7a9d3480a495beda5" category="paragraph">run:AI를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="7899a1a12ecf76a5676a6d5ddb64842f" category="inline-link">설치 실행: AKS에 AI 클러스터</block>
  <block id="54437101a8cdfe297499d517331ced60" category="list-text"><block ref="400679f1b873ae4a832f018613d486cc" category="inline-link-rx"></block>.</block>
  <block id="5f854e827ba37f66f45f8e47643e23ea" category="list-text">app.runai.ai 으로 이동하여 새 프로젝트 만들기 를 클릭하고 이름을 차선 감지 로 지정합니다. 이렇게 하면 runai로 시작하는 K8s 클러스터의 이름 뒤에 프로젝트 이름이 붙습니다. 이 경우 생성된 네임스페이스는 runai-lane-detection입니다.</block>
  <block id="e699d582d1b58a9a23ebd74cab11d5bc" category="paragraph"><block ref="e699d582d1b58a9a23ebd74cab11d5bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="546524b2c8ed6fd083c9286159ebd55a" category="inline-link">설치 실행: AI CLI</block>
  <block id="f3a9807f54199fd5dbad651af2ea853a" category="list-text"><block ref="6291ffcd5a23a3d0b996bc90930ef0b3" category="inline-link-rx"></block>.</block>
  <block id="08d1d73b27232763a82ef46a413779ce" category="list-text">터미널에서 다음 명령을 사용하여 레인 감지를 기본 run:AI 프로젝트로 설정합니다.</block>
  <block id="0ca589f93fd9565aa5fc097fd66437ae" category="paragraph"><block ref="0ca589f93fd9565aa5fc097fd66437ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cd1a85dd18a7a0b8f1d07b4240fafcf" category="list-text">프로젝트 네임스페이스(예: lane-detection)에 대해 ClusterRole 및 ClusterRoleBinding을 만들어 runai-lane-detection 네임스페이스에 속한 기본 서비스 계정은 작업 실행 중에 'volumesnapshot' 작업을 수행할 수 있는 권한을 갖습니다.</block>
  <block id="351495b134e625df33dfb5230d6eab7b" category="list-text">다음 명령을 사용하여 'runai-lane-detection'이 존재하는지 확인하기 위한 네임스페이스를 나열합니다.</block>
  <block id="bd546162071f28fd50f8c977ac61149e" category="paragraph">출력은 다음 예와 같이 나타나야 합니다.</block>
  <block id="8c33c9910dfecb6260489cd05f43b275" category="paragraph"><block ref="8c33c9910dfecb6260489cd05f43b275" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f23930532ba19f8970c6dcb4b6ad778f" category="list-text">다음 명령을 사용하여 ClusterRole의 "netaprosnapshot" 및 ClusterRoleBinding" netappsnapshot을 생성합니다.</block>
  <block id="7e3ec6f763cd8a13380162aba60c47e0" category="section-title">실행:AI 작업으로 TuSimple 데이터 세트를 다운로드하고 처리합니다</block>
  <block id="c0cc307d9f63d0a096f8d6e3193cd561" category="paragraph">실행 시 TuSimple 데이터 세트를 다운로드하고 처리하는 프로세스는 선택 사항입니다. AI 작업은 선택 사항입니다. 여기에는 다음 단계가 포함됩니다.</block>
  <block id="52eeaf7bac6d3e2111d129a11d0bafed" category="list-text">기존 Docker 이미지(예: muneer7589/download-tusimple:1.0)를 사용하려면 Docker 이미지를 빌드하고 푸시하거나 이 단계를 생략합니다</block>
  <block id="0d5647db76048e129c1146a822abbdd8" category="list-text">홈 디렉토리로 이동합니다.</block>
  <block id="02c403c221afbdccdc4f7182e2eb5cb7" category="list-text">'lane-detection-SCNN-horovod' 프로젝트의 데이터 디렉토리로 이동합니다.</block>
  <block id="eed104c2f8af7c3526ec55b8cc69dde7" category="list-text">build_image.sh 쉘 스크립트를 수정하고 Docker 리포지토리를 사용자 위치로 변경합니다. 예를 들어, 'muneer7589'를 Docker 리포지토리 이름으로 바꿉니다. Docker 이미지 이름과 태그(예: dowload-tusimple, 1.0)를 변경할 수도 있습니다.</block>
  <block id="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="paragraph"><block ref="689ff7d72d2cc0f0d595b0c8ace1cdfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed49e04589e6c9071bbd1af307f83a0" category="list-text">스크립트를 실행하여 Docker 이미지를 구축하고 다음 명령을 사용하여 Docker 저장소로 푸시합니다.</block>
  <block id="8ebf5e70d0ed304519c7c9b525d80af1" category="list-text">Run:AI 작업을 제출하여 NetApp Trident가 동적으로 생성한 'PVC'에 TuSimple 레인 감지 데이터 세트를 다운로드, 추출, 전처리 및 저장합니다.</block>
  <block id="050d58b165aef32cad86839521b721b2" category="list-text">다음 명령을 사용하여 run:AI 작업을 제출하십시오.</block>
  <block id="83b4fb868b7505e293871c3e5accc98c" category="list-text">실행:AI 작업을 제출하려면 아래 표의 정보를 입력하십시오.</block>
  <block id="e50d72d773874b2be58530daec43900c" category="cell">-이름</block>
  <block id="37e9bb74490b0ac510effff5a546f11d" category="cell">작업의 이름입니다</block>
  <block id="5503ed8f71ae365eb6f5e8221562a0eb" category="cell">-PVC</block>
  <block id="626299ff067d1e6a178beced1631ab43" category="cell">[StorageClassName]:Size:ContainerMountPath 형식의 PVC 위의 작업 제출에서 스토리지 클래스 azurenetappfiles가 있는 Trident를 사용하여 필요 시 PVC를 만듭니다. 여기서 영구 볼륨 용량은 100Gi 이며 경로 /mnt에 마운트됩니다.</block>
  <block id="0247d7fb481075907b9eb467cfe90e3a" category="cell">?곸긽</block>
  <block id="b30f1ca8b35fd6ccab829a959f414a51" category="cell">이 작업에 대한 컨테이너를 생성할 때 사용할 Docker 이미지입니다</block>
  <block id="22a55ba6c8590fa98f1b3234141f2848" category="paragraph"><block ref="22a55ba6c8590fa98f1b3234141f2848" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af270e479cd849e4a9cb6d17b76585ef" category="list-text">제출된 RUN:AI 작업을 나열합니다.</block>
  <block id="f740410b6ea33d3ffc740140cc23a0e2" category="paragraph"><block ref="f740410b6ea33d3ffc740140cc23a0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51869a860c4af748ec2815d406929a17" category="list-text">제출된 작업 로그를 확인하십시오.</block>
  <block id="ab353387b0e5276e03aecae4cc95d150" category="paragraph"><block ref="ab353387b0e5276e03aecae4cc95d150" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84dd51baa0cf15db0a639dbb6d5d8ee" category="list-text">만든 PVC를 나열합니다. 다음 단계에서 이 'PVC' 명령을 사용하여 훈련하십시오.</block>
  <block id="cc2e05fe54a847aee415a2deb0b7f13e" category="paragraph"><block ref="cc2e05fe54a847aee415a2deb0b7f13e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b20e4749f78095f0b9adf5c3cad36f81" category="list-text">실행 중인 작업 확인: AI UI (또는 'app.run.ai`).</block>
  <block id="ced39410c19f3968638fc81e16743f32" category="paragraph"><block ref="ced39410c19f3968638fc81e16743f32" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3dee54cb181d3bfde644600fb15bbac4" category="section-title">Horovod를 사용하여 분산 차선 감지 교육을 수행합니다</block>
  <block id="645e2c981858a720c673c6a782efd9ea" category="paragraph">Horovod를 사용하여 분산 차선 감지 교육을 수행하는 것은 선택적 프로세스입니다. 그러나 다음과 같은 단계가 있습니다.</block>
  <block id="04e568eec6dda4a0cfb1fc6680509d35" category="list-text">기존 Docker 이미지(예: 'muneer7589/dist-lane-detection: 3.1):'를 사용하려면 Docker 이미지를 빌드하고 푸시하거나 이 단계를 건너뜁니다</block>
  <block id="b01fdc5088b4a04549ed5e7cc71f898b" category="list-text">홈 디렉토리로 이동합니다.</block>
  <block id="14e21ef8495bc1dd543db0aebbe06c5b" category="list-text">프로젝트 디렉터리 레인 감지 SCNN-horovod로 이동합니다</block>
  <block id="0a27aa824e245e7b31f5f8d990636ead" category="list-text">'build_image.sh' 쉘 스크립트를 수정하고 Docker 리포지토리를 사용자 이름으로 변경합니다(예: 'muneer7589'를 Docker 리포지토리 이름으로 대체). Docker 이미지 이름과 태그(dist-lane-detection, 3.1 등)도 변경할 수 있습니다.</block>
  <block id="c9ce95c3d4cf96d5e894e4a834754cb6" category="paragraph"><block ref="c9ce95c3d4cf96d5e894e4a834754cb6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2776d43d1e635424496622f14cfd745c" category="list-text">스크립트를 실행하여 Docker 이미지를 구축하고 Docker 저장소로 이동합니다.</block>
  <block id="b9bcfd06c5cdfc67a00ffe8a0c846318" category="list-text">배포 교육(MPI)을 수행하기 위한 AI 작업 제출:</block>
  <block id="f3b76b64a9761cfb85f0ddc37d910fef" category="list-text">러닝 제출 사용: 이전 단계에서 PVC를 자동으로 생성하기 위한 AI(데이터 다운로드용)만 RWO 액세스를 허용할 수 있습니다. 이 경우 여러 Pod 또는 노드가 동일한 PVC에 대한 분산 교육 액세스를 허용하지 않습니다. 액세스 모드를 ReadWriteMany로 업데이트하고 Kubernetes 패치를 사용하여 업데이트합니다.</block>
  <block id="2874172b683ddc4047fd63f29baf543d" category="list-text">먼저 다음 명령을 실행하여 PVC의 볼륨 이름을 가져옵니다.</block>
  <block id="bcc0952c2970bfd6c85cd65050e00533" category="paragraph"><block ref="bcc0952c2970bfd6c85cd65050e00533" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64ac0e4e6343f4593e210b98f9c91de" category="list-text">볼륨을 패치하고 ReadWriteMany에 대한 액세스 모드를 업데이트합니다(다음 명령에서 볼륨 이름을 사용자 이름으로 바꾸기).</block>
  <block id="7a9d347cf2f324e82478a9cf243448f7" category="list-text">아래 표의 정보를 사용하여 배포된 교육 작업을 실행하기 위한 AI MPI 작업 제출:</block>
  <block id="b068931cc450442b63f5b3d276ea4297" category="cell">이름</block>
  <block id="e4580c1854231c935f0cf2eb4609d97a" category="cell">분산된 교육 작업의 이름입니다</block>
  <block id="384dd16a327b7f16278642f008c27fab" category="cell">대형 shm</block>
  <block id="fc9fed4d0a3cb207102499ba041f2603" category="cell">대용량 /dev/shm 디바이스 마운트 RAM에 마운트된 공유 파일 시스템이며 여러 CPU 작업자가 CPU RAM에 배치를 처리 및 로드할 수 있을 만큼 충분한 크기의 공유 메모리를 제공합니다.</block>
  <block id="530968b205d33b3869aa32e2933fbfad" category="cell">프로세스</block>
  <block id="403e4aa48fedb1c5777ee913b2f2bedb" category="cell">분산된 교육 프로세스 수</block>
  <block id="0aa0be2a866411d9ff03515227454947" category="cell">GPU</block>
  <block id="031492a2d708ca774bd08c099eb4dd79" category="cell">이 작업에서 작업에 할당할 GPU/프로세스 수, GPU 작업자 프로세스 3개(--프로세스=3)가 있으며, 각각 단일 GPU(--GPU 1)로 할당됩니다.</block>
  <block id="642542e40351edbd731ebad352b31317" category="cell">PVC</block>
  <block id="c50723a53a74a682495f8c3810ce4a65" category="cell">이전 작업(download-tusimple-data-0)에서 생성한 기존 영구 볼륨(PVC-download-tusimple-data-0)을 사용하고 path /mnt에 마운트됩니다</block>
  <block id="8c236f63f205a50942b609a6d45734a7" category="cell">컨테이너에 설정할 환경 변수를 정의합니다</block>
  <block id="61dcf83940f915d0c5fe5b985eed7be8" category="cell">작업자 사용</block>
  <block id="f84e120605e14d9755a1ed2e8e03cea6" category="cell">인수를 true로 설정하면 다중 프로세스 데이터 로드가 설정됩니다</block>
  <block id="90b186f5d2a6890e77373c8aa60461e7" category="cell">작업자 수</block>
  <block id="a10574eb8e119b847fb5ab95b788e723" category="cell">데이터 로더 작업자 프로세스의 수입니다</block>
  <block id="61c67ea819106ff81c08249014791d3b" category="cell">batch_size를 선택합니다</block>
  <block id="243f7fe32e2dbb7748c1a018fe60016e" category="cell">교육 배치 크기</block>
  <block id="d07f4474a5e5996da9b6e57abb250331" category="cell">VAL을 사용합니다</block>
  <block id="919bc92a851c1d3e2c467e844398b751" category="cell">인수를 TRUE로 설정하면 유효성 검사가 허용됩니다</block>
  <block id="c4407b612c3b5e2c00c1b5522c686c84" category="cell">Val_batch_size를 선택합니다</block>
  <block id="597765782da042e86019b4c919a86248" category="cell">검증 배치 크기</block>
  <block id="18e0d33045db50bb37e6f2fcd5c0b842" category="cell">snapshot을 설정합니다</block>
  <block id="67c5deea68dff022b0f807ffb3bf56e2" category="cell">인수를 TRUE로 설정하면 ML 버전 관리를 위해 데이터 및 훈련된 모델 스냅샷을 생성할 수 있습니다</block>
  <block id="cdd7dd1603420ef6c3efe7b264205137" category="cell">PVC_이름</block>
  <block id="d95926771c9100db9ba3e3247c86a192" category="cell">스냅샷을 생성할 PVC의 이름입니다. 위의 작업 제출에서 데이터 세트 및 교육 모델로 구성된 PVC-download-tusimple-data-0의 스냅샷을 촬영하고 있습니다</block>
  <block id="b302d66ab7f3f0c94236ff26c8ead4d9" category="inline-image-macro">오류: 그래픽 이미지가 없습니다</block>
  <block id="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="paragraph"><block ref="d52f66f6b7bb9cf3c7382d8ce6f6b9ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3299ed00d03beff0cc2ebaf178a91786" category="list-text">제출된 작업을 나열합니다.</block>
  <block id="2e593aa2ccf62807184e56a543d23e97" category="paragraph"><block ref="2e593aa2ccf62807184e56a543d23e97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82abe908a319245230ef0f3ec84c263f" category="list-text">제출된 작업 로그:</block>
  <block id="dab56217fc48a1919fee48434a7c7204" category="paragraph"><block ref="dab56217fc48a1919fee48434a7c7204" category="inline-image-macro-rx" type="image"></block></block>
  <block id="981528b0e4cd4a19c56310c6b9c915ce" category="list-text">아래 그림과 같이 RUN TO/RUN TO/AI GUI(또는 app.runai.ai): RUN:AI 대시보드 에서 교육 작업을 확인하십시오. 첫 번째 그림에서는 분산 훈련 작업에 할당된 3개의 GPU를 AKS의 3개 노드에 분산시키고, 두 번째 실행인 AI 작업에 대해 자세히 설명합니다.</block>
  <block id="d8cbd4299e4baf5de5572bf6af32dd52" category="paragraph"><block ref="d8cbd4299e4baf5de5572bf6af32dd52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="90fdc4068f0b660d1d6b102946986bd1" category="paragraph"><block ref="90fdc4068f0b660d1d6b102946986bd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9e8bb0b427c33dd6cf63d1a3a37c7022" category="list-text">교육이 완료되면 RUN:AI 작업과 연결되고 생성된 NetApp Snapshot 복사본이 있는지 확인하십시오.</block>
  <block id="6c94f812a836696605e3e2b6bd5ca768" category="paragraph"><block ref="6c94f812a836696605e3e2b6bd5ca768" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4c0a1395081fc81855e465c493f4967" category="section-title">NetApp 스냅샷 복사본에서 데이터를 복원합니다</block>
  <block id="ec8de1dcfce51c9d877901e2f6f5971e" category="paragraph">NetApp Snapshot 복사본에서 데이터를 복원하려면 다음 단계를 수행하십시오.</block>
  <block id="5adc4d7860e7ad0f78ada0bb1f0eaca6" category="list-text">프로젝트 디렉터리 'lane-detection-SCNN-horovod'로 이동합니다.</block>
  <block id="6344772f26907403fed713060f33b8f4" category="list-text">restore-snaphot-vc.yaML을 수정하고 데이터 복원을 원하는 스냅샷 사본으로 dataSource의 이름 필드를 업데이트합니다. 이 예제에서는 데이터 복원 위치를 PVC 이름으로 변경할 수도 있습니다.</block>
  <block id="b3b5448c329ac882bc890a1be1a1b369" category="paragraph"><block ref="b3b5448c329ac882bc890a1be1a1b369" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f8efb3d1b86c88cfab193291776b6ad" category="list-text">restore-snapshot-pvc.yAML을 사용하여 새로운 PVC를 생성한다.</block>
  <block id="34c7c2e95019754701182fe2ab194499" category="paragraph"><block ref="34c7c2e95019754701182fe2ab194499" category="inline-image-macro-rx" type="image"></block></block>
  <block id="070856555a817dbf9a4061542b2098ca" category="list-text">방금 복원한 데이터를 교육에 사용하려는 경우, 작업 제출은 이전과 동일하게 유지되며, 교육 작업을 제출할 때 다음 명령에 표시된 것처럼 'PVC_NAME'만 복원된 'PVC_NAME'으로 교체합니다.</block>
  <block id="e945ddc4d35a9c49a17bd00c53db05a6" category="section-title">성능 평가</block>
  <block id="3451b157ef07ae84bfaba5fb6639c1ba" category="paragraph">솔루션의 선형 확장성을 보여주기 위해 GPU 1개와 GPU 3개 등 두 가지 시나리오에서 성능 테스트를 수행했습니다. TuSimple 레인 감지 데이터 세트에 대한 교육 중에 GPU 할당, GPU 및 메모리 사용률, 다양한 단일 및 3노드 메트릭이 캡처되었습니다. 교육 프로세스 중 리소스 활용도를 분석하기 위해 데이터가 5배 증가합니다.</block>
  <block id="b8077d533d2f9918c47d330cbac4392d" category="inline-link-macro">Azure NetApp Files 서비스 레벨</block>
  <block id="da9b7dc2993c3c848d5d9a9a15806d8c" category="paragraph">이 솔루션을 통해 고객은 작은 데이터 세트와 몇 개의 GPU로 시작할 수 있습니다. 데이터의 양과 GPU 수요가 증가하면 고객은 표준 계층의 테라바이트를 동적으로 확장하고 프리미엄 계층까지 신속하게 확장하여 데이터 이동 없이 테라바이트당 처리량의 4배를 얻을 수 있습니다. 이 프로세스는 섹션, <block ref="bdbab4daa7de478307acc7147c869853" category="inline-link-macro-rx"></block>.</block>
  <block id="090a231c840a0cb23aa29c8d1afc7832" category="paragraph">GPU 1개의 처리 시간은 12시간 45분이었습니다. 3개 노드에서 3개의 GPU를 처리하는 데 약 4시간 30분이 소요되었습니다.</block>
  <block id="49eca64b9f03702167beb48ebd38587b" category="paragraph">이 문서의 나머지 부분에서는 개별 비즈니스 요구 사항에 따른 성능 및 확장성의 예를 보여 줍니다.</block>
  <block id="abfc10c2bc00a990735e6d27797295a8" category="paragraph">아래 그림은 1 GPU 할당 및 메모리 활용률을 보여 줍니다.</block>
  <block id="8d7e3abab70510c3f4636ff7bf953250" category="paragraph"><block ref="8d7e3abab70510c3f4636ff7bf953250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31a3d2def4927574922946c38f043c0b" category="paragraph">아래 그림은 단일 노드 GPU 활용률을 보여 줍니다.</block>
  <block id="58cf0f270760f08ac96254402d0696dc" category="paragraph"><block ref="58cf0f270760f08ac96254402d0696dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dcca9cfd87d9f2087d720ef187655cea" category="paragraph">아래 그림은 단일 노드 메모리 크기(16GB)를 보여줍니다.</block>
  <block id="e22d39f2830d0f3e3944644d0f605d41" category="paragraph"><block ref="e22d39f2830d0f3e3944644d0f605d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="576c0843e21d5ee884a067aa7b6a1a40" category="paragraph">아래 그림은 단일 노드 GPU 수(1)를 보여줍니다.</block>
  <block id="ef855771be83c072ebaafc60d2d1933f" category="paragraph"><block ref="ef855771be83c072ebaafc60d2d1933f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2c50f1b8fc86c36cc0df94dd14b46b9" category="paragraph">아래 그림은 단일 노드 GPU 할당(%)을 보여줍니다.</block>
  <block id="e295f84458327d01315b814d8deb2aea" category="paragraph"><block ref="e295f84458327d01315b814d8deb2aea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54b2b7f256373eac14419bfec5b84b21" category="paragraph">아래 그림은 3개 노드에서 GPU 할당 및 메모리인 3개의 GPU를 보여줍니다.</block>
  <block id="e763ef0e4b7cb9d022bf6db49319c570" category="paragraph"><block ref="e763ef0e4b7cb9d022bf6db49319c570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94ab4242b167972f7a9f0513ca772555" category="paragraph">아래 그림은 3개 노드의 사용률(%)에서 3개의 GPU를 보여줍니다.</block>
  <block id="d786146ae56597413fa5be548126cda9" category="paragraph"><block ref="d786146ae56597413fa5be548126cda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45c31ecb239228cac5e96860d42f9a4d" category="paragraph">아래 그림은 3개 노드의 메모리 사용률(%)에서 3개의 GPU를 보여줍니다.</block>
  <block id="2224958fd5113068ac8a3b55a336661b" category="paragraph"><block ref="2224958fd5113068ac8a3b55a336661b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79f05e8f99917560625d1cf3f2d4fc5d" category="inline-link">서비스 레벨</block>
  <block id="07c1fda2408980b5d53ea06ad3cc5ed1" category="paragraph">볼륨을 를 사용하는 다른 용량 풀로 이동하여 기존 볼륨의 서비스 수준을 변경할 수 있습니다<block ref="bc9fbd5fd43d884f02abe6a6f9b51339" category="inline-link-rx"></block> 볼륨에 대한 을 선택합니다. 볼륨에 대한 이 기존 서비스 수준 변경 사항은 데이터를 마이그레이션할 필요가 없습니다. 볼륨에 대한 액세스에도 영향을 주지 않습니다.</block>
  <block id="5e2ff0b5dc3206032a81aa3aecb7c462" category="section-title">볼륨의 서비스 수준을 동적으로 변경합니다</block>
  <block id="58e691ddc6184f73e5d6b513ca5a3c49" category="paragraph">볼륨의 서비스 수준을 변경하려면 다음 단계를 수행하십시오.</block>
  <block id="3f19b438418ed162387a3050b304c89b" category="list-text">볼륨 페이지에서 서비스 수준을 변경할 볼륨을 마우스 오른쪽 단추로 클릭합니다. 풀 변경 을 선택합니다.</block>
  <block id="5acf521dbc5099b2ec33a64efac89595" category="paragraph"><block ref="5acf521dbc5099b2ec33a64efac89595" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6533c4186062235d8b7f47e232e92597" category="list-text">Change Pool 창에서 볼륨을 이동할 용량 풀을 선택합니다. 그런 다음 확인을 클릭합니다.</block>
  <block id="3f0874d07ce6ae728a6dcdda7903f9cd" category="paragraph"><block ref="3f0874d07ce6ae728a6dcdda7903f9cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb935c59f24539e0966b7ab5c761e862" category="section-title">서비스 수준 변경 자동화</block>
  <block id="1391028ed384c93fd59fd5a0097f9181" category="paragraph">동적 서비스 수준 변경은 현재 공개 미리 보기에 있지만 기본적으로 활성화되어 있지 않습니다. Azure 구독에서 이 기능을 활성화하려면 “ 문서에 제공된 다음 단계를 수행하십시오<block ref="5c3671452d40598396b030d5c9c6dc27" category="inline-link-rx"></block>.”</block>
  <block id="407443b5508c517acd825fbcddb7ab4c" category="inline-link">AZ NetApp 파일 볼륨: ANF(Azure NetApp Files) 볼륨 리소스 관리</block>
  <block id="1d3afb31c5d2a81fca940ae760671a1c" category="list-text">Azure:CLI에 대해 다음 명령을 사용할 수도 있습니다. Azure NetApp Files의 풀 크기 변경에 대한 자세한 내용은 를 참조하십시오<block ref="8b45caafcc8d758d5c37edb19f8a2761" category="inline-link-rx"></block>.</block>
  <block id="ebd5b070cb8457b94f1916baa92c3c7d" category="inline-link">Azure NetApp Files 볼륨의 풀을 변경합니다</block>
  <block id="d5460fd5fbfbf643b9a4bc1d1de279d0" category="list-text">여기에 표시된 'et-aznetapfilesvolumepool' cmdlet은 Azure NetApp Files 볼륨의 풀을 변경할 수 있습니다. 볼륨 풀 크기 및 Azure PowerShell 변경에 대한 자세한 내용은 을 참조하십시오<block ref="70c8d95cde8b63eae0d37a8b81a31482" category="inline-link-rx"></block>.</block>
  <block id="3ad0505876550699ce505845f96683a7" category="doc">NetApp Cloud Sync를 사용하여 대화 내용 아카이빙</block>
  <block id="5b7a8a379330d9d43907b47a6d7ee306" category="inline-link-macro">Nemo Training을 사용하여 Intent 모델을 확장합니다</block>
  <block id="a7e4c14a726c28e6cb4b935701ac2899" category="paragraph">하루에 한 번 대화 기록을 CSV 파일로 덤프하면 Cloud Sync를 활용하여 로그 파일을 로컬 저장소에 다운로드할 수 있습니다. 다음 그림에서는 Cloud Sync를 사용하여 Nemo 교육을 위한 대화 기록을 전송하는 동안 Jarvis를 온프레미스 및 퍼블릭 클라우드에 구축하는 아키텍처를 보여 줍니다. Nemo 교육에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="14a0a4dd1a1c18cba42b2036fe4dfc33" category="inline-link-macro-rx"></block>.</block>
  <block id="e60c4461b2b4dcf3aa8535e3aab780b3" category="paragraph"><block ref="e60c4461b2b4dcf3aa8535e3aab780b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="00717575e300ae9f18fa0a24d97bcca5" category="inline-link-macro">다음: Nemo Training을 사용하여 Intent Models를 확장합니다</block>
  <block id="7ee8a10f8da0d566f0c5cccb9528b186" category="paragraph"><block ref="7ee8a10f8da0d566f0c5cccb9528b186" category="inline-link-macro-rx"></block></block>
  <block id="00a9f41b5383bf6bcb5b7f6540d427b4" category="summary">NVIDIA, AWS, Google 등에서 제공하는 최신 기술 및 사전 교육 모델링 툴을 사용하여 복잡한 모델을 가진 엔드 투 엔드 파이프라인을 상대적으로 쉽게 구축 및 사용자 정의할 수 있습니다.</block>
  <block id="2a3b399798aa16ecfbc1425cc560bfad" category="doc">사용 사례</block>
  <block id="14e5cae1e8e56eca8add5bdcedfe2335" category="inline-link-macro">이전: 지원 센터 분석.</block>
  <block id="d39a6e05d58eb4f71cae7257dc52a1d0" category="paragraph"><block ref="d39a6e05d58eb4f71cae7257dc52a1d0" category="inline-link-macro-rx"></block></block>
  <block id="710217ef02bea8d1d76bc6fc0e7bc056" category="paragraph">이러한 지원 센터에서 처리하는 통화 수 때문에 수동으로 수행할 경우 통화 성능 평가에 상당한 시간이 걸릴 수 있습니다. 단어 개수 계산 및 기타 방법과 같은 기존 방법은 일부 자동화를 달성할 수 있지만 이러한 방법은 동적 언어의 보다 미묘한 측면과 의미 컨텍스트를 캡처하지 않습니다. AI 모델링 기법을 사용하면 이러한 고급 분석 중 일부를 자동화된 방식으로 수행할 수 있습니다. 또한, NVIDIA, AWS, Google 등에서 제공하는 최신 기술 및 사전 교육 모델링 툴을 사용하여 복잡한 모델을 가진 엔드 투 엔드 파이프라인을 상대적으로 쉽게 구축 및 사용자 지정할 수 있습니다.</block>
  <block id="dd4541bcdb4728a1a380e825494f08e2" category="paragraph">지원 센터 정서 분석을 위한 엔드 투 엔드 파이프라인은 직원들이 통화자와 대화하면서 실시간으로 오디오 파일을 수집합니다. 그런 다음 이러한 오디오 파일을 텍스트 형식으로 변환하는 텍스트 음성 변환 구성 요소에서 사용할 수 있도록 처리됩니다. 대화의 각 문구에는 정서(긍정적, 부정적 또는 중립적)를 나타내는 레이블이 표시됩니다.</block>
  <block id="cfc9b6a29659e2208f66d876bd355200" category="paragraph">감정 분석은 통화 성과를 평가하기 위한 대화의 필수 요소를 제공할 수 있습니다. 이러한 감정은 직원과 통화자 간의 상호 작용에 대한 심도 있는 수준을 더하고 있습니다. AI 지원 정서 대시보드는 관리자가 대화 내에서 감정을 실시간으로 추적할 수 있도록 하며 직원의 과거 통화 내역을 후향적 분석합니다.</block>
  <block id="2357d01362feabb1716e49b27d23f9cf" category="inline-link">NVIDIA Maxine</block>
  <block id="a2415fcdba82ba111e08286b17d98943" category="paragraph">사전 구축된 툴을 강력한 방법으로 결합하여 이 문제를 해결하기 위한 엔드 투 엔드 AI 파이프라인을 빠르게 구축할 수 있습니다. 이 경우 NVIDIA Riva 라이브러리를 사용하여 두 개의 직렬 내 작업(오디오 전사 및 정서 분석)을 수행할 수 있습니다. 첫 번째는 감시 방식 학습 신호 처리 알고리즘이고 두 번째는 감시 방식 학습 NLP 분류 알고리즘입니다. NVIDIA TAO 툴킷을 사용하여 비즈니스 관련 데이터와 관련된 모든 사용 사례에 맞게 즉시 사용 가능한 알고리즘을 미세 조정할 수 있습니다. 따라서 훨씬 적은 비용과 리소스로 더 정확하고 강력한 솔루션을 구축할 수 있습니다. 고객은 을 통합할 수 있습니다<block ref="2aa9e1b3ec0ddf7f0bf09cdb2976222a" category="inline-link-rx"></block> 지원 센터 설계의 GPU 가속 비디오 회의 응용 프로그램용 프레임워크</block>
  <block id="076dd41fe8ba902e5439b5ba07f330ee" category="paragraph">다음 사용 사례가 이 솔루션의 핵심입니다. 두 사용 사례 모두 모델 세부 조정에는 TAO Toolkit을 사용하고 모델 배포에는 Riva를 사용합니다.</block>
  <block id="3d1aa46be43bf2f29633e829d42082af" category="list-text">텍스트 음성 변환</block>
  <block id="7cb906d40b2e5bad2205a60ef8b6a019" category="list-text">정서 분석</block>
  <block id="bc176e8f914533ec222bba678e13955f" category="paragraph">직원과 고객 간의 지원 센터 상호 작용을 분석하기 위해 오디오 통화 형식으로 각 고객 대화를 파이프라인을 통해 실행하여 문장별 감정을 추출할 수 있습니다. 그런 다음, 그 감정은 인간이 검증하여 정서를 정당화하거나 필요에 따라 조정할 수 있다. 그런 다음 레이블이 지정된 데이터가 미세 조정 단계로 전달되어 감정의 예측을 개선합니다. 레이블이 지정된 감정 데이터가 이미 있으면 모델 세부 조정을 신속하게 처리할 수 있습니다. 어느 경우든 파이프라인은 오디오를 수집하여 문장을 분류해야 하는 다른 솔루션에 일반화할 수 있습니다.</block>
  <block id="91fa9ce0e0cb723f35d6cc55f796be7e" category="paragraph"><block ref="91fa9ce0e0cb723f35d6cc55f796be7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8836d456396ee0865c317994c018a24b" category="paragraph">AI 정서 출력은 외부 클라우드 데이터베이스 또는 회사에서 관리하는 스토리지 시스템에 업로드됩니다. 감성 출력은 관리자의 정서 분석을 표시하는 대시보드 내에서 사용할 수 있도록 이 큰 데이터베이스에서 로컬 스토리지로 전송됩니다. 대시보드의 주요 기능은 고객 서비스 직원과 실시간으로 상호 작용하는 것입니다. 관리자는 통화 중에 각 문장의 감정을 실시간으로 업데이트하고 직원의 과거 성과 또는 고객 반응에 대한 과거의 평가를 통해 직원에 대한 피드백을 평가 및 제공할 수 있습니다.</block>
  <block id="586779135ffb596b1f1844ada64164b6" category="paragraph"><block ref="586779135ffb596b1f1844ada64164b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74bef786b12cb9d03a6c04df1f605181" category="inline-link-macro">NetApp DataOps 툴킷</block>
  <block id="539788a6fdaffc74393f282739bdd3e2" category="paragraph">를 클릭합니다 <block ref="95472f01c3cd86dddef6619dbb9af815" category="inline-link-macro-rx"></block> 는 Riva 추론 파이프라인에서 정서 레이블을 생성한 후에도 데이터 스토리지 시스템을 계속 관리할 수 있습니다. 이러한 AI 결과는 NetApp DataOps 툴킷에서 관리하는 데이터 스토리지 시스템에 업로드할 수 있습니다. 데이터 스토리지 시스템은 수백 개의 인서트를 관리할 수 있어야 하며 매 분마다 선택해야 합니다. 로컬 디바이스 스토리지 시스템은 더 큰 데이터 스토리지를 실시간으로 쿼리하여 압축을 풉니다. 또한 대규모 데이터 스토리지 인스턴스를 쿼리하여 기간별 데이터를 쿼리하면 대시보드 환경을 더욱 향상시킬 수 있습니다. NetApp DataOps 툴킷은 데이터를 빠르게 복제하고 이를 사용하는 모든 대시보드에 배포하여 이러한 두 용도 모두를 촉진합니다.</block>
  <block id="3190a811a89bc9da4384152bc43d1b94" category="section-title">대상</block>
  <block id="549c608b9fe93192110cc2552d28da22" category="paragraph">이 솔루션의 대상 고객은 다음과 같은 그룹을 포함합니다.</block>
  <block id="679db67ee98260ef471da732862ed356" category="list-text">직원 관리자</block>
  <block id="7e6beec614d536589c47de8f77fa1b1a" category="list-text">데이터 엔지니어/데이터 과학자</block>
  <block id="a2ce7e25564bee3c78076bcff87d1329" category="list-text">IT 관리자(사내, 클라우드 또는 하이브리드)</block>
  <block id="8dcd09ac05ad9012a6ff01f7b5fc337b" category="paragraph">대화 전반에 걸쳐 감정을 추적하는 것은 직원의 성과를 평가할 수 있는 귀중한 도구입니다. 관리자는 AI 대시보드를 사용하여 직원과 발신자가 어떻게 자신의 감정을 실시간으로 변화시킵니다．이를 통해 실시간 평가와 안내 세션을 진행할 수 있습니다． 또한, 기업은 음성 대화, 텍스트 챗봇 및 화상 회의에 참여하는 고객으로부터 중요한 고객 통찰력을 얻을 수 있습니다. 이러한 고객 분석은 최신 최첨단 AI 모델 및 워크플로우와 함께 규모에 따른 다중 모드 처리 기능을 사용합니다.</block>
  <block id="b7c29e65097b6ed45e464f6492ff670d" category="paragraph">데이터 측면에서 많은 수의 오디오 파일이 지원 센터에 의해 매일 처리됩니다. NetApp DataOps 툴킷은 모델 및 정서 분석 대시보드의 주기적인 미세 조정을 위해 이 데이터 처리 작업을 용이하게 합니다.</block>
  <block id="1da289b166db713f9283c5be78ef5b96" category="paragraph">IT 관리자는 NetApp DataOps 툴킷을 사용하여 구축 환경과 운영 환경 간에 데이터를 빠르게 이동할 수 있습니다. 또한, 실시간 추론을 위해 NVIDIA 환경과 서버를 관리하고 분산해야 합니다.</block>
  <block id="d463f48696e58e286e9c0d594169b395" category="inline-link-macro">다음: 아키텍처.</block>
  <block id="7179915e029316714169ac136027ef31" category="paragraph"><block ref="7179915e029316714169ac136027ef31" category="inline-link-macro-rx"></block></block>
  <block id="27d597678185c0988ffb2dbb0c1b941d" category="doc">ImageNet 데이터 세트 벤치마크 요약을 통한 ResNet-50</block>
  <block id="3c97b4929008c9f4091a8070f570ccd4" category="paragraph">산업 표준 벤치마크 도구 TensorFlow 벤치마크를 사용하여 이 시스템의 운영 및 성능을 검증했습니다. 이미지 분류를 위해 유명한 CNN(Convolutional Neural Network) DL 모델인 ResNet-50을 교육하기 위해 ImageNet 데이터 세트를 사용합니다. ResNet-50은 더욱 빠른 처리 시간으로 정확한 교육 결과를 제공하므로 스토리지에서 충분한 수요를 창출할 수 있습니다.</block>
  <block id="a89cd2a9c8244dab756ec04aeb8247e9" category="inline-link-macro">다음: AI 설치를 실행합니다</block>
  <block id="123704fec3ddad892d7c2ae5c4de301b" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block></block>
  <block id="1a17b23dd49d997677e18c9b9fe29935" category="summary">이 페이지에서는 기본 작업 스트림 대시보드를 사용하여 Dask를 모니터링하는 방법에 대해 설명합니다.</block>
  <block id="3268570ddd540695f3e92ff79d8f4684" category="doc">기본 작업 스트림 대시보드를 사용하여 Dask를 모니터링합니다</block>
  <block id="1e80a6d70a902d1dae25d26917a5b490" category="inline-link-macro">이전: Dask에서 Day 15를 로드하여 Dask cuML 무작위 포리스트 모델을 교육합니다.</block>
  <block id="3898f5ae37dfd830af10cdc128236b50" category="paragraph"><block ref="3898f5ae37dfd830af10cdc128236b50" category="inline-link-macro-rx"></block></block>
  <block id="9eeb55820f49a600fa229f23cfe9e5b5" category="inline-link">Dask 분산 스케줄러입니다</block>
  <block id="99b248c7005783fe2682ad82217e9a24" category="paragraph">를 클릭합니다<block ref="7df0d90bf997a373bfe85bbe10a2d2c8" category="inline-link-rx"></block> 다음과 같은 두 가지 형태로 실시간 피드백을 제공합니다.</block>
  <block id="d8516bf5d94a38a1fa1d7a8c3b92dee7" category="list-text">실시간 정보가 포함된 여러 플롯과 테이블이 포함된 대화형 대시보드</block>
  <block id="d22ebe91c5dc1499387785da997fbe7d" category="list-text">콘솔 또는 노트북에서 대화형 사용에 적합한 진행률 표시줄</block>
  <block id="6e35e4c1cc9332ebc8028df451bc4f06" category="paragraph">이 경우 다음 그림은 저장된 바이트, 스트림 수에 대한 자세한 분석 결과가 있는 작업 스트림, 실행된 관련 함수와 함께 작업 이름별 진행 상황 등을 포함하여 작업 진행 상황을 모니터링하는 방법을 보여 줍니다. 이 경우 작업자 노드가 3개이므로 스트림의 기본 청크가 3개 있고 색상 코드는 각 스트림 내의 서로 다른 작업을 나타냅니다.</block>
  <block id="5743e70224503025dacaa77fae253c4f" category="paragraph"><block ref="5743e70224503025dacaa77fae253c4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a5c7a858f05434bf6637c3995959f49" category="paragraph">개별 작업을 분석하고 실행 시간을 밀리초 단위로 점검하거나 장애물이나 장애물을 식별할 수 있는 옵션이 있습니다. 예를 들어 다음 그림에서는 랜덤 포리스트 모델 피팅 단계에 대한 작업 스트림을 보여 줍니다. DataFrame 프로세싱을 위한 고유한 청크, 랜덤 포리스트에 맞는 _Construct_RF 등 훨씬 더 많은 함수가 실행되고 있습니다. Criteo Click Logs에서 하루 동안 수집한 데이터의 크기가 45GB로 인해 대부분의 시간이 DataFrame 작업에 소비되었습니다.</block>
  <block id="816ff133aaa3d2f46ca0c7842f5fdaab" category="paragraph"><block ref="816ff133aaa3d2f46ca0c7842f5fdaab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5eca1492a19a4c24071ed91262666cf" category="inline-link-macro">다음: 교육 시간 비교.</block>
  <block id="d5d929f175d4a2062c661e45b9656f32" category="paragraph"><block ref="d5d929f175d4a2062c661e45b9656f32" category="inline-link-macro-rx"></block></block>
  <block id="17a9b27c376a8a5f5e184b2ebce41164" category="summary">모든 것이 배포된 후 새 데이터에 대한 추론을 실행합니다. 이 모델은 사용자가 검색 활동을 기반으로 광고를 클릭하는지 여부를 예측합니다. 예측 결과는 Dask cuDF에 저장됩니다. Prometheus를 사용하여 결과를 모니터링하고 Grafana 대시보드에서 시각화할 수 있습니다.</block>
  <block id="af4d0cbb3c6dcf4f3a5e831b08e40ace" category="doc">Prometheus 및 Grafana로 Dask 및 RAPIDS를 모니터링합니다</block>
  <block id="a5d741c60ca9280a87382bcc2667207c" category="inline-link-macro">이전: 교육 시간 비교.</block>
  <block id="8162cd02e2793715a1b14265f2bfb54b" category="paragraph"><block ref="8162cd02e2793715a1b14265f2bfb54b" category="inline-link-macro-rx"></block></block>
  <block id="23c1612202d19b502b3701f893fb2557" category="inline-link">RAPIDS AI 중간 포스트</block>
  <block id="9fed5c9f0dab5b88ba96d45cf450079f" category="paragraph">자세한 내용은 다음을 참조하십시오<block ref="47200b727ab2088d205d11a973529202" category="inline-link-rx"></block>.</block>
  <block id="a5705f3e27851573a7eafd2a00a523b5" category="inline-link-macro">다음: NetApp DataOps 툴킷을 사용하여 데이터 세트 및 모델 버전 관리</block>
  <block id="db75fb5c1fef47405a8df61e726e3c66" category="paragraph"><block ref="db75fb5c1fef47405a8df61e726e3c66" category="inline-link-macro-rx"></block></block>
  <block id="729d72c073b607d370c067152cc53a10" category="doc">검증 결과</block>
  <block id="25edd21a28cb2fca00ab6f30e47c6d79" category="paragraph">샘플 추론 요청을 실행하려면 다음 단계를 수행하십시오.</block>
  <block id="cb11a85322b32a7615367d2523718b49" category="list-text">클라이언트 컨테이너/포드에 셸을 가져옵니다.</block>
  <block id="b489ec265fd981ff7aa78a7721bd3101" category="list-text">샘플 추론 요청을 실행합니다.</block>
  <block id="15c5e1ffe753f0365f39e7b508ce5ae0" category="paragraph"><block ref="15c5e1ffe753f0365f39e7b508ce5ae0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5bf2ae3a2d0d1dd1e0740744c9ebb1b" category="paragraph">이 추론 요청은 이미지 인식에 사용되는 resnet50_netdef 모델을 호출합니다. 다른 클라이언트는 유사한 접근 방식을 따르고 적절한 모델을 호출하여 추론 요청을 동시에 보낼 수도 있습니다.</block>
  <block id="b872d0389acf826cc7cf1939cd17a05d" category="inline-link-macro">다음: 추가 정보를 찾을 위치</block>
  <block id="a301641e2c9595a0c9c39ee7986f7ca8" category="paragraph"><block ref="a301641e2c9595a0c9c39ee7986f7ca8" category="inline-link-macro-rx"></block></block>
  <block id="bd3114e9e2000f42e265a067e98b0d25" category="doc">타사 API에 이행 엔진으로 연결합니다</block>
  <block id="1aea646cd3c044dd0758af18e73cfef3" category="paragraph">다음 타사 API를 이행 엔진으로 연결하여 질문에 답변했습니다.</block>
  <block id="94c494471216991658782a32f1e3ef37" category="inline-link">WeatherStack API를 참조하십시오</block>
  <block id="f7eb24e530470f21243c27770bd2c549" category="list-text"><block ref="c8600f69e922164a09610e481537b92d" category="inline-link-rx"></block>: 지정된 위치에 날씨, 온도, 강우량 및 눈을 반환합니다.</block>
  <block id="1c96228fa1453bf3f691d5081cbd6adb" category="inline-link">Yelp Fusion API를 참조하십시오</block>
  <block id="55a3b552be8202b066ea237b831186f4" category="list-text"><block ref="8af0de0530d799485b6d6a2d146ab784" category="inline-link-rx"></block>: 지정된 위치에서 가장 가까운 매장 정보를 반환합니다.</block>
  <block id="114e8180b93cb1b21cd00067e446e5f0" category="inline-link">eBay Python SDK</block>
  <block id="da6816adc86546982065d9aef78845e5" category="list-text"><block ref="3d046b40b6d382ee41dd02d3b6ab007c" category="inline-link-rx"></block>: 지정된 항목의 가격을 반환합니다.</block>
  <block id="3f7ba19f5b656e6cf8db9c69330a6d6e" category="inline-link-macro">다음: NetApp Retail Assistant 데모</block>
  <block id="23e96dc8693037c8fa1d7c0587a2d5eb" category="paragraph"><block ref="23e96dc8693037c8fa1d7c0587a2d5eb" category="inline-link-macro-rx"></block></block>
  <block id="48c4dc7fbfa1197490124f13eb565bd2" category="doc">ONTAP AI 배포</block>
  <block id="70d5c23ad68d59b2546133efdd1c3267" category="inline-link">NVA-1121-deploy: NetApp ONTAP AI, NVIDIA 구현</block>
  <block id="b393f072bc6b17085b75486a2abbcf97" category="paragraph">ONTAP AI를 배포하려면 네트워킹, 컴퓨팅 및 스토리지 하드웨어를 설치하고 구성해야 합니다. ONTAP AI 인프라 구축에 대한 구체적인 지침은 이 문서의 범위를 벗어납니다. 자세한 배포 정보는 를 참조하십시오<block ref="8c03c9c25bc6aba17e86c510148a3423" category="inline-link-rx"></block>.</block>
  <block id="03e335ae74b1356b294af55e07eb6b70" category="paragraph">이 솔루션 검증에서 단일 볼륨이 생성되어 DGX-1 시스템에 마운트되었습니다. 그런 다음 이 마운트 지점을 컨테이너에 마운트하여 데이터를 교육에 액세스할 수 있도록 했습니다. 대규모 배포의 경우 NetApp Trident는 볼륨의 생성 및 마운트를 자동화하여 관리 오버헤드를 제거하고 최종 사용자 리소스 관리를 지원합니다.</block>
  <block id="328d9c8854162b6d9dae70c57baa7505" category="inline-link-macro">다음: Kubernetes 배포</block>
  <block id="5102c02ef61bdeaa79904c17f58ca7e3" category="paragraph"><block ref="5102c02ef61bdeaa79904c17f58ca7e3" category="inline-link-macro-rx"></block></block>
  <block id="3bb420314fa4b29837c4b0528524000f" category="doc">NetApp ONTAP AI 및 AI 제어 플레인</block>
  <block id="1b85c0e7f381bd6f8c3150cafe56a9f0" category="paragraph">NetApp ONTAP AI 아키텍처는 NVIDIA DGX 시스템과 NetApp 클라우드 연결형 스토리지 시스템을 기반으로 합니다. 이 참조 아키텍처는 IT 조직이 다음과 같은 이점을 얻을 수 있도록 해 줍니다.</block>
  <block id="9c6bd300c8cf3ca98c8548bbb27cc34a" category="list-text">설계 복잡성 제거</block>
  <block id="5116c5071beb9f4f5b673c988c417c71" category="list-text">컴퓨팅과 스토리지의 독립적인 확장 지원</block>
  <block id="eccaf37681e446d183db0332d1e50552" category="list-text">고객이 작은 규모로 시작한 후 원활하게 확장할 수 있도록 지원</block>
  <block id="bae698d3cdcc290d6a0048c7b786446c" category="list-text">다양한 성능 및 비용 관련 다양한 스토리지 옵션을 제공합니다.NetApp ONTAP AI는 DGX 시스템과 NetApp AFF A800 스토리지 시스템을 최첨단 네트워킹과 긴밀하게 통합합니다. NetApp ONTAP AI 및 DGX 시스템은 설계 복잡성과 추측을 제거함으로써 AI 배포를 단순화합니다. 고객은 작은 규모로 시작한 후 에지에서 코어 및 클라우드까지 포괄하여 데이터를 지능적으로 관리하면서 중단 없이 시스템을 확장할 수 있습니다.</block>
  <block id="c729dcbcad9e1c72ae15d4b823e9f311" category="paragraph">NetApp AI Control Plane은 데이터 과학자 및 데이터 엔지니어를 위한 전체 스택 AI, ML 및 딥 러닝(DL) 데이터 및 실험 관리 솔루션입니다. 조직이 AI를 더 많이 사용함에 따라 워크로드 확장성 및 데이터 가용성을 비롯한 여러 과제에 직면하게 됩니다. NetApp AI Control Plane은 GIT 보고에서와 같이 데이터 네임스페이스를 신속하게 클론 복제하여 추적 및 버전 관리를 위한 데이터 및 모델 기준선의 거의 즉각적인 생성을 통합하는 AI 교육 워크플로우를 정의 및 구현하는 등의 기능을 통해 이러한 문제를 해결합니다. NetApp AI Control Plane을 사용하면 사이트 및 지역 간에 데이터를 원활하게 복제하고 대규모 데이터 세트에 액세스할 수 있는 Jupyter Notebook 작업 공간을 신속하게 프로비저닝할 수 있습니다.</block>
  <block id="42cac0fcbbddfc99b31ff898d7902c83" category="inline-link-macro">다음: AI 워크로드 오케스트레이션에 대해 AI 플랫폼 실행</block>
  <block id="e3683938a3c34e6a7cf5b3896258e91e" category="paragraph"><block ref="a8dcbc617641d20db42fd66f3a42caae" category="inline-link-macro-rx"></block>.</block>
  <block id="6c2749dd86f49cdb85fde6976a317e4b" category="summary">이 섹션에서는 AI 솔루션의 기술 기반에 대해 설명합니다.</block>
  <block id="a1f13b9a0674cc0beb81e208dfb68d05" category="doc">기술 개요</block>
  <block id="5231f9fa4d08024f4620b759f83d0e97" category="inline-link-macro">이전: 소개.</block>
  <block id="42b507999e258502c07acce91c03de9f" category="paragraph"><block ref="42b507999e258502c07acce91c03de9f" category="inline-link-macro-rx"></block></block>
  <block id="b2412d3528eff2c1e191154bf1ecfd60" category="section-title">NetApp AFF 시스템</block>
  <block id="b7bec75e06d57a8576b1ec632131ea53" category="paragraph">최첨단 NetApp AFF 스토리지 시스템을 사용하면 AI 추론 구축을 통해 에지에서 업계 최고 수준의 성능, 탁월한 유연성, 클라우드 통합, 동급 최고의 데이터 관리로 엔터프라이즈 스토리지 요구사항을 충족할 수 있습니다. 플래시 전용으로 설계된 NetApp AFF 시스템은 비즈니스 크리티컬 데이터를 더 빠르게 처리하고 관리, 보호할 수 있도록 지원합니다.</block>
  <block id="45f242ad7738d4805c03311378260bbf" category="list-text">엔트리 레벨 NetApp AFF 스토리지 시스템은 FAS2750 하드웨어 및 SSD 플래시 미디어를 기반으로 합니다</block>
  <block id="d308392edcd4d2f839897b51e24cf6f6" category="list-text">HA 구성의 컨트롤러 2개</block>
  <block id="7df12cd193e8452ed6fc45ca8bcd3771" category="paragraph"><block ref="7df12cd193e8452ed6fc45ca8bcd3771" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6b0a1e5585dc8095dd546c5930f1a6c" category="paragraph">NetApp 엔트리 레벨 AFF C190 스토리지 시스템은 다음 기능을 지원합니다.</block>
  <block id="42087aa1683ece2ea30ab7fa45862cd6" category="list-text">최대 드라이브 수는 24x 960GB SSD입니다</block>
  <block id="d7123d8583ed65e3090da25ea5aee965" category="list-text">두 가지 가능한 구성:</block>
  <block id="35b9fc01c3820062d5969f142bdc5ce5" category="list-text">이더넷(10GbE): 10GBASE-T(RJ-45) 포트 4개</block>
  <block id="f5e2ae88aead451be011eb9f8abfdd6e" category="list-text">유니파이드(16Gb FC 또는 10GbE): 4x UTA2(Unified Target Adapter 2) 포트</block>
  <block id="1e927fd215e516034d85785b393b0efb" category="list-text">최대 50.5TB의 유효 용량</block>
  <block id="aa9cba7f7b6d2ff8fb2251620a584dcd" category="admonition">NAS 워크로드의 경우, 단일 엔트리 레벨 AFF C190 시스템은 연속 읽기의 경우 4.4GBps의 처리량과 작은 랜덤 읽기의 경우 1ms 이하의 지연 시간으로 230K IOPS를 지원합니다.</block>
  <block id="1672d070f346948fb25e819b40bb3ade" category="section-title">NetApp AFF A220을 참조하십시오</block>
  <block id="ac7bdd389786fda32ee572c48eef4838" category="paragraph">또한, NetApp은 대규모 구축을 위해 더 뛰어난 성능과 확장성을 제공하는 다른 엔트리급 스토리지 시스템을 제공합니다. NAS 워크로드의 경우 단일 엔트리 레벨 AFF A220 시스템이 다음을 지원합니다.</block>
  <block id="732568c5581337c7341011c38721e2db" category="list-text">순차적 읽기의 경우 6.2GBps의 처리량</block>
  <block id="4900f6d90a4169888690f2c04f3c6603" category="list-text">375K IOPS, 1ms 미만의 지연 시간으로 소규모 랜덤 읽기 지원</block>
  <block id="fbcd9d84b2d7be8631cbf7226884f17a" category="list-text">최대 드라이브 수는 144x 960GB, 3.8TB 또는 7.6TB SSD입니다</block>
  <block id="db527e605a2eacc627448a70b8a745db" category="list-text">AFF A220은 1PB 이상의 실제 용량으로 확장됩니다</block>
  <block id="25297dbc8df2aecff2fa2e9e47638d35" category="section-title">NetApp AFF A250</block>
  <block id="cac36335022421f12e1c8e999ffeb1af" category="list-text">최대 실제 용량은 35PB이며 최대 스케일아웃 2-24개 노드(HA 쌍 12개)를 지원하는 경우</block>
  <block id="62a23a7791227c5f5e3d068e70759128" category="list-text">AFF A220보다 45% 이상 높은 성능 향상을 제공합니다</block>
  <block id="dc7ac33362f108fc7f4b7d8eb0e2cf4e" category="list-text">440k IOPS 랜덤 읽기 @ 1ms</block>
  <block id="0f4615fb8d6105bcb2cbce504f8f091c" category="list-text">최신 NetApp ONTAP 릴리스 ONTAP 9.8을 기반으로 구축</block>
  <block id="440a976974d702d027543e058c1fffc0" category="list-text">HA 및 클러스터 인터커넥트에 2개의 25GB 이더넷을 활용합니다</block>
  <block id="4dc1c0d5a0f0257d8d9e183bc226ab45" category="section-title">NetApp E-Series EF 시스템</block>
  <block id="f5e23a285b378cde99c2d7fb43586c1b" category="paragraph">EF-Series는 엔트리 레벨 및 미드레인지 All-Flash SAN 스토리지 어레이 제품군으로, NetApp SANtricity 소프트웨어를 사용하여 데이터에 더 빠르게 액세스하고 가치를 더 빠르게 창출할 수 있습니다. 이러한 시스템은 SAS 및 NVMe 플래시 스토리지를 모두 제공하며 경제적인 가격으로 최고 수준의 IOPS, 100마이크로초 미만의 응답 시간, 최대 44GBps의 대역폭을 제공하므로 AI 추론 및 고성능 컴퓨팅(HPC)과 같은 까다로운 애플리케이션과 혼합 워크로드에 적합합니다.</block>
  <block id="96e4797e3006bef737785f8627faae06" category="paragraph">다음 그림에서는 NetApp EF280 스토리지 시스템을 보여 줍니다.</block>
  <block id="51ffc2dfd09bb521be00106f197d1009" category="paragraph"><block ref="51ffc2dfd09bb521be00106f197d1009" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6f17b7c2ad64f8977585fc43d702abf" category="section-title">NetApp EF280</block>
  <block id="2d6477e98cb834485323c97da975c640" category="list-text">32Gb/16Gb FC, 25Gb/10Gb iSCSI 및 12Gb SAS 지원</block>
  <block id="d637a0904677ae775d98b9ce0beda3d6" category="list-text">최대 실제 용량은 총 1.5PB의 96개 드라이브입니다</block>
  <block id="6f409cb54d8cb27deac8a918fe03f3cc" category="list-text">10GBps 처리량(순차적 읽기)</block>
  <block id="7c61b8793dbe5a66cbf144bdabcf76cd" category="list-text">300K IOPS(랜덤 읽기)</block>
  <block id="4c5a963973ae3026e92baab2ef522c6c" category="list-text">NetApp EF280은 NetApp 포트폴리오에서 가장 경제적인 All-Flash 어레이(AFA)입니다</block>
  <block id="44114b1635cead15f56735bad0467251" category="section-title">NetApp EF300</block>
  <block id="f1330bea5ad6aa446aa17d0a324bb579" category="list-text">24x NVMe SSD 드라이브로 총 367TB 용량 지원</block>
  <block id="6768e0b9e957297070e3822e98a4b8f9" category="list-text">총 240x NL-SAS HDD, 96x SAS SSD 또는 그 조합 확장 옵션</block>
  <block id="0fa40de31cbd933cc9a954d82204feb9" category="list-text">100Gb NVMe/IB, NVMe/RoCE, iSER/IB 및 SRP/IB</block>
  <block id="aee7a4e3788dbbff7166952ed0e2d2c9" category="list-text">32Gb NVMe/FC, FCP</block>
  <block id="c4b9deb88d9cf1b1a2160cb28a2c41ca" category="list-text">25GB iSCSI</block>
  <block id="03597240f9b0b4a23f3ffdf6e159d6ca" category="list-text">20GBps(순차적 읽기)</block>
  <block id="ffe3b3adfe232ee25f1914e7e7d266c4" category="list-text">670K IOPS(랜덤 읽기)</block>
  <block id="7105ea3513c2bdae1a0d63a9f0703579" category="inline-link">NetApp EF-Series NetApp EF-Series All-Flash 어레이 EF600, F300, EF570, EF280 데이터시트</block>
  <block id="6e69804b180359b12a32a56c17c0641e" category="admonition">자세한 내용은 를 참조하십시오<block ref="5f5484869dc0c271e2b062d172d38bee" category="inline-link-rx"></block>.</block>
  <block id="a5119a6bd0f4d733e0f1f4c10f9d063b" category="section-title">NetApp ONTAP 9</block>
  <block id="b407d5a86fd662f03d5a1615963e0827" category="paragraph">NetApp의 최신 세대 스토리지 관리 소프트웨어인 ONTAP 9.8.1을 통해 기업은 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다. ONTAP는 업계 최고 수준의 데이터 관리 기능을 활용하여 데이터가 상주하는 위치와 상관없이 단일 툴셋으로 데이터를 관리하고 보호할 수 있습니다. 필요에 따라 에지, 코어, 클라우드 등 어느 위치로도 데이터를 자유롭게 이동할 수 있습니다. ONTAP 9.8.1에는 데이터 관리를 단순화하고, 중요 데이터를 더 빨리 처리하고 보호하고, 하이브리드 클라우드 아키텍처 전반에서 차세대 인프라 기능을 지원하는 다양한 기능이 포함되어 있습니다.</block>
  <block id="f1586460cef11d0abaaf5270f37f18d7" category="section-title">데이터 관리를 단순화하십시오</block>
  <block id="2e2b24551fd50942c6da57d4f8efdfae" category="paragraph">애플리케이션 및 데이터 세트에 적절한 리소스가 사용될 수 있도록 데이터 관리는 엔터프라이즈 IT 운영에 매우 중요합니다. ONTAP에는 운영을 간소화 및 단순화하고 총 운영 비용을 절감할 수 있는 다음과 같은 기능이 포함되어 있습니다.</block>
  <block id="4934cd09a8e487be128d2b6321ee3279" category="list-text">* 인라인 데이터 컴팩션 및 확대된 중복제거. * 데이터 컴팩션은 스토리지 블록 내부의 낭비되는 공간을 줄이고, 중복제거는 실제 용량을 크게 증가시킵니다. 이는 로컬에 저장된 데이터와 클라우드로 계층화된 데이터에 적용됩니다.</block>
  <block id="0ddc097c124782f16e8a0a1b014fc2bb" category="list-text">* 최소, 최대 및 적응형 서비스 품질(AQoS). * 세분화된 서비스 품질(QoS) 제어는 공유 수준이 높은 환경에서 중요 애플리케이션의 성능 수준을 유지하는 데 도움이 됩니다.</block>
  <block id="0c720f269a89477f24f77f6f027719cc" category="inline-link-macro">TR-4598</block>
  <block id="7920a2957aeb5c70e8ee2fa43c94e741" category="list-text">* NetApp FabricPool. * 이 기능은 콜드 데이터를 AWS(Amazon Web Services), Azure, NetApp StorageGRID 스토리지 솔루션을 포함한 퍼블릭 및 프라이빗 클라우드 스토리지 옵션으로 자동 계층화합니다. FabricPool에 대한 자세한 내용은 를 참조하십시오 <block ref="38e4393e170a142db2e52760317ecb7f" category="inline-link-macro-rx"></block>.</block>
  <block id="28e23b5888c04e1859e75c594c6cec26" category="section-title">데이터 가속화 및 보호</block>
  <block id="85e643b872d0d98ec2251220de803a1f" category="paragraph">ONTAP 9은 탁월한 수준의 성능과 데이터 보호를 제공하며 다음과 같은 방법으로 이러한 기능을 확장합니다.</block>
  <block id="bfb9fa643243eb975ccd9d158cf97800" category="list-text">* 성능 및 낮은 지연 시간 * ONTAP는 가장 짧은 지연 시간으로 가장 높은 처리량을 제공합니다.</block>
  <block id="ef9770ee572f97c59254dc0d022afda8" category="list-text">* 데이터 보호. * ONTAP는 모든 플랫폼에서 공통 관리를 지원하는 내장 데이터 보호 기능을 제공합니다.</block>
  <block id="86a12b3dbbf039b371f714a515919535" category="list-text">* NVE(NetApp 볼륨 암호화). * ONTAP는 온보드 및 외부 키 관리를 모두 지원하여 네이티브 볼륨 레벨 암호화를 제공합니다.</block>
  <block id="b3023c0a4db125fc22f0d6056c6e379d" category="list-text">* 멀티테넌시 및 다단계 인증 * ONTAP를 통해 인프라 리소스를 최고 수준의 보안으로 공유할 수 있습니다.</block>
  <block id="685f280ead44650493627d9ac47818e1" category="section-title">미래 지향형 인프라</block>
  <block id="f9eaef0b2cf89b234c431c18aec36bf3" category="paragraph">ONTAP 9은 다음과 같은 기능을 통해 지속적으로 변화하는 까다로운 비즈니스 요구사항을 충족할 수 있도록 지원합니다.</block>
  <block id="9e98379ad83b5c60933a3437c7fb61c7" category="list-text">* 원활한 확장 및 무중단 운영 * ONTAP은 기존 컨트롤러 및 스케일아웃 클러스터에 무중단으로 용량을 추가할 수 있도록 지원합니다. 고객은 고비용이 따르는 데이터 마이그레이션이나 운영 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="0cee26e8172666a9085f957269fc4b64" category="list-text">* 클라우드 연결. * ONTAP은 클라우드에 가장 많이 연결되는 스토리지 관리 소프트웨어로, 모든 퍼블릭 클라우드에서 소프트웨어 정의 스토리지(ONTAP Select) 및 클라우드 네이티브 인스턴스(NetApp Cloud Volumes Service) 옵션이 제공됩니다.</block>
  <block id="b5dc6026803056308b6bf7007af32a2b" category="list-text">새로운 애플리케이션과의 통합 * ONTAP는 기존 엔터프라이즈 앱을 지원하는 인프라와 동일한 인프라를 사용하여 자율주행 차량, 스마트 시티, Industry 4.0과 같은 차세대 플랫폼 및 애플리케이션을 위한 엔터프라이즈급 데이터 서비스를 제공합니다.</block>
  <block id="e4872d9c30e978d9408425f0e08882c5" category="section-title">NetApp SANtricity를 참조하십시오</block>
  <block id="965539211ad2d7bc981e7e954db08850" category="inline-link">NetApp E-Series SANtricity 소프트웨어 데이터시트 를 참조하십시오</block>
  <block id="568549d316f6f749a07012e522e0bca3" category="paragraph">NetApp SANtricity는 E-Series 하이브리드 플래시 및 EF-Series All-Flash 어레이에 업계 최고의 성능, 안정성, 단순성을 제공하도록 설계되었습니다. 데이터 분석, 비디오 감시, 백업 및 복구 등 워크로드가 많은 애플리케이션에서 E-Series 하이브리드 플래시 및 EF-Series All-Flash 어레이의 성능과 활용률을 극대화합니다. SANtricity를 사용하면 스토리지를 온라인 상태로 유지하면서 구성 조정, 유지 관리, 용량 확장 및 기타 작업을 완료할 수 있습니다. 또한 SANtricity는 사용하기 쉬운 온박스형 시스템 관리자 인터페이스를 통해 뛰어난 데이터 보호, 사전 예방 모니터링 및 인증 보안을 제공합니다. 자세한 내용은 를 참조하십시오<block ref="64769f0652e98a060ba5d2cd17320298" category="inline-link-rx"></block>.</block>
  <block id="c4cf91172f1e96366d0dfa38c1167df9" category="section-title">최적의 성능</block>
  <block id="3d615c3559b8d33749ea23cf3a34b759" category="paragraph">성능에 최적화된 SANtricity 소프트웨어는 모든 데이터 분석, 비디오 감시 및 백업 앱에 높은 IOPS 및 처리량과 짧은 지연 시간으로 데이터를 제공합니다. IOPS가 높고 지연 시간이 짧은 애플리케이션과 대역폭과 처리량이 높은 애플리케이션의 성능을 더욱 높이십시오.</block>
  <block id="8238dd9365065265be82d79d4dd38a98" category="section-title">가동 시간 극대화</block>
  <block id="28ed557ae8b4ff60f83da71465cbcb9b" category="paragraph">스토리지가 온라인 상태일 때 모든 관리 작업을 완료하십시오. I/O를 중단하지 않고 구성을 변경하거나, 유지보수를 수행하거나, 용량을 확장할 수 있습니다 자동화된 기능, 온라인 구성, 최첨단 DPP(Dynamic Disk Pool) 기술 등을 통해 동급 최고의 안정성을 실현합니다.</block>
  <block id="2b34e4806834294a7dd611ad1d7d0308" category="section-title">편안한 휴식</block>
  <block id="7847b3892c0f355acdb3fe824654e209" category="paragraph">SANtricity 소프트웨어는 사용이 간편한 온박스형 시스템 관리자 인터페이스를 통해 뛰어난 데이터 보호, 사전 예방 모니터링 및 인증 보안을 제공합니다. 스토리지 관리 업무를 간소화합니다. 모든 E-Series 스토리지 시스템의 고급 튜닝에 필요한 유연성 확보 언제 어디서나 NetApp E-Series 시스템을 관리할 수 있습니다. NetApp의 온박스 웹 기반 인터페이스는 관리 워크플로우를 간소화합니다.</block>
  <block id="e71e852dc96d4d0e2da95de923a6f8ff" category="section-title">NetApp 트라이던트</block>
  <block id="2758085534b10a85f702f6a61737eefb" category="paragraph"><block ref="d14308042ff124582c531f74c03d90f3" category="inline-link-rx"></block> NetApp은 Docker 및 Kubernetes용 오픈 소스 동적 스토리지 오케스트레이터로서 영구 스토리지의 생성, 관리 및 사용을 단순화합니다. Kubernetes 네이티브 애플리케이션인 Trident는 Kubernetes 클러스터 내에서 직접 실행됩니다. Trident를 사용하면 고객이 DL 컨테이너 이미지를 NetApp 스토리지에 원활하게 배포하고 AI 컨테이너 배포를 위한 엔터프라이즈급 경험을 제공할 수 있습니다. Kubernetes 사용자(예: ML 개발자 및 데이터 과학자)는 오케스트레이션 및 클론 복제를 생성, 관리 및 자동화하여 NetApp 기술이 제공하는 NetApp 고급 데이터 관리 기능을 활용할 수 있습니다.</block>
  <block id="dc188738e6cc2e9f8314e1b95f18ebfd" category="section-title">NetApp Cloud Sync를 참조하십시오</block>
  <block id="e367efbc26bd12c0d6ae37dd6a55ef9b" category="inline-link">Cloud Sync</block>
  <block id="2d76806bea2175a1c575d37015a3621b" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> 는 빠르고 안전한 데이터 동기화를 제공하는 NetApp 서비스입니다. 온프레미스 NFS 또는 SMB 파일 공유, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, Amazon S3(Amazon Simple Storage Service), Amazon Elastic File System(Amazon EFS), Azure Blob, Google Cloud Storage 간에 파일을 전송해야 하는 경우 또는 IBM 클라우드 오브젝트 스토리지인 Cloud Sync를 사용하면 파일을 필요한 곳으로 빠르고 안전하게 이동할 수 있습니다. 데이터가 전송되면 소스와 타겟 모두에서 사용할 수 있습니다. Cloud Sync는 미리 정의된 일정에 따라 데이터를 지속적으로 동기화하여 변경된 부분만 이동하므로 데이터 복제에 소비되는 시간과 비용이 최소화됩니다. Cloud Sync는 매우 간편한 설정 및 사용이 가능한 SaaS(Software as a Service) 툴입니다. Cloud Sync에 의해 트리거되는 데이터 전송은 데이터 브로커가 수행합니다. AWS, Azure, Google Cloud Platform 또는 온프레미스에서 Cloud Sync 데이터 브로커를 구축할 수 있습니다.</block>
  <block id="d552f08a6baeb9bee58f2ca6ff5090d2" category="section-title">Lenovo ThinkSystem 서버</block>
  <block id="e76fa728781968dd4a707e2d3b1d8108" category="paragraph">Lenovo ThinkSystem 서버는 현재 고객의 과제를 해결하고 미래의 과제를 해결할 수 있는 혁신적인 모듈식 설계 접근 방식을 제공하는 혁신적인 하드웨어, 소프트웨어 및 서비스를 갖추고 있습니다. 이러한 서버는 동급 최강의 업계 표준 기술과 차별화된 Lenovo의 혁신적인 기술을 결합하여 x86 서버에서 최대한의 유연성을 제공합니다.</block>
  <block id="493e1540ce727fb5f465fff015aa4733" category="paragraph">Lenovo ThinkSystem 서버 배포의 주요 이점은 다음과 같습니다.</block>
  <block id="b7c6c5eb82b90f69eddd06060626e5e3" category="list-text">비즈니스 성장에 맞춰 확장할 수 있는 모듈식 설계</block>
  <block id="c2599c559a0be54b242b8aa3c67325c8" category="list-text">업계 최고 수준의 복원력으로 예기치 못한 가동 중지의 비용이 많이 드는 시간을 절약할 수 있습니다</block>
  <block id="c57cb88fcbeb47afa8496b8fc32cbf03" category="list-text">빠른 플래시 기술을 통해 지연 시간을 단축하고, 응답 시간을 단축하며, 데이터 관리를 실시간으로 수행할 수 있습니다</block>
  <block id="6d72d9a0181555ca86c9562861e47058" category="paragraph">AI 분야에서 Lenovo는 기업들이 워크로드에 대한 ML 및 AI의 이점을 이해하고 적용할 수 있도록 실질적인 접근 방식을 취하고 있습니다. Lenovo 고객은 Lenovo AI Innovation Center의 Lenovo AI 제품을 살펴보고 평가하여 해당 사용 사례의 가치를 완벽하게 파악할 수 있습니다. 가치 창출 시간을 단축하기 위해 이 고객 중심 접근 방식은 AI에 사용하고 최적화할 수 있는 솔루션 개발 플랫폼에 대한 개념 증명을 고객에게 제공합니다.</block>
  <block id="13f9a963bd60406520ccdc128d44b54a" category="section-title">Lenovo ThinkSystem SE350 Edge 서버</block>
  <block id="6bf0f92a7340921305982a91f7277085" category="paragraph">에지 컴퓨팅을 사용하면 데이터 센터 또는 클라우드로 전송되기 전에 네트워크 에지에서 IoT 장치의 데이터를 분석할 수 있습니다. 아래 그림과 같이 Lenovo ThinkSystem SE350은 견고하며 환경 친화적인 소형 폼 팩터에서 유연성, 연결, 보안 및 원격 관리 기능에 중점을 두고 엣지에서의 배포를 위한 고유한 요구 사항을 충족하도록 설계되었습니다.</block>
  <block id="72dd0df190a1bdc8d3043fafdba7122b" category="paragraph">에지 AI 워크로드에 대한 가속화를 지원할 수 있는 유연성을 갖춘 인텔 제온 D 프로세서를 장착한 SE350은 데이터 센터 외부의 다양한 환경에서 서버 배포의 과제를 해결하기 위해 특별히 제작되었습니다.</block>
  <block id="b739a166d96ffd72ac4d456012bfbe21" category="paragraph"><block ref="b739a166d96ffd72ac4d456012bfbe21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="paragraph"><block ref="1e8dc5b3fbe4fe568bf4cc78b4a053fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bd5e585bc974f029ff9c7cc8a2b68dd" category="section-title">MLPerf</block>
  <block id="45c08b3aee1d5fb5dc3447ec1271a853" category="inline-link">MLPerf Inference v0.7</block>
  <block id="f6922096e43c9e99d2be9d521357ff1c" category="paragraph">MLPerf는 AI 성능 평가를 위한 업계 최고의 벤치마크 제품군입니다. 여기에는 영상 분류, 물체 감지, 의료 영상 및 NLP(자연어 처리)를 비롯한 다양한 적용 AI 영역을 다룹니다. 이 검증에서는 이 검증이 완료될 때 MLPerf 추론의 최신 반복인 Inference v0.7 워크로드를 사용했습니다. 를 클릭합니다<block ref="1303efdddf9d8dbc0de31c402aa4ef22" category="inline-link-rx"></block> 데이터 센터 및 에지 시스템을 위한 새로운 벤치마크 4개가 포함된 제품군:</block>
  <block id="c781a146774780843a929b97004ba720" category="list-text">* BERT. * Transformers(BERT)의 양방향 Encoder Representation은 Squad 데이터 세트를 사용하여 질문 답변에 맞게 미세 조정되었습니다.</block>
  <block id="cb93b50c2b2216543a9eee4d9a38b38c" category="list-text">* DLRM. * DLRM(Deep Learning Recommendation Model)은 CTR(Click-Through Rates)을 최적화하도록 교육받은 개인 설정 및 권장 모델입니다.</block>
  <block id="16139bb6e8da8fe8f8aaf1e5fb8bde0d" category="list-text">* 3D U-Net. * 3D U-Net 아키텍처는 Brain Tumor Segmentation(뇌종양 분할) 데이터 세트에 대한 교육을 받습니다.</block>
  <block id="5691eec0e5e0ea401478ea67b8168d64" category="list-text">* RNN-T * Recurrent Neural Network Transducer(RNN-T)는 LibriSpeech의 하위 집합에 대한 교육을 받은 자동 음성 인식(ASR) 모델입니다. MLPerf Inference 결과 및 코드는 공개적으로 사용할 수 있으며 Apache 라이센스에 따라 릴리스됩니다. MLPerf Inference에는 다음과 같은 시나리오를 지원하는 Edge 분산이 있습니다.</block>
  <block id="e772865569495cb43ba25be1d6eed756" category="list-text">* 단일 스트림. * 이 시나리오는 스마트폰에서 실행되는 오프라인 AI 쿼리와 같이 응답성이 중요한 요소인 시스템을 모방합니다. 개별 쿼리가 시스템으로 전송되고 응답 시간이 기록됩니다. 모든 응답의 90번째 백분위수 지연 시간이 결과로 보고됩니다.</block>
  <block id="f9cf7025c2d80af397a9b960974631e2" category="list-text">* 멀티스트림. * 이 벤치마크는 여러 센서의 입력을 처리하는 시스템을 위한 것입니다. 테스트 중에 쿼리는 고정된 시간 간격으로 전송됩니다. QoS 제약(허용되는 최대 지연 시간)이 적용됩니다. QoS 제한을 충족하는 동안 시스템에서 처리할 수 있는 스트림의 수를 보고합니다.</block>
  <block id="78a9abbe3c771a5882830fc8e2a73a8f" category="list-text">* Offline. * 배치 처리 응용 프로그램을 다루는 가장 간단한 시나리오이며 메트릭은 초당 샘플 처리량입니다. 모든 데이터를 시스템에서 사용할 수 있으며 벤치마크는 모든 샘플을 처리하는 데 걸리는 시간을 측정합니다.</block>
  <block id="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link"><block ref="cc8cc2653d3a795d17b5d90b14d00e19" category="inline-link-rx"></block></block>
  <block id="c953c121914b99f83398f20ab2160ed1" category="paragraph">Lenovo는 이 문서에 사용된 서버인 T4가 포함된 SE350에 대한 MLPerf Inference 점수를 게시했습니다. 의 결과를 참조하십시오<block ref="8efc95b379113ebfb6f66010213223ce" category="inline-link-rx"></block> 입력 #0.7-145의 "Edge, Closed Division" 섹션에 있습니다.</block>
  <block id="26cb2cd90a9e0e03f63323eab13f117d" category="inline-link-macro">다음: 테스트 계획.</block>
  <block id="91666b8460dc62d134fe80c31f05d28b" category="paragraph"><block ref="91666b8460dc62d134fe80c31f05d28b" category="inline-link-macro-rx"></block></block>
  <block id="f521e3eae9fd2145ce8aeede6602641d" category="summary">이 섹션에서는 이 솔루션의 다양한 구성 요소에 대한 설계 고려 사항에 대해 설명합니다.</block>
  <block id="648bdcd0b9a0f83d7b068dbed3c21c07" category="doc">설계 고려 사항</block>
  <block id="5b1c62f1e35074e19185d9341b492c54" category="inline-link-macro">이전: 아키텍처.</block>
  <block id="b180067c966e23ba80c92f3bb1bf6745" category="paragraph"><block ref="b180067c966e23ba80c92f3bb1bf6745" category="inline-link-macro-rx"></block></block>
  <block id="35ff22a5291df56d5075c29d8dc65044" category="section-title">네트워크 및 컴퓨팅 설계</block>
  <block id="49d41bdb2234e0a4330f0c9d7d03853a" category="paragraph">데이터 보안 제한에 따라 모든 데이터는 고객의 인프라 또는 보안 환경 내에 있어야 합니다.</block>
  <block id="5a20c2b759137410d60f5ce368ca45d2" category="paragraph"><block ref="5a20c2b759137410d60f5ce368ca45d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d6e133bd239a98d559f693ee2ff5ecc" category="section-title">스토리지 설계</block>
  <block id="3051d856c7b26f6d385279d67a8a532b" category="paragraph">NetApp DataOps 툴킷은 스토리지 시스템 관리를 위한 1차 서비스 역할을 합니다. DataOps Toolkit은 개발자, 데이터 과학자, DevOps 엔지니어 및 데이터 엔지니어가 새로운 데이터 볼륨의 거의 즉각적인 프로비저닝 또는 JupyterLab 작업 공간, 데이터 볼륨의 거의 즉각적인 클론 복제 또는 JupyterLab 작업 공간과 같은 다양한 데이터 관리 작업을 간단하게 수행할 수 있는 Python 라이브러리입니다. 추적 기능 또는 베이스라인 기능을 위한 데이터 볼륨 또는 JupyterLab 작업 공간의 거의 즉각적인 스냅샷 기능을 제공합니다. 이 Python 라이브러리는 명령줄 유틸리티 또는 모든 Python 프로그램 또는 Jupyter Notebook로 가져올 수 있는 기능 라이브러리 중 하나로 작동할 수 있습니다.</block>
  <block id="6f9e8585e5f750b8ceb149639b1e25e6" category="section-title">Riva 모범 사례</block>
  <block id="7ecab6bd65c2f169e987be2f59219357" category="inline-link">모범 데이터 사례</block>
  <block id="f51b8fa6c731ea53318149e50e826ddb" category="paragraph">NVIDIA는 몇 가지 일반적인 기능을 제공합니다<block ref="f6aee1daf7f2fd9cd207fcd26f08d8be" category="inline-link-rx"></block> Riva 사용:</block>
  <block id="20430e77ba2ecbe15261761c8f4fa2c4" category="list-text">* 가능한 경우 무손실 오디오 형식을 사용합니다. * MP3와 같은 손실 코덱을 사용하면 품질이 저하될 수 있습니다.</block>
  <block id="8b3e389f067f32da1e1ab7df2b8d8155" category="list-text">* 교육 데이터를 보강합니다. * 오디오 교육 데이터에 배경 잡음을 추가하면 처음에는 정확도가 떨어되지만 견고성이 향상됩니다.</block>
  <block id="b37d69a795b4d7bb6e0f28a42c3ef8ae" category="list-text">* 스크레핑된 텍스트를 사용할 경우 어휘 크기를 제한합니다. * 많은 온라인 출처에는 오타 또는 부수적인 대명사 및 일반적이지 않은 단어가 포함되어 있습니다. 이러한 언어를 제거하면 언어 모델이 개선될 수 있습니다.</block>
  <block id="6afe4c71ada39a70da349380efbad345" category="list-text">* 가능한 경우 최소 16kHz의 샘플링 속도를 사용하십시오. * 그러나 리샘플링을 시도하지 마십시오. 리샘플링을 하면 오디오 품질이 저하됩니다.</block>
  <block id="cab3977e4ad163e19ab6245a9b09f541" category="paragraph">이러한 모범 사례 외에도 고객은 파이프라인의 각 단계에 대해 정확한 레이블이 있는 대표적인 샘플 데이터 세트를 우선적으로 수집해야 합니다. 즉, 샘플 데이터 세트는 타겟 데이터 세트에 예시된 지정된 특성을 비율에 맞게 반영해야 합니다. 마찬가지로 데이터 세트의 주석 역시 데이터의 품질과 양을 모두 최대화하도록 정확도와 레이블 지정 속도를 조율할 책임이 있습니다. 예를 들어, 이 지원 센터 솔루션에는 오디오 파일, 텍스트 레이블 및 정서 레이블이 필요합니다. 이 솔루션의 순차적 특성은 파이프라인 시작 부분의 오류가 끝까지 전파된다는 것을 의미합니다 오디오 파일의 품질이 좋지 않으면 텍스트 사본과 정서 레이블도 함께 표시됩니다.</block>
  <block id="0b6b65c9613285433178682e3550355c" category="paragraph">이 오류 전파는 이 데이터에 대한 교육을 받은 모델에도 비슷하게 적용됩니다. 감정의 예측이 100% 정확하지만 텍스트 음성 변환 모델이 제대로 작동하지 않는 경우, 최종 파이프라인은 초기 오디오-텍스트 사본으로 제한됩니다. 개발자는 각 모델의 성능을 개별적으로, 대규모 파이프라인의 구성 요소로 고려하는 것이 중요합니다. 이 경우 최종 목표는 감정을 정확하게 예측할 수 있는 파이프라인을 개발하는 것입니다. 따라서 파이프라인을 평가하는 전반적인 지표는 음성-텍스트 전사가 직접적으로 영향을 미치는 정서 정확도입니다.</block>
  <block id="f3b552e561f520013398b3be885a4420" category="paragraph"><block ref="f3b552e561f520013398b3be885a4420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1ce31a9f2a1a3a478bb69589e180bd" category="paragraph">NetApp DataOps 툴킷은 즉각적인 데이터 클론 복제 기술을 사용하여 데이터 품질 점검 파이프라인을 보완합니다. 레이블이 지정된 각 파일을 평가하고 기존의 레이블 파일과 비교해야 합니다. 이러한 품질 검사를 다양한 데이터 스토리지 시스템에 분산하면 이러한 검사가 빠르고 효율적으로 실행됩니다.</block>
  <block id="6d61a746e66a6545c5c9faf68668e013" category="inline-link-macro">다음: 지원 센터 정서 분석 구축</block>
  <block id="58a113e09ecc7941870d9bcc2d2ee3df" category="paragraph"><block ref="58a113e09ecc7941870d9bcc2d2ee3df" category="inline-link-macro-rx"></block></block>
  <block id="3887d417240a72ab69f6d0301efd3b2b" category="doc">추가 정보를 찾을 수 있는 위치</block>
  <block id="c701c7fe143bef79cc6eebc32606262e" category="paragraph">이 문서에 설명된 정보에 대한 자세한 내용은 다음 리소스를 참조하십시오.</block>
  <block id="b682eee68510f6de72c9f48b832fba3c" category="inline-link"><block ref="b682eee68510f6de72c9f48b832fba3c" category="inline-link-rx"></block></block>
  <block id="3e5d8230d86c09995fcd8e9ccf335813" category="list-text">cnvrg.io(<block ref="0691e14f48847a7f13eaf800c0f5813a" category="inline-link-rx"></block>):</block>
  <block id="6536b07bf755c64528073e655a567c32" category="list-text">cnvrg 코어(무료 ML 플랫폼)</block>
  <block id="0a16af2994c8e10c6c5976d774430a92" category="paragraph"><block ref="0a16af2994c8e10c6c5976d774430a92" category="inline-link-rx"></block></block>
  <block id="1b21ae34f592a7f2ca92d4a44122475d" category="list-text">cnvrg 문서</block>
  <block id="0730c44e9dc233c7fce5d95816294f52" category="inline-link"><block ref="0730c44e9dc233c7fce5d95816294f52" category="inline-link-rx"></block></block>
  <block id="f3a2f110576ed38849e70a6bb9794ae8" category="paragraph"><block ref="f3a2f110576ed38849e70a6bb9794ae8" category="inline-link-rx"></block></block>
  <block id="c7c082299876892b4274ecfb3c3f7bcd" category="list-text">NVIDIA DGX-1 서버:</block>
  <block id="d2647f7d8e79758eea27c6cdcf636638" category="list-text">NVIDIA DGX-1 서버</block>
  <block id="45a310b0e4b087b75cb073303044f6f9" category="paragraph"><block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="65d1be94e9f29dc4af77bef169d5be14" category="list-text">NVIDIA Tesla V100 Tensor 코어 GPU</block>
  <block id="fad8218d69ce01748faed5492aa5d3ef" category="paragraph"><block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="9052758d35faeab8995feefc50d729ed" category="list-text">NGC(NVIDIA GPU Cloud)</block>
  <block id="5c75bfead88762783d54deaaa3d62735" category="paragraph"><block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="64ba1593b4427fb62b53b007d4a1c26e" category="list-text">NetApp AFF 시스템:</block>
  <block id="584122d1d5e8c2c4232e029a6896ba40" category="list-text">AFF 데이터시트 를 참조하십시오</block>
  <block id="092940c9deac7c0f10a0ed36613c28c2" category="paragraph"><block ref="092940c9deac7c0f10a0ed36613c28c2" category="inline-link-rx"></block></block>
  <block id="b4199ce9c494dec10c6ee051ddb413e2" category="list-text">AFF를 위한 NetApp FlashAdvantage</block>
  <block id="9dcd8a7bfc88cf6bbca4b422861950bf" category="paragraph"><block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="30df7f622635480ab538fb3016f9c36a" category="list-text">ONTAP 9.x 설명서</block>
  <block id="974aeb47ab8fd0a635d02d8ac80b9eb1" category="paragraph"><block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="35d8efcf211e40a836698bff14ed0ff6" category="list-text">NetApp FlexGroup 기술 보고서</block>
  <block id="1ab29fc7fde3319a82a477ec308cf820" category="paragraph"><block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="de1e4a3a0cae539a34678546eb6e91b3" category="list-text">컨테이너용 NetApp 영구 스토리지:</block>
  <block id="36c1c8df527a7721115f4ba53b5ea5a6" category="paragraph"><block ref="36c1c8df527a7721115f4ba53b5ea5a6" category="inline-link-rx"></block></block>
  <block id="1cb9a8619999ebc0a2d9c07624d76166" category="list-text">NetApp 상호 운용성 매트릭스:</block>
  <block id="9ed4a475dd3705157a9fed8811f63ce2" category="list-text">NetApp 상호 운용성 매트릭스 툴</block>
  <block id="d51c982ce98a1e197c234ea0b9a5e7d9" category="paragraph"><block ref="d51c982ce98a1e197c234ea0b9a5e7d9" category="inline-link-rx"></block></block>
  <block id="7a211d267d46c5b44662098f9234fcd0" category="list-text">ONTAP AI 네트워킹:</block>
  <block id="b8a60c56690ddfc62bd735d0b212c396" category="list-text">Cisco Nexus 3232C 스위치</block>
  <block id="bb31172f259c591005fd4cbcdbfadd11" category="paragraph"><block ref="bb31172f259c591005fd4cbcdbfadd11" category="inline-link-rx"></block></block>
  <block id="926dc08a3a3a3946402bb1beab6545cc" category="list-text">Mellanox Spectrum 2000 시리즈 스위치</block>
  <block id="492f548658890a1d2495b8af5cebef8c" category="paragraph"><block ref="11ff6f8fb3928ea5c0863401e5e79d17" category="inline-link-rx"></block></block>
  <block id="193721fbb9ea3851cafcea43a4d95f73" category="list-text">ML 프레임워크 및 도구:</block>
  <block id="edb7d6728a9813b505cb306367d453e3" category="list-text">달리</block>
  <block id="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="paragraph"><block ref="bdee52e8a4d1d258eb5a296fbd0ad9b5" category="inline-link-rx"></block></block>
  <block id="1b2766572fa1896116e3c218eb697113" category="list-text">TensorFlow: 모두를 위한 오픈 소스 머신 러닝 프레임워크</block>
  <block id="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="paragraph"><block ref="c8c2399b3aef347e9bdc7ab4ff8da4e0" category="inline-link-rx"></block></block>
  <block id="26909d0380bdba02e2fcf7f7157cd78b" category="list-text">Horovod: Uber의 TensorFlow용 오픈 소스 분산 딥 러닝 프레임워크</block>
  <block id="3ffa9619031400d374ed5c0860d434ab" category="paragraph"><block ref="3ffa9619031400d374ed5c0860d434ab" category="inline-link-rx"></block></block>
  <block id="c9cbaff7c173f4b7bc923573ca753577" category="list-text">컨테이너 런타임 에코시스템에서 GPU 지원</block>
  <block id="b3a776c1e64d267ebe62a7bf45c6c1b7" category="paragraph"><block ref="b3a776c1e64d267ebe62a7bf45c6c1b7" category="inline-link-rx"></block></block>
  <block id="4c3db4ae25b5f5aaa206a7fedd201322" category="paragraph"><block ref="4c3db4ae25b5f5aaa206a7fedd201322" category="inline-link-rx"></block></block>
  <block id="30136395f01879792198317c11831ea4" category="list-text">쿠버네티스</block>
  <block id="9b4643ea7f05b216a0cf56ceddb43241" category="paragraph"><block ref="9b4643ea7f05b216a0cf56ceddb43241" category="inline-link-rx"></block></block>
  <block id="142f782bb2b326679982208fe40cec31" category="list-text">NVIDIA DeepOps</block>
  <block id="ccd09fd9430cf2df88a137dbec97676b" category="paragraph"><block ref="ccd09fd9430cf2df88a137dbec97676b" category="inline-link-rx"></block></block>
  <block id="a33d91971f7757996ab0eb8eb0362814" category="paragraph"><block ref="a33d91971f7757996ab0eb8eb0362814" category="inline-link-rx"></block></block>
  <block id="cc68740519bf7afc9dc5c17acc7db61e" category="list-text">Jupyter 노트북 서버</block>
  <block id="c90a0598d42425e6ec2dfb3058534b35" category="paragraph"><block ref="c90a0598d42425e6ec2dfb3058534b35" category="inline-link-rx"></block></block>
  <block id="22d149e351657eac5bd1db4934498bbe" category="list-text">데이터 세트 및 벤치마크</block>
  <block id="717108fd0999828c4a6d8290d419733b" category="list-text">NIH 흉부 X선 데이터 세트</block>
  <block id="4eb7427d14327fa86230f324870dc6b8" category="paragraph"><block ref="4eb7427d14327fa86230f324870dc6b8" category="inline-link-rx"></block></block>
  <block id="f249b6ce18772b83efb8a6e58ac09d47" category="list-text">Xiaosong Wang, Yifan Peng, Le Lu, Zhivyong Lu, Mohammadadadhadi Bagheri, Ronald Summers, ChestX-ray8: 병원 스케일 흉부 X선 데이터베이스 및 약한 감독 하에 Common Thorax 질환의 분류 및 국소화에 대한 벤치마크, IEEE CVPR, pp. 3462-3471, 2017TR-4841-0620</block>
  <block id="2732cb29fe3befd83c06e7c220b5456d" category="doc">섹션 4.10에 대한 테스트 세부 정보</block>
  <block id="6b4330df9a37bcfef1faecd1e8973464" category="inline-link-macro">할당량 초과 공정성</block>
  <block id="273936fc522fd7dbe4473de8a0b2a985" category="paragraph">이 섹션에서는 섹션에 대한 테스트 세부 정보를 다룹니다 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>.</block>
  <block id="cf46f9264bb33ef7576cf671194a0275" category="paragraph">팀-A, 팀-b, 팀-c의 순서로 작업을 제출합니다.</block>
  <block id="9e727fdd3aec8274f46685441900280d" category="cell">프로젝트</block>
  <block id="b3428404a5be1cf95d4e53b2ddc8288a" category="cell">GPU 수</block>
  <block id="96b0141273eabab320119c467cdcaf17" category="cell">합계</block>
  <block id="0be8406951cdfda82f00f79328cf4efc" category="cell">설명</block>
  <block id="9320270de4ff6824ae7a21f729fb7d44" category="cell">팀-A</block>
  <block id="c81e728d9d4c2f636f067f89cc14862c" category="cell">2</block>
  <block id="36d2df43ead992a1e3c86acd0cec69f9" category="cell">4월 4일</block>
  <block id="fac80c1054e849e1ec88244c017978e7" category="cell">1개의 워크로드가 대기열에 있습니다</block>
  <block id="eefc99cd833e14811fb22b758cbc62e5" category="cell">2개의 작업 부하가 대기 중입니다</block>
  <block id="238ff8d9192e9c01e50a8d6d21f1607b" category="cell">팀-b</block>
  <block id="867c7d7d65c50ae3679fabce2eab87a3" category="cell">2월 2일</block>
  <block id="3b40d1328b825dda4b761a8e534669b7" category="cell">팀 - c</block>
  <block id="be46ffa9e65cb964fc3236de02c41e4e" category="paragraph">다음 실행된 명령 시퀀스를 참조하십시오.</block>
  <block id="3bf38f884fd74f6e6f1ec3d80018edd8" category="paragraph">이때 다음과 같은 상태가 있어야 합니다.</block>
  <block id="e55f05703a3e04fbd9e10f76ae925cc9" category="cell">GPU가 할당되었습니다</block>
  <block id="26cc9c6ccae01f319282379c339cd90b" category="cell">작업 로드 대기 중</block>
  <block id="001f9003205f670658ffc60b1e4d62d8" category="cell">각각 GPU를 묻는 2개의 워크로드</block>
  <block id="f0f10ddbe8f00433aad17626c8d96a73" category="cell">각각 2개의 GPU를 요구하는 2개의 워크로드</block>
  <block id="ae7ccf7b1a6a1a023f611a294572a900" category="cell">팀 d</block>
  <block id="f82056dbbe3376b10ac622b0bdaae914" category="cell">8월 8일</block>
  <block id="6adf97f83acf6453d4a6a4b1070f3754" category="cell">없음</block>
  <block id="61b8291124bff8ee36a1c799e35395e9" category="paragraph">그런 다음 'team-d'에 대한 모든 워크로드를 삭제합니다.</block>
  <block id="ed9cf33d84548b5953f8b042c72faef4" category="paragraph">섹션을 참조하십시오 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>를 참조하십시오.</block>
  <block id="543cdcd352596e4ad69b4597a2188c02" category="paragraph"><block ref="543cdcd352596e4ad69b4597a2188c02" category="inline-link-macro-rx"></block></block>
  <block id="8708911de20cfce9bafb315fd0cde0a2" category="summary">제안된 아키텍처의 성능을 평가하기 위해 다수의 테스트를 실행했습니다. 6가지 워크로드(영상 분류, 물체 감지[소형], 물체 감지[대형], 의료 영상, 텍스트 음성 변환, 및 NLP(자연어 처리))를 사용하여 오프라인, 단일 스트림 및 멀티스트림 등 세 가지 시나리오에서 실행할 수 있습니다.</block>
  <block id="3274a50ba9f0d3c0adefdfa11c5094be" category="doc">테스트 결과</block>
  <block id="5e2777e1d5ba6adfeabc55064de508f5" category="inline-link-macro">이전: 테스트 절차</block>
  <block id="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="paragraph"><block ref="3ee9fa6b3e5baa3db7a7d6587d8d590b" category="inline-link-macro-rx"></block></block>
  <block id="507b481f4f0fb36b82f97222c73fb91d" category="section-title">AFF에 대한 테스트 결과</block>
  <block id="817fbb6103e6cb6855c19a5c1b25f817" category="paragraph">제안된 아키텍처의 성능을 평가하기 위해 다수의 테스트를 실행했습니다. 6가지 워크로드(영상 분류, 물체 감지[소형], 물체 감지[대형], 의료 영상, 텍스트 음성 변환, 및 NLP(Natural Language Processing))를 사용하여 오프라인, 단일 스트림 및 멀티스트림의 세 가지 시나리오에서 실행할 수 있습니다.</block>
  <block id="aaabb57453387e4d8fdae92cdf5d558b" category="admonition">마지막 시나리오는 영상 분류 및 물체 감지에 대해서만 구현됩니다.</block>
  <block id="e7b8f9d880e5e20f44e5277ba99d101b" category="paragraph">이렇게 하면 다음과 같은 세 가지 다른 설정 하에서 모두 테스트한 15가지 가능한 워크로드가 제공됩니다.</block>
  <block id="6beb824a1e58582d2c0c733600244087" category="list-text">단일 서버/로컬 스토리지</block>
  <block id="0ce03975d1039901bae5d17f67b2ac39" category="list-text">단일 서버/네트워크 스토리지</block>
  <block id="ffac1c611ceb8a0bd6268359872e3e68" category="list-text">멀티 서버/네트워크 스토리지</block>
  <block id="f5b98cda08f17c4b221c6ef2fbf7217f" category="paragraph">결과는 다음 섹션에 설명되어 있습니다.</block>
  <block id="18d566b8a783b6684a78fc2924714180" category="section-title">AFF의 오프라인 시나리오에서 AI 추론을 사용합니다</block>
  <block id="0aee493b887954641c1ba2e779adcf85" category="paragraph">이 시나리오에서는 서버에서 모든 데이터를 사용할 수 있었고 모든 샘플을 처리하는 데 걸린 시간이 측정되었습니다. 테스트 결과로 초당 샘플에 대역폭이 보고됩니다. 두 개 이상의 컴퓨팅 서버를 사용한 경우 모든 서버에 대한 총 대역폭을 합산한 것으로 보고합니다. 아래 그림에서는 세 가지 사용 사례 모두의 결과를 보여 줍니다. 2서버 사례에서는 두 서버의 결합된 대역폭을 보고합니다.</block>
  <block id="d39bc80b598327ae50c15f64c44bb6ea" category="paragraph"><block ref="d39bc80b598327ae50c15f64c44bb6ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0d89c8c627ec0463d3f82a6cbbc04bd" category="paragraph">결과에 따르면 네트워크 스토리지는 성능에 부정적인 영향을 주지 않습니다. 변경 사항은 최소이며 일부 작업의 경우 아무것도 발견되지 않습니다. 두 번째 서버를 추가할 때 총 대역폭이 정확히 두 배 또는 최악의 경우 변경률이 1% 미만입니다.</block>
  <block id="d0be2e7e62dc4b0bdbb35ded9b6d842e" category="section-title">AFF의 단일 스트림 시나리오에서 AI 추론을 사용합니다</block>
  <block id="fbbf5a4ee90b9175f00f7c8cab5a0670" category="paragraph">이 벤치마크는 지연 시간을 측정합니다. 여러 계산 서버 사례에서는 평균 지연 시간을 보고합니다. 작업 세트의 결과는 아래 그림에 나와 있습니다. 2서버 사례에서는 두 서버 모두의 평균 지연 시간을 보고합니다.</block>
  <block id="01f3906715186988e276bc34ebc661c0" category="paragraph"><block ref="01f3906715186988e276bc34ebc661c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ef9ced66e0746938556409b4c473052" category="paragraph">결과는 네트워크 스토리지가 작업을 처리하기에 충분하다는 것을 다시 한 번 보여 줍니다. 한 서버 케이스에서 로컬 스토리지와 네트워크 스토리지의 차이는 최소 또는 없음입니다. 마찬가지로 두 서버가 동일한 스토리지를 사용하는 경우 두 서버의 지연 시간은 동일하게 유지되거나 매우 적은 양의 변경 사항이 적용됩니다.</block>
  <block id="64a84459b695510c92164965941ad8f1" category="section-title">AFF의 다중 스트림 시나리오에서 AI 추론을 사용합니다</block>
  <block id="22ca0fa830d8fd46fe137f6748374c21" category="paragraph">이 경우 결과적으로 QoS 제약 조건을 만족하면서 시스템에서 처리할 수 있는 스트림의 수가 됩니다. 따라서 결과는 항상 정수입니다. 둘 이상의 서버에 대해 모든 서버에 대해 집계된 총 스트림 수를 보고합니다. 모든 워크로드가 이 시나리오를 지원하는 것은 아니지만 이를 실행했습니다. 테스트 결과는 아래 그림에 요약되어 있습니다. 2서버 사례에서는 두 서버 모두에서 스트림 수가 결합된 것으로 보고합니다.</block>
  <block id="758b60f43cbc650fded1dcf9be428fa5" category="paragraph"><block ref="758b60f43cbc650fded1dcf9be428fa5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3eefb9cc4232b7df67a3c63566ae707" category="paragraph">결과는 설정의 완벽한 성능을 보여줍니다. 로컬 및 네트워킹 스토리지는 동일한 결과를 제공하며 두 번째 서버를 추가하면 제안된 설정에서 처리할 수 있는 스트림 수가 두 배가 됩니다.</block>
  <block id="4ecb5ff41d7f3bd6f1c92bc183f1cb32" category="section-title">EF 테스트 결과</block>
  <block id="ee7c693721c881b091fdb1adf8a37707" category="paragraph">제안된 아키텍처의 성능을 평가하기 위해 다수의 테스트를 실행했습니다. 6가지 워크로드(영상 분류, 물체 감지[소형], 물체 감지[대형], 의료 영상, 텍스트 음성 변환, 두 가지 시나리오(오프라인 및 단일 스트림)에서 실행된 자연어 처리[NLP])를 들 수 있습니다. 결과는 다음 섹션에 설명되어 있습니다.</block>
  <block id="010bb9776a194ae73e567f4812c8be99" category="section-title">EF의 오프라인 시나리오에서 AI 추론을 사용합니다</block>
  <block id="f4fc0d2711e472dedfd5d2952191989c" category="paragraph">이 시나리오에서는 서버에서 모든 데이터를 사용할 수 있었고 모든 샘플을 처리하는 데 걸린 시간이 측정되었습니다. 테스트 결과로 초당 샘플에 대역폭이 보고됩니다. 단일 노드 실행의 경우 두 서버 모두에서 평균을 보고하며, 두 서버 실행 시 모든 서버에 대해 총 대역폭을 집계합니다. 사용 사례에 대한 결과는 아래 그림에 나와 있습니다.</block>
  <block id="8e793f971410e2b57df427d1305ee0a2" category="paragraph"><block ref="8e793f971410e2b57df427d1305ee0a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb71ae4a7513a21f0771b9aa65aeef9c" category="section-title">EF의 단일 스트림 시나리오에서 AI 추론을 사용합니다</block>
  <block id="ca0aa5c3a448e511d9334d94174b8b85" category="paragraph">이 벤치마크는 지연 시간을 측정합니다. 모든 경우에 대해 실행에 관련된 모든 서버의 평균 지연 시간을 보고합니다. 작업 세트의 결과가 제공됩니다.</block>
  <block id="5656e3a262dfb3d6e1cba96551717de0" category="paragraph"><block ref="5656e3a262dfb3d6e1cba96551717de0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f02eaec2bc90de6689765cffde92e809" category="paragraph">결과는 네트워크 스토리지가 작업을 처리하기에 충분하다는 것을 다시 보여줍니다. 한 서버 케이스에서 로컬 스토리지와 네트워크 스토리지의 차이는 Minimal(최소) 또는 None(없음)입니다. 마찬가지로 두 서버가 동일한 스토리지를 사용하는 경우 두 서버의 지연 시간은 동일하게 유지되거나 매우 적은 양의 변경 사항이 적용됩니다.</block>
  <block id="516a608926718d1a912cf9404f1a63ac" category="inline-link-macro">다음으로 아키텍처 사이징 옵션을 살펴보겠습니다.</block>
  <block id="9cedf0fb8faddf365d88f523ae482015" category="paragraph"><block ref="9cedf0fb8faddf365d88f523ae482015" category="inline-link-macro-rx"></block></block>
  <block id="290612199861c31d1036b185b4e69b75" category="doc">요약</block>
  <block id="ee0e2e290e4e02a3860382ef2cc42ca0" category="paragraph">ADAS(Advanced Driver Assistance Systems), Industry 4.0, 스마트 시티 및 IoT(Internet of Things)와 같은 몇 가지 새로운 애플리케이션 시나리오에서는 지연 시간이 거의 없이 지속적인 데이터 스트림을 처리해야 합니다. 이 문서에서는 이러한 요구사항을 충족하는 에지 환경에서 NetApp 스토리지 컨트롤러 및 Lenovo ThinkSystem 서버에 GPU 기반 인공 지능(AI) 추론을 배포하기 위한 컴퓨팅 및 스토리지 아키텍처에 대해 설명합니다. 또한, NVIDIA T4 GPU가 장착된 에지 서버에서 다양한 추론 작업을 평가하여 업계 표준 MLPerf Inference 벤치마크의 성능 데이터도 제공합니다. 오프라인, 단일 스트림 및 다중 스트림 추론 시나리오의 성능을 조사한 결과, 비용 효율적인 공유 네트워크 스토리지 시스템이 포함된 아키텍처의 성능이 매우 뛰어나며 여러 에지 서버에 대한 데이터 및 모델 관리의 중앙 지점을 제공하는 것으로 나타났습니다.</block>
  <block id="e88a70d67e9de42d391fd019f2d06484" category="summary">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및 웹 사이트를 검토하십시오.</block>
  <block id="0f68b904e33d9ac04605aecc958bcf52" category="doc">추가 정보</block>
  <block id="7d5b957cd473f6eaf5ad335a9c63c4ff" category="paragraph">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹 사이트를 검토하십시오.</block>
  <block id="b49efd5b259d6a3bceda1ebb8e34064a" category="list-text">데이터 세트: TuSimple</block>
  <block id="61554b11b65c50bf7a094a86d699c8d5" category="inline-link"><block ref="61554b11b65c50bf7a094a86d699c8d5" category="inline-link-rx"></block></block>
  <block id="b150fd9c1d7740c871626031a398c8a3" category="paragraph"><block ref="b150fd9c1d7740c871626031a398c8a3" category="inline-link-rx"></block></block>
  <block id="a3a3504f7b11916e352125a598e15797" category="list-text">딥 러닝 네트워크 아키텍처: 공간 컨볼루ional 신경망</block>
  <block id="6467a460cb421335f9f5b0523c38c9a6" category="inline-link"><block ref="6467a460cb421335f9f5b0523c38c9a6" category="inline-link-rx"></block></block>
  <block id="35527148b08f99f1d85797af833430dc" category="paragraph"><block ref="35527148b08f99f1d85797af833430dc" category="inline-link-rx"></block></block>
  <block id="cc1881adebe7ddf5b873966741a32ef1" category="list-text">분산형 딥 러닝 교육 프레임워크: Horovod</block>
  <block id="732f85d0d5eaa9222831dd5290518ff2" category="inline-link"><block ref="732f85d0d5eaa9222831dd5290518ff2" category="inline-link-rx"></block></block>
  <block id="655c281079d0281fcf4b8f2f08634c16" category="paragraph"><block ref="655c281079d0281fcf4b8f2f08634c16" category="inline-link-rx"></block></block>
  <block id="934b1fbd011b584c4878284f454f812e" category="list-text">실행: AI 컨테이너 오케스트레이션 솔루션: 실행: AI 제품 소개</block>
  <block id="64b899832bfcad18bb426fb355a0d03b" category="inline-link"><block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="b78ec84f003a4d277e318031a163e191" category="paragraph"><block ref="b78ec84f003a4d277e318031a163e191" category="inline-link-rx"></block></block>
  <block id="275dbaaa3169640f82917075918df905" category="list-text">AI 설치 설명서를 실행하십시오</block>
  <block id="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link"><block ref="1173c05ffb489483ec926c6c1dbc3c26" category="inline-link-rx"></block></block>
  <block id="517046a8acf2e7fa61798debc5b6e25e" category="inline-link"><block ref="517046a8acf2e7fa61798debc5b6e25e" category="inline-link-rx"></block></block>
  <block id="b8b2e04f115b148d49a8cb477ed86af9" category="paragraph"><block ref="f03e58e4917966d9b82995c8ce69643b" category="inline-link-rx"></block><block ref="3530112fad5ba376549c9e0750df83f3" category="inline-link-rx"></block></block>
  <block id="8787c0bfc5af7ce34db56c9a5739f788" category="list-text">실행 중인 작업 제출: AI CLI</block>
  <block id="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link"><block ref="99a4cc6ec01bd067dc6642e6fd5efa0a" category="inline-link-rx"></block></block>
  <block id="ca4ef6cf830a9de78ea71279d0d5417c" category="paragraph"><block ref="ca4ef6cf830a9de78ea71279d0d5417c" category="inline-link-rx"></block></block>
  <block id="984fd97f526f8afe9d2472b0894b84c2" category="inline-link"><block ref="984fd97f526f8afe9d2472b0894b84c2" category="inline-link-rx"></block></block>
  <block id="65640a241681656a4410cd7184278c9b" category="paragraph"><block ref="65640a241681656a4410cd7184278c9b" category="inline-link-rx"></block></block>
  <block id="33a756969a35b0a9029bf2a2c10e6d67" category="list-text">Azure 클라우드 리소스: Azure NetApp Files</block>
  <block id="99ac98f589f6b551211f31e86cb9a212" category="inline-link"><block ref="99ac98f589f6b551211f31e86cb9a212" category="inline-link-rx"></block></block>
  <block id="3085d4407b575d4a8938814c7db17d92" category="paragraph"><block ref="3085d4407b575d4a8938814c7db17d92" category="inline-link-rx"></block></block>
  <block id="f938809a358080d4c7a941e59abfca40" category="list-text">Azure Kubernetes 서비스</block>
  <block id="21d0acc34f6416d6ebd8074617c57439" category="inline-link"><block ref="21d0acc34f6416d6ebd8074617c57439" category="inline-link-rx"></block></block>
  <block id="91c4b230ded9b13564b447ba71304aeb" category="paragraph"><block ref="91c4b230ded9b13564b447ba71304aeb" category="inline-link-rx"></block></block>
  <block id="d9d650693b25d0540fbb606b1d1fbe4e" category="list-text">Azure VM SKU</block>
  <block id="08318cbecd61665ab1824d118c1029a5" category="inline-link"><block ref="08318cbecd61665ab1824d118c1029a5" category="inline-link-rx"></block></block>
  <block id="3e05fd8f7e2e0ac6116dd746a8823eaa" category="paragraph"><block ref="3e05fd8f7e2e0ac6116dd746a8823eaa" category="inline-link-rx"></block></block>
  <block id="b9a1a7c8f2194407b24183f7826d2e44" category="list-text">GPU SKU가 포함된 Azure VM</block>
  <block id="6046df9266bb79e1d99f9c232c1835e3" category="inline-link"><block ref="6046df9266bb79e1d99f9c232c1835e3" category="inline-link-rx"></block></block>
  <block id="d0bf246853f6f35070f6a8231d468c87" category="paragraph"><block ref="d0bf246853f6f35070f6a8231d468c87" category="inline-link-rx"></block></block>
  <block id="43a545df8285ba2aba289a52824f250d" category="inline-link"><block ref="43a545df8285ba2aba289a52824f250d" category="inline-link-rx"></block></block>
  <block id="944823ac69152177e369bd5d9a61a02f" category="paragraph"><block ref="944823ac69152177e369bd5d9a61a02f" category="inline-link-rx"></block></block>
  <block id="a9359a0f51034e1b1972f7690fe03f71" category="list-text">NetApp 구현 Data Fabric</block>
  <block id="781262103885a96ffc9275431a7ef132" category="inline-link"><block ref="781262103885a96ffc9275431a7ef132" category="inline-link-rx"></block></block>
  <block id="93e35e3e458c1d81846aa83c346e240e" category="paragraph"><block ref="93e35e3e458c1d81846aa83c346e240e" category="inline-link-rx"></block></block>
  <block id="bc4fe2352063642d68529f2aa0ca7ca3" category="list-text">NetApp 제품 설명서</block>
  <block id="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link"><block ref="3cd8b5fe5ca94a9fdb5caaf96875ef7e" category="inline-link-rx"></block></block>
  <block id="6bfac05f3cc2c0adace9c385ef708fd9" category="paragraph"><block ref="6bfac05f3cc2c0adace9c385ef708fd9" category="inline-link-rx"></block></block>
  <block id="677b450634b1a6a563206526cb4d9075" category="doc">TR-4858: 실행 시 NetApp 오케스트레이션 솔루션: AI</block>
  <block id="0959ee1db60e15d1e8e42d1206ca6a19" category="paragraph">Rick Huang, David Arnette, Sung-Han Lin, NetApp Yaron Goldberg, Run: AI</block>
  <block id="c87cafeb37457343ef978bbf8cad88b5" category="paragraph">NetApp AFF 스토리지 시스템은 탁월한 성능과 업계 최고 수준의 하이브리드 클라우드 데이터 관리 기능을 제공합니다. NetApp 및 Run: AI는 엔터프라이즈급 성능, 안정성 및 지원을 제공하는 인공 지능(AI) 및 머신 러닝(ML) 워크로드용 NetApp ONTAP AI 솔루션의 고유한 기능을 시연하기 위해 파트너 계약을 체결했습니다. 실행: AI 워크로드 오케스트레이션에서 Kubernetes 기반 스케줄링 및 리소스 활용률 플랫폼을 추가하여 연구원이 GPU 활용률을 관리하고 최적화할 수 있도록 지원합니다. NVIDIA DGX 시스템과 NetApp, NVIDIA, Run의 통합 솔루션: AI는 엔터프라이즈 AI 워크로드를 위해 특별 제작된 인프라 스택을 제공합니다. 이 기술 보고서는 다양한 사용 사례와 산업 수직 분야를 지원하기 위해 대화형 AI 시스템을 구축하는 고객에게 직접적인 지침을 제공합니다. 이 이니셔티브에는 Run:AI 및 NetApp AFF A800 스토리지 시스템 구축에 대한 정보가 포함되며, AI 이니셔티브를 빠르고 성공적으로 구현하는 가장 간단한 방법을 위한 참조 아키텍처 역할을 합니다.</block>
  <block id="cae36004793b7131e0fc2323f598e7bb" category="list-text">컨테이너 마이크로서비스와 같은 Kubernetes 기반 사용 사례에 대한 AI 모델 및 소프트웨어 개발을 위한 솔루션을 설계하는 엔터프라이즈 설계자</block>
  <block id="5d138e1f42e31fb645a3e3f5a8d37929" category="list-text">여러 팀 및 프로젝트가 있는 클러스터 환경에서 효율적인 모델 개발 목표를 달성할 수 있는 방법을 찾는 데이터 과학자</block>
  <block id="0d43a0c7aeec219a746e836746c0b208" category="list-text">운영 모델의 유지 관리 및 실행을 담당하는 데이터 엔지니어</block>
  <block id="00d764d2e91381a99d6f2c7b108e7c8e" category="list-text">최적의 Kubernetes 클러스터 리소스 활용률 경험을 만들고 AI 이니셔티브를 통한 시장 출시 기간을 단축하려는 경영진 및 IT 의사 결정자 및 비즈니스 리더</block>
  <block id="7a83f363d45e73d7915a600e1bbc92ba" category="inline-link-macro">다음: 솔루션 개요</block>
  <block id="29d90e44a805022079f5ad8bc748f89f" category="paragraph"><block ref="29d90e44a805022079f5ad8bc748f89f" category="inline-link-macro-rx"></block></block>
  <block id="7580f940c2b73a449943bf14cfdb743e" category="summary">이 페이지에서는 Azure NetApp Files에 대한 클라우드 리소스 구성에 대해 설명합니다.</block>
  <block id="9ab9ef31301ca94d2090a6ac7e5141f0" category="doc">클라우드 리소스 요구사항</block>
  <block id="1cee510209f529b7ddd8911bbc6e3ee2" category="inline-link-macro">이전: 소프트웨어 요구 사항.</block>
  <block id="abab2b04b3822b72d0eeb7b61dd84730" category="paragraph"><block ref="abab2b04b3822b72d0eeb7b61dd84730" category="inline-link-macro-rx"></block></block>
  <block id="00130c4c20e30be7264c0ff0d085261b" category="section-title">Azure NetApp Files를 구성합니다</block>
  <block id="d696f60435e09b1c41d1db77b458999b" category="inline-link">QuickStart: Azure NetApp Files를 설정하고 NFS 볼륨을 생성합니다</block>
  <block id="b955f251da04c8c868b22cbe7663a4f5" category="paragraph">에 설명된 대로 Azure NetApp Files를 구성합니다<block ref="f8525997ced72f3cfd70e1aecf287af9" category="inline-link-rx"></block>.</block>
  <block id="4ee734214d7dd4e522f2aab3d8e3d349" category="paragraph">Trident를 통해 볼륨을 생성하므로 "Azure NetApp Files용 NFS 볼륨 생성" 섹션을 계속 진행할 수 있습니다. 계속하기 전에 다음 단계를 완료하십시오.</block>
  <block id="2a304a1348456ccd2234cd71a81bd338" category="inline-link">링크</block>
  <block id="b1d13ce152415787185b9f596f9635e1" category="list-text">Azure Shell을 통해 Azure NetApp Files 및 NetApp 리소스 공급자 에 등록(<block ref="7a85c4f09a460b2978e2b516b5474576" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="4c21364a09ae3c9dab758e383fcae62d" category="list-text">Azure NetApp Files(<block ref="27e1abf4e17aeb1c0d418f5fee2f2b5f" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="97f203356061531d1acaf022df0d4c3c" category="list-text">용량 풀 설정(필요에 따라 최소 4TB Standard 또는 Premium)(<block ref="16f1daa909eef5f1fe1f552d6b28d086" category="inline-link-rx"></block>). 다음 표에는 클라우드에서 설정을 위한 네트워크 구성 요구 사항이 나와 있습니다. Dask 클러스터와 Azure NetApp Files는 동일한 Azure VNet(Virtual Network) 또는 피어링된 VNET에 있어야 합니다.</block>
  <block id="ddcf50c29294d4414f3f7c1bbc892cb5" category="cell">리소스</block>
  <block id="3e19b1ddc4033d0c6c439dad720f730d" category="cell">유형/버전</block>
  <block id="f2d1dd8f39098da402272f7606fd2638" category="cell">1.18.14</block>
  <block id="21b6b0c072968b7235d21d8ec72be5dc" category="cell">에이전트 노드</block>
  <block id="e5262abb96ddec17ecbca3557e70ea26" category="cell">3x Standard_DS2_v2</block>
  <block id="c64f4eaffc33134095fd3105b3d63832" category="cell">GPU 노드</block>
  <block id="11fed615c3da90add7abe544e965fa14" category="cell">표준 _NC6s_v3 3개</block>
  <block id="7450cfde7058dc5e1f7909d0280fd7ae" category="cell">Azure NetApp Files</block>
  <block id="238f4027146f2469c7d1209e594471e4" category="cell">표준 용량 풀</block>
  <block id="9163995275052e5abd777ae389b15dfd" category="cell">용량(TB</block>
  <block id="a87ff679a2f3e71d9181a67b7542122c" category="cell">4</block>
  <block id="a6a0cae93cb8ecdef629c6de5f05989c" category="inline-link-macro">다음: 클릭률 예측 사용 사례 요약</block>
  <block id="a5efee0d52d97830d344cded6ac0bf5c" category="paragraph"><block ref="a5efee0d52d97830d344cded6ac0bf5c" category="inline-link-macro-rx"></block></block>
  <block id="d8b778c81ae11eb5edbd4291a3cf8fff" category="doc">기술 개요</block>
  <block id="91c847ff0ec1e96ccc74039eaf1b5bf3" category="section-title">NetApp 개요</block>
  <block id="d30aa8861afaf98888c2367f107a8bc6" category="paragraph">NetApp은 하이브리드 클라우드 환경에서 데이터 관련 최고의 권위자입니다. NetApp은 클라우드와 온프레미스 환경에서 애플리케이션 및 데이터의 관리를 간소화하여 디지털 혁신을 앞당기는 다양한 하이브리드 클라우드 데이터 서비스를 제공합니다. NetApp은 파트너와 함께 글로벌 조직이 데이터의 잠재력을 극대화하여 고객과의 접점을 확대하고 혁신을 촉진하며 운영을 최적화할 수 있도록 돕고 있습니다.</block>
  <block id="af2063646dcea30a4bac90a1c51b14aa" category="section-title">NetApp ONTAP AI를 참조하십시오</block>
  <block id="ee86473f0dbd191846077276ce455778" category="paragraph">NVIDIA DGX 시스템과 NetApp 클라우드 연결형 All-Flash 스토리지를 기반으로 하는 NetApp ONTAP AI를 사용하면 데이터 흐름을 안정적으로 간소화하고 에지에서 코어 및 클라우드에 이르는 Data Fabric을 사용하여 분석, 훈련, 추론의 속도를 높일 수 있습니다. 이 아키텍처는 IT 조직에 다음과 같은 이점을 제공하는 아키텍처를 제공합니다.</block>
  <block id="cee5abf75433f502c31530bc72eecd6a" category="list-text">컴퓨팅과 스토리지를 독립적으로 확장할 수 있습니다</block>
  <block id="6cb062d50ca0d4a2bfa0caec33fea16f" category="list-text">다양한 성능 및 비용 포인트를 위한 다양한 스토리지 옵션을 제공합니다.NetApp ONTAP AI는 NVIDIA DGX-1, 페타플롭 확장 AI 시스템, NVIDIA Mellanox 고성능 이더넷 스위치를 통합한 통합 인프라 스택을 제공하여 AI 워크로드를 통합하고 구축을 간소화하고 ROI를 가속합니다. NetApp은 이 기술 보고서를 위해 하나의 DGX-1 및 NetApp AFF A800 스토리지 시스템과 함께 ONTAP AI를 활용했습니다. 다음 이미지는 이 검증에 사용된 DGX-1 시스템과 ONTAP AI의 토폴로지를 보여줍니다.</block>
  <block id="3eedc2d7451e7ff0440f17c9e61227dc" category="paragraph"><block ref="3eedc2d7451e7ff0440f17c9e61227dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="543ca2d3d9aa63e1a63c69dd219d5f2a" category="section-title">NetApp AI Control Plane</block>
  <block id="e1fc355cf7f97dbf25407695f8852241" category="paragraph">NetApp AI Control Plane을 사용하면 최고의 확장성, 간소화된 구축, 무중단 데이터 가용성을 제공하는 솔루션을 통해 AI 및 ML을 활용할 수 있습니다. AI Control Plane 솔루션은 Kubernetes 및 Kubeflow를 NetApp 구현 Data Fabric과 통합합니다. 클라우드 네이티브 구현을 위한 업계 표준 컨테이너 오케스트레이션 플랫폼인 Kubernetes는 워크로드 확장성 및 이동성을 지원합니다. Kubeflow는 관리 및 구현을 간소화하여 개발자가 더 많은 데이터 과학을 더 빠르게 수행할 수 있도록 지원하는 오픈 소스 머신 러닝 플랫폼입니다. NetApp 구현 Data Fabric은 최고의 데이터 가용성 및 이동성을 제공하여 에지, 코어, 클라우드에 이르는 파이프라인 전반에서 데이터에 액세스할 수 있도록 합니다. 이 기술 보고서에서는 MLRun 파이프라인에서 NetApp AI Control Plane을 사용합니다. 다음 이미지는 각 클러스터에 대해 서로 다른 엔드포인트를 가질 수 있는 Kubernetes 클러스터 관리 페이지를 보여줍니다. NFS 영구 볼륨을 Kubernetes 클러스터에 연결했고 다음 이미지에는 클러스터에 연결된 영구 볼륨이 표시됩니다. 여기서<block ref="33155b45dbdad2f412212744fbe6f8dc" category="inline-link-rx"></block> 영구 스토리지 지원 및 데이터 관리 기능을 제공합니다.</block>
  <block id="b058638c35435549e77a90b91abd3305" category="paragraph"><block ref="b058638c35435549e77a90b91abd3305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eee185b539f0e52d8b64916066463222" category="paragraph"><block ref="eee185b539f0e52d8b64916066463222" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d371ade9f9702601a7e2f8f57c8b013" category="paragraph"><block ref="7d371ade9f9702601a7e2f8f57c8b013" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1dc271f7d3ae88e2a019314b7e4fd8e" category="section-title">Iguazio 개요</block>
  <block id="0c9fe13fe6a660070e99a54151edd7c3" category="paragraph">Iguazio Data Science Platform은 완전히 통합되고 안전한 PaaS(Data Science Platform as a Service)로서 개발을 간소화하고, 성능을 가속화하고, 협업을 촉진하며, 운영 문제를 해결합니다. 이 플랫폼에는 다음과 같은 구성 요소가 통합되어 있으며 이과지오 데이터 과학 플랫폼이 다음 이미지에 나와 있습니다.</block>
  <block id="2137518d79f0a3dfe335e8c02312cf96" category="list-text">Jupyter Notebooks, 통합 분석 엔진 및 Python 패키지를 포함하는 데이터 과학 워크벤치입니다</block>
  <block id="68ed19bfa85e4c4677e50979864e169b" category="list-text">실험 추적 및 자동화된 파이프라인 기능을 사용하여 관리 모델링</block>
  <block id="37a28d84cd653345f1f2c036cb732f2d" category="list-text">확장 가능한 Kubernetes 클러스터를 통해 데이터 및 ML 서비스를 관리했습니다</block>
  <block id="77fdda1a79199ac02cde44b4249cb509" category="list-text">Nuclio는 실시간 서버리스 기능 프레임워크입니다</block>
  <block id="96a6f4a99a7526e82a294d44ed005701" category="list-text">SQL, NoSQL, 시계열 데이터베이스, 파일(단순한 개체), 스트리밍을 지원하는 매우 빠르고 안전한 데이터 계층입니다</block>
  <block id="00a48f02675717eaf6082c4ba536a366" category="list-text">NetApp, Amazon S3, HDFS, SQL 데이터베이스, 스트리밍 또는 메시징 프로토콜 등의 타사 데이터 소스와 통합</block>
  <block id="901630ad39a688431a68dc119f5378a3" category="list-text">Grafana 기반의 실시간 대시보드</block>
  <block id="887fce38ef8ddd8546748bb746ed7e5a" category="paragraph"><block ref="887fce38ef8ddd8546748bb746ed7e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="961027a0ac9a1d9515fa54a5d5372c79" category="inline-link-macro">다음: 소프트웨어 및 하드웨어 요구 사항</block>
  <block id="a10e3ee0949323f601d4c9624980eb47" category="paragraph"><block ref="a10e3ee0949323f601d4c9624980eb47" category="inline-link-macro-rx"></block></block>
  <block id="7661400c51b9fc184bdec46eb5577ff9" category="doc">GitHub에서 코드를 가져옵니다</block>
  <block id="1a3652d661d6b73b6aa57aff1fa5e4d4" category="paragraph">이제 Iguazio 클러스터와 개발자 환경에서 NetApp Cloud Volume 또는 NetApp Trident 볼륨을 사용할 수 있으므로 애플리케이션 검토를 시작할 수 있습니다.</block>
  <block id="ae53ae826cc9a587fbaee0e834dd75ca" category="paragraph">사용자는 고유한 작업 공간(디렉터리)을 가지고 있습니다. 모든 노트북에서 사용자 디렉토리 경로는 "/User"입니다. Iguazio 플랫폼은 디렉토리를 관리합니다. 위의 지침을 따르면 NetApp Cloud 볼륨은 '/NetApp' 디렉토리에 있습니다.</block>
  <block id="754e85a9ea7f4fbb718080a73790abdb" category="paragraph">Jupyter 터미널을 사용하여 GitHub에서 코드를 가져옵니다.</block>
  <block id="1d706cc291efb1d79274befd6f9dd64c" category="paragraph"><block ref="1d706cc291efb1d79274befd6f9dd64c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12d0e4b8ba8db4e6a7aa1dda942a1ed4" category="paragraph">Jupyter 터미널 프롬프트에서 프로젝트를 복제합니다.</block>
  <block id="d4095d9e0ab52b6d683ace00b5cbea55" category="paragraph">이제 Jupyter 작업 공간의 파일 트리에 'netops-netapp' 폴더가 표시됩니다.</block>
  <block id="f8161ff446bbd6f76b0d99d6f34a1d7f" category="inline-link-macro">다음: 작업 환경 구성</block>
  <block id="48dd929a2f5f248856ce2768950aff4e" category="paragraph"><block ref="48dd929a2f5f248856ce2768950aff4e" category="inline-link-macro-rx"></block></block>
  <block id="1703cadf8e847114fb353feaaf03beb9" category="summary">이 섹션에는 Kubernetes를 ONTAP AI Pod에 구축할 때 실행할 수 있는 다양한 고성능 작업의 예가 포함되어 있습니다.</block>
  <block id="639ce1b23959b4470d67802f0e5e412a" category="doc">ONTAP AI 배포에 대한 고성능 작업 예</block>
  <block id="b7cd12d2dd9ac8e3414514a02e5df6f4" category="inline-link-macro">다음: 단일 노드 AI 워크로드 실행</block>
  <block id="6ee8519e7493385361c9afcfd675c8d0" category="paragraph"><block ref="6ee8519e7493385361c9afcfd675c8d0" category="inline-link-macro-rx"></block></block>
  <block id="0a1bc6b4024485ff9b55c99c1237e175" category="doc">실행 시 클러스터 및 GPU 활용률 최적화: AI</block>
  <block id="612edeb05f6d237e20f3d843d6e7eba4" category="paragraph">다음 섹션에서는 AI 설치, 테스트 시나리오, 그리고 이 검증에서 수행된 결과에 대해 자세히 설명합니다.</block>
  <block id="2df14da3d7db15550e8eafc892e89d8e" category="paragraph">TensorFlow 벤치마크를 비롯하여 업계 표준 벤치마크 툴을 사용하여 이 시스템의 운영 및 성능을 검증했습니다. ImageNet 데이터 세트는 이미지 분류를 위해 유명한 CNN(Convolutional Neural Network) DL 모델인 ResNet-50을 교육하는 데 사용되었습니다. ResNet-50은 더욱 빠른 처리 시간으로 정확한 교육 결과를 제공하므로 스토리지에서 충분한 수요를 창출할 수 있습니다.</block>
  <block id="13bb3aa52565b3e3f517764c0e88c324" category="paragraph"><block ref="123704fec3ddad892d7c2ae5c4de301b" category="inline-link-macro-rx"></block>.</block>
  <block id="d577549f9b3a229c338e203a433489f6" category="summary">이 섹션에서는 AKS VNET를 Azure NetApp Files VNET와 피어로 사용하는 방법을 설명합니다.</block>
  <block id="e61e6d340ad05dc2e1ad0982f6857d7d" category="doc">피어 AKS VNET 및 Azure NetApp Files VNET</block>
  <block id="1c45d541f316a23589217be5991b1545" category="inline-link-macro">이전: Azure NetApp Files에 대해 위임된 서브넷을 만듭니다.</block>
  <block id="786730f8769009abf0bf6400157dd16b" category="paragraph"><block ref="786730f8769009abf0bf6400157dd16b" category="inline-link-macro-rx"></block></block>
  <block id="e6ef5f0946a89d073a8f360de1038061" category="paragraph">AKS VNET를 Azure NetApp Files VNET와 상호 운용하려면 다음 단계를 수행하십시오.</block>
  <block id="87c2d6c506d0bf65d2c5d773474f9c0f" category="list-text">검색 필드에 가상 네트워크를 입력합니다.</block>
  <block id="7680f3bc49a836c67a8b0e7d2d9ccb44" category="list-text">VNET AKS-VNET-NAME을 선택합니다 이 버튼을 클릭하고 검색 필드에 '북경'을 입력합니다.</block>
  <block id="fc3bb6a018a8f599cab21678959f92b0" category="list-text">추가 를 클릭합니다.</block>
  <block id="1991ef5bd8e165e42c56ccaefa2f640f" category="list-text">다음 설명을 입력합니다.</block>
  <block id="51e5b9c0a583a9afbc2f998e622fd30d" category="list-text">피어링 링크명은 AKS-VNET-NAME_to_anf입니다.</block>
  <block id="14ac6521e2758ba95fe7be9ca6a82cd1" category="list-text">VNET 피어링 파트너로 구독하는 Azure NetApp Files VNET와 가입자 ID입니다.</block>
  <block id="70b58cb057d859d4da9f17e43ffd238c" category="list-text">별표가 아닌 모든 섹션은 기본값을 사용하여 남겨 둡니다.</block>
  <block id="1bb250fbf1946dd1bd7ad228032f8803" category="list-text">추가 를 클릭합니다.</block>
  <block id="50e3209c871e4867931ef51a9344a921" category="paragraph">자세한 내용은 을 참조하십시오<block ref="f81943721c88f7efe9b8252470f9ea43" category="inline-link-rx"></block>.</block>
  <block id="fd3c95528aa9718948de8d4e38b2fa2c" category="inline-link-macro">다음: Trident를 설치합니다.</block>
  <block id="18337fe57049583a9c04a79f64a2088f" category="paragraph"><block ref="18337fe57049583a9c04a79f64a2088f" category="inline-link-macro-rx"></block></block>
  <block id="2e52c56d063752bbfeda9c8f9d2fee41" category="summary">이 페이지에서는 Kubernetes 클러스터에서 NetApp Trident를 설치 및 구성하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="7c4090c7fa7a91e8c7fed182401dbf6b" category="doc">NetApp Trident 구축 및 구성</block>
  <block id="e539ec743b02403b5ba74b884d117a5a" category="paragraph">이 섹션에서는 Kubernetes 클러스터에 NetApp Trident를 설치 및 구성하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="ee68e5b99222bbc29a480fcb0d1d6ee2" category="section-title">필수 구성 요소</block>
  <block id="e5595c75c723712666f834213ee6568f" category="paragraph">이 섹션에 요약된 배포 연습을 수행하기 전에 이미 다음 작업을 수행했다고 가정합니다.</block>
  <block id="40ef3fb23e015d9b4b46a16fa50f10d3" category="inline-link">Trident 문서</block>
  <block id="14ede02439184c7c75e53410ffa40370" category="list-text">Trident에서 지원하는 작업 중인 NetApp 스토리지 어플라이언스, 소프트웨어 정의 인스턴스 또는 클라우드 스토리지 서비스가 이미 있습니다.</block>
  <block id="984b69562391cb8032fd50ded03a29a6" category="paragraph">Kubernetes 클러스터에 NetApp Trident를 설치 및 구성하려면 배포 점프 호스트에서 다음 작업을 수행하십시오.</block>
  <block id="07d8795f785e6495307106596d07402e" category="list-text">다음 방법 중 하나를 사용하여 Trident를 배포합니다.</block>
  <block id="040d3466a6f1c45ca2e523c9354dfdc7" category="inline-link">Trident 배포 지침</block>
  <block id="bb6989644edf59b8c5e0de0c25b6f8b6" category="list-text">NVIDIA DeepOps를 사용하여 Kubernetes 클러스터를 구축한 경우, NVIDIA DeepOps를 사용하여 Kubernetes 클러스터에 Trident를 구축할 수도 있습니다. DeepOps를 사용하여 Trident를 배포하려면 을 따릅니다<block ref="77e542aaaac8c5d2482c94ca2d79c997" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="014e85e7f3bbdad1ad6f193e82d21755" category="inline-link">배포 지침</block>
  <block id="f363c1a10e150fdee0f4f310a06acb5e" category="inline-link-macro">ONTAP AI 배포에 대한 Trident 백엔드 예</block>
  <block id="7cfdcb466d040b6c8f9c85e9981b9652" category="inline-link-macro">ONTAP AI 배포를 위한 Kubernetes Storagecles의 예</block>
  <block id="180b707bbdd9c2fc8001a966c6c7d029" category="admonition">ONTAP AI Pod에 NetApp AI Control Plane 솔루션을 구축하는 경우 를 참조하십시오 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block> 및 를 생성할 수 있는 다른 Trident 백엔드의 몇 가지 예를 확인하십시오 <block ref="d495c2f5a68f6923824470c0096419c8" category="inline-link-macro-rx"></block> 생성할 수 있는 여러 Kubernetes StorageClasses의 몇 가지 예를 확인하십시오.</block>
  <block id="4fe6ae61b2ccf0bd553bc2c0f15cf803" category="inline-link-macro">다음: ONTAP AI 배포에 대한 Trident 백엔드 예</block>
  <block id="8de05380035e6d3c48105e0b80ca2e32" category="paragraph"><block ref="8de05380035e6d3c48105e0b80ca2e32" category="inline-link-macro-rx"></block></block>
  <block id="ca6d5ad374e3cf268dec341c0c398442" category="summary">이 아키텍처에서 초점은 AI 또는 머신 러닝(ML) 분산 훈련 프로세스 중 가장 컴퓨팅 집약적인 레인 감지 프로세스에 있습니다.</block>
  <block id="c0c4b60d27032c028c91440e9d3be949" category="doc">솔루션 개요</block>
  <block id="8cb13336dc020a2fb7bca9d4e940cc64" category="paragraph">이 아키텍처에서 초점은 AI 또는 머신 러닝(ML) 분산 훈련 프로세스 중 가장 컴퓨팅 집약적인 레인 감지 프로세스에 있습니다. 차선 감지는 자동 주행에서 가장 중요한 작업 중 하나로서, 차선 표시를 현지화함으로써 차량을 인도하는 데 도움이 됩니다. 차선 표시와 같은 정적 구성 요소는 차량이 고속도로를 대화식으로 안전하게 주행하도록 안내합니다.</block>
  <block id="0721542454dcaa77c97cd9c545d9063f" category="paragraph">합성신경망(CNN) 기반 접근 방식은 장면에 대한 이해와 세그멘테이션을 새로운 차원으로 끌어올려 왔습니다. 폐쇄될 수 있는 긴 구조 및 영역(예: 폴, 차선의 음영 등)이 있는 물체에는 이 기능이 제대로 작동하지 않습니다. 공간 컨벌루ional Neural Network(SCNN)는 CNN을 풍부한 공간 수준으로 일반화합니다. 동일한 레이어에서 뉴런 간에 정보를 전달할 수 있으므로 폐색이 있는 레인, 폴 또는 트럭과 같은 구조적 개체에 가장 적합합니다. 이러한 호환성은 공간 정보를 보강할 수 있고 매끄러움과 지속성을 유지하기 때문입니다.</block>
  <block id="df38a65c87631c9530cc3a6832ea7a7d" category="paragraph">모델이 데이터세트의 다양한 구성 요소를 학습하고 구분할 수 있도록 시스템에 수천 개의 화면 이미지를 삽입해야 합니다. 이러한 이미지에는 날씨, 주간 또는 야간, 다차선 고속도로 도로 및 기타 교통 상황이 포함됩니다.</block>
  <block id="f7759f002b4a60b5c837abb7f8936037" category="paragraph">교육에는 양질의 데이터와 많은 양의 데이터가 필요합니다. 단일 GPU 또는 여러 GPU를 사용하여 교육을 완료하는 데 며칠~몇 주가 걸릴 수 있습니다. 데이터 분산 교육을 통해 여러 노드 및 GPU를 사용하여 프로세스를 가속화할 수 있습니다. Horovod는 분산 교육을 제공하지만 GPU 클러스터 간에 데이터를 읽는 것이 방해가 될 수 있는 프레임워크 중 하나입니다. Azure NetApp Files은 컴퓨팅 용량의 최고에 GPU를 활용할 수 있도록 초고속, 높은 처리량, 지속적으로 짧은 지연 시간을 제공합니다. 이번 실험에서 클러스터 전체의 모든 GPU가 SCNN을 사용하여 차선 감지를 교육하기 위해 평균 96% 이상 사용되고 있다는 것을 확인했습니다.</block>
  <block id="bf8dd94f74c5878ba969abeeef0286d1" category="section-title">대상</block>
  <block id="0ca450eccdc7141b5e85e9e691a7f16b" category="paragraph">데이터 과학은 IT 및 비즈니스 분야의 여러 분야를 통합하므로 여러 페르소나가 대상 고객을 대상으로 합니다.</block>
  <block id="8acb1f50d0ada4e1149c01a5aa15b9ce" category="list-text">데이터 과학자는 자신이 선택한 도구와 라이브러리를 사용할 수 있는 유연성이 필요합니다.</block>
  <block id="d0ba3808090644db73caeb23fcc2b17c" category="list-text">데이터 엔지니어는 데이터 흐름과 데이터 위치를 알아야 합니다.</block>
  <block id="22a8c99419dee54a28ed1e2355a6706b" category="list-text">자율 주행 사용 사례 전문가</block>
  <block id="18f66c4bad233033dabddf6ff1289eeb" category="list-text">클라우드 관리자 및 설계자는 Azure(클라우드) 리소스를 설정하고 관리합니다.</block>
  <block id="4c9b6067f04f945e9247ecd00c22e328" category="list-text">DevOps 엔지니어는 새로운 AI/ML 애플리케이션을 CI/CD(Continuous Integration and Continuous Deployment) 파이프라인에 통합하는 툴을 필요로 합니다.</block>
  <block id="53720cf6403ac6b8a2402cce66c79d4f" category="list-text">비즈니스 사용자는 AI/ML 애플리케이션에 액세스할 수 있기를 원합니다.</block>
  <block id="68dcdc6243e54c14b4c41c129d574c43" category="paragraph">이 문서에서는 Azure NetApp Files, RUN:AI 및 Microsoft Azure가 각 역할이 비즈니스에 제공하는 데 어떤 도움이 되는지 설명합니다.</block>
  <block id="8f4c7939e8a42e023939df947aba54f6" category="section-title">솔루션 기술</block>
  <block id="8017303b9b2c96742151083f089fc51f" category="paragraph">이 섹션에서는 Azure 클라우드에서 완벽하게 실행되는 분산 교육 솔루션을 구현하여 레인 감지 사용 사례에 대한 기술 요구 사항을 다룹니다. 아래 그림은 솔루션 아키텍처를 간략하게 보여 줍니다.</block>
  <block id="f17291da16ed3dd7b705548f16706120" category="paragraph">이 솔루션에 사용되는 요소는 다음과 같습니다.</block>
  <block id="f28c5620810ae2a6961a1811277a7ff8" category="list-text">Azure Kubernetes 서비스(AKS)</block>
  <block id="03023f4a63d3d8f8ff86ff8246f75b9a" category="list-text">NVIDIA GPU를 사용하는 Azure Compute SKU</block>
  <block id="ae5ba69294a1b9feb03e6dd75395092c" category="list-text">실행: AI</block>
  <block id="951370659c41a55ac9f80ff19c2f4b26" category="paragraph">여기에 언급된 모든 요소에 대한 링크는 에 나와 있습니다 <block ref="c8b73068ae16e202922904f7ed452f8e" category="inline-link-macro-rx"></block> 섹션을 참조하십시오.</block>
  <block id="00d9279819736707d2b224ec427a8aae" category="paragraph"><block ref="00d9279819736707d2b224ec427a8aae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6a2faff353ad4e74bf3ee92e5d8b9c6" category="section-title">클라우드 리소스 및 서비스 요구사항</block>
  <block id="5b691a1a00c6c03be70e559f55ae4fef" category="paragraph">다음 표에는 솔루션을 구현하는 데 필요한 하드웨어 구성요소가 나와 있습니다. 솔루션 구현에 사용되는 클라우드 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="c8e2277ecfb1427838c488c217f99466" category="cell">클라우드</block>
  <block id="694e8d1f2ee056f98ee488bdc4982d73" category="cell">수량</block>
  <block id="5f3bc5eb45e6b472bf3345d1036945e9" category="cell">AKS</block>
  <block id="55b8660903ebaaed924e945432fe269e" category="cell">최소 3개의 시스템 노드 및 3개의 GPU 작업자 노드</block>
  <block id="3580a6b3e7ba0d55af17daee07244cbd" category="cell">가상 머신(VM) SKU 시스템 노드입니다</block>
  <block id="8f75b0af54b5e672a660f4f1f1557f18" category="cell">Standard_DS2_v2 3개</block>
  <block id="a6066b29e1c4603af2c5c46cf549f764" category="cell">VM SKU GPU 작업자 노드입니다</block>
  <block id="6aa4bab72f83c0b68587ee208f2c9ab0" category="cell">표준 _NC6s_v3 3개</block>
  <block id="3468e131592d70a22139936f3fb21403" category="cell">4TB 표준 계층</block>
  <block id="7ddb33edf227a18eb76201fcb9e2c9db" category="section-title">소프트웨어 요구 사항</block>
  <block id="d9ae1ecd6158beb6acd24c9f59d0498e" category="paragraph">다음 표에는 솔루션을 구현하는 데 필요한 소프트웨어 구성요소가 나와 있습니다. 솔루션 구현에 사용되는 소프트웨어 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="719d067b229178f03bcfa1da4ac4dede" category="cell">소프트웨어</block>
  <block id="cb251883efe045266871b7dd15229644" category="cell">버전 또는 기타 정보</block>
  <block id="bb451ae1fa5a629a0307949d38a60e2d" category="cell">AKS - Kubernetes 버전</block>
  <block id="13c5eaa211a3778d391d5c8f65b80234" category="cell">실행: AI CLI</block>
  <block id="89633b9d6f401377b6ece0682b92530a" category="cell">v2.2.25</block>
  <block id="4b138e2d1492b1e550d42348c65cbf82" category="cell">실행: AI Orchestration Kubernetes Operator version</block>
  <block id="6db851ff24c4b893a85242e63bbea119" category="cell">1.0.109</block>
  <block id="f5f1c35a78d5584cdb787d4e3b6b10b6" category="cell">호로브</block>
  <block id="4a7724061c17f8cf5be61a8adf4c170f" category="cell">0.21.2</block>
  <block id="44adee2c140fc723412bae93732e5993" category="cell">20.01.1</block>
  <block id="152090ff5e9a05ea7e1cf0c248449638" category="cell">헬름</block>
  <block id="272f0a04b740763e0a29316bc4af89a4" category="cell">3.0.0</block>
  <block id="cff4cbb413623685c446a2632974cf62" category="summary">이 페이지에서는 기존 Pandas를 이용한 모델 교육 시간을 DASK와 비교합니다. Pandas의 경우, 메모리 오버플로를 방지하기 위해 처리 시간이 느려지기 때문에 더 적은 양의 데이터를 로드했습니다. 따라서 공정한 비교를 제공하기 위해 결과를 보간했습니다.</block>
  <block id="014020acc8f97c1da58961d44b6301eb" category="doc">교육 시간 비교</block>
  <block id="76c5145913d13d6c3105c4265a78047e" category="inline-link-macro">이전: 기본 작업 스트림 대시보드를 사용하여 Dask를 모니터링합니다.</block>
  <block id="a871e4d194e2df9c65b061a5fc7cb154" category="paragraph"><block ref="a871e4d194e2df9c65b061a5fc7cb154" category="inline-link-macro-rx"></block></block>
  <block id="c8ed0bb49061765f5f30ba006ea7c5c0" category="paragraph">이 섹션에서는 기존 Pandas를 사용한 모델 교육 시간을 DASK와 비교합니다. Pandas의 경우, 메모리 오버플로를 방지하기 위해 처리 시간이 느려지기 때문에 더 적은 양의 데이터를 로드했습니다. 따라서 공정한 비교를 제공하기 위해 결과를 보간했습니다.</block>
  <block id="5b5214524edbd74fb721da08e61c8a41" category="paragraph">다음 표에서는 Pandas 무작위 포리스트 모델에 사용되는 데이터(데이터 세트의 15일 당 20억 개 중 5천만 개 행)가 상당히 적은 경우의 원시 교육 시간 비교를 보여 줍니다. 이 샘플은 사용 가능한 모든 데이터의 0.25% 이하만을 사용합니다. Dask-cuML의 경우 사용 가능한 모든 20억 행에 대해 무작위 포리스트 모델을 교육했습니다. 두 가지 접근 방식은 비슷한 훈련 시간을 낳았습니다.</block>
  <block id="40a68b5da4b9b224764558bb02ecd028" category="cell">접근 방식</block>
  <block id="0e90ab0d7d04d2a878961f8d40071c83" category="cell">교육 시간</block>
  <block id="24cc88af022e13431f8005b38f74e0fd" category="cell">Scikit-learn: 15일째에 50M 행만 교육 데이터로 사용합니다</block>
  <block id="26e394f0b8009246698f4844db682015" category="cell">47분 21초</block>
  <block id="ed536b2798ed9f16a79fb8f772601548" category="cell">RAPIDS-DASK: 15일 안에 20B 행을 모두 훈련 데이터로 사용</block>
  <block id="8809f6d1a4b5cbd872b52f83e378e527" category="cell">1시간, 12분, 11초</block>
  <block id="57093fade268287629c2720356ecac57" category="paragraph">다음 표와 같이 교육 시간 결과를 선형적으로 보간할 경우 Dask와 함께 분산 훈련을 사용하면 큰 이점이 있습니다. 기존의 Pandas scikit-learn 접근 방식을 통해 클릭 로그를 하루에 45GB의 데이터를 처리하고 교육하는 데 13일이 걸리는 반면, RAPIDS-Dask 방식을 사용하면 같은 양의 데이터를 262.39배 더 빠르게 처리할 수 있습니다.</block>
  <block id="36ebc33745cb5ac06238c615c8aaebdc" category="cell">Scikit-learn: 15일째에 20B 행을 모두 훈련 데이터로 사용합니다</block>
  <block id="b2ab615236e8c7812b0ab7dff59c552f" category="cell">13일, 3시간, 40분, 11초</block>
  <block id="0d7cda3e89555f27bf26cf0c0c4f4fed" category="paragraph">이전 표에서 RAPIDS와 DASK를 사용하여 여러 GPU 인스턴스에 데이터 처리 및 모델 훈련을 분산하면, Scikit-learn 모델 훈련을 통해 기존 PandDataFrame 처리에 비해 실행 시간이 상당히 짧아진다는 것을 알 수 있습니다. 이 프레임워크를 통해 다중 노드, 다중 GPU 클러스터의 온프레미스뿐만 아니라 클라우드에서 스케일업 및 스케일아웃이 가능합니다.</block>
  <block id="fbd52cffa97d6ec5e0230516fc61f14c" category="inline-link-macro">다음: Prometheus 및 Grafana를 사용하여 Dask 및 RAPIDS를 모니터링합니다.</block>
  <block id="78117011d88a8971f2eadbeee6ac6474" category="paragraph"><block ref="78117011d88a8971f2eadbeee6ac6474" category="inline-link-macro-rx"></block></block>
  <block id="84860cc77161e23e44eccd05430c00ea" category="doc">실행 중인 작업 제출: AI CLI</block>
  <block id="68c9d249f35c91dfcc4a11e209ccbdba" category="paragraph">이 섹션에서는 Kubernetes 작업 실행에 사용할 수 있는 기본 Run:AI 명령에 대한 자세한 정보를 제공합니다. 워크로드 유형에 따라 3개 부분으로 나뉩니다. AI/ML/DL 워크로드는 다음과 같은 두 가지 일반 유형으로 나눌 수 있습니다.</block>
  <block id="754edd5bae16b4a2ed8e6673821d3339" category="list-text">* 무인 교육 세션 *. 이러한 유형의 워크로드를 사용하여 데이터 과학자는 자체 실행 워크로드를 준비하여 실행을 위해 보냅니다. 실행 중에 고객은 결과를 검토할 수 있습니다. 이러한 유형의 워크로드는 생산 또는 인물 개발에 사람의 개입이 필요 없는 단계에 있을 때 주로 사용됩니다.</block>
  <block id="fdfda155b7c1021ae5e73d2ab01c0129" category="list-text">* 대화형 빌드 세션 *. 이러한 유형의 워크로드를 사용하여 데이터 과학자는 Bash, Jupyter Notebook, remote PyCharm 또는 유사한 IDE를 사용한 대화형 세션을 열고 GPU 리소스에 직접 액세스합니다. 연결된 포트를 사용하여 대화형 워크로드를 실행하는 세 번째 시나리오가 포함되어 컨테이너 사용자에게 내부 포트를 제공합니다.</block>
  <block id="6ec08732676824c58d76b0ecdc2aed24" category="section-title">무인 교육 워크로드</block>
  <block id="18cb2734d0533ff093ddcb1b3005e216" category="paragraph">프로젝트를 설정하고 GPU를 지정한 후 명령줄에서 다음 명령을 사용하여 모든 Kubernetes 워크로드를 실행할 수 있습니다.</block>
  <block id="68e667063c4711033bbf6b7f8b312e1f" category="paragraph">이 명령은 단일 GPU를 할당하여 팀 A의 무인 교육 작업을 시작합니다. 이 작업은 샘플 Docker 이미지 'GCR.IO/RUN-AI-DEMO/QuickStart'를 기반으로 합니다. 우리는 그 일을 하이퍼1이라고 명명했다. 그런 다음 다음 다음 명령을 실행하여 작업의 진행률을 모니터링할 수 있습니다.</block>
  <block id="cbae10285b6d282e740369a59fd25aaf" category="paragraph">다음 그림은 루나이 리스트 명령의 결과를 보여준다. 표시되는 일반적인 상태는 다음과 같습니다.</block>
  <block id="e749e4e3bf7ed6d5368f336ba6ceeead" category="list-text">'ContainerCreating' Docker 컨테이너를 클라우드 저장소에서 다운로드하고 있습니다.</block>
  <block id="f5231f23820da3ad520bb16a9dfe97a7" category="list-text">'보류 중'. 작업이 예약될 때까지 대기 중입니다.</block>
  <block id="411497b40a902afd2813d3c7af137ffb" category="list-text">'러닝'입니다. 작업이 실행 중입니다.</block>
  <block id="c0801feb8216aa6b36a769e14c3bc138" category="paragraph"><block ref="c0801feb8216aa6b36a769e14c3bc138" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4f5f0c8fb5ec5bccf18cfd167b1d3bc5" category="paragraph">작업에 대한 추가 상태를 가져오려면 다음 명령을 실행합니다.</block>
  <block id="db0b192c9c9b9885b435e466b9ac861c" category="paragraph">작업의 로그를 보려면 "runai logs &lt;job-name&gt;" 명령을 실행합니다.</block>
  <block id="280782f59c990a941b600c998427a52c" category="paragraph">이 예에서는 각 단계에 대해 현재 교육 Epoch, ETA, 손실 함수 값, 정확도 및 경과 시간을 포함하여 실행 중인 DL 세션의 로그를 확인해야 합니다.</block>
  <block id="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link"><block ref="d63ebd1b7a89c0dad6259299d710b16e" category="inline-link-rx"></block></block>
  <block id="848ad760ae00e3eca33445cd09cfdf34" category="paragraph">의 Run:AI UI에서 클러스터 상태를 볼 수 있습니다<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>. 대시보드 &gt; 개요 에서 GPU 사용률을 모니터링할 수 있습니다.</block>
  <block id="f899123d07ffe99c3d97952ae96017ed" category="paragraph">이 워크로드를 중지하려면 다음 명령을 실행합니다.</block>
  <block id="1f979b6140776c287d458036805ad8aa" category="inline-link">무인 교육 워크로드 실행</block>
  <block id="637552715214e8c0c87022bac459e824" category="paragraph">이 명령은 교육 워크로드를 중지합니다. 이 작업은 'runai list'를 다시 실행하여 확인할 수 있습니다. 자세한 내용은 을 참조하십시오<block ref="e5fbbc266c1fd3a9a029581f5747622d" category="inline-link-rx"></block>.</block>
  <block id="7afece97948db40e546138d81dd343e1" category="section-title">대화형 빌드 워크로드</block>
  <block id="30330792601ba24e9ad5f4f5ee0d5151" category="paragraph">프로젝트를 설정하고 GPU를 할당하면 명령줄에서 다음 명령을 사용하여 대화형 빌드 워크로드를 실행할 수 있습니다.</block>
  <block id="ca57038d87e3f48eb98329e6fd449824" category="paragraph">이 작업은 샘플 Docker 이미지 Python을 기반으로 합니다. 우리는 작업 구축1이라는 이름을 붙였습니다.</block>
  <block id="39fd96ce47a2aa757eb5cc98cd910730" category="admonition">인터액티브 플래그는 작업이 시작이나 끝이 없다는 뜻입니다 이 일을 마무리하는 것은 연구자의 책임입니다. 관리자는 시스템에 의해 종료된 후 대화형 작업에 대한 시간 제한을 정의할 수 있습니다.</block>
  <block id="d39d9c693980c2af510d4a58be6f2620" category="paragraph">이 작업에는 '--g 1' 플래그가 GPU를 하나만 할당합니다. 명령어와 논리는 '--명령 슬립--args 무한대'입니다. 명령을 제공해야 합니다. 그렇지 않고 컨테이너가 시작되고 즉시 종료됩니다.</block>
  <block id="aedc6bf8e3cb52af4a660584c69353ca" category="paragraph">다음 명령은 에 설명된 명령과 유사하게 작동합니다 <block ref="a09c3ced87a580a4004dfa2429aba9c7" category="inline-xref-macro-rx"></block>:</block>
  <block id="1d2bac5ee25c12c0ee793df98c1b4d49" category="list-text">'runai list': 이름, 상태, 나이, 노드, 이미지, 작업을 위해 프로젝트, 사용자 및 GPU를 지원합니다.</block>
  <block id="6b5b5fdb13c8b8af02a41b296af91a2e" category="list-text">runai get build1: 작업 build1에 추가 상태를 표시합니다.</block>
  <block id="9c1e129aa488b11d05275f016f42dda5" category="list-text">'runai delete build1': 대화형 워크로드 빌드 중지1. bash 셸을 컨테이너에 가져오려면 다음 명령을 사용합니다.</block>
  <block id="ac97b61bdc50cfc22ffd507de190d00c" category="paragraph">그러면 컴퓨터에 직접 셸이 제공됩니다. 그런 다음 데이터 과학자는 컨테이너 내에서 모델을 개발 또는 미세 조정할 수 있습니다.</block>
  <block id="5051a9eb1fad38f876a260ba0a4850af" category="inline-link"><block ref="5051a9eb1fad38f876a260ba0a4850af" category="inline-link-rx"></block></block>
  <block id="c7fdd5fcf033fb9395c27ecbf2e54fc9" category="inline-link">대화형 빌드 워크로드 시작 및 사용</block>
  <block id="ff53dc42327d97c7410a6ac241222ffe" category="paragraph">의 Run:AI UI에서 클러스터 상태를 볼 수 있습니다<block ref="29f2b88109b12c4db8e875d3f5ba7aae" category="inline-link-rx"></block>. 자세한 내용은 을 참조하십시오<block ref="f3d6ab8050b43c83f452779c7622ab1d" category="inline-link-rx"></block>.</block>
  <block id="1028c65994f7201e0f43b3bf5d3c6b41" category="section-title">연결된 포트를 사용하는 대화형 작업 부하</block>
  <block id="7d05c708b92b4809bfe9bf66edf8f765" category="inline-link">침투</block>
  <block id="34274fcc13408f06acfe43c4065c3f3b" category="paragraph">대화형 빌드 워크로드의 확장으로 Run:AI CLI로 컨테이너를 시작할 때 컨테이너 사용자에게 내부 포트를 표시할 수 있습니다. 이 기능은 Jupyter Notebooks와 함께 작업하거나 다른 마이크로서비스에 연결하는 클라우드 환경에 유용합니다.<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> Kubernetes 클러스터 외부에서 Kubernetes 서비스에 액세스할 수 있습니다. 어떤 인바운드 연결이 어떤 서비스에 연결할지 정의하는 규칙 모음을 만들어 액세스를 구성할 수 있습니다.</block>
  <block id="e7f72a2c9a0cb7337eb00a3093f846da" category="paragraph">클러스터의 서비스에 대한 외부 액세스를 보다 효율적으로 관리하기 위해 클러스터 관리자를 설치하는 것이 좋습니다<block ref="fd51448530c36b6101cc67fbacf525b9" category="inline-link-rx"></block> 및 로드 밸런서를 구성합니다.</block>
  <block id="16d79943625573d5b80809fe2a7ddbdd" category="paragraph">서비스 유형으로 수신을 사용하려면 다음 명령을 실행하여 워크로드를 제출할 때 메서드 유형과 포트를 설정합니다.</block>
  <block id="79fcc0299f1a85ebab053926e2222bca" category="paragraph">컨테이너가 성공적으로 시작된 후 runai list를 실행하여 Jupyter Notebook에 액세스할 수 있는 Service URL(S)을 확인합니다. URL은 수신 엔드포인트, 작업 이름 및 포트로 구성됩니다. 예를 들어 를 참조하십시오<block ref="0309fbe8f364c8f6dfe6f383da8c46c2" category="inline-link-rx"></block>.</block>
  <block id="451b08ed1bf6f7f0a8931cff52c4c45e" category="inline-link">연결된 포트를 사용하여 대화형 빌드 워크로드 시작</block>
  <block id="b524842923f8cb1e38064fadc680893f" category="paragraph">자세한 내용은 을 참조하십시오<block ref="414875add8a18a03ddddfb14fb1c47f4" category="inline-link-rx"></block>.</block>
  <block id="5bb97c2dd089da990a792356c72a6128" category="inline-link-macro">다음: 높은 클러스터 사용률 달성</block>
  <block id="8f87de13e6ff3dd2fc164bdb930759bb" category="paragraph"><block ref="8f87de13e6ff3dd2fc164bdb930759bb" category="inline-link-macro-rx"></block></block>
  <block id="3ff1a758f526c5ceb434059efe27020a" category="summary">Apache Airflow 워크플로의 예</block>
  <block id="6e4cd672cd8bd06c42a9e4ba697c61de" category="inline-link">Kubernetes용 NetApp 데이터 과학 툴킷</block>
  <block id="c5da96d7204df28dd9fdc33139c8a776" category="paragraph">를 클릭합니다<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> 공기 흐름과 함께 사용할 수 있습니다. 공기 흐름이 원활한 NetApp 데이터 과학 툴킷을 사용하면 NetApp 데이터 관리 작업을 공기 흐름으로 조율되는 자동화된 워크플로우에 통합할 수 있습니다.</block>
  <block id="dee957e8ec77b256b931e812220f0553" category="inline-link">공기 흐름의 예</block>
  <block id="9fc322b3a5bb56d2d6ac18c15773d1c2" category="paragraph">을 참조하십시오<block ref="c50bba54faf39c027cd571674d44a9c0" category="inline-link-rx"></block> NetApp Data Science Toolkit GitHub 리포지토리 내의 섹션에서 공기 흐름이 포함된 툴킷 사용에 대한 자세한 내용을 확인하십시오.</block>
  <block id="64b0abe7a29610e134041ed793101fce" category="inline-link-macro">다음: Trident 작업의 예</block>
  <block id="f6c488122d476f1d213cf78dc2ee84d2" category="paragraph"><block ref="f6c488122d476f1d213cf78dc2ee84d2" category="inline-link-macro-rx"></block></block>
  <block id="65f63f96295566cd4278775eef1b4c8c" category="doc">덜 까다로운 워크로드 또는 대화형 워크로드에 대한 부분 GPU 할당</block>
  <block id="1b3d285072ee60a98cde2f66b6e47fde" category="paragraph">연구자와 개발자가 개발, 고매개 변수 조정 또는 디버깅 단계에서 자신의 모델을 작업할 때 이러한 워크로드는 일반적으로 컴퓨팅 리소스를 적게 사용합니다. 따라서 동일한 GPU를 다른 워크로드에 동시에 할당할 수 있도록 소수점 GPU 및 메모리를 프로비저닝하는 것이 더 효율적입니다. 실행: AI의 오케스트레이션 솔루션은 Kubernetes에서 컨테이너화된 워크로드를 위한 분할 GPU 공유 시스템을 제공합니다. 이 시스템은 CUDA 프로그램을 실행하는 워크로드를 지원하며 추론과 모델 구축과 같은 가벼운 AI 작업에 특히 적합합니다. 소수점 GPU 시스템은 데이터 과학과 AI 엔지니어링 팀에게 단일 GPU에서 동시에 여러 워크로드를 실행할 수 있는 기능을 투명하게 제공합니다. 이를 통해 기업은 컴퓨터 비전, 음성 인식 및 자연어 처리와 같은 더 많은 워크로드를 동일한 하드웨어에서 실행할 수 있으므로 비용이 절감됩니다.</block>
  <block id="5db1fcd5bb529fa2475aaf893414d2e4" category="paragraph">실행: AI의 분할 GPU 시스템은 컨테이너가 자급식 프로세서인 것처럼 사용하고 액세스할 수 있는 자체 메모리 및 컴퓨팅 공간을 사용하여 가상화된 논리 GPU를 효과적으로 생성합니다. 따라서 여러 워크로드가 서로 간섭하지 않고 동일한 GPU의 컨테이너에서 나란히 실행될 수 있습니다. 이 솔루션은 투명하고 단순하며 이식 가능하며 컨테이너 자체를 변경할 필요가 없습니다.</block>
  <block id="71cdf780e37cc9571b5fcd0bf89958b1" category="paragraph">일반적인 UseCase는 동일한 GPU에서 실행되는 작업을 2~8개 볼 수 있으며, 이는 동일한 하드웨어에서 8배 더 많은 작업을 수행할 수 있음을 의미합니다.</block>
  <block id="0a1f69603a47f75f701f92ad7d94e3c5" category="paragraph">다음 그림에서 PROJECT 팀 d에 속한 Frac05 작업에 대해 할당된 GPU 수가 0.50인 것을 알 수 있다. 이는 컨테이너에 사용 가능한 GPU 메모리가 DGX-1 노드의 V100 GPU당 32GB의 절반 인 16,255MB임을 보여 주는 'NVIDIA-SMI' 명령으로 더욱 검증되었습니다.</block>
  <block id="e6d9743072cdc6867ea2980c7db7e7fd" category="paragraph"><block ref="e6d9743072cdc6867ea2980c7db7e7fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9afb11deef37d75cf56adc6e1a2f4020" category="inline-link-macro">다음으로, 초과 할당 GPU 할당을 사용하여 높은 클러스터 사용률을 달성하십시오</block>
  <block id="15968f671ef08561726e3064358c707b" category="paragraph"><block ref="15968f671ef08561726e3064358c707b" category="inline-link-macro-rx"></block></block>
  <block id="431db7b0dc79bb29f07c20c6060c3338" category="summary">이 섹션에서는 Jupyter Notebooks와 이 솔루션에 유용한 기타 리소스를 소개합니다.</block>
  <block id="de42653a3a04e4aefa258105632011d4" category="doc">비디오 및 데모</block>
  <block id="eeb22c31d24f52a9b8225da48c32dd15" category="inline-link-macro">이전: 확인 결과.</block>
  <block id="234bbb7420397102b6a782bcaafff71a" category="paragraph"><block ref="234bbb7420397102b6a782bcaafff71a" category="inline-link-macro-rx"></block></block>
  <block id="4b8db041d93aa27fd0cc94a261e224ca" category="inline-link-macro">“지원 센터-정서-분석-파이프라인.iynb”</block>
  <block id="4e336784d7218f9fd7024470cba6b522" category="inline-link">“Support-Center-Model-Transfer-Learning-and-fine-Tuning.ipynb”</block>
  <block id="46e3dcdd2c6c30a1d9fcf40d37f0deb3" category="paragraph">감정 분석 파이프라인이 포함된 두 개의 노트북이 있습니다.<block ref="8ed620ac9482ce00db4c0f6de7250148" category="inline-link-rx"></block> 및 <block ref="ff8619e3bd3fbeea07c38337a7b773f7" category="inline-link-macro-rx"></block>. 이 노트북은 함께 지원 센터 데이터를 수집하고 사용자 데이터에 맞게 조정된 최첨단 딥 러닝 모델을 사용하여 각 문장에서 감정을 추출하는 파이프라인을 개발하는 방법을 보여줍니다.</block>
  <block id="fa8c0b2056c13341c1455ad44cc91889" category="section-title">지원 센터 - 정서 분석 파이프라인. ipynb</block>
  <block id="6b3450c2b921c398bbf90a1aee0b016c" category="paragraph">이 노트북에는 오디오 인제스트, 텍스트로 변환, 외부 대시보드에서 사용할 정서 추출용 추론 Riva 파이프라인이 포함되어 있습니다. 아직 완료되지 않은 경우 데이터 세트가 자동으로 다운로드되고 처리됩니다. 전자 필기장의 첫 번째 섹션은 오디오 파일을 텍스트로 변환하는 작업을 처리하는 텍스트 음성 변환 섹션입니다. 그 다음에는 각 텍스트 문장에 대한 감정을 추출하고 제안된 대시보드와 유사한 형식으로 결과를 표시하는 감정 분석 섹션이 이어집니다.</block>
  <block id="63abda3d2c420172da9a3a20c7f64dda" category="admonition">이 노트북은 모델 훈련 및 미세 조정 전에 실행해야 합니다. MP3 데이터 세트를 다운로드하여 올바른 형식으로 변환해야 하기 때문입니다.</block>
  <block id="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="paragraph"><block ref="33e7b29c6dc1bb2252ba04ad52f5b1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="295c2feb943bbe2efca238849828084e" category="section-title">Support Center - 모델 교육 및 미세 조정. ipynb</block>
  <block id="6efbeb8cfc7e387edbf91bad41170349" category="paragraph">TAO 툴킷 가상 환경은 노트북을 실행하기 전에 설정해야 합니다(설치 지침은 명령 개요 의 TAO 툴킷 섹션 참조).</block>
  <block id="a9d805c9ddfdf62e60632a9754e29404" category="paragraph">이 노트북은 TAO 툴킷을 사용하여 고객 데이터에 대한 딥 러닝 모델을 미세 조정합니다. 이전 전자 필기장과 마찬가지로 이 섹션은 텍스트 음성 대 텍스트 및 감정 분석 구성 요소에 대한 두 섹션으로 구분됩니다. 각 섹션은 데이터 처리, 모델 교육 및 세부 조정, 결과 평가 및 모델 내보내기를 거치게 됩니다. 마지막으로, Riva에서 사용할 미세 조정된 모델을 모두 배포하기 위한 마지막 섹션이 있습니다.</block>
  <block id="b40454c57dd60f999f3243514cd90ede" category="paragraph"><block ref="b40454c57dd60f999f3243514cd90ede" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b774a4819b60036fd16dae7b1618fe7" category="inline-link-macro">다음: 결론.</block>
  <block id="f89bf51287609a0c0cf7563b31265c06" category="paragraph"><block ref="f89bf51287609a0c0cf7563b31265c06" category="inline-link-macro-rx"></block></block>
  <block id="84ffd62e595c9d0122e136c3b255f4df" category="doc">감사의 말</block>
  <block id="74f47434914d29c7ec7d7d42593303b7" category="list-text">NetApp 기술 마케팅 엔지니어 Mike Olesby</block>
  <block id="94a8512f59eafd68b470105fc3269fd4" category="list-text">NetApp 선임 기술 담당 이사 Santosh Rao</block>
  <block id="17e1dd6389643aeecf567ba08bf1df2c" category="paragraph"><block ref="17e1dd6389643aeecf567ba08bf1df2c" category="inline-link-macro-rx"></block></block>
  <block id="74c071ff3c1d6d6fc39b72d617aefdf8" category="doc">솔루션 배포 및 검증 세부 정보</block>
  <block id="b122830b8b8edd9e76690ea23b0c4cbd" category="paragraph">다음 섹션에서는 솔루션 구축 및 검증에 대한 세부 정보를 다룹니다.</block>
  <block id="ebe48d794d8ada5d4e067cd5993bdd3e" category="inline-link-macro">다음: ONTAP AI 배포</block>
  <block id="3b103491115e62f2388d69086a2eff9d" category="paragraph"><block ref="3b103491115e62f2388d69086a2eff9d" category="inline-link-macro-rx"></block></block>
  <block id="8b6327b93d10679b1f412976af9d3bba" category="summary">Docker, Kubernetes 등의 오케스트레이션 툴과 통합된 Azure NetApp Files, RAPIDS, DASK를 사용하면 대규모 ML 처리 및 훈련 구축을 더 빠르게 처리하고 간소화할 수 있습니다. 이 솔루션은 엔드 투 엔드 데이터 파이프라인을 통합함으로써 수많은 고급 컴퓨팅 워크로드에서 발생하는 지연 시간과 복잡성을 줄여 개발과 운영 간의 격차를 효과적으로 해소합니다.</block>
  <block id="53ffd6a9e0049c8cbf7f940c2b8bc793" category="inline-link-macro">이전: NetApp DataOps 툴킷을 사용하여 데이터 세트 및 모델 버전 관리</block>
  <block id="01643859d7e5dff013d2acd6a02af35e" category="paragraph"><block ref="01643859d7e5dff013d2acd6a02af35e" category="inline-link-macro-rx"></block></block>
  <block id="7527b11aa1f9aa169a9d6103e9c4c417" category="paragraph">Azure NetApp Files, RAPIDS 및 DASK는 Docker, Kubernetes 등의 오케스트레이션 툴과 통합하여 대규모 ML 처리 및 훈련 구축을 간소화하고 있습니다. 이 솔루션은 엔드 투 엔드 데이터 파이프라인을 통합함으로써 수많은 고급 컴퓨팅 워크로드에서 발생하는 지연 시간과 복잡성을 줄여 개발과 운영 간의 격차를 효과적으로 해소합니다. 데이터 과학자는 대규모 데이터 세트에서 쿼리를 실행하고 교육 단계 동안 다른 사용자와 데이터 및 알고리즘 모델을 안전하게 공유할 수 있습니다.</block>
  <block id="bd9091c7320e4b1069eed28f04839354" category="paragraph">자체 AI/ML 파이프라인을 구축할 때는 아키텍처 구성 요소의 통합, 관리, 보안 및 접근성을 구성하는 것이 매우 어렵습니다. 개발자가 자신의 환경에 액세스하고 제어하도록 하는 것은 또 다른 도전 과제입니다.</block>
  <block id="a93fc9ba708498e20819f22e22ecfa5c" category="paragraph">클라우드에 엔드 투 엔드 분산 교육 모델 및 데이터 파이프라인을 구축하여 총 워크플로우 완료 시간을 GPU 가속 데이터 처리 및 컴퓨팅 프레임워크를 활용하지 않는 기존의 오픈 소스 접근 방식에 비해 크게 두 배나 단축한 것으로 입증되었습니다.</block>
  <block id="fcceee9f9e65e4b0d089c6c433f6c191" category="paragraph">NetApp, Microsoft, 오픈 소스 오케스트레이션 프레임워크 및 NVIDIA가 결합되어 최신 기술을 유연한 관리 서비스로 통합하여 기술 채택을 가속화하고 새로운 AI/ML 애플리케이션의 출시 시기를 앞당길 수 있습니다. 이러한 고급 서비스는 사내 및 하이브리드 구축 아키텍처용으로 쉽게 포팅할 수 있는 클라우드 네이티브 환경에서 제공됩니다.</block>
  <block id="40a15e6807b47955e7b7a9b1bd330b01" category="inline-link-macro">다음: 추가 정보를 찾을 위치.</block>
  <block id="eee817389517c17ec810d52f22a8222d" category="paragraph"><block ref="eee817389517c17ec810d52f22a8222d" category="inline-link-macro-rx"></block></block>
  <block id="7a879e305f90568b91e8623ce5f9ee39" category="summary">2019년 5월부터 Microsoft는 NetApp ONTAP 기술을 기반으로 엔터프라이즈 NFS 및 SMB 파일 서비스를 위한 Azure 네이티브 자사 포털 서비스를 제공합니다.</block>
  <block id="0bf51d984b6a6d3fddc0e24f62eb1a14" category="doc">TR-4896: Azure에서 분산된 교육: 차선 감지 - 솔루션 설계</block>
  <block id="0ab5aa2896d8eed7732e69be5e5782b4" category="paragraph">Muneer Ahmad and Verron Martina, NetApp Ronden Dar, run:AI</block>
  <block id="a89ade32996e322edf837476febbc9bd" category="paragraph">2019년 5월부터 Microsoft는 NetApp ONTAP 기술을 기반으로 엔터프라이즈 NFS 및 SMB 파일 서비스를 위한 Azure 네이티브 자사 포털 서비스를 제공합니다. 이러한 개발을 위해 Microsoft와 NetApp의 전략적 파트너십을 활용하고 세계적인 수준의 ONTAP 데이터 서비스를 Azure로 확장합니다.</block>
  <block id="d6312cb01ee08559dbaa35c308e72268" category="paragraph">업계 최고의 클라우드 데이터 서비스 공급자인 NetApp이 Run:AI와 팀을 이루어 AI 인프라를 가상화하여 AI의 전체 GPU 활용률을 더욱 빠르게 실험할 수 있도록 했습니다. 이 파트너십을 통해 팀에서는 데이터를 빠르게 활용하고 컴퓨팅 리소스를 무제한으로 활용하여 여러 실험을 병렬로 실행하여 AI 속도를 높일 수 있습니다. 실행: AI는 리소스 할당을 자동화하여 전체 GPU 활용률을 지원하며, 검증된 Azure NetApp Files 아키텍처를 통해 데이터 파이프라인의 장애물을 제거하여 모든 실험을 최대 속도로 실행할 수 있습니다.</block>
  <block id="5234f8ee670afed8c398940a707f25df" category="paragraph">NetApp과 RUN TO NETAPP: AI는 고객에게 Azure에서의 AI 전환을 위한 미래 지향형 플랫폼을 제공하기 위해 힘을 합했습니다. 분석 및 고성능 컴퓨팅(HPC)에서 자율적 결정(고객이 필요한 시점에 필요한 비용만 지불하여 IT 투자를 최적화할 수 있음)에 이르기까지, NetApp과 실행 시 AI는 Azure Cloud에서 통합된 단일 경험을 제공합니다.</block>
  <block id="67d45a00257105f21f4427f31e0c9fa1" category="summary">이 기술 보고서에서는 이전 학습 및 대화형 AI를 사용하는 NVIDIA 소프트웨어 프레임워크와 NetApp 데이터 관리 기술을 함께 사용하여 엔터프라이즈 수준의 글로벌 지원 센터에서 NetApp 데이터 관리 기술을 수행하는 고객에 대한 감정 분석을 수행할 수 있는 설계 지침을 제공합니다.</block>
  <block id="494027a6b5e9fc8bb84443d03b97a9b7" category="doc">TR-4910: NetApp AI를 통한 고객 커뮤니케이션의 감정 분석</block>
  <block id="22268d4ee4f32cda2f20141957aac961" category="paragraph">Rick Huang, Sathish Thyagarajan, David Arnette, NetApp Diego Sosa-Coba, SFL Scientific</block>
  <block id="0c450c48691e7a55b657f2cb7d18a0dd" category="paragraph">이 기술 보고서에서는 이전 학습 및 대화형 AI를 사용하는 NVIDIA 소프트웨어 프레임워크와 NetApp 데이터 관리 기술을 함께 사용하여 엔터프라이즈 수준의 글로벌 지원 센터에서 NetApp 데이터 관리 기술을 수행하는 고객에 대한 감정 분석을 수행할 수 있는 설계 지침을 제공합니다. 이 솔루션은 채팅 로그, 이메일 및 기타 텍스트 또는 오디오 통신을 나타내는 녹음된 음성 또는 텍스트 파일을 통해 고객 통찰력을 얻고자 하는 모든 산업에 적용됩니다. NetApp은 NetApp 클라우드 연결 All-Flash 스토리지를 통해 GPU 가속 컴퓨팅 클러스터에서 자동 음성 인식, 실시간 감정 분석, 딥 러닝 자연어 처리 모델 재교육 기능을 시연하기 위해 엔드 투 엔드 파이프라인을 구축했습니다. 방대한 최신 언어 모델을 훈련 및 최적화하여 글로벌 지원 센터와 신속하게 추론을 수행하여 탁월한 고객 경험과 객관적이고 장기적인 직원 성과 평가를 생성할 수 있습니다.</block>
  <block id="549c85ede9b39be6ef0eec80db7e098c" category="paragraph">정서 분석은 자연어 처리(NLP) 내 연구 분야로서 텍스트에서 긍정적, 부정적 또는 중립적 감정을 도출합니다. 점점 더 많은 사람들이 대화하는 AI 시스템은 거의 세계적인 수준의 통합으로 부상했습니다. 감정 분석은 지원 센터 직원의 통화 성과를 확인하고 적절한 자동 챗봇 응답을 제공하는 등 다양한 활용 사례를 통해 분기별 수익 통화 시 기업 담당자와 대상 간의 상호 작용을 기반으로 회사의 주식 가격을 예측해 볼 수 있습니다. 또한, 감정 분석을 사용하여 브랜드가 제공하는 제품, 서비스 또는 지원에 대한 고객의 관점을 결정할 수 있습니다.</block>
  <block id="5855677156d63ad3c93a7b5382098060" category="paragraph">이 엔드 투 엔드 솔루션은 NLP 모델을 사용하여 지원 센터 분석 프레임워크를 지원하는 고수준 정서 분석을 수행합니다. 오디오 녹음은 서면 텍스트로 처리되며 대화의 각 문장에서 감정은 추출됩니다. 대시보드로 집계된 결과는 역사적, 실시간으로 대화 감정을 분석하기 위해 만들 수 있습니다. 이 솔루션은 유사한 데이터 양식 및 출력 요구가 있는 다른 솔루션으로 일반화할 수 있습니다. 적절한 데이터를 사용하여 다른 사용 사례를 수행할 수 있습니다. 예를 들어 동일한 종단간 파이프라인을 사용하여 기업 수익 통화를 분석하여 감정을 분석할 수 있습니다. 또한 파이프라인의 유연한 특성 때문에 주제 모델링 및 NER(명명된 엔티티 인식)과 같은 다른 형태의 NLP 분석이 가능합니다.</block>
  <block id="ea4f750fd9fd89aeff4ca8d4162fb673" category="paragraph">이러한 AI 구현은 NVIDIA Riva, NVIDIA TAO 툴킷 및 NetApp DataOps 툴킷을 함께 사용하여 가능했습니다. NVIDIA의 툴은 사전 구축된 모델 및 파이프라인을 사용하여 고성능 AI 솔루션을 신속하게 배포하는 데 사용됩니다. NetApp DataOps 툴킷은 다양한 데이터 관리 작업을 단순화하여 개발 속도를 높여줍니다.</block>
  <block id="7a7e97f7fcf4e2974d9a6feee2b056f8" category="section-title">고객 가치</block>
  <block id="3815ef30c3d6c6bdc3862cc9530d091e" category="paragraph">기업은 감성 분석을 위해 텍스트, 오디오 및 비디오 대화를 위한 직원 평가 및 고객 반응 도구를 통해 가치를 확인합니다. 관리자는 대시보드에 표시되는 정보를 활용하여 대화 양쪽을 기준으로 직원 및 고객 만족도를 평가할 수 있습니다.</block>
  <block id="da210ea22d819ca26070a3795f9a14d4" category="paragraph">또한 NetApp DataOps 툴킷은 고객 인프라 내에서 데이터의 버전 관리 및 할당을 관리합니다. 따라서 복잡하지 않은 데이터 스토리지 비용을 발생시키지 않고 대시보드 내에 제공되는 분석 내용이 자주 업데이트됩니다.</block>
  <block id="e5fcadecc4515efec9267b8ad57b28a5" category="inline-link-macro">다음으로, 사용 사례를 살펴보겠습니다.</block>
  <block id="93b7bce28e36a4eebec23c8fd4be315d" category="paragraph"><block ref="93b7bce28e36a4eebec23c8fd4be315d" category="inline-link-macro-rx"></block></block>
  <block id="c4e7b8572218b2c9421122c7ab76be25" category="paragraph">NetApp과 cnvrg.io는 파트너십을 통해 고객에게 ML 및 DL 소프트웨어 개발을 위한 완벽한 데이터 관리 솔루션을 제공합니다. ONTAP AI는 모든 규모의 운영에 고성능 컴퓨팅 및 스토리지를 제공하며 cnvrg.io 소프트웨어는 데이터 과학 워크플로우를 간소화하고 리소스 활용률을 향상합니다.</block>
  <block id="c6a4d485e7c4cefa4c121ce6c59b28dc" category="inline-link-macro">다음은 감사의 말</block>
  <block id="0c8a89e4d7937b03d3adc0f1d6530b08" category="paragraph"><block ref="0c8a89e4d7937b03d3adc0f1d6530b08" category="inline-link-macro-rx"></block></block>
  <block id="354967c7509f48d7d8a6d2845803bfbc" category="summary">다른 사용 사례에 맞게 검증에 사용된 설정을 조정할 수 있습니다.</block>
  <block id="c4236be1a211aab0c15476d08b3e7e0c" category="doc">아키텍처 사이징 옵션</block>
  <block id="ac0ec60d36dfa69ed9c33bff90080b23" category="inline-link-macro">이전: 테스트 결과.</block>
  <block id="389a3124af7d4b9dc7165b05fd96a378" category="paragraph"><block ref="389a3124af7d4b9dc7165b05fd96a378" category="inline-link-macro-rx"></block></block>
  <block id="9d8c4ebebb4b789e6ec48dda7ac54406" category="section-title">컴퓨팅 서버</block>
  <block id="1b3bfec82c01730e4379631c5f74db2d" category="paragraph">우리는 SE350에서 지원되는 최저 수준의 CPU인 Intel Xeon D-2123IT CPU를 4개의 물리적 코어와 60W TDP로 사용했습니다. 서버는 CPU 교체를 지원하지 않지만 보다 강력한 CPU로 주문할 수 있습니다. 지원되는 최상위 CPU는 16개의 코어가 있는 Intel Xeon D-2183IT, 2.20GHz에서 실행되는 100W입니다. 이렇게 하면 CPU 계산 기능이 크게 향상됩니다. CPU는 추론 워크로드 자체를 실행하는 데 병목 지점이 되지 않지만, 데이터 처리와 추론과 관련된 다른 작업에 도움이 됩니다. 현재 NVIDIA T4는 에지 사용 사례에 사용할 수 있는 유일한 GPU이므로, 현재는 GPU를 업그레이드하거나 다운그레이드할 수 없습니다.</block>
  <block id="928fe421f0c735b90f3b3ec353741235" category="section-title">공유 스토리지</block>
  <block id="ba49c21e7aa335a8ea452042c02f306a" category="paragraph">테스트 및 검증을 위해 최대 스토리지 용량이 50.5TB, 순차적 읽기의 경우 처리량 4.4GBps, 소규모 랜덤 읽기의 경우 230K IOPS를 지원하는 NetApp AFF C190 시스템이 이 문서의 목적에 사용되었으며 에지 추론 워크로드에 적합한 것으로 입증되었습니다.</block>
  <block id="bb33c803e43b816786d862bbbbf2c824" category="paragraph">그러나 스토리지 용량 또는 더 빠른 네트워킹 속도가 필요한 경우 NetApp AFF A220 또는 을 사용해야 합니다<block ref="03f94a30ec5c979321fdd9a1ba99a1c6" category="inline-link-rx"></block> 기술을 자세히 소개합니다. 또한 최대 1.5PB의 용량을 가진 NetApp EF280 시스템도 이 솔루션 검증을 위해 10Gbps 대역폭 사용이 사용되었습니다. 더 높은 대역폭으로 더 많은 스토리지 용량을 원하는 경우,<block ref="ab4f2e0c1e56faa457a7a1f93253a647" category="inline-link-rx"></block> 사용할 수 있습니다.</block>
  <block id="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="paragraph"><block ref="fdd5191dcc2e7fa6e2ec4d0618cf2a40" category="inline-link-macro-rx"></block></block>
  <block id="19075a93ccd90f3ea7019f0572778b2a" category="summary">이 페이지에는 이 솔루션에 필요한 소프트웨어 요구 사항이 나열되어 있습니다.</block>
  <block id="b0167c15bc26c48af07aea36aba706fa" category="inline-link-macro">이전: 기술 개요</block>
  <block id="440b940924209e1d417ef7c4ef9bce34" category="paragraph"><block ref="440b940924209e1d417ef7c4ef9bce34" category="inline-link-macro-rx"></block></block>
  <block id="793d18702a236e0e3b768917638f0ba2" category="paragraph">다음 표에는 이 솔루션에 필요한 소프트웨어 요구 사항이 나열되어 있습니다.</block>
  <block id="34b6cd75171affba6957e308dcbd92be" category="cell">버전</block>
  <block id="8ab697a4168b5fb33603a98d6bc9a436" category="cell">RAPIDS 및 Dask 컨테이너 이미지입니다</block>
  <block id="9ab6289633c326d69a377cbb29bd81a3" category="cell">리포지토리: "rapidsai/rapidsai" 태그: 0.17-ca11.0-runtime-uubuntu18.04</block>
  <block id="6e1b77cc3b83d87aaee751e2eaed5044" category="inline-link-macro">다음으로, 클라우드 리소스 요구사항을 살펴보겠습니다.</block>
  <block id="58bc7690a5a3a5a1aa5dc70739fd0b53" category="paragraph"><block ref="58bc7690a5a3a5a1aa5dc70739fd0b53" category="inline-link-macro-rx"></block></block>
  <block id="cb2418c01859c7704da751aa5a7d2421" category="doc">솔루션 개요</block>
  <block id="fbe29309a183681bc26203d4c65853a2" category="paragraph">이 섹션에서는 기존의 데이터 과학 파이프라인과 그 단점을 검토합니다. 또한, 제안된 데이터 세트 캐싱 솔루션의 아키텍처도 제공합니다.</block>
  <block id="1f14aecc1193f646e0005e27fbc6e63d" category="section-title">기존의 데이터 과학 파이프라인 및 결점</block>
  <block id="17fb7d0ba5495199d3e18fe23dff7b59" category="paragraph">ML 모델 개발 및 배포의 일반적인 시퀀스에는 다음을 포함하는 반복 단계가 포함됩니다.</block>
  <block id="63e1ded7e3ae73253b5c287bc9bdef02" category="list-text">데이터 수집 중</block>
  <block id="52e028dc7ac82e9d4b7b1ae588fecc9a" category="list-text">데이터 사전 처리(여러 버전의 데이터 세트 생성)</block>
  <block id="33cd0fcdd9ee7e650043133b12516155" category="list-text">하이퍼파라미터 최적화, 다른 모델 등과 관련된 여러 실험 실행</block>
  <block id="ea355214fd4bc7c57f471bd92918879b" category="list-text">구축</block>
  <block id="b85c416c94e0c5314a1e6fcc21d4139e" category="list-text">Monitoringcnvrg.io는 연구부터 배포에 이르는 모든 작업을 자동화하는 포괄적인 플랫폼을 개발했습니다. 다음 그림에서는 파이프라인과 관련된 대시보드 스크린샷의 작은 샘플을 보여 줍니다.</block>
  <block id="5a5ade85e7f7478bcba59e8c3891c914" category="paragraph"><block ref="5a5ade85e7f7478bcba59e8c3891c914" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26d6a4638ffd0b7779f1353f5fe54f0d" category="paragraph">퍼블릭 저장소 및 프라이빗 데이터에서 여러 데이터 세트를 재생하는 것이 일반적입니다. 또한 각 데이터 세트에는 데이터 세트 정리 또는 기능 엔지니어링으로 인해 여러 버전이 있을 수 있습니다. 다음 그림과 같이 팀에서 공동 작업 및 일관성 도구를 사용할 수 있도록 데이터 세트 허브와 버전 허브를 제공하는 대시보드가 필요합니다.</block>
  <block id="e884d73b6a4214bea010ec3bbfdad8b6" category="paragraph"><block ref="e884d73b6a4214bea010ec3bbfdad8b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93661dde7027bf31b3d007740a3d4648" category="paragraph">파이프라인의 다음 단계에서는 각각 데이터 세트 및 특정 컴퓨팅 인스턴스와 관련된 교육 모델의 여러 병렬 인스턴스가 필요합니다. 특정 컴퓨팅 인스턴스를 사용하여 특정 실험으로 데이터 세트를 바인딩하는 것은 쉽지 않습니다. AWS(Amazon Web Services)의 GPU 인스턴스에서 일부 실험을 수행하는 동시에, DGX-1 또는 DGX-2 온프레미스 인스턴스에서 다른 실험을 수행할 수 있기 때문입니다. GCP의 CPU 서버에서 다른 실험을 실행할 수도 있지만 데이터 세트 위치가 교육을 수행하는 컴퓨팅 리소스 가까이에 있지 않습니다. 데이터 세트 스토리지에서 컴퓨팅 인스턴스까지 지연 시간이 짧은 10GbE 또는 더 많은 연결이 끊어지려면 어느 정도의 근접성이 있어야 합니다.</block>
  <block id="ba4f5ee1b0d01d3416723cfc3ec296ec" category="paragraph">데이터 과학자는 훈련을 수행하고 실험을 실행하는 컴퓨팅 인스턴스에 데이터 세트를 다운로드하는 것이 일반적입니다. 그러나 이 접근 방식에는 몇 가지 잠재적 문제가 있습니다.</block>
  <block id="90b6a1c5b483f6c6b399bc17c5e1af9a" category="list-text">데이터 과학자가 데이터 세트를 컴퓨팅 인스턴스로 다운로드할 때 통합 컴퓨팅 스토리지가 고성능을 보장하는 것은 아닙니다(고성능 시스템의 예로는 ONTAP AFF A800 NVMe 솔루션이 있음).</block>
  <block id="5713a88504bb65e3808faac627a6a0fc" category="list-text">다운로드한 데이터 세트가 하나의 컴퓨팅 노드에 상주하면 NetApp ONTAP 고성능 분산 스토리지와 달리 여러 노드에서 분산 모델을 실행하면 스토리지 병목 현상이 발생할 수 있습니다.</block>
  <block id="299b9ae5439d32ed932f51f3b3aa92d6" category="list-text">대기열 충돌 또는 우선순위 때문에 훈련 실험의 다음 반복을 다른 컴퓨팅 인스턴스에서 수행할 수 있으며, 데이터 세트에서 컴퓨팅 위치까지의 거리가 크게 멀어지거나</block>
  <block id="30e37003024e85518a26760a7ab58f4e" category="list-text">동일한 컴퓨팅 클러스터에서 교육 실험을 실행하는 다른 팀 구성원은 이 데이터 세트를 공유할 수 없으며, 각 팀원이 임의의 위치에서 데이터 세트의 (값비싼) 다운로드를 수행합니다.</block>
  <block id="9e5d53150336efb0446a063309805f01" category="list-text">후속 훈련 작업에 동일한 데이터 세트의 다른 데이터 세트 또는 버전이 필요한 경우 데이터 과학자는 training.NetApp 및 cnvrg.io를 수행하는 컴퓨팅 인스턴스에 데이터 세트의 (값비싼) 다운로드를 다시 수행해야 합니다. 그 결과, 이러한 장애 요소를 제거하는 새로운 데이터 세트 캐싱 솔루션이 만들어졌습니다. 이 솔루션은 ONTAP 고성능 스토리지 시스템에서 핫 데이터 세트를 캐싱하여 ML 파이프라인의 실행을 가속합니다. ONTAP NFS를 사용하면 NetApp에서 제공하는 Data Fabric(예: AFF A800)에서 데이터 세트를 한 번만 캐싱할 수 있으며, 이 데이터는 컴퓨팅과 함께 배치됩니다. NetApp ONTAP NFS 고속 스토리지가 여러 ML 컴퓨팅 노드를 지원할 수 있으므로 교육 모델의 성능이 최적화되어 비용 절감, 생산성 및 운영 효율성이 조직에 제공됩니다.</block>
  <block id="9f6302143996033ebb94d536b860acc3" category="section-title">솔루션 아키텍처</block>
  <block id="a63af1f206939a3c956a2e8b6ab53103" category="paragraph">다음 그림과 같이 NetApp 및 cnvrg.io의 이 솔루션은 데이터 세트 캐싱을 제공합니다. 데이터 세트 캐싱을 사용하면 데이터 과학자가 원하는 데이터 세트 또는 데이터 세트 버전을 선택하여 ML 컴퓨팅 클러스터 근처에 있는 ONTAP NFS 캐시로 이동할 수 있습니다. 이제 데이터 과학자는 지연 또는 다운로드를 유발하지 않고 여러 실험을 실행할 수 있습니다. 또한 모든 공동 작업 엔지니어는 데이터 레이크에서 추가로 다운로드할 필요 없이 연결된 컴퓨팅 클러스터(노드를 선택할 수 있는 자유로이)에서 동일한 데이터 세트를 사용할 수 있습니다. 데이터 과학자는 모든 데이터 세트 및 버전을 추적 및 모니터링하고 캐시된 데이터 세트를 확인하는 대시보드를 제공합니다.</block>
  <block id="612eaee91b23ecc385c1b402d44c081f" category="paragraph">cnvrg.io 플랫폼은 특정 시간 동안 사용되지 않은 오래된 데이터 세트를 자동으로 감지하여 캐시에서 데이터를 제거하므로 자주 사용하는 데이터 세트에 대해 사용 가능한 NFS 캐시 공간을 유지합니다. ONTAP의 데이터 세트 캐싱은 클라우드와 사내에서 이루어지므로 최대한의 유연성을 제공하는 것이 중요합니다.</block>
  <block id="0cb5e14601fcf39745352a9556939aa3" category="paragraph"><block ref="0cb5e14601fcf39745352a9556939aa3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="810aceabf729ffa8c2dfd61a3aaeafaa" category="inline-link-macro">다음: 개념 및 구성 요소</block>
  <block id="0a01ff9defa9120e928e7e306e3e3234" category="paragraph"><block ref="0a01ff9defa9120e928e7e306e3e3234" category="inline-link-macro-rx"></block></block>
  <block id="dcfa517bb68d187d11e580baf2ecf588" category="summary">이 페이지에서는 제어(Helm)를 사용하여 AKS에서 RAPIDS를 사용하여 Dask를 설정하는 방법에 대해 설명합니다.</block>
  <block id="fd22fb1626b987fa7b72743fa9698ec6" category="doc">Helm을 사용하여 AKS에서 RAPIDS를 사용하여 Dask를 설정합니다</block>
  <block id="d74bb88aa6e4b1c540be703fda33923e" category="inline-link-macro">이전: Trident를 설치합니다.</block>
  <block id="6020c64d2124fc0caa426123bfc5ba38" category="paragraph"><block ref="6020c64d2124fc0caa426123bfc5ba38" category="inline-link-macro-rx"></block></block>
  <block id="d81f517b6ad0d9702be81a8199a2246f" category="paragraph">Hrom을 사용하여 AKS에서 RAPIDS를 사용하여 Dask를 설정하려면 다음 단계를 수행하십시오.</block>
  <block id="549c839f491ec7099a895dd1cfea7534" category="list-text">RAPIDS를 사용하여 Dask를 설치하기 위한 네임스페이스를 생성합니다.</block>
  <block id="74d041e68ac2a21a636ab14ae78f279d" category="list-text">PVC를 생성하여 클릭률 데이터 세트를 저장합니다.</block>
  <block id="f5008aa6b27cdcaadbe27960383c8ff6" category="list-text">다음 YAML 콘텐츠를 파일에 저장하여 PVC를 생성합니다.</block>
  <block id="67d464c36bcc48173c964a780459dbfd" category="list-text">Kubernetes 클러스터에 YAML 파일을 적용하십시오.</block>
  <block id="be0ca76aafd92c18792693b8f05d01ce" category="inline-link"><block ref="be0ca76aafd92c18792693b8f05d01ce" category="inline-link-rx"></block></block>
  <block id="dc7ba914646428512334728c1f0ebd7d" category="list-text">"rapidsai git" 리포지토리 복제(<block ref="4f08c7c28c19e75f4d8607fc65d40067" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="50aef45ee39d958bc589f422bfb6d1bf" category="list-text">"Values.YAML"을 수정하고, 작업자와 Jupyter 작업공간을 위해 앞서 만든 PVC를 포함합니다.</block>
  <block id="06867e85b141bb9d17f8ed6b4b685c46" category="list-text">리포지토리의 "rapidsai" 디렉토리로 이동합니다.</block>
  <block id="1a985ac965074fab9cfcee28ef954755" category="list-text">Values.YAML 파일을 업데이트하고 PVC를 사용해 볼륨을 마운트합니다.</block>
  <block id="52076eb1fec3929530258335052328b3" category="list-text">리포지토리의 홈 디렉토리로 이동하여 H제어 를 사용하여 AKS에 작업자 노드 3개가 있는 Dask를 배포합니다.</block>
  <block id="bd4e74749939dd3c9f80ff138c18af53" category="inline-link-macro">다음: Azure NetApp Files 성능 계층</block>
  <block id="52d5e0adb69809963ce4f94104a75b5e" category="paragraph"><block ref="52d5e0adb69809963ce4f94104a75b5e" category="inline-link-macro-rx"></block></block>
  <block id="e40030fd64108859627c7a126638f0e6" category="list-text">NetApp AI 컨트롤 플레인:</block>
  <block id="63178726ae501745b3914ec3aa50969e" category="list-text">NetApp AI Control Plane 기술 보고서</block>
  <block id="3ce56c027572d1908d65b63056be024f" category="inline-link"><block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="445a4d3400bdde832e8898d8349696c0" category="paragraph"><block ref="445a4d3400bdde832e8898d8349696c0" category="inline-link-rx"></block></block>
  <block id="e582bd0f584c041fb70164ea1502666b" category="paragraph"><block ref="e582bd0f584c041fb70164ea1502666b" category="inline-link-rx"></block></block>
  <block id="9a8ec45d909b996af4c042e44b5c5f29" category="list-text">TensorFlow: 모두를 위한 오픈 소스 머신 러닝 프레임워크<block ref="db3465122fd83ad1dc4cff7e67d794df" category="inline-link-rx"></block></block>
  <block id="60ea9e9ecbf839c413c5e977002eabf4" category="paragraph"><block ref="60ea9e9ecbf839c413c5e977002eabf4" category="inline-link-rx"></block></block>
  <block id="6bd14be39aedfe96ceacec2caaac0532" category="paragraph"><block ref="6bd14be39aedfe96ceacec2caaac0532" category="inline-link-rx"></block></block>
  <block id="6771540ad76dbed724cb9025978b8510" category="paragraph"><block ref="6771540ad76dbed724cb9025978b8510" category="inline-link-rx"></block></block>
  <block id="ef9e62eeb81c0987fbe61de48635886a" category="paragraph"><block ref="ef9e62eeb81c0987fbe61de48635886a" category="inline-link-rx"></block></block>
  <block id="3bc4d41311862190a8fd0d6c8f661971" category="list-text">Iguazio 데이터 과학 플랫폼</block>
  <block id="737d4d1e81ff236001338f46d1623aaa" category="list-text">Iguazio 데이터 과학 플랫폼 문서</block>
  <block id="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link"><block ref="7911479a3e8e121b0dc1c551f56fa6ca" category="inline-link-rx"></block></block>
  <block id="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="paragraph"><block ref="bcdc0ac9ae93bcfb8ae21a0a8713528e" category="inline-link-rx"></block></block>
  <block id="4f0f362becf6baf6e08f490115d76d98" category="list-text">Nuclio 서버리스 기능</block>
  <block id="89aa84cdf5db1bece2993801c78914de" category="inline-link"><block ref="89aa84cdf5db1bece2993801c78914de" category="inline-link-rx"></block></block>
  <block id="93eac034cc1c1aaedaf6ed41063825ee" category="paragraph"><block ref="93eac034cc1c1aaedaf6ed41063825ee" category="inline-link-rx"></block></block>
  <block id="b5266d58998338015b5e02ee7e84a833" category="list-text">MLRun OpenSource 파이프라인 오케스트레이션 프레임워크</block>
  <block id="b96a861dccea968edc0b7a9ff96203e9" category="inline-link"><block ref="b96a861dccea968edc0b7a9ff96203e9" category="inline-link-rx"></block></block>
  <block id="70a8a001358e056f435199da7e17e427" category="paragraph"><block ref="70a8a001358e056f435199da7e17e427" category="inline-link-rx"></block></block>
  <block id="b3f90aaddad391963c2090db8f1b727e" category="list-text">NVIDIA DGX-1 시스템</block>
  <block id="af828c56c03364ebbde4c582adeb8de3" category="paragraph"><block ref="af828c56c03364ebbde4c582adeb8de3" category="inline-link-rx"></block></block>
  <block id="d6a377b23d0f4dbe3f5bf91d5f6abf74" category="list-text">NVIDIA Tesla V100 Tensor 코어 GPU</block>
  <block id="a724832176ce84a9d4be5c34e44891d3" category="paragraph"><block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="0df7621d860637a2e6e462c56322edab" category="list-text">NVIDIA GPU 클라우드</block>
  <block id="839d9b8469a8d9554891a7515a2b9be7" category="paragraph"><block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="9a84c14d2692222552174943486e7136" category="inline-link"><block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="0d9d8991a05834f0e52a99b37ce360b8" category="paragraph"><block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="5f662f6dc276dd5a2a83440d0fe63e9b" category="list-text">AFF용 NetApp 플래시의 이점</block>
  <block id="72cf25e9f1e13167cd0dde6f285552ea" category="paragraph"><block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link"><block ref="a5bc7bee9fd33d829e41934aedd6404c" category="inline-link-rx"></block></block>
  <block id="a5d59e86f09bafae4247836d5135b6a3" category="paragraph"><block ref="a5d59e86f09bafae4247836d5135b6a3" category="inline-link-rx"></block></block>
  <block id="7a26d62dac2be507dcc3e5b9da0ed765" category="paragraph"><block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="47c991332229e0cbfe947beaa428ea61" category="list-text">DGX-1 및 Cisco 네트워킹 기반 ONTAP AI 설계 가이드</block>
  <block id="b141781260425e95eee945147e2f0d99" category="inline-link"><block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="9fbee18519e76388280bc1f8e3fd6c7e" category="paragraph"><block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="0be3b0697a0ffdfe9065df24ec1d3e16" category="list-text">DGX-1 및 Cisco 네트워킹 지원 ONTAP AI 배포 가이드</block>
  <block id="921f17c41dea89b0a711f380e9864e09" category="inline-link"><block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="aef3d0752148699921f8a251537d5ff3" category="paragraph"><block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="205a4f16a51f3acd6dbba76dbeb10818" category="list-text">DGX-1 및 Mellanox 네트워킹 설계 가이드를 지원하는 ONTAP AI</block>
  <block id="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link"><block ref="07dc94af34e2f98bbc8328d8ef9ea1e0" category="inline-link-rx"></block></block>
  <block id="0a9e1455c4a5a9965867a5efd6b8cc9b" category="paragraph"><block ref="0a9e1455c4a5a9965867a5efd6b8cc9b" category="inline-link-rx"></block></block>
  <block id="913c29df09bcb5715ed7a48c12f3a0da" category="list-text">ONTAP AI 네트워킹</block>
  <block id="ae2703e9b1dff6da048c786142c2e7db" category="list-text">Cisco Nexus 3232C 시리즈 스위치</block>
  <block id="96eb8aa0e86d101fdf87284d7d6f1bc7" category="paragraph"><block ref="96eb8aa0e86d101fdf87284d7d6f1bc7" category="inline-link-rx"></block></block>
  <block id="8a27a2062df55e0aa73964ea8ec2ab55" category="list-text">Mellanox 스케일 아웃 SN2000 이더넷 스위치 시리즈</block>
  <block id="87a849c2f3c412a491f97674d5e27ed1" category="inline-link"><block ref="fd77c1cd25d650110f7047fa02f8327d" category="inline-link-rx"></block></block>
  <block id="a6c16c720941d75800533dedd69929cc" category="paragraph"><block ref="ad90d1952f7d0f85370461937e4484b7" category="inline-link-rx"></block></block>
  <block id="9e40fd8f5f0e113c758dfa63adc1221d" category="summary">Kubeflow는 새로운 Jupyter Notebook 서버를 신속하게 프로비저닝하여 데이터 과학자 작업 공간 역할을 할 수 있습니다. Kubeflow와 함께 새로운 Jupyter Notebook 서버를 프로비저닝하려면 이 페이지에 나열된 작업을 수행합니다.</block>
  <block id="7fad49a67f130cbd7629be2d6c719aea" category="doc">데이터 과학자 또는 개발자 사용을 위한 Jupyter Notebook Workspace를 제공합니다</block>
  <block id="7236436bac67d8eaadbf52811774b916" category="inline-link">Kubeflow 공식 문서</block>
  <block id="52d84951381eb0ab7a285dd32b31702c" category="paragraph">Kubeflow는 새로운 Jupyter Notebook 서버를 신속하게 프로비저닝하여 데이터 과학자 작업 공간 역할을 할 수 있습니다. Kubeflow와 함께 새로운 Jupyter Notebook 서버를 프로비저닝하려면 다음 작업을 수행합니다. Kubeflow 컨텍스트 내의 Jupyter Notebooks에 대한 자세한 내용은 를 참조하십시오<block ref="05932219411c169f9e48f874e56f1ed3" category="inline-link-rx"></block>.</block>
  <block id="5e82e4aa94a53b3b50acf347914be197" category="list-text">Kubeflow 중앙 대시보드에서 기본 메뉴의 Notebook Servers를 클릭하여 Jupyter Notebook 서버 관리 페이지로 이동합니다.</block>
  <block id="358d18b5a42ec1d80b04e767298ea372" category="paragraph"><block ref="358d18b5a42ec1d80b04e767298ea372" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208feb7a4d57f0afc49e53fe1fe8b978" category="list-text">New Server를 클릭하여 새 Jupyter Notebook 서버를 프로비저닝합니다.</block>
  <block id="3541a3b25823fa3b302c686b6fe2a212" category="paragraph"><block ref="3541a3b25823fa3b302c686b6fe2a212" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f95069a2e81949b101427e1fa4afddf" category="list-text">새 서버의 이름을 지정하고, 서버를 기반으로 할 Docker 이미지를 선택한 다음, 서버에서 예약할 CPU와 RAM의 양을 지정합니다. 네임스페이스 필드가 비어 있는 경우 페이지 머리글의 네임스페이스 선택 메뉴를 사용하여 네임스페이스를 선택합니다. 그러면 Namespace 필드가 선택한 네임스페이스로 자동 채워집니다.</block>
  <block id="4fbbbc4aaa49d653f486738eed12357a" category="paragraph">다음 예에서는 kubeflow-anonymous 네임스페이스가 선택됩니다. 또한 Docker 이미지, CPU 및 RAM에 대한 기본값을 사용할 수 있습니다.</block>
  <block id="69bc8b3ae7667985c27ce3ef5de0e6ca" category="paragraph"><block ref="69bc8b3ae7667985c27ce3ef5de0e6ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="124793fd2a85b1699a94b12bf4661758" category="inline-link-macro">Kubeflow 구축</block>
  <block id="095efbb867f01094d56c633d3337a412" category="list-text">작업 공간 볼륨 세부 정보를 지정합니다. 새 볼륨을 생성하기로 선택한 경우 기본 StorageClass를 사용하여 해당 볼륨 또는 PVC가 프로비저닝됩니다. Trident를 사용하는 StorageClass가 섹션에서 기본 StorageClass로 지정되었기 때문입니다 <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>, 볼륨 또는 PVC는 Trident를 사용하여 프로비저닝됩니다. 이 볼륨은 Jupyter Notebook Server 컨테이너 내의 기본 작업 공간으로 자동으로 마운트됩니다. 사용자가 서버에서 별도의 데이터 볼륨에 저장되지 않은 전자 필기장은 이 작업 영역 볼륨에 자동으로 저장됩니다. 따라서 재부팅 시에도 노트북이 유지됩니다.</block>
  <block id="c44927b0124469511a724e179c80bfb5" category="paragraph"><block ref="c44927b0124469511a724e179c80bfb5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="555e44b3745904843417371073338d08" category="list-text">데이터 볼륨을 추가합니다. 다음 예에서는 'PB-FG-ALL'이라는 기존 PVC를 지정하고 기본 마운트 지점을 적용합니다.</block>
  <block id="0c73069b282d8e99ecbd8feb39164d40" category="paragraph"><block ref="0c73069b282d8e99ecbd8feb39164d40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b120f9006af3d27ef70eb256c99c6617" category="list-text">* 선택 사항: * 원하는 수의 GPU를 노트북 서버에 할당하도록 요청합니다. 다음 예에서는 GPU 1개가 요청됩니다.</block>
  <block id="c969e6364e4561a959d1ce20f7187723" category="paragraph"><block ref="c969e6364e4561a959d1ce20f7187723" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8da2142543d647576288d71dddabb01" category="list-text">시작 을 클릭하여 새 노트북 서버를 프로비저닝합니다.</block>
  <block id="37a742c47c216725dd178d8c3c7a3f31" category="list-text">노트북 서버가 완전히 준비될 때까지 기다립니다. 지정한 Docker 이미지를 사용하여 서버를 프로비저닝하지 않은 경우 이미지를 다운로드해야 하므로 몇 분 정도 걸릴 수 있습니다. 서버가 완전히 프로비저닝되면 Jupyter Notebook 서버 관리 페이지의 상태 열에 녹색 확인 표시가 나타납니다.</block>
  <block id="417a2eafac6842560d3900cf9d12b5bb" category="paragraph"><block ref="417a2eafac6842560d3900cf9d12b5bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0463a63e8059055e703ecd9ffa72e106" category="list-text">연결을 클릭하여 새 서버 웹 인터페이스에 연결합니다.</block>
  <block id="4fbf21602f4888216386998d62f1defd" category="list-text">6단계에서 지정한 데이터 세트 볼륨이 서버에 마운트되었는지 확인합니다. 이 볼륨은 기본적으로 기본 작업 공간 내에 마운트됩니다. 사용자의 관점에서 이것은 작업 영역 내의 다른 폴더일 뿐입니다. 인프라 전문가가 아닌 데이터 과학자인 사용자는 이 볼륨을 사용하기 위해 스토리지 전문 지식을 보유할 필요가 없습니다.</block>
  <block id="c4b6acc44505864a5dccae2571b74f6a" category="paragraph"><block ref="c4b6acc44505864a5dccae2571b74f6a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7d375154397ce9358d2234ec578ff7e" category="paragraph"><block ref="a7d375154397ce9358d2234ec578ff7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="479d03862d87da58784e60e5cfcec977" category="list-text">터미널을 열고 5단계에서 새 볼륨이 요청되었다고 가정하고 df -h를 실행하여 새로운 Trident 제공 영구 볼륨이 기본 작업 공간으로 마운트되었는지 확인합니다.</block>
  <block id="68f39a4f77e618e6617c3830fb47de7c" category="paragraph">기본 작업 공간 디렉터리는 서버의 웹 인터페이스에 처음 액세스할 때 표시되는 기본 디렉터리입니다. 따라서 웹 인터페이스를 사용하여 생성한 아티팩트는 Trident가 제공하는 영구 볼륨에 저장됩니다.</block>
  <block id="d3e91c75db0cb717734224e6eb72e201" category="paragraph"><block ref="d3e91c75db0cb717734224e6eb72e201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d739fe0e421e9cb4d6315f0021cc5eb" category="paragraph"><block ref="1d739fe0e421e9cb4d6315f0021cc5eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8c20de15cf5efa2297f9d40d899450e" category="list-text">터미널을 사용하여 NVIDIA-SMI를 실행하여 올바른 개수의 GPU가 노트북 서버에 할당되었는지 확인합니다. 다음 예에서는 7단계에서 요청했던 대로 하나의 GPU가 노트북 서버에 할당되었습니다.</block>
  <block id="ed4e7225349e5c6cd33dfd15ad878438" category="paragraph"><block ref="ed4e7225349e5c6cd33dfd15ad878438" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c64f80d07d5c1623b7b2f34e40d7b46c" category="inline-link-macro">다음: 노트북 및 파이프라인 예제</block>
  <block id="c3714374d558db5573b4ecd4261e206e" category="paragraph"><block ref="c3714374d558db5573b4ecd4261e206e" category="inline-link-macro-rx"></block></block>
  <block id="4b022a47bb6a38cb1b05a5cbec618ccd" category="inline-link-macro">이전: 피어 AKS VNET 및 Azure NetApp Files VNET</block>
  <block id="fec5fee1adce318e5e2f9ce6a66ccc02" category="paragraph"><block ref="fec5fee1adce318e5e2f9ce6a66ccc02" category="inline-link-macro-rx"></block></block>
  <block id="999aa3cd55c654beafcfa7653b65d339" category="paragraph">Hrom을 사용하여 Trident를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="36cd38f49b9afa08222c0dc9ebfe35eb" category="inline-link">출처</block>
  <block id="9c5f8711af47a869d4ef82db9e55eda5" category="list-text">Helm을 설치합니다(설치 지침은 를 참조하십시오<block ref="adf15389dc6d5fe4bd9024075437080f" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="f7c078ec85c617d77dfa95c309e4df1b" category="list-text">Trident 20.01.1 설치 프로그램을 다운로드하고 압축을 풉니다.</block>
  <block id="5729bb69ffc852a2e2757d743b7cb833" category="list-text">시스템 '$path'의 디렉토리에 tridentctl을 복사합니다.</block>
  <block id="d7fc4d1537e4623fdcebe9b8ba333cbb" category="list-text">Kubernetes(K8s) 클러스터에 Trident를 설치하고 H제어(<block ref="cbc920955683fc4acb62f9ea7099333f" category="inline-link-rx"></block>):</block>
  <block id="f515d7de4d597c284ba8042f699a0eab" category="list-text">디렉터리를 'helm' 디렉토리로 변경합니다.</block>
  <block id="6ee4094e2c3617e3e298ec79f9dc2898" category="list-text">Trident Pod의 상태를 확인합니다.</block>
  <block id="30f93734da9765d3bc7d49ca89932736" category="paragraph">모든 Pod가 가동되어 실행 중이면 Trident가 설치되어 앞으로 이동할 수 있습니다.</block>
  <block id="cde865911fa15995bc83db30d852300b" category="list-text">AKS에 대한 Azure NetApp Files 백엔드 및 스토리지 클래스를 설정합니다.</block>
  <block id="476fdb61358f28988640245a33bd9199" category="list-text">Azure 서비스 원칙을 만듭니다.</block>
  <block id="5cdfb88cd634d9d0eb47237e3251d4bd" category="paragraph">서비스 보안 주체는 Trident가 Azure와 통신하여 Azure NetApp Files 리소스를 조작하는 방법입니다.</block>
  <block id="253a9ccb0f0696ed79c174b388867829" category="list-text">Trident 백엔드 json 파일(예: "anf-backend.json")을 생성합니다.</block>
  <block id="c17b83e07524acc467ac01e42fa0ebdb" category="list-text">원하는 텍스트 편집기를 사용하여 'anf-backend.json' 파일 안에 다음 필드를 입력합니다.</block>
  <block id="1197f8dc56b70115d87008dd2ecd3fca" category="list-text">다음 필드로 대체합니다.</block>
  <block id="b0b2134849d44712e969d6872e7245e5" category="list-text">'스크립트 ID'입니다. Azure 구독 ID입니다.</block>
  <block id="7b42dbe86adeab0d66f36221b33bb0f4" category="list-text">텐antID. 이전 단계에서 'az ad sp'의 출력에서 Azure 테넌트 ID입니다.</block>
  <block id="5a8bb8e509b4a424a1df50ef0bb41d89" category="list-text">'클라이언트 ID'. 이전 단계에서 'az ad sp'의 출력에서 귀하의 appID.</block>
  <block id="6334b606a5807346a083767eaab3934f" category="list-text">'clientSecret' 이전 단계에서 사용한 'az ad sp' 출력의 암호입니다.</block>
  <block id="12104fe8975b3ce95324ec3cab160ffc" category="list-text">구성 파일로 anf-backend.json을 사용하여 trident 네임스페이스에 Azure NetApp Files 백엔드를 생성하도록 Trident에 지시합니다.</block>
  <block id="d6d34c355bcd6b2efe2795a2aeedd247" category="paragraph"><block ref="d6d34c355bcd6b2efe2795a2aeedd247" category="inline-image-macro-rx" type="image"></block></block>
  <block id="004530c3d3b3f442f56243625372db1d" category="list-text">스토리지 클래스를 생성합니다. Kubernetes 사용자는 이름으로 스토리지 클래스를 지정하는 PVC를 사용하여 볼륨을 프로비저닝합니다. K8s에게 이전 단계에서 만든 Trident 백엔드를 참조하는 스토리지 클래스 "azurenetappfiles"를 생성하도록 지시합니다.</block>
  <block id="e777b114d6f12bc1190a60eaf8498e37" category="list-text">스토리지 클래스 및 복사본을 위한 YAML('anf-storage-class.yAML') 파일을 생성합니다.</block>
  <block id="01d45e8c6af153b1a477537e02466b5c" category="list-text">스토리지 클래스가 생성되었는지 확인합니다.</block>
  <block id="445895be8456b7de5e864fc09994551a" category="paragraph"><block ref="445895be8456b7de5e864fc09994551a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d3fec4cfe088bc80c2c2930f051b60b" category="inline-link-macro">다음: 헬름으로 AKS에서 RAPIDS를 사용하여 Dask를 설정합니다.</block>
  <block id="f2d1f2f412dd744c26a147e39bfa708f" category="paragraph"><block ref="f2d1f2f412dd744c26a147e39bfa708f" category="inline-link-macro-rx"></block></block>
  <block id="2fb227f90ebf269423fe0cf1a15b8111" category="doc">영구 볼륨 클레임을 정의합니다</block>
  <block id="8f5da11015f2baf835f0e8b421c1cfe9" category="list-text">다음 YAML을 파일에 저장하여 기본 유형의 PVC를 생성합니다.</block>
  <block id="04c58cdb1d0c073dd558caf87f2b8ed1" category="list-text">Iguazio Kubernetes 클러스터에 YAML 파일을 적용하십시오.</block>
  <block id="f685fdfcc5aedb3ccc237a4020b69cd8" category="section-title">Jupyter Notebook에 NetApp Volume을 연결합니다</block>
  <block id="dc4b8e255a77b2c73f89b702dbb7acc5" category="inline-link">Iguazio 응용 프로그램 서비스 및 도구 개요</block>
  <block id="11eb1e24a14c1d15ee5e287b4338b764" category="paragraph">Iguazio는 데이터 과학자에게 AI/ML 애플리케이션의 개발 및 배포를 위한 완벽한 종단 간 스택을 제공하기 위해 여러 가지 관리 서비스를 제공합니다. 에서 이러한 구성 요소에 대해 자세히 알아볼 수 있습니다<block ref="2cf4dcc22fda31f66959754df93d6196" category="inline-link-rx"></block>.</block>
  <block id="3591be3d07a4f8a37d218b9e92bea432" category="paragraph">관리 서비스 중 하나는 Jupyter Notebook입니다. 각 개발자는 개발에 필요한 리소스와 함께 노트북 컨테이너를 직접 배포할 수 있습니다. NetApp Cloud Volume에 대한 액세스 권한을 부여하려면 볼륨을 해당 컨테이너에 할당하고 리소스 할당, 실행 중인 사용자 및 영구 볼륨 청구에 대한 환경 변수 설정을 다음 이미지에 표시할 수 있습니다.</block>
  <block id="31bbf80f0649d07d3e8340123f1a6963" category="inline-link">TR-4798</block>
  <block id="e0d870d503aeb797f7626b14c9acb4ae" category="paragraph">온-프레미스 구성의 경우 를 참조할 수 있습니다<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> 버전 관리를 위한 데이터 또는 모델의 스냅샷 복사본 생성 등 NetApp ONTAP 데이터 관리 기능을 지원하는 Trident 설정에서 Trident 백엔드 구성 파일에 다음 줄을 추가하여 스냅샷 디렉토리를 표시합니다.</block>
  <block id="12ce9751e0e6d2a7d593d46e19211984" category="inline-link">Trident 명령</block>
  <block id="71f8fa2d01d0c5a2d9af72f90f65e379" category="paragraph">JSON 형식으로 Trident 백 엔드 구성 파일을 생성한 후 다음을 실행해야 합니다<block ref="1dce3ee9e9ff2b59caf27104be259d37" category="inline-link-rx"></block> 이를 참조하려면:</block>
  <block id="2842c07cfacaf614e63dc1f2afef93b2" category="paragraph"><block ref="2842c07cfacaf614e63dc1f2afef93b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d47cd04a0ddb5c3e6a2d9b9bc5c6a120" category="inline-link-macro">다음: 응용 프로그램 배포</block>
  <block id="fafac2eb9a7c4fcf46778865a22a00d2" category="paragraph"><block ref="fafac2eb9a7c4fcf46778865a22a00d2" category="inline-link-macro-rx"></block></block>
  <block id="fb1290be14b9bc3c64a2c3c9ace6c065" category="doc">사용 사례 개요 및 문제 설명</block>
  <block id="aa04a8198c7c60df7adcd6cd49bec6f8" category="paragraph">데이터 세트 및 데이터 세트 버전은 일반적으로 비용을 줄이고 기타 운영 이점을 제공하는 NetApp StorageGRID 오브젝트 기반 스토리지와 같은 데이터 레이크에 있습니다. 데이터 과학자는 이러한 데이터 세트를 가져와 다양한 단계로 엔지니어링하여 특정 모델을 사용하여 교육 준비를 합니다. 종종 여러 버전을 만들어냅니다. 다음 단계로 데이터 과학자는 모델을 실행하기 위해 최적화된 컴퓨팅 리소스(GPU, 하이엔드 CPU 인스턴스, 온프레미스 클러스터 등)를 선택해야 합니다. 다음 그림에서는 ML 컴퓨팅 환경에서 데이터 세트의 근접 위치 부족을 보여 줍니다.</block>
  <block id="cc054601488581e80cc1d19c227126f6" category="paragraph"><block ref="cc054601488581e80cc1d19c227126f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88515fca547c502286d6f2a9081fc734" category="paragraph">하지만 다양한 컴퓨팅 환경에서 여러 개의 교육 실험을 병렬로 실행해야 합니다. 각 환경에서는 데이터 레이크에서 데이터 세트를 다운로드해야 하며, 이 프로세스는 비용과 시간이 많이 소요됩니다. 데이터 세트와 컴퓨팅 환경(특히 하이브리드 클라우드의 경우)의 근접성이 보장되지는 않습니다. 또한 동일한 데이터 세트를 사용하여 자체 실험을 수행하는 다른 팀 구성원은 동일한 극한 용도의 프로세스를 거쳐야 합니다. 분명한 느린 데이터 액세스 외에도 데이터 세트 버전 추적, 데이터 세트 공유, 협업 및 재현성의 어려움 등의 문제가 있습니다.</block>
  <block id="30b64502c0cb2f8a9bf951993e0abbac" category="section-title">고객 요구 사항</block>
  <block id="5243f720d7e440d7746f03df97ef885f" category="paragraph">리소스를 효율적으로 사용하면서 고성능 ML 실행을 구현하기 위해 고객 요구사항이 달라질 수 있습니다. 예를 들어, 고객은 다음과 같은 요구사항을 충족해야 할 수 있습니다.</block>
  <block id="1735cf11ce0034dbb80c297fb204bc21" category="list-text">많은 비용이 드는 다운로드 및 데이터 액세스 복잡성을 발생시키지 않으면서 교육 모델을 실행하는 각 컴퓨팅 인스턴스에서 데이터 세트에 빠르게 액세스할 수 있습니다</block>
  <block id="80085a846f90523080cf086e66561d52" category="list-text">데이터 세트의 위치에 관계없이 클라우드 또는 온프레미스에서 컴퓨팅 인스턴스(GPU 또는 CPU)를 사용합니다</block>
  <block id="de79912b1ab8764406a232888aab85e5" category="list-text">불필요한 지연 시간 및 데이터 지연 시간 없이 동일한 데이터 세트에서 여러 컴퓨팅 리소스와 동시에 여러 교육 실험을 실행하여 효율성 및 생산성 향상</block>
  <block id="5211203793a223f02322b88b2e698a82" category="list-text">컴퓨팅 인스턴스 비용 최소화</block>
  <block id="6a6fcee71b4e22ac6a4afdfdb5940b67" category="list-text">데이터 세트, 계열, 버전 및 기타 메타데이터 세부 정보를 기록할 수 있는 도구를 통해 재현성이 향상되었습니다</block>
  <block id="930d18875813298018f8364069441eee" category="list-text">공유 및 협업이 향상되어 권한이 있는 팀원 중 한 명이 데이터 세트에 액세스하여 실험을 실행할 수 있습니다</block>
  <block id="5f700d00ad72470694a5aa06cd515c8b" category="paragraph">NetApp ONTAP 데이터 관리 소프트웨어를 사용하여 데이터 세트 캐싱을 구축하려면 다음과 같은 작업을 수행해야 합니다.</block>
  <block id="41fac0272180c0141b5cd7ad6ad85a44" category="list-text">컴퓨팅 리소스에 가장 가까운 NFS 스토리지를 구성하고 설정합니다.</block>
  <block id="25a3a7ee3cfbb4afc291cd5b94dec000" category="list-text">캐시할 데이터 세트 및 버전을 결정합니다.</block>
  <block id="dbffd2a20c35c06fbb6ba0cd17e54ef6" category="list-text">캐시된 데이터 세트에 커밋된 총 메모리 용량과 추가 캐시 커밋에 사용할 수 있는 NFS 스토리지 용량(예: 캐시 관리)을 모니터링합니다.</block>
  <block id="61d5e7050cbe037ad5adeaf246e6be19" category="list-text">특정 시간에 사용하지 않은 데이터 세트가 캐시에서 노후화되었습니다. 기본값은 1일입니다. 다른 구성 옵션을 사용할 수 있습니다.</block>
  <block id="36691dc48fac4774974c970e3bfa1a7d" category="paragraph"><block ref="36691dc48fac4774974c970e3bfa1a7d" category="inline-link-macro-rx"></block></block>
  <block id="57a499fcdd85136edfd1ee55dedd9675" category="summary">이 솔루션은 AI/ML 애플리케이션의 라이프사이클 뒤에 있습니다. 먼저 데이터 과학자의 작업을 통해 데이터를 준비하고 모델을 교육하는 데 필요한 다양한 단계를 정의합니다. DASK에서 RAPIDS를 활용하여 Azure Kubernetes Service(AKS) 클러스터 전반에 걸쳐 분산 교육을 수행하여 기존 Python 좌식 키트 학습 접근법과 비교하여 교육 시간을 크게 줄였습니다. 전체 주기를 완료하기 위해 Azure NetApp Files과 파이프라인을 통합합니다.</block>
  <block id="0359d40b3d1a900a1841f1e8bd783cd5" category="doc">TR-4904: Azure에서 제공되는 분산 교육 - 클릭 비율 예측</block>
  <block id="e6fab630e7da86a500e1e3c51fa61a00" category="paragraph">Rick Huang, Verron Martina, Muneer Ahmad, NetApp</block>
  <block id="4c3816ce69205bc811aa89dbe9d09a1a" category="paragraph">데이터 과학자의 작업은 머신 러닝(ML) 및 인공 지능(AI) 모델의 훈련 및 튜닝에 중점을 두어야 합니다. 그러나 구글의 조사에 따르면, 데이터 과학자들은 약 80%의 시간을 들여 모델을 엔터프라이즈 애플리케이션과 연동하고 대규모로 실행하는 방법을 찾아내고 있습니다.</block>
  <block id="a1451f6988178ae140f8da836d63a157" category="paragraph">엔드 투 엔드 AI/ML 프로젝트를 관리하려면 엔터프라이즈 구성 요소를 더 잘 이해해야 합니다. DevOps가 정의, 통합 및 구축을 인수했지만, 이러한 유형의 구성요소는 AI/ML 프로젝트를 포함하는 유사한 흐름을 타겟으로 합니다. 엔터프라이즈에서 엔드 투 엔드 AI/ML 파이프라인이 어떤 영향을 받는지 알아보려면 다음 필수 구성요소 목록을 참조하십시오.</block>
  <block id="8c4aa541ee911e8d80451ef8cc304806" category="list-text">스토리지</block>
  <block id="a5fa5746370b608090b994a97b49e98b" category="list-text">네트워킹</block>
  <block id="ea2ef9b0d095bf991f4973633b485340" category="list-text">데이터베이스를 지원합니다</block>
  <block id="3b18b13f059019d19211f8a9f36f7e4e" category="list-text">파일 시스템</block>
  <block id="d6c823008f20bbfce5f39b30ec9fa918" category="list-text">CI/CD(Continuous Integration and Continuous Deployment) 파이프라인</block>
  <block id="24bea3d677b34d6aea9ff01417fd9d06" category="list-text">IDE(통합 개발 환경)</block>
  <block id="2fae32629d4ef4fc6341f1751b405e45" category="list-text">보안</block>
  <block id="bd0992d43bb2d0ca676184502e14754e" category="list-text">데이터 액세스 정책</block>
  <block id="3c02a379965ab0dfcd77b1c484450433" category="list-text">하드웨어</block>
  <block id="a9353b1bd1eeedb788a74090b5f8d0bc" category="list-text">데이터 과학 도구 세트 및 라이브러리</block>
  <block id="e6a53478c3fc5682c6f851672b3e7bc9" category="paragraph">데이터 과학의 세계는 IT와 비즈니스의 여러 분야를 아우릅니다.</block>
  <block id="cddde51824956f407b4c02c1e4bc8004" category="list-text">데이터 과학자는 자신이 선택한 도구와 라이브러리를 사용할 수 있는 유연성이 필요합니다.</block>
  <block id="310a768ecb4689bcaf80072231d73e83" category="list-text">데이터 엔지니어는 데이터 흐름과 데이터 위치를 알아야 합니다.</block>
  <block id="c12281f5ea7b17e370414efbf3f26c30" category="list-text">DevOps 엔지니어는 새로운 AI/ML 애플리케이션을 CI/CD 파이프라인에 통합하는 툴을 필요로 합니다.</block>
  <block id="9ca78187997ba2a23a73c094256ae63f" category="list-text">클라우드 관리자와 설계자는 Azure 리소스를 설정하고 관리할 수 있어야 합니다.</block>
  <block id="060bc2911862b1ab8f6b4b77542434a2" category="paragraph">이 기술 보고서에서는 Azure NetApp Files, RAPIDS AI, DASK, Azure가 이러한 각 역할이 비즈니스에 어떤 가치를 제공하는지 설명합니다.</block>
  <block id="ed8b6e047f5d4e844fe3e870c3fda4a3" category="paragraph">Azure NetApp Files는 다양한 성능 계층을 제공합니다. 고객은 표준 계층으로 시작하여 데이터를 이동하지 않고도 고성능 계층으로 스케일아웃 및 스케일업할 수 있습니다. 이 기능을 통해 데이터 과학자는 성능 문제 없이 규모에 맞게 모델을 교육할 수 있으므로 아래 그림과 같이 클러스터 전체에서 데이터 사일로를 피할 수 있습니다.</block>
  <block id="d4dc9019b6000fd12d9dc6b091fe3e26" category="paragraph"><block ref="d4dc9019b6000fd12d9dc6b091fe3e26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b320345f652aacf7148c76dff24e2f68" category="inline-link-macro">다음: 기술 개요</block>
  <block id="a20978df09e58f39953eb81f9368c2f2" category="paragraph"><block ref="a20978df09e58f39953eb81f9368c2f2" category="inline-link-macro-rx"></block></block>
  <block id="58415f353579ec62f4e5d8047761a3cc" category="summary">AI 기반 자동화 및 에지 컴퓨팅은 비즈니스 조직이 디지털 혁신을 달성하고 운영 효율성과 안전을 극대화할 수 있도록 지원하는 선도적인 접근 방식입니다. 에지 컴퓨팅은 데이터 센터와 데이터를 전송할 필요가 없기 때문에 훨씬 더 빠르게 처리됩니다. 따라서 데이터를 데이터 센터 또는 클라우드로 전송하는 데 따른 비용이 절감됩니다.</block>
  <block id="1490b4526090ba1052ae7d989d2f44df" category="inline-link-macro">이전: 아키텍처 사이징 옵션</block>
  <block id="9d58af74dd11a7bf0a907e66af94ae03" category="paragraph"><block ref="9d58af74dd11a7bf0a907e66af94ae03" category="inline-link-macro-rx"></block></block>
  <block id="7d7c5045abef00692470c8d5ed1aeebd" category="paragraph">AI 기반 자동화 및 에지 컴퓨팅은 비즈니스 조직이 디지털 혁신을 달성하고 운영 효율성과 안전을 극대화할 수 있도록 지원하는 선도적인 접근 방식입니다. 에지 컴퓨팅은 데이터 센터와 데이터를 전송할 필요가 없기 때문에 훨씬 더 빠르게 처리됩니다. 따라서 데이터를 데이터 센터 또는 클라우드로 전송하는 데 따른 비용이 절감됩니다. 에지에 구축된 AI 추론 모델을 사용하여 거의 실시간으로 의사 결정을 내려야 하는 경우 지연 시간이 단축되고 속도가 빨라질 수 있습니다.</block>
  <block id="691e8c5d8b13259848ef2e5515d14ca9" category="paragraph">NetApp 스토리지 시스템은 로컬 SSD 스토리지와 동일하거나 더 우수한 성능을 제공하여 데이터 과학자, 데이터 엔지니어, AI/ML 개발자 및 비즈니스 또는 IT 의사 결정자에게 다음과 같은 이점을 제공합니다.</block>
  <block id="59ceee4c2b9743d6e9aae43f1e9ee547" category="list-text">AI 시스템, 분석 및 기타 중요한 비즈니스 시스템 간에 데이터를 손쉽게 공유 이러한 데이터 공유는 인프라 오버헤드를 줄이고 성능을 향상하며 기업 전체에서 데이터 관리를 간소화합니다.</block>
  <block id="b9f30f0e1030c74a0db7ca1a1e82a22f" category="list-text">컴퓨팅과 스토리지를 독립적으로 확장하므로 비용을 최소화하고 리소스 사용량을 높일 수 있습니다.</block>
  <block id="40454c2a63608aacf0433b6a47f388f4" category="list-text">즉각적이고 공간 효율적인 사용자 작업 공간, 통합 버전 제어 및 자동화된 구축을 위해 통합 Snapshot 복사본과 클론을 사용하여 개발 및 구축 워크플로우를 간소화했습니다.</block>
  <block id="0543f71645ff9108a860d92965cc1383" category="list-text">재해 복구 및 비즈니스 연속성을 위한 엔터프라이즈급 데이터 보호 기능 이 문서에 제공된 NetApp 및 Lenovo 솔루션은 에지에서 엔터프라이즈급 AI 추론 배포에 이상적인 유연한 스케일아웃 아키텍처입니다.</block>
  <block id="68c8080de8c25b2c95e86546db2c34f4" category="list-text">J.J. Falkanger, 선임 Lenovo, HPC 및 AI 솔루션 매니저</block>
  <block id="a1be3af64bad65325413de79cbdd38ec" category="list-text">Dave Arnette, NetApp 기술 마케팅 엔지니어</block>
  <block id="ab7eb4cf2e6900db95523411e2e2d968" category="list-text">Joey Parnell, 기술 팀장 E-Series AI 솔루션, NetApp</block>
  <block id="7506341ffff969b3db4120a09a3cd873" category="list-text">Cody Harryman, NetApp QA 엔지니어</block>
  <block id="4bb047f8c530785002e490ef17fa725e" category="section-title">추가 정보를 찾을 수 있는 위치</block>
  <block id="345245c83d2b2c4c2a5eb9f2887da627" category="paragraph">이 문서에 설명된 정보에 대한 자세한 내용은 다음 문서 및/또는 웹 사이트를 참조하십시오.</block>
  <block id="16d9e623379df2a050a5042b643bf4fc" category="list-text">NetApp AFF A-Series 어레이 제품 페이지 를 참조하십시오</block>
  <block id="2eea2276b1fb61cd770f311f77c0f440" category="inline-link"><block ref="2eea2276b1fb61cd770f311f77c0f440" category="inline-link-rx"></block></block>
  <block id="3ac5561d8de2087fdd9ac49ace880bff" category="paragraph"><block ref="3ac5561d8de2087fdd9ac49ace880bff" category="inline-link-rx"></block></block>
  <block id="ac2e4973250b614c4ffed16837be9bda" category="list-text">NetApp ONTAP 데이터 관리 소프트웨어 - ONTAP 9 정보 라이브러리</block>
  <block id="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="paragraph"><block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="5dbac8b4dac620b04fd11b54388ac506" category="list-text">TR-4727: NetApp EF-Series 소개</block>
  <block id="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link"><block ref="3df74183de4e18a002d0a9dadd2b4b41" category="inline-link-rx"></block></block>
  <block id="5e60359f54f57375f6417990b408bc8d" category="paragraph"><block ref="5e60359f54f57375f6417990b408bc8d" category="inline-link-rx"></block></block>
  <block id="bf8eb67f3476640d74487d7395b166a8" category="list-text">NetApp E-Series SANtricity 소프트웨어 데이터시트 를 참조하십시오</block>
  <block id="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link"><block ref="01e4cb0e0f13f033fd419d3abf905d34" category="inline-link-rx"></block></block>
  <block id="62cabab367af4d0d4f74456d673e91e7" category="paragraph"><block ref="62cabab367af4d0d4f74456d673e91e7" category="inline-link-rx"></block></block>
  <block id="f11b61c13d771c4795415471f8362f8c" category="list-text">컨테이너용 NetApp 영구 스토리지 - NetApp Trident</block>
  <block id="856500f909a4984692886f9549398b67" category="inline-link"><block ref="856500f909a4984692886f9549398b67" category="inline-link-rx"></block></block>
  <block id="fe6e33e3be237f2a488d04432ad4b35f" category="list-text"><block ref="fe6e33e3be237f2a488d04432ad4b35f" category="inline-link-rx"></block></block>
  <block id="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link"><block ref="9083657cbd1d0fb49ada01ab2e2cc193" category="inline-link-rx"></block></block>
  <block id="3de4b3f21621e41c0738a82d4e694114" category="list-text"><block ref="3de4b3f21621e41c0738a82d4e694114" category="inline-link-rx"></block></block>
  <block id="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link"><block ref="1f07318e5a4df96a96fc92d83bbe5d70" category="inline-link-rx"></block></block>
  <block id="25b3dca46bdabc4612ba4ba5dac0f9db" category="list-text"><block ref="25b3dca46bdabc4612ba4ba5dac0f9db" category="inline-link-rx"></block></block>
  <block id="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link"><block ref="b658c024dad07cbf1d8523e4c3ba8d21" category="inline-link-rx"></block></block>
  <block id="fdad8301fde8271edff994d643d18865" category="paragraph"><block ref="fdad8301fde8271edff994d643d18865" category="inline-link-rx"></block></block>
  <block id="7749687216549469e9a78db087fbb44b" category="list-text">TensorFlow 벤치마크</block>
  <block id="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link"><block ref="7c8f9b5afa9dfab5f8f375d1b977b046" category="inline-link-rx"></block></block>
  <block id="be1b7087c9993d320070b1e676c832f9" category="paragraph"><block ref="be1b7087c9993d320070b1e676c832f9" category="inline-link-rx"></block></block>
  <block id="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link"><block ref="e15fea5c6bb7e2f7d8e055fbb773fc11" category="inline-link-rx"></block></block>
  <block id="b1a88588a48ee9492506277f8561b392" category="paragraph"><block ref="b1a88588a48ee9492506277f8561b392" category="inline-link-rx"></block></block>
  <block id="f9732caa47051768fc11729f5535891b" category="list-text">Lenovo ThinkSystem DM5100F 유니파이드 플래시 스토리지 어레이</block>
  <block id="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link"><block ref="a031d2e6ff4219cf38830b0db9d366b1" category="inline-link-rx"></block></block>
  <block id="f8287e56c1a5982e49b792d1116aa372" category="paragraph"><block ref="f8287e56c1a5982e49b792d1116aa372" category="inline-link-rx"></block></block>
  <block id="f6a738f75f76f62a241636eca02cd87d" category="section-title">버전 기록</block>
  <block id="44749712dbec183e983dcd78a7736c41" category="cell">날짜</block>
  <block id="8002bc13927c65b5f265b031079ce1d4" category="cell">문서 버전 기록</block>
  <block id="3798985ee5e15c84c4263815d5a4d0b7" category="cell">버전 1.0</block>
  <block id="5e79a20254a28ffdb604f6cba5216c75" category="cell">2021년 3월</block>
  <block id="dfd02aef9802f4824ead7c08b8f81f1f" category="cell">최초 릴리스</block>
  <block id="304f30474edd152dc34aef7dbb123607" category="cell">버전 2.0</block>
  <block id="a5f3f63c2f6e1d6d4605650633b9ce8a" category="cell">2021년 10월</block>
  <block id="71b3f2dc39aa770e58cd3fad98b76c37" category="cell">EF 및 MLPerf Inference v1.1로 업데이트되었습니다</block>
  <block id="232abf87aa3028a990e94f6bb51fe8bd" category="summary">Kubernetes 클러스터에서 단일 노드 AI 및 ML 작업을 실행하려면 배포 점프 호스트에서 이 페이지의 작업을 수행하십시오.</block>
  <block id="46300fa439cc237919f854816fc89fc2" category="doc">단일 노드 AI 워크로드 실행</block>
  <block id="ebbcd572ece7625ba24f2c3ecda6d5b5" category="paragraph">Kubernetes 클러스터에서 단일 노드 AI 및 ML 작업을 실행하려면 배포 점프 호스트에서 다음 작업을 수행하십시오. Trident를 사용하면 페타바이트에 이를 수 있는 데이터 볼륨을 빠르고 쉽게 만들어 Kubernetes 워크로드에 액세스할 수 있습니다. Kubernetes Pod에서 데이터 볼륨에 액세스할 수 있도록 하려면 POD 정의에 PVC를 지정하기만 하면 됩니다. 이 단계는 Kubernetes 네이티브 운영이므로 NetApp의 전문성이 필요하지 않습니다.</block>
  <block id="e3305581bc1f67d1989e08e42a43c113" category="admonition">이 섹션에서는 Kubernetes 클러스터에서 실행하려고 하는 특정 AI 및 ML 워크로드를 이미 컨테이너화(Docker 컨테이너 형식)했다고 가정합니다.</block>
  <block id="6bdbab1141be3c52dec1f29c4c5fdf52" category="inline-link">ImageNet 웹 사이트</block>
  <block id="08eb6cc7203ec1b36805e4767d450467" category="list-text">다음 명령 예는 ImageNet 데이터 세트를 사용하는 TensorFlow 벤치마크 워크로드에 대한 Kubernetes 작업 생성을 보여줍니다. ImageNet 데이터 세트에 대한 자세한 내용은 를 참조하십시오<block ref="19a9693db577a40175aef26761f77fe7" category="inline-link-rx"></block>.</block>
  <block id="56920225f5c2d474925baad76ae3e7ce" category="paragraph">이 예시 작업은 8개의 GPU를 요청하므로 8개 이상의 GPU를 갖춘 단일 GPU 작업자 노드에서 실행할 수 있습니다. 이 예시 작업은 8개 이상의 GPU를 갖춘 작업자 노드가 없거나 현재 다른 워크로드를 사용 중인 클러스터에 제출할 수 있습니다. 이 경우 해당 작업자 노드를 사용할 수 있을 때까지 작업은 보류 중 상태로 유지됩니다.</block>
  <block id="8f811f6151a10e9d15de57c2af8fcfed" category="inline-link">Kubernetes 공식 문서</block>
  <block id="dd36f0d653a70e6e6c7e838454ee7e20" category="paragraph">또한 스토리지 대역폭을 최대화하기 위해 필요한 교육 데이터가 들어 있는 볼륨이 이 작업에서 생성되는 POD 내에 두 번 마운트됩니다. 포드에도 다른 볼륨이 마운트됩니다. 이 두 번째 볼륨은 결과 및 메트릭을 저장하는 데 사용됩니다. 이러한 용적은 PVC 이름을 사용하여 작업 정의에서 참조됩니다. Kubernetes 작업에 대한 자세한 내용은 를 참조하십시오<block ref="0ceaf9ba0112a862c5fa5f8d38bee04b" category="inline-link-rx"></block>.</block>
  <block id="225e66547943a27f429558dce4e639e2" category="paragraph">이 예시 작업이 생성하는 포드의 /dev/shm에 Memory의 midium 값을 가진 emptyDir 볼륨이 실장된다. Docker 컨테이너 런타임을 통해 자동으로 생성되는 '/dev/shm' 가상 볼륨의 기본 크기는 TensorFlow의 요구 사항에 비해 부족할 수 있습니다. 다음 예제와 같이 "emptyDir" 볼륨을 마운트하면 충분히 큰 "/dev/shm" 가상 볼륨이 제공됩니다. 'emptyDir' 볼륨에 대한 자세한 내용은 를 참조하십시오<block ref="ad2ab91baa5517930a567ac7588e61fd" category="inline-link-rx"></block>.</block>
  <block id="ac5f33311bbfb696a5966510fc4a38b8" category="paragraph">이 예제 작업 정의에 지정된 단일 컨테이너에는 'ecurityContext &gt; privileged' 값이 'true'로 지정됩니다. 이 값은 컨테이너가 호스트에 대한 루트 액세스 권한을 효과적으로 가지고 있음을 의미합니다. 이 경우 실행되는 특정 워크로드에 루트 액세스가 필요하므로 이 주석이 사용됩니다. 특히, 워크로드가 수행하는 명확한 캐시 작업에서는 루트 액세스가 필요합니다. 이 "특권" 주석이 필요한지 여부는 실행 중인 특정 워크로드의 요구 사항에 따라 달라집니다.</block>
  <block id="8db728b0062c29a77e48bcd3be77be7f" category="list-text">1단계에서 만든 작업이 올바르게 실행 중인지 확인합니다. 다음 명령 예에서는 작업 정의에 지정된 대로 작업에 대해 단일 POD가 생성되었으며 이 POD가 현재 GPU 작업자 노드 중 하나에서 실행되고 있음을 확인합니다.</block>
  <block id="7b2880ed5066d8fda6f6d5a4ec8f39ac" category="list-text">1단계에서 생성한 작업이 성공적으로 완료되었는지 확인합니다. 다음 명령 예에서는 작업이 성공적으로 완료되었음을 확인합니다.</block>
  <block id="bead823acab8a06d478eb02c7ff84d35" category="list-text">* 선택 사항: * 작업 아티팩트 정리. 다음 예제 명령은 1단계에서 만든 작업 오브젝트의 삭제를 보여 줍니다.</block>
  <block id="cb215cf0e9fb88bd1fc97b4ba53fd36f" category="paragraph">작업 개체를 삭제하면 Kubernetes에서 연결된 포드를 자동으로 삭제합니다.</block>
  <block id="7af76512b5f0f470c6a7a6db368a9818" category="inline-link-macro">다음: 동기 분산 AI 워크로드 실행</block>
  <block id="e79dd849e38d01ac3faa7090e83320b2" category="paragraph"><block ref="e79dd849e38d01ac3faa7090e83320b2" category="inline-link-macro-rx"></block></block>
  <block id="a7fbadb37067070a61a3da62b548ba3c" category="paragraph">NVIDIA Nemo는 NVIDIA에서 대화형 AI 애플리케이션을 만들기 위해 만든 툴킷입니다. 이 툴킷에는 ASR, NLP 및 TTS에 대한 사전 교육 모듈 모음이 포함되어 있어 연구자와 데이터 과학자가 복잡한 신경망 아키텍처를 쉽게 구성하고 자체 애플리케이션을 설계하는 데 더 많은 노력을 집중할 수 있습니다.</block>
  <block id="1a56a4858eeec63d31bc890d38325b84" category="paragraph">앞의 예에서와 같이 나라에서는 제한된 질문 유형만 처리할 수 있습니다. 사전 교육 받은 NLP 모델은 이러한 유형의 질문에만 교육을 제공하기 때문입니다. Nara가 보다 광범위한 질문을 처리하도록 하려면 자체 데이터세트를 사용하여 재교육해야 합니다. 따라서 여기서는 Nemo를 사용하여 NLP 모델을 확장하여 요구 사항을 충족하는 방법을 보여 줍니다. 우선 Nara에서 수집한 로그를 Nemo 형식으로 변환한 다음 NLP 모델을 향상시키기 위해 데이터 세트를 사용하여 훈련합니다.</block>
  <block id="a559b87068921eec05086ce5485e9784" category="section-title">모델</block>
  <block id="4e19d1e300ea3cd63472939c24caf65d" category="paragraph">우리의 목표는 Nara가 사용자 선호도에 따라 항목을 정렬할 수 있도록 하는 것입니다. 예를 들어, 나라에게 최고 등급의 스시 레스토랑을 추천하거나 나라(Nara)가 가장 낮은 가격으로 청바지를 찾아보길 원할 수도 있습니다. 이를 위해 Nemo에 제공된 intent detection 및 slot filling 모델을 실습 모델로 사용한다. 이 모델을 통해 Nara는 선호하는 검색의 의도를 이해할 수 있습니다.</block>
  <block id="5cb83e5ef3cd25eb53fa55d635a7758f" category="section-title">데이터 준비</block>
  <block id="807cace7b07fcded06b9d106c4dd4d2d" category="paragraph">모델을 학습하기 위해 이 유형의 질문에 대한 데이터 세트를 수집하고 이를 Nemo 형식으로 변환합니다. 여기서는 모델을 훈련하는 데 사용하는 파일을 나열했습니다.</block>
  <block id="dc1d3747ed1059f234cbe4a104700abd" category="section-title">dict.intents.csv</block>
  <block id="e803005a5c3a99889733e9c8e8bba406" category="paragraph">이 파일에는 Nemo가 이해할 수 있는 모든 인텐트가 나열되어 있습니다. 여기서는 일차 연고 2개와 일차 연고 중 하나에 적합하지 않은 질문을 분류하는 데만 사용되는 의도로 1개를 사용합니다.</block>
  <block id="ce2440c5074ba6a1e30fa2ec906dafb4" category="section-title">dict.slots.csv</block>
  <block id="a3fc542c51797c85b30365ba9b2d12c5" category="paragraph">이 파일에는 교육 질문에 표시할 수 있는 모든 슬롯이 나열되어 있습니다.</block>
  <block id="795cab38744084526a62914e47789fbe" category="section-title">훈련.TSV</block>
  <block id="8a5ae45ea3762f79d1a520bcf61275d5" category="paragraph">이 데이터 세트는 주요 교육 데이터 세트입니다. 각 줄은 dict.intent.csv 파일의 의도 범주 목록에 따라 질문으로 시작합니다. 레이블은 0부터 열거됩니다.</block>
  <block id="db487d8daea13e36203f660d46b3cdfc" category="section-title">기차_슬롯.TSV</block>
  <block id="73ade6fc5004174d2abe822c85cdfbef" category="section-title">모델 훈련</block>
  <block id="c764142480a5daa39ac98125503352e8" category="paragraph">그런 다음 다음 다음 다음 명령을 사용하여 컨테이너를 시작합니다. 이 명령은 간단한 교육 연습이므로 컨테이너가 단일 GPU(GPU ID=1)를 사용하도록 제한합니다. 또한 로컬 작업 공간/작업 공간/Nemo/를 컨테이너/Nemo 내부의 폴더에 매핑합니다.</block>
  <block id="a712c52af847db1e143ca43fdd44bd39" category="paragraph">컨테이너 내부에서 사전 훈련된 원래 BERT 모델에서 시작하려면 다음 명령을 사용하여 교육 절차를 시작할 수 있습니다. data_dir은 교육 데이터의 경로를 설정하기 위한 인수입니다. Work_dir 체크포인트 파일을 저장할 위치를 구성할 수 있습니다.</block>
  <block id="9e654b2215e90d20951b3ddd67a15bc6" category="paragraph">새로운 교육 데이터 세트가 있고 이전 모델을 개선하려는 경우 다음 명령을 사용하여 중지한 시점부터 계속 진행할 수 있습니다. checkpoint_dir 은 경로를 이전 체크포인트 폴더로 가져갑니다.</block>
  <block id="87eea49f703666c49da2d7987ba093b2" category="section-title">모델을 추론합니다</block>
  <block id="484c4e9e4a0a20bf41551f65663fa9d2" category="paragraph">특정 수의 Epoch 후에 교육 이수 모델의 성능을 검증해야 합니다. 다음 명령을 사용하여 쿼리를 하나씩 테스트할 수 있습니다. 예를 들어, 이 명령에서 모델이 '최고의 파스타를 어디서 얻을 수 있는지'라는 질의의 의도를 제대로 파악할 수 있는지 확인해야 합니다.</block>
  <block id="de558a28e6333ac9f453a42631f44c12" category="paragraph">그런 다음, 추론의 출력입니다. 출력물에서는 숙련된 모델이 find_the_store의 의도를 적절히 예측하고 관심 있는 키워드를 반환할 수 있습니다. 이러한 키워드를 사용하여 Nara는 사용자가 원하는 것을 검색하고 보다 정확한 검색을 수행할 수 있습니다.</block>
  <block id="254a4a0ddc892d6a01d7e7ef286fbb71" category="inline-link-macro">다음: 결론</block>
  <block id="5b7f09a1d5da38512130330f4d38fd32" category="paragraph"><block ref="5b7f09a1d5da38512130330f4d38fd32" category="inline-link-macro-rx"></block></block>
  <block id="3993b517d983222c5b766976180367f0" category="inline-link-macro">Previous(이전): 추가 정보를 찾을 위치.</block>
  <block id="7d5fc90090e6ef28f1b090f458e3bb91" category="paragraph"><block ref="7d5fc90090e6ef28f1b090f458e3bb91" category="inline-link-macro-rx"></block></block>
  <block id="248f830b158797f9c038ea35ea266b89" category="cell">2021년 8월</block>
  <block id="ea9349a37bfee247df0f87cbcacca796" category="cell">최초 릴리스.</block>
  <block id="86608a0b346f307c76f8ae00c9f6bcb9" category="summary">이 보고서는 데이터 네임스페이스를 빠르게 클론 복제하는 방법을 보여 줍니다. 추적 및 버전 관리를 위해 거의 즉각적인 데이터 생성 및 모델 기준선을 통합하는 AI 교육 워크플로우를 정의하고 구현하는 방법을 보여줍니다. 또한, 사이트 및 지역 전반에서 데이터를 원활하게 복제하고 대규모 데이터 세트에 액세스할 수 있는 Jupyter Notebook 작업 공간을 신속하게 프로비저닝하는 방법도 보여 줍니다.</block>
  <block id="fffa1b56750a0334993c90d5adc9912a" category="doc">TR-4798: NetApp AI Control Plane</block>
  <block id="f0829d8f9d70b9de9de7beae86dc2129" category="paragraph">Mike Oglesby, NetApp에서 직접 지원합니다</block>
  <block id="27114500e25aba7a27847b772d396575" category="paragraph">모든 규모와 업종에 상관없이 모든 기업과 조직은 실제 문제를 해결하고 혁신적인 제품과 서비스를 제공하며 경쟁이 갈수록 치열해지는 시장에서 경쟁 우위를 확보하기 위해 인공 지능(AI), 머신 러닝(ML), 딥 러닝(DL)으로 눈을 돌리고 있습니다. AI, ML 및 DL의 사용이 증가함에 따라 워크로드 확장성 및 데이터 가용성을 비롯한 많은 과제에 직면하게 됩니다. 이 문서에서는 NetApp 데이터 관리 기능을 널리 사용되는 오픈 소스 툴 및 프레임워크와 결합하여 제공하는 솔루션인 NetApp AI Control Plane을 사용하여 이러한 과제를 해결하는 방법을 보여줍니다.</block>
  <block id="98300151efa6f504dee4866e49cf2078" category="paragraph">이 보고서는 데이터 네임스페이스를 빠르게 클론 복제하는 방법을 보여 줍니다. 또한, 사이트 및 지역 전반에서 데이터를 원활하게 복제하여 결합형 통합 AI/ML/DL 데이터 파이프라인을 생성하는 방법을 보여줍니다. 또한 추적 가능성 및 버전 관리를 위한 데이터 및 모델 기준선의 거의 즉각적인 생성을 통합하는 AI, ML 및 DL 교육 워크플로우를 정의하고 구현하는 방법을 안내합니다. 이 솔루션을 사용하면 모든 모델 훈련을 다시 모델을 훈련 및/또는 검증하는 데 사용된 정확한 데이터 세트로 추적할 수 있습니다. 마지막으로, 이 문서에서는 방대한 데이터 세트에 액세스하여 Jupyter Notebook 작업 공간을 신속하게 프로비저닝하는 방법을 설명합니다.</block>
  <block id="3a8a3991c7ef251983bda0fd052b9b10" category="inline-link-macro">TR-4890</block>
  <block id="3cbee33bcafaf0315e821a3331b91eb5" category="inline-link-macro">NetApp의 완벽하게 지원되는 병렬 파일 시스템 솔루션인 BeeGFS</block>
  <block id="63de7cb3a054a3754335c60a0c8ba878" category="paragraph">참고: 동일한 데이터 세트에 대한 공유 액세스가 필요한 다수의 GPU 서버가 포함된 대규모 HPC 스타일 분산 교육이거나 병렬 파일 시스템이 필요하거나 선호한다면, 확인해 보십시오 <block ref="f82f3a4db7a848244fd5070f378c86fb" category="inline-link-macro-rx"></block>. 이 기술 보고서에서는 을 포함하는 방법을 설명합니다 <block ref="99c493838dffa23aa6d1149e33e3edf0" category="inline-link-macro-rx"></block> NetApp AI Control Plane의 일부로, 이 솔루션은 소수의 NVIDIA DGX A100 시스템에서 완전한 140개 노드 SuperPOD까지 확장하도록 설계되었습니다.</block>
  <block id="9f1cc947f3e0236f8d5bc32d8d33509a" category="inline-link">cloud.netapp.com</block>
  <block id="9d50c340b35848862ab6ecbdadc401ed" category="paragraph">NetApp AI Control Plane은 데이터 과학자 및 데이터 엔지니어를 대상으로 하므로 최소한의 NetApp 또는 NetApp ONTAP ® 전문 지식이 필요합니다. 이 솔루션에서는 단순하고 친숙한 툴과 인터페이스를 사용하여 데이터 관리 기능을 실행할 수 있습니다. 귀사 환경에 NetApp 스토리지가 이미 구축되어 있다면 지금 바로 NetApp AI Control Plane을 시험 구동할 수 있습니다. 솔루션을 시험하고 싶지만 NetApp 스토리지가 없는 경우, 를 방문하십시오<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>클라우드 기반 NetApp 스토리지 솔루션을 사용하여 몇 분 이내에 시스템을 구축하고 실행할 수 있습니다. 다음 그림은 솔루션을 시각적으로 보여 줍니다.</block>
  <block id="1f39acb56ba2a8669371819a64348c74" category="paragraph"><block ref="1f39acb56ba2a8669371819a64348c74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6dd86945b1681007efc06cd445661f24" category="inline-link-macro">다음: 개념 및 구성 요소.</block>
  <block id="742ed784bbf61aca3af793407a42b1f5" category="paragraph"><block ref="742ed784bbf61aca3af793407a42b1f5" category="inline-link-macro-rx"></block></block>
  <block id="dfcb1d1644aa3be367d0ca7761be62ad" category="summary">이 페이지에서는 Azure NetApp Files에 대해 위임된 서브넷을 생성하는 데 필요한 단계를 설명합니다.</block>
  <block id="d991c79e9311d59d4e38f3115d9c5b24" category="inline-link-macro">이전: AKS 클러스터를 설치하고 설정합니다.</block>
  <block id="5dd65debe44935eb5866a15b9a62237e" category="paragraph"><block ref="5dd65debe44935eb5866a15b9a62237e" category="inline-link-macro-rx"></block></block>
  <block id="8bffe528b31ee595be868b5a4af3d25a" category="paragraph">Azure NetApp Files에 대해 위임된 서브넷을 만들려면 다음 단계를 수행하십시오.</block>
  <block id="1aa0034de6393efa24703b8a479a5aa6" category="list-text">Azure 포털에서 가상 네트워크로 이동합니다. 새로 생성한 가상 네트워크를 찾습니다. AKS-VNET와 같은 접두사가 있어야 합니다.</block>
  <block id="f1621549bc319674bb9e859babb2a671" category="list-text">VNET의 이름을 클릭합니다.</block>
  <block id="c536871a8fac3a4390226f6e485cf662" category="paragraph"><block ref="c536871a8fac3a4390226f6e485cf662" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5025fbb3995af8640cab85f4f91126b" category="list-text">서브넷 을 클릭하고 상단 도구 모음에서 + 서브넷 을 클릭합니다.</block>
  <block id="22307856839205c5209cc8ce1f4ed0df" category="paragraph"><block ref="22307856839205c5209cc8ce1f4ed0df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e45b350630c9a3b31bf0c1a1f03dffb0" category="list-text">서브넷에는 ANF.SN과 같은 이름을 입력하고 Subnet Delegation 제목 아래에서 microsoft.Netapp/volumes` 을 선택합니다. 다른 어떤 것도 변경하지 마십시오. 확인 을 클릭합니다.</block>
  <block id="3621b1bf0075cb659f152966504dfc0d" category="paragraph"><block ref="3621b1bf0075cb659f152966504dfc0d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8034fc216ae23edc69bb75430f3de2f" category="paragraph">Azure NetApp Files 볼륨은 애플리케이션 클러스터에 할당되며 Kubernetes에서 영구 볼륨 청구(PVC)로 사용됩니다. 또한 이 프로세스를 통해 Jupyter 노트북, 서버리스 기능 등과 같은 다양한 서비스에 유연하게 매핑할 수 있습니다.</block>
  <block id="ac3654eb11c3b0cfc94c6c1abdc6767a" category="paragraph">서비스 사용자는 다양한 방법으로 플랫폼의 스토리지를 사용할 수 있습니다. 이 기술 보고서에서 NFS에 대해 설명함에 따라 Azure NetApp Files의 주요 이점은 다음과 같습니다.</block>
  <block id="42ba8b77b788a422a7e4ba2d8bb2d45e" category="list-text">사용자에게 스냅샷 복사본 사용 기능 제공</block>
  <block id="a51448debe1bbe5bb229b849d4057e09" category="list-text">사용자가 Azure NetApp Files 볼륨에 대량의 데이터를 저장할 수 있도록 지원</block>
  <block id="b7c10d399d058ef3538882e444459ba5" category="list-text">대규모 파일 세트에서 모델을 실행할 때 Azure NetApp Files 볼륨의 성능 이점을 사용합니다.</block>
  <block id="4b15c9979e20dd7eb0c0263e9d5ab1db" category="inline-link-macro">다음: 피어 AKS VNET 및 Azure NetApp Files VNET</block>
  <block id="a9f725be439e4752193d45f7e7f41851" category="paragraph"><block ref="a9f725be439e4752193d45f7e7f41851" category="inline-link-macro-rx"></block></block>
  <block id="e1490a61359279998443f8eab1c0483e" category="summary">이 페이지에는 분산형 또는 대규모 교육에서 Azure NetApp Files의 이점이 요약되어 있습니다.</block>
  <block id="b0de8e85db65da6381bb71646929daa6" category="doc">클릭률 예측 사용 사례 요약</block>
  <block id="d7550d336c660c27c3f1aa9ffdbc1e08" category="inline-link-macro">이전: 클라우드 리소스 요구사항</block>
  <block id="6a4fb77bb2a725598588e7db128b749b" category="paragraph"><block ref="6a4fb77bb2a725598588e7db128b749b" category="inline-link-macro-rx"></block></block>
  <block id="3f504d5ee520c44b83e5875afd3f2831" category="inline-link">테라바이트 로그를 클릭합니다</block>
  <block id="ce2803fd5e9b90b62d0792d13e715d11" category="inline-link">Criteo AI Lab을 참조하십시오</block>
  <block id="b622f3d3bde9c5202a2be0c23982e0b2" category="paragraph">이 사용 사례는 공개적으로 제공되는 를 기반으로 합니다<block ref="f00b4c49198828625540594bcd2c0e57" category="inline-link-rx"></block> 데이터 세트 시작<block ref="3ba217c046bd683ab55f300076736b4a" category="inline-link-rx"></block>. 최근 ML 플랫폼 및 애플리케이션의 발전으로 이제 대규모 학습에 많은 관심이 집중되고 있습니다. 클릭 비율(CTR)은 온라인 광고 노출 100회 당 평균 클릭 수(백분율로 표시)로 정의됩니다. 디지털 마케팅, 소매, 전자 상거래 및 서비스 공급자를 포함한 다양한 산업 및 사용 사례에서 핵심 메트릭으로 널리 채택되고 있습니다. CTR을 잠재적인 고객 트래픽에 대한 중요한 메트릭으로 사용하는 예는 다음과 같습니다.</block>
  <block id="d86cf69a8b82547a94ca3f6a307cf9a6" category="inline-link">Google 웹로그 분석</block>
  <block id="fe123d76ac9bec74ba2056b6a34fbf5d" category="inline-link">광고 순위</block>
  <block id="747d705222dc64c89cfadd75a9792b30" category="list-text">* 디지털 마케팅: * in<block ref="6c9e2e85af2f8f35c64de5000ebda91e" category="inline-link-rx"></block>, CTR은 광고주 또는 상인의 키워드, 광고 및 무료 리스팅이 얼마나 잘 수행되고 있는지 측정하는 데 사용할 수 있습니다. 높은 CTR은 사용자가 귀하의 광고 및 리스팅을 유용하고 관련성 있는 것으로 찾도록 하는 좋은 지표입니다. 또한 CTR은 의 구성 요소인 키워드의 예상 CTR에 기여합니다<block ref="428c3403a03510f9dc338448b285e764" category="inline-link-rx"></block>.</block>
  <block id="8a2e97f5a0cefdd4b76863bdd3773fb2" category="list-text">* 전자 상거래: * 활용은 물론<block ref="8785133d6074d4ab5f5345c36bc35a21" category="inline-link-rx"></block>전자 상거래 백엔드에는 최소 일부 방문자 통계가 있습니다. 이러한 통계는 한 눈에 유용하지 않을 수 있지만 일반적으로 읽기 쉽고 다른 정보보다 정확할 수 있습니다. 이러한 통계로 구성된 타사 데이터 세트는 독점 데이터이므로 전자 상거래 셀러, 구매자 및 플랫폼과 가장 관련이 있습니다. 이러한 데이터 세트는 추가 분석을 위해 시계시리즈를 구성하여 결과를 작년도와 어제와 비교하여 벤치마크 설정에 사용할 수 있습니다.</block>
  <block id="5737cd832bf93fd33459cf0a04787441" category="list-text">* 소매: * 오프라인 유통업체는 방문자 수와 고객 수를 CTR과 연관시킬 수 있습니다. 고객 수는 POS(Point of Sale) 기록에서 확인할 수 있습니다. 소매업체의 웹 사이트 또는 광고 트래픽에서 CTR을 사용하면 앞서 언급한 판매량이 발생할 수 있습니다. 로열티 프로그램은 온라인 광고나 다른 웹 사이트에서 리디렉션된 고객이 보상을 받기 위해 참여할 수 있기 때문에 또 다른 활용 사례입니다. 소매업체는 로열티 프로그램을 통해 고객을 확보하고 판매 기록에서 고객 행동을 기록하여 다양한 범주의 소비자 구매 행동을 예측할 뿐만 아니라 쿠폰을 개인화하고 이탈을 줄이는 추천 시스템을 구축할 수 있습니다.</block>
  <block id="32c14bcab423a033bf540425e236d3e6" category="list-text">* 서비스 공급자: * 통신 회사 및 인터넷 서비스 공급자는 통찰력 있는 AI, ML 및 분석 사용 사례를 위한 수많은 제3자 사용자 원격 측정 데이터를 보유하고 있습니다. 예를 들어, 통신 회사는 모바일 가입자의 웹 브라우징 최상위 도메인 기록 로그를 매일 활용하여 기존 모델을 세부 조정하여 최신 사용자 세분화, 고객 행동 예측, 온라인 경험 개선을 위한 실시간 광고 제작을 위해 광고업체와 협업할 수 있습니다. 이러한 데이터 중심 마케팅 워크플로에서 CTR은 변환을 반영하는 중요한 지표입니다.</block>
  <block id="78ae79f63f58a3ac75e77e3a075fd19e" category="inline-link">Criteo Terabyte 클릭 로그</block>
  <block id="deb698cbe7918324e2e1564708266732" category="paragraph">디지털 마케팅의 맥락에서<block ref="cc065865c19a3af4babfdf02c1c6b55d" category="inline-link-rx"></block> 이제 ML 플랫폼 및 알고리즘의 확장성을 평가하는 데 필요한 참조 데이터세트가 되었습니다. 광고주는 클릭 비율을 예측함으로써 광고에 반응할 가능성이 가장 높은 방문자를 선택하고, 검색 기록을 분석하고, 사용자의 관심사에 따라 가장 관련성이 높은 광고를 표시할 수 있습니다.</block>
  <block id="5f326be91a09bc93ca87444e834df2a6" category="paragraph">이 기술 보고서에 제공된 솔루션은 다음과 같은 이점을 제공합니다.</block>
  <block id="67ccf3c7c1e67c90000dfee83bab38ec" category="list-text">Azure NetApp Files는 분산 또는 대규모 교육에서 이점을 제공합니다</block>
  <block id="e15bc9f9b7a013d672cb689660ab9f9f" category="list-text">RAPIDS CUDA 지원 데이터 처리(cuDF, cuPy 등) 및 ML 알고리즘(cuML)</block>
  <block id="e150c8d445e71cda899957943e39b75f" category="list-text">분산 교육을 위한 Dask 병렬 컴퓨팅 프레임워크입니다</block>
  <block id="ec61531814ab09c5338813eecc764692" category="paragraph">RAPIDS AI 및 Azure NetApp Files를 기반으로 하는 엔드 투 엔드 워크플로우에서 랜덤 포리스트 모델 훈련 시간을 크게 두 배나 단축한 것으로 입증되었습니다. 이러한 개선은 매일 45GB의 구조화된 표 형식 데이터(평균)를 사용하여 실제 클릭 로그를 처리할 때 기존의 Pandas 접근 방식과 비교했을 때 매우 중요합니다. 이는 약 20억 개의 행이 포함된 DataFrame과 같습니다. 클러스터 환경 설정, 프레임워크 및 라이브러리 설치, 데이터 로드 및 처리, 기존 교육과 분산 교육 비교, 시각화 및 모니터링, 이 기술 보고서의 중요한 엔드 투 엔드 런타임 결과를 비교합니다.</block>
  <block id="3876b7e4b6a608a0b9001ae2e65c91b1" category="inline-link-macro">다음: AKS 클러스터를 설치하고 설정합니다.</block>
  <block id="2f0a1a89887d5c4f057724084bfdb718" category="paragraph"><block ref="2f0a1a89887d5c4f057724084bfdb718" category="inline-link-macro-rx"></block></block>
  <block id="0b7e964d1176d21b9ba3eceec8ed95ac" category="doc">개념 및 구성 요소</block>
  <block id="56dfbb2acffcc994819cbad5ec450617" category="paragraph">이 섹션에서는 ML 워크플로우에서 데이터 캐싱과 관련된 개념 및 구성 요소에 대해 설명합니다.</block>
  <block id="091fa9121c047db1dd48c3e2ab5f3c91" category="section-title">머신 러닝</block>
  <block id="d3f18dede1775f82df24232095090253" category="paragraph">ML은 전 세계 많은 기업과 조직에 빠르게 필수 요소가 되고 있습니다. 따라서, IT 및 DevOps 팀은 ML 워크로드 및 프로비저닝 클라우드, 온프레미스, 하이브리드 컴퓨팅 리소스를 표준화하여 ML 작업 및 파이프라인에 필요한 동적이고 집약적인 워크플로우를 지원해야 하는 과제에 직면해 있습니다.</block>
  <block id="f71dfff263d05c18171dcf4b8c538ebf" category="section-title">컨테이너 기반 머신 러닝 및 Kubernetes</block>
  <block id="002f314c3c41ffb741f8c91d2274af9a" category="paragraph">컨테이너는 공유 호스트 운영 체제 커널 위에서 실행되는 격리된 사용자 공간 인스턴스입니다. 컨테이너 채택이 빠르게 증가하고 있습니다. 컨테이너는 가상 머신(VM)이 제공하는 것과 동일한 애플리케이션 샌드박스(sandbox)의 많은 이점을 제공합니다. 하지만 VM이 사용하는 하이퍼바이저 및 게스트 운영 체제 계층이 없어졌기 때문에 컨테이너는 훨씬 더 가볍습니다.</block>
  <block id="91945d3c9ebb2261142b9c7fc516b559" category="inline-link">Docker 웹 사이트</block>
  <block id="ce8bb3a31abf8bfcdcdacb34d96b010a" category="paragraph">또한 컨테이너를 사용하면 애플리케이션 종속성, 실행 시간 등을 애플리케이션과 직접 효율적으로 패키징할 수 있습니다. 가장 일반적으로 사용되는 컨테이너 패키징 형식은 Docker 컨테이너입니다. Docker 컨테이너 형식으로 컨테이너화된 애플리케이션은 Docker 컨테이너를 실행할 수 있는 모든 시스템에서 실행할 수 있습니다. 모든 종속성이 컨테이너 자체에 패키지되어 있기 때문에 응용 프로그램의 종속성이 컴퓨터에 없는 경우에도 마찬가지입니다. 자세한 내용은 를 참조하십시오<block ref="5b5112034c22f544bc19c7a568afbfcb" category="inline-link-rx"></block>.</block>
  <block id="1304134d4f70b5d09af5fb5a8bda1de8" category="inline-link">Kubernetes 웹 사이트</block>
  <block id="cfbe31a3e8ac3348240670510232ed8f" category="paragraph">데이터 과학자는 널리 사용되는 컨테이너 오케스트레이터인 Kubernetes를 사용하여 유연한 컨테이너 기반 작업 및 파이프라인을 시작할 수 있습니다. 또한 인프라 팀이 단일 관리형 클라우드 네이티브 환경에서 ML 워크로드를 관리하고 모니터링할 수 있습니다. 자세한 내용은 를 참조하십시오<block ref="45556eaecf73275e38fa694031a104a3" category="inline-link-rx"></block>.</block>
  <block id="e5e8ab661917b89b4161959c7dc28442" category="section-title">cnvrg.io</block>
  <block id="371ac536e4099ad82f6080b713ce9647" category="paragraph">cnvrg.io는 AI 및 데이터 과학 개발의 관리, 확장 및 속도를 연구에서 운영으로 전환하는 AI 운영 체제입니다. 데이터 과학자가 코드 우선 플랫폼을 구축하고 사내 또는 클라우드에서 유연하게 실행할 수 있습니다. 모델 관리, MLOps 및 지속적인 ML 솔루션을 통해 cnvrg.IO는 데이터 과학 팀에 최고의 기술을 제공하므로 DevOps에 더 적은 시간을 할애하고 진정한 마법인 알고리즘에 집중할 수 있습니다. cnvrg.io를 사용한 이후, 여러 산업 분야의 팀들이 생산 모델에 더 많은 모델을 투입하여 비즈니스 가치를 증대하고 있습니다.</block>
  <block id="ffb1d184fa3790eda48f1fc2d9c2f821" category="section-title">cnvrg.io 메타 스케줄러</block>
  <block id="55fdc117823776b1ebb2170b4adfadf6" category="paragraph">cnvrg IO는 IT와 엔지니어가 서로 다른 컴퓨팅 리소스를 동일한 제어 평면에 연결하고 cnvrg.io를 사용하여 모든 리소스에 걸쳐 ML 작업을 관리할 수 있는 고유한 아키텍처를 가지고 있습니다. 즉, 다음 그림과 같이 여러 온프레미스 Kubernetes 클러스터, VM 서버 및 클라우드 계정을 연결하고 모든 리소스에서 ML 워크로드를 실행할 수 있습니다.</block>
  <block id="3c7fcf7e73eda18d7277b14914857f38" category="paragraph"><block ref="3c7fcf7e73eda18d7277b14914857f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cfff0196a077e92a8fe9326f97cb7fc5" category="section-title">cnvrg.io 데이터 캐싱</block>
  <block id="ad693e5ee82f0e0486a136821d0a0779" category="paragraph">데이터 과학자는 cnvrg.io를 사용하여 데이터 캐싱 기술을 통해 핫 데이터 세트 및 콜드 데이터 세트 버전을 정의할 수 있습니다. 기본적으로 데이터 세트는 중앙 집중식 오브젝트 스토리지 데이터베이스에 저장됩니다. 그런 다음 데이터 과학자는 선택한 컴퓨팅 리소스에 특정 데이터 버전을 캐시하여 다운로드 시간을 줄이고 ML 개발 및 생산성을 향상시킬 수 있습니다. 캐싱되고 며칠 동안 사용되지 않는 데이터 세트는 선택한 NFS에서 자동으로 지워집니다. 한 번의 클릭으로 캐시 캐싱 및 지우기를 수행할 수 있으며 코딩, IT 또는 DevOps 작업이 필요하지 않습니다.</block>
  <block id="42cf1b27f88752e1e98918981aa76e41" category="section-title">cnvrg.io는 플로우 및 ML 파이프라인</block>
  <block id="1bc2ab6c98ec5b23a8a384861da1c6ca" category="paragraph">cnvrg.IO Flows는 생산 ML 파이프라인을 구축하기 위한 도구입니다. 플로우의 각 구성 요소는 기본 Docker 이미지를 사용하여 선택한 컴퓨팅에서 실행되는 스크립트/코드입니다. 이 설계를 통해 데이터 과학자와 엔지니어가 사내 및 클라우드에서 모두 실행할 수 있는 단일 파이프라인을 구축할 수 있습니다. cnvrg.io는 데이터, 매개 변수 및 아티팩트가 서로 다른 구성 요소 간에 이동하고 있는지 확인합니다. 또한 각 흐름을 모니터링하고 추적하여 100% 재현성 있는 데이터 과학을 제공합니다.</block>
  <block id="87cd11047488d3aa87eb2829eeb02305" category="section-title">cnvrg.io 코어</block>
  <block id="526c8ebff3057ce85f47160f32e15556" category="paragraph">cnvrg.io core는 데이터 과학자가 DevOps에 초점을 맞추는 데 도움을 주기 위해 데이터 과학 커뮤니티를 위한 무료 플랫폼입니다. Core의 유연한 인프라를 통해 데이터 과학자는 온프레미스 또는 클라우드 등 어떤 언어, AI 프레임워크 또는 컴퓨팅 환경이라도 사용할 수 있으므로 가장 잘하는 일을 하고 알고리즘을 구축할 수 있습니다. cnvrg.io 코어는 모든 Kubernetes 클러스터에서 단일 명령으로 간편하게 설치할 수 있습니다.</block>
  <block id="f92894a2a2633c488de71d74ace474d7" category="paragraph">ONTAP AI는 NetApp AFF 스토리지 시스템 및 NVIDIA DGX 시스템과 Tesla V100 GPU를 사용하는 ML 및 딥 러닝(DL) 워크로드를 위한 데이터 센터 참조 아키텍처입니다. ONTAP AI는 100Gb 이더넷을 통한 산업 표준 NFS 파일 프로토콜을 기반으로 하며, 표준 데이터 센터 기술을 사용하여 구현 및 관리 오버헤드를 줄이는 고성능 ML/DL 인프라를 고객에게 제공합니다. 표준화된 네트워크 및 프로토콜을 사용하여 ONTAP AI를 하이브리드 클라우드 환경에 통합하는 동시에 운영 일관성과 단순성을 유지할 수 있습니다. 사전 검증된 인프라 솔루션인 ONTAP AI를 사용하면 구축 시간과 위험을 줄이고 관리 오버헤드를 크게 줄여 고객이 투자 회수 시간을 단축할 수 있습니다.</block>
  <block id="47bbe104ad41e6af2ee0dba5dc76d74d" category="inline-link">DeepOps 웹 사이트</block>
  <block id="b1c5aef0d1e7ec0339ca5caa48c1b3e3" category="paragraph">DeepOps는 NVIDIA의 오픈 소스 프로젝트로, Ansible을 사용하여 GPU 서버 클러스터를 모범 사례에 따라 자동으로 구축합니다. DeepOps는 모듈식이며 다양한 배포 작업에 사용할 수 있습니다. 이 문서와 이 문서에서 설명하는 검증 연습에서는 GPU 서버 작업자 노드로 구성된 Kubernetes 클러스터를 배포하는 데 DeepOps를 사용합니다. 자세한 내용은 를 참조하십시오<block ref="640792bfd91bad987ba8fd5d776a2824" category="inline-link-rx"></block>.</block>
  <block id="6ea70a0ecace7daa9dfbbc8ff3282de1" category="inline-link">Trident 웹 사이트</block>
  <block id="c2148c4c14a795b271b67f662900da4e" category="paragraph">Trident는 NetApp에서 개발 및 유지 관리하는 오픈 소스 스토리지 오케스트레이터로서 Kubernetes 워크로드를 위한 영구 스토리지의 생성, 관리 및 사용을 크게 단순화합니다. Trident 자체 Kubernetes 네이티브 애플리케이션 - Kubernetes 클러스터 내에서 직접 실행됩니다. Trident를 사용하면 Kubernetes 사용자(개발자, 데이터 과학자, Kubernetes 관리자 등)가 이미 익숙한 표준 Kubernetes 형식으로 영구 스토리지 볼륨을 생성, 관리 및 상호 작용할 수 있습니다. 이와 동시에 NetApp 기술에서 제공하는 NetApp 고급 데이터 관리 기능과 Data Fabric을 활용할 수 있습니다. Trident는 영구 스토리지의 복잡성을 추상화하여 사용이 간편합니다. 자세한 내용은 를 참조하십시오<block ref="c98bfcab9052a99136f8752a5ac8ed0b" category="inline-link-rx"></block>.</block>
  <block id="55cf1a0f0fce69fd543500e5761dd26d" category="section-title">NetApp StorageGRID를 참조하십시오</block>
  <block id="ecfefbd82f34239e668be7aac3762226" category="paragraph">NetApp StorageGRID는 사용자가 S3 프로토콜을 통해 액세스할 수 있는 간단하고 클라우드식 스토리지를 제공하여 이러한 요구를 충족하도록 설계된 소프트웨어 정의 오브젝트 스토리지 플랫폼입니다. StorageGRID는 인터넷에 연결된 사이트에서 거리에 관계없이 여러 노드를 지원하도록 설계된 스케일아웃 시스템입니다. StorageGRID의 지능형 정책 엔진을 사용하여 지리적 복원력을 위해 사이트 전체에서 오브젝트를 삭제 코딩하거나 원격 사이트 간에 오브젝트 복제를 선택하여 WAN 액세스 지연 시간을 최소화할 수 있습니다. StorageGRID은 이 솔루션에서 탁월한 프라이빗 클라우드 1차 오브젝트 스토리지 데이터 레이크를 제공합니다.</block>
  <block id="0f0b99ea2f70cd363c2c6a279f74e760" category="section-title">NetApp Cloud Volumes ONTAP를 참조하십시오</block>
  <block id="c060a6548f860aa739b76c0178ac7c5c" category="paragraph">NetApp Cloud Volumes ONTAP 데이터 관리 소프트웨어는 AWS, Google Cloud Platform 및 Microsoft Azure를 비롯한 퍼블릭 클라우드 공급자의 유연성을 통해 사용자 데이터에 제어, 보호 및 효율성을 제공합니다. Cloud Volumes ONTAP은 NetApp ONTAP 스토리지 소프트웨어를 기반으로 하는 클라우드 네이티브 데이터 관리 소프트웨어로, 클라우드 데이터 요구사항을 해결하는 뛰어난 범용 스토리지 플랫폼을 제공합니다. 클라우드와 사내에서 동일한 스토리지 소프트웨어를 사용하는 사용자는 새로운 데이터 관리 방법을 통해 IT 직원을 교육하지 않고도 Data Fabric의 가치를 실현할 수 있습니다.</block>
  <block id="e16f1943a363dfa46a958bd450c2ecf8" category="paragraph">하이브리드 클라우드 구현 모델에 관심 있는 고객을 위해 Cloud Volumes ONTAP은 대부분의 퍼블릭 클라우드에서 동일한 기능과 동급 최고의 성능을 제공하여 어떠한 환경에도 일관되고 원활한 사용자 경험을 제공할 수 있습니다.</block>
  <block id="2d52bcd2e896c32a66c9fe10fed38e0f" category="inline-link-macro">다음: 하드웨어 및 소프트웨어 요구 사항</block>
  <block id="82ac5cdab15b3954389238dddbc12168" category="paragraph"><block ref="82ac5cdab15b3954389238dddbc12168" category="inline-link-macro-rx"></block></block>
  <block id="0dff6955889d5634f0212efb574ef815" category="doc">클릭률 예측 데이터 처리 및 모델 교육을 통해</block>
  <block id="3642f282b12269091ab196a3aabf0858" category="summary">Trident 작업의 예</block>
  <block id="7f41e102595a65d30401b887b75060a4" category="paragraph">이 섹션에는 Trident를 사용하여 수행할 수 있는 다양한 작업의 예가 포함되어 있습니다.</block>
  <block id="5a95bc44d2d93c77b65585a52a71d631" category="section-title">기존 볼륨을 가져옵니다</block>
  <block id="37e60d34ab15afa59aac0989309fc77a" category="paragraph">Kubernetes 클러스터 내의 컨테이너에 마운트할 NetApp 스토리지 시스템/플랫폼에 기존 볼륨이 있지만, 클러스터의 PVC와 연결되지 않은 경우 이러한 볼륨을 가져와야 합니다. Trident 볼륨 가져오기 기능을 사용하여 이러한 볼륨을 가져올 수 있습니다.</block>
  <block id="4330c34147b36030c50afe1d04ec2213" category="paragraph">다음 예제 명령은 섹션의 예에서 생성된 각 Trident 백엔드에 대해 동일한 볼륨("PB_FG_ALL"이라는 이름)을 두 번 가져오는 것을 보여 줍니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 1단계. 같은 볼륨을 이러한 방식으로 두 번 가져오면 섹션에 설명된 대로 여러 LIF에서 볼륨(기존 FlexGroup 볼륨)을 여러 번 마운트할 수 있습니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 1단계. PVC에 대한 자세한 내용은 를 참조하십시오<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>. 볼륨 가져오기 기능에 대한 자세한 내용은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="313da63dfeb95842dd6a105fdcf40ebc" category="paragraph">예제 PVC 규격 파일에는 'ReadOnlyMany'의 'accessModes' 값이 지정되어 있습니다. 'accessMode' 필드에 대한 자세한 내용은 를 참조하십시오<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="6631bf64346739a9880a9789a941a8d6" category="inline-link-macro">ONTAP AI 구축을 위한 Kubernetes StorageClasses의 예</block>
  <block id="e6d82e60d43fe02e01930addfe670e8f" category="admonition">다음 가져오기 명령에 지정된 백엔드 이름은 섹션의 예제에서 생성한 백엔드에 해당합니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 1단계. 다음 예제 PVC 정의 파일에 지정된 StorageClass 이름은 섹션의 예제에서 만든 StorageClasses에 해당합니다 <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, 1단계.</block>
  <block id="533fff63e0b7486b2768ad15b5e2981c" category="section-title">새 볼륨을 프로비저닝합니다</block>
  <block id="e149d2e1fdb31ad28f79dd3d2c7ee8ff" category="paragraph">Trident를 사용하여 NetApp 스토리지 시스템 또는 플랫폼에서 새 볼륨을 프로비저닝할 수 있습니다. 다음 명령 예에서는 새 FlexVol 볼륨의 프로비저닝을 보여 줍니다. 이 예제에서는 섹션의 예제에서 만든 StorageClass 를 사용하여 볼륨을 프로비저닝합니다 <block ref="6d8c8eb29a4e4c3a50119b70d2e8171e" category="inline-link-macro-rx"></block>, 2단계.</block>
  <block id="78b7c8c28867630a421236d6f1ff9ba3" category="paragraph">다음 PVC 정의 파일에는 ReadWriteMany 의 accessModes 값이 지정되어 있습니다. 'accessMode' 필드에 대한 자세한 내용은 를 참조하십시오<block ref="ca589c3cf5b20ae0a636e2b7691f2873" category="inline-link-rx"></block>.</block>
  <block id="c515da31cebf8cf63b394c59f3f5f2c0" category="inline-link-macro">다음: ONTAP AI 배포에 대한 고성능 작업 예 개요</block>
  <block id="5c11e6d83807487f2c41bd48dc524734" category="paragraph"><block ref="5c11e6d83807487f2c41bd48dc524734" category="inline-link-macro-rx"></block></block>
  <block id="60f89129c6220bfb3de5a84b4f6471ca" category="summary">이 페이지에서는 Pandas 및 Dask DataFrames를 사용하여 Criteo Terabyte 데이터 세트에서 Click Logs 데이터를 로드하는 방법을 설명합니다. 이 사용 사례는 광고 교환을 위한 디지털 광고에서 광고 클릭 여부를 예측하여 사용자의 프로필을 작성하는 데 사용됩니다. 또한 교환에서 자동화된 파이프라인에서 정확한 모델을 사용하지 않는 경우도 해당됩니다.</block>
  <block id="efdbc2f24f0a87c559175250c645b26b" category="doc">Pandas에서 Logs day 15를 로드하여 좌골키트을 훈련합니다. 무작위 포리스트 모델을 학습하십시오</block>
  <block id="2979440f06f7cfcab78b9a92ca964f28" category="inline-link-macro">이전: 데이터 처리 및 모델 훈련을 위한 라이브러리.</block>
  <block id="f2982e3861753bd206faa379a769d904" category="paragraph"><block ref="f2982e3861753bd206faa379a769d904" category="inline-link-macro-rx"></block></block>
  <block id="f82859e215621220b9aae984f796ef24" category="paragraph">이 섹션에서는 Pandas 및 Dask DataFrames를 사용하여 Criteo Terabyte 데이터 세트에서 Click Logs 데이터를 로드하는 방법을 설명합니다. 이 사용 사례는 광고 교환을 위한 디지털 광고에서 광고 클릭 여부를 예측하여 사용자의 프로필을 작성하는 데 사용됩니다. 또한 교환에서 자동화된 파이프라인에서 정확한 모델을 사용하지 않는 경우도 해당됩니다.</block>
  <block id="f08833dbbe310e84a1ba564838776db2" category="paragraph">Click Logs 데이터 세트에서 15일차 데이터를 로드하여 총 45GB를 기록했습니다. Jupyter Notebook CTR-PandasRF-Collated에서 다음 셀을 실행하면 처음 5000만 개의 행이 포함된 Pandas DataFrame을 생성하고 좌골키트학습 무작위 포리스트 모델을 생성합니다.</block>
  <block id="f9964b2f8f54a1422ac46bab70fd1216" category="inline-link">공식 좌골 키트 - 학습 문서</block>
  <block id="5646953e1414498e1ddf2eb3ab488e27" category="paragraph">훈련된 무작위 포리스트 모델을 사용하여 예측을 수행하려면 이 전자 필기장에서 다음 단락을 실행하십시오. 중복을 피하기 위해 15일째부터 마지막 100만 행을 테스트 세트로 테스트했습니다. 또한 이 셀은 예측의 정확도를 계산하고, 사용자가 광고를 클릭하는지 여부를 모델이 정확하게 예측한 발생 비율로 정의됩니다. 이 노트북에서 잘 모르는 구성 요소를 검토하려면 을 참조하십시오<block ref="27e4d9ca2442a6439517a3ec2c7a4e73" category="inline-link-rx"></block>.</block>
  <block id="4e5653c75e720212b79703e8083de2a8" category="inline-link-macro">다음: Dask에서 Day 15를 로드하여 Dask cuML 무작위 포리스트 모델을 교육합니다.</block>
  <block id="8c9976282cff1b15934d937349911c30" category="paragraph"><block ref="8c9976282cff1b15934d937349911c30" category="inline-link-macro-rx"></block></block>
  <block id="1e48409a293254dced52407be3dbb722" category="doc">Jarvis, Cloud Sync 및 Nemo를 사용하여 가상 도우미를 빌드합니다</block>
  <block id="68dc442228015e015ca6272edb5994e4" category="inline-link-macro">다음: Jarvis, Cloud Sync 및 Nemo 개요를 사용하여 가상 도우미를 만듭니다</block>
  <block id="f308b9afc8e29196ebb4fe535e29fc51" category="paragraph"><block ref="f308b9afc8e29196ebb4fe535e29fc51" category="inline-link-macro-rx"></block></block>
  <block id="ccc33823c0dc5e9ee0838a5eaa86f076" category="doc">섹션 4.9의 테스트 세부 정보</block>
  <block id="c83553858a60514501e9751c0747dea0" category="inline-link-macro">기본 자원 할당 공정성</block>
  <block id="ed8e4613850a4014b0e6ef830982caf2" category="paragraph">이 섹션에서는 섹션에 대한 테스트 세부 정보를 다룹니다 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>.</block>
  <block id="f354c9a7a0a52e7a5a3514252ea5f8b7" category="paragraph">다음 순서로 작업을 제출합니다.</block>
  <block id="17b3673d5c28fb72e7cc48549f489dd4" category="cell">6/8</block>
  <block id="ffe090618e54b7916fa47cf8881019b1" category="cell">팀-b/c 워크로드가 일시 중지되고 "보류 중"으로 이동합니다.</block>
  <block id="bccfe4ac65004fb31c146d17003d00e8" category="cell">다른 팀(b/c)의 워크로드는 일시 중지되고 "보류 중"으로 이동합니다.</block>
  <block id="3b099141b6a7e4e8804c3fda5ed4f440" category="paragraph">섹션을 참조하십시오 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block> 진행 중인 테스트 시나리오에 대한 논의.</block>
  <block id="5d52789e4f8028aca21d5650bed8273b" category="inline-link-macro">다음: 섹션 4.10의 테스트 세부 정보</block>
  <block id="61a1556247485f1d0fbb34dbe36d1503" category="paragraph"><block ref="61a1556247485f1d0fbb34dbe36d1503" category="inline-link-macro-rx"></block></block>
  <block id="01360221b637a04fa184dc6b9355fa46" category="summary">우리는 이 솔루션 작성의 일부로 간단한 성능 비교를 수행했습니다. Kubernetes를 사용하여 몇 가지 표준 NetApp 벤치마킹 작업을 실행했고, 단순한 Docker 실행 명령을 사용하여 수행한 실행과 벤치마크 결과를 비교했습니다.</block>
  <block id="0e2f0f77407bfd956f621e13b8c1be34" category="doc">성능 테스트</block>
  <block id="467941822b3a557a8db7197e12285f14" category="paragraph">우리는 이 솔루션 작성의 일부로 간단한 성능 비교를 수행했습니다. Kubernetes를 사용하여 몇 가지 표준 NetApp AI 벤치마킹 작업을 실행했으며, 단순한 Docker 실행 명령을 사용하여 수행한 실행과 벤치마크 결과를 비교했습니다. 뚜렷한 성능 차이는 없었습니다. 따라서, 컨테이너화된 AI 교육 작업을 오케스트레이션하기 위해 Kubernetes를 사용할 경우 성능에 부정적인 영향을 미치지 않는다는 결론을 내렸습니다. 성능 비교 결과는 다음 표를 참조하십시오.</block>
  <block id="74575b23d5305310e904f87eb02ff980" category="cell">벤치마크</block>
  <block id="239658e016e3d5d06ae719d280a79fec" category="cell">데이터 세트</block>
  <block id="c269688995d2959579fca276425898b8" category="cell">Docker 실행(이미지/초)</block>
  <block id="b3acbf223e2bb7a3a796e3b698a7748d" category="cell">Kubernetes(이미지/초)</block>
  <block id="6de4dbc350a60fb9d5ea80ac7854681d" category="cell">단일 노드 TensorFlow</block>
  <block id="2ec7cdace40d8a092e842288dfe854f7" category="cell">합성 데이터</block>
  <block id="a5ee9f5535788c17b947b7f2d8354351" category="cell">6,667.2475</block>
  <block id="b573d76a35b8d44de29524f11e873c60" category="cell">6,661.93125</block>
  <block id="b318879f822314efe94c2f096d06465c" category="cell">ImageNet</block>
  <block id="f9622443c76d58838af97acd4f0c12ed" category="cell">6,570.2025</block>
  <block id="f93ed9c22230ae6e2ed85323e8d3dff7" category="cell">6,530.59125</block>
  <block id="83817408eae44458daefc1a9516ad170" category="cell">동기식 분산 2노드 TensorFlow</block>
  <block id="d4b63997154f30598f823403bb4df7ba" category="cell">13,213.70625</block>
  <block id="a328a929a422e4b69be5bbe94694282e" category="cell">13,218.288125</block>
  <block id="209f721713f475a9a0f4ba2743b40853" category="cell">12,941.69125</block>
  <block id="1f07dab13107a813c6d35bb76648ec48" category="cell">12,881.33875</block>
  <block id="68cba59815f152ec72363e2495bab8d2" category="paragraph"><block ref="68cba59815f152ec72363e2495bab8d2" category="inline-link-macro-rx"></block></block>
  <block id="0de039e647bc53dcce6e7bceb8605cbf" category="paragraph">모든 규모와 업종에 상관없이 모든 기업과 조직은 실제 문제를 해결하고 혁신적인 제품과 서비스를 제공하며 경쟁이 갈수록 치열해지는 시장에서 경쟁 우위를 확보하기 위해 인공 지능(AI), 머신 러닝(ML), 딥 러닝(DL)으로 눈을 돌리고 있습니다. AI, ML 및 DL의 사용이 증가함에 따라 워크로드 확장성 및 데이터 가용성을 비롯한 많은 과제에 직면하게 됩니다. 이러한 문제는 NetApp AI Control Plane 솔루션을 사용하여 해결할 수 있습니다.</block>
  <block id="cae02473f4798da0fdd40f4f598b1d96" category="paragraph">이 솔루션을 사용하면 데이터 네임스페이스를 빠르게 클론 복제할 수 있습니다. 또한 추적 가능성 및 버전 관리를 위한 데이터 및 모델 기준선의 거의 즉각적인 생성을 통합하는 AI, ML 및 DL 교육 워크플로우를 정의하고 구현할 수 있습니다. 이 솔루션을 사용하면 모든 단일 모델 교육을 모델이 훈련 및/또는 검증을 거친 정확한 데이터 세트로 추적할 수 있습니다. 끝으로, 이 솔루션을 사용하면 방대한 데이터 세트에 액세스할 수 있는 Jupyter Notebook 작업 공간을 신속하게 프로비저닝할 수 있습니다.</block>
  <block id="696dba9a093d4ac7b67234745dd57835" category="paragraph">이 솔루션은 데이터 과학자 및 데이터 엔지니어들을 대상으로 하기 때문에 최소한의 NetApp 또는 NetApp ONTAP 전문 지식이 필요합니다. 이 솔루션에서는 단순하고 친숙한 툴과 인터페이스를 사용하여 데이터 관리 기능을 실행할 수 있습니다. 또한 이 솔루션은 완전한 오픈 소스 및 무료 구성 요소를 활용합니다. 따라서 환경에 NetApp 스토리지가 이미 있는 경우 지금 이 솔루션을 구현할 수 있습니다. 이 솔루션을 시험하고 싶지만 NetApp 스토리지가 없는 경우 를 방문하십시오<block ref="d72e38e0d1c5ca8869f2dd987734920b" category="inline-link-rx"></block>또한 클라우드 기반 NetApp 스토리지 솔루션을 사용하여 시스템을 신속하게 가동할 수 있습니다.</block>
  <block id="0a37acabf89826767b5a5fcb8dacffa3" category="summary">이 페이지에서는 Kubernetes 클러스터에 Kubeflow를 구축하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="e560b8ed748180150ee1a196f2247fce" category="paragraph">이 섹션에서는 Kubernetes 클러스터에 Kubeflow를 구축하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="f48269a81318d4bd2dd9e57a8239fe56" category="list-text">Kubernetes 작업 클러스터가 이미 있으며, Kubeflow에서 지원하는 Kubernetes 버전을 실행하고 있습니다. 지원되는 버전 목록은 를 참조하십시오<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>.</block>
  <block id="3429b7e0331de8d2f8d377b034ca6855" category="inline-link-macro">Trident 구축 및 구성</block>
  <block id="9fc644d78f21555decceeddf5b691fa4" category="list-text">에 설명된 대로 Kubernetes 클러스터에 NetApp Trident를 이미 설치 및 구성했습니다 <block ref="ec7700e2b8d95edf2f2700b590eab273" category="inline-link-macro-rx"></block>.</block>
  <block id="72727333279dd1f9e8b63f969075bca8" category="section-title">기본 Kubernetes StorageClass를 설정합니다</block>
  <block id="e1be30d98edccc10974d5d339832197c" category="paragraph">Kubeflow를 구현하기 전에 Kubernetes 클러스터 내에서 기본 StorageClass를 지정해야 합니다. Kubeflow 배포 프로세스에서는 기본 StorageClass를 사용하여 새 영구 볼륨의 프로비저닝을 시도합니다. 기본 StorageClass로 지정된 StorageClass가 없으면 배포가 실패합니다. 클러스터 내에서 기본 StorageClass를 지정하려면 배포 점프 호스트에서 다음 작업을 수행합니다. 클러스터 내에서 기본 StorageClass를 이미 지정한 경우에는 이 단계를 건너뛸 수 있습니다.</block>
  <block id="e3e4fbe325df2b20670ca04ad0c2a517" category="list-text">기존 StorageClasses 중 하나를 기본 StorageClass로 지정합니다. 다음 명령을 실행하면 기본 StorageClass로 ONTAP-ai-FlexVols-Retain이라는 StorageClass가 지정됩니다.</block>
  <block id="f830a6eea70ae3a0e7af4606462ad281" category="admonition">ONTAP-NAS-Flexgroup Trident 백엔드 유형은 PVC 크기가 매우 큽니다. 기본적으로 Kubeflow는 크기가 몇 GB인 PVC를 프로비저닝하려고 시도합니다. 따라서 Kubeflow 구축을 위해 "ONTAP-NAS-flexgroup" 백엔드 유형을 기본 StorageClass로 사용하는 StorageClass를 지정할 수 없습니다.</block>
  <block id="f12aad36b1ab9194dd8bc67542366bff" category="section-title">NVIDIA DeepOps를 사용하여 Kubeflow를 배포합니다</block>
  <block id="3e1922d78dd7bdb1e8d7e7bd8f5aa92c" category="paragraph">NVIDIA DeepOps에서 제공하는 Kubeflow 구현 툴을 사용할 것을 권장합니다. DeepOps 구축 툴을 사용하여 Kubernetes 클러스터에 Kubeflow를 배포하려면 배포 점프 호스트에서 다음 작업을 수행합니다.</block>
  <block id="7586dbf5f3ac1a66383f6c201a17a341" category="inline-link">설치 지침</block>
  <block id="3ede8bc1f55c95b9a16b2429e0b9bbcc" category="admonition">또는 에 따라 Kubeflow를 수동으로 배포할 수도 있습니다<block ref="c75d7e23bc80ca81cea11fe427173cb3" category="inline-link-rx"></block> 공식 Kubeflow 문서에서 제공됩니다</block>
  <block id="a73d6d865f72179145299c720c53d39c" category="inline-link">Kubeflow 구축 지침</block>
  <block id="04e3c704baa1b4c23cd48a18c10fcf39" category="list-text">에 따라 클러스터에 Kubeflow를 구현합니다<block ref="5e7f04c1dfa70dd058d2720be031c44b" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="2efdbab31c5d41a149e5092f4b8d7e48" category="list-text">DeepOps Kubeflow 구현 도구에서 출력하는 Kubeflow 대시보드 URL을 기록합니다.</block>
  <block id="b714a06d49f16f8b7f988d95734d177f" category="list-text">Kubeflow 네임스페이스 내에 배포된 모든 Pod에 'Running'이라는 'Status'가 표시되는지 확인하고 네임스페이스 내에 배포된 구성 요소가 오류 상태에 있지 않은지 확인합니다. 모든 Pod를 시작하는 데 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="d6049afd6b1943d1e98ca6347dd907c5" category="list-text">웹 브라우저에서 2단계에서 기록해 둔 URL로 이동하여 Kubeflow 중앙 대시보드에 액세스합니다.</block>
  <block id="64f559cf2e77f73aca6bd3dc9649f62c" category="paragraph">기본 사용자 이름은 admin@kubeflow.org, 기본 암호는 12341234입니다. 추가 사용자를 생성하려면 의 지침을 따르십시오<block ref="f529217f090b2c9cc3764f14abdec5f7" category="inline-link-rx"></block>.</block>
  <block id="2d84920115f9dc91fe2d35c4dc07eaf0" category="paragraph"><block ref="2d84920115f9dc91fe2d35c4dc07eaf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="defd49beb1345ee37b446e866e8b3420" category="inline-link-macro">다음: Kubeflow 작업 및 작업 예</block>
  <block id="2ecf31480279823ef2aed30a0fc061f2" category="paragraph"><block ref="2ecf31480279823ef2aed30a0fc061f2" category="inline-link-macro-rx"></block></block>
  <block id="e1196fc000d661461f32bcaab7319c6a" category="doc">소매 사용 사례에 대한 상태 및 흐름을 사용자 지정합니다</block>
  <block id="1e3ecab57c1572b4a25412b1e395562a" category="paragraph">특정 사용 사례에 맞게 Dialog Manager의 상태 및 흐름을 사용자 지정할 수 있습니다. 당사의 소매 예시에서 다음과 같은 네 가지 YAML 파일이 다양한 인도에 따라 대화를 유도합니다.</block>
  <block id="608f6d7dfd7bc98630446f0c601cc730" category="paragraph">다음 파일 이름 목록과 각 파일에 대한 설명을 따르십시오.</block>
  <block id="77d10e2958e3d21f89adae8647e8d0d2" category="list-text">main_flow.yml: 주요 대화의 흐름과 상태를 정의하고 필요에 따라 다른 3개의 YAML 파일로 흐름을 안내합니다.</block>
  <block id="96b445ea5c6b049dfc1250466b6bdf2e" category="list-text">RETail_flow.yml: 소매 또는 관심 지점 질문과 관련된 주가 포함되어 있습니다. 시스템은 가장 가까운 매장의 정보 또는 지정된 품목의 가격을 제공합니다.</block>
  <block id="17a0ea5055e6be908d7e2f6f983aa471" category="list-text">날씨 흐름.yml: 날씨 문제와 관련된 주가 포함되어 있습니다. 위치를 확인할 수 없는 경우 시스템은 추가 질문을 통해 명확히 합니다.</block>
  <block id="ade7d8cc2b23f24add45c4096dd41795" category="list-text">error_flow.yml: 위의 3가지 YAML 파일에 포함되지 않는 경우를 처리합니다. 오류 메시지를 표시한 후 시스템은 사용자 질문 수락으로 다시 라우팅합니다. 다음 섹션에는 이러한 YAML 파일에 대한 자세한 정의가 나와 있습니다.</block>
  <block id="ef7c28f5093b59a07761555c8914df26" category="section-title">Main_flow.yml</block>
  <block id="dfc9a806326d590aa4ccf49aa6909cda" category="section-title">retail_flow.yml</block>
  <block id="6e08d9d65c68d5f447f4fd239052c12e" category="section-title">WATEER_flow.yml</block>
  <block id="b7dc1d2ced2caa9352158983c5ffeda1" category="section-title">ERROR_flow.yml</block>
  <block id="c6496825f1a87696b60935af9416283a" category="inline-link-macro">다음: 타사 API에 Fulfillment Engine으로 연결합니다</block>
  <block id="3a9d38bca913120b9d3638cb194cd7e6" category="paragraph"><block ref="3a9d38bca913120b9d3638cb194cd7e6" category="inline-link-macro-rx"></block></block>
  <block id="bf8b135ff3c775c5b9bbba1b2f7a61ce" category="doc">이 솔루션에 사용된 하드웨어</block>
  <block id="3b31e2e4387e938056251a113831e6da" category="inline-link">NVA-1121</block>
  <block id="a4ec49885c617f2b2500789af7e6eebf" category="paragraph">이 솔루션은 ONTAP AI 참조 아키텍처 2개의 DGX-1 노드 및 1개의 AFF A800 스토리지 시스템을 사용하여 검증되었습니다. 을 참조하십시오<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> 이 검증에 사용된 인프라에 대한 자세한 내용은 를 참조하십시오.</block>
  <block id="6c4fbfa85e86ba1acd8a66b367a3b2c4" category="paragraph">다음 표에는 솔루션을 테스트하는 데 필요한 하드웨어 구성요소가 나와 있습니다.</block>
  <block id="fe59cdcdefd7c53625e1e745b9c5be09" category="cell">DGX-1 시스템</block>
  <block id="53270fbfda62583949b287e08ae3d063" category="cell">AFF A800</block>
  <block id="c4ca4238a0b923820dcc509a6f75849b" category="cell">1</block>
  <block id="6da64488bfb7f3216610e30ced34ff23" category="cell">Nexus 3232C 스위치</block>
  <block id="4c2db3e48f4f33a355c8e493453b53c2" category="inline-link-macro">다음: 소프트웨어 요구 사항</block>
  <block id="54870296c311c566be3a76b4a4df8e8c" category="paragraph"><block ref="43a6574de87222e6a8a22c8138fc4c45" category="inline-link-macro-rx"></block>.</block>
  <block id="638c2d891d4e85bcfae409499fba817c" category="doc">할당량 초과 GPU 할당을 통한 높은 클러스터 사용률 달성</block>
  <block id="5648f06cc2dff861e557e088190ccbe2" category="paragraph">섹션을 참조하십시오 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, 및 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>복잡한 워크로드 관리, 자동 사전 예방 예약 및 초과 할당량 GPU 프로비저닝을 위한 Run:AI 조정 기능을 시연하기 위해 고급 테스트 시나리오를 고안했습니다. 이를 통해 ONTAP AI 환경에서 클러스터 리소스를 많이 사용하고 엔터프라이즈급 데이터 과학 팀 생산성을 최적화할 수 있었습니다.</block>
  <block id="fed09193953a2a2d15bfba4063981f8c" category="paragraph">이 세 섹션에서는 다음 프로젝트 및 할당량을 설정합니다.</block>
  <block id="d2d5c3e087f684e56b5b81d6212d7ccb" category="cell">할당량</block>
  <block id="c9f0f895fb98ab9159f51fd0297e236d" category="cell">8</block>
  <block id="207b738b6cd0e1cf6ac4a405dc72102f" category="paragraph">또한 다음 세 개의 단원에 다음과 같은 컨테이너를 사용합니다.</block>
  <block id="cc6f12794ea24a191cb4f699f1b95036" category="list-text">Jupyter Notebook: jupyter/base-notebook</block>
  <block id="b8d0bb7e356bfdd7e018a7c62f9343fa" category="list-text">Run:AI QuickStart:'GCR.IO/RUN-AI-DEMO/QuickStart'를 실행하십시오</block>
  <block id="c9582d103b2fe8050364d3e629c4e80e" category="paragraph">이 테스트 시나리오에 대해 다음과 같은 목표를 설정했습니다.</block>
  <block id="c2d51205301247cd0aa0eca284d3889b" category="list-text">리소스 프로비저닝의 간편성 및 리소스를 사용자로부터 추상화한 방법을 보여줍니다</block>
  <block id="dfd4af458e74e30246827532e692dca7" category="list-text">GPU의 분수와 GPU의 정수 수를 간편하게 프로비저닝하는 방법을 보여줍니다</block>
  <block id="d7bf7c7f0d7884bd8fe07da4f6a8aba3" category="list-text">클러스터에 무료 GPU가 있을 경우 팀 또는 사용자가 리소스 할당량을 처리할 수 있으므로 시스템에서 컴퓨팅 병목 현상이 해소되는 방법을 보여줍니다</block>
  <block id="f93609e9c7f7c826e6c83bb1f8416207" category="list-text">NetApp 컨테이너와 같은 컴퓨팅 집약적인 작업을 실행할 때 NetApp 솔루션을 사용하여 데이터 파이프라인의 병목 현상을 제거하는 방법을 보여줍니다</block>
  <block id="8ac218f5a62c8021756a192ac737a7f2" category="list-text">시스템을 사용하여 여러 유형의 컨테이너를 실행하는 방법을 보여 줍니다</block>
  <block id="802125395813e0bec35472d0403ab94e" category="list-text">Jupyter 노트북</block>
  <block id="91c4a4ef606f959264719f8d084aab0e" category="list-text">실행: AI 컨테이너</block>
  <block id="23edbe937c996eb973ab4c69f9648893" category="list-text">클러스터가 가득 찼을 때 높은 사용률을 표시합니다</block>
  <block id="37e875b843ef9539c02d09d3bbee6668" category="inline-link-macro">섹션 4.8의 테스트 세부 사항</block>
  <block id="815a27a2c38741e36d920cbea5587384" category="paragraph">테스트 중에 실행된 실제 명령 시퀀스에 대한 자세한 내용은 을 참조하십시오 <block ref="3a65193f11bb9f699d19b0e9a996cd93" category="inline-link-macro-rx"></block>.</block>
  <block id="9d020ce52f8e9ff0d2f2defe3942d660" category="paragraph">13개의 워크로드를 모두 제출하면 다음 그림과 같이 할당된 컨테이너 이름 및 GPU 목록을 볼 수 있습니다. NetApp은 7개의 교육 및 6개의 대화식 작업을 통해 4개의 데이터 과학 팀을 시뮬레이션하며 각 팀은 개발 또는 자체 모델을 실행하고 있습니다. 대화형 작업의 경우, 개별 개발자는 Jupyter Notebooks를 사용하여 코드를 작성하거나 디버깅합니다. 따라서 클러스터 리소스를 너무 많이 사용하지 않고 GPU 분할을 프로비저닝하는 것이 좋습니다.</block>
  <block id="5deafc9e56279ca519f1e3c351856aa8" category="paragraph"><block ref="5deafc9e56279ca519f1e3c351856aa8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa04853a58b1b9ab0033c7e24b9d929" category="paragraph">이 테스트 시나리오의 결과는 다음과 같습니다.</block>
  <block id="dbaf41fcdcf0aa8cd93bfdf0e7f916f2" category="list-text">클러스터가 꽉 찼어야 합니다. 16/16개의 GPU를 사용했습니다.</block>
  <block id="25421e793bda820f3023762c547a2495" category="list-text">높은 클러스터 사용률.</block>
  <block id="fdf3de6e0502b5404d2e0b379421f759" category="list-text">부분 할당으로 인해 GPU보다 더 많은 실험</block>
  <block id="68cf93a70e0f0fe62bc0428ce8a8b348" category="list-text">팀 d는 쿼터를 모두 사용하지 않으므로 팀 b와 팀 c는 실험에 추가 GPU를 사용할 수 있어 혁신의 시간을 단축할 수 있습니다.</block>
  <block id="9083e59932e59a6f85524ab956fcf772" category="inline-link-macro">다음: 기본 자원 할당 공정성</block>
  <block id="654c44d69d64b0a5a656dd7b1375ac03" category="paragraph"><block ref="654c44d69d64b0a5a656dd7b1375ac03" category="inline-link-macro-rx"></block></block>
  <block id="28b9eb1a9ba550cf23239eb33610203e" category="doc">소프트웨어 및 하드웨어 요구 사항</block>
  <block id="dce011ea921230b4e3061bb70569c598" category="section-title">네트워크 구성</block>
  <block id="5c56d5a342310a4d1ead67adc85adcab" category="paragraph">다음은 클라우드에서 설정하기 위한 네트워크 구성 요구 사항입니다.</block>
  <block id="df97d4ea35e2febbb06b9bd1ba29b50e" category="list-text">Iguazio 클러스터와 NetApp Cloud Volumes는 동일한 가상 프라이빗 클라우드에 있어야 합니다.</block>
  <block id="a8f3c1a7fc956bcddef483bc8797e742" category="list-text">클라우드 관리자는 Iguazio 앱 노드의 포트 6443에 액세스할 수 있어야 합니다.</block>
  <block id="0d1562d43d3c0d4c52eef4a841896eba" category="list-text">이 기술 보고서에서는 Amazon Web Services를 사용했습니다. 그러나 사용자는 모든 클라우드 공급자에 솔루션을 배포할 수 있습니다.NVIDIA DGX-1을 사용하는 ONTAP AI에서의 온프레미스 테스트를 위해 이과지오에서 호스팅하는 DNS 서비스를 편리하게 사용했습니다.</block>
  <block id="820de5e74a90f4dbc17e37b78258c35b" category="paragraph">클라이언트는 동적으로 생성된 DNS 도메인에 액세스할 수 있어야 합니다. 고객은 원하는 경우 자체 DNS를 사용할 수 있습니다.</block>
  <block id="930dd6e7cbd550494f96b487d9d38ec8" category="section-title">하드웨어 요구 사항</block>
  <block id="43ad77bf4f253415b4e90ea4aa41a2d7" category="paragraph">Iguazio는 자체 클러스터에 설치할 수 있습니다. NetApp은 NVIDIA DGX-1 시스템을 통해 NetApp ONTAP AI의 솔루션을 검증했습니다. 다음 표에는 이 솔루션을 테스트하는 데 사용되는 하드웨어가 정리되어 있습니다.</block>
  <block id="7b6f2acc1b4489fd971965be635ea987" category="cell">NetApp AFF A800 시스템</block>
  <block id="55552614d2dd18f2d6c40759f2de9e22" category="cell">1개의 고가용성(HA) 2노드에 컨트롤러 2개와 NVMe SSD 48개(3.8TB 이상) 포함</block>
  <block id="413400218c4c262991ad8483b3be0a04" category="cell">Cisco Nexus 3232C 네트워크 스위치</block>
  <block id="72f23e74ab545a9064f74aca4d904bf4" category="paragraph">다음 표에는 사내 테스트에 필요한 소프트웨어 구성 요소가 나열되어 있습니다.</block>
  <block id="5acec1d6c6e07042eb0c19bc926d2633" category="cell">버전 또는 기타 정보</block>
  <block id="5339d389f2f896062fb28b05454dc94a" category="cell">NetApp ONTAP 데이터 관리 소프트웨어</block>
  <block id="f82f50748d06cc9643330a4a8297ba43" category="cell">9.7</block>
  <block id="efdec37786e687a58664ebd4ef6bdba4" category="cell">Cisco NX-OS 스위치 펌웨어</block>
  <block id="976d6c35e21478ef03ca2cec2a74dc71" category="cell">7.0(3) I6(1)</block>
  <block id="a62649c559be1634e22dd7df0b58ad32" category="cell">NVIDIA DGX OS</block>
  <block id="751601035b4077a9c6f7280ab1d3369c" category="cell">4.4-Ubuntu 18.04 LTS</block>
  <block id="44769dc982b2126503d2d014bcf7c15a" category="cell">Docker 컨테이너 플랫폼</block>
  <block id="bb3121464976ef0c6b6b2b81fc75f3c5" category="cell">19.03.5</block>
  <block id="2a820a07d05055e147221622557f34b9" category="cell">컨테이너 버전입니다</block>
  <block id="6f3d0f773f6be20d70e6bbbafca93de9" category="cell">20.01-tF1-py2</block>
  <block id="46b6cc5d90605df4689002387db99128" category="cell">머신 러닝 프레임워크</block>
  <block id="f060e908e90b13cff9447e18fbb6bb20" category="cell">TensorFlow 1.15.0</block>
  <block id="4ec1f03a0b910370451392d8af8cd05a" category="cell">이과시오</block>
  <block id="80b1aaf85493db4117fca57135bec077" category="cell">버전 2.8 이상</block>
  <block id="20de768bd6142b858c4e99c64e19f37b" category="cell">ESX Server를 선택합니다</block>
  <block id="f884cc5c56f9c9a8d4d61568ff64db9c" category="cell">6.5</block>
  <block id="95b4a53c1023a65c982b077b13be4b96" category="paragraph">이 솔루션은 Iguazio 버전 2.5 및 NetApp Cloud Volumes ONTAP for AWS로 완전히 테스트되었습니다. Iguazio 클러스터와 NetApp 소프트웨어가 모두 AWS에서 실행되고 있습니다.</block>
  <block id="efbef76fea5d52b17e66f66b7fbdb1be" category="cell">버전 또는 유형</block>
  <block id="1f2c90c0f9931b94eab6d9d2d3a640c9" category="cell">앱 노드</block>
  <block id="8f33b30dd333b320c87f038f61e17523" category="cell">M5.4xLarge</block>
  <block id="b8f3b98512c841c7f30ce704570ac0b6" category="cell">데이터 노드</block>
  <block id="ea93f0324aaeaa177497ea41b52cb9ff" category="cell">I3.4xLarge</block>
  <block id="870032d2d605939c0c8a813ac8534e80" category="inline-link-macro">다음: 네트워크 장치 오류 예측 사용 사례 요약</block>
  <block id="6b90a2e4861b0a6faf4f640ece131282" category="paragraph"><block ref="6b90a2e4861b0a6faf4f640ece131282" category="inline-link-macro-rx"></block></block>
  <block id="c2ae2e58baf01933984b63bbfd58c6c2" category="summary">이 섹션에서는 Kubernetes 클러스터에 공기 흐름을 구축하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="7d2a9e50f39ee00c2b180900e7bacc92" category="doc">Apache Airflow Deployment</block>
  <block id="f23c532f744716d23270b963c3eca570" category="paragraph">Kubernetes에서 Apache Airflow를 실행하는 것이 좋습니다. 이 섹션에서는 Kubernetes 클러스터에 공기 흐름을 구축하기 위해 완료해야 하는 작업에 대해 설명합니다.</block>
  <block id="1874d60ac69d2a867825b1b7ab0f9297" category="admonition">Kubernetes 이외의 플랫폼에 공기 흐름을 배포할 수 있습니다. Kubernetes가 아닌 다른 플랫폼에 공기 흐름을 배포하는 것은 이 솔루션의 범위를 벗어납니다.</block>
  <block id="c7a7dda60a4edd19d3b5bad13d43d605" category="list-text">Kubernetes 클러스터 작업이 이미 진행 중입니다.</block>
  <block id="e59b39fd5c122dde3747561247eb2888" category="list-text">"NetApp Trident 배포 및 구성" 섹션에 설명된 대로 Kubernetes 클러스터에 NetApp Trident를 이미 설치 및 구성했습니다.</block>
  <block id="ead9806c164633fcb334dc844a3d588f" category="section-title">제어 장치를 설치합니다</block>
  <block id="f9093f3279eca680041e957a2a0505dd" category="paragraph">Kubernetes의 유명 패키지 매니저인 Helm을 사용하여 공기 흐름을 구축합니다. 공기 흐름을 배치하기 전에 배포 점프 호스트에 Helm을 설치해야 합니다. 배포 점프 호스트에 Helm을 설치하려면 에 따르십시오<block ref="cf3f65305f288242c9d49061d26ec8ec" category="inline-link-rx"></block> 공식 Helm 문서.</block>
  <block id="678c0949a1824bf54eba73ab0a2609d8" category="paragraph">공기 흐름을 구축하기 전에 Kubernetes 클러스터 내에서 기본 StorageClass를 지정해야 합니다. Airflow 배포 프로세스는 기본 StorageClass를 사용하여 새 영구 볼륨의 프로비저닝을 시도합니다. 기본 StorageClass로 지정된 StorageClass가 없으면 배포가 실패합니다. 클러스터 내에서 기본 StorageClass를 지정하려면 섹션에 설명된 지침을 따르십시오 <block ref="b868c02e3d390c0001190527c8f4ba0b" category="inline-link-macro-rx"></block>. 클러스터 내에서 기본 StorageClass를 이미 지정한 경우에는 이 단계를 건너뛸 수 있습니다.</block>
  <block id="c7feb8d7350bb5372c4dd0dfc1383865" category="section-title">Helm을 사용하여 공기 흐름을 전개하십시오</block>
  <block id="a781e1f3dbd7b5f15c3257febe820528" category="paragraph">Helm을 사용하여 Kubernetes 클러스터에 공기 흐름을 배포하려면 배포 점프 호스트에서 다음 작업을 수행하십시오.</block>
  <block id="fe1b26293aba127732d69bdc90866794" category="list-text">에 따라 헬름으로 공기 흐름을 전개하십시오<block ref="e4140084ec840191180d755827375d89" category="inline-link-rx"></block> Artifact Hub의 공식 공기 흐름 도표입니다. 다음 명령 예는 Helm을 사용한 공기 흐름의 배치를 보여줍니다. 환경과 원하는 구성에 따라 필요에 따라 'custom-values.yAML' 파일에서 값을 수정, 추가 및/또는 제거합니다.</block>
  <block id="fa7edbfc4d9facbb8db918116ff0ae46" category="list-text">모든 공기 흐름 포드가 실행 중인지 확인합니다. 모든 Pod를 시작하는 데 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="9bb040ffef8c89d0861be81732ca17de" category="list-text">1단계에서 제어 장치를 사용하여 공기 흐름을 배포할 때 콘솔에 인쇄된 지침에 따라 공기 흐름 웹 서비스 URL을 얻습니다.</block>
  <block id="0db6a8f601b49c6c3780b668eac398a8" category="list-text">Airflow 웹 서비스에 액세스할 수 있는지 확인합니다.</block>
  <block id="6a8e19652a540e359304ba812d39ea8e" category="paragraph"><block ref="6a8e19652a540e359304ba812d39ea8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99c61a2c4480337fdf852f9dbe8a8863" category="inline-link-macro">다음: Apache Airflow 워크플로우의 예</block>
  <block id="d719776b249ed9e7109b922484d474a2" category="paragraph"><block ref="d719776b249ed9e7109b922484d474a2" category="inline-link-macro-rx"></block></block>
  <block id="74b3e84bf9817092a6f26ddf10a2f3f8" category="summary">이 페이지에서는 이 솔루션에 사용된 기술에 대해 간략하게 설명합니다.</block>
  <block id="dd5a70c15c985f455edb59eebf8d3eaa" category="paragraph"><block ref="dd5a70c15c985f455edb59eebf8d3eaa" category="inline-link-macro-rx"></block></block>
  <block id="4b2eedb67d8fb9da01af759e6e722a13" category="section-title">Microsoft 및 NetApp</block>
  <block id="09e4ef7b38fea4a7bdf4341b588176d6" category="paragraph">2019년 5월부터 Microsoft는 NetApp ONTAP 기술을 기반으로 엔터프라이즈 NFS 및 SMB 파일 서비스를 위한 Azure 네이티브 자사 포털 서비스를 제공해 왔습니다. 이러한 개발을 위해 Microsoft와 NetApp의 전략적 파트너십을 활용하고 세계적인 수준의 ONTAP 데이터 서비스를 Azure로 확장합니다.</block>
  <block id="851e5baafa3bd23201e65e29f2fdf06a" category="paragraph">Azure NetApp Files 서비스는 엔터프라이즈급 고성능 용량제 파일 스토리지 서비스입니다. Azure NetApp Files은 모든 워크로드 유형을 지원하며 기본적으로 고가용성을 제공합니다. 서비스를 통해 서비스 및 성능 수준을 선택하고 스냅샷 복사본을 설정할 수 있습니다. Azure NetApp Files은 코드 변경 없이 데이터베이스, SAP, 고성능 컴퓨팅 애플리케이션 등 클라우드에서 가장 까다로운 엔터프라이즈 파일 워크로드를 마이그레이션 및 실행하기 위한 Azure 퍼스트 파티 서비스입니다.</block>
  <block id="f014a6e06480ef33e3f1ab027f7065ca" category="paragraph">이 참조 아키텍처는 IT 조직이 다음과 같은 이점을 얻을 수 있도록 해 줍니다.</block>
  <block id="5e6e9a1ee378cf26b50e61d8bd46d54d" category="list-text">다양한 성능 및 비용 요소에 부합하는 폭넓은 스토리지 계층을 제공합니다</block>
  <block id="295f4f6daaf50c87d2639d407c47f357" category="section-title">Dask 및 NVIDIA RAPIDS 개요</block>
  <block id="a9dcf931a9aad845de3c5b908d562955" category="paragraph">Dask는 여러 시스템에서 Python 라이브러리를 확장하고 대용량 데이터의 처리 속도를 높이는 오픈 소스 병렬 컴퓨팅 도구입니다. Pandas, Numpy 및 scikit-learn과 같은 단일 스레드 기존 Python 라이브러리와 유사한 API를 제공합니다. 따라서 기본 Python 사용자는 클러스터 전체에서 리소스를 사용하기 위해 기존 코드의 많은 부분을 변경하지 않아도 됩니다.</block>
  <block id="955647f3573b932f8596ba04ed80b7b6" category="paragraph">NVIDIA RAPIDS는 전체 GPU에서 엔드 투 엔드 ML 및 데이터 분석 워크플로우를 실행하도록 지원하는 오픈 소스 라이브러리 제품군입니다. DASK와 함께 사용하면 GPU 워크스테이션(스케일업)에서 다중 노드, 다중 GPU 클러스터(스케일아웃)까지 쉽게 확장할 수 있습니다.</block>
  <block id="7a9ece70a2d60d73203e927718fd8454" category="paragraph">클러스터에서 Dask를 구축할 경우 Kubernetes를 리소스 오케스트레이션에 사용할 수 있습니다. 다음 그림과 같이 프로세스 요구 사항에 따라 작업자 노드를 확장하거나 축소할 수도 있습니다. 그러면 클러스터 리소스 소비를 최적화할 수 있습니다.</block>
  <block id="b3951b803e4010ed575c9238d2803949" category="paragraph"><block ref="b3951b803e4010ed575c9238d2803949" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2e194dd3ce5b4d001a02991ef567211" category="inline-link-macro">다음: 소프트웨어 요구 사항.</block>
  <block id="23704e1baeed350311b18c3583ad89e9" category="paragraph"><block ref="23704e1baeed350311b18c3583ad89e9" category="inline-link-macro-rx"></block></block>
  <block id="e353dbe42c8654f33588d4da0b517469" category="doc">추상화</block>
  <block id="1d91c2c04b7f73cb59edb799d095c75c" category="paragraph">이 백서에서는 NVIDIA Jarvis 프레임워크를 사용하여 인공 지능(AI) 대화형 솔루션을 구축하는 고객을 위한 지침과 소매 및 기타 사용 사례를 위한 NetApp ONTAP AI 및 Cloud Sync를 제공합니다. 여기에는 가상 보조자를 위한 NLP(자연어 처리) 모델 개발, 검증된 테스트 사례 및 결과에 사용되는 고급 워크플로에 대한 정보가 포함되어 있습니다.</block>
  <block id="52c7321ea4e3d5b264fdc8639a65e280" category="doc">Grafana 대시보드 배포</block>
  <block id="c843fc0ceca9c58b409cab519799c125" category="paragraph">모든 것이 배포되면 새 데이터에 대한 추론을 실행합니다. 이 모델은 네트워크 장치 장비의 고장을 예측합니다. 예측 결과는 Iguazio 시간 계열 테이블에 저장됩니다. Iguazio의 보안 및 데이터 액세스 정책과 통합된 플랫폼을 통해 Grafana로 결과를 시각화할 수 있습니다.</block>
  <block id="ae93e86067cc1d0e7bb1ec8fdca6fbc3" category="paragraph">제공된 JSON 파일을 클러스터의 Grafana 인터페이스로 가져와 대시보드를 구축할 수 있습니다.</block>
  <block id="213977705fe35a4cb0cfc9365088fc87" category="list-text">Grafana 서비스가 실행 중인지 확인하려면 서비스 아래를 살펴보십시오.</block>
  <block id="b426c25dbb35de6b9c6bff0b10b8bef9" category="paragraph"><block ref="b426c25dbb35de6b9c6bff0b10b8bef9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58b6e0cc0a098260878a0e8fa4eb7766" category="list-text">이 인스턴스가 없으면 서비스 섹션에서 인스턴스를 배포합니다.</block>
  <block id="cd40a7a2e0a86f4a0283af5999a050db" category="list-text">새 서비스를 클릭합니다.</block>
  <block id="59c4bcb990174489660974167376a50a" category="list-text">목록에서 Grafana를 선택합니다.</block>
  <block id="7e280ecf88737f34a1972ac94f9ae2a1" category="list-text">기본값을 그대로 사용합니다.</block>
  <block id="9e47b36567e5001dea59ffee81456737" category="list-text">다음 단계를 클릭합니다.</block>
  <block id="4fa350b43dd079673b6fca4852841147" category="list-text">사용자 ID를 입력합니다.</block>
  <block id="af81385be6cef15b54f8c8c126c0eab0" category="list-text">서비스 저장 을 클릭합니다.</block>
  <block id="568c8b6f668936384414e470f9ddd939" category="list-text">맨 위에 있는 변경 내용 적용을 클릭합니다.</block>
  <block id="b5be50b376063d6c3ffaa3be10d4a9d3" category="list-text">대시보드를 배포하려면 Jupyter 인터페이스를 통해 NetopsPredictions-Dashboard.json 파일을 다운로드합니다.</block>
  <block id="587b311a501585c3a1d9260d4f147990" category="paragraph"><block ref="587b311a501585c3a1d9260d4f147990" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4ad16c6527a3abd13b6864b8b078586b" category="list-text">서비스 섹션에서 Grafana를 열고 대시보드를 가져옵니다.</block>
  <block id="0b78dd574d02d72071845d040fdde57c" category="paragraph"><block ref="0b78dd574d02d72071845d040fdde57c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3ce0bca8ff75db7ff2bbc3e76532b2" category="list-text">Upload(*.json) File을 클릭하고 앞서 다운로드한 파일('NetopsPredictions - Dashboard.json')을 선택한다. 업로드가 완료되면 대시보드가 표시됩니다.</block>
  <block id="7cd4d06091771aa3f16d2759a067e18c" category="paragraph"><block ref="7cd4d06091771aa3f16d2759a067e18c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a0258dc4515b0e18ecd4b55651e27671" category="section-title">정리 기능을 배포합니다</block>
  <block id="ff4bdefb3ddd7532393d08c8df14d786" category="paragraph">많은 데이터를 생성할 때 정리 및 정리하는 것이 중요합니다. 이를 위해 정리 기능을 정리 iynb 공책에 배치한다.</block>
  <block id="e654f7a86a4458b9cd662267e0f29b52" category="section-title">이점</block>
  <block id="6d0f7ccc9b17bcabb743cabdfb56e0da" category="paragraph">NetApp과 Iguazio는 Docker, Kubernetes와 같은 오케스트레이션 툴과 함께 Kubeflow, Apache Spark 및 TensorFlow 등의 필수 프레임워크를 구축하여 AI 및 ML 애플리케이션의 구축 속도를 높이고 단순화합니다. NetApp과 Iguazio는 엔드 투 엔드 데이터 파이프라인을 통합함으로써 수많은 고급 컴퓨팅 워크로드에서 발생하는 지연 시간과 복잡성을 줄이고 개발 및 운영 간의 격차를 효과적으로 좁혀줍니다. 데이터 과학자는 대규모 데이터 세트에서 쿼리를 실행하고 교육 단계 동안 권한 있는 사용자와 데이터 및 알고리즘 모델을 안전하게 공유할 수 있습니다. 컨테이너식 모델이 운영 환경에 준비되면 개발 환경에서 운영 환경으로 쉽게 이동할 수 있습니다.</block>
  <block id="daee7e425c63dff416cde0a8932a8483" category="paragraph"><block ref="daee7e425c63dff416cde0a8932a8483" category="inline-link-macro-rx"></block></block>
  <block id="3b878279a04dc47d60932cb294d96259" category="doc">개요</block>
  <block id="f68b67869778246b8f0d8a98ed043512" category="paragraph">이 섹션에서는 Virtual Retail Assistant 구현에 대해 자세히 설명합니다.</block>
  <block id="02216530e0245f79b0b7448e14bffbce" category="inline-link-macro">다음: Jarvis 배포</block>
  <block id="a9ca2532d8607b5827969961f314249e" category="paragraph"><block ref="a9ca2532d8607b5827969961f314249e" category="inline-link-macro-rx"></block></block>
  <block id="ad2376beebecdcf7846ba973fa1a005b" category="doc">설정</block>
  <block id="9783bbad26249ed7f40d89e12ba42020" category="doc">실행: AI 워크로드 오케스트레이션에 AI 플랫폼 사용</block>
  <block id="cb39fb629a91fdf37928a15d38e05318" category="list-text">더 빠르게 혁신을 이룩할 수 있습니다. 연구원들은 NetApp 스토리지 시스템과 함께 AI 리소스 풀링, 큐 처리 및 우선순위 지정 메커니즘을 사용하여 인프라 관리 문제에서 제거되며 데이터 과학에만 집중할 수 있습니다. 실행: AI 및 NetApp 고객은 컴퓨팅 또는 데이터 파이프라인 병목 현상 없이 필요한 만큼 워크로드를 실행하여 생산성을 향상할 수 있습니다.</block>
  <block id="8df86cf2931aab70fd9ad1f919f40449" category="list-text">팀 생산성 향상. Run:AI Fairness 알고리즘은 모든 사용자와 팀이 리소스의 페어공유를 확보할 수 있도록 보장합니다. 우선 순위 프로젝트와 관련된 정책을 미리 설정할 수 있으며, 플랫폼을 통해 사용자 팀 간에 리소스를 동적으로 할당할 수 있으므로 사용자가 원하는 GPU 리소스에 적시에 액세스할 수 있습니다.</block>
  <block id="c835378d4be1896f62ef5d2760340909" category="list-text">GPU 활용률이 향상되었습니다. Run:AI Scheduler를 사용하면 Kubernetes에서 분산된 훈련을 위해 소수점 GPU, 정수 GPU 및 여러 GPU 노드를 쉽게 사용할 수 있습니다. 이런 식으로 AI 워크로드는 용량이 아닌 요구사항에 따라 실행됩니다. 데이터 과학 팀은 동일한 인프라에서 더 많은 AI 실험을 실행할 수 있습니다.</block>
  <block id="5960deb1522a82336a7a31213acea4b0" category="inline-link-macro">다음: 솔루션 기술</block>
  <block id="dde440f8f7c47863e65c2d82a820b8a5" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block>.</block>
  <block id="2e240897109c5037e05afe0bf035d177" category="inline-link-macro">이전: 결론.</block>
  <block id="9c08a0abcced906f3225e86f61dd598c" category="paragraph"><block ref="9c08a0abcced906f3225e86f61dd598c" category="inline-link-macro-rx"></block></block>
  <block id="c5648cc9e6e76ab4aa041d71661d0288" category="list-text">3D 대화형 데모</block>
  <block id="26e071d5769be8e940617a0c8dd5c22d" category="inline-link">www.netapp.com/ai</block>
  <block id="9e22db1b830d668e86d5dc1b5c204555" category="paragraph"><block ref="9e22db1b830d668e86d5dc1b5c204555" category="inline-link-rx"></block></block>
  <block id="1fa584a3d1190f1a7fdded0c91412cac" category="list-text">NetApp AI 전문가와의 직접 연결</block>
  <block id="91fc02253adb6a9eea2156b684aa70f5" category="inline-link"><block ref="91fc02253adb6a9eea2156b684aa70f5" category="inline-link-rx"></block></block>
  <block id="488d7301e5d1a52040c33186d7e11657" category="paragraph"><block ref="488d7301e5d1a52040c33186d7e11657" category="inline-link-rx"></block></block>
  <block id="787dd83fbbc162f0279e320ada1f7c0b" category="list-text">NVDIA Base Command Platform with NetApp 솔루션 개요</block>
  <block id="5541299dd0999c42fcd24fd754001e38" category="inline-link"><block ref="5541299dd0999c42fcd24fd754001e38" category="inline-link-rx"></block></block>
  <block id="ac527e3c2b2d8a080840aa28c13b127b" category="paragraph"><block ref="ac527e3c2b2d8a080840aa28c13b127b" category="inline-link-rx"></block></block>
  <block id="465b9c508fba1d27d188eb21e0655293" category="list-text">AI를 위한 NetApp 10가지 이유 인포그래픽</block>
  <block id="75048e22ffd1c45ce07e6cae3170780a" category="inline-link"><block ref="75048e22ffd1c45ce07e6cae3170780a" category="inline-link-rx"></block></block>
  <block id="e2435a6f01dee5a11f6cd698a292183d" category="paragraph"><block ref="e2435a6f01dee5a11f6cd698a292183d" category="inline-link-rx"></block></block>
  <block id="66d4373905c5c7c0a3f51e5480d443b2" category="list-text">의료 부문의 AI: 폐 CT 스캔에서 COVID-19 병변을 식별하는 딥 러닝 백서</block>
  <block id="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link"><block ref="2fb5802df8b60fe09d232df217cc9ba6" category="inline-link-rx"></block></block>
  <block id="d1e9d43080e6c2364ee86ac930ae1341" category="paragraph"><block ref="d1e9d43080e6c2364ee86ac930ae1341" category="inline-link-rx"></block></block>
  <block id="2ece031fbb30496ba2ec244a07557107" category="list-text">의료 부문의 AI: 의료 설정에서 안면 마스크 사용 모니터링 백서</block>
  <block id="aa895997d9bc7e84d90779885cb936b7" category="inline-link"><block ref="aa895997d9bc7e84d90779885cb936b7" category="inline-link-rx"></block></block>
  <block id="4ac3d75f4e132824f0fe3a418d42a9f9" category="paragraph"><block ref="4ac3d75f4e132824f0fe3a418d42a9f9" category="inline-link-rx"></block></block>
  <block id="ff11da2c36a9883c6eb658395f3de353" category="list-text">의료 부문의 AI: 진단 이미징 기술 보고서</block>
  <block id="41575d740e0d837694e2fa66ce618124" category="inline-link"><block ref="41575d740e0d837694e2fa66ce618124" category="inline-link-rx"></block></block>
  <block id="61a15cd6b61d637fb54ae6ae99ae39d5" category="paragraph"><block ref="61a15cd6b61d637fb54ae6ae99ae39d5" category="inline-link-rx"></block></block>
  <block id="1527888e6b729290296c51cf9c3aeeec" category="list-text">소매 분야 AI: NVIDIA Riva를 통한 NetApp의 대화형 AI</block>
  <block id="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link"><block ref="17a311ea95071308f8bb7a7ce3b073ee" category="inline-link-rx"></block></block>
  <block id="dc1f6c62d8de3b68ec946b66d053f5a7" category="paragraph"><block ref="dc1f6c62d8de3b68ec946b66d053f5a7" category="inline-link-rx"></block></block>
  <block id="2281741ceb773b1efc91b48b4e5e04fe" category="list-text">NetApp ONTAP AI 솔루션 개요</block>
  <block id="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link"><block ref="4070d4ea40d3cf7f99e4e941ca73d200" category="inline-link-rx"></block></block>
  <block id="a32cc63ad53dc74caf680b96a921ad3b" category="paragraph"><block ref="a32cc63ad53dc74caf680b96a921ad3b" category="inline-link-rx"></block></block>
  <block id="c6b4ec978259e83d537f6a179912448a" category="list-text">NetApp DataOps 툴킷 솔루션 요약 정보</block>
  <block id="c50b3ec30c711b6233dd7753f12165d4" category="inline-link"><block ref="c50b3ec30c711b6233dd7753f12165d4" category="inline-link-rx"></block></block>
  <block id="a045bf4eb32fbbf6c351d4c3cbd5932c" category="paragraph"><block ref="a045bf4eb32fbbf6c351d4c3cbd5932c" category="inline-link-rx"></block></block>
  <block id="9399af78c2a9b2a197612e42bf8b8f79" category="list-text">NetApp AI Control Plane 솔루션 요약</block>
  <block id="c771257beb97f479ebb6d342d91b61bd" category="inline-link"><block ref="c771257beb97f479ebb6d342d91b61bd" category="inline-link-rx"></block></block>
  <block id="ce6060d7bc79a57fdb337f6364f0e8a9" category="paragraph"><block ref="ce6060d7bc79a57fdb337f6364f0e8a9" category="inline-link-rx"></block></block>
  <block id="b6e1af8dc83073dfa46f061507b15586" category="list-text">데이터 드라이브를 통한 산업 혁신 AI eBook</block>
  <block id="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link"><block ref="795a425d6438d3f619ddd3a7ac1ff64c" category="inline-link-rx"></block></block>
  <block id="195010aa6331d4b94de36f6aa5cf3fc7" category="paragraph"><block ref="195010aa6331d4b94de36f6aa5cf3fc7" category="inline-link-rx"></block></block>
  <block id="4dcaafba5ac7511b65c0f3a3688f8d81" category="list-text">NetApp EF-Series AI 솔루션 개요</block>
  <block id="385bae1ac9580238d4ef22dad99878c3" category="inline-link"><block ref="385bae1ac9580238d4ef22dad99878c3" category="inline-link-rx"></block></block>
  <block id="5bbcd3b785c7ecb740b1302ea68fb4ff" category="paragraph"><block ref="5bbcd3b785c7ecb740b1302ea68fb4ff" category="inline-link-rx"></block></block>
  <block id="e72de1f0850154df8bf93fae76b2276d" category="list-text">NetApp AI 및 Lenovo ThinkSystem for AI Inferencing 솔루션 개요</block>
  <block id="883d1d69b62bc20ea26446649b6c95b0" category="inline-link"><block ref="883d1d69b62bc20ea26446649b6c95b0" category="inline-link-rx"></block></block>
  <block id="74686a12110c0c39ad22ac2252bcb1a1" category="paragraph"><block ref="74686a12110c0c39ad22ac2252bcb1a1" category="inline-link-rx"></block></block>
  <block id="8954bee2812529847e7f3108185fc57d" category="list-text">엔터프라이즈 AI 및 ML용 NetApp AI 및 Lenovo ThinkSystem 솔루션 개요</block>
  <block id="f877ccffca68b901c2c61513c04dbf37" category="inline-link"><block ref="f877ccffca68b901c2c61513c04dbf37" category="inline-link-rx"></block></block>
  <block id="214ebd5c8513ce31087d4bf0cd12af76" category="paragraph"><block ref="214ebd5c8513ce31087d4bf0cd12af76" category="inline-link-rx"></block></block>
  <block id="7cbca96fc14ecadf4054303e98a81787" category="list-text">NetApp과 NVIDIA – AI 비디오를 통해 가능한 것을 새롭게 정의합니다</block>
  <block id="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link"><block ref="cb9dfd830902f3481279d486cd9ddd0d" category="inline-link-rx"></block></block>
  <block id="c7531fbb829ae07f04aab76de6fad46c" category="paragraph"><block ref="c7531fbb829ae07f04aab76de6fad46c" category="inline-link-rx"></block></block>
  <block id="3cfbc3bac23f6bb9e7ebdc6deefeaf1d" category="paragraph">NetApp과 NVIDIA가 개발 및 검증한 NetApp ONTAP AI 아키텍처는 NVIDIA DGX 시스템과 NetApp 클라우드 연결형 스토리지 시스템을 기반으로 합니다. 이 참조 아키텍처는 IT 조직이 다음과 같은 이점을 얻을 수 있도록 해 줍니다.</block>
  <block id="410a2fbd85ad3d74051034eac2b94889" category="list-text">다양한 성능 및 비용 요소에 부합하는 폭넓은 스토리지 옵션을 제공합니다</block>
  <block id="6fa0f6cc1d5d12069641e73217a17be2" category="paragraph">NetApp ONTAP AI는 DGX 시스템과 NetApp AFF A800 스토리지 시스템을 최첨단 네트워킹과 긴밀하게 통합합니다. NetApp ONTAP AI 및 DGX 시스템은 설계 복잡성과 추측을 제거함으로써 AI 배포를 단순화합니다. 고객은 작은 규모로 시작한 후 에지에서 코어 및 클라우드까지 포괄하여 데이터를 지능적으로 관리하면서 중단 없이 시스템을 확장할 수 있습니다.</block>
  <block id="bdc094a519f73076386a8bf2948832a6" category="paragraph">NetApp AI Control Plane은 데이터 과학자 및 데이터 엔지니어를 위한 전체 스택 AI, ML 및 딥 러닝(DL) 데이터 및 실험 관리 솔루션입니다. 조직이 AI를 더 많이 사용함에 따라 워크로드 확장성 및 데이터 가용성을 비롯한 여러 과제에 직면하게 됩니다. NetApp AI Control Plane은 Git repo와 마찬가지로 데이터 네임스페이스를 신속하게 클론 복제하여 추적 및 버전 관리를 위한 데이터 및 모델 기준을 거의 즉각적으로 생성하는 AI 교육 워크플로우를 정의 및 구현하는 등의 기능을 통해 이러한 문제를 해결합니다. NetApp AI Control Plane을 사용하면 사이트 및 지역 간에 데이터를 원활하게 복제하고 대규모 데이터 세트에 액세스할 수 있는 Jupyter Notebook 작업 공간을 신속하게 프로비저닝할 수 있습니다.</block>
  <block id="22101b8498dea1c2e2e35bd4868847a4" category="paragraph">실행: AI는 AI 인프라를 위한 세계 최초의 오케스트레이션 및 가상화 플랫폼을 구축했습니다. 실행: AI는 기본 하드웨어에서 워크로드를 추상화하여 동적으로 프로비저닝할 수 있는 GPU 리소스 공유 풀을 만들어 AI 워크로드를 효율적으로 조정하고 GPU를 최적화된 상태로 사용할 수 있도록 지원합니다. 데이터 과학자는 대용량 GPU 전력을 원활하게 소비하여 연구 결과를 개선하고 가속화하는 동시에, IT 팀이 리소스 프로비저닝, 대기 및 활용률에 대한 중앙 집중식 교차 사이트 제어 및 실시간 가시성을 유지할 수 있습니다. 실행: AI 플랫폼은 Kubernetes를 기반으로 구축되므로 기존 IT 및 데이터 과학 워크플로우와의 간편한 통합이 가능합니다.</block>
  <block id="ae00256db8d45ecdaf9c364a96821417" category="paragraph">Run:AI 플랫폼은 다음과 같은 이점을 제공합니다.</block>
  <block id="d472807c15e94ef6053e95521ff7e838" category="list-text">* 혁신을 위한 더 빠른 시간. * Run을 사용하면 AI 리소스 풀링, 큐 처리 및 우선순위 지정 메커니즘을 NetApp 스토리지 시스템과 함께 사용하여 연구원들은 인프라 관리 문제와 관련된 문제를 해결할 수 있으며 데이터 과학에만 집중할 수 있습니다. 실행: AI 및 NetApp 고객은 컴퓨팅 또는 데이터 파이프라인 병목 현상 없이 필요한 만큼 워크로드를 실행하여 생산성을 향상할 수 있습니다.</block>
  <block id="2707d068deb9b46967615c70c806e0d8" category="list-text">* 팀 생산성 향상. * 실행: AI 공정성 알고리즘은 모든 사용자와 팀이 적절한 리소스 공유를 확보할 수 있도록 보장합니다. 우선 순위 프로젝트와 관련된 정책을 미리 설정할 수 있으며, 플랫폼을 통해 사용자 또는 팀 간에 리소스를 동적으로 할당할 수 있으므로 사용자가 원하는 GPU 리소스에 적시에 액세스할 수 있습니다.</block>
  <block id="faa5854c7e84507b88cba1c0ec1a9aaf" category="list-text">* GPU 사용률이 개선되었습니다. * 실행: AI 스케줄러를 사용하면 Kubernetes에서 분산된 훈련을 위해 소수점 GPU, 정수 GPU 및 여러 GPU 노드를 쉽게 사용할 수 있습니다. 이런 식으로 AI 워크로드는 용량이 아닌 사용자의 요구사항을 기반으로 실행됩니다. 데이터 과학 팀은 동일한 인프라에서 더 많은 AI 실험을 실행할 수 있습니다.</block>
  <block id="d9533ea5c6cb975dff314dace88f2aa4" category="paragraph"><block ref="d9533ea5c6cb975dff314dace88f2aa4" category="inline-link-macro-rx"></block></block>
  <block id="5328ed3b5c6e4726166e04c16c2e5581" category="summary">이 섹션에서는 Pandas에서 Criteo Click Logs day 15를 로드하고 좌골키트학습 무작위 포리스트 모델을 훈련하는 방법에 대해 설명합니다. 이 예에서는 Dask cuDF를 사용하여 DataFrame 로드를 수행하고 Dask cuML에서 임의의 포리스트 모델을 교육했습니다.</block>
  <block id="a0432b74d7d4d2ad68e93e947654c865" category="doc">Dask에서 Day 15를 로드하고 Dask cuML 무작위 포리스트 모델을 교육합니다</block>
  <block id="7c784438423fe1bee9ab4f91a8fd7559" category="inline-link-macro">이전: Pandas에서 Logs day 15를 Load Critio 클릭하여 좌골 키트 교육 - Learn random forest model.</block>
  <block id="5d5b75a952d74a7d4520c521956b9d7e" category="paragraph"><block ref="5d5b75a952d74a7d4520c521956b9d7e" category="inline-link-macro-rx"></block></block>
  <block id="78dc33cd9d496e2466a0c1e2ba09ab3f" category="inline-link-macro">“교육 시간 비교.”</block>
  <block id="4a2764258721dd882c9ec28454963797" category="paragraph">이전 섹션과 비슷한 방식으로, Pandas에서 Criteo Click Logs day 15 를 로드하고 좌골키트학습 무작위 포리스트 모델을 훈련합니다. 이 예에서는 Dask cuDF를 사용하여 DataFrame 로드를 수행하고 Dask cuML에서 임의의 포리스트 모델을 교육했습니다. 이 섹션에서는 교육 시간과 규모의 차이를 비교했습니다 <block ref="8d6c01ed5b9db5301efeb6183c858b76" category="inline-link-macro-rx"></block></block>
  <block id="356d8553da3749641cb731d318c85b0c" category="section-title">criteo_dask_rf.ipynb입니다</block>
  <block id="2f4f1a139be92d2b17647025ff8630ab" category="paragraph">이 노트북은 다음 예와 같이 'numpy', 'cuml', 필요한 'dask' 라이브러리를 가져옵니다.</block>
  <block id="7b871613dade772ae668d694698383bf" category="paragraph">Dask 클라이언트()를 시작합니다.</block>
  <block id="3e9277d3d0f0519292426b933e52f232" category="paragraph">클러스터가 올바르게 구성된 경우 작업자 노드의 상태를 확인할 수 있습니다.</block>
  <block id="d6b257c355ced1525e4967c96b62b83e" category="paragraph">AKS 클러스터에서 다음 상태가 표시됩니다.</block>
  <block id="d94a77691c281e8bf418635fea6ca580" category="paragraph"><block ref="d94a77691c281e8bf418635fea6ca580" category="inline-image-macro-rx" type="image"></block></block>
  <block id="073b2194006d8da73b5f74f3d7224d76" category="paragraph">DASK는 처리 코드를 즉시 실행하는 대신 실행 대신 실행 대신 대상 지정 DAG(Acyclic Graph)를 생성합니다. DAG에는 각 작업자가 실행해야 하는 일련의 작업과 상호 작용이 포함되어 있습니다. 이 레이아웃은 사용자가 Dask에서 한 가지 방식 또는 다른 방식으로 작업을 실행하도록 지시할 때까지 작업이 실행되지 않음을 의미합니다. Dask를 사용하면 다음과 같은 세 가지 주요 옵션을 사용할 수 있습니다.</block>
  <block id="a40049c3d7270ce955d2023f8e2015dc" category="list-text">* DataFrame의 컴퓨팅()을 호출합니다. * 이 호출은 모든 파티션을 처리한 다음 결과를 스케줄러에 반환하여 최종 집계 및 cuDF DataFrame으로 변환합니다. 이 옵션은 스케줄러 노드의 메모리가 부족하지 않는 한 적은 결과에만 사용해야 합니다.</block>
  <block id="30e170dbe1dd223491e1a822605da52d" category="list-text">* Call persist() on a DataFrame. * 이 호출은 그래프를 실행하지만 결과를 스케줄러 노드로 반환하는 대신 클러스터의 전체 노드를 메모리에 유지하여 사용자가 이러한 중간 결과를 다시 사용하지 않고도 파이프라인에서 재사용할 수 있도록 합니다.</block>
  <block id="ca013764f3f6faeab137d2d529dba598" category="list-text">* DataFrame의 Call head(). * cuDF와 마찬가지로 이 호출은 10개의 레코드를 스케줄러 노드로 다시 반환합니다. 이 옵션을 사용하면 DataFrame 에 원하는 출력 형식이 포함되어 있는지 또는 레코드 자체가 타당한지 여부를 처리 및 계산에 따라 빠르게 확인할 수 있습니다.</block>
  <block id="7ac60f98a199ceae63010c7802a9aefa" category="paragraph">따라서 사용자가 이러한 작업을 호출하지 않는 한 작업자는 스케줄러가 처리를 시작할 때까지 유휴 상태로 있습니다. 이러한 게으른 실행 패러다임은 Apache Spark와 같은 오늘날의 병렬적이고 분산된 컴퓨팅 프레임워크에서 흔히 볼 수 있습니다.</block>
  <block id="d887d6a29f39f14cec0f83c5b02c42f8" category="paragraph">다음 단락에서는 분산 GPU 가속 컴퓨팅에 Dask cuML을 사용하여 임의 포리스트 모델을 교육하고 모델 예측 정확도를 계산합니다.</block>
  <block id="de76ff3258bd3001f89804efae30da38" category="inline-link-macro">다음: 기본 작업 스트림 대시보드를 사용하여 Dask를 모니터링합니다.</block>
  <block id="5db30f2a693de098d03dec622875beec" category="paragraph"><block ref="5db30f2a693de098d03dec622875beec" category="inline-link-macro-rx"></block></block>
  <block id="228af426af79aabaa0b969d8cee05002" category="summary">이 문서는 MLPerf Inference v0.7 코드, MLPerf Inference v1.1 코드 및 규칙을 따릅니다. 이 단원에 나와 있는 표에 정의된 대로 모서리에서 추론을 위해 설계된 벤치마크를 실행했습니다.</block>
  <block id="b3e6ac4f3c523ea5a90f4f79ca3e585d" category="doc">테스트 계획</block>
  <block id="35e08a3e7b357a4284ef29b287063ae5" category="paragraph"><block ref="35e08a3e7b357a4284ef29b287063ae5" category="inline-link-macro-rx"></block></block>
  <block id="c13367945d5d4c91047b3b50234aa7ab" category="inline-link">코드</block>
  <block id="a4f86f7bfc24194b276c22e0ef158197" category="inline-link">규칙</block>
  <block id="eb190159f20d63d1c7687ecafd03fc73" category="paragraph">이 문서는 MLPerf Inference v0.7을 따릅니다<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block>, MLPerf Inference v1.1<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block>, 및<block ref="efc21f34f290528320a21a8cc99ffcfc" category="inline-link-rx"></block>. 아래 표에 정의된 대로 에지에서 추론을 위해 설계된 MLPerf 벤치마크를 실행했습니다.</block>
  <block id="deec4ff19974f12ed781cb9a59064214" category="cell">영역</block>
  <block id="eaeb30f9f18e0c50b178676f3eaef45f" category="cell">작업</block>
  <block id="e110cde47b67924ec0ef64500e8cb067" category="cell">QSL 크기</block>
  <block id="571094bb27864b600d8e6b561a137a55" category="cell">품질</block>
  <block id="77f086368f7402e03b21bb823cda2eb3" category="cell">멀티스트림 지연 제한</block>
  <block id="99a0628d9f7179c032e0cf59efbc0fad" category="cell">비전</block>
  <block id="c84e3388f5bc3e4ce028dc81625bf819" category="cell">영상 분류</block>
  <block id="4cf67db3abdf54de6064fce40cf27398" category="cell">Resnet50v1.5</block>
  <block id="05e96e35d2778a07f18ff8b414821ee8" category="cell">ImageNet(224x224)</block>
  <block id="021bbc7ee20b71134d53e20206bd6feb" category="cell">1024</block>
  <block id="79267804a18aa7217c234994e26bb5c7" category="cell">FP32의 99%</block>
  <block id="c2010c9d1312ce345a2313d3acb5c6d5" category="cell">50ms</block>
  <block id="5d9387d7bf46f8c6854a5caafd6cfbf3" category="cell">물체 감지(대형)</block>
  <block id="7dd82182395c2720676a1e82b781ef04" category="cell">SSD-ResNet34</block>
  <block id="0505dc2363120e454308e12e47f6d354" category="cell">코코(1200x1200)</block>
  <block id="ea5d2f1c4608232e07d3aa3d998e5135" category="cell">64</block>
  <block id="f336aeb0ea3de7c70100c292338460e3" category="cell">66ms</block>
  <block id="a3e1c35debe58b3684abba30911eb0f9" category="cell">물체 감지(소형)</block>
  <block id="d05a0b1a6c857a559314f24c10825416" category="cell">SSD - MobileNetsv1</block>
  <block id="f471fd17e298022a58bcbd05aa25a819" category="cell">코코(300x300)</block>
  <block id="f718499c1c8cef6730f9fd03c8125cab" category="cell">256</block>
  <block id="ed076605284997250d9cc771eedbfc61" category="cell">의료 영상 분할</block>
  <block id="b8ffefa5ddac895023e8ab6fe1b55b45" category="cell">3D UNET</block>
  <block id="5ea5e4840c21271f42762e8b9271527a" category="cell">2019 (224x224x160)</block>
  <block id="c74d97b01eae257e44aa9d5bade97baf" category="cell">16</block>
  <block id="8322d3768dee2653e9cc15c955ee60a8" category="cell">FP32의 99% 및 99.9%</block>
  <block id="274b68192b056e268f128ff63bfcd4a4" category="cell">해당 없음</block>
  <block id="04a83927cfa1af6ae14f94e90aab9ebb" category="cell">음성</block>
  <block id="ade9e8d743e7e78d87c5c5603b0aa4ae" category="cell">텍스트 음성 변환</block>
  <block id="69ee0ff6f427bb2dfd286a55bbc181ea" category="cell">RNNT</block>
  <block id="d3c7d61f6e8ea0b76fd8b65e5115b28b" category="cell">리브리스페흐(LiBrispeech) 개발 - 청소</block>
  <block id="84b20b1f5a0d103f5710bb67a043cd78" category="cell">2513</block>
  <block id="4994a8ffeba4ac3140beb89e8d41f174" category="cell">언어</block>
  <block id="f8672b43ad1f9d3531557d69b6da380c" category="cell">언어 처리</block>
  <block id="221c3eff38f8ab54d359694f9da63c6e" category="cell">베르</block>
  <block id="f50c0cca078c7426bed1eb196911c809" category="cell">스쿼드 v1.1</block>
  <block id="d56da061d55e2175bd67901d5f0948be" category="cell">10833</block>
  <block id="816720c0b642aa1eef01c4f9108f54c5" category="paragraph">다음 표에는 Edge 벤치마크 시나리오가 나와 있습니다.</block>
  <block id="85051346c766b4444af7bfaaa0c189f5" category="cell">시나리오</block>
  <block id="4bb9c2b62dbc9558da74af948130693b" category="cell">영상 분류</block>
  <block id="d5348bf8d0ff8e72043bdbb08aef9767" category="cell">단일 스트림, 오프라인, 멀티스트림</block>
  <block id="468acb809a41b49bb7fcdf7425dcd7ee" category="cell">단일 스트림, 오프라인</block>
  <block id="7966e67de4ba20fb5412257b4023f4d1" category="paragraph">이 검증에서 개발된 네트워크 스토리지 아키텍처를 사용하여 이러한 벤치마크를 수행한 결과 및 이전에 MLPerf에 제출한 에지 서버에서 로컬 실행의 결과를 비교했습니다. 이와 비교하여 공유 스토리지가 추론 성능에 미치는 영향을 확인합니다.</block>
  <block id="a53c037982ff4e0cd4a61ba90c4c21d3" category="inline-link-macro">다음: 구성을 테스트합니다.</block>
  <block id="50cbf9a915ce97c432035077add8a92f" category="paragraph"><block ref="50cbf9a915ce97c432035077add8a92f" category="inline-link-macro-rx"></block></block>
  <block id="1cf7e301510c711b73d2b182b9dcf084" category="doc">사용 사례</block>
  <block id="4c2588a1e3dbf6824a4f05095df75f83" category="paragraph">오늘날의 모든 애플리케이션은 AI가 지원하지 않지만, AI의 탁월한 이점을 활용할 수 있도록 하는 새로운 기능도 필요합니다. AI의 채택을 지원하려면 최적의 상태로 기능하고 지속적인 혁신을 지원하는 데 필요한 리소스를 제공하는 인프라가 필요합니다.</block>
  <block id="31965de7c735983bb41a0b7e70361db2" category="paragraph">AI 기반 애플리케이션의 경우 에지 위치가 데이터의 주요 소스 역할을 합니다. 사용 가능한 데이터는 일정 기간 동안 여러 에지 위치에서 수집된 교육에 사용하여 교육 데이터 세트를 구성할 수 있습니다. 그런 다음, 훈련된 모델을 데이터가 수집된 에지 위치로 다시 구축하여 운영 데이터를 전용 추론 플랫폼으로 반복적으로 전송할 필요 없이 더 빠른 추론을 사용할 수 있습니다.</block>
  <block id="9e53c147a93fed13d4349cba2a35e36b" category="paragraph">NetApp H615c 컴퓨팅 노드에서 지원하는 NetApp HCI AI 추론 솔루션은 NVIDIA T4 GPU 및 NetApp 클라우드 연결 스토리지 시스템을 통해 NetApp 및 NVIDIA를 통해 개발 및 검증되었습니다. NetApp HCI은 애매모호한 영역을 해결하여 설계 상의 복잡성을 제거하고 추측을 말하여 에지 데이터 센터에서 AI 추론 솔루션 구축을 단순화합니다. 이 솔루션은 다음과 같은 특징을 갖춘 규범적 아키텍처를 IT 조직에 제공합니다.</block>
  <block id="9c4a53996590c74a0de3bba81f878254" category="list-text">에지 데이터 센터에서 AI 추론을 사용할 수 있습니다</block>
  <block id="20c3f996d396cc8c92788bb3585a6e86" category="list-text">GPU 리소스 소비를 최적화합니다</block>
  <block id="06e81c54cb9157aa59541289f1163daf" category="list-text">유연성 및 확장성을 위해 Kubernetes 기반 추론 플랫폼을 제공합니다</block>
  <block id="ba37c372c4a9119e45c7f525f4743cfc" category="paragraph">에지 데이터 센터는 거의 생성 지점에 있는 위치에서 데이터를 관리 및 처리합니다. 이러한 근접성으로 인해 효율성이 증가하고 데이터 처리와 관련된 지연 시간이 줄어듭니다. 많은 업종별 시장에서 에지 데이터 센터의 이점을 인식하고 있으며 이러한 분산 데이터 처리 방식을 적극적으로 채택하고 있습니다.</block>
  <block id="b501a0f0a3e7d559cecfad08c330227e" category="paragraph">다음 표에는 엣지 수직 시장과 애플리케이션이 나열되어 있습니다.</block>
  <block id="06ce2a25e5d12c166a36f654dbea6012" category="cell">수직</block>
  <block id="1ddf333c6654f7f89c739dddfb4cc429" category="cell">응용 프로그램</block>
  <block id="077262cc53a1fb1b5f651d31b6bf81ba" category="cell">의료</block>
  <block id="9da98fbc1c3d290fefb743a2df8914b4" category="cell">컴퓨터 보조 진단 기능은 의료진이 조기 질병 감지에 도움이 됩니다</block>
  <block id="fa0a7aa1622ad105e9cdf5a706058333" category="cell">석유 및 가스</block>
  <block id="55dae4e2e7f267e43e5768e66c7c3771" category="cell">원격 생산 시설, 비디오 및 이미지 분석에 대한 자동 검사</block>
  <block id="252ddb15657f2c60bddc73633a7bf8c0" category="cell">항공</block>
  <block id="7a84f6faf76fd3533ae6ca65d28c53eb" category="cell">항공 교통 제어 지원 및 실시간 비디오 피드 분석</block>
  <block id="81ea9456adf225bcf11b668b427fd4f2" category="cell">미디어 및 엔터테인먼트</block>
  <block id="5015819e58d425b19f8acc93866e76fa" category="cell">오디오/비디오 콘텐츠 필터링을 통해 가족 친화적인 콘텐츠를 제공합니다</block>
  <block id="616e90f12cb95950bc1c75396902393a" category="cell">비즈니스 분석</block>
  <block id="3e4c06851690089d4952320e9df36dc2" category="cell">브랜드 인지도를 통해 라이브 스트리밍 TV 행사에서 브랜드 이미지를 분석할 수 있습니다</block>
  <block id="a9f7ecebb493e129aafb4cbfd73e85df" category="cell">전자 상거래</block>
  <block id="5df4fc692c9317012855d6935bf10310" category="cell">이상적인 가맹점과 창고 조합을 찾기 위한 공급업체 제공의 스마트 번들</block>
  <block id="053e0bc8b9627b28e2ed8029a34b35bd" category="cell">소매</block>
  <block id="7cf7816e39e6e0c259a79dc29c5a5e7c" category="cell">고객이 장바구니에 넣은 품목을 인식하고 디지털 결제를 용이하게 하기 위한 자동 체크 아웃</block>
  <block id="165f5687ea9050fba239731810d0abe8" category="cell">스마트 시티</block>
  <block id="a47b360ffbe39c5a39c7e12e2ae8fdf5" category="cell">교통 흐름을 개선하고, 주차 상황을 최적화하고, 보행자 및 자전거 운전자 안전을 강화합니다</block>
  <block id="e86883c7cfc07afcf1e5ad8dffd7e1cc" category="cell">제조</block>
  <block id="f4d790a35097fa97c2687ac573b25338" category="cell">품질 관리, 조립 라인 모니터링 및 결함 식별</block>
  <block id="2273d1167a6212812d95dc8fadbae78e" category="cell">고객 서비스</block>
  <block id="bf4948e47ea0d77a86e639979879262d" category="cell">고객 서비스 자동화 - 전화, 이메일 및 소셜 미디어 등의 질문 분석 및 분류</block>
  <block id="8e54e9aa508ea37f7fe734e86ba9da27" category="cell">농업</block>
  <block id="7fb956270d49b22c3226bc1db2b0269f" category="cell">비료 및 살균제 사용을 최적화하기 위한 지능형 농장 운영 및 활동 계획</block>
  <block id="134481f7bea652a34fa2ada120d250e5" category="list-text">데이터 과학자</block>
  <block id="8d26f0555c7ace3d4b297da8c12fb31b" category="list-text">IT 설계자</block>
  <block id="c114d2813b0041352b49187ebc28b62b" category="list-text">현장 컨설턴트</block>
  <block id="2d6d0cc18609f97853f883c1891397d2" category="list-text">구축</block>
  <block id="467f739adb5605167109d76676b44696" category="list-text">IT 관리자</block>
  <block id="dcfa1c08d3b0126217af0b8690305c08" category="list-text">에지 위치에서 IT 혁신과 강력한 데이터 및 애플리케이션 서비스를 제공하는 인프라가 필요한 모든 고객</block>
  <block id="ad54e6f7d665098e981d7e41732ce4c2" category="inline-link-macro">다음: 아키텍처</block>
  <block id="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="paragraph"><block ref="dcea35e5c6c7dfb5a3d0b5083bb4bb90" category="inline-link-macro-rx"></block></block>
  <block id="8383a1cf96c028a0986b7371049c8495" category="doc">네트워크 장치 오류 예측 사용 사례 요약</block>
  <block id="dea416ff04e558b0d76cce896b618880" category="paragraph">이 사용 사례는 아시아 통신 분야의 이과지오 고객을 기반으로 합니다. 매년 100K 기업 고객 및 125k 네트워크 중단 이벤트가 발생하면서 네트워크 장애가 고객에게 영향을 미치지 않도록 사전에 조치를 취하고 예측해야 했습니다. 이 솔루션은 다음과 같은 이점을 제공합니다.</block>
  <block id="feb68271e6d14db0b1ff524f3eb47a27" category="list-text">네트워크 장애에 대한 예측 분석</block>
  <block id="70e00676492bea584fb8e7d551515eb5" category="list-text">발권 시스템과 통합</block>
  <block id="6de8d1444549249c0161228a7b7c1d27" category="list-text">네트워크 장애를 방지하기 위한 사전 예방 조치 이과지오(Iguazio)의 구현 결과, 60%의 장애를 사전에 예방했습니다.</block>
  <block id="fd80dbb606385d62c59605ec96147d3f" category="inline-link-macro">다음: 설정 개요</block>
  <block id="d31627f0c8fea1236773b2420ab9cd39" category="paragraph"><block ref="d31627f0c8fea1236773b2420ab9cd39" category="inline-link-macro-rx"></block></block>
  <block id="1d22ea3c852f35081a408a42b1caa719" category="doc">cnvrg.io 배포</block>
  <block id="e1d91df1cfd0e5839c45e06d0504c9d6" category="section-title">제어 장치를 사용하여 cnvrg 코어를 배포합니다</block>
  <block id="7e9e2a4317009b27ebfc0b4cd222ba30" category="paragraph">Helm은 모든 클러스터, 온프레미스, Minikube 또는 모든 클라우드 클러스터(예: AKS, EKS, GKE)를 사용하여 cnvrg를 신속하게 배포하는 가장 쉬운 방법입니다. 이 섹션에서는 Kubernetes가 설치된 사내(DGX-1) 인스턴스에 cnvrg를 설치한 방법을 설명합니다.</block>
  <block id="ea6de3fdf29035cd2d521949527c2a44" category="paragraph">설치를 완료하려면 먼저 로컬 컴퓨터에 다음 종속 항목을 설치하고 준비해야 합니다.</block>
  <block id="6f49e891fdb1bb11823492f4d315b2fd" category="list-text">쿠베틀입니다</block>
  <block id="5e6cef7c129d4703b20be420ac32145c" category="list-text">Helm 3.x</block>
  <block id="93fafc2be5db6c259030d6d8dc989752" category="list-text">Kubernetes 클러스터 1.15 이상</block>
  <block id="116efea8faeef9714de76fe9f81d9b82" category="section-title">헬름으로 배포</block>
  <block id="237800170a9b824a7de8c08766ea114e" category="list-text">최신 cnvrg Helm 차트를 다운로드하려면 다음 명령을 실행합니다.</block>
  <block id="9b821098b02043dada6b07b924f4ef5f" category="list-text">cnvrg를 구축하기 전에 클러스터의 외부 IP 주소와 cnvrg를 배포할 노드의 이름이 필요합니다. 사내 Kubernetes 클러스터에 cnvrg를 배포하려면 다음 명령을 실행합니다.</block>
  <block id="1d1eb4e0da8bac1b4eaa79c1f0be9e04" category="list-text">helm install 명령을 실행합니다. 모든 서비스 및 시스템이 클러스터에 자동으로 설치됩니다. 이 프로세스는 최대 15분 정도 소요될 수 있습니다.</block>
  <block id="e269e5751f8883222b6d2f55da7ed811" category="list-text">헬름 설치 명령은 10분 정도 걸릴 수 있습니다. 배포가 완료되면 새로 배포된 cnvrg의 URL로 이동하거나 새 클러스터를 조직 내의 리소스로 추가합니다. 'helm' 명령은 올바른 URL을 알려줍니다.</block>
  <block id="ac0cc75e8d4f0df818dd93a00041897a" category="list-text">모든 컨테이너의 상태가 실행 중 또는 완료됨이면 cnvrg가 성공적으로 배포된 것입니다. 이 결과는 다음 예제 출력과 유사해야 합니다.</block>
  <block id="3e82668da957bceb0d0c7024273ab624" category="section-title">ResNet50 및 Chest X-ray 데이터 집합을 사용한 컴퓨터 비전 모델 교육</block>
  <block id="c9c734dfca60f137a58e1a5cb9c89b62" category="inline-link">NIH 다운로드 사이트</block>
  <block id="0c7f26c15912f9f5d0e0473bb21cb9a2" category="paragraph">cnvrg.io AI OS는 NVIDIA DGX 시스템을 기반으로 하는 NetApp ONTAP AI 아키텍처를 기반으로 Kubernetes 설정에 구축했습니다. 검증을 위해 흉부 X-레이의 식별 불가 영상으로 구성된 NIH Chest X-ray 데이터 세트를 사용했습니다. 이미지는 PNG 형식이었습니다. 이 데이터는 NIH 임상 센터에서 제공했으며 을 통해 확인할 수 있습니다<block ref="4e3f11b94ad47864cbd9c6049036ac93" category="inline-link-rx"></block>. 15개 클래스에서 627, 615의 이미지를 사용하여 250GB 데이터 샘플을 사용했습니다.</block>
  <block id="de53b795a18176edb91a88632f621868" category="paragraph">데이터 세트가 cnvrg 플랫폼으로 업로드되었으며 NetApp AFF A800 스토리지 시스템에서 NFS 엑스포트에 캐싱되었습니다.</block>
  <block id="ec948f075c372d4beb7d19a5266f22d5" category="section-title">컴퓨팅 리소스 설정</block>
  <block id="42af2f71dc8561eb9cfe43d45664ecb3" category="paragraph">엔지니어 및 IT 전문가는 cnvrg 아키텍처 및 메타 스케줄링 기능을 사용하여 서로 다른 컴퓨팅 리소스를 단일 플랫폼에 연결할 수 있습니다. 설정에서 딥 러닝 워크로드를 실행하기 위해 배포된 것과 동일한 클러스터 cnvrg를 사용했습니다. 추가 클러스터를 연결해야 하는 경우 다음 스크린샷과 같이 GUI를 사용합니다.</block>
  <block id="df25fca4c07e68ed339b0e1974a9d59f" category="paragraph"><block ref="df25fca4c07e68ed339b0e1974a9d59f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f541774a08fc687f6e2016c77a6ebca5" category="section-title">데이터 로드</block>
  <block id="564bfd33ed32c02158989dfcee59ae89" category="paragraph">cnvrg 플랫폼에 데이터를 업로드하려면 GUI 또는 cnvrg CLI를 사용할 수 있습니다. 대규모 데이터 세트의 경우 많은 파일을 처리할 수 있는 강력하고 확장 가능하며 안정적인 툴이므로 CLI를 사용하는 것이 좋습니다.</block>
  <block id="41ad6001e0d3c17bd4a7957e18bd8bab" category="paragraph">데이터를 업로드하려면 다음 단계를 완료하십시오.</block>
  <block id="192b006166881688d04f398db712aaeb" category="inline-link">cnvrg CLI를 참조하십시오</block>
  <block id="8e9fbcfb57e26d7a14f0292c11fae122" category="list-text">를 다운로드합니다<block ref="d3ae4cf97b77cb5805c16205cd459ce4" category="inline-link-rx"></block>.</block>
  <block id="5cea56fcf2481a021f3d93843a22c319" category="list-text">X-ray 디렉토리로 이동합니다.</block>
  <block id="1c5a650f398227a4f97ed81accfbbb4b" category="list-text">'cnvrg data init' 명령으로 플랫폼 내 데이터세트를 초기화한다.</block>
  <block id="5c48f13a3d988e0d618145098a829e3a" category="list-text">중앙 오브젝트 저장소(StorageGRID, S3 등)에 데이터를 업로드한 후 GUI로 검색할 수 있습니다. 다음 그림은 로드된 흉부 X선 섬유증 영상 PNG 파일을 보여줍니다. 또한, cnvrg는 데이터를 버전화하므로 빌드하는 모든 모델을 데이터 버전으로 복제할 수 있습니다.</block>
  <block id="935b6e25167b65d839bc1487ebb2fa6e" category="paragraph"><block ref="935b6e25167b65d839bc1487ebb2fa6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="308e9394a715dc64aa4e48e0054775ed" category="section-title">Cach 데이터</block>
  <block id="556cde11a66a789acb7e62b934c1a88c" category="paragraph">각 모델의 교육 및 실험을 위해 600k+ 파일을 다운로드하지 않고 더 빠르게 교육을 제공하기 위해 데이터를 중앙 데이터 레이크 오브젝트 저장소에 처음 업로드한 후 데이터 캐싱 기능을 사용했습니다.</block>
  <block id="3d163413cac9b6cc4726a9c83d37fed3" category="paragraph"><block ref="3d163413cac9b6cc4726a9c83d37fed3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d006c100d76e7d21d64055ce3cfe6a24" category="paragraph">사용자가 캐시를 클릭하면 cnvrg는 원격 오브젝트 저장소에서 특정 커밋에 있는 데이터를 다운로드하여 ONTAP NFS 볼륨에 캐시합니다. 완료되면 데이터를 즉시 교육에 사용할 수 있습니다. 또한 데이터가 며칠 동안 사용되지 않으면(예: 모델 교육 또는 탐색) cnvrg가 자동으로 캐시를 지웁니다.</block>
  <block id="53ad459d9bb7a65de3d1cc839b75c19f" category="section-title">캐시된 데이터로 ML 파이프라인을 구축합니다</block>
  <block id="db226c80bcb6098ce2f47dd3982cca26" category="paragraph">cnvrg 흐름으로 생산 ML 파이프라인을 쉽게 구축할 수 있습니다. 흐름은 유연하며 모든 종류의 ML 사용 사례에 사용할 수 있으며 GUI 또는 코드를 통해 생성할 수 있습니다. 플로우의 각 구성 요소는 다른 Docker 이미지를 사용하여 다른 컴퓨팅 리소스에서 실행될 수 있으므로 하이브리드 클라우드와 최적화된 ML 파이프라인을 구축할 수 있습니다.</block>
  <block id="6b0eae96748d48b032362774a6467411" category="paragraph"><block ref="6b0eae96748d48b032362774a6467411" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e1f18dfff2566b35d7d0e528565c43aa" category="section-title">흉부 X선 흐름 구축:데이터 설정</block>
  <block id="adec555cb8cd4de3f288baed510d1163" category="paragraph">새로 생성된 흐름에 데이터 세트를 추가했습니다. 데이터 집합을 추가할 때 특정 버전(커밋)을 선택하고 캐시된 버전을 사용할지 여부를 지정할 수 있습니다. 이 예에서는 캐시된 커밋을 선택했습니다.</block>
  <block id="6dd780034ed574b328dbc16a6b485b79" category="paragraph"><block ref="6dd780034ed574b328dbc16a6b485b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13e0789c536fc18ddcdc32b4ca598b58" category="section-title">흉부 X선 흐름 구축:교육 모델 설정:ResNet50</block>
  <block id="fa3c48d58d8e9fd17365fd986906dd52" category="paragraph">파이프라인에서는 원하는 모든 종류의 사용자 지정 코드를 추가할 수 있습니다. cnvrg에는 재사용 가능한 ML 구성 요소 컬렉션인 AI 라이브러리도 있습니다. AI 라이브러리에는 모든 ML 또는 딥 러닝 플로우에 사용할 수 있는 알고리즘, 스크립트, 데이터 소스 및 기타 솔루션이 있습니다. 이 예에서는 사전 구축된 ResNet50 모듈을 선택했습니다. batch_size:128, epoch:10 등과 같은 기본 매개 변수를 사용했습니다. 이러한 매개 변수는 AI 라이브러리 문서에서 확인할 수 있습니다. 다음 스크린샷은 ResNet50에 연결된 X선 데이터 세트의 새로운 흐름을 보여줍니다.</block>
  <block id="defe5cc08faaa501eeb5fc5500664d29" category="paragraph"><block ref="defe5cc08faaa501eeb5fc5500664d29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf9bb479506589dfd719446fe3e054c7" category="section-title">ResNet50의 컴퓨팅 리소스를 정의합니다</block>
  <block id="943cb3f5c7789c68e811b0accdb6c5d9" category="paragraph">cnvrg 플로우의 각 알고리즘 또는 구성 요소는 다른 Docker 이미지와 함께 다른 컴퓨팅 인스턴스에서 실행될 수 있습니다. 저희 셋업에서는 NetApp ONTAP AI 아키텍처를 사용하여 NVIDIA DGX 시스템에 대한 훈련 알고리즘을 실행하려고 했습니다. 다음 그림에서는 사내 클러스터의 컴퓨팅 템플릿과 사양인 GPU-Real을 선택했습니다. 또한 템플릿 큐와 여러 템플릿을 선택했습니다. 이렇게 하면 'GPU-실제' 리소스를 할당할 수 없는 경우(예: 다른 데이터 과학자가 사용 중인 경우) 클라우드 공급자 템플릿을 추가하여 자동 클라우드 증가를 지원할 수 있습니다. 다음 스크린샷에서는 ResNet50의 컴퓨팅 노드로 GPU-real을 사용하는 방법을 보여 줍니다.</block>
  <block id="27c8450e6f62877ec794262ae4c5a713" category="paragraph"><block ref="27c8450e6f62877ec794262ae4c5a713" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bee38713f37ae72239f6bda08384dfbb" category="section-title">추적 및 모니터링 결과</block>
  <block id="546b7da7049f1d7fdf35cdb57fa96c7c" category="paragraph">흐름이 실행된 후 cnvrg가 추적 및 모니터링 엔진을 트리거합니다. 각 흐름 실행은 자동으로 문서화되고 실시간으로 업데이트됩니다. Hyperparameters, 메트릭, 리소스 사용량(GPU 활용률 등), 코드 버전, 아티팩트, 로그, 다음 두 스크린샷과 같이 실험 섹션에서 자동으로 사용할 수 있습니다.</block>
  <block id="8fabeb8b8d143d509bb92087cbbf953c" category="paragraph"><block ref="8fabeb8b8d143d509bb92087cbbf953c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdbd22304f732000189e44de22498da1" category="paragraph"><block ref="fdbd22304f732000189e44de22498da1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="debe391efc3dc12a7d87720a4cf068a5" category="paragraph"><block ref="debe391efc3dc12a7d87720a4cf068a5" category="inline-link-macro-rx"></block></block>
  <block id="efbb4ade01a09771413f4c09880e800a" category="paragraph">이 섹션에서는 여러 팀에서 워크로드를 제출하고 할당량을 초과하는 시나리오를 확장합니다. 이 방법으로 Run:AI의 Fairness 알고리즘이 사전 설정된 할당량의 비율에 따라 클러스터 리소스를 할당하는 방법을 보여 줍니다.</block>
  <block id="3bd5af2e3a75651c4b9c45d26400fbaa" category="paragraph">이 테스트 시나리오의 목표:</block>
  <block id="cc9e23eb4fe1626d97a5dfeab7cf0d25" category="list-text">여러 팀에서 할당량을 통해 GPU를 요청할 때 큐 메커니즘을 표시합니다.</block>
  <block id="050060785f2852b203c9e82254f2946a" category="list-text">할당량 비율에 따라 할당량이 초과된 여러 팀 간에 클러스터가 공평하게 분배되어 할당량이 더 큰 팀이 여유 용량을 더 많이 점유하도록 하는 방법을 보여 줍니다.</block>
  <block id="9e06f625a31670e60f0a8a09917c3ba0" category="paragraph">의 끝에 있습니다 <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>팀-b, 팀-c의 두 가지 워크로드가 대기 중입니다. 이 섹션에서는 추가 워크로드를 전담합니다.</block>
  <block id="286cda6cf9e9438a2cff2827773cfe7a" category="inline-link-macro">섹션 4.10의 테스트 세부 정보</block>
  <block id="0e7a9992269080ceaf2b90c188cbb861" category="paragraph">작업 제출, 사용된 컨테이너 이미지 및 실행된 명령 시퀀스를 포함한 자세한 내용은 을 참조하십시오 <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>.</block>
  <block id="b1df8ade330dd8e3c0962d87a58c1ba9" category="paragraph">섹션에 따라 모든 작업이 제출되는 경우 <block ref="37da92aa18d307c3afbe514e0c6c1f90" category="inline-link-macro-rx"></block>시스템 대시보드에는 팀-A, 팀-b, 팀-c가 모두 미리 설정된 할당량보다 더 많은 GPU를 가지고 있는 것으로 표시됩니다. 팀 A는 미리 설정된 소프트 쿼터보다 4개의 GPU를 더 점유하고, 팀 b와 팀 c는 각각 소프트 할당량(2개)보다 2개의 GPU를 더 점유합니다. 할당된 초과 할당량 GPU의 비율은 사전 설정된 할당량의 비율과 동일합니다. 이는 시스템이 사전 설정 할당량을 우선 순위에 따라 사용하고 여러 팀에서 더 많은 GPU를 요청하고 할당량을 초과할 경우 적절히 프로비저닝하기 때문입니다. 이러한 자동 로드 밸런싱은 엔터프라이즈 데이터 과학 팀이 AI 모델 개발 및 생산에 적극적으로 참여할 때 공정성과 우선순위를 제공합니다.</block>
  <block id="6effcb49094093af4699b050b9994a58" category="paragraph"><block ref="6effcb49094093af4699b050b9994a58" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3be1869ca88e0b5881bc6d1da583426" category="list-text">시스템이 다른 팀의 작업 부하를 취소하기 시작합니다.</block>
  <block id="d2325970b5cec6b47eb2c10267e3a599" category="list-text">대기열은 공정성 알고리즘에 따라 결정되며, 팀-b와 팀-c는 할당량 초과 GPU(할당량이 비슷하므로)와 동일한 양을 할당받습니다. 또 팀-A는 쿼터보다 2배 많은 양의 GPU를 갖게 된다. 팀-b, 팀-c의 쿼터보다 쿼터량이 2배 더 높기 때문이다.</block>
  <block id="e2cc28c61aaa6ca7e38bd7ed9de398f1" category="list-text">모든 할당이 자동으로 수행됩니다.</block>
  <block id="c21d5f3e7c1336258c406bddcde6e0f8" category="paragraph">따라서 시스템은 다음 상태에서 안정되어야 합니다.</block>
  <block id="8f2185cd998019e76038f11669cfbfb0" category="cell">GPU가 할당되었습니다</block>
  <block id="3b55c08436be9e1008bb19488c139c88" category="cell">8월 4일</block>
  <block id="f532ced5959572a93091758c821d7ff1" category="cell">할당량에 4개의 GPU가 사용됩니다. 대기열이 비어 있습니다.</block>
  <block id="c3a4885d143dc5b306446fb380c6cfda" category="cell">4월 2일</block>
  <block id="b0713292a73176f9754bd528cecde2d1" category="cell">할당량을 통해 2개의 GPU가 제공됩니다. 하나의 워크로드가 대기 중입니다.</block>
  <block id="1f0189591d8d7dc1d3db367398fb49c5" category="cell">0/8</block>
  <block id="7c0de9de98eb6577a96694238e533915" category="cell">GPU를 전혀 사용하지 않고, 대기 중인 워크로드가 없습니다.</block>
  <block id="948c32bf5f56f7dd6f3b2baab5f6d89d" category="paragraph">다음 그림에서는 섹션에 대한 Run:AI Analytics 대시보드의 시간별 프로젝트당 GPU 할당을 보여 줍니다 <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>, <block ref="26be59a535445b1fffeef12f5e70f3e6" category="inline-link-macro-rx"></block>, 및 <block ref="2783e1454358e180d4e2876ef9492c64" category="inline-link-macro-rx"></block>. 그림의 각 줄은 언제든지 특정 데이터 과학 팀에 프로비저닝된 GPU 수를 나타냅니다. 시스템이 제출된 워크로드에 따라 GPU를 동적으로 할당하는지 확인할 수 있습니다. 따라서 클러스터에 사용 가능한 GPU가 있을 때 팀은 할당량을 초과하고, 공정성에 따라 작업을 사전에 미분하여 4팀 모두에 대해 안정적인 상태가 될 수 있습니다.</block>
  <block id="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="paragraph"><block ref="d7fc0f82166b3a8fb5cbc55d2fb5efb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e94097f9836d70dc64016728992696a0" category="inline-link-macro">다음: Trident에서 프로비저닝한 PersistentVolume에 데이터 저장</block>
  <block id="14718f3c808034f0e3239dbaf832a478" category="paragraph"><block ref="14718f3c808034f0e3239dbaf832a478" category="inline-link-macro-rx"></block></block>
  <block id="2034cc978abb3057c4cf27e92b16ee74" category="doc">Kubernetes 구축</block>
  <block id="47302a7393e0a038a150e679c9b3e80d" category="paragraph">NVIDIA DeepOps를 사용하여 Kubernetes 클러스터를 구축하고 구성하려면 배포 점프 호스트에서 다음 작업을 수행하십시오.</block>
  <block id="5c51dc3fcfdd9653809e90fa3948c2f4" category="inline-link">시작 페이지</block>
  <block id="21f937997adb0cac073e2458491f2c2f" category="list-text">의 지침에 따라 NVIDIA DeepOps를 다운로드합니다<block ref="a94c3c17b923443c927cfa8fe7a2482a" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="76ada3ea43b0e44772967793fe69b1bd" category="inline-link">Kubernetes 구축 가이드</block>
  <block id="03628142cdc704dd6ffe5d7d13573999" category="list-text">의 지침에 따라 클러스터에 Kubernetes를 배포합니다<block ref="cdf0a6d71dcbe898357c0e37010d30de" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="2dfe8bb84d94f23030d91e315d7899bc" category="admonition">DeepOps Kubernetes 구축이 작동하려면 모든 Kubernetes 마스터 및 작업자 노드에 동일한 사용자가 있어야 합니다.</block>
  <block id="c6fff1434177c1b95244b5300314f730" category="paragraph">배포가 실패하면 depops/config/group_vars/k8s-cluster.yml에서 kubctl_localhost의 값을 false로 변경하고 2단계를 반복합니다. kubeck_localhost의 값이 true인 경우에만 실행되는 Ansible 호스트에 kubbeck 바이너리 복사 작업은 알려진 메모리 사용 문제가 있는 Ansible 모듈 가져오기를 사용합니다. 이러한 메모리 사용 문제로 인해 작업이 실패할 수 있습니다. 메모리 문제로 인해 작업이 실패하면 나머지 배포 작업이 성공적으로 완료되지 않습니다.</block>
  <block id="24e1fa4c913dcdc975e022f921d4d603" category="paragraph">kubbctl_localhost의 값을 false로 변경한 후 배포가 성공적으로 완료되면 Kubernetes 마스터 노드에서 배포 점프 호스트로 kubbectl 바이너리를 수동으로 복사해야 합니다. 특정 마스터 노드에서 kudctl 명령을 직접 실행하여 kubctl 바이너리의 위치를 찾을 수 있습니다.</block>
  <block id="a185054da23018c3578742c41141312b" category="inline-link-macro">다음: cnvrg.io 배포</block>
  <block id="c18b567a6a5397941715c30a00a97395" category="paragraph"><block ref="c18b567a6a5397941715c30a00a97395" category="inline-link-macro-rx"></block></block>
  <block id="337f05fad2de58e4a8b74cb25536b52d" category="doc">설정 개요</block>
  <block id="666f45aef7a28ef5ba6e4bfb2f71bcee" category="section-title">Iguazio 설치</block>
  <block id="b681b0e4b3576aa1cd854e2b66c16dcd" category="paragraph">Iguazio는 온프레미스 또는 클라우드 공급자에 설치할 수 있습니다. 프로비저닝은 서비스로 수행하고 Iguazio 또는 고객이 관리할 수 있습니다. 두 경우 모두 Iguazio는 클러스터를 배포 및 관리하기 위한 배포 애플리케이션(Provazio)을 제공합니다.</block>
  <block id="8334797b9b3383d4f48d98178b8845ea" category="inline-link">이 페이지</block>
  <block id="ade8a7efee71036d2ca57676a54b31e3" category="paragraph">온-프레미스 설치의 경우 을 참조하십시오<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block> 컴퓨팅, 네트워크 및 스토리지 설정을 위해 사용할 수 있습니다. Iguazio는 고객의 추가 비용 없이 구내 배치 서비스를 제공합니다. 을 참조하십시오<block ref="d273dd0a16e6003b56381a70823807f7" category="inline-link-rx"></block> DNS 및 SMTP 서버 구성의 경우 Provazio 설치 페이지는 다음과 같다.</block>
  <block id="8e72dced5918c4009ff80044ba6f44db" category="paragraph"><block ref="8e72dced5918c4009ff80044ba6f44db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c16d8d5e717cd029389f76abddf769b7" category="inline-link-macro">다음: Kubernetes 클러스터 구성</block>
  <block id="1d42e0b2a8893ff00a35554162554936" category="paragraph"><block ref="1d42e0b2a8893ff00a35554162554936" category="inline-link-macro-rx"></block></block>
  <block id="1f9a7430deed674d394796eaea14138f" category="paragraph">이 기술 보고서에서는 Run:AI CLI 및 NetApp ONTAP AI의 시스템 대시보드를 사용하여 Kubernetes 클러스터 및 GPU 사용을 최적화할 수 있는 중소기업과 대형 데이터 과학/엔지니어링 팀을 보유한 고객을 위한 지침을 제공합니다. 또한 검증된 테스트 사례를 위한 Run:AI 플랫폼 설치 정보, 테스트 시나리오, 세부 명령도 포함되어 있습니다. Run:AI 오케스트레이션 솔루션과 NetApp AI Control Plane은 최적의 리소스 활용을 통해 개발자 생산성을 향상하여 혁신을 위한 시간을 단축합니다.</block>
  <block id="892726726d592ee18c9ee8ad25a088ae" category="inline-link-macro">다음: 핵심 요약</block>
  <block id="e6c479abab08e982bd2f0efd6e3e405a" category="paragraph"><block ref="e6c479abab08e982bd2f0efd6e3e405a" category="inline-link-macro-rx"></block></block>
  <block id="0e85d8fd0ce7acdba87f57325a14b3fb" category="summary">이전 섹션에서 언급한 바와 같이, 두 개 이상의 기계 학습 모델이 순서대로 실행될 때마다 오류가 파이프라인 전체에 전파됩니다. 이 솔루션을 위해, 이 회사의 주식 리스크 수준을 측정하는 데 있어 가장 중요한 요소는 문장의 감정입니다. 파이프라인에 필수적인 스피치-텍스트 모델은 정서를 예측할 수 있는 전처리부 역할을 합니다.</block>
  <block id="6700d3710d10e74d6e48f994b760d48b" category="doc">검증 결과</block>
  <block id="ee4eec78ae095f539af53c130e976afa" category="inline-link-macro">이전: 지원 센터 감정 분석 구축</block>
  <block id="ac96c8f3af95b93c2683c2124998e668" category="paragraph"><block ref="ac96c8f3af95b93c2683c2124998e668" category="inline-link-macro-rx"></block></block>
  <block id="2e10a4ae90aad11c07592a14fbf8c5c6" category="paragraph">이전 섹션에서 언급한 바와 같이, 두 개 이상의 기계 학습 모델이 순서대로 실행될 때마다 오류가 파이프라인 전체에 전파됩니다. 이 솔루션을 위해, 이 회사의 주식 리스크 수준을 측정하는 데 있어 가장 중요한 요소는 문장의 감정입니다. 파이프라인에 필수적인 스피치-텍스트 모델은 정서를 예측할 수 있는 전처리부 역할을 합니다. 진짜 중요한 것은 근거 있는 진실과 예측된 문장 사이의 감정의 차이이다. 이는 WER(Error Rate)의 프록시 역할을 합니다. 음성-텍스트 정확도는 중요하지만 WER은 최종 파이프라인 메트릭에 직접 사용되지 않습니다.</block>
  <block id="0fc4c7871adf5db8dd2b13fc4c381da8" category="paragraph">이러한 정서 메트릭은 각 문장의 F1 점수, 리콜 및 정밀도에 대해 계산할 수 있습니다. 그런 다음 결과를 집계하여 각 메트릭의 신뢰 간격과 함께 혼란 매트릭스 내에 표시할 수 있습니다.</block>
  <block id="66554c8f1474c5658d17e23710901f98" category="paragraph">전송 학습 기능을 사용하면 적은 데이터 요구사항, 교육 시간 및 비용으로 모델 성능을 향상할 수 있습니다. 또한 세부 조정된 모델을 기준 버전과 비교하여 전송 학습이 페어링되지 않고 성능을 향상시키도록 해야 합니다. 다시 말해, 세부 조정된 모델은 사전 교육 모델보다 지원 센터 데이터의 성능이 더 우수해야 합니다.</block>
  <block id="6e979ee914c9401fddd049d16cdef66a" category="section-title">파이프라인 평가</block>
  <block id="7f109f66c71a1fd15436d1c413354c41" category="cell">테스트 케이스</block>
  <block id="e7f1ec3a5f35af805407a8a531eefb79" category="cell">테스트 번호</block>
  <block id="6bf1af9a7f1b6dd6cca4b7434097ad94" category="cell">파이프라인 정서 지표</block>
  <block id="beed3529b961c63b785104d7a17cf5f4" category="cell">테스트 필수 구성 요소</block>
  <block id="c7320b1f70fd8a9831e530d17a82f34d" category="cell">음성-텍스트 및 정서 분석 모델을 위해 미세 조정된 모델</block>
  <block id="9d5b1bc6dcdedf0c8750e543fab75738" category="cell">예상 결과</block>
  <block id="74015a89b882f01e94433a9c1f1c904c" category="cell">미세 조정된 모델의 정서 측정 기준은 원래 사전 교육 모델보다 성능이 뛰어납니다.</block>
  <block id="68d279a19e31962e0ab0b648f25c07ee" category="list-text">기준 모델의 정서 메트릭을 계산합니다.</block>
  <block id="b6168629c9e5a47b0637aa362112642d" category="list-text">미세 조정된 모델의 정서 메트릭을 계산합니다.</block>
  <block id="97ae5da5f745d90cf815a206b3549e0a" category="list-text">이러한 메트릭 간의 차이를 계산합니다.</block>
  <block id="fc997f472d1b5e66aadb364e10c29f4f" category="list-text">모든 문장에 걸친 평균 차이입니다.</block>
  <block id="c6b3b1378b2e31169a4a1cd4c20691c8" category="inline-link-macro">다음: 비디오 및 데모</block>
  <block id="6016219a0b0ad0bb3594f964b5e6396d" category="paragraph"><block ref="6016219a0b0ad0bb3594f964b5e6396d" category="inline-link-macro-rx"></block></block>
  <block id="9d273bd32c1fceb91b7d6a4d40e98bdd" category="doc">소프트웨어 요구 사항</block>
  <block id="8e926487edd9348114ada5fa88a732df" category="paragraph">이 솔루션은 Run:AI 운영자가 설치된 기본 Kubernetes 구축을 사용하여 검증되었습니다. Kubernetes는 를 사용하여 구축했습니다<block ref="1c894f7463797b81796e78efc8345fb0" category="inline-link-rx"></block> 구축 엔진: 즉시 프로덕션할 수 있는 환경에 필요한 모든 구성 요소를 배포합니다. DeepOps가 자동으로 배포됩니다<block ref="ca1c90879f9a0e8dc4ff805fb398f7ff" category="inline-link-rx"></block> 스토리지를 K8s 환경과 지속적으로 통합하고 기본 스토리지 클래스를 만들어 컨테이너가 AFF A800 스토리지 시스템에서 스토리지를 활용하도록 했습니다. ONTAP AI 기반 Kubernetes를 사용하는 Trident에 대한 자세한 내용은 를 참조하십시오<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block>.</block>
  <block id="a2525584dd9d2a9522ddea95841c06b3" category="cell">9.6p4</block>
  <block id="4a5be8fea83a32ad5c7fc31b02ef1028" category="cell">4.0.4 - Ubuntu 18.04 LTS</block>
  <block id="80afba45eb055fc9bdc48c90d1debd06" category="cell">Kubernetes 버전</block>
  <block id="4bbe90408850f459864a71c8054732f1" category="cell">1.17</block>
  <block id="f1112223b41fddc71fd6a626582dfb78" category="cell">Trident 버전</block>
  <block id="43d66966083b0e0feac8fb9be14ba5b8" category="cell">20.04.0</block>
  <block id="e993176eed424766bc6bd4758eaf2cb6" category="cell">실행: AI CLI</block>
  <block id="5e6305186adf6e7dcf03f5cbfc802c49" category="cell">v2.1.13</block>
  <block id="f3eeed8e4b2791f80e2f123c4720aef5" category="cell">실행: AI Orchestration Kubernetes Operator version</block>
  <block id="bf8c2933a2f54ce25fe986f66d3bffa3" category="cell">1.0.39</block>
  <block id="0cc9a8e76e0a79d0e0072e0a0d675fe5" category="cell">18.06.1-CE[e68fc7a]</block>
  <block id="076ca75e2fc5b6ea85d72b0a9adc8844" category="inline-link">AI GPU 클러스터의 사전 요구사항 을 실행하십시오</block>
  <block id="eaec7f01752b17abf6125d8f29a8543c" category="paragraph">Run:AI에 대한 추가 소프트웨어 요구사항은 에서 확인할 수 있습니다<block ref="98bb21d82bcd499a183c82dcfc9b02f3" category="inline-link-rx"></block>.</block>
  <block id="cc352f05f03c970b081b8afa29693b60" category="inline-link-macro">다음: AI 실행을 통한 최적의 클러스터 및 GPU 활용률</block>
  <block id="f7235eb2146d800446cbbbac3a57548c" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block>.</block>
  <block id="9a50201aa3bf66a7a0337ccf29d20c90" category="doc">솔루션 기술</block>
  <block id="ed4a202c34987f40d5e245e76a65a243" category="paragraph">다음 그림에서는 제안한 대화형 AI 시스템 아키텍처를 보여 줍니다. 음성 신호 또는 텍스트 입력으로 시스템과 상호 작용할 수 있습니다. 음성 입력이 감지되면 Jarvis AIaaS(AI-as-service)가 ASR을 수행하여 Dialog Manager에 대한 텍스트를 생성합니다. 대화 관리자는 대화 상태를 기억하고, 텍스트를 해당 서비스로 라우팅하고, 명령을 이행 엔진에 전달합니다. Jarvis NLP 서비스는 텍스트를 가져와 인텐트와 엔터티를 인식하고 이러한 인텐트와 엔터티 슬롯을 다시 대화 상자 매니저로 출력한 다음 작업을 이행 엔진에 보냅니다. 이행 엔진은 사용자 쿼리에 응답하는 타사 API 또는 SQL 데이터베이스로 구성됩니다. 이행 엔진에서 결과를 수신한 후 대화 상자 관리자는 텍스트를 Jarvis TTS AIaaS로 라우팅하여 최종 사용자에 대한 오디오 응답을 생성합니다. 대화 기록을 보관하고, intents와 nemo 교육 슬롯을 사용해 문장에 주석을 달 수 있습니다. 그러면 NLP 서비스가 시스템과 상호 작용하는 사용자가 많아질수록 성능이 향상됩니다.</block>
  <block id="308a0722262fbc3adde5d5d900ad0c36" category="paragraph"><block ref="308a0722262fbc3adde5d5d900ad0c36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="863eef2617ffc374c485389aabdd8a24" category="paragraph">이 솔루션은 하나의 DGX Station과 하나의 AFF A220 스토리지 시스템을 사용하여 검증되었습니다. Jarvis는 딥 신경 네트워크 계산을 수행하려면 T4 또는 V100 GPU가 필요합니다.</block>
  <block id="71c9e70899509bff35197ba9da10dafc" category="cell">T4 또는 V100 GPU</block>
  <block id="8f452959667e7665cddf2484ddca1724" category="cell">NVIDIA DGX 스테이션</block>
  <block id="f7a05af899e536cde0a9c8476c2da0a1" category="paragraph">다음 표에는 테스트를 통해 솔루션을 구현하는 데 필요한 소프트웨어 구성요소가 나와 있습니다.</block>
  <block id="eaf2f97729e8d5e4d205672da8afc9a5" category="cell">9.6</block>
  <block id="0664d9eb73230b2a0b514b0facae8ade" category="cell">NVIDIA Jarvis 프레임워크</block>
  <block id="cc5f21cb121669006a19c9fde049f048" category="cell">EA v0.2</block>
  <block id="dfcc0491fc5a6e738ca8b5ef3a258093" category="cell">NVIDIA 니모</block>
  <block id="317fe32bf712dffb43ddc0ee8dde8c3c" category="cell">nvcr.io/nvidia/nemo:v0.10</block>
  <block id="3032d0de2852f0bb1e13142c2c47cd5b" category="inline-link-macro">다음: Jarvis, Cloud Sync 및 Nemo 개요를 사용하여 가상 도우미를 만듭니다</block>
  <block id="5cefb81f0324c44ec13c02fa7700924b" category="paragraph"><block ref="5cefb81f0324c44ec13c02fa7700924b" category="inline-link-macro-rx"></block></block>
  <block id="b831e128b8fd177e9c80396ed741b7c1" category="doc">하드웨어 및 소프트웨어 요구 사항</block>
  <block id="afee48a46dd68b9618cec81a8ee5ba86" category="paragraph">이 섹션에서는 ONTAP AI 솔루션의 기술 요구사항을 다룹니다.</block>
  <block id="e96b7604f8b75ae786c6c0e1016e46fd" category="inline-link">ONTAP AI 웹 사이트</block>
  <block id="929f5f13d86d1be55b96dba26e773c6f" category="paragraph">하드웨어 요구사항은 특정 고객 워크로드에 따라 다르지만, ONTAP AI는 대규모 ML/DL 작업을 위해 단일 GPU에서 랙 확장 구성까지 데이터 엔지니어링, 모델 훈련, 운영 추론을 위해 어떤 확장하고 구축할 수 있습니다. ONTAP AI에 대한 자세한 내용은 를 참조하십시오<block ref="7ec9b089c41da1b986bad97e1099df1c" category="inline-link-rx"></block>.</block>
  <block id="41e840b508d9e839f95d16dd582af8d6" category="paragraph">이 솔루션은 컴퓨팅, NetApp AFF A800 스토리지 시스템 및 Cisco Nexus 3232C 네트워크 연결을 위해 DGX-1 시스템을 사용하여 검증되었습니다. 이 검증에 사용된 AFF A800은 대부분의 ML/DL 워크로드에 대해 최대 10개의 DGX-1 시스템을 지원할 수 있습니다. 다음 그림은 이 검증에서 모델 훈련에 사용되는 ONTAP AI 토폴로지를 보여줍니다.</block>
  <block id="bc2eb92d1e1797a759b677c38f619a8f" category="paragraph"><block ref="bc2eb92d1e1797a759b677c38f619a8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d98e5c43e7b3be89fe8a9076f89f1e99" category="paragraph">이 솔루션을 퍼블릭 클라우드로 확장하려면 Cloud Volumes ONTAP을 클라우드 GPU 컴퓨팅 리소스와 함께 구축하고 하이브리드 클라우드 데이터 패브릭에 통합하면 모든 워크로드에 적합한 리소스를 사용할 수 있습니다.</block>
  <block id="4dc70b997a39a64b2def3ef74a96fdb4" category="paragraph">다음 표는 이 솔루션 검증에 사용된 특정 소프트웨어 버전을 보여줍니다.</block>
  <block id="2cb05e4bb7830be982f0922fed86b4cd" category="cell">구성 요소</block>
  <block id="3d945423f8e9496c429a5d8c65b4604f" category="cell">우분투</block>
  <block id="d173e10eb6a0fc7969fe540c987e0c7d" category="cell">18.04.4 LTS</block>
  <block id="9b4bffa460105781f82b1d463bde8200" category="cell">4.4.0</block>
  <block id="3c1d47ba5c1ada327abd4532ff9f4437" category="cell">20.02.1</block>
  <block id="0083e57a258edd18b949d3afbf6cfc2a" category="cell">1.15</block>
  <block id="232de5556d4148d75b55012e1230616c" category="cell">3.1.0</block>
  <block id="7b02ea300aef2e0bff0d7f6111053284" category="cell">NetApp ONTAP를 참조하십시오</block>
  <block id="d8a31094f88724af6834c47a6697dc56" category="cell">9.6P4</block>
  <block id="9909115a4f9fe32731077286c367501c" category="paragraph">이 솔루션 검증에서 Kubernetes는 DGX-1 시스템에서 단일 노드 클러스터로 구축되었습니다. 대규모 배포의 경우 관리 서비스의 고가용성을 제공하고 ML 및 DL 워크로드에 대한 중요한 DGX 리소스를 예약하려면 독립 Kubernetes 마스터 노드를 구축해야 합니다.</block>
  <block id="1c428dd76324aae91879799ae73fbc37" category="inline-link-macro">다음: 솔루션 배포 및 검증 세부 정보</block>
  <block id="5e5761a91dc25c881f4ca86678634b1b" category="paragraph"><block ref="5e5761a91dc25c881f4ca86678634b1b" category="inline-link-macro-rx"></block></block>
  <block id="d7cd7846436814deb26b0df06d7a4b2a" category="summary">Kubernetes 클러스터에서 동기식 다중 노드 AI 및 ML 작업을 실행하려면 배포 점프 호스트에서 이 페이지에 나열된 작업을 수행하십시오. 이 프로세스를 통해 NetApp 볼륨에 저장된 데이터를 활용하고 단일 작업자 노드가 제공할 수 있는 것보다 더 많은 GPU를 사용할 수 있습니다.</block>
  <block id="8725f0c1877790fea82aedbc23e26e70" category="doc">동기식 분산 AI 워크로드 실행</block>
  <block id="deb7f52575de614a91ae7472b76138ec" category="paragraph">Kubernetes 클러스터에서 동기식 다중 노드 AI 및 ML 작업을 실행하려면 배포 점프 호스트에서 다음 작업을 수행하십시오. 이 프로세스를 통해 NetApp 볼륨에 저장된 데이터를 활용하고 단일 작업자 노드가 제공할 수 있는 것보다 더 많은 GPU를 사용할 수 있습니다. 동기식 분산 AI 작업을 설명하는 방법은 다음 그림을 참조하십시오.</block>
  <block id="c073d47c72ebccdc821d9e6419b3008c" category="admonition">동기 분산 작업은 비동기 분산 작업에 비해 성능 및 교육 정확도를 높일 수 있습니다. 동기 작업과 비동기 작업의 장단점을 논하는 것은 이 문서의 범위를 벗어납니다.</block>
  <block id="262523fcbe6eb0ec96ea58299e58f65c" category="paragraph"><block ref="262523fcbe6eb0ec96ea58299e58f65c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a9af10e4883efa64de927027b5b0ffa" category="list-text">다음 명령 예는 섹션의 예에서 단일 노드에서 실행된 동일한 TensorFlow 벤치마크 작업의 동기식 분산 실행에 참여하는 작업자 1명의 생성을 보여 줍니다 <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>. 이 특정 예제에서는 작업이 두 작업자 노드에 걸쳐 실행되므로 한 명의 작업자만 배포됩니다.</block>
  <block id="e3a5f2bdfc8576b6847bcbf0d53889d4" category="paragraph">이 작업자 배포는 8개의 GPU를 요청하므로 8개 이상의 GPU를 갖춘 단일 GPU 작업자 노드에서 실행할 수 있습니다. GPU 작업자 노드에서 8개 이상의 GPU를 사용하여 성능을 극대화한 경우, 이 숫자를 작업자 노드가 갖춘 GPU 수와 같게 늘리고 싶을 수 있습니다. Kubernetes 구축에 대한 자세한 내용은 를 참조하십시오<block ref="29c4feb256f061356947baec0e1bfcb2" category="inline-link-rx"></block>.</block>
  <block id="bfe89db11adc9a38165e670f3062d398" category="paragraph">이 예에서는 특정 컨테이너형 작업자가 자체적으로 완료되지 않기 때문에 Kubernetes 구축이 생성됩니다. 따라서 Kubernetes 작업 구성을 사용하여 구축하는 것은 타당하지 않습니다. 작업자가 혼자서 완료되도록 설계되거나 작성된 경우 작업 구성을 사용하여 작업자를 배포하는 것이 합리일 수 있습니다.</block>
  <block id="05bdf5435b916b7b205f448788324f2b" category="paragraph">이 예제 배포 사양에 지정된 POD에 "true"의 "hostNetwork" 값이 제공됩니다. 이 값은 이 Pod가 일반적으로 Kubernetes에서 각 Pod에 생성하는 가상 네트워킹 스택 대신 호스트 작업자 노드의 네트워킹 스택을 사용한다는 것을 의미합니다. 이 경우 특정 워크로드는 개방형 MPI, NCCL 및 Horovod를 통해 동기식 분산 방식으로 워크로드를 실행하기 때문에 이 주석이 사용됩니다. 따라서 호스트 네트워킹 스택에 액세스해야 합니다. 공개 MPI, NCCL 및 Horovod에 대한 논의는 이 문서의 범위를 벗어납니다. 이 "hostNetwork: true" 주석이 필요한지 여부는 실행 중인 특정 워크로드의 요구 사항에 따라 달라집니다. hostNetwork 필드에 대한 자세한 내용은 를 참조하십시오<block ref="f46b1bf9e67570ceac06230c1e502909" category="inline-link-rx"></block>.</block>
  <block id="b3f8c0432fa807543e6e24f429362a32" category="list-text">1단계에서 만든 작업자 배포가 성공적으로 시작되었는지 확인합니다. 다음 예제 명령은 배포 정의에 나와 있는 것처럼 단일 작업자 POD가 배포용으로 생성되었으며 이 POD가 현재 GPU 작업자 노드 중 하나에서 실행되고 있음을 확인합니다.</block>
  <block id="3ba975f6a7389af18602f0e938bcc37b" category="list-text">동기 다중 노드 작업의 실행을 종료, 참여 및 추적하는 마스터에 대한 Kubernetes 작업을 생성합니다. 다음 명령 예에서는 이 섹션의 예제에서 단일 노드에서 실행된 것과 동일한 TensorFlow 벤치마크 작업의 동기식 분산 실행을 시작, 참여 및 추적하는 하나의 마스터를 생성합니다 <block ref="b66468ea886b06cfd7c572c68cd74c28" category="inline-link-macro-rx"></block>.</block>
  <block id="4161928cbea20386310894ea85fd3711" category="paragraph">이 마스터 작업에서는 8개의 GPU를 요청하므로 8개 이상의 GPU를 갖춘 단일 GPU 작업자 노드에서 실행할 수 있습니다. GPU 작업자 노드에서 8개 이상의 GPU를 사용하여 성능을 극대화한 경우, 이 숫자를 작업자 노드가 갖춘 GPU 수와 같게 늘리고 싶을 수 있습니다.</block>
  <block id="3e04ef9469e6953d66ae9c7536ed9b26" category="paragraph">이 예에서 지정한 마스터 포드는 1단계에서 작업자 포드가 hostNetwork 값이 true인 것처럼 true의 hostNetwork 값이 지정됩니다. 이 값이 필요한 이유에 대한 자세한 내용은 1단계를 참조하십시오.</block>
  <block id="8600ba20f40fb5668a1b2c02f92e220d" category="list-text">3단계에서 만든 마스터 작업이 올바르게 실행되고 있는지 확인합니다. 다음 예제 명령은 작업 정의에 나와 있는 것처럼 작업에 대해 단일 마스터 포드가 생성되었으며 이 포드가 현재 GPU 작업자 노드 중 하나에서 실행되고 있음을 확인합니다. 또한 1단계에서 처음 보았던 작업자 포드가 여전히 실행 중이고 마스터 포드와 작업자 포드가 다른 노드에서 실행되고 있음을 확인해야 합니다.</block>
  <block id="0f27ae3c630b411ce8f8dc123361f1b1" category="list-text">3단계에서 만든 마스터 작업이 성공적으로 완료되었는지 확인합니다. 다음 명령 예에서는 작업이 성공적으로 완료되었음을 확인합니다.</block>
  <block id="6fe5035373f479ed2a1c1d457e64ae9d" category="list-text">작업자 배포가 더 이상 필요하지 않으면 삭제합니다. 다음 예제 명령은 1단계에서 만든 작업자 배포 개체를 삭제하는 방법을 보여 줍니다.</block>
  <block id="e3861d1527373e7d8eeea1704f818a15" category="paragraph">작업자 배포 개체를 삭제하면 Kubernetes에서 연결된 작업자 포드를 자동으로 삭제합니다.</block>
  <block id="7e4d2c0ae78fc38eeb38ffe12f736290" category="list-text">* 선택 사항: * 마스터 작업 아티팩트를 정리하십시오. 다음 예제 명령은 3단계에서 만든 마스터 작업 오브젝트의 삭제를 보여 줍니다.</block>
  <block id="d844794bfc5a0949dc2c38fecacf9ff1" category="paragraph">마스터 작업 개체를 삭제하면 연결된 마스터 포드가 자동으로 삭제됩니다.</block>
  <block id="256fbc599203bd1bd63bfe25b7a5b9ad" category="inline-link-macro">다음: 성능 테스트.</block>
  <block id="35bb3345a07dfa439dd6936ea8f69faf" category="paragraph"><block ref="35bb3345a07dfa439dd6936ea8f69faf" category="inline-link-macro-rx"></block></block>
  <block id="e7446d382d8184be0a342a2fc45d4394" category="doc">WP-7328: NVIDIA Jarvis를 사용하는 NetApp 대화형 AI</block>
  <block id="5dabc617366db74ce2a9fa3915f6af5a" category="paragraph">Rick Huang, Sung-Han Lin, NetApp Davide Onfrio, NVIDIA</block>
  <block id="018aacc6ea95e20996bf57b319fd037a" category="paragraph">NVIDIA DGX 시스템 제품군은 엔터프라이즈 AI용으로 특별 제작된 세계 최초의 통합 인공 지능(AI) 기반 시스템으로 구성되어 있습니다. NetApp AFF 스토리지 시스템은 탁월한 성능과 업계 최고 수준의 하이브리드 클라우드 데이터 관리 기능을 제공합니다. NetApp과 NVIDIA는 협력 관계를 맺고 엔터프라이즈급 성능, 안정성 및 지원을 제공하는 AI 및 머신 러닝(ML) 워크로드를 위한 턴키 솔루션인 NetApp ONTAP AI 참조 아키텍처를 구축했습니다.</block>
  <block id="1a76c739ce37834495a22c5db663d24b" category="paragraph">이 백서에서는 다양한 산업 분야의 다양한 사용 사례를 지원하는 대화 AI 시스템을 구축하는 고객에게 직접 지침을 제공합니다. NVIDIA Jarvis를 사용하는 시스템 구축에 대한 정보를 제공합니다. 테스트는 NVIDIA DGX Station 및 NetApp AFF A220 스토리지 시스템을 사용하여 수행되었습니다.</block>
  <block id="f813bd56d696cb8de386a53a37eed6f6" category="list-text">가상 소매 비서 등의 대화형 AI 사용 사례를 위한 AI 모델 및 소프트웨어 개발을 위한 솔루션을 설계하는 엔터프라이즈 설계자</block>
  <block id="0497dfe9ff978e87977c978d3443e206" category="list-text">언어 모델링 개발 목표를 달성하기 위한 효율적인 방법을 찾고 있는 데이터 과학자</block>
  <block id="e84c345e30f668aa19a041e2e12bc9fe" category="list-text">고객 질문 및 대화 내용 등 텍스트 데이터의 유지 관리 및 처리를 담당하는 데이터 엔지니어</block>
  <block id="00101e6b2bf526b1ee79d39389f461fa" category="list-text">대화형 AI 경험을 바꾸고 AI 이니셔티브를 통해 출시 시기를 앞당기고자 하는 경영진 및 IT 의사 결정자 및 비즈니스 리더</block>
  <block id="88851610d9d91a7b78ab814276bebba7" category="paragraph"><block ref="88851610d9d91a7b78ab814276bebba7" category="inline-link-macro-rx"></block></block>
  <block id="1a7fa7cc4c79d5163f691ff60e6fc34d" category="doc">실행: AI 대시보드 및 뷰</block>
  <block id="3473dab452c5446b1a01a923e9879461" category="paragraph">Run:AI를 Kubernetes 클러스터에 설치하고 컨테이너를 올바르게 구성하면 에 다음과 같은 대시보드와 뷰가 표시됩니다<block ref="2af90fde6f4d8ae5947b005d1208e742" category="inline-link-rx"></block> 다음 그림과 같이 브라우저에서</block>
  <block id="f977554b7762214959db36c20484c697" category="paragraph"><block ref="f977554b7762214959db36c20484c697" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8dfd99441ce89d4be896e4fc9757f7d2" category="paragraph">2개의 DGX-1 노드에서 제공하는 클러스터에 총 16개의 GPU가 있습니다. 노드 수, 총 사용 가능한 GPU, 워크로드와 할당된 할당된 할당된 GPU, 총 실행 중인 작업 수, 보류 중인 작업 및 유휴 할당 GPU를 볼 수 있습니다. 오른쪽의 막대 다이어그램에서는 프로젝트당 GPU를 보여 주며, 각 팀이 클러스터 리소스를 사용하는 방법을 요약합니다. 가운데는 작업 이름, 프로젝트, 사용자, 작업 유형, 각 작업이 실행 중인 노드, 해당 작업에 할당된 GPU 수, 작업의 현재 실행 시간, 작업의 작업 진행 상태, 해당 작업의 GPU 사용률 단일 팀('team-A')이 제출한 실행 중인 작업이 3개뿐이므로 클러스터 사용률이 낮은 상태(GPU 사용률이 23%)입니다.</block>
  <block id="67545e2efac33412706ff883eff2e1c4" category="paragraph">다음 섹션에서는 프로젝트 탭에서 여러 팀을 생성하고 각 팀에 GPU를 할당하여 클러스터당 사용자가 많을 때 클러스터 사용을 최대화하고 리소스를 관리하는 방법을 보여줍니다. 테스트 시나리오는 훈련, 추론 및 대화형 워크로드 간에 메모리 및 GPU 리소스가 공유되는 엔터프라이즈 환경을 모방합니다.</block>
  <block id="73eea118e4762640a7f60136f3e5c1a0" category="inline-link-macro">다음으로, 데이터 과학 팀을 위한 프로젝트 생성 및 GPU 할당</block>
  <block id="7c2c470385b4f61a9e9b5b0881d2f061" category="paragraph"><block ref="7c2c470385b4f61a9e9b5b0881d2f061" category="inline-link-macro-rx"></block></block>
  <block id="ae6f5747bf29f889c1d28208afab2a1a" category="doc">응용 프로그램 배포</block>
  <block id="cef52206f11ced919c8d0dd4b2c791a4" category="paragraph">다음 섹션에서는 응용 프로그램을 설치하고 배포하는 방법에 대해 설명합니다.</block>
  <block id="d0954433c0b62861850b87d9cba7599f" category="inline-link-macro">다음: GitHub에서 코드를 가져옵니다</block>
  <block id="255a6bf7e1d34563f76daaf2b6cd6184" category="paragraph"><block ref="26e27ac56fb4c03c9632ab9bd4fc068b" category="inline-link-macro-rx"></block>.</block>
  <block id="39cf3ca3e5dbe56d6eade7cbe3cc40e6" category="doc">Kubeflow 작업 및 작업 예</block>
  <block id="368c8f521d74a015b7a3e1a46c8847b1" category="paragraph">이 섹션에서는 Kubeflow를 사용하여 수행할 수 있는 다양한 작업 및 작업의 예를 제공합니다.</block>
  <block id="bdbf5a5e65f2cf7435dfcea294400b35" category="inline-link-macro">다음: 데이터 과학자 또는 개발자 사용을 위해 Jupyter Notebook Workspace를 프로비저닝합니다.</block>
  <block id="86e512bbf34bd396dd043a14ff2027ec" category="paragraph"><block ref="86e512bbf34bd396dd043a14ff2027ec" category="inline-link-macro-rx"></block></block>
  <block id="820423ca1ad0e872ef04cbb366b6e3de" category="paragraph">NetApp과 Iguazio는 이러한 기술을 관리형 서비스로 결합하여 기술 채택을 가속하고 새로운 AI/ML 애플리케이션의 출시 시기를 앞지였습니다.</block>
  <block id="b0a9c7dc36cb18f93679b833533b9936" category="paragraph"><block ref="b0a9c7dc36cb18f93679b833533b9936" category="inline-link-macro-rx"></block></block>
  <block id="d3202b7eec66185e032fcad76b4c2aa3" category="paragraph"><block ref="d3202b7eec66185e032fcad76b4c2aa3" category="inline-link-macro-rx"></block></block>
  <block id="27a5a0a02525fbb66788e119b829fe28" category="list-text">Azure NetApp Files:</block>
  <block id="45bd81d391ee3bd9831a237bff32b2c1" category="list-text">Azure NetApp Files용 솔루션 아키텍처 페이지</block>
  <block id="57b815cb2da0c842a09d5ef586792c0a" category="inline-link"><block ref="57b815cb2da0c842a09d5ef586792c0a" category="inline-link-rx"></block></block>
  <block id="02508d077a7c6fbe1035568c37610d22" category="paragraph"><block ref="02508d077a7c6fbe1035568c37610d22" category="inline-link-rx"></block></block>
  <block id="f42fced7b7a9bfef49a209632add6f80" category="list-text">컨테이너용 Trident 영구 스토리지:</block>
  <block id="158e66cfa121c58b072656402170ca60" category="list-text">Azure NetApp Files 및 Trident</block>
  <block id="d9fe72ef646d82c8372b45ff009726a2" category="inline-link"><block ref="d9fe72ef646d82c8372b45ff009726a2" category="inline-link-rx"></block></block>
  <block id="e3c781df174a80c19c70a938b96db93a" category="paragraph"><block ref="e3c781df174a80c19c70a938b96db93a" category="inline-link-rx"></block></block>
  <block id="145f2a04d99fdbd7a450ef83e82d471b" category="list-text">Dask 및 RAPIDS:</block>
  <block id="df5eb1591e808e358e02221e1e0111e6" category="list-text">Dask(질문)</block>
  <block id="7db6639777894f081a3d7c055b97900a" category="inline-link"><block ref="7db6639777894f081a3d7c055b97900a" category="inline-link-rx"></block></block>
  <block id="4846c68fb34aec3b1b7b7de96d27e71f" category="paragraph"><block ref="4846c68fb34aec3b1b7b7de96d27e71f" category="inline-link-rx"></block></block>
  <block id="41563f9620e92fbfd1e105e32ac297e4" category="list-text">Dask를 설치합니다</block>
  <block id="8659b02378fc9b47aac4428f69411abc" category="inline-link"><block ref="8659b02378fc9b47aac4428f69411abc" category="inline-link-rx"></block></block>
  <block id="972dffc891589785367dd3581a5abcef" category="paragraph"><block ref="972dffc891589785367dd3581a5abcef" category="inline-link-rx"></block></block>
  <block id="3ba7abeba4fd0f5d5ca9072155319afd" category="list-text">Dask API</block>
  <block id="f7673aa4f6b36ba9952cef7c98115776" category="inline-link"><block ref="f7673aa4f6b36ba9952cef7c98115776" category="inline-link-rx"></block></block>
  <block id="d43a23bd530cae7ba37a2e0ed6513bad" category="paragraph"><block ref="d43a23bd530cae7ba37a2e0ed6513bad" category="inline-link-rx"></block></block>
  <block id="1bfabf7fb7bf05567331dfc3d20c4921" category="list-text">Dask 기계 학습</block>
  <block id="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link"><block ref="9e480c1539fe5b14bbbcefb9676dc031" category="inline-link-rx"></block></block>
  <block id="d05f63d77306100c615132f350f3fafe" category="paragraph"><block ref="d05f63d77306100c615132f350f3fafe" category="inline-link-rx"></block></block>
  <block id="90223e93e145939c9954970520e1767a" category="list-text">Dask 분산 진단</block>
  <block id="e7252fe9d67234e05be7dc251c48cf74" category="inline-link"><block ref="e7252fe9d67234e05be7dc251c48cf74" category="inline-link-rx"></block></block>
  <block id="925c8b588cf5ae5fc486494a21fba8ac" category="paragraph"><block ref="925c8b588cf5ae5fc486494a21fba8ac" category="inline-link-rx"></block></block>
  <block id="d97adf46c9b097cad5eff54e3b65a21f" category="paragraph"><block ref="d97adf46c9b097cad5eff54e3b65a21f" category="inline-link-rx"></block></block>
  <block id="528d52adf23d34a248f0b9bf684c1832" category="paragraph"><block ref="528d52adf23d34a248f0b9bf684c1832" category="inline-link-rx"></block></block>
  <block id="a43c7ca8f7e6a4a034f6a940ec7566f5" category="inline-link-macro">다음: 버전 기록.</block>
  <block id="5f751f93279ebf35ea83b9aa80ef02df" category="paragraph"><block ref="5f751f93279ebf35ea83b9aa80ef02df" category="inline-link-macro-rx"></block></block>
  <block id="1e92efa8f46c28a3c3a1c03ababfa7be" category="doc">NetApp Retail Assistant 데모</block>
  <block id="c2e2fce3a995f59900d7afbbe58683f5" category="inline-link">이 링크</block>
  <block id="bb07f1ff94c6f99bf48a403706bea4ca" category="paragraph">NetApp Retail Assistant(Nara)의 데모 비디오를 녹화했습니다. 을 클릭합니다<block ref="c1305d6e7f2e06345748f63e36abba33" category="inline-link-rx"></block> 다음 그림을 열고 비디오 데모를 재생합니다.</block>
  <block id="088070f65f454d6b38e8e40e332e70a8" category="paragraph"><block ref="088070f65f454d6b38e8e40e332e70a8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d81ccbd202a60c621000abca3f6f3de" category="inline-link-macro">다음: NetApp Cloud Sync를 사용하여 대화 내용 아카이빙</block>
  <block id="a165baa9089720dc90e8baf16267821f" category="paragraph"><block ref="a165baa9089720dc90e8baf16267821f" category="inline-link-macro-rx"></block></block>
  <block id="45ce76bfe721ca13d37ca15fdbebd391" category="paragraph">저자는 NVIDIA의 존경받는 동료 Davide Onofrio, Alex Qi, Sicong Ji, Marty Jain 및 Robert Sohigian이 이 백서에 기여한 바를 진심으로 인정합니다. 또한 NetApp의 주요 팀원 중 Santosh Rao, David Arnette, Michael Oglesby, Brent Davis, Andy Sayare의 기여에 대해 인정하고자 합니다. Erik Mulder와 Mike McNamara가 함께 합니다.</block>
  <block id="81fbc4247f2c3a990b090cef6b9ebe03" category="paragraph">본 문서를 작성하는 데 큰 도움이 되는 통찰과 전문 지식을 제공해주신 모든 분에게 진심으로 감사합니다.</block>
  <block id="bc2f62a5c14dc9d16f38cc32c304164c" category="paragraph"><block ref="bc2f62a5c14dc9d16f38cc32c304164c" category="inline-link-macro-rx"></block></block>
  <block id="6f7f6c0b1054487e622896990b1d6d55" category="doc">TR-4841: 데이터 캐싱을 지원하는 하이브리드 클라우드 AI 운영 체제</block>
  <block id="1b55e21d5b19a6ba57ae9bbd6f3a0630" category="paragraph">Rick Huang, David Arnette, NetApp Yochay Ettun, cnvrg.io</block>
  <block id="28d9fd6fa10254fdcc59aa182ae32dc9" category="paragraph">데이터의 폭발적인 증가와 ML 및 AI의 기하급수적인 성장으로 인해 고유한 개발 및 구현 과제를 가진 제타바이트 경제성이 창출되었습니다.</block>
  <block id="eb35f773ff882afb6d6d67613a4701ee" category="paragraph">머신 러닝 모델은 데이터를 많이 필요로 하며 컴퓨팅 리소스 가까이에 고성능 데이터 스토리지가 필요한 것으로 널리 알려져 있지만, 실제로 하이브리드 클라우드 및 탄력적인 컴퓨팅 인스턴스 구축을 위해 이러한 모델을 구현하는 것은 그리 간단하지 않습니다. 일반적으로 대량의 데이터가 GPU와 같은 고성능 AI 컴퓨팅 리소스가 효율적으로 액세스할 수 없는 저비용 데이터 레이크에 저장됩니다. 일부 워크로드가 클라우드에서 작동하고 일부는 사내 또는 다른 HPC 환경에 완전히 있는 하이브리드 클라우드 인프라에서는 이 문제가 더욱 가중됩니다.</block>
  <block id="2b8ab86ccf473cca225e50ddb8c47e25" category="paragraph">이 문서에서는 IT 전문가와 데이터 엔지니어가 토폴로지 인식 데이터 허브로 진정한 하이브리드 클라우드 AI 플랫폼을 구축하여 데이터 과학자가 컴퓨팅 리소스 가까이에 있는 데이터 세트의 캐시를 즉시 자동으로 생성할 수 있는 새로운 솔루션을 소개합니다. 있습니다. 그 결과, 고성능 모델 훈련을 수행할 수 있을 뿐만 아니라 데이터 세트 버전 허브 내에서 데이터 세트 캐시, 버전 및 계모델에 즉시 액세스할 수 있는 여러 AI 전문가의 협업을 비롯한 추가 이점을 얻을 수 있습니다.</block>
  <block id="3bc3b194b0ef70e2e6ce113f819619c4" category="inline-link-macro">다음: 사용 사례 개요 및 문제 설명</block>
  <block id="3eb8a6b81400ec3a497fb59a7e6f4360" category="paragraph"><block ref="3eb8a6b81400ec3a497fb59a7e6f4360" category="inline-link-macro-rx"></block></block>
  <block id="dbb4dd9a11f48db13d63eedaae717fe5" category="doc">데이터 과학 팀을 위한 프로젝트 생성 및 GPU 할당</block>
  <block id="22d09d229a06f294b0f45804f8e639d3" category="paragraph">연구원들은 Run:AI CLI, Kubeflow 또는 유사한 프로세스를 통해 워크로드를 제출할 수 있습니다. 리소스 할당을 간소화하고 우선 순위를 만들기 위해 Run:AI에는 프로젝트의 개념이 도입되었습니다. 프로젝트는 프로젝트 이름을 GPU 할당 및 기본 설정과 연결하는 할당량 요소입니다. 여러 데이터 과학 팀을 관리할 수 있는 간단하고 편리한 방법입니다.</block>
  <block id="c0bd05e9d88cf015eac684873bfd14c7" category="paragraph">워크로드를 제출하는 연구원은 프로젝트를 워크로드 요청과 연계해야 합니다. Run:AI 스케줄러는 요청을 현재 할당 및 프로젝트와 비교하여 워크로드에 리소스를 할당할 수 있는지 또는 보류 중 상태를 유지해야 하는지 여부를 결정합니다.</block>
  <block id="800f40fa67f69116bf6f38cd07456608" category="paragraph">시스템 관리자는 실행: AI 프로젝트 탭에서 다음 매개 변수를 설정할 수 있습니다.</block>
  <block id="9c429f2284a95aaa299c7d85ccb16734" category="list-text">* 모델 프로젝트 * 사용자별 프로젝트를 설정하고, 사용자 팀별로 프로젝트를 설정하고, 실제 조직 프로젝트별로 프로젝트를 설정합니다.</block>
  <block id="b2f1422cf0d082a495bbf865b9a5621d" category="list-text">* 프로젝트 할당량 * 각 프로젝트는 이 프로젝트에 동시에 할당할 수 있는 GPU 할당량과 연관됩니다. 이 프로젝트는 클러스터의 상태에 관계없이 이 프로젝트를 사용하는 연구원이 GPU 수를 확보할 수 있다는 점에서 보장된 할당량입니다. 일반적으로 프로젝트 할당의 합계는 클러스터에 있는 GPU 수와 같아야 합니다. 이 외에도 이 프로젝트의 사용자는 초과 할당량을 받을 수 있습니다. GPU를 사용하지 않는 한, 이 프로젝트를 사용하는 연구자는 더 많은 GPU를 얻을 수 있습니다. 에서는 할당량 초과 테스트 시나리오와 공정성 고려 사항을 보여 줍니다<block ref="9563fd9ab6978412dc97d80a70e51786" category="inline-link-rx"></block>,<block ref="a8ad108feafc827856baa28b0b9070ed" category="inline-link-rx"></block>, 및<block ref="be867f64efefe193012b1dfc6c82f783" category="inline-link-rx"></block>.</block>
  <block id="20a3a45fbbd9502add12fd216350d569" category="list-text">새 프로젝트를 만들고, 기존 프로젝트를 업데이트하고, 기존 프로젝트를 삭제합니다.</block>
  <block id="3bf13b237342258b6ddb3f167d679a3b" category="inline-link">AI 문서 를 실행하십시오</block>
  <block id="77332641abf52ec5dc1af8b23b2339f3" category="list-text">* 특정 노드 그룹에서 실행할 작업 제한 *. 특정 노드에서만 실행되도록 특정 프로젝트를 할당할 수 있습니다. 이 기능은 프로젝트 팀이 충분한 메모리를 갖춘 특수 하드웨어가 필요한 경우에 유용합니다. 또는 프로젝트 팀은 전문 예산으로 구입한 특정 하드웨어의 소유자가 되거나, 더 약한 하드웨어에서 작동하고 더 긴 훈련이나 무인 워크로드를 더 빠른 노드로 직접 처리하기 위해 직접 빌드하거나 대화형 워크로드를 실행해야 할 수도 있습니다. 노드를 그룹화하고 특정 프로젝트에 대한 선호도를 설정하는 명령은 을 참조하십시오 <block ref="eae60ce89b8727160634b52e7654bf73" category="inline-link-rx"></block>.</block>
  <block id="2bd802cca9bf193b441123437f5d39ca" category="list-text">* 대화형 작업 기간 제한 *. 연구자들은 종종 대화식 작업을 종결하는 것을 잊어버립니다. 이로 인해 리소스가 낭비될 수 있습니다. 일부 조직에서는 대화형 작업의 기간을 제한하고 자동으로 작업을 종결하는 것을 선호합니다.</block>
  <block id="10c2495ded559d79de96be22751712dc" category="paragraph">다음 그림에서는 네 개의 팀이 생성된 프로젝트 보기를 보여 줍니다. 각 팀에는 서로 다른 워크로드를 처리할 수 있는 서로 다른 수의 GPU가 할당되며, 총 GPU 수는 2개의 DGX-1로 구성된 클러스터에서 사용 가능한 총 GPU 수와 같습니다.</block>
  <block id="9ba047faa1d241a6153be986be27097f" category="paragraph"><block ref="9ba047faa1d241a6153be986be27097f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4804b15e4766599ceade052b5ca8af9" category="inline-link-macro">다음: AI CLI 실행 에서 작업 제출</block>
  <block id="9c6088fad9917e07026030c1d3eaad09" category="paragraph"><block ref="9c6088fad9917e07026030c1d3eaad09" category="inline-link-macro-rx"></block></block>
  <block id="33204bfa9ee287508f03782fd7ad512e" category="summary">Trident를 사용하여 Kubernetes 클러스터 내에서 스토리지 리소스를 동적으로 프로비저닝하려면 먼저 하나 이상의 Kubernetes StorageClasses를 생성해야 합니다. 이 페이지의 예제는 ONTAP AI POD에 NetApp AI Control Plane 솔루션을 구축할 경우 생성할 수 있는 여러 가지 유형의 StorageClasses를 보여줍니다.</block>
  <block id="d9206a5144976221af82df78ad3d7977" category="paragraph">Trident를 사용하여 Kubernetes 클러스터 내에서 스토리지 리소스를 동적으로 프로비저닝하려면 먼저 하나 이상의 Kubernetes StorageClasses를 생성해야 합니다. 다음 예제는 ONTAP AI POD에 NetApp AI Control Plane 솔루션을 구축할 경우 생성할 수 있는 다양한 유형의 StorageClasses를 보여줍니다. StorageClasses에 대한 자세한 내용은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="993143e7434e63409a07cf3e8c422505" category="list-text">NetApp은 섹션에 생성한 각 FlexGroup 지원 Trident 백엔드에 대해 별도의 StorageClass를 생성할 것을 권장합니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 1단계. 이러한 세분화된 StorageClasses를 사용하면 특정 LIF(Trident 백엔드를 생성할 때 지정한 LIF)에 해당하는 NFS 마운트를 StorageClass 사양 파일에 지정된 특정 백엔드에서 추가할 수 있습니다. 다음 예제 명령은 섹션에 생성된 두 예제 백엔드에 해당하는 두 개의 StorageClasses를 생성하는 방법을 보여 줍니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 1단계. StorageClasses에 대한 자세한 내용은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="d9348d075dc7b3c91cff99d56dfc327b" category="inline-link">Kubernetes 문서</block>
  <block id="a596fcc71d1c43e3ba86b1557ac7af81" category="paragraph">영구 볼륨은 해당 PersistentVolumeClaim(PVC)이 삭제되어도 삭제되지 않도록 다음 예에서는 "Retain"의 "reclaimPolicy" 값을 사용합니다. '청구 정책' 필드에 대한 자세한 내용은 공식 을 참조하십시오<block ref="2b8f9bbf9efeff879b3debc5484f0056" category="inline-link-rx"></block>.</block>
  <block id="f053cb3a491d2bc48d41230b10a9b164" category="list-text">또한 섹션에서 생성한 FlexVol 지원 Trident 백엔드에 해당하는 StorageClass를 생성하는 것이 좋습니다 <block ref="5ce2b96729b1637e197bdd36eb4db4ee" category="inline-link-macro-rx"></block>, 2단계. 다음 명령 예에서는 FlexVol 볼륨에 대한 단일 StorageClass를 생성하는 것을 보여 줍니다.</block>
  <block id="99608a01905f0e69895bbb864a0deba3" category="paragraph">다음 예에서는 FlexVol 지원 Trident 백엔드가 하나만 생성되었기 때문에 StorageClass 정의 파일에 특정 백엔드가 지정되지 않습니다. Kubernetes를 사용하여 이 StorageClass를 사용하는 볼륨을 관리할 경우 Trident는 'ONTAP-NAS' 드라이버를 사용하는 사용 가능한 백엔드를 사용하려고 합니다.</block>
  <block id="ee1d27a4ae3e30ff30ef72e305b029e7" category="list-text">또한 FlexGroup 볼륨에 대한 일반 StorageClass를 생성하는 것이 좋습니다. 다음 예제 명령은 FlexGroup 볼륨에 대한 단일 일반 StorageClass 를 생성하는 방법을 보여 줍니다.</block>
  <block id="d4a43a35c5d5a5ce3aefe77ceaa73a5c" category="paragraph">StorageClass 정의 파일에 특정 백엔드가 지정되지 않았습니다. 따라서 Kubernetes를 사용하여 이 StorageClass를 사용하는 볼륨을 관리할 때 Trident는 'ONTAP-NAS-Flexgroup' 드라이버를 사용하는 사용 가능한 백엔드를 사용하려고 합니다.</block>
  <block id="b569e24403ad128c09e2d0dbd0116463" category="inline-link-macro">다음은 Kubeflow 구축 개요입니다.</block>
  <block id="66f5564ed29f37f0b81d2dde741b9c8f" category="paragraph"><block ref="66f5564ed29f37f0b81d2dde741b9c8f" category="inline-link-macro-rx"></block></block>
  <block id="8fcbbd73e86fa0b56d72d6127c318c85" category="paragraph">데이터의 폭발적인 증가와 머신 러닝(ML)과 인공 지능(AI)의 기하급수적인 성장으로 인해 고유한 개발 및 구현 과제와 함께 새로운 경제를 창조했습니다. 일반적으로 대량의 데이터는 GPU와 같은 고성능 AI 컴퓨팅 리소스가 효율적으로 액세스할 수 없는 저렴한 데이터 레이크에 저장됩니다. 이 보고서에서는 데이터 과학 전문가가 데이터 허브를 구현하고, 한 번의 클릭으로 위치와 관계없이 컴퓨팅 리소스 가까이에 데이터 세트 캐시를 생성할 수 있는 새로운 솔루션을 제공합니다. 따라서 AI 실무자는 새로운 데이터 세트 버전 허브를 통해 향상된 협업을 통해 고성능 모델 훈련을 더 쉽게 수행할 수 있습니다.</block>
  <block id="13e8f52d7e19f83d3e64003c58ea220b" category="doc">NDE를 사용하여 NetApp HCI에 VMware 가상 인프라 구축(자동화된 구축)</block>
  <block id="2635318d9bf1ea76c73bfab7f3eeafb7" category="section-title">NDE 배포 필수 구성 요소</block>
  <block id="f6ec2c1aa5118cb19e89af5a10ecb65c" category="inline-link">NetApp HCI 필수 구성 요소 체크리스트</block>
  <block id="2187fc20798cda55150d8c067fac10be" category="paragraph">을 참조하십시오<block ref="c760383d1767df51ab118e6ffc289894" category="inline-link-rx"></block> 배포를 시작하기 전에 NetApp HCI에 대한 요구 사항 및 권장 사항을 확인하십시오.</block>
  <block id="cd02d0868a7414dd1e76924b30b82b52" category="list-text">네트워크 및 스위치 요구 사항 및 구성</block>
  <block id="1d8b6c167080876dff9ad2e74e70fecf" category="list-text">필요한 VLAN ID를 준비합니다</block>
  <block id="17cec09f14c225b5f27dc73542e9077a" category="list-text">스위치 구성</block>
  <block id="4d40082ed807aa2fb7e1d2f03921e4d4" category="list-text">NetApp HCI 및 VMware의 IP 주소 요구 사항</block>
  <block id="2e8e4792043f43cb4b34a84b8dcd909b" category="list-text">DNS 및 시간 유지 요구 사항</block>
  <block id="829710d6ec2a8e59e7a69fb3537ec494" category="list-text">최종 준비</block>
  <block id="fb720b4ad7c03710e0e5771c9fb58b44" category="section-title">NDE 실행</block>
  <block id="cf50c81e30d1d64fcb4992a9792abedb" category="paragraph">NDE를 실행하기 전에 모든 구성 요소의 랙 및 스택, 네트워크 스위치 구성 및 모든 사전 요구 사항 확인을 완료해야 합니다. NDE가 모든 주소를 자동으로 구성하도록 하려면 단일 스토리지 노드의 관리 주소에 연결하여 NDE를 실행할 수 있습니다.</block>
  <block id="130c61c344b6fbf262b6f63818eab7e4" category="paragraph">NDE는 HCI 시스템을 온라인으로 전환하는 다음과 같은 작업을 수행합니다.</block>
  <block id="d89f68a2ec388fe5d72fb6fe024a0176" category="list-text">최소 2개의 스토리지 노드에 스토리지 노드(NetApp Element 소프트웨어)를 설치합니다.</block>
  <block id="f6f86c1086573c7daeb1f48535041576" category="list-text">최소 2개의 컴퓨팅 노드에 VMware 하이퍼바이저를 설치합니다.</block>
  <block id="0718265bec3e2ee6fc9d5e0773b5ff60" category="list-text">VMware vCenter를 설치하여 전체 NetApp HCI 스택을 관리합니다.</block>
  <block id="e09575b9713329ebe2480dbf404b2b1b" category="list-text">NetApp 스토리지 관리 노드(mNode) 및 NetApp 모니터링 에이전트를 설치 및 구성합니다.</block>
  <block id="dddc28f734d0bcb367638f51ef8b4dfa" category="admonition">이 검증에서는 NDE를 사용하여 모든 주소를 자동으로 구성합니다. 사용자 환경에서 DHCP를 설정하거나 각 스토리지 노드 및 컴퓨팅 노드에 대해 IP 주소를 수동으로 할당할 수도 있습니다. 이러한 단계는 본 가이드에서 다루지 않습니다.</block>
  <block id="dd9cd526f5753b79bda6de19f1a66fe9" category="paragraph">앞에서 설명한 것처럼 이 검증에서는 컴퓨팅 노드에 대해 2케이블 구성을 사용합니다.</block>
  <block id="32691d86c49e682187776e0262b732d7" category="paragraph">NDE에 대한 자세한 단계는 본 문서에서 다루지 않습니다.</block>
  <block id="968a3687be335c74374e73712c63e2e4" category="inline-link">구축 가이드</block>
  <block id="8b6e1a3a9d21ff63520793416432cd56" category="paragraph">기본 NetApp HCI 플랫폼 배포 완료에 대한 단계별 지침은 를 참조하십시오<block ref="7742239770a3accee30f01673a1a43a5" category="inline-link-rx"></block>.</block>
  <block id="61ef02ded53524d506cd714c5821cd86" category="list-text">NDE가 완료되면 vCenter에 로그인하여 ONTAP Select 및 애플리케이션에서 사용할 NFS 네트워크에 대한 분산 포트 그룹 NetApp HCI VDS 01-NFS_Network를 생성합니다.</block>
  <block id="9fb27fdce8d8c70b2c7b741958c8ac6e" category="inline-link-macro">다음: NetApp H615c 구성(수동 구축)</block>
  <block id="6623698128b1c14d8639f2404306f783" category="paragraph"><block ref="6623698128b1c14d8639f2404306f783" category="inline-link-macro-rx"></block></block>
  <block id="c755c33dca37a8aaffbf190bdf3f5fef" category="paragraph">이 솔루션은 NetApp AFF A800 시스템 1대, DGX-1 서버 2대, Cisco Nexus 3232C 100GbE 스위치 2개를 사용하여 구축했습니다. RoCE(RDMA over Converged Ethernet)를 통한 원격 직접 메모리 액세스(RDMA)를 사용하여 각 DGX-1 서버는 GPU 간 통신에 사용되는 4개의 100GbE 연결을 통해 Nexus 스위치에 연결합니다. NFS 스토리지 액세스를 위한 기존 IP 통신도 이 링크에서 발생합니다. 4개의 100GbE 링크를 사용하여 각 스토리지 컨트롤러를 네트워크 스위치에 연결합니다. 다음 그림은 모든 테스트 시나리오에 대해 이 기술 보고서에 사용된 ONTAP AI 솔루션 아키텍처를 보여줍니다.</block>
  <block id="782c9fdc3f29358987c2f5b99fe9e6b9" category="paragraph"><block ref="782c9fdc3f29358987c2f5b99fe9e6b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1b09355c9538fe149372d3728c98bb1" category="paragraph"><block ref="b1b09355c9538fe149372d3728c98bb1" category="inline-link-macro-rx"></block></block>
  <block id="aa364e0963e38930007df2b60bdba067" category="doc">Trident에서 프로비저닝한 PersistentVolume에 데이터 저장</block>
  <block id="ef1fb51957f2aa894de5476a9a0112a2" category="paragraph">NetApp Trident는 컨테이너화된 애플리케이션의 정교한 지속성 요구사항을 충족하도록 설계된 완전 지원되는 오픈 소스 프로젝트입니다. 데이터 계층화, 암호화, NetApp Snapshot 기술, 규정 준수 및 NetApp ONTAP 데이터 관리 소프트웨어에서 제공하는 우수한 성능의 이점을 추가로 활용하여 Trident에서 프로비저닝한 Kubernetes PersistentVolume(PV)에 데이터를 읽고 쓸 수 있습니다.</block>
  <block id="a821f368daf439d909bfed3c8e95d4b9" category="section-title">기존 네임스페이스에서 PVC 재사용</block>
  <block id="be3455a34c69a26df1a5f04a6245249b" category="inline-link">NetApp Trident 문서</block>
  <block id="15040fc521e7fa5e8ef42694ca89e53d" category="paragraph">대규모 AI 프로젝트의 경우, 여러 컨테이너가 동일한 Kubernetes PV에서 데이터를 읽고 쓰는 것이 더 효율적일 수 있습니다. Kubernetes PVC(Persistent Volume Claim)를 재사용하려면 이미 PVC를 생성해야 합니다. 를 참조하십시오<block ref="5b6274adc29653ed1820027957bdb4e2" category="inline-link-rx"></block> PVC 작성에 대한 자세한 내용은. 다음은 기존 PVC를 재사용하는 예입니다.</block>
  <block id="743520c366f0d11ca817811dda85fcf1" category="paragraph">다음 명령어를 실행해 프로젝트 팀 A에 대한 작업 PVC-TEST의 상태를 확인할 수 있다.</block>
  <block id="7d4c508442c775f946e3d9318b75b1a0" category="paragraph">team-A job 'PVC-test'에 PV/tmp/pvc1mount가 마운트된 것을 볼 수 있습니다. 이렇게 하면 여러 컨테이너를 동일한 볼륨에서 읽을 수 있으므로 개발 또는 운영 중인 경쟁 모델이 여러 개 있을 때 유용합니다. 데이터 과학자는 모델의 앙상블을 만든 다음 대부분의 투표 또는 기타 기술을 통해 예측 결과를 결합할 수 있습니다.</block>
  <block id="dae81aa45b8ce281aabbd1402afe277b" category="paragraph">다음을 사용하여 컨테이너 셸에 액세스합니다.</block>
  <block id="bc63da8fa87210da818596598e359427" category="paragraph">그런 다음 마운트된 볼륨을 확인하고 컨테이너 내의 데이터에 액세스할 수 있습니다.</block>
  <block id="fc180b17e3fccb2beb46854f71d31406" category="paragraph">PVC를 재사용할 수 있는 이 기능은 NetApp FlexVol 볼륨 및 NetApp ONTAP FlexGroup 볼륨과 함께 작동하여 데이터 엔지니어가 보다 유연하고 강력한 데이터 관리 옵션을 통해 NetApp이 제공하는 Data Fabric을 활용할 수 있도록 지원합니다.</block>
  <block id="2e203cb5454e63a32bcdb87dc9cb77ad" category="paragraph"><block ref="2e203cb5454e63a32bcdb87dc9cb77ad" category="inline-link-macro-rx"></block></block>
  <block id="c1579c333c7c7a4e52136c7f58a7efc6" category="summary">이 기술 보고서에서 제안된 솔루션은 이러한 탁월한 고객 경험의 제공을 지원하는 것으로 입증되었으며, 이제 기업이 AI 인프라 및 워크플로의 현대화를 위한 조치를 취하도록 하는 것이 과제입니다.</block>
  <block id="9c5e72cb1709251063c12e4bddb1ba12" category="inline-link-macro">이전: 비디오 및 데모.</block>
  <block id="2f6461cd01fcb0c2d85704a563bd7c19" category="paragraph"><block ref="2f6461cd01fcb0c2d85704a563bd7c19" category="inline-link-macro-rx"></block></block>
  <block id="50d6e8cef34560d1d68c6688a12b1cb8" category="paragraph">고객 경험이 점점 더 경쟁이 치열해지는 주요 전장으로 간주됨에 따라, 거의 모든 산업의 기업이 간과할 수 없는 중요한 구성 요소가 AI 강화 글로벌 지원 센터가 되었습니다. 이 기술 보고서에서 제안된 솔루션은 이러한 탁월한 고객 경험의 제공을 지원하는 것으로 입증되었으며, 이제 기업이 AI 인프라 및 워크플로의 현대화를 위한 조치를 취하도록 하는 것이 과제입니다.</block>
  <block id="f6e349295b2165b25a412793116b8675" category="paragraph">고객 서비스에서 AI를 가장 잘 구현하는 것은 상담원을 대체하지 않는 것입니다. 오히려 AI를 사용하면 실시간 감정 분석, 분쟁 에스컬레이션, 다중 모달 Affective 컴퓨팅을 통해 탁월한 고객 경험을 창출하여 포괄적인 AI 모델이 규모에 따라 권장사항을 제시하고 개별 상담원의 부족한 사항을 보완할 수 있는 언어, 비언어적, 안면 신호를 감지할 수 있습니다. 또한 AI는 특정 고객과 현재 사용 가능한 에이전트 간에 더 나은 일치를 제공할 수 있습니다. AI를 사용하는 기업은 공급자의 제품, 서비스 및 브랜드 이미지에 대한 생각과 인상에 대해 귀중한 고객 감정을 끌어낼 수 있습니다.</block>
  <block id="eb5cb6f03236a80f7ddd5085afa95729" category="paragraph">이 솔루션을 사용하여 지원 상담원이 객관적인 성능 평가 메트릭으로 사용할 시계열 데이터를 구성할 수도 있습니다. 일반적인 고객 만족도 설문 조사에는 대개 충분한 응답이 없습니다. 고용주는 장기적인 직원 및 고객 감정을 수집하여 지원 상담원의 성과에 대해 충분한 정보를 바탕으로 의사 결정을 내릴 수 있습니다.</block>
  <block id="aa20fc291fbb8ceda8651d8d8ee9dba6" category="paragraph">NetApp, SFL Scientific, 오픈 소스 오케스트레이션 프레임워크 및 NVIDIA의 결합을 통해 최신 기술을 관리형 서비스로 통합하고 기술 도입을 가속하고 새로운 AI/ML 애플리케이션의 출시 시기를 앞당길 수 있습니다. 이러한 고급 서비스는 클라우드 네이티브 환경과 하이브리드 구축 아키텍처에 대해 쉽게 이식할 수 있는 온프레미스 서비스입니다.</block>
  <block id="71fd14327d5bf7e725ab97e00192b238" category="paragraph"><block ref="71fd14327d5bf7e725ab97e00192b238" category="inline-link-macro-rx"></block></block>
  <block id="9e59f01034d2c132fac901b9c14a5d88" category="summary">Kubernetes용 NetApp DataOps 툴킷은 스토리지 리소스와 Kubernetes 워크로드를 데이터 과학 작업 공간 수준까지 추상화합니다. 이러한 기능은 데이터 과학자와 데이터 엔지니어를 위해 설계된 간단하고 사용하기 쉬운 인터페이스로 패키징되어 있습니다.</block>
  <block id="7aee811c7e891ab94bb5be40b333faaf" category="doc">NetApp DataOps 툴킷을 사용하여 데이터 세트 및 모델 버전 관리</block>
  <block id="f7136197d3b16131979b9319c4acce63" category="inline-link-macro">이전: Prometheus 및 Grafana를 사용하여 Dask 및 RAPIDS를 모니터링합니다.</block>
  <block id="402dae1972461d7e7ba986ab6728df6c" category="paragraph"><block ref="402dae1972461d7e7ba986ab6728df6c" category="inline-link-macro-rx"></block></block>
  <block id="fd2d048a9ec0f96d89493b98f72cbe34" category="paragraph">Kubernetes용 NetApp DataOps 툴킷은 스토리지 리소스와 Kubernetes 워크로드를 데이터 과학 작업 공간 수준까지 추상화합니다. 이러한 기능은 데이터 과학자와 데이터 엔지니어를 위해 설계된 간단하고 사용하기 쉬운 인터페이스로 패키징되어 있습니다. 데이터 과학자와 엔지니어는 익숙한 형식의 Python 프로그램을 사용하여 JupyterLab 작업 공간을 단 몇 초 만에 프로비저닝 및 폐기할 수 있습니다. 이러한 작업 공간에는 테라바이트나 페타바이트급의 스토리지 용량이 포함될 수 있으므로 데이터 과학자는 모든 훈련 데이터 세트를 프로젝트 작업 공간에 직접 저장할 수 있습니다. 작업 영역과 데이터 볼륨을 별도로 관리하는 시대는 지났습니다.</block>
  <block id="4a6c7893abd7ef92fb09d3359e17324d" category="inline-link">GitHub 리포지토리</block>
  <block id="eb0d40310a9cc0432fac66dc97652c39" category="paragraph">자세한 내용은 툴킷 을 참조하십시오<block ref="64134ca6239d4056f34489b42f2baeed" category="inline-link-rx"></block>.</block>
  <block id="1d1983037d4fd7beac963697b84f82bd" category="paragraph"><block ref="1d1983037d4fd7beac963697b84f82bd" category="inline-link-macro-rx"></block></block>
  <block id="a6214fe1ac9a6825ffe38f3b34489c9d" category="summary">NetApp Run AI는 AI 워크로드 오케스트레이션을 단순화하기 위해 실행 AI 플랫폼과 함께 Azure NetApp Files의 고유한 기능을 시연하기 위해 이 기술 보고서를 작성하는 데 협력했습니다.</block>
  <block id="a55106260c16aab506cebfb58e07e030" category="paragraph">NetApp과 RUN: AI는 AI 워크로드 오케스트레이션을 단순화하기 위한 RUN:AI 플랫폼과 함께 Azure NetApp Files의 고유한 기능을 시연하기 위해 이 기술 보고서를 작성하는 데 협력했습니다. 이 기술 보고서는 분산 차선 감지 교육을 위한 데이터 파이프라인 및 워크로드 오케스트레이션 프로세스의 간소화를 위한 참조 아키텍처를 제공합니다.</block>
  <block id="4e51614a389f3ad4fa17e2ce7ad984e7" category="paragraph">결론적으로, 규모에 따른 분산 교육(특히 퍼블릭 클라우드 환경)과 관련하여 리소스 오케스트레이션 및 스토리지 구성요소를 솔루션의 중요한 요소로 간주하게 됩니다. 데이터를 관리하여 여러 GPU 처리를 방해해서는 안 되므로 GPU 사이클을 최적으로 활용할 수 있습니다. 따라서 대규모 분산 교육 용도로 시스템을 최대한 비용 효율적으로 만들 수 있습니다.</block>
  <block id="269c35b1959d92e9ef6665bb4c60ad5d" category="paragraph">NetApp에서 제공하는 Data Fabric을 사용하면 데이터 과학자와 데이터 엔지니어가 사내 및 클라우드에 연결하여 수동 개입 없이 동기식 데이터를 사용할 수 있으므로 문제를 극복할 수 있습니다. 다시 말해, Data Fabric은 여러 위치에 분산되어 있는 AI 워크플로우를 관리하는 프로세스를 원활하게 처리합니다. 또한, 데이터를 컴퓨팅 가까이에 두고 분석, 교육, 검증을 필요할 때 언제 어디서나 수행하여 수요 기반 데이터 가용성을 지원합니다. 이 기능을 사용하면 데이터 통합뿐만 아니라 전체 데이터 파이프라인의 보호 및 보안을 실현할 수 있습니다.</block>
  <block id="d68d11ee3f69a45d681f78c744cae498" category="summary">볼륨에 대해 원하는 서비스 수준을 사용하는 다른 용량 풀로 볼륨을 이동하여 기존 볼륨의 서비스 수준을 변경할 수 있습니다. 이 솔루션을 통해 고객은 작은 데이터 세트와 Standard Tier의 적은 수의 GPU로 시작한 후 데이터 및 GPU가 증가함에 따라 프리미엄 계층으로 스케일아웃 또는 스케일업할 수 있습니다.</block>
  <block id="2fe5665064f07acc8afc830f911c09a5" category="doc">Azure NetApp Files 성능 계층</block>
  <block id="d84e339c1d1265f11e2f217f8d04354a" category="inline-link-macro">이전: Helm을 사용하여 AKS에서 RAPIDS 배포를 사용하여 Dask를 설정합니다.</block>
  <block id="1be55e0d10ba600a3d66b1f73f978b9f" category="paragraph"><block ref="1be55e0d10ba600a3d66b1f73f978b9f" category="inline-link-macro-rx"></block></block>
  <block id="de524ca3fc83ef426bc329e1a8b712ea" category="paragraph">볼륨에 대해 원하는 서비스 수준을 사용하는 다른 용량 풀로 볼륨을 이동하여 기존 볼륨의 서비스 수준을 변경할 수 있습니다. 이 솔루션을 통해 고객은 작은 데이터 세트와 Standard Tier의 적은 수의 GPU로 시작한 후 데이터 및 GPU가 증가함에 따라 프리미엄 계층으로 스케일아웃 또는 스케일업할 수 있습니다. Premium Tier는 Standard Tier보다 테라바이트당 처리량이 4배 더 향상되었으며, 볼륨의 서비스 수준을 변경하기 위해 데이터를 이동할 필요 없이 스케일업이 가능합니다.</block>
  <block id="5f92df8a2ac38644ed8ba20e16791602" category="paragraph">볼륨의 서비스 수준을 동적으로 변경하려면 다음 단계를 수행하십시오.</block>
  <block id="8c83c4957baac2f6fea18f9d77767e3a" category="paragraph"><block ref="8c83c4957baac2f6fea18f9d77767e3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21ec2eabbe87e02cad1b0d4279ea00a7" category="list-text">Change Pool 창에서 볼륨을 이동할 용량 풀을 선택합니다.</block>
  <block id="ef3a0105bad35ad4c385d92daf6496a6" category="paragraph"><block ref="ef3a0105bad35ad4c385d92daf6496a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18d0ad44a1e563aaf9f5871e32535a6c" category="list-text">확인 을 클릭합니다.</block>
  <block id="32ae33eea9c6b04002778d814c344fb5" category="section-title">성능 계층 변경을 자동화합니다</block>
  <block id="1c9506694c5a6fe83d1a0389d1d24564" category="paragraph">다음 옵션을 사용하여 성능 계층 변경을 자동화할 수 있습니다.</block>
  <block id="54a3bcd89041e8f96766dcb598b15511" category="list-text">동적 서비스 수준 변경은 현재 Public Preview에 있으며 기본적으로 활성화되어 있지 않습니다. Azure 구독에서 이 기능을 활성화하려면 이 설명서에서 방법을 참조하십시오<block ref="773d4c9e90e7325c5fcf35857900af6e" category="inline-link-rx"></block>.</block>
  <block id="0b01c5f61940e864222c5b29615a7eeb" category="inline-link">볼륨 풀 변경 설명서</block>
  <block id="265eed4df59633a830c9da49505786fc" category="list-text">Azure CLI 볼륨 풀 변경 명령은 에 나와 있습니다<block ref="db78b725076ccf0203288c6620e52eb9" category="inline-link-rx"></block> 및 의 예는 다음과 같습니다.</block>
  <block id="4455e376dc005ca0a99be0491b917ce7" category="inline-link">Set-AzNetAppFilesVolumePool cmdlet</block>
  <block id="a5bce2f378011f6036711869a5e8073b" category="list-text">PowerShell<block ref="45dc9ea5ce8eabd60a14674d792889e0" category="inline-link-rx"></block> Azure NetApp Files 볼륨의 풀을 변경하며 다음 예에 표시됩니다.</block>
  <block id="b79b50d5bff47e3a668f266c7b9dbc7b" category="inline-link-macro">다음: 데이터 처리 및 모델 훈련을 위한 라이브러리.</block>
  <block id="edd770dcbb857ec8f0871955fb2f7d5d" category="paragraph"><block ref="edd770dcbb857ec8f0871955fb2f7d5d" category="inline-link-macro-rx"></block></block>
  <block id="b8b025dc1895637326d2420e912751e0" category="summary">Trident를 사용하여 Kubernetes 클러스터 내에서 스토리지 리소스를 동적으로 프로비저닝하려면 먼저 하나 이상의 Trident 백엔드를 생성해야 합니다. 이 페이지의 예는 ONTAP AI Pod에 NetApp AI Control Plane 솔루션을 구축할 경우 생성할 수 있는 다양한 유형의 백엔드를 나타냅니다.</block>
  <block id="c0fe00dd01499e23426b850b65782c77" category="paragraph">Trident를 사용하여 Kubernetes 클러스터 내에서 스토리지 리소스를 동적으로 프로비저닝하려면 먼저 하나 이상의 Trident 백엔드를 생성해야 합니다. 다음 예는 ONTAP AI 포드에 NetApp AI Control Plane 솔루션을 구축할 경우 생성할 수 있는 다양한 유형의 백엔드를 보여줍니다. 백엔드에 대한 자세한 내용은 을 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="1e698f68960fb964df99e73068c9377c" category="list-text">NetApp AFF 시스템에서 사용할 각 데이터 LIF(데이터 액세스를 제공하는 논리적 네트워크 인터페이스)에 대해 FlexGroup 지원 Trident 백엔드를 생성하는 것이 좋습니다. LIF 간 볼륨 마운트의 균형을 조정할 수 있습니다</block>
  <block id="327a3876126e4773cfcc5e30649c9483" category="paragraph">다음 명령 예는 동일한 ONTAP 스토리지 가상 시스템(SVM)과 연관된 2개의 서로 다른 데이터 LIF에 대해 2개의 FlexGroup 지원 Trident 백엔드를 생성하는 것을 보여줍니다. 이러한 백엔드는 'ONTAP-NAS-Flexgroup' 스토리지 드라이버를 사용합니다. ONTAP는 FlexVol와 FlexGroup의 두 가지 기본 데이터 볼륨 유형을 지원합니다. FlexVol 볼륨의 크기는 제한되어 있습니다(이 쓰기 작업 시 최대 크기는 특정 구축에 따라 다름). 반면 FlexGroup 볼륨은 최대 20PB 및 4천억 개 파일까지 선형적으로 확장할 수 있으므로 데이터 관리를 크게 간소화하는 단일 네임스페이스를 제공합니다. 따라서 FlexGroup 볼륨은 대량의 데이터를 사용하는 AI 및 ML 워크로드에 최적화되어 있습니다.</block>
  <block id="ba9f56aafb45a750a8dffe5de6d2ed78" category="paragraph">소량의 데이터로 작업하고 FlexGroup 볼륨 대신 FlexVol 볼륨을 사용하려는 경우, ONTAP-NAS-Flexgroup 스토리지 드라이버 대신 'ONTAP-NAS' 스토리지 드라이버를 사용하는 Trident 백엔드를 생성할 수 있습니다.</block>
  <block id="d04adbc45ec06c05c1826745b8f4ddf2" category="list-text">또한 하나 이상의 FlexVol 지원 Trident 백엔드를 생성하는 것이 좋습니다. 데이터 세트 스토리지를 훈련하는 데 FlexGroup 볼륨을 사용하는 경우 FlexVol 볼륨을 사용하여 결과, 출력, 디버그 정보 등을 저장할 수 있습니다. FlexVol 볼륨을 사용하려면 하나 이상의 FlexVol 지원 Trident 백엔드를 생성해야 합니다. 다음 명령의 예는 단일 데이터 LIF를 사용하는 단일 FlexVol 지원 Trident 백엔드를 생성하는 것입니다.</block>
  <block id="f8bc0cf277b3c4424978d08f10f9df70" category="inline-link-macro">다음: ONTAP AI 배포를 위한 Kubernetes Storagecles의 예</block>
  <block id="a58ef634a291d01e3abec43e5619294a" category="paragraph"><block ref="a58ef634a291d01e3abec43e5619294a" category="inline-link-macro-rx"></block></block>
  <block id="fa752e98365b630341b8478c89a6757f" category="doc">Kubernetes 클러스터 구성 중</block>
  <block id="f12c340e651d989970371432778f9be2" category="paragraph">이 섹션은 클라우드 및 온프레미스 구축을 위한 두 부분으로 나누어져 있습니다.</block>
  <block id="ee06675a624f2ec74e8b71b5a57f8f9e" category="section-title">클라우드 구축 Kubernetes 구성</block>
  <block id="b513a0297a0d2efdebed8ce18e2f1715" category="paragraph">NetApp Cloud Manager를 통해 Iguazio Kubernetes 클러스터 연결을 정의할 수 있습니다. Trident를 사용하려면 클러스터의 여러 리소스에 액세스하여 볼륨을 사용할 수 있어야 합니다.</block>
  <block id="2d5bc331cc722113dd483838e908804c" category="list-text">액세스를 설정하려면 Iguazio 노드 중 하나에서 Kubernetes 구성 파일을 가져옵니다. 이 파일은 `/home/Iguazio/.kube/config.' 아래에 있습니다 이 파일을 바탕 화면에 다운로드합니다.</block>
  <block id="17c6b0de5b91c5c06a0d8173c89110d8" category="list-text">구성할 클러스터 검색 으로 이동합니다.</block>
  <block id="df37cca51036f4c5b59db211df5354bc" category="paragraph"><block ref="df37cca51036f4c5b59db211df5354bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b848e07dc3f62b4307419421d844f123" category="list-text">Kubernetes 구성 파일을 업로드합니다. 다음 이미지를 참조하십시오.</block>
  <block id="5bcc42d0a2624f1586064488c3484529" category="paragraph"><block ref="5bcc42d0a2624f1586064488c3484529" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63de24a45facebf9f65cb6578847f2b4" category="list-text">Trident를 구축하고 클러스터와 볼륨을 연결합니다. Iguazio 클러스터에 영구 볼륨 정의 및 할당에 대한 다음 이미지를 참조하십시오. 이 프로세스는 Iguazio의 Kubernetes 클러스터에 영구 볼륨(PV)을 만듭니다. 이를 사용하려면 먼저 영구 볼륨 클레임(PVC)을 정의해야 합니다.</block>
  <block id="8b69025b2efa1b2ccb917bc911d30ccd" category="section-title">온프레미스 구축 Kubernetes 구성</block>
  <block id="5be8900878997a404baf02b07ff271c6" category="paragraph">NetApp Trident의 사내 설치에 대한 자세한 내용은 을 참조하십시오<block ref="7ccf7acaa308282d5274101157fd43e5" category="inline-link-rx"></block> 를 참조하십시오. Kubernetes 클러스터를 구성하고 NetApp Trident를 설치한 후 Trident를 Iguazio 클러스터에 연결하여 데이터 및 모델의 Snapshot 복사본 생성 등의 NetApp 데이터 관리 기능을 사용할 수 있습니다.</block>
  <block id="50af1dc10d66589053fc82292fe61444" category="inline-link-macro">Next(다음): 영구 볼륨 클레임을 정의합니다</block>
  <block id="bb0c0300eb362a15d2d6480d832ecfbe" category="paragraph"><block ref="bb0c0300eb362a15d2d6480d832ecfbe" category="inline-link-macro-rx"></block></block>
  <block id="a8a1e11a906a27bd156606bf4717e8e8" category="summary">이 지원 센터 솔루션의 아키텍처는 NVIDIA의 사전 구축된 툴과 NetApp DataOps 툴킷을 중심으로 돌아가고 있습니다. NVIDIA의 도구는 사전 구축된 모델 및 파이프라인을 사용하여 고성능 AI 솔루션을 신속하게 배포하는 데 사용됩니다. NetApp DataOps 툴킷은 다양한 데이터 관리 작업을 단순화하여 개발 속도를 높여줍니다.</block>
  <block id="2d242bb36ec91b32005f9296ff03a912" category="doc">있습니다</block>
  <block id="d51083e81cbf0ec7828af24692206315" category="inline-link-macro">이전: 사용 사례.</block>
  <block id="beff34f173af198016bee889c9f9ed7a" category="paragraph"><block ref="beff34f173af198016bee889c9f9ed7a" category="inline-link-macro-rx"></block></block>
  <block id="c779b37f861deb44744634dea201514f" category="inline-link-macro">NVIDIA Riva</block>
  <block id="ccfdc9ae99a97b7a6b8ad83a329bcdc8" category="paragraph"><block ref="eb3a0fd60dc608626ce6d809beb18359" category="inline-link-macro-rx"></block> GPU에 실시간 성능을 제공하는 멀티모달 대화형 AI 애플리케이션을 구축하기 위한 GPU 가속 SDK NVIDIA Train, 조정 및 최적화(TAO) 툴킷은 교육을 가속화하고 매우 정확하고 성능 높은 도메인 특정 AI 모델을 빠르게 생성할 수 있는 더 빠르고 쉬운 방법을 제공합니다.</block>
  <block id="600ff5755ecd6aa4213eb806162b679e" category="paragraph">NetApp DataOps Toolkit은 개발자, 데이터 과학자, DevOps 엔지니어 및 데이터 엔지니어가 다양한 데이터 관리 작업을 수행할 수 있도록 지원하는 Python 라이브러리입니다. 여기에는 새로운 데이터 볼륨 또는 JupyterLab 작업 공간의 거의 즉각적인 프로비저닝, 데이터 볼륨 또는 JupyterLab 작업 공간의 거의 즉각적인 클론 복제, 추적 및 베이스라인 기능을 위한 데이터 볼륨 또는 JupyterLab 작업 공간의 거의 즉각적인 스냅샷 생성이 포함됩니다.</block>
  <block id="2b0d957e4ad1bdfd446155ff5bb8a9b2" category="section-title">아키텍처 다이어그램</block>
  <block id="1c8bd88c9d2cb845c6c27915f4a3fe8e" category="paragraph">다음 다이어그램에서는 솔루션 아키텍처를 보여 줍니다. 클라우드, 코어, 에지의 세 가지 주요 환경 범주가 있습니다. 각 범주는 지리적으로 분산될 수 있습니다. 예를 들어, 클라우드에는 여러 영역의 버킷에 오디오 파일이 있는 오브젝트 저장소가 포함되어 있는 반면, 코어에는 고속 네트워크 또는 NetApp Cloud Sync를 통해 연결된 데이터 센터가 포함될 수 있습니다. 에지 노드는 개별 상담원의 일상 업무 플랫폼을 나타내며, 대화형 대시보드 도구 및 마이크를 사용하여 감정을 시각화하고 고객과의 대화에서 오디오 데이터를 수집할 수 있습니다.</block>
  <block id="be5acbec67071810913f6782071a73eb" category="inline-link-macro">스토리지 설계</block>
  <block id="5d103a663d28ddc9aa2af5f7b958e52c" category="inline-link">리바</block>
  <block id="cc7a5a83afae781789c3a002465500b5" category="inline-link">Tao 툴킷</block>
  <block id="9595827147dc1170c44979ae1fcabaa6" category="paragraph">GPU 가속 데이터 센터에서 기업은 NVIDIA를 사용할 수 있습니다<block ref="cfd3aefe24e0725c1b0424dd8b503dc1" category="inline-link-rx"></block> 대화형 AI 애플리케이션을 구축하기 위한 프레임워크로, 이 애플리케이션은 에서 사용할 수 있습니다<block ref="ccdd6931e40e98163a0ae3c3c3bfb185" category="inline-link-rx"></block> TRANSFER L-Learning 기술을 사용하여 모델 마무리 및 재교육을 위한 연결 이러한 컴퓨팅 애플리케이션과 워크플로우가 에서 제공됩니다<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>ONTAP이 제공하는 최고의 데이터 관리 기능을 활용할 수 있습니다. 이 툴킷은 기업 데이터 팀이 추적 가능성, 버전 관리, A/B 테스트를 위해 스냅샷 및 클론을 통해 관련 정형 및 비정형 데이터와 함께 모델을 신속하게 프로토타입화할 수 있도록 해 줍니다. 따라서 보안, 거버넌스, 및 규정 준수: 섹션을 참조하십시오 <block ref="3f1432f6921bc0c51d34759cb0d748ab" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="816c3453eeba98af344f96d7eefe8834" category="paragraph">이 솔루션은 오디오 파일 처리, NLP 모델 교육, 전송 학습 및 데이터 관리 세부 정보 단계를 보여 줍니다. 결과적으로 전체 파이프라인은 인적 지원 상담원의 대시보드에 실시간으로 표시되는 정서 요약을 생성합니다.</block>
  <block id="b6fb1598d37d2537eed4160a485b790e" category="paragraph"><block ref="b6fb1598d37d2537eed4160a485b790e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47dee50ad0138b8f5ca70e40e86e6c04" category="section-title">하드웨어 요구 사항</block>
  <block id="d993b502abe38cef7c7256291e3ffa8e" category="paragraph">다음 표에는 솔루션을 구현하는 데 필요한 하드웨어 구성요소가 나와 있습니다. 이 솔루션을 구체적으로 구축하는 데 사용되는 하드웨어 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="62519b55e4debcf57caf02c89620de61" category="cell">응답 지연 시간 테스트</block>
  <block id="b763dc0a5ffab97a986c74098214cae6" category="cell">시간(밀리초)</block>
  <block id="08fa9c0a2e18301dd14e18c393fb4280" category="cell">데이터 처리</block>
  <block id="d3d9446802a44259755d38e6d163e820" category="cell">10</block>
  <block id="08db96f19d3c99c2b42fd180d9d81580" category="cell">추론</block>
  <block id="212e6da10eee5f14935bd37b84fe9684" category="paragraph">이러한 응답 시간 테스트는 560건의 대화에서 50,000개 이상의 오디오 파일로 실행되었습니다. 각 오디오 파일의 크기는 MP3로 최대 100KB, WAV로 변환될 경우 최대 1MB였습니다. 데이터 처리 단계에서는 MP3를 WAV 파일로 변환합니다. 추론 단계에서는 오디오 파일을 텍스트로 변환하고 텍스트에서 감정을 추출합니다. 이러한 단계는 모두 서로 독립적이며 병렬화를 통해 프로세스 속도를 높일 수 있습니다.</block>
  <block id="c18e24981c583441c6975f2116288cb7" category="paragraph">매장 간의 데이터 전송 지연 시간을 고려하여 관리자는 문장의 끝 후 1초 이내에 실시간 감정 분석에 대한 업데이트를 볼 수 있어야 합니다.</block>
  <block id="1c4968697a5851a64ad0fbf1b594e919" category="section-title">NVIDIA Riva 하드웨어</block>
  <block id="5a2ebfb8baa378cfcfcba58bbb1380c2" category="cell">요구 사항</block>
  <block id="17bc10091293fdc562a6db69940ee924" category="cell">OS</block>
  <block id="4c8be35e5fe3d8471f378a69f74c0ab6" category="cell">Linux x86_64</block>
  <block id="4d240f00b5a82cfaaf594cdc72f552f3" category="cell">GPU 메모리(ASR)</block>
  <block id="3fa503e0bb3bf46423ef9176821a1f6c" category="cell">스트리밍 모델: ~5600 MB 비스트리밍 모델: ~3100 MB</block>
  <block id="6345afe417f42d9e0cf6a269bff00b4c" category="cell">GPU 메모리(NLP)</block>
  <block id="217941fb2e441b0bae1b5fec0b454c31" category="cell">BERT 모델당 최대 500MB</block>
  <block id="7e04ebd38c78635d1f8aa53de0dde49b" category="section-title">NVIDIA TAO 툴킷 하드웨어</block>
  <block id="03282e46abfd7449ab38bb851caf2c8d" category="cell">시스템 RAM</block>
  <block id="edaf98e5dae9931cbd74a93b3dd93849" category="cell">32GB</block>
  <block id="6ddfc451ef4f9a7613468cd288d2ab3e" category="cell">GPU RAM</block>
  <block id="2b55387dd066c5bac646ac61543d152d" category="cell">CPU</block>
  <block id="04911a799cc8712b473ed5a3cb2b8904" category="cell">8코어</block>
  <block id="52f9ec21735243ad9917cda3ca077d32" category="cell">GPU</block>
  <block id="fceec3562665d08f1dd24689f68f0f29" category="cell">NVIDIA(A100, V100 및 RTX 30x0)</block>
  <block id="34df20bab5e85dc75bfc94ef569cced9" category="cell">SSD를 지원합니다</block>
  <block id="2f9289dfcac06a2ba95650d7e24ea9e8" category="cell">100GB</block>
  <block id="19aa61315132dbea1d19c7aeeef5f5b2" category="section-title">플래시 스토리지 시스템</block>
  <block id="fd5487a1e906d6cd514dbbc16f17a489" category="paragraph">NetApp의 최신 세대 스토리지 관리 소프트웨어인 ONTAP 9.9를 통해 기업은 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다. ONTAP는 업계 최고 수준의 데이터 관리 기능을 활용하여 데이터가 상주하는 위치와 상관없이 단일 툴셋으로 데이터를 관리하고 보호할 수 있습니다. 필요에 따라 에지, 코어, 클라우드 등 어느 위치로도 데이터를 자유롭게 이동할 수 있습니다. ONTAP 9.9에는 데이터 관리를 단순화하고, 중요 데이터를 더 빨리 처리하고, 보호하며, 하이브리드 클라우드 아키텍처 전체에서 차세대 인프라 기능을 지원하는 다양한 기능이 포함되어 있습니다.</block>
  <block id="78a2efe59d4ad6ad51556ea77f5fdec3" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> 은(는) 빠르고 안전한 데이터 동기화를 제공하는 NetApp 서비스로, 사용자는 온프레미스 NFS 또는 SMB 파일 공유 간에 파일을 다음 타겟으로 전송할 수 있습니다.</block>
  <block id="df2c24964ca3e99761acc48b2c8a75c9" category="list-text">NetApp ONTAP S3</block>
  <block id="1a4c7c9b6e3157ccd0101fd0836c0bfc" category="list-text">NetApp Cloud Volumes Service를 참조하십시오</block>
  <block id="ddcf3699b41cd4c4ee5be4b9dd95c1e6" category="list-text">Amazon Simple Storage Service(Amazon S3)</block>
  <block id="8224436b00c48149c863f4b17219a19d" category="list-text">Amazon Elastic File System(Amazon EFS)</block>
  <block id="52745271323ee9ea30e3a37d0338d118" category="list-text">Azure Blob</block>
  <block id="833c2c211a541e50ad94433664e4b5c1" category="list-text">Google 클라우드 스토리지</block>
  <block id="5446a6bee3301e1f52824fc0affa6299" category="list-text">IBM 클라우드 오브젝트 스토리지</block>
  <block id="1b238365e840da0711b49e8f646e2fdf" category="paragraph">Cloud Sync는 파일을 필요한 위치로 빠르고 안전하게 이동합니다. 데이터가 전송되면 소스와 타겟 모두에서 사용할 수 있습니다. Cloud Sync는 미리 정의된 일정에 따라 데이터를 지속적으로 동기화하여 변경된 부분만 이동하여 데이터 복제에 소요되는 시간과 비용을 최소화합니다. Cloud Sync는 설정과 사용이 간편한 SaaS(Software as a Service) 툴입니다. Cloud Sync에 의해 트리거되는 데이터 전송은 데이터 브로커가 수행합니다. AWS, Azure, Google Cloud Platform 또는 온프레미스에서 Cloud Sync 데이터 브로커를 구축할 수 있습니다.</block>
  <block id="a5c952f5be43013a024d778712474fbc" category="paragraph">StorageGRID 소프트웨어 정의 오브젝트 스토리지 제품군은 퍼블릭, 프라이빗, 하이브리드 멀티 클라우드 환경에서 다양한 사용 사례를 원활하게 지원합니다. 업계 최고 수준의 혁신적인 NetApp StorageGRID은 오랫동안 자동 라이프사이클 관리를 포함하여 다목적 사용을 위해 비정형 데이터를 저장, 보안, 보호 및 보존합니다. 자세한 내용은 를 참조하십시오<block ref="7660f0463c83c682b9f091117b07c3b3" category="inline-link-rx"></block> 사이트.</block>
  <block id="6ffce2da93d4b296032f30d7b2adea01" category="paragraph">다음 표에는 이 솔루션을 구축하는 데 필요한 소프트웨어 구성요소가 나와 있습니다. 이 솔루션을 구체적으로 구축하는 데 사용되는 소프트웨어 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="d20072ce64f4d9efd57e036d2b7c30ec" category="cell">호스트 시스템</block>
  <block id="7915eebeca25d928212b5d457786a549" category="cell">Riva(이전 명칭 JARVIS)</block>
  <block id="1bf6e69c18341244d990250bf5aa3ce0" category="cell">1.4.0</block>
  <block id="7a2cd4790985cbbb0b362dfe8e59d991" category="cell">Tao 툴킷(이전 명칭: 학습 툴킷)</block>
  <block id="55c82b601deae028c1c5e87fd820923d" category="cell">3.0</block>
  <block id="253b40ae359ba25b56231803430c4873" category="cell">ONTAP</block>
  <block id="67c6ecbcd91c613e8659b3f0c4b01510" category="cell">9.9.1</block>
  <block id="8bec4fb7fbc1430e393d3f41063748e7" category="cell">DGX OS</block>
  <block id="43ff194f410f3e93a8680bef5ba51e50" category="cell">5.1</block>
  <block id="1b13fe3d4acac980a061d9efb92000d5" category="cell">생년월일</block>
  <block id="d233662f9c26d1a06118c93ef2fd1de9" category="cell">2.0.0</block>
  <block id="76e535c7d7533499b0d86f60a0d15b84" category="section-title">NVIDIA Riva 소프트웨어</block>
  <block id="5d7bf724a19463b3251c61a94a446c4c" category="cell">&gt;19.02(NVIDIA-Docker 설치 시) &gt;=19.03(DGX를 사용하지 않는 경우</block>
  <block id="3ff6010d41ffb33d6f0971a202e76ad7" category="cell">NVIDIA 드라이버</block>
  <block id="616120c1963dd46f2321dd37e823f8a0" category="cell">465.19.01 + 418.40+, 440.33+, 450.51+, 460.27+(데이터 센터 GPU용</block>
  <block id="88f8128d405513d54a3e9831c73f87a0" category="cell">컨테이너 OS</block>
  <block id="73611f9a837b7a25dad3a9c5d1a98658" category="cell">Ubuntu 20.04</block>
  <block id="a33b7755e5f9b504d2d038eaca4ff28d" category="cell">CUDA</block>
  <block id="a26b47ba45087eadbeaa7c4802b3a8c8" category="cell">11.3.0</block>
  <block id="d92ef06e9564a9db573d075b4220057e" category="cell">큐블라스</block>
  <block id="a8a364c27ce7406b7be591b4f973d5bb" category="cell">11.5.1.101</block>
  <block id="9bfd6cd63a5597c998aa2d96564f5c34" category="cell">큐드NN</block>
  <block id="15daa8f1432fd7e2b07f63097623dfab" category="cell">8.2.0.41</block>
  <block id="1ed15cc4178fd8ec4d845042a8f1ead0" category="cell">NCCL</block>
  <block id="f10585a0c5c8f535143471006baef867" category="cell">2.9.6</block>
  <block id="61918500e2bc645b2aea3f447086a8a5" category="cell">TensorRT</block>
  <block id="086934e5e95d3c797fc75f38fb3d086c" category="cell">7.2.3.4</block>
  <block id="d024876954df77538311467564f00917" category="cell">Triton Inference Server를 참조하십시오</block>
  <block id="0d6f7e6ce6f1553544acb14682c8eb07" category="cell">2.9.0</block>
  <block id="2efc85a476098fde0ecbf8d81505b612" category="section-title">NVIDIA TAO 툴킷 소프트웨어</block>
  <block id="cb6c22f673a55391483c7f040d8cf637" category="cell">Ubuntu 18.04 LTS</block>
  <block id="4077fabc9a8b0e761cfd9bf752e03c8a" category="cell">18.04</block>
  <block id="23eeeb4347bdd26bfc6b7ee9a3b755dd" category="cell">파이썬</block>
  <block id="c80362c25c18981fcf433e78dda5de78" category="cell">&gt;= 3.6.9</block>
  <block id="aec7ff22e2f74b581cffbfa59e63f347" category="cell">Docker-CE 를 참조하십시오</block>
  <block id="21ca3af3ea5e6a282911a64dbf5ced7a" category="cell">&gt;19.03.5</block>
  <block id="0cf76d9b00333f4396d0424ae164dd07" category="cell">Docker-API를 지원합니다</block>
  <block id="ca2b7e7213f7ba5d4b3923e807af27df" category="cell">1.40</block>
  <block id="ad2f80b0463af47fcb7430e0e1789841" category="cell">NVIDIA - 컨테이너 - 툴킷</block>
  <block id="12b58130c1d9383cf3bf63391bd04721" category="cell">&gt;1.3.0-1</block>
  <block id="cec57b9746d41fd1c1749d591dbd7baf" category="cell">nvidia-container-runtime</block>
  <block id="68b90d96e3d934d65890ff695d37f354" category="cell">3.4.0-1</block>
  <block id="f235b98dbe494fca328354abf0b52858" category="cell">nVidia-docker2</block>
  <block id="10439f6f665bce43173e2871a0b7bfc6" category="cell">2.5.0-1</block>
  <block id="fd3811d814e856dc6a43152673bb6753" category="cell">nVidia - 드라이버</block>
  <block id="06c61cdd8c93e750b3e0d4e2537416ea" category="cell">&gt;455</block>
  <block id="b6da1806d8ccb5327c3d80bbcfea4737" category="cell">Python-PIP</block>
  <block id="7b043cb99d00fe56df3fead569b1a4de" category="cell">&gt;21.06</block>
  <block id="3bdf92e45d10e51e2bdc2b16cf33f345" category="cell">nVidia-pyindex</block>
  <block id="9ca445b9db010a99239196af5ac3a8b9" category="cell">최신 버전</block>
  <block id="cf87f69879c53ebf670ee8bd793ad7ba" category="section-title">사용 사례 세부 정보</block>
  <block id="976894dcc596e37094668684315ccac4" category="paragraph">이 솔루션은 다음과 같은 사용 사례에 적용됩니다.</block>
  <block id="52a38da70697d6c80e3b6a204f64263f" category="paragraph"><block ref="52a38da70697d6c80e3b6a204f64263f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8ff4a485cc084b2a4b5bb829cf18055" category="paragraph">텍스트 음성 변환 사용 사례는 지원 센터의 오디오 파일을 수집하여 시작합니다. 그런 다음 이 오디오는 Riva가 요구하는 구조에 맞게 처리됩니다. 오디오 파일이 아직 분석 단위로 분할되지 않은 경우 Riva에 오디오를 전달하기 전에 이 작업을 수행해야 합니다. 오디오 파일이 처리되면 Riva 서버에 API 호출로 전달됩니다. 서버는 호스팅 중인 여러 모델 중 하나를 사용하고 응답을 반환합니다. 이 텍스트 음성 변환(자동 음성 인식의 일부)은 오디오의 텍스트 표현을 반환합니다. 여기서 파이프라인은 감정 분석 부분으로 전환됩니다.</block>
  <block id="230007c23660d290efdea5586b1716aa" category="paragraph">감정 분석의 경우 자동 음성 인식의 텍스트 출력은 텍스트 분류에 대한 입력 역할을 합니다. 텍스트 분류는 텍스트를 다양한 범주로 분류하는 NVIDIA 구성 요소입니다. 지원 센터 대화의 경우 긍정적 범주에서 부정적 범주에 이르기까지 다양합니다. 미세 조정 단계의 성공을 결정하기 위해 홀드아웃 세트를 사용하여 모델의 성능을 평가할 수 있습니다.</block>
  <block id="3390cebd79348bc76a1e5eb5f169bedf" category="paragraph"><block ref="3390cebd79348bc76a1e5eb5f169bedf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="952b3f5758e644ef2558d59d3aace0b1" category="inline-link">NVIDIA NGC 카탈로그</block>
  <block id="4fa0a0d712258621946173068bf4f7e0" category="paragraph">TAO 툴키트의 텍스트 음성 및 정서 분석에 비슷한 파이프라인이 사용됩니다. 주요 차이점은 모델의 미세 조정에 필요한 라벨 사용입니다. TAO 툴킷 파이프라인은 데이터 파일 처리부터 시작합니다. 그런 다음 미리 훈련된 모델(에서 제공)을 사용합니다<block ref="aaddb3bb47bcb0ca6e2a55cdce808e9b" category="inline-link-rx"></block>)는 지원 센터 데이터를 사용하여 미세 조정됩니다. 미세 조정된 모델은 해당 성능 메트릭을 기준으로 평가되며, 사전 훈련된 모델보다 성능 기준에 더 적합한 경우 Riva 서버에 배포됩니다.</block>
  <block id="587796d49571c1c4d5c89993d7ed01dd" category="inline-link-macro">다음: 설계 고려 사항.</block>
  <block id="1165e49145cd3a7ebc2b75e325d8797a" category="paragraph"><block ref="1165e49145cd3a7ebc2b75e325d8797a" category="inline-link-macro-rx"></block></block>
  <block id="8537de5688b6b855ec8b5465eca4e8f6" category="list-text">NVIDIA DGX Station, V100 GPU, GPU Cloud</block>
  <block id="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link"><block ref="e4c64a7040f5ee4721b3880f35ae02c8" category="inline-link-rx"></block></block>
  <block id="432a0462f3a215c89d6067d01ac9fee8" category="list-text">NVIDIA DGX 스테이션<block ref="00e84bc2760804fd15a292583676639b" category="inline-link-rx"></block></block>
  <block id="a8135dcfdfd9c1074b55895b8d51f9be" category="list-text">NVIDIA V100 Tensor 코어 GPU<block ref="a724832176ce84a9d4be5c34e44891d3" category="inline-link-rx"></block></block>
  <block id="f3e44b157fa7ead37042e8a6f3b14071" category="list-text">NGC<block ref="839d9b8469a8d9554891a7515a2b9be7" category="inline-link-rx"></block></block>
  <block id="45f2cdf50f8bb89b245e814009b4244c" category="list-text">NVIDIA Jarvis 다중 모드 프레임워크</block>
  <block id="944c1fe2317541350506cecb6131b857" category="inline-link"><block ref="944c1fe2317541350506cecb6131b857" category="inline-link-rx"></block></block>
  <block id="d3ceb6166da1ada512f22bc7832ec047" category="list-text">NVIDIA Jarvis<block ref="34ae4389dc7afcada801d63c08e322b9" category="inline-link-rx"></block></block>
  <block id="21ce987b6ba4d344f1427dc72d497669" category="inline-link"><block ref="21ce987b6ba4d344f1427dc72d497669" category="inline-link-rx"></block></block>
  <block id="7bf7a8db8c3809766aa2579c2eadf37d" category="list-text">NVIDIA Jarvis 조기 액세스<block ref="2daee9604c6a07f74e6776847d2ee61e" category="inline-link-rx"></block></block>
  <block id="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link"><block ref="e58709fef6e6eb28a11c06d27c5d6aa7" category="inline-link-rx"></block></block>
  <block id="852c7bf0a8f3b30a5a001dbf642dbebe" category="list-text">NVIDIA 니모<block ref="fa9e246f0ef36a285adacc70507ae974" category="inline-link-rx"></block></block>
  <block id="299a4717590cda2cfe1db321802b4995" category="inline-link"><block ref="299a4717590cda2cfe1db321802b4995" category="inline-link-rx"></block></block>
  <block id="dfc2ce4fd02d20052bebaa2e6b8cd029" category="list-text">개발자 가이드 를 참조하십시오<block ref="9940ba67713949ce4f2fc05d3a37bd8c" category="inline-link-rx"></block></block>
  <block id="5467c9d1c07a7d1786936650b3c2d52a" category="list-text">NetApp AFF A 시리즈 데이터시트<block ref="0d9d8991a05834f0e52a99b37ce360b8" category="inline-link-rx"></block></block>
  <block id="6bb399f406fc5ac4150ad21c6aa05ab2" category="list-text">All Flash FAS에서 NetApp 플래시의 이점<block ref="72cf25e9f1e13167cd0dde6f285552ea" category="inline-link-rx"></block></block>
  <block id="9415aef2732728cc097fbbc9ab96b2fe" category="list-text">ONTAP 9 정보 라이브러리<block ref="8ac8a4cdf844ed67e9ec6ddc4b3e95ad" category="inline-link-rx"></block></block>
  <block id="d106dc348953acc0500f03a25379282e" category="list-text">NetApp ONTAP FlexGroup 볼륨 기술 보고서<block ref="7a26d62dac2be507dcc3e5b9da0ed765" category="inline-link-rx"></block></block>
  <block id="05dbc5885d3bec70d2317a4b51526d96" category="list-text">DGX-1 및 Cisco 네트워킹 기반 ONTAP AI 설계 가이드<block ref="9fbee18519e76388280bc1f8e3fd6c7e" category="inline-link-rx"></block></block>
  <block id="af5797305db370f4f59d77bf7c73160b" category="list-text">DGX-1 및 Cisco 네트워킹 지원 ONTAP AI 배포 가이드<block ref="aef3d0752148699921f8a251537d5ff3" category="inline-link-rx"></block></block>
  <block id="f2345b2674d3976c091d4af042c36a8f" category="inline-link"><block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="f63c45f352478237d0d0fe7c5a26d6bf" category="list-text">DGX-1 및 Mellanox 네트워킹 설계 가이드를 지원하는 ONTAP AI<block ref="459df3a4bfb1f89f6920196001257745" category="inline-link-rx"></block></block>
  <block id="b38db7c217c396412f601b87dfc58a8c" category="inline-link"><block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="da8009e462fd2ec5eeb41b4cf3721f7a" category="list-text">DGX-2 기반 ONTAP AI 설계 가이드<block ref="86d70269673ee41c37a2673f7d3655ce" category="inline-link-rx"></block></block>
  <block id="3a607d0e3fa64fd7558e11352f751dd0" category="summary">NetApp AI Control Plane 솔루션은 이 특정 하드웨어에 종속되지 않습니다.</block>
  <block id="976cf3edd8adeff2e75cd7a9dd0dae21" category="paragraph">NetApp AI Control Plane 솔루션은 이 특정 하드웨어에 종속되지 않습니다. 이 솔루션은 Trident에서 지원하는 모든 NetApp 물리적 스토리지 어플라이언스, 소프트웨어 정의 인스턴스 또는 클라우드 서비스와 호환됩니다. 예를 들어 NetApp AFF 스토리지 시스템, Azure NetApp Files, NetApp Cloud Volumes Service, NetApp ONTAP Select 소프트웨어 정의 스토리지 인스턴스 또는 NetApp Cloud Volumes ONTAP 인스턴스가 있습니다. 또한, 사용된 Kubernetes 버전이 Kubeflow 및 NetApp Trident에서 지원하는 경우 모든 Kubernetes 클러스터에서 구현할 수 있습니다. Kubeflow에서 지원하는 Kubernetes 버전 목록은 를 참조하십시오<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Trident에서 지원하는 Kubernetes 버전 목록은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>. 솔루션을 검증하는 데 사용된 환경에 대한 자세한 내용은 다음 표를 참조하십시오.</block>
  <block id="2e4fd4a404800f52299c132a3403dc72" category="cell">인프라 구성 요소</block>
  <block id="64d354dc5879cf570ce7b4ef676e75bd" category="cell">운영 체제</block>
  <block id="4152ac69f367cb5f64dfbc247dd41db0" category="cell">배포 점프 호스트</block>
  <block id="583a65df9db4119165f5ea0abaa50281" category="cell">VM</block>
  <block id="204dd0a482d284a7fb87c908f713f9bd" category="cell">Ubuntu 20.04.2 LTS</block>
  <block id="f341fd2fe180518e152be2d6fb4ec20b" category="cell">Kubernetes 마스터 노드</block>
  <block id="a89c263b82f7c7f61c9b6c93080f8425" category="cell">Kubernetes 작업자 노드</block>
  <block id="76a7e6383604f84ace970ce86ba76a9f" category="cell">Kubernetes GPU 작업자 노드</block>
  <block id="f89b34b046a8d6e3137c95861fa3cf8a" category="cell">NVIDIA DGX-1(베어 메탈)</block>
  <block id="eba551f3f972830c55b1c9bef15b5f26" category="cell">NVIDIA DGX OS 4.0.5(Ubuntu 18.04.2 LTS 기준)</block>
  <block id="0911ffdbb76c891f964e39a07eb6b697" category="cell">1개의 HA 쌍</block>
  <block id="d1d73cf191d1afbd40e85644467cae8b" category="cell">NetApp ONTAP 9.7 P6</block>
  <block id="68782f72ebeb2cac06f03226a6e941bb" category="cell">소프트웨어 구성 요소</block>
  <block id="385904ba8ac27bcacafadf2113386df4" category="cell">아파치 기류</block>
  <block id="47354877541923135499c38a6606138a" category="cell">2.0.1</block>
  <block id="9ba69bd971d430b368ce3f0286c8e77c" category="cell">Apache Airflow Helm Chart(Apache Airflow 제어 차트</block>
  <block id="ecfa741d55b7b1a85bd61a2307877c8c" category="cell">8.0.8</block>
  <block id="fd99a7ef225418315b041ad631a5674c" category="cell">2012년 3월 19일</block>
  <block id="56765472680401499c79732468ba4340" category="cell">1.2</block>
  <block id="48d02190984e4f8526f99f9cd9550e08" category="cell">1.18.9</block>
  <block id="d58d49f83f534f5d71b20750bb7927c7" category="cell">21.01.2</block>
  <block id="7a04e1f765218bcbfc633ef331b312b8" category="inline-link-macro">61898cdfda</block>
  <block id="7855beff2fafbce2cf0df4d67f8dfed7" category="cell">커밋 시 마스터 분기의 Trident 배포 기능 <block ref="686ead03155c78694e1a59db0970fc1a" category="inline-link-macro-rx"></block>버전 21.03의 다른 모든 기능</block>
  <block id="db5eb84117d06047c97c9a0191b5fffe" category="section-title">지원</block>
  <block id="b2e75bbfb9933bc21b7f875e8676641d" category="inline-link-macro">NetApp에 문의하십시오</block>
  <block id="a1773dfa99aa26853e90886d55e0d05a" category="paragraph">NetApp은 Apache Airflow, Docker, Kubeflow, Kubernetes 또는 NVIDIA DeepOps에 대한 엔터프라이즈 지원을 제공하지 않습니다. NetApp AI Control Plane 솔루션과 유사한 기능을 갖춘 완벽한 지원 솔루션을 원하는 경우, <block ref="103a4ac9affe57bb7edb7796bfdeb684" category="inline-link-macro-rx"></block> NetApp이 파트너와 공동으로 제공하는 완전 지원되는 AI/ML 솔루션 정보</block>
  <block id="26c21566450ecb01d82e6d0e3f7ef1a3" category="inline-link-macro">다음: Kubernetes 배포.</block>
  <block id="0635bed13bdc0ace58fec0264ac3d119" category="paragraph"><block ref="0635bed13bdc0ace58fec0264ac3d119" category="inline-link-macro-rx"></block></block>
  <block id="b481424c052310e67a9b67a931165509" category="summary">이 섹션에서는 이 솔루션을 검증하는 데 사용되는 테스트 절차를 설명합니다.</block>
  <block id="3562305aa864cd56d3e2840eb5071caa" category="doc">테스트 절차</block>
  <block id="e46c1f341c1cea1321f4c00d15e90b0d" category="inline-link-macro">이전: 구성을 테스트합니다.</block>
  <block id="ed760d2dffd7d011a7870619f7884005" category="paragraph"><block ref="ed760d2dffd7d011a7870619f7884005" category="inline-link-macro-rx"></block></block>
  <block id="bff816e8e8ddbe2a3b705d92abba6627" category="paragraph">이 검증에서 다음 테스트 절차를 사용했습니다.</block>
  <block id="1b0981f820949c10d68daad3fdf03976" category="section-title">운영 체제 및 AI 추론 설정</block>
  <block id="fe03e7fb4a8d3a1afb24c94c4c88d32f" category="paragraph">AFF C190의 경우 NVIDIA GPU를 지원하고 MLPerf를 사용하는 NVIDIA 드라이버 및 Docker와 함께 Ubuntu 18.04를 사용했습니다<block ref="72ea1359ddbf7a99cdb0a438fda3e022" category="inline-link-rx"></block> MLPerf Inference v0.7에 대한 Lenovo 제출의 일부로 사용할 수 있습니다.</block>
  <block id="504812acf44740b8f536a0d166375734" category="paragraph">EF280의 경우 NVIDIA GPU 및 MLPerf를 지원하는 Ubuntu 20.04와 NVIDIA 드라이버 및 Docker를 사용했습니다<block ref="7dc141edfa21f33dbd4b0757be1ad69f" category="inline-link-rx"></block> MLPerf Inference v1.1에 대한 Lenovo 제출의 일부로 제공됩니다.</block>
  <block id="fbd2228a821a8ab1948d4a8c3121fb0e" category="paragraph">AI 추론을 설정하려면 다음 단계를 수행하십시오.</block>
  <block id="9177ba75c6dc50d818c52360f10e2fe1" category="list-text">등록이 필요한 데이터 세트, ImageNet 2012 검증 세트, Critio Terabyte 데이터 세트 및 브라츠 2019 교육 세트를 다운로드한 다음 파일의 압축을 풉니다.</block>
  <block id="12dda17fb1d76556387dceb2e85a9290" category="list-text">최소 1TB의 작업 디렉토리를 생성하고 디렉토리를 참조하는 환경 변수 MLPERF_Scratch_path를 정의합니다.</block>
  <block id="342ecacc441a9548b60eae46065039f8" category="paragraph">네트워크 스토리지 활용 사례나 로컬 데이터로 테스트할 때 로컬 디스크에 대해 공유 스토리지에서 이 디렉토리를 공유해야 합니다.</block>
  <block id="7c5f7553ff57e0548889000668d1cf39" category="list-text">make "prebuild" 명령을 실행하여 필요한 추론 작업을 위해 Docker 컨테이너를 빌드하고 실행합니다.</block>
  <block id="9cfc451dfe052c5c3835b0355375b1b7" category="admonition">다음 명령은 실행 중인 Docker 컨테이너 내에서 모두 실행됩니다.</block>
  <block id="b25e1e6ba392fe4c0e0da7617a67fa4d" category="list-text">MLPerf Inference 태스크에 대한 사전 교육 AI 모델 'MAKE download_model'을 다운로드합니다</block>
  <block id="ed43016366915f1fc65fe332de60965f" category="list-text">무료로 다운로드할 수 있는 추가 데이터셋 'make download_data'를 다운로드하세요</block>
  <block id="41165a10471c0644aef30b976f113946" category="list-text">데이터 사전 처리: preprocess_data를 만든다</block>
  <block id="f0bacb5df46d2e8bed3d6d0d863fce01" category="list-text">러닝: 메이크 빌드.</block>
  <block id="189eed4566c6894d64b4d4f8bc9df94c" category="list-text">컴퓨팅 서버의 GPU에 최적화된 추론 엔진 'make generate_gservers'를 구축합니다</block>
  <block id="4efea18a74f8c5a6fa0f4b239ff2d734" category="list-text">추론 워크로드를 실행하려면 다음 명령을 실행합니다(하나의 명령).</block>
  <block id="9ce2624cb32bec75a2ad4e276fa594f6" category="section-title">AI 추론 실행</block>
  <block id="2a71d3fa50a14f6fa9c62d9fe3935d5d" category="paragraph">세 가지 유형의 실행이 실행되었습니다.</block>
  <block id="3a4a320ee019614122e99baebf056b86" category="list-text">로컬 스토리지를 사용하는 단일 서버 AI 추론</block>
  <block id="adf25fe660bba733a104887732393fdd" category="list-text">네트워크 스토리지를 사용하여 단일 서버 AI 추론</block>
  <block id="34e4c32e4097a70208139be85d5dc892" category="list-text">네트워크 스토리지를 사용하여 다중 서버 AI 추론</block>
  <block id="7dc96590f7bab3379a7a79986056d22a" category="inline-link-macro">다음: 테스트 결과.</block>
  <block id="697d202c2969580ba0434be04d39a929" category="paragraph"><block ref="697d202c2969580ba0434be04d39a929" category="inline-link-macro-rx"></block></block>
  <block id="d052a88935efadcc9eebf94684d52e19" category="doc">높은 클러스터 사용률 달성</block>
  <block id="8d46742dbd21a217f738a9ca6a31f634" category="paragraph">이 섹션에서는 GPU 리소스의 우선순위 지정 및 밸런싱을 유지하면서 높은 클러스터 사용률을 달성하는 Run:AI 오케스트레이션 솔루션을 시연하기 위해 4개의 데이터 과학 팀이 각자 고유의 워크로드를 제출하는 실제 시나리오를 에뮬레이트합니다. 먼저 섹션에 설명된 ResNet-50 벤치마크를 사용합니다 <block ref="5872a8c23866a6bf186843724ee58ad7" category="inline-link-macro-rx"></block>:</block>
  <block id="14f48338822299bdf82bb4528d3c9e07" category="paragraph">에서와 같이 ResNet-50 벤치마크를 실행했습니다<block ref="c37aff28e1a25306bf31a11e21ff2c71" category="inline-link-rx"></block>. 우리는 공공 Docker 리포지토리에 없는 컨테이너에 '--local-image' 플래그를 사용했습니다. 호스트 DGX-1 노드의 /mnt와 /tmp 디렉토리를 각각 컨테이너에 `/mnt', '/tmp' 디렉토리에 마운트했습니다. 데이터 세트는 디렉토리를 가리키는 dataset_dir와 함께 NetApp AFFA800에 있습니다. '--num_devices=1'과 '-g 1'은 이 작업에 하나의 GPU를 할당한다는 것을 의미합니다. 전자는 run.py 스크립트의 주장이고 후자는 runai submit 명령의 플래그입니다.</block>
  <block id="bccb844975c2eec86eb25c0d8e2a989b" category="paragraph">다음 그림은 97%의 GPU 사용률과 16개의 사용 가능한 GPU가 할당된 시스템 개요 대시보드를 보여 줍니다. GPU/프로젝트 막대 차트에서 각 팀에 할당된 GPU 수를 쉽게 확인할 수 있습니다. 실행 중인 작업 창에는 현재 실행 중인 작업 이름, 프로젝트, 사용자, 유형, 노드, GPU 사용량, 실행 시간, 진행률 및 활용률 세부 정보 대기 시간이 있는 대기열의 워크로드 목록이 보류 중인 작업에 표시됩니다. 마지막으로, 노드 상자는 클러스터의 개별 DGX-1 노드에 대한 GPU 수와 활용률을 제공합니다.</block>
  <block id="1acc627e7c9d8002628b2e12c91ac683" category="paragraph"><block ref="1acc627e7c9d8002628b2e12c91ac683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5d3b5670d9303fddfb021e681546c0" category="inline-link-macro">다음으로, 덜 까다롭거나 대화형 워크로드에 대한 GPU 할당 분수를 지정합니다</block>
  <block id="3d9997e0f8b3b6a279c8779455e7c760" category="paragraph"><block ref="3d9997e0f8b3b6a279c8779455e7c760" category="inline-link-macro-rx"></block></block>
  <block id="66bc9494be0116470b223f2e07873f77" category="summary">이 페이지에서는 NetApp AI Control Plane 솔루션을 구현하기 위해 Kubernetes 클러스터를 구축하는 데 필요한 작업에 대해 설명합니다. Kubernetes 클러스터가 이미 있는 경우, Kubeflow 및 NetApp Trident에서 지원하는 Kubernetes 버전을 실행 중인 경우 이 섹션을 건너뛸 수 있습니다.</block>
  <block id="7c1ab988344d6a8d8cd9a30d6240955a" category="paragraph">이 섹션에서는 NetApp AI Control Plane 솔루션을 구현하기 위해 Kubernetes 클러스터를 구축하는 데 필요한 작업에 대해 설명합니다. Kubernetes 클러스터가 이미 있는 경우, Kubeflow 및 NetApp Trident에서 지원하는 Kubernetes 버전을 실행 중인 경우 이 섹션을 건너뛸 수 있습니다. Kubeflow에서 지원하는 Kubernetes 버전 목록은 를 참조하십시오<block ref="01b2e82a7080cdbeb934280240df876e" category="inline-link-rx"></block>. Trident에서 지원하는 Kubernetes 버전 목록은 를 참조하십시오<block ref="e6b3671f5db59046617458d31ef4f50b" category="inline-link-rx"></block>.</block>
  <block id="ef8333b35fd982099a6ca0c7799b5618" category="paragraph">NVIDIA GPU를 탑재한 베어 메탈 노드를 포함하는 온프레미스 Kubernetes 배포의 경우 NVIDIA의 DeepOps Kubernetes 배포 도구를 사용하는 것이 좋습니다. 이 섹션에서는 DeepOps를 사용하여 Kubernetes 클러스터 구축에 대해 간략하게 설명합니다.</block>
  <block id="612cba744b0eac9a7f153d2c4b8975da" category="list-text">표준 구성 지침에 따라 베어 메탈 Kubernetes 노드(예: ONTAP AI 포드의 일부인 NVIDIA DGX 시스템)를 이미 구성했습니다.</block>
  <block id="5a881e8e37e19924ac592136b5e7cfd3" category="inline-link">DeepOps GitHub 사이트</block>
  <block id="452f5f6e8da4512f6cce223a76ae3558" category="list-text">모든 Kubernetes 마스터 및 작업자 노드와 배포 점프 호스트에 지원되는 운영 체제를 설치했습니다. DeepOps에서 지원하는 운영 체제 목록은 를 참조하십시오<block ref="253a2cf380d7db7eaadb375aa91e2221" category="inline-link-rx"></block>.</block>
  <block id="a711e4ccced882d1762a8c653be8e921" category="section-title">NVIDIA DeepOps를 사용하여 Kubernetes 설치 및 구성</block>
  <block id="0e91d2e60705ecb1730e9b96510019af" category="list-text">의 지침에 따라 NVIDIA DeepOps를 다운로드합니다<block ref="6fb71807bf6999d2aec034d498e3ebf6" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="2ed5978807d3da780c60a19b3f38a293" category="inline-link">Kubernetes 배포 가이드 페이지</block>
  <block id="5c18e4efa8c5cc9efb26e3f748b4e26d" category="list-text">의 지침에 따라 클러스터에 Kubernetes를 배포합니다<block ref="b336a8bbad16f0e8d58bf87e261f51fa" category="inline-link-rx"></block> NVIDIA DeepOps GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="e76934323b48d5421aa2271f7e9fbee2" category="inline-link-macro">다음으로, NetApp Trident 구축 및 구성 개요 를 참조하십시오.</block>
  <block id="4e3ff90ed271e98a6802a9063034ea76" category="paragraph"><block ref="4e3ff90ed271e98a6802a9063034ea76" category="inline-link-macro-rx"></block></block>
  <block id="207e9f2f3c6b5a3e8c9228ceadc806b2" category="summary">이 섹션에서는 테스트된 구성, 네트워크 인프라, SE350 서버 및 스토리지 프로비저닝 세부 정보에 대해 설명합니다.</block>
  <block id="32d798df7254f6703ed2262024e0e174" category="doc">구성을 테스트합니다</block>
  <block id="b1ee26c1917a17c30b17d7cd6b01e2cd" category="inline-link-macro">이전: 테스트 계획.</block>
  <block id="7dffe110836fe412eac19d0f63cf5b5b" category="paragraph"><block ref="7dffe110836fe412eac19d0f63cf5b5b" category="inline-link-macro-rx"></block></block>
  <block id="a55faacbe457d923ebd296421a71b898" category="paragraph">다음 그림은 테스트 구성을 보여 줍니다. NetApp AFF C190 스토리지 시스템과 Lenovo ThinkSystem SE350 서버 2대(각각 NVIDIA T4 가속기 1대)를 사용했습니다. 이러한 구성요소는 10GbE 네트워크 스위치를 통해 연결됩니다. 네트워크 스토리지는 검증/테스트 데이터 세트와 사전 교육 모델을 보유하고 있습니다. 서버는 컴퓨팅 기능을 제공하며 스토리지는 NFS 프로토콜을 통해 액세스됩니다.</block>
  <block id="d8c97013f1e301478b23530ad6ed1ef6" category="paragraph">이 섹션에서는 테스트된 구성, 네트워크 인프라, SE350 서버 및 스토리지 프로비저닝 세부 정보에 대해 설명합니다. 다음 표에서는 솔루션 아키텍처의 기본 구성 요소를 보여 줍니다.</block>
  <block id="7e897f23ed71aef1c0a8acf1ae54e9e4" category="cell">솔루션 구성 요소</block>
  <block id="fe8ab8cb391be4f8cf88a9b64c3ce3cd" category="list-text">각각 NVIDIA T4 GPU 카드 1개가 장착된 SE350 서버 2대</block>
  <block id="acd4671bd4d78c7fc0ac8cbc66a01483" category="list-text">각 서버에는 2.20GHz 및 128GB RAM에서 4개의 물리적 코어가 실행되는 Intel Xeon D-2123IT CPU 1개가 포함되어 있습니다</block>
  <block id="d7d02fd9ab069a2d95dee248370100f9" category="cell">엔트리 레벨 NetApp AFF 스토리지 시스템(HA 쌍,</block>
  <block id="1d680806b37a387e8d84b0c21be4d816" category="list-text">NetApp ONTAP 9 소프트웨어</block>
  <block id="0c1dcc458c4dd96728e0b0998cba7305" category="list-text">24x 960GB SSD</block>
  <block id="a2a817ee9a8e05389f7b11bd8ce4bbdb" category="list-text">NFS 프로토콜</block>
  <block id="d8e87bd5878266cd4137e82d919799eb" category="list-text">컨트롤러당 1개의 인터페이스 그룹으로, 마운트 지점에 4개의 논리 IP 주소를 사용합니다</block>
  <block id="1a538c197da3186f1eba50d82572dc34" category="paragraph"><block ref="1a538c197da3186f1eba50d82572dc34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="208eac927f1261c6e6eaa3135a529cf3" category="paragraph">다음 표에는 스토리지 구성이 2RU, 24개 드라이브 슬롯이 포함된 AFF C190에 나와 있습니다.</block>
  <block id="9bbf373797bf7cf7ba62c80023682e25" category="cell">컨트롤러</block>
  <block id="2ee34178bb8415b7d7234cd27b83aed6" category="cell">집계</block>
  <block id="e9db3004828d9514fafc57881dfbdbd2" category="cell">FlexGroup 볼륨</block>
  <block id="2e0fb97d51b96b1635dcc3ca51f74fee" category="cell">애그리게이트 크기</block>
  <block id="b94c9ec583603e13b5c32d83199c7376" category="cell">볼륨 크기</block>
  <block id="53a35f8b51acc9748a3e172a76f542a7" category="cell">운영 체제 마운트 지점</block>
  <block id="6a1ab89ed912a96429c83ff1ba0f48d0" category="cell">컨트롤러1</block>
  <block id="4d80d82716f0b771738e7fad121e059a" category="cell">집계1</block>
  <block id="e39298390e27007517a0cb199728188a" category="cell">/netapplenovo_AI_FG</block>
  <block id="4923ec171d721fba1d4547deefc98e8c" category="cell">8.42TiB</block>
  <block id="f13cb116755b4e8fa1af1b201025f377" category="cell">15TB</block>
  <block id="3fe74875837b518b23813988af1e39d9" category="cell">/NetApp_Lenovo_FG입니다</block>
  <block id="3877384a92be771d61972d07648b799f" category="cell">컨트롤러 2</block>
  <block id="f3913037ef38679d334aa0cf30e2b6fd" category="cell">집계2</block>
  <block id="6b02e3a677be18a8be3641bb43e8b220" category="paragraph">/netappLenovo_AI_FG 폴더에는 모델 검증에 사용된 데이터 세트가 포함되어 있습니다.</block>
  <block id="e4239f67d8e47773c69a7cb4be34d949" category="paragraph">아래 그림은 테스트 구성을 보여 줍니다. NetApp EF280 스토리지 시스템과 두 개의 Lenovo ThinkSystem SE350 서버(각각 NVIDIA T4 가속기 1개 포함)를 사용했습니다. 이러한 구성요소는 10GbE 네트워크 스위치를 통해 연결됩니다. 네트워크 스토리지는 검증/테스트 데이터 세트와 사전 교육 모델을 보유하고 있습니다. 서버는 컴퓨팅 기능을 제공하며 스토리지는 NFS 프로토콜을 통해 액세스됩니다.</block>
  <block id="efb90877bc42cc445eb6e1b59c0e1b16" category="paragraph">다음 표에는 EF280에 대한 스토리지 구성이 나와 있습니다.</block>
  <block id="0951a6690e5dc87411346792c9f941c7" category="cell">볼륨 그룹</block>
  <block id="bd7a9717d29c5ddcab1bc175eda1e298" category="cell">볼륨</block>
  <block id="6c88d21af6046f64871457b825dcf1c8" category="cell">DDPsize를 참조하십시오</block>
  <block id="59b02558285aa326c0e9018324ed0c4f" category="cell">연결 방법</block>
  <block id="db320b0194c895c7ac56fedae7928e63" category="cell">DDP1</block>
  <block id="fc452c26db3c4aa6f6213b9c5d9e3abc" category="cell">볼륨 1</block>
  <block id="fe066d0b9d36398d5f525d6ac7f8e8c5" category="cell">16TB</block>
  <block id="e0d2b052ec3dbd102ff7a7f2b356ea41" category="cell">SE350-1에서 iSCSI LUN 0으로</block>
  <block id="ef0e038a9f9b0db74b504d5521e7a0fc" category="cell">볼륨 2</block>
  <block id="5b846730a13fc5ea0a76a6b7b9a69d5a" category="cell">SE350-2를 iSCSI LUN 1로 설정합니다</block>
  <block id="43fa57e4031b0f759153c9c9fa49e6ed" category="paragraph"><block ref="43fa57e4031b0f759153c9c9fa49e6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0fccd40a3886a1e5dc539059407586a0" category="inline-link-macro">다음: 테스트 절차</block>
  <block id="3bee5237e36a9a0dc60fd351ce904544" category="paragraph"><block ref="3bee5237e36a9a0dc60fd351ce904544" category="inline-link-macro-rx"></block></block>
  <block id="9dc7cfc5bd8fb85bad9fdab5cdded288" category="doc">AI 설치 를 실행하십시오</block>
  <block id="c1b7d088e01f6ec6ec89bf69437e4bb1" category="paragraph">Run:AI를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="7ad0483bc07dbde29ffd404af83f8305" category="list-text">DeepOps를 사용하여 Kubernetes 클러스터를 설치하고 NetApp 기본 스토리지 클래스를 구성합니다.</block>
  <block id="16d20d34f759cd25fd7486bbc4046a50" category="list-text">GPU 노드 준비:</block>
  <block id="d3eff3861b26ba61222bacaa41bc0fa7" category="list-text">NVIDIA 드라이버가 GPU 노드에 설치되었는지 확인합니다.</block>
  <block id="3683aa7fe695a205b8e40e9589c94a2e" category="list-text">nVidia-docker가 기본 Docker 런타임으로 설치 및 구성되어 있는지 확인합니다.</block>
  <block id="cef990020518a58fb1e70a90b5df80fe" category="list-text">러닝 설치: AI:</block>
  <block id="e2d6778a342979b567501f951e36118a" category="inline-link">AI 관리자 UI를 실행합니다</block>
  <block id="6fc7ea9b01c6028f691aac2aeac528f1" category="list-text">에 로그인합니다<block ref="668d940d94d02be49a88c4cfd2736fa9" category="inline-link-rx"></block> 클러스터를 생성합니다.</block>
  <block id="fe8f08cfda6726e2dcc5d0b85ed2c67d" category="list-text">생성된 'runai-operator-&lt;clustername&gt;.yAML' 파일을 다운로드합니다.</block>
  <block id="b428155da5c27d208abd6c179c7669d3" category="list-text">Kubernetes 클러스터에 운영자 구성을 적용하십시오.</block>
  <block id="fac4447e0ea2e4cd1a2d9e2fefeab694" category="list-text">설치를 확인합니다.</block>
  <block id="2d14c64dc5dfa79a68cd6965fbf9e4b7" category="list-text">로 이동합니다<block ref="115d2727bd1dc614110a31f98c029830" category="inline-link-rx"></block>.</block>
  <block id="feb48a27d95fc7a7e0c6db496c54d2fa" category="list-text">개요 대시보드로 이동합니다.</block>
  <block id="09fa3891e2b39bb62217c6d097310577" category="inline-link">Run 설치: 사내 Kubernetes 클러스터에 AI를 설치합니다</block>
  <block id="45d7be937e1eddf966adaf68562966d4" category="inline-link">Run:AI CLI 설치</block>
  <block id="728f8fd776de1dc47f318473052286db" category="list-text">오른쪽 위에 있는 GPU 수가 예상 GPU 수를 반영하고 GPU 노드가 모두 서버 목록에 있는지 확인합니다.실행:AI 배포에 대한 자세한 내용은 을 참조하십시오<block ref="089aa48f8d7b3b135b035765dd1e17ba" category="inline-link-rx"></block> 및<block ref="f2f48a2074c9edc0c2dea174863a4f6e" category="inline-link-rx"></block>.</block>
  <block id="db9d1f740f050b1d20ab43a459bb225a" category="inline-link-macro">다음: AI 대시보드 및 보기를 실행합니다</block>
  <block id="c56b5d251d18e9b020f95696fef9f0b9" category="paragraph"><block ref="c56b5d251d18e9b020f95696fef9f0b9" category="inline-link-macro-rx"></block></block>
  <block id="ff9caff469d56a572a569942ca24c8b4" category="list-text">NVIDIA DGX 시스템</block>
  <block id="b69073c22b4269568fd577ea090ce638" category="list-text">NVIDIA DGX-1 시스템<block ref="45a310b0e4b087b75cb073303044f6f9" category="inline-link-rx"></block></block>
  <block id="fe287c518b9b1345defadacdc6a9ecbf" category="list-text">NVIDIA V100 Tensor 코어 GPU<block ref="fad8218d69ce01748faed5492aa5d3ef" category="inline-link-rx"></block></block>
  <block id="d6a8716635a5681cde357a465953bc72" category="list-text">NGC<block ref="5c75bfead88762783d54deaaa3d62735" category="inline-link-rx"></block></block>
  <block id="11bdb18e1c5e7d1e4362c9d2f6956fc8" category="list-text">실행: AI 컨테이너 오케스트레이션 솔루션</block>
  <block id="5afc85c81e76f427a293dd861e0109a3" category="list-text">실행: AI 제품 소개<block ref="64b899832bfcad18bb426fb355a0d03b" category="inline-link-rx"></block></block>
  <block id="9acfbb098f0d9b45b5897b44ae347ee9" category="list-text">AI 설치 설명서를 실행하십시오<block ref="cb05a776556ca5a25aec417185ef6863" category="inline-link-rx"></block>
<block ref="b2e8533fae57aa9047d7731db51b6dfe" category="inline-link-rx"></block></block>
  <block id="b0d8a6d0eebdc42ac243c16f9137118d" category="list-text">Run:AI CLI에서 작업 제출<block ref="97ec6c214f99d7e6a39194a167aeecc8" category="inline-link-rx"></block>
<block ref="d75350381b5fda5cc9c9a1ce34c24299" category="inline-link-rx"></block></block>
  <block id="9bd35f4f3f6faa9e9330c54fd2086967" category="list-text">실행 시 GPU 분할 할당: AI CLI<block ref="e343516de5fb56c6a0d652bcdfceaab7" category="inline-link-rx"></block></block>
  <block id="ddb27cb97146c8f5964eaf368feb4ce0" category="list-text">기술 보고서<block ref="3ce56c027572d1908d65b63056be024f" category="inline-link-rx"></block></block>
  <block id="2273cd603e277bb35f96881a557b0608" category="list-text">간단한 데모<block ref="61e3673018126d9a106032d9ff691322" category="inline-link-rx"></block></block>
  <block id="45f26b752dfae88ec8c7def446162521" category="list-text">GitHub 리포지토리<block ref="f9a4909739179bedfa8ba1d225598979" category="inline-link-rx"></block></block>
  <block id="c36e36ff8b7edf8dd17781148ed57337" category="list-text">NetApp AFF A 시리즈 데이터시트<block ref="9a84c14d2692222552174943486e7136" category="inline-link-rx"></block></block>
  <block id="ffc4c8e8bc10afc438d9c590f44e3b51" category="list-text">All Flash FAS에서 NetApp 플래시의 이점<block ref="9dcd8a7bfc88cf6bbca4b422861950bf" category="inline-link-rx"></block></block>
  <block id="7843ce52c43038d88c2f54d85f3f764d" category="list-text">ONTAP 9 정보 라이브러리<block ref="974aeb47ab8fd0a635d02d8ac80b9eb1" category="inline-link-rx"></block></block>
  <block id="5f1b8a708e16776ca4372c71dc377653" category="list-text">NetApp ONTAP FlexGroup 볼륨 기술 보고서<block ref="1ab29fc7fde3319a82a477ec308cf820" category="inline-link-rx"></block></block>
  <block id="062d7e5979c653f33e03cb0aaeaec6e9" category="list-text">DGX-1 및 Cisco 네트워킹 기반 ONTAP AI 설계 가이드<block ref="b141781260425e95eee945147e2f0d99" category="inline-link-rx"></block></block>
  <block id="59086e50189644b7c19947dfa68f8395" category="list-text">DGX-1 및 Cisco 네트워킹 지원 ONTAP AI 배포 가이드<block ref="921f17c41dea89b0a711f380e9864e09" category="inline-link-rx"></block></block>
  <block id="062afad089226e62b53e77ba2af24574" category="list-text">DGX-1 및 Mellanox 네트워킹 설계 가이드를 지원하는 ONTAP AI<block ref="f2345b2674d3976c091d4af042c36a8f" category="inline-link-rx"></block></block>
  <block id="e6b737f0513721f0a8024f538058333e" category="list-text">DGX-2 기반 ONTAP AI 설계 가이드<block ref="b38db7c217c396412f601b87dfc58a8c" category="inline-link-rx"></block></block>
  <block id="a905494ad30a6d54678a2122c04bfd54" category="summary">Jupyter Notebooks 및 Kubeflow 파이프라인 예제</block>
  <block id="80e94617849fe0b057f3edcc76a6ac72" category="doc">예제 전자 필기장 및 파이프라인</block>
  <block id="3da57858cd6a76521b38784effc6a06f" category="paragraph">를 클릭합니다<block ref="42224cf159df1ff428bf611c27a06039" category="inline-link-rx"></block> Kubeflow와 함께 사용할 수 있습니다. Kubeflow와 함께 NetApp Data Science Toolkit을 사용하면 다음과 같은 이점이 있습니다.</block>
  <block id="624a53dc5871ce49612a285ee2bf367e" category="list-text">데이터 과학자는 Jupyter Notebook 내에서 직접 고급 NetApp 데이터 관리 작업을 수행할 수 있습니다.</block>
  <block id="1c7d37cb415e8b7777b071784911a77a" category="list-text">고급 NetApp 데이터 관리 작업은 Kubeflow 파이프라인 프레임워크를 사용하여 자동화된 워크플로우에 통합할 수 있습니다.</block>
  <block id="5e646a4ae4330cb948544333980f9f49" category="inline-link">Kubeflow 예</block>
  <block id="987823970c7b662272fb9e0058bf5ff1" category="paragraph">을 참조하십시오<block ref="3eb5d4ffd5360858e22dfb9799f211d7" category="inline-link-rx"></block> Kubeflow 기반 툴킷 사용에 대한 자세한 내용은 NetApp Data Science Toolkit GitHub 리포지토리 를 참조하십시오.</block>
  <block id="52a739b78342bd0cef8801d4c5c193b6" category="inline-link-macro">다음: Apache Airflow Deployment</block>
  <block id="6564dd7688129caf4acb63587998eb65" category="paragraph"><block ref="6564dd7688129caf4acb63587998eb65" category="inline-link-macro-rx"></block></block>
  <block id="dc12a1ce34c0a7a264de91bc9b933a62" category="paragraph">이 섹션에서는 'team-d'가 더 많은 GPU(할당량 아래)를 요청할 때 시스템이 'team-b'와 'team-c'의 워크로드를 일시 중지하고 공평한 분배 방식으로 보류 중인 상태로 전환한다는 것을 보여 줍니다.</block>
  <block id="86bbd55ea7850716c0c192b19c86176a" category="paragraph">작업 제출, 사용된 컨테이너 이미지 및 실행된 명령 시퀀스를 포함한 자세한 내용은 섹션을 참조하십시오 <block ref="94d73a1896276f719be59227f0e93a14" category="inline-link-macro-rx"></block>.</block>
  <block id="b6ea2a2f48a443e7d027bd652ac84762" category="paragraph">다음 그림은 자동 로드 밸런싱 및 사전 예방 예약 기능으로 인해 발생하는 클러스터 활용률, 팀당 할당된 GPU 및 보류 중인 작업을 보여줍니다. 모든 팀 작업 부하에 의해 요청된 총 GPU 수가 클러스터에서 사용 가능한 총 GPU 수를 초과할 때 Run:AI의 내부 공정성 알고리즘은 프로젝트 할당량을 충족했기 때문에 "team-b"와 "team-c"에 대해 각각 하나의 작업을 일시 중지한다는 것을 알 수 있습니다. 따라서 전반적인 높은 클러스터 활용률이 제공되지만 데이터 과학 팀은 관리자가 설정한 리소스 제약 조건에서 작업을 계속 수행할 수 있습니다.</block>
  <block id="d1a54cf8cb2a06c0715d2f042fbf44bd" category="paragraph"><block ref="d1a54cf8cb2a06c0715d2f042fbf44bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d52816ece2166f7a2e0eadf58d617df9" category="paragraph">이 테스트 시나리오의 결과는 다음과 같습니다.</block>
  <block id="bce83ec0a92a5b10380007a1643b2fd0" category="list-text">* 자동 로드 밸런싱. * 시스템은 GPU의 할당량을 자동으로 조정하여 각 팀에서 현재 할당량을 사용하고 있습니다. 일시 중지된 워크로드는 할당량이 초과된 팀에 속합니다.</block>
  <block id="f8be0d1ca354f8cb4aaa4c8aadcea80b" category="list-text">* 공정한 공유 일시 중지. * 시스템이 할당량이 초과된 팀의 작업 부하를 중지하도록 선택한 다음 다른 팀의 작업 부하를 중지시킵니다. 실행: AI에는 내부 공정성 알고리즘이 있습니다.</block>
  <block id="c088b6e407ba7f9c0274382acfa3eae0" category="inline-link-macro">다음: 할당량 초과 공정성</block>
  <block id="8e015e1b989b11d70fcb778747b8c614" category="paragraph"><block ref="8e015e1b989b11d70fcb778747b8c614" category="inline-link-macro-rx"></block></block>
  <block id="48fe531f68f98f9f6afcf79da6d3b1b3" category="doc">TR-4834: MLRun 파이프라인에 대한 NetApp과 Iguazio</block>
  <block id="a0e5bba9c75f65c1d58c6a238316bd2b" category="paragraph">Rick Huang, David Arnette, NetApp Marcelo Litovsky, Iguazio</block>
  <block id="dd9508a891c15cc4bb34f03dc870ab6c" category="paragraph">이 문서에서는 NetApp ONTAP AI, NetApp AI Control Plane, NetApp Cloud Volumes 소프트웨어 및 Iguazio 데이터 과학 플랫폼을 사용하는 MLRun 파이프라인의 세부 정보를 다룹니다. Nuclio serverless 기능, Kubernetes Persistent Volumes, NetApp Cloud Volumes, NetApp Snapshot 복사본, Grafana 대시보드를 사용했습니다. 네트워크 장애 감지 시뮬레이션을 위한 종단 간 데이터 파이프라인을 구축하기 위한 Iguazio 플랫폼의 기타 서비스. Iguazio 및 NetApp 기술을 통합하여 사내와 클라우드에서 모델 구축, 데이터 복제 및 운영 모니터링 기능을 빠르게 구현합니다.</block>
  <block id="d431a0ad3e0e99cf99c08fda529884bd" category="paragraph">데이터 과학자의 작업은 머신 러닝(ML) 및 인공 지능(AI) 모델의 훈련 및 튜닝에 중점을 두어야 합니다. 그러나 Google의 조사에 따르면 데이터 과학자는 다음 이미지에서와 같이 모델을 엔터프라이즈 애플리케이션과 연동하고 대규모로 실행하는 방법을 찾는 데 80% 정도 시간을 소비합니다. AI/ML 워크플로우에서 모델 개발을 묘사한 것으로 나타났습니다.</block>
  <block id="f08b641e59dba6d999dc1bc2085bcd2c" category="paragraph"><block ref="f08b641e59dba6d999dc1bc2085bcd2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eec0363d19df86d30ecefc2e44170fa" category="paragraph">엔드 투 엔드 AI/ML 프로젝트를 관리하려면 엔터프라이즈 구성 요소를 더 잘 이해해야 합니다. DevOps가 이러한 유형의 구성 요소를 정의, 통합 및 배포했지만 머신 러닝 작업은 AI/ML 프로젝트를 포함하는 비슷한 흐름을 목표로 합니다. 엔터프라이즈에서 엔드 투 엔드 AI/ML 파이프라인이 어떤 영향을 받는지 알아보려면 다음 필수 구성요소 목록을 참조하십시오.</block>
  <block id="52681719ec1296447ae0e357c4781415" category="list-text">개발 IDE(통합 개발 환경)</block>
  <block id="2f0ff7df4fd6fa99bbf249af2ea4c3a5" category="paragraph">이 문서에서는 NetApp과 Iguazio 간의 파트너십을 통해 엔드 투 엔드 AI/ML 파이프라인 개발을 획기적으로 단순화하는 방법을 보여줍니다. 이러한 단순화 덕분에 모든 AI/ML 애플리케이션의 출시 시기를 앞당길 수 있습니다.</block>
  <block id="253411380ba9cde08bcfafbd516ad585" category="paragraph">데이터 과학의 세계는 정보 기술 및 비즈니스의 여러 분야에 영향을 줍니다.</block>
  <block id="f1a4e0eca545ebe9e3c32f1fde407410" category="list-text">비즈니스 사용자는 AI/ML 애플리케이션에 액세스할 수 있기를 원합니다. NetApp과 Iguazio가 각 역할을 통해 당사의 플랫폼을 통해 비즈니스에서 가치를 창출하는 방법을 설명합니다.</block>
  <block id="00cc9e5c959e62a9132baca479060db3" category="paragraph">이 솔루션은 AI/ML 애플리케이션의 라이프사이클 뒤에 있습니다. 먼저 데이터 과학자의 작업을 통해 데이터를 준비하고 모델을 훈련 및 구축하는 데 필요한 다양한 단계를 정의합니다. 또한 아티팩트를 추적하고, 실행을 실험하고, Kubeflow에 배포할 수 있는 능력을 갖춘 전체 파이프라인을 생성하는 데 필요한 작업을 수행합니다. 전체 주기를 완료하기 위해 NetApp Cloud Volumes와 파이프라인을 통합하여 다음 이미지와 같이 데이터 버전 관리를 지원합니다.</block>
  <block id="ddd4a11ec23c52d3f0831809bc4d7c8f" category="paragraph"><block ref="ddd4a11ec23c52d3f0831809bc4d7c8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7c8cd7998e5c4a67923acf8580d94e2" category="inline-link-macro">다음: 기술 개요</block>
  <block id="b9023dede6231d8f57593d31db930bf6" category="paragraph"><block ref="b9023dede6231d8f57593d31db930bf6" category="inline-link-macro-rx"></block></block>
  <block id="d9ed812c8dd9083f1fb345425b8ce100" category="paragraph">이 섹션에서는 섹션의 테스트 세부 정보를 다룹니다 <block ref="fdc629b29ea94e672f68b28bf3b661b4" category="inline-link-macro-rx"></block>.</block>
  <block id="be53a0541a6d36f6ecb879fa2c584b08" category="cell">이미지</block>
  <block id="c6e328a3639bc00374d81e681f89f609" category="cell">Jupyter를 선택합니다</block>
  <block id="ff8bed43ac09b1148fc7648f5845f698" category="cell">1/4</block>
  <block id="37ce74088416f28dc9bb04355c2e5a28" category="cell">–</block>
  <block id="cfaa375bf6c7f9fcc1bc04d4f30c9154" category="cell">넷엡</block>
  <block id="6408e079aefee9702aa00f77228dd941" category="cell">2월 4일</block>
  <block id="00833fac70036c049bd75443869cacb5" category="cell">실행: AI</block>
  <block id="d2313e844e73fe4a8f63d93f4df355fc" category="cell">모든 할당량을 사용합니다</block>
  <block id="e95e1ca27d0e39aa03eb5a611ce4122f" category="cell">0.6</block>
  <block id="e4275e3860ed32f489dbb6a5d4a10f5f" category="cell">0.6/2</block>
  <block id="8457d97e0a0f74a5926d1dee27e53541" category="cell">소수점 GPU</block>
  <block id="54fbf38cf649866815e0fefc46a1f6c7" category="cell">0.4</block>
  <block id="975ca8804565c1a569450d61090b2743" category="cell">1/2로</block>
  <block id="411472b1216ec08457e653eac42d7bbd" category="cell">2개 초과 할당량</block>
  <block id="d310cb367d993fb6fb584b198a2fd72c" category="cell">0.5</block>
  <block id="76169512ef5ca1abe70b32c0993856af" category="cell">0.5/2</block>
  <block id="e85b79abfd76b7c13b1334d8d8c194a5" category="cell">0.3</block>
  <block id="5c2b079fc9750c2995852b8fb354aae3" category="cell">2월 8일</block>
  <block id="3d522deaf85577451c01974654b36ad3" category="cell">0.2</block>
  <block id="00fd1da21e8b4ef31d987665dc575099" category="cell">3월 2일</block>
  <block id="0375b76ff57435094e28e94015a5f052" category="cell">1개 초과 할당</block>
  <block id="ecdb9acc2db02134680a9c49abe3e991" category="cell">8월 4일</block>
  <block id="30c006c71ada68e2273b128bc2e6831b" category="cell">할당량의 절반을 사용합니다</block>
  <block id="36cf0dc9f04c54214fa577ec66ff53fc" category="paragraph">명령 구조:</block>
  <block id="7b3a4ccf5e0cc7918cd458f7e46b9c8e" category="paragraph">테스트에 사용된 실제 명령 시퀀스:</block>
  <block id="478eb1c4e698b325048b6bccfb8974f6" category="cell">4/4(소프트 할당량/실제 할당)</block>
  <block id="2df6f557cc57e6d4044b9611b1f56439" category="inline-link-macro">Over-uota GPU 할당을 통한 높은 클러스터 활용률 달성</block>
  <block id="3667ebc7f28f59fc13bfcf314c67de05" category="paragraph">섹션을 참조하십시오 <block ref="dee5d16c649661a62d3a765af5b1a963" category="inline-link-macro-rx"></block> 진행 중인 테스트 시나리오에 대한 논의.</block>
  <block id="ac8466404b94a669f51a3d2db2401cf0" category="inline-link-macro">다음: 섹션 4.9의 테스트 세부 정보</block>
  <block id="84b7d04f598931bc149a92c543d3146f" category="paragraph"><block ref="84b7d04f598931bc149a92c543d3146f" category="inline-link-macro-rx"></block></block>
  <block id="34d110ef6b6b3684adfe9c791fce2f95" category="summary">이 섹션에서는 이 솔루션을 배포하는 데 필요한 세부 단계를 설명합니다.</block>
  <block id="e0673e67d0ae2470ff4a9a3a926792b0" category="doc">지원 센터 정서 분석 배포</block>
  <block id="0c7ee1e6d81ae421558f2979d46adb5d" category="inline-link-macro">이전: 설계 고려 사항.</block>
  <block id="2e4639bc721df1da69c19fe5c10f5764" category="paragraph"><block ref="2e4639bc721df1da69c19fe5c10f5764" category="inline-link-macro-rx"></block></block>
  <block id="b23f4e3eb5ff4f900ba54c824bf7a676" category="paragraph">솔루션 배포에는 다음 구성 요소가 포함됩니다.</block>
  <block id="1b497bff4e1d2dff7f8855237612936b" category="list-text">NGC 구성</block>
  <block id="2dcf1afb8ed1445e4b167ef91fdd8a1b" category="list-text">NVIDIA Riva 서버</block>
  <block id="6894a1e922948fc0bc9cc96291183448" category="list-text">NVIDIA TAO 툴킷</block>
  <block id="3b498dd8feee94c2dbcb419be10d3b70" category="list-text">TAO 모델을 Riva로 내보냅니다</block>
  <block id="534b37206d500ff97473ada660fb69d3" category="paragraph">배포를 수행하려면 다음 단계를 수행하십시오.</block>
  <block id="2f6c7bd50828792593b3aa4deff875cc" category="section-title">NetApp DataOps 툴킷: 지원 센터 정서 분석</block>
  <block id="3b84de14b99e2695fdfd099f56b254be" category="paragraph">를 사용합니다<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>에서 다음 단계를 완료합니다.</block>
  <block id="d19523f192f664c9e34bf949d6f084c3" category="list-text">PIP 도구 키트를 설치합니다.</block>
  <block id="1fe6ae43439f5ccecf9883686d6b3784" category="list-text">데이터 관리를 구성합니다</block>
  <block id="36b413e2c45a91e66db4aac6abd67ba1" category="section-title">NGC 구성: 지원 센터 정서 분석</block>
  <block id="e3ab64bcab09d9eb8219520405242267" category="inline-link">NGC</block>
  <block id="f526ba073cf7bc97c2b0d3bfe091e293" category="paragraph">를 눌러 설정합니다<block ref="5b4e29c9d8254a25bb1abc36cd17ca4c" category="inline-link-rx"></block>에서 다음 단계를 완료합니다.</block>
  <block id="a485a457c113aa9f2f8096ac1ca500d7" category="list-text">NGC를 다운로드합니다.</block>
  <block id="7438544460c4a4fdf0b70bb65bb03a92" category="list-text">현재 디렉터리를 경로에 추가합니다.</block>
  <block id="4f1208b2473595e5f4c3118c13de0fcc" category="list-text">명령을 실행할 수 있도록 NGC CLI를 구성해야 합니다. 메시지가 나타나면 API 키를 포함하여 다음 명령을 입력합니다.</block>
  <block id="6c92285fa6d3e827b198d120ea3ac674" category="inline-link">여기</block>
  <block id="5307692c5f99e57b8002a6a87f08c240" category="paragraph">Linux 기반이 아닌 운영 체제는 을 참조하십시오<block ref="481e32faa0c657434738f6f0a550651b" category="inline-link-rx"></block>.</block>
  <block id="326419ec6a380f68d7d15a373452bf35" category="section-title">NVIDIA Riva 서버: 지원 센터 정서 분석</block>
  <block id="92ed82a726e834b50a6863c8c4e9db4e" category="paragraph">를 눌러 설정합니다<block ref="fb85035785391c7c4b815d01de952f38" category="inline-link-rx"></block>에서 다음 단계를 완료합니다.</block>
  <block id="a4fc5fd3d1cea05f031d5adc045dc1e0" category="list-text">NGC에서 Riva 파일을 다운로드합니다.</block>
  <block id="5f2573d8cf9e274560d9a9b3eb2e1aaa" category="list-text">Riva 설정 초기화('Riva_init.sh')</block>
  <block id="3b570ac682cfeffcdb2c7243afdbf285" category="list-text">Riva 서버('Riva_start.sh')를 시작합니다.</block>
  <block id="d44d4e10378cce2928c99a4b49e45cea" category="list-text">Riva client('Riva_start_client.sh')를 시작합니다.</block>
  <block id="6846c1a17ddaf84e01f26ec51c151e78" category="inline-link">FFmpeg</block>
  <block id="22c9c751571566e0566c448194d9d64f" category="list-text">Riva 클라이언트 내에서 오디오 처리 라이브러리(<block ref="3e294dfc4ee3a49adac5a070482274ce" category="inline-link-rx"></block>)</block>
  <block id="8637711b2ee1b94fe789bb28e88c4b61" category="list-text">를 시작합니다<block ref="37a4c4b3ad3c3851ac5717bfd3104346" category="inline-link-rx"></block> 서버.</block>
  <block id="b57a5203a9fd3e877aacee6cba6bc9c8" category="list-text">Riva Inference Pipeline 노트북을 실행합니다.</block>
  <block id="5dceab25ae38dae0d7ed3167abd32377" category="section-title">NVIDIA TAO Toolkit: 지원 센터 정서 분석</block>
  <block id="2418d4c7f6be40d5c9a50e4aecab1b27" category="paragraph">NVIDIA TAO 툴킷을 설정하려면 다음 단계를 수행하십시오.</block>
  <block id="630eef78d15fd844ba4a38ea7f7a9c79" category="inline-link">가상 환경</block>
  <block id="35fb58d5f90347e4f0c445b4968db5f6" category="list-text">를 준비하고 활성화합니다<block ref="3d97a4392c0af686650645d1371fa8ef" category="inline-link-rx"></block> TAO 툴킷을 참조하십시오.</block>
  <block id="0a80b2068950d6e04f34c0142a10e719" category="inline-link">필수 패키지</block>
  <block id="40eb0bd8a87ab1b39e8f2ee5ea287a22" category="list-text">를 설치합니다<block ref="3646357cb54591ae95dd3b8f0889f0c2" category="inline-link-rx"></block>.</block>
  <block id="c0e95a7dacbc170e387c4e1a0fe41a0b" category="list-text">교육 및 미세 조정 중에 사용된 이미지를 수동으로 당깁니다.</block>
  <block id="b5a6ae7c1df936b55910309efc466f01" category="list-text">TAO 미세 조정 노트북을 실행합니다.</block>
  <block id="e6dda626093691f78b3127a8faa82b6e" category="section-title">TAO 모델을 Riva로 내보내기: 지원 센터 정서 분석</block>
  <block id="6a358d81cb24a7e408b0339062f6bb92" category="inline-link">Riva의 Tao 툴킷 모델</block>
  <block id="53ace4ba305859107cead3e5b0b53b8b" category="paragraph">사용합니다<block ref="ce50a5bf8eb35af9ad9bb322336ee3af" category="inline-link-rx"></block>에서 다음 단계를 완료합니다.</block>
  <block id="08c3be8307b7659c6ad67ee4d9659d58" category="list-text">TAO 미세 조정 노트북에 모델을 저장합니다.</block>
  <block id="ac711bb6af28947dfa8b29512acb36e8" category="list-text">TAO 교육을 받은 모델을 Riva 모델 디렉토리에 복사합니다.</block>
  <block id="1317e1d8d20d5c44c680825aba2196e6" category="section-title">구축 방해</block>
  <block id="6e3da39922ebbd1a8a1a5a7238a89168" category="paragraph">다음은 자체 솔루션을 개발할 때 고려해야 할 몇 가지 사항입니다.</block>
  <block id="47c0613abd5b97b67a94c2355692cf08" category="list-text">NetApp DataOps 툴킷은 데이터 스토리지 시스템이 최적으로 실행되도록 하기 위해 먼저 설치됩니다.</block>
  <block id="943f803f8c6b4c6508bc97536a6d7b2b" category="list-text">NVIDIA NGC는 이미지와 모델의 다운로드를 인증하기 때문에 다른 무엇보다도 먼저 설치해야 합니다.</block>
  <block id="70367b72bfd96b5608a7c72ac3f983bf" category="list-text">TAO 툴킷을 설치하기 전에 Riva를 설치해야 합니다. Riva 설치는 필요에 따라 Docker 데몬을 구성하여 이미지를 가져옵니다.</block>
  <block id="1ed7124aa68792cb6ce3049f6f1d4f7b" category="list-text">모델을 다운로드하려면 DGX 및 Docker에 인터넷 액세스 권한이 있어야 합니다.</block>
  <block id="de9b04ca3177b736c9f3cc74d62f5088" category="inline-link-macro">다음: 확인 결과.</block>
  <block id="3556370bb03d018998375ff0476db59a" category="paragraph"><block ref="3556370bb03d018998375ff0476db59a" category="inline-link-macro-rx"></block></block>
  <block id="00760d3595ff19f6db2da5213b1fdd58" category="summary">이 문서에서는 새로운 애플리케이션 시나리오를 충족하는 에지 환경에서 NetApp 스토리지 컨트롤러 및 Lenovo ThinkSystem 서버에 GPU 기반 인공 지능(AI) 추론을 배포하기 위한 컴퓨팅 및 스토리지 아키텍처에 대해 설명합니다.</block>
  <block id="09f4ae28e2596e14a7568f3e12a77834" category="doc">TR-4886: Edge-NetApp에서 Lenovo ThinkSystem - 솔루션 설계를 사용한 AI 추론</block>
  <block id="6671938f046112e34e990cb75cc642dd" category="paragraph">Sathish Thyagarajan, NetApp Miroslav Hodak, Lenovo</block>
  <block id="0b79795d3efc95b9976c7c5b933afce2" category="section-title">소개</block>
  <block id="a27de0758c1fc778a0fb19ebcb6a8aff" category="paragraph">기업들은 네트워크 에지에 대량의 데이터를 생성하고 있습니다. 스마트 센서 및 IoT 데이터를 활용하여 최대의 가치를 실현하기 위해 조직은 에지 컴퓨팅을 지원하는 실시간 이벤트 스트리밍 솔루션을 찾고 있습니다. 따라서 데이터 센터 외부의 에지에서는 컴퓨팅 작업이 점점 더 많이 수행됩니다. AI 추론을 이러한 트렌드에 동인으로 이끄는 요인 중 하나입니다. 에지 서버는 특히 가속기를 사용할 때 이러한 워크로드에 충분한 연산 능력을 제공하지만 제한된 스토리지는 종종 문제가 됩니다. 특히 다중 서버 환경에서는 더욱 그렇습니다. 이 문서에서는 에지 환경에서 공유 스토리지 시스템을 구축하는 방법과 성능 저하 없이 AI 추론 워크로드의 이점을 활용하는 방법을 설명합니다.</block>
  <block id="c22ef83c0446b759f6cd8835206adaae" category="paragraph">이 문서에서는 에지의 AI 추론을 위한 참조 아키텍처에 대해 설명합니다. 여러 Lenovo ThinkSystem 에지 서버를 NetApp 스토리지 시스템과 결합하여 간편하게 구축 및 관리할 수 있는 솔루션을 구축합니다. 이 가이드는 여러 대의 카메라와 산업용 센서가 장착된 공장 바닥, 소매 거래의 POS(Point-of-Sale) 시스템 또는 자율 차량의 시각적 이상을 식별하는 FSD(Full Self-Driving) 시스템 등 다양한 상황에서 실제 배포를 위한 기본 안내서입니다.</block>
  <block id="36d77288dbd3663ec436c43b32682300" category="paragraph">이 문서에서는 Lenovo ThinkSystem SE350 Edge Server와 엔트리 레벨 NetApp AFF 및 EF-Series 스토리지 시스템으로 구성된 컴퓨팅 및 스토리지 구성의 테스트 및 검증을 다룹니다. 참조 아키텍처는 AI 배포를 위한 효율적이고 비용 효율적인 솔루션을 제공하는 동시에 NetApp ONTAP 및 NetApp SANtricity 데이터 관리 소프트웨어를 통해 포괄적인 데이터 서비스, 통합 데이터 보호, 원활한 확장성 및 클라우드 연결 데이터 스토리지를 제공합니다.</block>
  <block id="5dd536dd8122d7ba5df3ce642e603305" category="paragraph">이 문서는 다음 사용자를 대상으로 합니다.</block>
  <block id="ebb25f3a3991f2ad744d7ec643c950fe" category="list-text">에지의 AI를 제품화하려는 비즈니스 리더 및 엔터프라이즈 설계자</block>
  <block id="c19c4b63370004c67b540d52ae4d0ba3" category="list-text">데이터 과학자, 데이터 엔지니어, AI/기계 학습(ML) 연구원 및 AI 시스템 개발자.</block>
  <block id="d64b2d5963d22d2d9c15222cbbe4a41c" category="list-text">AI/ML 모델 및 애플리케이션 개발을 위한 솔루션을 설계하는 엔터프라이즈 설계자</block>
  <block id="563f47ae807a7a985313a5186e239a5d" category="list-text">딥 러닝(DL) 및 ML 모델을 구축하는 효율적인 방법을 찾고 있는 데이터 과학자 및 AI 엔지니어</block>
  <block id="c1df171c3c219ea01c2724d28fa03f93" category="list-text">에지 장치 관리자 및 에지 서버 관리자는 에지 추론 모델의 구축과 관리를 담당합니다.</block>
  <block id="a40893fa754ed62d5268702b023fea91" category="section-title">솔루션 아키텍처</block>
  <block id="cc402abc10a0191493024c4510783afc" category="paragraph">이 Lenovo ThinkSystem 서버 및 NetApp ONTAP 또는 NetApp SANtricity 스토리지 솔루션은 기존 CPU와 함께 GPU의 처리 능력을 사용하여 대규모 데이터 세트에서 AI 추론을 처리하도록 설계되었습니다. 이 검증 방식은 다음 두 그림에 표시된 대로 단일 NetApp AFF 스토리지 시스템과 상호 연결된 단일 또는 다중 Lenovo SR350 에지 서버를 사용하는 아키텍처로 고성능 및 최적의 데이터 관리를 수행하는 것입니다.</block>
  <block id="5174c42549c4dd0407a40298a4d9e362" category="paragraph"><block ref="5174c42549c4dd0407a40298a4d9e362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aacb24ff7918ccc37aea66f8c9548b68" category="paragraph"><block ref="aacb24ff7918ccc37aea66f8c9548b68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fa68c0f0557e1b1d9b151c9be9aae26a" category="paragraph">다음 그림의 논리적 아키텍처 개요에서는 이 아키텍처의 컴퓨팅 및 스토리지 요소 역할을 보여 줍니다. 특히 다음과 같은 사항이 표시됩니다.</block>
  <block id="f2e5640bc98f623bd0a257e3088ead2c" category="list-text">에지 컴퓨팅 장치가 카메라, 센서 등의 데이터를 기반으로 추론을 수행합니다.</block>
  <block id="ba8dee772ce5a627767af000b8bbb826" category="list-text">다양한 용도로 사용되는 공유 스토리지 요소:</block>
  <block id="8a1d15a179258733a83884fac2d16e38" category="list-text">추론 모델과 추론을 수행하는 데 필요한 다른 데이터를 위한 중심 위치를 제공합니다. 컴퓨팅 서버는 스토리지를 직접 액세스하고 로컬에서 복사할 필요 없이 네트워크 전체에서 추론 모델을 사용합니다.</block>
  <block id="6c20432374a9a40cfb818250edf55367" category="list-text">업데이트된 모델이 여기에 푸시됩니다.</block>
  <block id="4a32229da6d6fceda48d909ad92a952a" category="list-text">에지 서버가 나중에 분석할 수 있도록 수신하는 입력 데이터를 보관합니다. 예를 들어, 에지 장치가 카메라에 연결된 경우 저장소 요소는 카메라에서 캡처한 비디오를 유지합니다.</block>
  <block id="45d9a14c8d568ce70d22acbde8373657" category="paragraph"><block ref="45d9a14c8d568ce70d22acbde8373657" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bda9643ac6601722a28f238714274da4" category="cell">빨간색</block>
  <block id="48d6215903dff56238e52e8891380c8f" category="cell">파란색</block>
  <block id="95e6ac9e87f07caf580a7b83adb1526b" category="cell">Lenovo 컴퓨팅 시스템</block>
  <block id="81a15d59c420e43b55830213cc8c16b9" category="cell">NetApp AFF 스토리지 시스템</block>
  <block id="f46e4977aa2e9918471e011cafc5cbe1" category="cell">카메라, 센서 등의 입력에서 추론을 수행하는 에지 장치</block>
  <block id="edb1af4b83edf30ec5e56e3f4a6352f3" category="cell">추측 모델과 에지 디바이스의 데이터를 저장하는 공유 스토리지로, 추후 분석 지원</block>
  <block id="6fa1f5494d341a20c6c746a33cbb31b3" category="paragraph">이 NetApp 및 Lenovo 솔루션은 다음과 같은 주요 이점을 제공합니다.</block>
  <block id="f1bd3fc2711f634964362fb2a96445bf" category="list-text">소규모 지사 또는 부서에서의 GPU 가속 컴퓨팅.</block>
  <block id="a644cc245485a603217667e7cbdb7ef9" category="list-text">공유 스토리지에서 백업 및 관리되는 다중 에지 서버 배포</block>
  <block id="d649f2b00c65fe4953b1a7e7469c9431" category="list-text">데이터 손실 없이 낮은 RPO(복구 시점 목표) 및 RTO(복구 시간 목표)를 충족하는 강력한 데이터 보호</block>
  <block id="2d0fcf5abf2f152f10ecfbf80a62e9db" category="list-text">NetApp Snapshot 복사본 및 클론을 통해 데이터 관리를 최적화하여 개발 워크플로우를 간소화합니다.</block>
  <block id="94d9a1cd726b8a3fed2b6beb07904959" category="section-title">이 아키텍처를 사용하는 방법</block>
  <block id="9a22eb3c4ef782aa04a39e5ad3ffc8b5" category="paragraph">이 문서에서는 제안된 아키텍처의 설계 및 성능을 검증합니다. 하지만 NetApp은 특정 소프트웨어 수준의 컨테이너, 워크로드, 모델 관리, 클라우드 또는 온프레미스의 데이터 센터 등과 같은 특정 소프트웨어 레벨 구성 요소를 테스트하지 않았습니다. 이러한 소프트웨어 레벨 구성 요소가 배포 시나리오에 한정되어 있기 때문입니다. 여기에는 여러 개의 선택 사항이 있습니다.</block>
  <block id="080e5221e660ab18a3746fe480956ebc" category="paragraph">컨테이너 관리 수준에서 Kubernetes 컨테이너 관리는 좋은 선택이며 전체 업스트림 버전(Canonical) 또는 엔터프라이즈 배포에 적합한 수정 버전(Red Hat)에서 지원됩니다. 를 클릭합니다 <block ref="8ff9014ec7345470e1bb9286d28496e4" category="inline-link-macro-rx"></block> NetApp Trident 및 새로 추가된 Trident를 사용합니다<block ref="18f9f1b3975974bec435249b1752c2d6" category="inline-link-rx"></block> 데이터 과학자 및 데이터 엔지니어가 NetApp 스토리지와 통합할 수 있도록 추적 가능성, 데이터 관리 기능, 인터페이스 및 툴을 기본으로 제공합니다. Kubernetes용 ML 툴킷인 Kubeflow는 추가 AI 기능을 제공하는 동시에 TensorFlow Serving 또는 NVIDIA Triton Inference Server와 같은 여러 플랫폼에서 모델 버전 관리 및 KFServing을 지원합니다. 또 다른 옵션은 NVIDIA EGX 플랫폼으로, GPU 지원 AI 추론 컨테이너 카탈로그에 액세스하여 워크로드 관리를 제공합니다. 그러나 이러한 옵션을 사용하려면 운영 환경에 투입하기 위해 상당한 노력과 전문 지식이 필요할 수 있으며 타사 ISV(독립 소프트웨어 공급업체) 또는 컨설턴트의 도움이 필요할 수 있습니다.</block>
  <block id="1a667cf8dc2ace931f29baf9aeed69d9" category="section-title">솔루션 영역</block>
  <block id="560d585bccd63f1ccf34b07b325adbcd" category="paragraph">AI 추론 및 에지 컴퓨팅의 주요 이점은 지연 시간 없이 높은 수준의 품질로 데이터를 컴퓨팅, 처리 및 분석할 수 있는 장치의 기능입니다. 이 문서에서 설명하는 에지 컴퓨팅 사용 사례는 매우 많지만 다음과 같은 몇 가지 대표적인 사례가 있습니다.</block>
  <block id="8106f228c3a2b774c2e47d0d2ca766eb" category="section-title">자동차: 자율주행 차량</block>
  <block id="49f3cb6fe79fc77d0b151dcc2f7d7109" category="paragraph">전형적인 에지 컴퓨팅 일러스트는 자율주행 차량(AV)의 첨단 운전자 지원 시스템(ADAS)에 포함되어 있습니다. 무인 자동차의 AI는 안전하고 성공적인 운전자가 되려면 카메라와 센서의 많은 데이터를 신속하게 처리해야 합니다. 물체와 사람 사이의 해석에 너무 많은 시간이 걸릴경우 생명 또는 사망이 발생할 수 있으므로 데이터를 최대한 차량과 가깝게 처리할 수 있어야 합니다. 이 경우 하나 이상의 에지 컴퓨팅 서버가 카메라, 레이더, LiDAR 및 기타 센서의 입력을 처리하는 동시에 공유 스토리지에는 추론 모델이 저장되고 센서의 입력 데이터가 저장됩니다.</block>
  <block id="e5e51dcd521792cb797e6e3c53736987" category="section-title">의료: 환자 모니터링</block>
  <block id="a5031cd8ea18cb91370c532194ecd58e" category="paragraph">AI 및 에지 컴퓨팅이 미치는 가장 큰 영향 중 하나는 가정 및 중환자실(ICU) 모두에서 만성 질환 환자를 지속적으로 모니터링할 수 있는 기능입니다. 인슐린 수치, 호흡, 신경학적 활동, 심장 리듬 및 위장관 기능을 모니터링하는 에지 장치에서 얻은 데이터는 다른 사람의 생명을 구하기 위한 제한된 시간이 있기 때문에 즉시 실행되어야 하는 데이터에 대한 즉각적인 분석이 필요합니다.</block>
  <block id="7e4b8a4224f71143d7bd188ceeea4acd" category="section-title">소매: 계산원 없는 지불</block>
  <block id="a8712e81fee7af830aa2cd6466cfb339" category="paragraph">에지 컴퓨팅은 유통업체가 계산 시간을 단축하고 발트 트래픽을 늘릴 수 있도록 AI 및 ML을 지원합니다. 계산원이 필요 없는 시스템은 다음과 같은 다양한 구성 요소를 지원합니다.</block>
  <block id="dbc0817910529140e6894b79ec51b412" category="list-text">인증 및 액세스. 물리적 쇼핑객을 검증된 계정에 연결하고 소매 공간에 대한 액세스를 허용합니다.</block>
  <block id="349a2650c71706ec201ef08d57dc58e7" category="list-text">인벤토리 모니터링. 센서, RFID 태그 및 컴퓨터 비전 시스템을 사용하여 쇼핑객의 아이템 선택 또는 선택 취소를 확인할 수 있습니다.</block>
  <block id="86f5df5b4d7496a74d1d41bed2929983" category="paragraph">여기서 각 에지 서버는 각 계산 카운터를 처리하며 공유 스토리지 시스템은 중앙 동기화 지점으로 사용됩니다.</block>
  <block id="498375fc1d2fd41616385f8abfd37893" category="section-title">금융 서비스: 키오스크의 인적 안전 및 사기 방지</block>
  <block id="1dd0f8c70693faa846f69d76af9ffbf7" category="paragraph">은행 조직에서는 AI 및 에지 컴퓨팅을 사용하여 혁신을 진행하고 맞춤형 뱅킹 경험을 만들고 있습니다. 실시간 데이터 분석 및 AI 추론을 사용하는 대화형 키오스크는 이제 ATM을 통해 고객이 돈을 인출할 수 있도록 지원할 뿐만 아니라 카메라에서 캡처한 이미지를 통해 키오스크를 사전 예방적으로 모니터링하여 사람의 안전 또는 사기 행위 위험을 식별할 수 있습니다. 이 시나리오에서는 에지 컴퓨팅 서버 및 공유 스토리지 시스템이 대화형 키오스크 및 카메라에 연결되어 은행이 AI 추론 모델로 데이터를 수집하고 처리할 수 있도록 도와줍니다.</block>
  <block id="0014200d8a9f4fe7a8b65ae923557be6" category="section-title">제조: Industry 4.0</block>
  <block id="18bfb27ab22a9db6eb932a3bfe5f51a4" category="paragraph">4차 산업혁명(Industry 4.0)은 Smart Factory 및 3D 프린팅과 같은 새로운 트렌드와 함께 시작되었습니다. 데이터 중심의 미래에 대비하기 위해 대규모 M2M(Machine-to-Machine) 통신 및 IoT가 통합되어 사람의 개입 없이 자동화 수준을 높일 수 있습니다. 제조는 이미 고도로 자동화되어 있으며 AI 기능을 추가하는 것은 장기적인 추세를 자연스럽게 이어주는 것입니다. AI를 사용하면 컴퓨터 비전 및 기타 AI 기능을 활용하여 자동화할 수 있는 운영을 자동화할 수 있습니다. 제조 공장이 안전 및 품질 관리에 필요한 ISO 표준을 충족할 수 있도록 제조 공장의 조립 라인에서 자재를 더 빠르게 분석하는 데 있어 인간의 시각이나 의사 결정에 의존하는 품질 관리 또는 작업을 자동화할 수 있습니다. 여기서 각 컴퓨팅 에지 서버는 제조 프로세스를 모니터링하는 센서 배열에 연결되고 필요에 따라 업데이트된 추론 모델이 공유 스토리지로 푸시됩니다.</block>
  <block id="a2df8c6c694bb6d9b42851d95a6d7814" category="section-title">통신: Rust 감지, 타워 검사 및 네트워크 최적화</block>
  <block id="d562d0e475687af21d44b6ea803c10a8" category="paragraph">통신 업계에서는 컴퓨터 비전과 AI 기술을 사용하여 녹을 자동으로 탐지하고 부식된 셀 타워를 식별하는 이미지를 처리하여 추가적인 검사가 필요합니다. 드론 이미지와 AI 모델을 사용하여 타워의 특정 영역을 식별하고 녹, 표면 균열 및 부식을 분석하는 일이 최근 몇 년 사이에 증가했습니다. 통신 인프라와 셀 타워를 효율적으로 검사하고, 정기적으로 성능 저하를 평가하며, 필요할 때 신속하게 수리할 수 있는 AI 기술에 대한 수요가 지속적으로 증가하고 있습니다.</block>
  <block id="50dba7db75064ae2e0beea487226ed46" category="paragraph">또한, 데이터 트래픽 패턴을 예측하고 5G 지원 장치를 감지하고 MIMO(다중 입력 및 다중 출력) 에너지 관리를 자동화 및 보강하기 위해 AI 및 ML 알고리즘을 사용하는 것도 통신 업계의 새로운 사용 사례입니다. MIMO 하드웨어는 무선 타워에서 네트워크 용량을 늘리기 위해 사용되지만, 추가 에너지 비용이 필요합니다. 셀 사이트에 배치된 “MIMO 절전 모드”용 ML 모델은 무전기의 효율적인 사용을 예측하고 모바일 네트워크 사업자(MNO)의 에너지 소비 비용을 줄이는 데 도움이 됩니다. AI 추론 및 에지 컴퓨팅 솔루션은 MNO가 데이터 센터로 주고받는 데이터 양을 줄이고, TCO를 낮추고, 네트워크 운영을 최적화하고, 최종 사용자의 전반적인 성능을 개선하는 데 도움이 됩니다.</block>
  <block id="f45c430b02aac052aef8d958c80ff351" category="paragraph"><block ref="f45c430b02aac052aef8d958c80ff351" category="inline-link-macro-rx"></block></block>
  <block id="10dedd24e41d2fa9b5a5e681dd5b4882" category="summary">이 페이지에는 컨테이너, Kubernetes, NetApp Trident 등에 대한 정보를 비롯하여 NetApp이 AI 프로젝트를 진행하는 방법을 이해할 수 있는 배경이 포함되어 있습니다.</block>
  <block id="5cd2adc9e2a5254e4c1da803519f298b" category="section-title">인공 지능</block>
  <block id="c2fabc0982aa161064ff2b73f50800d5" category="paragraph">AI는 컴퓨터가 인간의 마음의 인지 기능을 모방하도록 훈련되는 컴퓨터 과학 분야입니다. AI 개발자는 컴퓨터를 교육하여 사람과 유사하거나 훨씬 뛰어난 방식으로 문제를 배우고 해결합니다. 딥 러닝 및 머신 러닝은 AI의 하위 필드입니다. 조직은 중요한 비즈니스 요구사항을 지원하기 위해 AI, ML 및 DL을 점점 더 채택하고 있습니다. 몇 가지 예는 다음과 같습니다.</block>
  <block id="b3e764d3292b880c63140b20b9a90e6c" category="list-text">방대한 양의 데이터를 분석하여 이전에 알려지지 않은 비즈니스 인사이트를 도출합니다</block>
  <block id="30512c04b26c269ec31ecd09f1f3a208" category="list-text">자연어 처리를 사용하여 고객과 직접 상호 작용</block>
  <block id="4ee20869dbb821d3744d87176797401f" category="list-text">다양한 비즈니스 프로세스 및 기능 자동화</block>
  <block id="5919922c658bd2a4f33f0cf546be3ea9" category="paragraph">최신 AI 훈련 및 추론 워크로드에는 대규모 병렬 컴퓨팅 기능이 필요합니다. 따라서 GPU의 병렬 처리 기능이 범용 CPU보다 훨씬 뛰어나기 때문에 AI 작업을 실행하는 데 GPU가 점점 더 많이 사용되고 있습니다.</block>
  <block id="2154bae452b2343b649ee4b088b399f6" category="paragraph">컨테이너는 공유 호스트 운영 체제 커널 위에서 실행되는 격리된 사용자 공간 인스턴스입니다. 컨테이너 채택이 빠르게 증가하고 있습니다. 컨테이너는 가상 머신(VM)이 제공하는 것과 동일한 애플리케이션 샌드박스(sandbox)의 많은 이점을 제공합니다. 하지만 VM이 사용하는 하이퍼바이저 및 게스트 운영 체제 계층이 없어졌기 때문에 컨테이너는 훨씬 더 가볍습니다. 다음 그림에서는 가상 시스템과 컨테이너를 보여 줍니다.</block>
  <block id="da28cd415837c7f3d1d6221ff490b84b" category="paragraph">또한 컨테이너를 사용하면 애플리케이션 종속성, 실행 시간 등을 애플리케이션과 직접 효율적으로 패키징할 수 있습니다. 가장 일반적으로 사용되는 컨테이너 패키징 형식은 Docker 컨테이너입니다. Docker 컨테이너 형식으로 컨테이너화된 애플리케이션은 Docker 컨테이너를 실행할 수 있는 모든 시스템에서 실행할 수 있습니다. 모든 종속성이 컨테이너 자체에 패키지되어 있기 때문에 응용 프로그램의 종속성이 컴퓨터에 없는 경우에도 마찬가지입니다. 자세한 내용은 를 참조하십시오<block ref="f3aa778c455b7c9002cc51cdc41e7924" category="inline-link-rx"></block>.</block>
  <block id="9c3d617029ed075512781527983e01e4" category="paragraph"><block ref="9c3d617029ed075512781527983e01e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a1446916a360f9c8ae3b94a97ad8c86" category="paragraph">Kubernetes는 Google에서 원래 설계한 개방형 소스, 분산형 컨테이너 오케스트레이션 플랫폼으로, 현재 CNCF(Cloud Native Computing Foundation)에서 관리하고 있습니다. Kubernetes는 컨테이너화된 애플리케이션의 구축, 관리, 확장 기능을 자동화할 수 있습니다. 최근 몇 년 동안 Kubernetes는 주요 컨테이너 오케스트레이션 플랫폼으로 부상했습니다. 다른 컨테이너 패키징 형식과 실행 시간이 지원되지만 Kubernetes는 Docker 컨테이너용 오케스트레이션 시스템으로 가장 많이 사용됩니다. 자세한 내용은 를 참조하십시오<block ref="b99a36b6d7a8af9ad1172136115f0275" category="inline-link-rx"></block>.</block>
  <block id="f9b736ec48694a34e744a1a0309602bd" category="paragraph">Trident는 NetApp에서 개발 및 유지 관리하는 오픈 소스 스토리지 오케스트레이터로서 Kubernetes 워크로드를 위한 영구 스토리지의 생성, 관리 및 사용을 크게 단순화합니다. Kubernetes 네이티브 애플리케이션인 Trident는 Kubernetes 클러스터 내에서 직접 실행됩니다. Trident를 사용하면 Kubernetes 사용자(개발자, 데이터 과학자, Kubernetes 관리자 등)가 이미 익숙한 표준 Kubernetes 형식으로 영구 스토리지 볼륨을 생성, 관리 및 상호 작용할 수 있습니다. 이와 동시에 NetApp 기술에서 제공하는 NetApp 고급 데이터 관리 기능과 Data Fabric을 활용할 수 있습니다. Trident는 영구 스토리지의 복잡성을 추상화하여 사용이 간편합니다. 자세한 내용은 를 참조하십시오<block ref="ad5406ed69f3fe0de810f757310402c9" category="inline-link-rx"></block>.</block>
  <block id="173c35c4ef789d6956a0cd6fbd9a0cfc" category="inline-link">Kubeflow 웹 사이트</block>
  <block id="ea77b50ef31a778a66411b993d6cb7d1" category="paragraph">Kubeflow는 Google에서 원래 개발한 Kubernetes용 오픈 소스 AI 및 ML 툴킷입니다. Kubeflow 프로젝트를 통해 Kubernetes에서 AI 및 ML 워크플로우를 간단하게 배포, 이식 및 확장할 수 있습니다. Kubeflow는 복잡한 Kubernetes를 추상화하여 데이터 과학자가 자신이 가장 잘 알고 있는 데이터 과학에 집중할 수 있도록 지원합니다. 시각화는 다음 그림을 참조하십시오. 쿠버플로는 엔터프라이즈 IT 부서가 Kubernetes에서 점점 더 표준화되고 있으므로 상당한 주목을 받고 있습니다. 자세한 내용은 를 참조하십시오<block ref="bbfd4ba68f44e2ff98f04ea32205485d" category="inline-link-rx"></block>.</block>
  <block id="a2b0a43dcae6386929654b652393e691" category="paragraph"><block ref="a2b0a43dcae6386929654b652393e691" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e569c07c88fe6f8af1f63410c200abd1" category="section-title">Kubeflow 파이프라인</block>
  <block id="384873a621d99250018cd7ce1768f8af" category="paragraph">Kubeflow 파이프라인은 Kubeflow의 핵심 구성 요소입니다. Kubeflow 파이프라인은 이식 가능하고 확장 가능한 AI 및 ML 워크플로우를 정의하고 배포하기 위한 플랫폼 및 표준입니다. 자세한 내용은 를 참조하십시오<block ref="6de5a235a0c43df48d05588e1b69b959" category="inline-link-rx"></block>.</block>
  <block id="a0b0430a41f582a12dac8f4d63ab450d" category="inline-link">Jupyter 웹 사이트</block>
  <block id="3cecf3b7bbdb1a67a537c65bfd6fd529" category="paragraph">Jupyter Notebook Server는 데이터 과학자가 실시간 코드와 설명이 포함된 Jupyter Notebooks라는 위키 형식의 문서를 만들 수 있는 오픈 소스 웹 애플리케이션입니다. Jupyter Notebooks는 AI 및 ML 프로젝트를 문서화, 저장, 공유하는 수단으로 AI 및 ML 커뮤니티에서 널리 사용되고 있습니다. Kubeflow는 Kubernetes에서 Jupyter Notebook Server의 프로비저닝 및 구축을 단순화합니다. Jupyter Notebooks에 대한 자세한 내용은 를 참조하십시오<block ref="412a2c3f2a7af96a2a4f6a512ee2088e" category="inline-link-rx"></block>. Kubeflow와 관련하여 Jupyter Notebooks에 대한 자세한 내용은 를 참조하십시오<block ref="c5d2218884acd101e6deb4d8c7d39370" category="inline-link-rx"></block>.</block>
  <block id="c01fb6f699235f8c5d36bdda9e155c77" category="paragraph">Apache Airflow는 복잡한 엔터프라이즈 워크플로우를 프로그래밍 방식으로 작성, 스케줄링 및 모니터링할 수 있는 오픈 소스 워크플로우 관리 플랫폼입니다. ETL 및 데이터 파이프라인 워크플로우를 자동화하는 데 주로 사용되지만, 이러한 유형의 워크플로우에만 국한되지 않습니다. Airbnb가 공기 흐름 프로젝트를 시작했지만 그 이후 업계에서 매우 인기를 끌며 현재는 Apache Software Foundation의 후원으로 자리 잡았습니다. Python으로 공기 흐름을 작성하고 Python 스크립트를 통해 공기 흐름을 생성하고 "코드로 구성"이라는 원칙에 따라 공기 흐름을 설계할 수 있습니다. 많은 엔터프라이즈 공기 흐름 사용자가 이제 Kubernetes에서 공기 흐름을 실행합니다.</block>
  <block id="8fb4a72500791f0bea82c5c9b4c33772" category="section-title">유도된 DAG(Acclic Graphs)</block>
  <block id="afd712bbacf94fbaf2852bd23c6b1a84" category="paragraph">공기 흐름에서 워크플로우는 DAG(Directed Acyclic Graphs)라고 합니다. DAG는 DAG 정의에 따라 순차적으로, 병렬로 또는 둘의 조합으로 실행되는 작업으로 구성됩니다. 공기 흐름 스케줄러는 DAG 정의에 지정된 작업 수준 종속성을 준수하여 일련의 작업자에 대해 개별 작업을 실행합니다. DAG는 Python 스크립트를 통해 정의 및 생성됩니다.</block>
  <block id="0b83cba78e13ee67f3ada794b1e8edb8" category="paragraph">NetApp ONTAP 9은 NetApp의 최신 세대 스토리지 관리 소프트웨어로, 이 소프트웨어를 사용하여 귀사와 같은 기업에서 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다. 업계 최고의 데이터 관리 기능을 갖춘 ONTAP은 데이터의 위치와 상관없이 단일 툴셋으로 데이터를 관리하고 보호할 수 있도록 지원합니다. 필요에 따라 에지, 코어, 클라우드 등 어느 위치로도 데이터를 자유롭게 이동할 수 있습니다. ONTAP 9에는 데이터 관리를 단순화하고, 중요 데이터를 더 빨리 처리하고 보호하는 다수의 기능이 포함되어 있으므로 하이브리드 클라우드 아키텍처 전체에 미래 지향형 인프라를 제공합니다.</block>
  <block id="849f9e6e3176f7bb2abaf1dfdda6f4de" category="section-title">데이터 관리 단순화</block>
  <block id="5d0a72b50313f5f3615263a7d19ee676" category="paragraph">애플리케이션 및 데이터 세트에 적절한 리소스를 사용할 수 있도록 데이터 관리는 엔터프라이즈 IT 운영에 매우 중요합니다. ONTAP에는 운영을 간소화 및 단순화하고 총 운영 비용을 절감할 수 있는 다음과 같은 기능이 포함되어 있습니다.</block>
  <block id="30490e1b1bd18c329c3b28df91914ffe" category="list-text">* 인라인 데이터 컴팩션 및 확대된 중복제거. * 데이터 컴팩션은 스토리지 블록 내부의 낭비되는 공간을 줄이고, 중복제거는 실제 용량을 크게 증가시킵니다.</block>
  <block id="c5b25bb449b07e8b863f41dbe3b90a2a" category="list-text">* 최소, 최대 및 적응형 서비스 품질(QoS). * 세분화된 QoS 제어로 고도의 공유 환경에서 중요 애플리케이션의 성능 수준을 유지할 수 있습니다.</block>
  <block id="d9a5709ce7afa0856dd86539f75c8087" category="list-text">* ONTAP FabricPool. * 이 기능은 콜드 데이터를 AWS(Amazon Web Services), Azure, NetApp StorageGRID 오브젝트 기반 스토리지와 같은 퍼블릭 및 프라이빗 클라우드 스토리지 옵션으로 자동 계층화합니다.</block>
  <block id="ddb2f8d78c57d5743fdee9e17ae053c9" category="section-title">데이터 가속화 및 보호</block>
  <block id="4994fe58be1734616de0863809040200" category="paragraph">ONTAP는 탁월한 수준의 성능과 데이터 보호를 제공하며 다음과 같은 기능으로 이러한 기능을 확장합니다.</block>
  <block id="b109ecc7b4570bf3dbb9f8d082595075" category="list-text">* 고성능 및 낮은 지연 시간 * ONTAP는 가장 짧은 지연 시간으로 가장 높은 처리량을 제공합니다.</block>
  <block id="9e184f7b8847a390232c0163d45ab461" category="list-text">* NetApp ONTAP FlexGroup 기술. * FlexGroup 볼륨은 최대 20PB 및 4천억 개 파일까지 선형적으로 확장할 수 있는 고성능 데이터 컨테이너로, 단일 네임스페이스를 제공하여 데이터 관리를 단순화합니다.</block>
  <block id="493a7caad772a79b06f5d4a7dd98afcd" category="list-text">* NetApp 볼륨 암호화. * ONTAP는 온보드 및 외부 키 관리를 모두 지원하는 기본 볼륨 레벨 암호화를 제공합니다.</block>
  <block id="0950833529b7822458a242631cce3b3b" category="section-title">미래 지향형 인프라</block>
  <block id="ba5b61620e18b71a8644dbc382c0c4f1" category="paragraph">ONTAP 9은 지속적으로 변화하는 까다로운 요구사항을 충족할 수 있도록 지원합니다.</block>
  <block id="d9d73747d25ab5e9c5de8f1f61c9ec7c" category="list-text">* 원활한 확장 및 무중단 운영 * ONTAP은 기존 컨트롤러 및 스케일아웃 클러스터에 무중단으로 용량을 추가할 수 있도록 지원합니다. 고비용이 따르는 데이터 마이그레이션이나 운영 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="512a65c054e8b5d06216e0eae55abedb" category="list-text">* 클라우드 연결. * ONTAP은 클라우드에 가장 많이 연결된 스토리지 관리 소프트웨어 중 하나로, 모든 퍼블릭 클라우드에서 소프트웨어 정의 스토리지(ONTAP Select) 및 클라우드 네이티브 인스턴스(NetApp Cloud Volumes Service) 옵션을 제공합니다.</block>
  <block id="5ca60f373401802dfa44501cfa4f5cc7" category="list-text">새로운 애플리케이션과의 통합 * 기존 엔터프라이즈 애플리케이션을 지원하는 인프라와 동일한 인프라를 사용하는 ONTAP는 OpenStack, Hadoop, MongoDB와 같은 차세대 플랫폼 및 애플리케이션을 위한 엔터프라이즈급 데이터 서비스를 제공합니다.</block>
  <block id="49a023178611b07475bac0823fc2dd53" category="section-title">NetApp Snapshot 복사본</block>
  <block id="42884680ea9780d61f4cce71fdc606b1" category="paragraph">NetApp 스냅샷 복사본은 볼륨의 읽기 전용 시점 이미지입니다. 다음 그림과 같이 이미지는 스토리지 공간을 최소한으로 사용하고, 마지막 스냅샷 복사본 생성 이후 생성된 파일의 변경사항만 기록하므로 경미한 성능 오버헤드를 발생시킵니다.</block>
  <block id="13455e6dd452fcc850acd6696e670600" category="paragraph">스냅샷 복사본은 핵심 ONTAP 스토리지 가상화 기술인 WAFL(Write Anywhere File Layout)의 효율성을 높여줍니다. 데이터베이스와 마찬가지로 WAFL는 메타데이터를 사용하여 디스크의 실제 데이터 블록을 가리킵니다. 하지만 WAFL은 데이터베이스와 달리 기존 블록을 덮어쓰지 않습니다. 업데이트된 데이터를 새 블록에 쓰고 메타데이터를 변경합니다. ONTAP은 데이터 블록을 복사하는 대신 스냅샷 복사본을 생성할 때 메타데이터를 참조하므로 스냅샷 복사본이 매우 효율적입니다. 이렇게 하면 복사할 블록을 찾는 데 다른 시스템이 발생하는 탐색 시간과 복사본 자체를 만드는 비용이 제거됩니다.</block>
  <block id="921d0d1d37872e6233bf4da3688b03ef" category="paragraph">스냅샷 복사본을 사용하여 개별 파일 또는 LUN을 복구하거나 볼륨의 전체 콘텐츠를 복원할 수 있습니다. ONTAP은 스냅샷 복사본의 포인터 정보를 디스크의 데이터와 비교하여 다운타임 또는 상당한 성능 비용 없이 누락 또는 손상된 개체를 재구성합니다.</block>
  <block id="9787a3a5983c64cfaf3029a721aab4f0" category="paragraph"><block ref="9787a3a5983c64cfaf3029a721aab4f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76a33b697177fedefd70387e86214ebd" category="section-title">NetApp FlexClone 기술</block>
  <block id="78e8cd917c99154d22a94ba80186ac33" category="paragraph">NetApp FlexClone 기술은 Snapshot 메타데이터를 참조하여 볼륨의 쓰기 가능한 특정 시점 복사본을 생성합니다. 복사본은 다음 그림과 같이 복사본에 변경 사항이 기록될 때까지 메타데이터에 필요한 사항을 제외하고 데이터 블록을 부모와 공유하고 스토리지를 사용하지 않습니다. FlexClone 소프트웨어를 사용하면 기존 복사본을 생성하는 데 몇 분 또는 몇 시간이 걸릴 수 있으며 최대 규모의 데이터 세트도 거의 즉시 복사할 수 있습니다. 따라서 동일한 데이터 세트의 여러 복사본(예: 개발 작업 공간)이 필요하거나 데이터 세트의 임시 복사본(운영 데이터 세트에 대해 애플리케이션 테스트)이 필요한 경우에 적합합니다.</block>
  <block id="423c2edb645c178257ba9d79bd9ac684" category="paragraph"><block ref="423c2edb645c178257ba9d79bd9ac684" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f67824f4f94415299484432a092f76b1" category="section-title">NetApp SnapMirror 데이터 복제 기술</block>
  <block id="553416a55e03cc49df61e631d17b8011" category="paragraph">NetApp SnapMirror 소프트웨어는 Data Fabric에서 사용하기 쉬운 비용 효율적인 통합 복제 솔루션입니다. LAN 또는 WAN을 통해 데이터를 고속으로 복제합니다. 가상 환경과 기존 환경 모두에서 비즈니스 크리티컬 애플리케이션을 포함한 모든 유형의 애플리케이션에 대해 높은 데이터 가용성과 빠른 데이터 복제를 제공합니다. 하나 이상의 NetApp 스토리지 시스템에 데이터를 복제하고 2차 데이터를 지속적으로 업데이트함으로써 데이터가 최신 상태로 유지되고 필요할 때마다 사용할 수 있으며 외부 복제 서버가 필요하지 않습니다. 다음 그림은 SnapMirror 기술을 활용하는 아키텍처의 예입니다.</block>
  <block id="5a12ba5d186c9ffcce65438f531e7c47" category="paragraph">SnapMirror 소프트웨어는 변경된 블록만 네트워크를 통해 전송함으로서 NetApp ONTAP 스토리지 효율성을 활용합니다. SnapMirror 소프트웨어는 또한 내장된 네트워크 압축 기능을 사용하여 데이터 전송을 더 신속하게 수행하고 네트워크 대역폭 활용률을 70%까지 줄입니다. SnapMirror 기술을 사용하면 하나의 씬 복제 데이터 스트림을 활용하여 활성 미러와 이전 시점의 복사본을 둘 다 유지 관리하는 단일 저장소를 만들 수 있으므로 네트워크 트래픽이 최대 50% 감소합니다.</block>
  <block id="423eee692f81241addaf586841d0c66a" category="paragraph"><block ref="423eee692f81241addaf586841d0c66a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2e386ef1ace3f8ea71edbaa6f9cbbd00" category="paragraph">Cloud Sync는 빠르고 안전한 데이터 동기화를 제공하는 NetApp 서비스입니다. 사내 NFS 또는 SMB 파일 공유 간에 파일을 전송해야 하는 경우, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, AWS S3, AWS EFS, Azure Blob, Google 클라우드 스토리지 또는 IBM 클라우드 오브젝트 스토리지인 Cloud Sync는 필요한 파일을 빠르고 안전하게 이동시킵니다.</block>
  <block id="c1bea6c8c836c6911127e6fe3fde762a" category="paragraph">데이터가 전송되면 소스와 타겟 모두에서 사용할 수 있습니다. Cloud Sync는 사전 정의된 일정에 따라 업데이트가 트리거되거나 지속적으로 데이터가 동기화될 때 필요 시 데이터를 동기화할 수 있습니다. Cloud Sync는 델타만 이동하므로 데이터 복제에 소비되는 시간과 비용이 최소화됩니다.</block>
  <block id="18c24ab391d7e12f4abcfea370fb4e81" category="paragraph">Cloud Sync는 매우 간편한 설정 및 사용이 가능한 SaaS(Software as a Service) 툴입니다. Cloud Sync에 의해 트리거되는 데이터 전송은 데이터 브로커가 수행합니다. Cloud Sync 데이터 브로커는 AWS, Azure, Google Cloud Platform 또는 온프레미스에 구축할 수 있습니다.</block>
  <block id="6efa8f47d1a76af77ce311b436e4dca9" category="section-title">NetApp XCP</block>
  <block id="0e4fcaf78d0d4feda27a31ecb6944b58" category="paragraph">NetApp XCP는 모든 NetApp 및 NetApp 간 데이터 마이그레이션 및 파일 시스템 통찰력을 위한 클라이언트 기반 소프트웨어입니다. xCP는 사용 가능한 모든 시스템 리소스를 활용하여 대용량 데이터 세트 및 고성능 마이그레이션을 처리함으로써 최대한의 성능을 발휘하도록 설계되었습니다. xCP를 사용하면 보고서를 생성하는 옵션을 통해 파일 시스템에 대한 완벽한 가시성을 확보할 수 있습니다.</block>
  <block id="9a3914e340e4b09762f8231f9fd0ddaa" category="paragraph">NetApp XCP는 NFS 및 SMB 프로토콜을 지원하는 단일 패키지로 제공됩니다. xCP에는 NFS 데이터 세트용 Linux 바이너리와 SMB 데이터 세트용 Windows 실행 파일이 포함되어 있습니다.</block>
  <block id="adc911d4d2f4e0008e765523cff39824" category="paragraph">NetApp XCP File Analytics는 파일 공유를 감지하고 파일 시스템에서 스캔을 실행하며 파일 분석을 위한 대시보드를 제공하는 호스트 기반 소프트웨어입니다. XCP File Analytics는 NetApp 및 타사 시스템과 모두 호환되며 Linux 또는 Windows 호스트에서 실행되어 NFS 및 SMB에서 내보낸 파일 시스템에 대한 분석 기능을 제공합니다.</block>
  <block id="957e30f73566564bd8a99a6fac13e015" category="section-title">NetApp ONTAP FlexGroup 볼륨</block>
  <block id="22bd32dacc144ffc2601e6685260b4c3" category="paragraph">교육 데이터 세트는 잠재적으로 수십억 개의 파일로 구성됩니다. 파일에는 텍스트, 오디오, 비디오 및 기타 형식의 비정형 데이터가 포함될 수 있으며, 이 데이터를 병렬로 읽고 저장해야 합니다. 스토리지 시스템은 수많은 작은 파일을 저장해야 하며 순차적 I/O 및 랜덤 I/O를 위해 병렬로 이들 파일을 읽어야 합니다</block>
  <block id="6d7d8c1311f5ac7d2ed289e012822f78" category="paragraph">FlexGroup 볼륨은 다음 그림과 같이 여러 개의 구성 멤버 볼륨으로 구성된 단일 네임스페이스입니다. 스토리지 관리자 관점에서 FlexGroup 볼륨은 NetApp FlexVol 볼륨과 마찬가지로 관리되고 작동합니다. FlexGroup 볼륨의 파일은 개별 구성원 볼륨에 할당되며 볼륨 또는 노드에 스트라이핑되지 않습니다. 다음과 같은 기능을 지원합니다.</block>
  <block id="28f25e3d6de5d5fe801c8d194234f0a5" category="list-text">FlexGroup 볼륨은 메타데이터가 많은 워크로드에 수 페타바이트에 달하는 용량과 예측 가능한 짧은 지연 시간을 제공합니다.</block>
  <block id="82b42713e1be50bb140b7e85eecdd91f" category="list-text">동일한 네임스페이스에서 최대 4천억 개의 파일을 지원합니다.</block>
  <block id="50af21bd57d5360eb9ffc8dbc4b9a5bd" category="list-text">CPU, 노드, 애그리게이트, 구성 FlexVol 볼륨에서 NAS 워크로드에 병렬 작업을 지원합니다.</block>
  <block id="07e40bce6e02494c0af7b6a5f2aeaad8" category="paragraph"><block ref="07e40bce6e02494c0af7b6a5f2aeaad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96e1c56a273105095d8b5e23e670f72f" category="inline-link-macro">다음: 하드웨어 및 소프트웨어 요구 사항.</block>
  <block id="1c3ce2e5bdbf1449bbeba4ecbd124676" category="paragraph"><block ref="1c3ce2e5bdbf1449bbeba4ecbd124676" category="inline-link-macro-rx"></block></block>
  <block id="2625fb6375d503af481868caf90606c9" category="summary">이 섹션에서는 이 기술 보고서와 관련된 Jupyter 노트북 2개에 대한 링크를 제공합니다.</block>
  <block id="91409fc3ebd20becb4eb816cbcceb02e" category="doc">Jupyter 노트북을 참조하십시오</block>
  <block id="cdd5560e07964d04d88721f16446a3b6" category="paragraph">이 기술 보고서와 관련하여 2개의 Jupyter 노트북이 있습니다.</block>
  <block id="1490d9a5ddbc6bcbe6cedaa01eb50f99" category="inline-link-macro">* CTR-PandasRF-Collated.ipynb. *</block>
  <block id="562c7333f0fea5590cfeb818a55e6557" category="list-text"><block ref="6f686a9606ae64621340ea0a5e72dfde" category="inline-link-macro-rx"></block> 이 노트북은 Criteo Terabyte Click Logs 데이터 세트에서 15일을 로드하고 Pandas DataFrame으로 데이터를 처리 및 포맷하고 Scikit-Learn 무작위 포리스트 모델을 교육하며 예측을 수행하고 정확도를 계산합니다.</block>
  <block id="c0cb1f1199ae4e4bdfa626e26a5a25cd" category="inline-link-macro">criteo_dask_rf.ipynb. * 를 사용합니다</block>
  <block id="fa93cb17bf7778768ccae778487bf90d" category="list-text"><block ref="01d86d8522c2722466fcbda71181d3ff" category="inline-link-macro-rx"></block> 이 전자 필기장은 Criteo Terabyte Click Logs 데이터 집합에서 15일을 로드하고, 데이터를 처리하여 Dask cuDF로 서식을 지정하고, Dask cuML 임의 포리스트 모델을 교육하고, 예측을 수행하고, 정확도를 계산합니다. GPU에 여러 작업자 노드를 활용함으로써 이러한 분산 데이터 및 모델 처리 및 교육 접근 방식이 매우 효율적입니다. 처리하는 데이터가 많을수록 기존 ML 방식에 비해 시간 절감 효과가 더 커집니다. 네트워킹 설정을 통해 데이터 및 모델 배포를 자유롭게 이동할 수 있는 한, 이 메모장을 클라우드, 온프레미스 또는 Kubernetes 클러스터에 다른 위치의 컴퓨팅 및 스토리지가 포함된 하이브리드 환경에 배포할 수 있습니다.</block>
  <block id="321cf11d6ad313e01614cfa7817893fb" category="doc">Jarvis 배포</block>
  <block id="24a0684c018bf0ed5e7001773d8df2c5" category="inline-link">Jarvis Early Access 프로그램</block>
  <block id="55ce258288b89404cc493de8c839e20a" category="paragraph">에 등록할 수 있습니다<block ref="de4a7b23900edb1996cbcb27f4a65904" category="inline-link-rx"></block> NGC(NVIDIA GPU Cloud)에서 Jarvis 컨테이너에 액세스 NVIDIA로부터 자격 증명을 받은 후 다음 단계를 사용하여 Jarvis를 배포할 수 있습니다.</block>
  <block id="e5a6dabbbe3f9144d9f6e72b568893cd" category="list-text">NGC에 로그인합니다.</block>
  <block id="a668e3da095eca41ef93e0c494a6ebad" category="list-text">NGC를 통해 조직을 "ea-2-Jarvis"로 설정합니다.</block>
  <block id="f3b0315f8d213517a6076eb7aff49cb6" category="list-text">Jarvis EA v0.2 자산 찾기: Jarvis 컨테이너는 '개인 레지스트리'&gt;'조직 컨테이너'에 있습니다.</block>
  <block id="6db8e9899d42bcac6aeb824da5e952ef" category="list-text">자비스(Jarvis) 를 선택하고 모델 스크립트(Model Scripts) 로 이동한 다음 자비스 빠른 시작(Jarvis Quick Start) 을 클릭합니다</block>
  <block id="737af365257800065a6412e56d652acc" category="list-text">모든 자산이 제대로 작동하는지 확인합니다.</block>
  <block id="8a5fd124171d01a74b1af73e73ab7761" category="list-text">PDF는 모델 스크립트 &gt; Jarvis Documentation &gt; File Browser에서 찾을 수 있습니다.</block>
  <block id="f3e3b1e7550f6cf9fe883b01695163b7" category="inline-link-macro">다음: 소매 사용 사례에 대한 상태 및 흐름 사용자 지정</block>
  <block id="3ae7e712d75bd01d43546679548a28a1" category="paragraph"><block ref="3ae7e712d75bd01d43546679548a28a1" category="inline-link-macro-rx"></block></block>
  <block id="e2b5e920360785877a1831ff4b128520" category="summary">NetApp 설정</block>
  <block id="9af8334f3fca73145524498c2f49ee10" category="inline-link-macro">다음: 개요</block>
  <block id="02e8a07ffc2e2c5240049e5214d70427" category="paragraph"><block ref="02e8a07ffc2e2c5240049e5214d70427" category="inline-link-macro-rx"></block></block>
  <block id="adb2100439d02c2978c4a5670cda87b8" category="summary">이 페이지에는 이 작업을 만드는 데 사용된 라이브러리와 프레임워크가 나열되어 있습니다. 이러한 모든 구성 요소는 Azure의 역할 기반 액세스 및 보안 제어와 완벽하게 통합됩니다.</block>
  <block id="235ff38f40d20846e27b4c64e964ce28" category="doc">데이터 처리 및 모델 교육을 위한 라이브러리</block>
  <block id="542e61809d35e9c83a99b29c87aa40fb" category="inline-link-macro">이전: Azure NetApp Files 성능 계층</block>
  <block id="b7fe935ab4f924b870ae1983e3f3a271" category="paragraph"><block ref="b7fe935ab4f924b870ae1983e3f3a271" category="inline-link-macro-rx"></block></block>
  <block id="c4e831049faaa8b89e89eebd0a105dab" category="paragraph">다음 표에서는 이 작업을 만드는 데 사용된 라이브러리와 프레임워크를 보여 줍니다. 이러한 모든 구성 요소는 Azure의 역할 기반 액세스 및 보안 제어와 완벽하게 통합됩니다.</block>
  <block id="faeae27c134f5193efb923d2492daa47" category="cell">라이브러리/프레임워크</block>
  <block id="b540cdb28de9a6c72ef1a92504e69423" category="cell">Dask cuML</block>
  <block id="1fc1b4b6567949aab2cb7e6fecb1e68f" category="inline-link">cuML 라이브러리</block>
  <block id="efe85bbaa5690074ea98a2bfef62d930" category="cell">GPU에서 작업할 ML의 경우<block ref="514c908f6fc3f426a00e1dabdf37831f" category="inline-link-rx"></block> Dask를 사용하여 RAPIDS cuML 패키지에 대한 액세스를 제공합니다. RAPIDS cuML은 고성능 GPU 기반 구축을 통해 클러스터링, 차원 축소, 회귀 접근 방식을 비롯한 인기 있는 ML 알고리즘을 구현하여 CPU 기반 접근 방식에 비해 최대 100배 빠른 속도를 제공합니다.</block>
  <block id="ede0db3d6c9043439d0762ee99543654" category="cell">Dask cuDF</block>
  <block id="a9c380d6e09cc11f858b53d56cf69da4" category="inline-link">dask-cudf 라이브러리</block>
  <block id="13a7d0199f9797a3533ff335da46b446" category="cell">CuDF에는 데이터 하위 설정, 변환, 핫 인코딩 등 GPU 가속 추출, 변환, 로드(ETL)를 지원하는 다양한 함수가 포함되어 있습니다. RAPIDS 팀은 을 유지합니다<block ref="836818db4e43067816d31d2b73198787" category="inline-link-rx"></block> 여기에는 Dask 및 cuDF를 사용하는 도우미 메서드가 포함됩니다.</block>
  <block id="0c9c2e873df681f1ab5b13053be78af7" category="cell">Scikit 학습</block>
  <block id="cd1235fc9b090edba051d73dbc6f66bf" category="inline-link">평가자</block>
  <block id="1977c9daa1d67de51a4651abdb160c09" category="inline-link">맞춤</block>
  <block id="4f54da5a2c4a796e8215f20eb95fddcc" category="cell">Scikit-Learn은 견적기라고 하는 수십 가지의 기계 학습 알고리즘과 모델을 제공합니다. 각각<block ref="855747fa3f470c1754852d09071dd101" category="inline-link-rx"></block> 를 사용하여 일부 데이터에 장착할 수 있습니다<block ref="e52e604a9dbe357e0fb9bc58f4b62add" category="inline-link-rx"></block> 방법.</block>
  <block id="0dd4d530afb3c99ab869350770d7bebd" category="paragraph">비교를 위해 두 대의 노트북을 사용해 ML 파이프라인을 구축했으며, 하나는 기존의 Pandas scikit-learn 접근방식이고, 다른 하나는 RAPIDS 및 Dask를 사용한 분산 훈련입니다. 각 노트북을 개별적으로 테스트하여 시간과 규모의 측면에서 성능을 확인할 수 있습니다. RAPIDS 및 DASK를 사용한 분산 훈련의 이점을 설명하기 위해 각 노트북을 개별적으로 다룹니다.</block>
  <block id="7dd297826f91c438fab12307224d2c40" category="inline-link-macro">다음: Pandas에서 Logs day 15를 클릭하고 좌골키트학습 무작위 포리스트 모델을 훈련합니다.</block>
  <block id="ade9906123700a8bf734457510b6b3c8" category="paragraph"><block ref="ade9906123700a8bf734457510b6b3c8" category="inline-link-macro-rx"></block></block>
  <block id="4ac9fa791a6d1c7c97bbae134dd22586" category="paragraph">진정한 대화형 AI 시스템은 인간과 같은 대화에 참여하고, 컨텍스트를 이해하고, 지능적인 응답을 제공합니다. 이러한 AI 모델은 대개 규모가 크고 매우 복잡합니다. NVIDIA GPU 및 NetApp 스토리지를 사용하면 최첨단 대용량 언어 모델을 훈련 및 최적화하여 추론을 신속하게 실행할 수 있습니다. 빠르게, 크고 복잡한 AI 모델 간에 이루어지는 거래를 끝내기 위한 주요 발걸음을 내딛습니다. 의료, 소매 및 금융 서비스 등의 산업을 위해 GPU에 최적화된 언어 이해 모델을 AI 애플리케이션에 통합하여 스마트 스피커 및 고객 서비스 분야에서 고급 디지털 음성 지원 기능을 제공할 수 있습니다. 이러한 고품질 대화형 AI 시스템을 통해 수직 시장에 있는 기업들은 고객과 교류할 때 이전에는 불가능했던 맞춤형 서비스를 제공할 수 있습니다.</block>
  <block id="45d5663acc501eba25058f8956035e9a" category="paragraph">Jarvis를 사용하면 가상 보조자, 디지털 아바타, 다중 모드 센서 Fusion(CV와 ASR/NLP/TTS 결합) 또는 변환 등의 ASR/NLP/TTS/CV 독립 실행형 사용 사례를 구축할 수 있습니다. 날씨, 관심 지점 및 재고 가격 관련 질문에 답할 수 있는 가상 소매 도우미를 구축했습니다. 또한 Cloud Sync를 사용하여 대화 내용을 보관하고 새 데이터에 Nemo 모델을 교육하여 대화형 AI 시스템의 자연어 이해 기능을 개선하는 방법을 시연했습니다.</block>
  <block id="38a609a97a676f2cc28ccec3d3097d4b" category="paragraph"><block ref="38a609a97a676f2cc28ccec3d3097d4b" category="inline-link-macro-rx"></block></block>
  <block id="4ed0a51bc1c995651eec6f50591eec1a" category="section-title">NetApp ONTAP AI 및 Cloud Sync</block>
  <block id="bff183f31dd9706bece9767f4388a819" category="paragraph">NVIDIA DGX 시스템 및 NetApp 클라우드 연결형 스토리지 시스템을 기반으로 하는 NetApp ONTAP AI 아키텍처는 NetApp과 NVIDIA가 개발 및 검증했습니다. 이 참조 아키텍처는 IT 조직이 다음과 같은 이점을 얻을 수 있도록 해 줍니다.</block>
  <block id="88acd7d612f76d7928b6b0448806e1ea" category="list-text">다양한 성능 및 비용 관련 다양한 스토리지 옵션을 제공합니다.NetApp ONTAP AI는 DGX 시스템과 NetApp AFF A220 스토리지 시스템을 최첨단 네트워킹과 완벽하게 통합합니다. NetApp ONTAP AI 및 DGX 시스템은 설계 복잡성과 추측을 제거함으로써 AI 배포를 단순화합니다. 고객은 작은 규모로 시작한 후 에지에서 코어 및 클라우드까지 포괄하여 데이터를 지능적으로 관리하면서 중단 없이 시스템을 확장할 수 있습니다.</block>
  <block id="69be3bc10a1ad78dbe823def1907c730" category="paragraph">NetApp Cloud Sync를 사용하면 두 개의 NFS 공유, 두 개의 CIFS 공유, 한 개의 파일 공유와 Amazon S3, Amazon Elastic File System(EFS) 또는 Azure Blob 스토리지 간에 다양한 프로토콜을 통해 데이터를 쉽게 이동할 수 있습니다. 액티브-액티브 작업은 소스와 타겟을 동시에 계속 사용하여 필요한 경우 데이터 변경 사항을 점진적으로 동기화할 수 있음을 의미합니다. 온프레미스 또는 클라우드 기반 등 모든 소스 시스템과 대상 시스템 간에 데이터를 이동 및 증분 동기화하여 Cloud Sync은 데이터를 사용할 수 있는 다양한 새로운 방법을 제시합니다. 사내 시스템, 클라우드 온보딩, 클라우드 마이그레이션, 협업 및 데이터 분석 간에 데이터를 마이그레이션하는 작업을 모두 쉽게 수행할 수 있게 되었습니다. 아래 그림은 사용 가능한 소스 및 대상을 보여줍니다.</block>
  <block id="1e01782ef13699818c9eb9eab796bffc" category="paragraph">대화형 AI 시스템에서 개발자는 Cloud Sync를 활용하여 클라우드에서 데이터 센터에 이르는 대화 내역을 아카이브하여 NLP(자연어 처리) 모델의 오프라인 교육을 수행할 수 있습니다. 더 많은 연고를 인식하는 교육 모델을 통해 대화형 AI 시스템은 최종 사용자의 더 복잡한 질문을 더 효과적으로 관리할 수 있습니다.</block>
  <block id="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="paragraph"><block ref="7e3a7922ac3cd73ae37b26c0b9c99ee3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ad66827309f61fd22dc58cbbb2f8273" category="inline-link">NVIDIA Jarvis</block>
  <block id="241d985aedf9124840f9adfa9496755d" category="paragraph"><block ref="9f89431954623c8e5c580e4350b427e7" category="inline-link-rx"></block> 대화형 AI 서비스를 구축하기 위한 엔드 투 엔드 프레임워크입니다. 다음과 같은 GPU 최적화 서비스가 포함됩니다.</block>
  <block id="bb3e7af8136880e3a92118c172aed302" category="list-text">자동 음성 인식(ASR)</block>
  <block id="3c07089a439435a2998f14ea97f90825" category="list-text">자연어 이해(NLU)</block>
  <block id="8375cc1d63ce172363c4ed9c3cddd508" category="list-text">도메인별 이행 서비스와 통합</block>
  <block id="84fb561f92aa70d5e118f429e98ee99b" category="list-text">TTS(Text-to-Speech)</block>
  <block id="9478a4e1be70e1be0fdd56f3929bbdc2" category="list-text">컴퓨터 비전(CV) Jarvis 기반 서비스는 최첨단 딥 러닝 모델을 사용하여 실시간 대화 AI의 복잡하고 까다로운 작업을 해결합니다. 최종 사용자와의 자연스러운 실시간 상호 작용을 지원하기 위해 모델은 300밀리초 이내에 계산을 완료해야 합니다. 자연스러운 상호작용은 어려운 과제이며, 다중 모드 감각 통합이 필요합니다. 또한 모델 파이프라인은 복잡하며 위 서비스 간의 조정이 필요합니다.</block>
  <block id="c29efa8b1d5c9d6d647a8ce72bef1b74" category="paragraph">Jarvis는 엔드 투 엔드 딥 러닝 파이프라인을 사용하는 다중 모달 대화 AI 서비스를 구축하기 위한 애플리케이션 프레임워크입니다. Jarvis 프레임워크는 음성, 비전 및 NLU 작업을 위한 사전 교육 대화 AI 모델, 도구 및 최적화된 엔드 투 엔드 서비스를 포함합니다. Jarvis를 사용하면 AI 서비스 외에도 비전, 오디오 및 기타 센서 입력을 동시에 결합하여 가상 보조자, 다중 사용자 양극화 및 콜센터 보조자와 같은 애플리케이션에서 다중 사용자, 다중 컨텍스트 대화 등의 기능을 제공할 수 있습니다.</block>
  <block id="dc3652fc64a2a6ea2a3cfd5c40443b16" category="paragraph"><block ref="4282ee73b9eecd67e90ed51f4f36b077" category="inline-link-rx"></block> 사용하기 쉬운 API(애플리케이션 프로그래밍 인터페이스)를 사용하여 GPU 가속 첨단 대화 AI 모델을 구축, 교육 및 미세 조정하는 오픈 소스 Python 툴킷입니다. Nemo는 NVIDIA GPU에서 Tensor Core를 사용하여 혼합 정밀 컴퓨팅을 실행하며 여러 GPU로 손쉽게 확장하여 가능한 최고의 교육 성능을 제공할 수 있습니다. Nemo는 의료, 재무, 소매 및 통신 등 다양한 산업 분야에서 화상 통화 기록, 지능형 비디오 비서, 자동화된 콜 센터 지원 등의 실시간 ASR, NLP 및 TTS 애플리케이션을 위한 모델을 구축하는 데 사용됩니다.</block>
  <block id="4e5ae683e2a399c166a1724b0aa6952e" category="paragraph">Nemo를 사용하여 아카이빙된 대화 기록의 사용자 질문에서 복잡한 인텐트를 인식하는 모델을 교육했습니다. 이 교육은 소매 가상 보조자의 능력을 Jarvis가 제공하는 지원 범위를 넘어 확장합니다.</block>
  <block id="053bc62e92a61e44afd338bcb27c422f" category="section-title">소매 사용 사례 요약</block>
  <block id="8b6b761738b93e745ffa4f73dd233c08" category="paragraph">NVIDIA Jarvis를 사용하여 음성 또는 텍스트 입력을 수용하는 가상 소매 도우미를 구축하고 날씨, 관심 지점 및 재고 가격 관련 질문에 답변했습니다. 대화형 AI 시스템은 예를 들어, 사용자가 날씨 또는 관심 지점을 지정하지 않은 경우 후속 질문을 하여 대화 흐름을 기억할 수 있습니다. 또한 이 시스템은 "태국식 음식" 또는 "노트북 메모리"와 같은 복잡한 엔터티도 인식합니다. 그것은 “다음주 로스앤젤레스에서 비가 올까요?”와 같은 자연어 질문을 이해합니다. 소매 가상 비서의 데모는 에서 확인할 수 있습니다<block ref="0ba395e7fb59bace5ff35ab3c02ad737" category="inline-link-rx"></block>.</block>
  <block id="af8f881c5074e5e10cd7a34ccbaa9e57" category="paragraph"><block ref="af8f881c5074e5e10cd7a34ccbaa9e57" category="inline-link-macro-rx"></block></block>
  <block id="c94d29f1f4f8ef37e9d27f30b7d7c67d" category="summary">SnapCenter 하이브리드 클라우드 데이터베이스 워크로드 환경을 준비하려면 이 섹션에 설명된 작업을 사내 에서 완료해야 합니다.</block>
  <block id="f6a196d9d3a941e76765e4a9395630c4" category="doc">사전 요구 사항 온-프레미스</block>
  <block id="eac55cbc45bfe6b98b8847b3952de7d3" category="inline-link-macro">이전: 사전 요구 사항 구성.</block>
  <block id="e63a288cc25b5c4127d3021b339c9f20" category="paragraph"><block ref="e63a288cc25b5c4127d3021b339c9f20" category="inline-link-macro-rx"></block></block>
  <block id="40931dcd4d9132545ec0faf2c5fb1b64" category="paragraph">SnapCenter 하이브리드 클라우드 데이터베이스 워크로드 환경을 준비하기 위해 온프레미스에서 다음 작업을 완료해야 합니다.</block>
  <block id="79daf399b9626cde309801f41a1e2e14" category="section-title">SnapCenter 설치 및 구성</block>
  <block id="2607530756fefa4173e12cfcd5fbfb01" category="paragraph">워크그룹 배포도 가능하긴 하지만, NetApp SnapCenter 툴은 Windows 도메인 환경에서 일반적으로 실행되는 Windows 기반 애플리케이션입니다. 데이터베이스 작업 부하를 위해 중앙 집중식 관리 서버(SnapCenter 서버)와 데이터베이스 서버 호스트의 SnapCenter 플러그인을 포함하는 다중 계층 아키텍처를 기반으로 합니다. 다음은 하이브리드 클라우드 구축과 관련된 몇 가지 주요 고려 사항입니다.</block>
  <block id="9f8c0bcd11d7afd1dd2ee818191cb914" category="list-text">* 단일 인스턴스 또는 HA 배포. * HA 배포는 단일 SnapCenter 인스턴스 서버 장애 시 중복성을 제공합니다.</block>
  <block id="1bfa2867d5aa49106efbf3ac752f3084" category="list-text">* 이름 확인. * 정방향 및 역방향 조회를 위해 모든 데이터베이스 호스트와 스토리지 SVM을 확인하도록 SnapCenter 서버에서 DNS를 구성해야 합니다. 또한 정방향 및 역방향 조회를 위해 SnapCenter 서버와 스토리지 SVM을 확인하기 위해 데이터베이스 서버에도 DNS를 구성해야 합니다.</block>
  <block id="41f54308d86c1d7b525475d6ead22892" category="list-text">* 역할 기반 액세스 제어(RBAC) 구성. * 혼합 데이터베이스 워크로드의 경우 RBAC를 사용하여 Oracle 데이터베이스의 관리자 또는 SQL Server의 관리자와 같은 서로 다른 DB 플랫폼의 관리 책임을 분리할 수 있습니다. DB 관리자 사용자에게 필요한 권한이 부여되어야 합니다.</block>
  <block id="5aee5dffd2e329652ec35995add763ae" category="list-text">* 정책 기반 백업 전략을 활성화합니다. * 백업 일관성 및 안정성을 적용합니다.</block>
  <block id="dde4790e572aa9d01cd58fcfd8498766" category="list-text">* 방화벽에서 필요한 네트워크 포트를 엽니다. * 온프레미스 SnapCenter 서버가 클라우드 DB 호스트에 설치된 에이전트와 통신합니다.</block>
  <block id="e2962676531ebdcf62cb2a7b96042e77" category="list-text">* 사내 및 퍼블릭 클라우드 간 SnapMirror 트래픽이 가능하도록 포트가 열려 있어야 합니다. * SnapCenter 서버는 ONTAP SnapMirror를 기반으로 온사이트 Snapshot 백업을 클라우드 CVO 스토리지 SVM으로 복제합니다.</block>
  <block id="549762060d7242346fa79f39cba51791" category="inline-link-macro">SnapCenter 설치 워크플로우</block>
  <block id="aec875397d57826c45f7072636026a07" category="paragraph">신중하게 사전 설치 계획 및 고려했으면 이 항목을 클릭합니다 <block ref="f44e9d032441cc842cad02c3aab57d84" category="inline-link-macro-rx"></block> SnapCenter 설치 및 구성에 대한 자세한 내용은 를 참조하십시오.</block>
  <block id="df3fb602185c77a88bab186791d02636" category="section-title">온프레미스 데이터베이스 서버 스토리지 구성</block>
  <block id="f7f3a649be867b87ccb26789453199db" category="paragraph">스토리지 성능은 데이터베이스 및 애플리케이션의 전반적인 성능에서 중요한 역할을 합니다. 잘 설계된 스토리지 레이아웃은 DB 성능을 개선할 뿐만 아니라 데이터베이스 백업 및 복구를 쉽게 관리할 수 있도록 합니다. 데이터베이스 크기, 데이터베이스의 예상 데이터 변경율, 백업을 수행하는 빈도 등 스토리지 레이아웃을 정의할 때 몇 가지 요소를 고려해야 합니다.</block>
  <block id="8481231881c8e64b34aa3c7e29510a25" category="paragraph">가상화된 데이터베이스 워크로드를 위해 NFS 또는 iSCSI를 통해 스토리지 LUN을 게스트 VM에 직접 연결하면 일반적으로 VMDK를 통해 할당된 스토리지보다 성능이 향상됩니다. 다음 그림에 표시된 LUN의 대규모 SQL Server 데이터베이스에 대한 스토리지 레이아웃을 사용하는 것이 좋습니다.</block>
  <block id="cc75f443d22e45e490468a8f20689d77" category="paragraph"><block ref="cc75f443d22e45e490468a8f20689d77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99aea05cf884bfdec230afa5250968b2" category="paragraph">다음 그림은 LUN의 중소 규모 SQL Server 데이터베이스에 대한 NetApp 권장 스토리지 레이아웃을 보여 줍니다.</block>
  <block id="9fc72535f1113895818f8aa60ef773e7" category="paragraph"><block ref="9fc72535f1113895818f8aa60ef773e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ecde8f778d0dd0676f392793ce4382" category="admonition">로그 디렉토리는 SnapCenter 전용으로 데이터베이스 복구를 위한 트랜잭션 로그 롤업을 수행합니다. 초대형 데이터베이스의 경우, 성능 향상을 위해 여러 LUN을 볼륨에 할당할 수 있습니다.</block>
  <block id="ee9158729a15dbd90d166650ba285d0e" category="paragraph">Oracle 데이터베이스 워크로드의 경우 SnapCenter는 호스트에 물리적 또는 가상 디바이스로 마운트된 ONTAP 스토리지가 지원하는 데이터베이스 환경을 지원합니다. 환경의 중요도에 따라 단일 또는 여러 스토리지 장치에서 전체 데이터베이스를 호스팅할 수 있습니다. 일반적으로 고객은 전용 스토리지의 데이터 파일을 제어 파일, 재실행 파일 및 아카이브 로그 파일과 같은 다른 모든 파일에서 격리합니다. 따라서 관리자는 Snapshot 기술을 사용하여 (ONTAP 단일 파일 SnapRestore)를 신속하게 복원하거나 (페타바이트 규모)의 대규모 중요 데이터베이스를 몇 초에서 몇 분 이내에 클론 복제할 수 있습니다.</block>
  <block id="b31fbb7e1a6e863315e431fdf9c00db9" category="paragraph"><block ref="b31fbb7e1a6e863315e431fdf9c00db9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="959a3405dfdfb0469534f5276ffb8e5e" category="paragraph">지연 시간에 민감한 미션 크리티컬 워크로드의 경우, 최적의 지연 시간을 달성하기 위해 다양한 유형의 Oracle 파일에 전용 스토리지 볼륨을 구축해야 합니다. 대규모 데이터베이스의 경우 볼륨당 여러 개의 LUN(최대 8개 권장)을 데이터 파일에 할당해야 합니다.</block>
  <block id="ac111cbcae2e9eaedafe418acc3a2cab" category="paragraph"><block ref="ac111cbcae2e9eaedafe418acc3a2cab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2702ce3d59ec94853fa030462b309f2f" category="paragraph">소규모 Oracle 데이터베이스의 경우 SnapCenter는 여러 데이터베이스 또는 데이터베이스의 일부를 동일한 스토리지 볼륨 또는 LUN에 호스팅할 수 있는 공유 스토리지 레이아웃을 지원합니다. 이 레이아웃의 예로는 + data ASM 디스크 그룹 또는 볼륨 그룹의 모든 데이터베이스에 대한 데이터 파일을 호스팅할 수 있습니다. 나머지 파일(재실행, 아카이브 로그 및 제어 파일)은 다른 전용 디스크 그룹 또는 볼륨 그룹(LVM)에서 호스팅할 수 있습니다. 이러한 구축 시나리오는 아래에 나와 있습니다.</block>
  <block id="6c12e98a6e201f55836390c2a6232e5a" category="paragraph"><block ref="6c12e98a6e201f55836390c2a6232e5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93cf45b97655292e0536b810cb248828" category="paragraph">Oracle 데이터베이스 재배치를 용이하게 하기 위해 일반 백업 정책에 포함된 별도의 LUN에 Oracle 바이너리를 설치해야 합니다. 따라서 새 서버 호스트로 데이터베이스를 재배치할 경우 동기화 해제된 Oracle 바이너리로 인해 발생할 수 있는 문제 없이 Oracle 스택을 복구에 시작할 수 있습니다.</block>
  <block id="1e69a4a8adec0842d1e110e970112268" category="section-title">라이센스 요구 사항</block>
  <block id="7f59934b2c0edd33f0d981f3bc4d12e7" category="paragraph">SnapCenter은 NetApp의 라이센스 소프트웨어입니다. 일반적으로 사내 ONTAP 라이센스에 포함됩니다. 하지만 하이브리드 클라우드를 구축할 경우, SnapCenter용 클라우드 라이센스를 통해 SnapCenter에 CVO를 타겟 데이터 복제 대상으로 추가해야 합니다. 자세한 내용은 SnapCenter 표준 용량 기반 라이센스에 대한 다음 링크를 참조하십시오.</block>
  <block id="9e86ae6c96041e3cb31e88116102ee35" category="inline-link-macro">SnapCenter 표준 용량 기반 라이센스</block>
  <block id="a1d51b5b5f3258b40cbe392146bc8868" category="paragraph"><block ref="a1d51b5b5f3258b40cbe392146bc8868" category="inline-link-macro-rx"></block></block>
  <block id="85db56d490cdd7a31d40697ad1c9be3c" category="section-title">네트워킹 및 보안</block>
  <block id="254215e6d18fb5582ba78464fa468553" category="paragraph">개발/테스트 및 재해 복구를 위해 클라우드로 안전하게 전환하는 온프레미스 운영 데이터베이스가 필요한 하이브리드 데이터베이스 작업에서는 환경을 설정하고 사내 데이터 센터에서 퍼블릭 클라우드에 연결할 때 네트워킹 및 보안을 고려해야 합니다.</block>
  <block id="1e356fab450b44971b6cdbd1c25586b8" category="paragraph">퍼블릭 클라우드는 일반적으로 VPC(가상 프라이빗 클라우드)를 사용하여 퍼블릭 클라우드 플랫폼 내에서 서로 다른 사용자를 격리합니다. 개별 VPC 내에서 보안은 VPC 잠금에 대한 사용자 요구에 따라 구성할 수 있는 보안 그룹과 같은 방법을 사용하여 제어됩니다.</block>
  <block id="5192a6d33c7a0127a67cbd7e07801735" category="paragraph">VPN 터널을 통해 사내 데이터 센터에서 VPC로의 연결을 보호할 수 있습니다. VPN 게이트웨이에서 NAT 및 방화벽 규칙을 사용하여 보안을 강화할 수 있습니다. 이 규칙은 인터넷에 있는 호스트로부터 회사 데이터 센터 내의 호스트로의 네트워크 연결을 설정하는 시도를 차단합니다.</block>
  <block id="04a3995237c020c6a587d8a7723af6a6" category="paragraph">네트워킹 및 보안 고려 사항에 대해서는 선택한 퍼블릭 클라우드에 대한 관련 인바운드 및 아웃바운드 CVO 규칙을 검토하십시오.</block>
  <block id="d15513a147fbd525b88805bee9ea17ea" category="inline-link-macro">CVO-AWS의 보안 그룹 규칙</block>
  <block id="f8d1f085169118c4d407be16136389c6" category="list-text"><block ref="f8d1f085169118c4d407be16136389c6" category="inline-link-macro-rx"></block></block>
  <block id="39f48b44d100d16ed6e2b931111663b7" category="inline-link-macro">CVO-Azure의 보안 그룹 규칙</block>
  <block id="bcde746324630d82052a4fc9861cfea6" category="list-text"><block ref="bcde746324630d82052a4fc9861cfea6" category="inline-link-macro-rx"></block></block>
  <block id="7b20c547f2fd113499deaa3c0e418282" category="inline-link-macro">CVO-GCP의 방화벽 규칙</block>
  <block id="acde731d82a437ab33cb200791f7a197" category="list-text"><block ref="acde731d82a437ab33cb200791f7a197" category="inline-link-macro-rx"></block></block>
  <block id="d9446a69434b7c7fdec5c9e35d222834" category="section-title">Ansible 자동화를 사용하여 온프레미스 및 클라우드 간 DB 인스턴스를 동기화하십시오(선택 사항)</block>
  <block id="1c7c9b49a62ea0dc765d1439120cfc8f" category="paragraph">하이브리드 클라우드 데이터베이스 환경의 관리를 단순화하기 위해, NetApp은 산연 인스턴스를 온프레미스 및 클라우드에 동기화하는 등 일부 관리 작업을 자동화하기 위해 Ansible 컨트롤러를 구축할 것을 적극 권장하지만 필요로 하지는 않습니다. 이는 특히 중요합니다. 클라우드의 비동기 컴퓨팅 인스턴스는 커널 패키지 및 기타 문제가 누락되어 복구된 데이터베이스를 클라우드에서 오류가 발생하기 쉬운 상태로 만들 수 있기 때문입니다.</block>
  <block id="7468552c7fc3a7ca377b7fc2405a9940" category="paragraph">Ansible 컨트롤러의 자동화 기능도 SnapMirror 인스턴스를 확장하여 운영 시 DR 데이터 복사본을 활성화하는 등 특정 작업에 SnapCenter를 보강할 수 있습니다.</block>
  <block id="6ac547919eb6ca11f5a8387eaf990843" category="inline-link-macro">RedHat/CentOS Ansible 컨트롤러 설치</block>
  <block id="c8e133fc33bbdb52f84b3532496f2ac8" category="inline-link-macro">Ubuntu/Debian Ansible 컨트롤러 설치</block>
  <block id="6f332c2f54a4d49478f9588c5cd6c57c" category="paragraph">다음 지침에 따라 RedHat 또는 CentOS 시스템에 대한 Ansible 제어 노드를 설정합니다. <block ref="fedce547519117863322cfa54cc2ba7d" category="inline-link-macro-rx"></block>. 다음 지침에 따라 Ubuntu 또는 Debian 시스템용 Ansible 제어 노드를 설정합니다. <block ref="1c50818f5fe40dbc8b2e05138d554fa4" category="inline-link-macro-rx"></block>.</block>
  <block id="d5316785c089f90464e8e683aadd02e1" category="inline-link-macro">다음으로: 퍼블릭 클라우드.</block>
  <block id="d09f79a080b121cb1acc181711b5d02a" category="paragraph"><block ref="d09f79a080b121cb1acc181711b5d02a" category="inline-link-macro-rx"></block></block>
  <block id="467bda78c0e1adcc5ed650843fbfbdf5" category="summary">이 섹션에서는 AWS에서 Cloud Manager 및 Cloud Volumes ONTAP를 구축하는 프로세스에 대해 설명합니다.</block>
  <block id="298a4809d5445df75b6c4a9fb94074a4" category="doc">AWS 퍼블릭 클라우드 시작하기</block>
  <block id="b8f5ff8c1ae69fa5befe459d3f34b68a" category="inline-link-macro">이전: 온-프레미스 시작.</block>
  <block id="19f84106226ff97c314f55dd621bbd98" category="paragraph"><block ref="19f84106226ff97c314f55dd621bbd98" category="inline-link-macro-rx"></block></block>
  <block id="8a3f037eef48de78bfe13d14e3d7cdfa" category="section-title">설치하고</block>
  <block id="87aa698992e009d04733c9906225592c" category="admonition">그 결과를 더욱 쉽게 확인할 수 있도록 AWS에 구축된 이 문서를 토대로 마련했습니다. 그러나 프로세스는 Azure 및 GCP와 매우 유사합니다.</block>
  <block id="39845311263ccad04c0d4f0b9aa9d4c6" category="section-title">비행 전 점검</block>
  <block id="12ed93944854c12caa37886d620f16db" category="paragraph">배포 전에 다음 단계에서 배포할 수 있도록 인프라가 마련되어 있는지 확인합니다. 여기에는 다음이 포함됩니다.</block>
  <block id="c6368ae044df0f7bb26ed60afda5c591" category="list-text">설치하 고 있습니다</block>
  <block id="4019c185756035c18c03fabfccd7d4b2" category="list-text">선택한 지역에서 VPC를 사용할 수 있습니다</block>
  <block id="fca5d2fece6e360f78dff4573ba04a20" category="list-text">공용 인터넷에 액세스할 수 있는 서브넷입니다</block>
  <block id="e3e5c3dadc3e70d536645a3be9744f79" category="list-text">AWS 계정에 IAM 역할을 추가할 수 있는 권한</block>
  <block id="bd5c82fb0e0371a168f609848b11e92a" category="list-text">AWS 사용자를 위한 비밀 키 및 액세스 키입니다</block>
  <block id="c3d1ff3c88148b2246bb0972916da82a" category="section-title">2.AWS에서 Cloud Manager 및 Cloud Volumes ONTAP를 구축하는 단계</block>
  <block id="6d0eb695a99109617b806676e9610075" category="inline-link">NetApp 클라우드 문서</block>
  <block id="593581e466784760a050bceaea5e0c48" category="admonition">Cloud Manager와 Cloud Volumes ONTAP를 구축하는 방법은 매우 간단합니다. 이 방법은 가장 간단하지만 가장 많은 권한이 필요합니다. 이 방법이 AWS 환경에 적합하지 않은 경우 을 참조하십시오<block ref="97a20614f8c0e53f461a9353634e5e51" category="inline-link-rx"></block>.</block>
  <block id="bb3e779fdf877143137572122cf424e3" category="section-title">Cloud Manager 커넥터를 배포합니다</block>
  <block id="49fc376ed35249f3841846ede4dab884" category="inline-link">NetApp Cloud Central에서</block>
  <block id="4c6e32ff373dc3ce5b49202f92f01b08" category="list-text">로 이동합니다<block ref="143fea272f01f72dbdc942451156df21" category="inline-link-rx"></block> 로그인 또는 가입</block>
  <block id="356cf5e12d635c19d987b1b195ff5a40" category="paragraph"><block ref="356cf5e12d635c19d987b1b195ff5a40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2300b8579a8761e452d89a2af6636b7d" category="list-text">로그인한 후 Canvas로 옮겨야 합니다.</block>
  <block id="af93b0b88e1db5f3aa229d2336fedb3c" category="paragraph"><block ref="af93b0b88e1db5f3aa229d2336fedb3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3fbf2c408ce86ff3403990e7e32dcb3" category="list-text">"작업 환경 추가"를 클릭하고 AWS에서 Cloud Volumes ONTAP를 선택합니다. 단일 노드 시스템을 배포할지 고가용성 쌍을 구축할지를 선택할 수도 있습니다. 고가용성 쌍을 구축하기로 선택했습니다.</block>
  <block id="bb18ff1ebac7ea2039aa297469c76b76" category="paragraph"><block ref="bb18ff1ebac7ea2039aa297469c76b76" category="inline-image-macro-rx" type="image"></block></block>
  <block id="016aa0c0a7322975ec4b8eeac805f2c0" category="list-text">커넥터가 작성되지 않은 경우 커넥터를 작성하라는 팝업 메시지가 나타납니다.</block>
  <block id="a05691eb0d806668c3796d3d6fe01157" category="paragraph"><block ref="a05691eb0d806668c3796d3d6fe01157" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fc3362a0d8ab63cc8fa21bbd0fb07db" category="list-text">시작 을 클릭한 다음 AWS 를 선택합니다.</block>
  <block id="55f5adc74d49945abd7798742f307124" category="paragraph"><block ref="55f5adc74d49945abd7798742f307124" category="inline-image-macro-rx" type="image"></block></block>
  <block id="deae4c054bb3102bbf634b14534da9bf" category="inline-link">NetApp 정책 페이지를 참조하십시오</block>
  <block id="651d429a2b6cfcd93f6adb1d4825a214" category="list-text">암호 키와 액세스 키를 입력합니다. 사용자에게 에 설명된 올바른 권한이 있는지 확인합니다<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block>.</block>
  <block id="94497191b0b0c6d05a2df7d2175e87f5" category="paragraph"><block ref="94497191b0b0c6d05a2df7d2175e87f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d8d59b60a74630e45f83fd3c48207b47" category="list-text">커넥터에 이름을 지정하고 에 설명된 대로 미리 정의된 역할을 사용합니다<block ref="fb0c65a047527c32e46baadcaacb4fe2" category="inline-link-rx"></block> 또는 Cloud Manager에게 역할을 맡도록 요청하십시오.</block>
  <block id="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="paragraph"><block ref="1e64ebe4af05f5d4a8b8c6542e7a09e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02d395705fb063ad8d33d8c83c856e6f" category="list-text">커넥터를 배포하는 데 필요한 네트워킹 정보를 제공합니다. 다음과 같은 방법으로 아웃바운드 인터넷 액세스가 활성화되었는지 확인합니다.</block>
  <block id="8215126360cbe5d8f5566c7ffc8cf224" category="list-text">커넥터에 공용 IP 주소를 제공합니다</block>
  <block id="22adb619c008bfd7495288573093ae44" category="list-text">커넥터를 통해 작업할 프록시를 제공합니다</block>
  <block id="58a149795bbe86e4e0d4ab8f10413219" category="list-text">인터넷 게이트웨이를 통해 공용 인터넷에 연결되는 경로를 커넥터에 제공합니다</block>
  <block id="5908ad1cf5bd748238e305dd5fc52fac" category="paragraph"><block ref="5908ad1cf5bd748238e305dd5fc52fac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7c58ebc9f032dc8d2e5c4f522cedbe0b" category="list-text">보안 그룹을 제공하거나 새 보안 그룹을 생성하여 SSH, HTTP 및 HTTPS를 통해 커넥터와 통신할 수 있습니다. IP 주소에서만 커넥터에 대한 액세스를 활성화했습니다.</block>
  <block id="1d39d9c13f50dd25f7e54173c87c633a" category="paragraph"><block ref="1d39d9c13f50dd25f7e54173c87c633a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb444cfaba774437ecdbbb95856d94cd" category="list-text">요약 페이지의 정보를 검토하고 추가 를 클릭하여 커넥터를 배포합니다.</block>
  <block id="5576df68e3720f55e585e7e091d5b9e3" category="paragraph"><block ref="5576df68e3720f55e585e7e091d5b9e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4255ace47c9ad7f2907c18df7512bb9f" category="list-text">이제 커넥터는 클라우드 형성 스택을 사용하여 전개됩니다. Cloud Manager에서 또는 AWS를 통해 진행률을 모니터링할 수 있습니다.</block>
  <block id="ff7fb4bedc0d09880f85d9745ec258a5" category="paragraph"><block ref="ff7fb4bedc0d09880f85d9745ec258a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca320cc147e2b9fac2dd7379e91012b6" category="list-text">배포가 완료되면 성공 페이지가 나타납니다.</block>
  <block id="f5bbadf1ed57058e80e27764684e6314" category="paragraph"><block ref="f5bbadf1ed57058e80e27764684e6314" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6382283fd45b13b5c983745731fec990" category="section-title">Cloud Volumes ONTAP 구축</block>
  <block id="5fe90897c7135ba3020c4a397f55adb6" category="list-text">요구사항에 따라 AWS 및 구축 유형을 선택하십시오.</block>
  <block id="63b636f2002a2e7b7c2e2420cd64ff73" category="paragraph"><block ref="63b636f2002a2e7b7c2e2420cd64ff73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ccf1300c5621fdebe8c1a70fade44f3b" category="list-text">구독이 할당되지 않은 상태에서 PAYGO를 사용하여 구매하려는 경우 자격 증명 편집 을 선택합니다.</block>
  <block id="b893bded7e1bd3419a443758a8ef410f" category="paragraph"><block ref="b893bded7e1bd3419a443758a8ef410f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88eb84b1a8f0417c9de6e1202125df56" category="list-text">구독 추가 를 선택합니다.</block>
  <block id="0b5d3e3d1a9347ff4a7395d09208a8f4" category="paragraph"><block ref="0b5d3e3d1a9347ff4a7395d09208a8f4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="052208bafdfe08bc8f0735a78226e541" category="list-text">가입하려는 계약 유형을 선택합니다. 나는 선불 종량제 를 선택했습니다.</block>
  <block id="4d5ab1ed0682fe644e831558598d4638" category="paragraph"><block ref="4d5ab1ed0682fe644e831558598d4638" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65577508f7897e730adb501d0db73913" category="list-text">AWS로 리디렉션됩니다. 구독으로 계속 을 선택합니다.</block>
  <block id="ac33260d1e06f504f1dcac229aeb269c" category="paragraph"><block ref="ac33260d1e06f504f1dcac229aeb269c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="439c4fb23c120f0a99894c630cedaabd" category="list-text">구독하면 NetApp Cloud Central로 리디렉션됩니다. 이미 가입되어 있고 리디렉션되지 않는 경우 "여기를 클릭" 링크를 선택하십시오.</block>
  <block id="a90c8b1fc04a41aff490fd2b269f5932" category="paragraph"><block ref="a90c8b1fc04a41aff490fd2b269f5932" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14b9e98d2b57da92c29826ce7de32c32" category="list-text">구독의 이름을 지정하고 Cloud Central 계정에 할당해야 하는 Cloud Central로 리디렉션됩니다.</block>
  <block id="c89376fd9624f6ebda7959df6176ef34" category="paragraph"><block ref="c89376fd9624f6ebda7959df6176ef34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4508f5994d1b34ff85cd1e8a1884d6c1" category="list-text">성공하면 확인 표시 페이지가 나타납니다. Cloud Manager 탭으로 다시 이동합니다.</block>
  <block id="2b206bbd8f3b20e3282b660a356d90be" category="paragraph"><block ref="2b206bbd8f3b20e3282b660a356d90be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3294e5fb9ec1c42cde7ebf9b206c583" category="list-text">이제 Cloud Central에 구독이 나타납니다. 계속하려면 적용을 클릭하십시오.</block>
  <block id="37ce5c33a55d907edabe632c39a2707c" category="paragraph"><block ref="37ce5c33a55d907edabe632c39a2707c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7927b068a5dddb4852b2e7dc256544" category="list-text">다음과 같은 작업 환경 세부 정보를 입력합니다.</block>
  <block id="0dbae4d42c7a0db53e2eb32adee12892" category="list-text">클러스터 이름입니다</block>
  <block id="0c191ee206a91460fd94e2ff976a38e7" category="list-text">클러스터 암호입니다</block>
  <block id="53aa18427d1e2c7b7113c668561a62d2" category="list-text">AWS 태그(선택 사항)</block>
  <block id="d3b6ff1e8c6317d132d3a5e974f1374c" category="paragraph"><block ref="d3b6ff1e8c6317d132d3a5e974f1374c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fb5b261ae3a3581304a283ef70a5246" category="inline-link">NetApp Cloud 홈 페이지</block>
  <block id="e7b29c75e71a48483734401322ef6e92" category="list-text">구축할 추가 서비스를 선택하십시오. 이러한 서비스에 대한 자세한 내용은 를 참조하십시오<block ref="1bb1213784e04e4f47d06f252d1ba164" category="inline-link-rx"></block>.</block>
  <block id="88e71a2c19d98c79d2ed51a753c8a4c2" category="paragraph"><block ref="88e71a2c19d98c79d2ed51a753c8a4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0dffa77d5644a3816ba69e24ce813ff" category="list-text">여러 가용성 영역(각각 다른 AZ에 있는 3개의 서브넷이 필요함) 또는 단일 가용성 영역에 구축할지 선택합니다. 여러 개의 AZs를 선택했습니다.</block>
  <block id="6e4a3fe2b0629dae504d8e727147f709" category="paragraph"><block ref="6e4a3fe2b0629dae504d8e727147f709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b889b7255c34e7f230e392668605860" category="list-text">구축할 클러스터의 지역, VPC 및 보안 그룹을 선택합니다. 이 섹션에서는 노드별(및 중재자) 가용성 영역과 해당 영역이 차지하는 서브넷도 할당합니다.</block>
  <block id="9ad68c9f72863557931a8569462bff52" category="paragraph"><block ref="9ad68c9f72863557931a8569462bff52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be43ebbf5380089f153e4f1b13e35e6f" category="list-text">노드 및 중재자의 연결 방법을 선택합니다.</block>
  <block id="8bf6da8b537127466c4421c1ae3169be" category="paragraph"><block ref="8bf6da8b537127466c4421c1ae3169be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="204bd52e1d13052712299779cf041df6" category="admonition">중재자가 AWS API와 통신해야 합니다. 중재자 EC2 인스턴스를 구축한 후 API에 연결할 수 있으면 공용 IP 주소가 필요하지 않습니다.</block>
  <block id="52fade87431f9acc43b7bf6e4c5fd2f1" category="inline-link">NetApp 클라우드 문서화</block>
  <block id="0c79e4a46253eeb94ba6b8218928aa99" category="list-text">부동 IP 주소는 클러스터 관리 및 데이터 서비스 IP를 포함하여 Cloud Volumes ONTAP가 사용하는 다양한 IP 주소에 대한 액세스를 허용하는 데 사용됩니다. 이러한 주소는 네트워크 내에서 아직 라우팅할 수 없는 주소여야 하며 AWS 환경의 라우팅 테이블에 추가됩니다. 이러한 주소는 페일오버 중에 HA 쌍의 일관된 IP 주소를 지원하는 데 필요합니다. 부동 IP 주소에 대한 자세한 내용은 에서 찾을 수 있습니다<block ref="72cde540b4f97efa19e071f729439801" category="inline-link-rx"></block>.</block>
  <block id="fd4a46ceddfb2402b7e37177af575e04" category="paragraph"><block ref="fd4a46ceddfb2402b7e37177af575e04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95ca6b5e9b64aed9132a6be07d061f3b" category="list-text">부동 IP 주소를 추가할 라우팅 테이블을 선택합니다. 이러한 라우팅 테이블은 클라이언트가 Cloud Volumes ONTAP와 통신하는 데 사용됩니다.</block>
  <block id="3453ab81a2f04d5c39ae750fb79ece2a" category="paragraph"><block ref="3453ab81a2f04d5c39ae750fb79ece2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af918e519f9c0db1ed5ab4fd4b6e9e05" category="list-text">ONTAP 루트, 부팅 및 데이터 디스크를 암호화하기 위해 AWS 관리 암호화를 사용할지 AWS KMS를 사용할지 여부를 선택합니다.</block>
  <block id="058eaefa711702bd45c5f6650cf01e4c" category="paragraph"><block ref="058eaefa711702bd45c5f6650cf01e4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01bd54fa77587425fca4a6c352309b5c" category="list-text">라이센스 모델을 선택합니다. 선택할 항목을 모르는 경우 NetApp 담당자에게 문의하십시오.</block>
  <block id="e5e49184799594a9fa690c9122eb883e" category="paragraph"><block ref="e5e49184799594a9fa690c9122eb883e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04110b24d1459a6e21e35ad976a8f10e" category="list-text">사용 사례에 가장 적합한 구성을 선택하십시오. 이는 사전 요구 사항 페이지에서 다룬 크기 조정 고려 사항과 관련이 있습니다.</block>
  <block id="e19584159c9c3791a9e3c462cb0aa451" category="paragraph"><block ref="e19584159c9c3791a9e3c462cb0aa451" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ed47788a525c6d08246bfa2f90922da" category="list-text">필요에 따라 볼륨을 생성합니다. 다음 단계에서는 SnapMirror를 사용하고, 이로 인해 볼륨이 생성되므로 필요하지 않습니다.</block>
  <block id="01da9401385484b72ba9c016ac6c19ab" category="paragraph"><block ref="01da9401385484b72ba9c016ac6c19ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76011f95c4e1b3f68fa5829dab0fb786" category="list-text">선택 사항을 검토하고 상자를 선택하여 Cloud Manager가 AWS 환경에 리소스를 구축함을 이해했는지 확인합니다. 준비가 되면 이동 을 클릭합니다.</block>
  <block id="7b78e746aa55ffe6fee1f3e0b65b8cca" category="paragraph"><block ref="7b78e746aa55ffe6fee1f3e0b65b8cca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13b7f009673a469e5482a96832be1473" category="list-text">이제 Cloud Volumes ONTAP가 배포 프로세스를 시작합니다. Cloud Manager는 AWS API 및 클라우드 형성 스택을 사용하여 Cloud Volumes ONTAP를 구축합니다. 그런 다음 시스템을 사양에 맞게 구성하여 즉시 활용할 수 있는 즉시 사용 가능한 시스템을 제공합니다. 이 프로세스의 타이밍은 선택한 항목에 따라 달라집니다.</block>
  <block id="11d15d8a4bb9195b48d5010fa30fa547" category="paragraph"><block ref="11d15d8a4bb9195b48d5010fa30fa547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e63d2329924bb302fb012e7916b3614" category="list-text">타임라인으로 이동하여 진행 상황을 모니터링할 수 있습니다.</block>
  <block id="77405312cc4c1e96d3f7f796e838bf89" category="paragraph"><block ref="77405312cc4c1e96d3f7f796e838bf89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b4df7cc92b3ee31f5d95082a78c7903" category="list-text">타임라인은 Cloud Manager에서 수행된 모든 작업에 대한 감사 역할을 합니다. AWS와 ONTAP 클러스터 모두에 설정하는 동안 Cloud Manager에서 수행하는 모든 API 호출을 볼 수 있습니다. 또한 이 기능을 사용하면 발생하는 모든 문제를 효과적으로 해결할 수 있습니다.</block>
  <block id="8c17e020c76595308d57605fa71dc7af" category="paragraph"><block ref="8c17e020c76595308d57605fa71dc7af" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c5674ad1910f0a25455fdeb0f3f097a" category="list-text">구축이 완료되면 CVO 클러스터가 현재 용량인 Canvas에 표시됩니다. 현재 상태의 ONTAP 클러스터는 즉시 사용 가능한 진정한 환경을 제공할 수 있도록 완전히 구성되어 있습니다.</block>
  <block id="db044bc640be9fc8227b7ada891f279d" category="paragraph"><block ref="db044bc640be9fc8227b7ada891f279d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28d2e01957d5845ff59688f17bd34339" category="section-title">사내에서 클라우드까지 SnapMirror를 구성합니다</block>
  <block id="081494b1a178710486921a42e2bdfa87" category="paragraph">소스 ONTAP 시스템과 타겟 ONTAP 시스템을 구축했으므로 이제 데이터베이스 데이터가 포함된 볼륨을 클라우드에 복제할 수 있습니다.</block>
  <block id="cb3269c2496a99fb03bebe82b6a3e4bc" category="inline-link">SnapMirror 호환성 매트릭스</block>
  <block id="46aad6288d89ba29f38b4742bf018aca" category="paragraph">SnapMirror용 호환 ONTAP 버전에 대한 지침은 를 참조하십시오<block ref="f75a4f2138bf92eb17ef87cad85a9e34" category="inline-link-rx"></block>.</block>
  <block id="36c5350a8474f2212fecc811eb77df57" category="list-text">소스 ONTAP 시스템(온-프레미스)을 클릭하고 대상을 끌어다 놓고 복제 &gt; 활성화 를 선택하거나 복제 &gt; 메뉴 &gt; 복제 를 선택합니다.</block>
  <block id="5dbe69ec28d70286f46385336e96d003" category="paragraph"><block ref="5dbe69ec28d70286f46385336e96d003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8771a8fdaa9e84a7eef7540edcca5f40" category="paragraph">사용을 선택합니다.</block>
  <block id="ac21962f3f0ae9f9c17b26196452f903" category="paragraph"><block ref="ac21962f3f0ae9f9c17b26196452f903" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6a8dc55f6f333187a100f6ed328bdc0" category="paragraph">또는 옵션 을 선택합니다.</block>
  <block id="949fa0a5e194cf44c9e08903cb914566" category="paragraph"><block ref="949fa0a5e194cf44c9e08903cb914566" category="inline-image-macro-rx" type="image"></block></block>
  <block id="066bf779660ad446aa9b0d4021c4bf40" category="paragraph">복제.</block>
  <block id="deafbb4908c633cb93a7f7e76b31da08" category="paragraph"><block ref="deafbb4908c633cb93a7f7e76b31da08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a803b2a55429f981d25fbb8da94aef7" category="list-text">끌어서 놓기를 하지 않은 경우 복제할 대상 클러스터를 선택합니다.</block>
  <block id="630e74180bc1b6c0c0c866d5478ff029" category="paragraph"><block ref="630e74180bc1b6c0c0c866d5478ff029" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761124dc5e0730086556a7d33d43418c" category="list-text">복제할 볼륨을 선택합니다. 데이터와 모든 로그 볼륨을 복제했습니다.</block>
  <block id="7bec2596a51a0d4a808a37dec9e6c540" category="paragraph"><block ref="7bec2596a51a0d4a808a37dec9e6c540" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bde4e8497f5ecaef866c0f049aada776" category="list-text">대상 디스크 유형 및 계층화 정책을 선택합니다. 재해 복구를 위해 디스크 유형으로 SSD를 사용하고 데이터 계층화를 유지하는 것이 좋습니다. 데이터 계층화는 미러링된 데이터를 저비용 오브젝트 스토리지로 계층화하여 로컬 디스크의 비용을 절감합니다. 관계를 끊거나 볼륨을 클론하면 데이터에 빠른 로컬 스토리지가 사용됩니다.</block>
  <block id="a7d9908d0f610b3db167c894d109d1ec" category="paragraph"><block ref="a7d9908d0f610b3db167c894d109d1ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f06f2f09c024b69ef3944a8cd78ad9" category="list-text">대상 볼륨 이름 선택: '[source_volume_name]_dr'을 선택했습니다.</block>
  <block id="6f8ba85bc89d216799431f124e48b25f" category="paragraph"><block ref="6f8ba85bc89d216799431f124e48b25f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2882a0dbc1a6ad74198ac2cb6316870d" category="list-text">복제에 대한 최대 전송 속도를 선택합니다. 따라서 VPN과 같이 클라우드에 대역폭이 낮은 경우 대역폭을 절약할 수 있습니다.</block>
  <block id="041263f562a9058ae414685962469951" category="paragraph"><block ref="041263f562a9058ae414685962469951" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f81dd66e0f0847d4cb1d2d12fadcc2f3" category="list-text">복제 정책을 정의합니다. 우리는 미러를 선택했습니다. 이 미러는 최신 데이터 세트를 가져와 타겟 볼륨에 복제합니다. 요구 사항에 따라 다른 정책을 선택할 수도 있습니다.</block>
  <block id="d0b86e2934c870915aaa77674d1d79d7" category="paragraph"><block ref="d0b86e2934c870915aaa77674d1d79d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4db5384e8d04b01ff24a9178b3efaf6a" category="list-text">복제를 트리거할 스케줄을 선택합니다. 요구사항에 따라 변경할 수 있지만 데이터 볼륨에 대한 "일별" 스케줄과 로그 볼륨에 대한 "시간별" 스케줄을 설정하는 것이 좋습니다.</block>
  <block id="c6715d4de4d68a1f8eb9cb8acb63b097" category="paragraph"><block ref="c6715d4de4d68a1f8eb9cb8acb63b097" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02e3a269661e3c96a86a075872a1b269" category="list-text">입력한 정보를 검토하고 이동을 클릭하여 클러스터 피어와 SVM 피어를 트리거한 다음(두 클러스터 간에 처음 복제하는 경우) SnapMirror 관계를 구축하고 초기화합니다.</block>
  <block id="75c2d297cd7282b30ce0400170110307" category="paragraph"><block ref="75c2d297cd7282b30ce0400170110307" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c160366cab97ee8f1a35416d1294ddb" category="list-text">데이터 볼륨 및 로그 볼륨에 대해 이 프로세스를 계속합니다.</block>
  <block id="64853c47f4f907262466c1e5ad154c8c" category="list-text">모든 관계를 확인하려면 Cloud Manager 내의 Replication 탭으로 이동합니다. 여기에서 관계를 관리하고 상태를 확인할 수 있습니다.</block>
  <block id="641e620fe8c714d7381775d20a707726" category="paragraph"><block ref="641e620fe8c714d7381775d20a707726" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c88bec52f9e24233a78b6a90efa32ec6" category="list-text">모든 볼륨이 복제된 후에는 안정적 상태가 되며 재해 복구 및 개발/테스트 워크플로우로 이동할 준비가 된 것입니다.</block>
  <block id="86fb3ee49ae2f8c0ee121c551a8f08c2" category="section-title">데이터베이스 워크로드에 EC2 컴퓨팅 인스턴스를 구축합니다</block>
  <block id="91ba52045df2b9244f28270482f749c9" category="inline-link">EC2 인스턴스 유형</block>
  <block id="33aaa72e62140af9cecb2c48f836b84b" category="paragraph">AWS는 다양한 워크로드를 위해 EC2 컴퓨팅 인스턴스를 사전 구성되어 있습니다. 인스턴스 유형 선택에 따라 CPU 코어 수, 메모리 용량, 스토리지 유형 및 용량, 네트워크 성능이 결정됩니다. 사용 사례의 경우, OS 파티션을 제외하고 데이터베이스 워크로드를 실행할 기본 스토리지가 CVO 또는 FSx ONTAP 스토리지 엔진에서 할당됩니다. 따라서 고려해야 할 주요 요소는 CPU 코어, 메모리 및 네트워크 성능 수준을 선택하는 것입니다. 일반적인 AWS EC2 인스턴스 유형은 여기에서 찾을 수 있습니다.<block ref="9334d5b9e602c5921b4f295f6041489b" category="inline-link-rx"></block>.</block>
  <block id="0af43c3d809d6e56a6a7a0d1ed039bbc" category="section-title">컴퓨팅 인스턴스 사이징</block>
  <block id="0b6e77aedd6bd733f979314fef2a98d7" category="list-text">필요한 워크로드를 기준으로 적합한 인스턴스 유형을 선택합니다. 고려해야 할 요소에는 지원할 비즈니스 트랜잭션 수, 동시 사용자 수, 데이터 세트 사이징 등이 포함됩니다.</block>
  <block id="c421d122321bec48d6b30858f4e7b515" category="inline-link">Amazon EC2</block>
  <block id="ed4b68006572e288530a2152f7fbe5fe" category="list-text">EC2 대시보드에서 EC2 인스턴스 구축을 시작할 수 있습니다. 정확한 배포 절차는 이 솔루션의 범위를 벗어납니다. 을 참조하십시오<block ref="3a5862dd365e3998013717e9cf118a9a" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="708991723f71fa1bd7b8081be442552c" category="section-title">Oracle 워크로드를 위한 Linux 인스턴스 구성</block>
  <block id="5c17b7d75ff16063f772234e1ea8eeb1" category="paragraph">이 섹션에는 EC2 Linux 인스턴스를 배포한 이후의 추가 구성 단계가 포함되어 있습니다.</block>
  <block id="39d786446455bb2b3017b793805fc902" category="list-text">SnapCenter 관리 도메인 내에서 이름 확인을 위해 DNS 서버에 Oracle 대기 인스턴스를 추가합니다.</block>
  <block id="385a2a4f5305fe5ce8017f18fb7eabd4" category="list-text">암호 없이 sudo 권한을 가진 SnapCenter OS 자격 증명으로 Linux 관리 사용자 ID를 추가합니다. EC2 인스턴스에서 SSH 암호 인증을 사용하여 ID를 활성화합니다. (기본적으로 EC2 인스턴스에서는 SSH 암호 인증 및 암호 없는 sudo가 해제되어 있습니다.)</block>
  <block id="a2b4677d7a72840a78373c600441681a" category="list-text">OS 패치, Oracle 버전 및 패치 등과 같은 온프레미스 Oracle 설치와 일치하도록 Oracle 설치를 구성합니다.</block>
  <block id="66b65364302a847feb2630bfd7974256" category="inline-link">Oracle 19c 자동화된 구축</block>
  <block id="fa470598a181c1ed905bace243e46aa3" category="list-text">NetApp Ansible DB 자동화 역할을 활용하여 데이터베이스 개발/테스트 및 재해 복구 사용 사례에 맞게 EC2 인스턴스를 구성할 수 있습니다. 자동화 코드는 NetApp 퍼블릭 GitHub 사이트에서 다운로드할 수 있습니다.<block ref="437f8b44ff65600fb5697e9d369a0c54" category="inline-link-rx"></block>. 목표는 사내 OS 및 데이터베이스 구성과 일치하도록 EC2 인스턴스에 데이터베이스 소프트웨어 스택을 설치 및 구성하는 것입니다.</block>
  <block id="97875b4799caf4c948118e7b4776c9fb" category="section-title">SQL Server 작업 부하에 대한 Windows 인스턴스 구성</block>
  <block id="c63751cfdcf8c0b4e26635a47c7f0d97" category="paragraph">이 섹션에는 EC2 Windows 인스턴스를 처음 구축한 이후의 추가 구성 단계가 나와 있습니다.</block>
  <block id="5f44e6a78874f9f49acae3caa71cc14d" category="list-text">RDP를 통해 인스턴스에 로그인하려면 Windows 관리자 암호를 검색합니다.</block>
  <block id="eabafc642b0901afd6622ab0f19d9ef0" category="list-text">Windows 방화벽을 비활성화하고, 호스트를 Windows SnapCenter 도메인에 연결하고, DNS 서버에 인스턴스를 추가하여 이름을 확인합니다.</block>
  <block id="08bf2d7ff3ac9ab37cfa8dc449b3c8da" category="list-text">SnapCenter 로그 볼륨을 프로비저닝하여 SQL Server 로그 파일을 저장합니다.</block>
  <block id="f97ac9d1946c873247af15165559b47a" category="list-text">Windows 호스트에서 iSCSI를 구성하여 볼륨을 마운트하고 디스크 드라이브를 포맷합니다.</block>
  <block id="6c2a9c611f48cae767f6ebea6fca0457" category="inline-link">NetApp 자동화</block>
  <block id="6dea6226167bd38268de4c4d948d72de" category="list-text">SQL Server용 NetApp 자동화 솔루션을 사용하면 이전 작업 중 많은 작업을 자동화할 수 있습니다. 새로 게시된 역할 및 솔루션은 NetApp 자동화 퍼블릭 GitHub 사이트 에서 확인할 수 있습니다.<block ref="8cafb3a3b1222d318fcd262791229701" category="inline-link-rx"></block>.</block>
  <block id="752c08adf364adb2721c9a373759f8f6" category="inline-link-macro">다음: 개발/테스트 환경의 클라우드 용량 증가를 위한 워크플로우</block>
  <block id="4e3fc3c2eb04754fcac9e4e23b6de054" category="paragraph"><block ref="4e3fc3c2eb04754fcac9e4e23b6de054" category="inline-link-macro-rx"></block></block>
  <block id="d0bb28dcc0cc1b523a41bbb46875db9e" category="summary">Cloud Manager 커넥터와 Cloud Volumes ONTAP를 설치하고 SnapMirror를 구성하기 전에 먼저 클라우드 환경에 대한 몇 가지 준비를 수행해야 합니다. 이 페이지에서는 수행해야 하는 작업과 Cloud Volumes ONTAP를 구축할 때의 고려 사항에 대해 설명합니다.</block>
  <block id="8c6fb9ece3bad11d3e76d1344d9ed9ab" category="doc">퍼블릭 클라우드의 사전 요구사항</block>
  <block id="ac7eeb8ecebe00daa1fdf4fd06cc46de" category="inline-link-macro">이전: 사전 요구 사항 온-프레미스.</block>
  <block id="70ba5e430ac8eade85f8e01e51412fe4" category="paragraph"><block ref="70ba5e430ac8eade85f8e01e51412fe4" category="inline-link-macro-rx"></block></block>
  <block id="5a2798d22185b0e40ea502bbbb171d38" category="section-title">Cloud Manager 및 Cloud Volumes ONTAP 구축 사전 요구 사항 체크리스트</block>
  <block id="1e094e6477be231098329b0096c7221f" category="list-text">NetApp Cloud Central 로그인</block>
  <block id="b59e275c4ece2430dff67db92845ab7f" category="list-text">웹 브라우저에서 여러 엔드포인트로 네트워크 액세스</block>
  <block id="d2ed5c7ede8a1ce9d218ec60b0f03935" category="list-text">커넥터의 네트워크 위치입니다</block>
  <block id="0d07862d67097acd517fe27c0de099d7" category="list-text">클라우드 공급자 권한</block>
  <block id="203802866ac2835e79bd76c94a3761c2" category="list-text">개별 서비스를 위한 네트워킹</block>
  <block id="c4d5e1cbdfc47a0fdcb4a1a9dddd9e17" category="inline-link">클라우드 문서</block>
  <block id="1a22a3f7b690b2ec8919c8806633fb26" category="paragraph">시작하는 데 필요한 사항에 대한 자세한 내용은 를 참조하십시오<block ref="247d95fa755d21bb8790cc6d7a2fc412" category="inline-link-rx"></block>.</block>
  <block id="ea61e2c2ff507048203824add1eb7c21" category="section-title">고려 사항</block>
  <block id="176ca67b83510a1281a4cfc749a3543a" category="section-title">Cloud Manager 커넥터란 무엇입니까?</block>
  <block id="1681641037afae45bd6074dcde9eed00" category="paragraph">대부분의 경우 Cloud Central 계정 관리자는 클라우드 또는 온-프레미스 네트워크에 커넥터를 배포해야 합니다. Connector를 사용하면 Cloud Manager에서 퍼블릭 클라우드 환경 내의 리소스 및 프로세스를 관리할 수 있습니다.</block>
  <block id="8a78be5d168f00b24bf1625de3d5409c" category="paragraph">커넥터에 대한 자세한 내용은 를 참조하십시오<block ref="f39c14bbbbdd46ca70a63fb06046c789" category="inline-link-rx"></block>.</block>
  <block id="fcc2bf38b8157a22b5fc6975b7054acc" category="section-title">2.Cloud Volumes ONTAP 사이징 및 아키텍처</block>
  <block id="1c09b5154aa1f43cb9ebcbd6fea5eadc" category="paragraph">Cloud Volumes ONTAP를 배포할 때 미리 정의된 패키지 또는 사용자 고유의 구성 생성 중에서 선택할 수 있습니다. 이러한 값 중 대부분은 중단 없이 변경할 수 있지만, 클라우드에 구축할 워크로드를 기반으로 구축하기 전에 결정해야 할 몇 가지 중요한 사항이 있습니다.</block>
  <block id="331ce28903aee0b30cd3c94e5483edf5" category="inline-link">CVO 사이징 툴</block>
  <block id="acaed5d74e38e1779b3831dcf51c7600" category="paragraph">각 클라우드 공급자마다 구축 옵션이 다르며, 워크로드에 따라 저마다 고유한 속성이 있습니다. NetApp에는 이 있습니다<block ref="6a71e7e42ab9335484c5530029f79b92" category="inline-link-rx"></block> 따라서 용량과 성능을 기준으로 구축 환경을 올바르게 사이징하는 데 도움이 될 수 있지만, 다음과 같은 몇 가지 기본 개념을 기반으로 구축되었습니다.</block>
  <block id="145c90afb7955854f2371e9decf3de9b" category="list-text">필요한 용량</block>
  <block id="f1521b662bf51f1af6c2d38bd610afae" category="list-text">클라우드 가상 머신의 네트워크 기능</block>
  <block id="f75d8ba5edc8017382d5df68baf9e30f" category="list-text">클라우드 스토리지의 성능 특성</block>
  <block id="af9d66ea3132fcfeb46b85557bc1af1b" category="paragraph">핵심은 현재의 용량 및 성능 요구사항을 충족할 뿐만 아니라 향후 성장을 내다보는 구성을 계획하는 것입니다. 이는 일반적으로 용량 여유 공간 및 성능 여유 공간 이라고 합니다.</block>
  <block id="4847e034bb0a55fcbc8a3380d6a3ab80" category="inline-link">설치하고</block>
  <block id="3a580f142203677f1f0bc30898f63f53" category="inline-link">Azure를 지원합니다</block>
  <block id="c731f72e1d22a7c5e01a7cb789a8885e" category="inline-link">GCP</block>
  <block id="180f0326dff3a03aecf5e184943d108a" category="paragraph">자세한 내용을 보려면 에 대한 계획에 대한 문서를 참조하십시오<block ref="af5d70b69c3436f8bcf6f7b9579c4e83" category="inline-link-rx"></block>,<block ref="c2e85b51d3015b4c720388e64a3de23e" category="inline-link-rx"></block>, 및<block ref="b1068926334a08925797774f64291db4" category="inline-link-rx"></block>.</block>
  <block id="c50ea1f0c6dcf02fbdd39e1e6b5befc2" category="section-title">3.단일 노드 또는 고가용성?</block>
  <block id="eadb13b9c72271dbf16967e78059fea4" category="paragraph">모든 클라우드에서 CVO를 단일 노드 또는 2개의 노드로 구성된 클러스터 고가용성 쌍에 구축할 수 있는 옵션이 있습니다. 사용 사례에 따라 비용 절감을 위해 단일 노드를 구축하거나 추가 가용성과 이중화를 제공하기 위해 HA 쌍을 구축할 수 있습니다.</block>
  <block id="9cbd119b18cd836b6020fcfd3bfbe37f" category="paragraph">DR 사용 사례 또는 개발 및 테스트를 위한 임시 스토리지 회전 시 갑작스러운 조널 또는 인프라 중단의 영향이 더 낮기 때문에 단일 노드가 일반적인 경우가 많습니다. 그러나 모든 운영 사용 사례에서 데이터가 단일 위치에만 있거나 데이터 세트에 더 많은 이중화 및 가용성이 필요할 경우 고가용성을 사용하는 것이 좋습니다.</block>
  <block id="83d2ad0cda1f71c52878284cc7c1f713" category="paragraph">각 클라우드 버전의 고가용성 아키텍처에 대한 자세한 내용은 의 설명서를 참조하십시오<block ref="4344469628657b2a6a0d147e5e6fbc9a" category="inline-link-rx"></block>,<block ref="28a8305eced80cb5b1351f5cffb268ae" category="inline-link-rx"></block> 및<block ref="1b945d178a8347e94e5c5456dc9e6db8" category="inline-link-rx"></block>.</block>
  <block id="f0d106c1997a933ecb53ee88e83670e7" category="inline-link-macro">다음: 시작하기 개요</block>
  <block id="fd43d07d375b44f30fde6995279b9265" category="paragraph"><block ref="fd43d07d375b44f30fde6995279b9265" category="inline-link-macro-rx"></block></block>
  <block id="64899c745691f41e5b1dc01d3a4487d2" category="summary">이 섹션에서는 클라우드에서 SQL Server와 함께 Azure NetApp Files를 사용할 때 고려해야 할 여러 가지 문제에 대해 설명합니다.</block>
  <block id="bb4695a70b92668f0a7927d04580db60" category="doc">고려해야 할 요소</block>
  <block id="4dd91c7652639dacea041fe6033e2627" category="section-title">VM 성능</block>
  <block id="e6ac657ee6eac68b739c5cc437863922" category="inline-link">메모리 최적화</block>
  <block id="68e5d4a238cdfe033afa141123484499" category="paragraph">공용 클라우드에서 관계형 데이터베이스의 성능을 최적화하려면 올바른 VM 크기를 선택하는 것이 중요합니다. 온프레미스 서버 환경의 SQL Server에 적용되는 것과 동일한 데이터베이스 성능 조정 옵션을 계속 사용하는 것이 좋습니다. 사용<block ref="187f54af8632f4f6696d6052e8b74aec" category="inline-link-rx"></block> SQL Server 워크로드에 가장 적합한 성능을 제공하는 VM 크기입니다. 기존 배포의 성능 데이터를 수집하여 올바른 인스턴스를 선택하는 동안 RAM 및 CPU 사용률을 식별합니다. 대부분의 배포는 D, E 또는 M 시리즈 중에서 선택합니다.</block>
  <block id="fcbd19b726fdd6160dfe2ab43f285a55" category="paragraph">* 참고: *</block>
  <block id="8b2db846b8ed65b2919d93a68b819a43" category="list-text">SQL Server 워크로드의 성능을 최적화하려면 메모리에 최적화된 VM 크기를 사용합니다.</block>
  <block id="32a3b4d7b7e6cf1ecde48636119e0288" category="list-text">NetApp과 Microsoft는 적절한 메모리 대 VCORE 비율을 갖는 인스턴스 유형을 선택하기 전에 스토리지 성능 요구 사항을 파악하기를 권장합니다. 또한 VM의 스토리지 처리량 제한을 극복하기 위해 적절한 네트워크 대역폭을 가진 낮은 인스턴스 유형을 선택하는 데도 도움이 됩니다.</block>
  <block id="0abdff1d9e33eca61c14ccafe8012cd5" category="section-title">VM 중복성</block>
  <block id="9fecd525b2d9ad39ac38bbfc4d05ee17" category="inline-link">사용 가능 여부 설정</block>
  <block id="26075dbb6cfad683e0d9bd0d29c570b8" category="inline-link">가용성 영역</block>
  <block id="e936e004eab3eccfc1e7f46a3187dfd1" category="paragraph">중복성과 고가용성을 높이려면 SQL Server VM이 같아야 합니다<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> 또는 다른<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. Azure VM을 생성할 때 가용성 세트 구성과 가용성 영역 중 하나를 선택해야 합니다. Azure VM은 두 영역에 모두 참여할 수 없습니다.</block>
  <block id="05807e454c19f244770adae059b3c330" category="section-title">고가용성</block>
  <block id="94eeeae1e60f97a446e8c4f69d6d6f43" category="paragraph">고가용성을 위해 SQL Server AOAG 또는 FCI(Always On Failover Cluster Instance)를 구성하는 것이 가장 좋습니다. AOAG의 경우 가상 네트워크의 Azure 가상 머신에 있는 SQL Server의 여러 인스턴스가 포함됩니다. 데이터베이스 수준에서 고가용성이 필요한 경우 SQL Server 가용성 그룹을 구성하는 것이 좋습니다.</block>
  <block id="6e8775bd755a8835ce86806d669677ea" category="section-title">스토리지 구성</block>
  <block id="fa32aac4116ce1980c311f004157a133" category="paragraph">Microsoft SQL Server를 SMB 파일 공유와 함께 스토리지 옵션으로 구축할 수 있습니다. SQL Server 2012, 시스템 데이터베이스(master, model, msdb 또는 tempdb), 사용자 데이터베이스는 SMB(Server Message Block) 파일 서버와 함께 스토리지 옵션으로 설치할 수 있습니다. 이는 SQL Server 독립 실행형 및 SQL Server FCI 모두에 적용됩니다.</block>
  <block id="250548ef00796e6a203215b1d550bb0d" category="admonition">SQL Server 데이터베이스용 파일 공유 스토리지는 지속적인 사용 가능 속성을 지원해야 합니다. 따라서 파일 공유 데이터에 중단 없이 액세스할 수 있습니다.</block>
  <block id="ba110408cece764b57b56f1129b3ba2e" category="inline-link">Azure NetApp Files for SQL Server 구축의 이점</block>
  <block id="45a6af9c92529e3da9ccdbeae9d692ac" category="paragraph">Azure NetApp Files는 까다로운 작업 부하를 모두 충족할 수 있는 고성능 파일 스토리지를 제공하며 블록 스토리지 솔루션과 비교하여 SQL Server TCO를 줄입니다. 블록 스토리지에서 VM은 디스크 작업에 대해 I/O 및 대역폭에 제한을 가했으며 네트워크 대역폭 제한만 Azure NetApp Files에 적용됩니다. 즉, Azure NetApp Files에는 VM 레벨의 I/O 제한이 적용되지 않습니다. 이러한 I/O 제한이 없다면 Azure NetApp Files에 연결된 소규모 VM에서 실행되는 SQL Server는 물론 훨씬 큰 VM에서 실행되는 SQL Server도 수행할 수 있습니다. Azure NetApp Files는 컴퓨팅 및 소프트웨어 라이센싱 비용을 줄여 SQL Server 구축 비용을 절감합니다. SQL Server 배포용으로 Azure NetApp Files를 사용할 때의 비용 분석 및 성능 이점에 대한 자세한 내용은 를 참조하십시오<block ref="458fda910151e8d66385b2aabb6cd60e" category="inline-link-rx"></block>.</block>
  <block id="9d2b7eb8bc76e60b0d9cd237d67a34fb" category="paragraph">SQL Server용 Azure NetApp Files를 사용하면 다음과 같은 이점이 있습니다.</block>
  <block id="8ee22743237d82e9adc18a596977a138" category="list-text">Azure NetApp Files를 사용하면 더 작은 인스턴스를 사용할 수 있으므로 컴퓨팅 비용이 절감됩니다.</block>
  <block id="3de639403ea86ae87a5883d359deb4ab" category="list-text">또한 Azure NetApp Files는 소프트웨어 라이센스 비용을 줄여 전체 TCO를 절감합니다.</block>
  <block id="46790c8fe72176f6262b4b5531482ee5" category="list-text">볼륨에 대한 재구성 및 동적 서비스 수준 기능은 안정적인 워크로드 사이징과 오버 프로비저닝을 방지하여 비용을 최적화합니다.</block>
  <block id="860d93b2ef30525111fa6440bf4d5bd7" category="list-text">중복성과 고가용성을 높이려면 SQL Server VM이 같아야 합니다<block ref="47fe032b9b8e985355e53596ae7973ec" category="inline-link-rx"></block> 또는 다른 방식으로<block ref="ef39442dc7c0eb954c4472567a9ca1e3" category="inline-link-rx"></block>. 사용자 정의 데이터 파일이 필요한 경우 파일 경로 요구 사항을 고려합니다. 이 경우 SQL AOAG 대신 SQL FCI를 선택합니다.</block>
  <block id="c6fbfcd868e29e37e88eaeff82a7f430" category="inline-link">ANFSMB-b4ca.anf.test\SQLDB 및\\ANFSMB-b4ca.anf.test\SQLDB\</block>
  <block id="e2bed4e218692d056237b3ae3d24293c" category="list-text">다음 UNC 경로가 지원됩니다.<block ref="cb8cdd6ee3ebeed12086142f1a66cc3e" category="inline-link-rx"></block>.</block>
  <block id="0b4d3828f5dae91cd27e48bffa786d91" category="list-text">루프백 UNC 경로는 지원되지 않습니다.</block>
  <block id="db3d2f4f54b992af225801eb51ea7387" category="list-text">사이징의 경우 사내 환경의 기존 데이터를 사용하십시오. OLTP 워크로드의 경우 디스크 읽기/초 및 디스크 쓰기/초 성능 카운터와 함께 평균 및 최대 사용 시간에 워크로드를 사용하여 성능 요구 사항에 맞는 타겟 IOPS를 제공합니다. 데이터 웨어하우스 및 보고 워크로드의 경우 평균 및 최대 시간에 워크로드를 사용하여 목표 처리량과 디스크 읽기 바이트/초 및 디스크 쓰기 바이트/초를 일치시킵니다 평균 값은 볼륨 재구성 기능과 함께 사용할 수 있습니다.</block>
  <block id="da3259c6aa3dafdc8ca15c687022a5cd" category="section-title">지속적으로 사용 가능한 공유를 생성합니다</block>
  <block id="f7ee3eee4fa679986e37911272d13a29" category="inline-link">지속적으로 사용 가능한 공유 생성</block>
  <block id="de7d92d6f4ac1f140ac05886ec017f09" category="paragraph">Azure Portal 또는 Azure CLI를 통해 지속적으로 사용 가능한 공유를 생성합니다. 포털에서 지속적인 가용성 사용 속성 옵션을 선택합니다. Azure CLI의 경우 '$True'로 설정된 SMB-Continuously-aVL을 사용하여 생성한 az netapfile volume을 사용하여 공유를 지속적으로 사용 가능한 공유로 지정합니다. 지속적인 가용성을 지원하는 새 볼륨을 생성하는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="86e4b436e8054cc83fccec640f98e218" category="inline-link-rx"></block>.</block>
  <block id="9a3932b7bdfdbb892087fd595ec7acb9" category="list-text">다음 이미지와 같이 SMB 볼륨에 대한 지속적인 가용성을 설정합니다.</block>
  <block id="c012fe8c05a3d9875a4f87cee09d1ca9" category="list-text">관리자가 아닌 도메인 계정을 사용하는 경우 계정에 필요한 보안 권한이 할당되었는지 확인합니다.</block>
  <block id="762783478495f0889d01a59db256f92c" category="list-text">공유 수준에서 적절한 사용 권한과 적절한 파일 수준 사용 권한을 설정합니다.</block>
  <block id="bfb74db6a55528f52e8ecb83a507a043" category="inline-link">기존 SMB 볼륨을 무중단 가용성을 사용하도록 변환</block>
  <block id="3cad4a4fcd378074292bfc2ff45fd4ca" category="list-text">기존 SMB 볼륨에서 지속적으로 사용 가능한 속성을 설정할 수 없습니다. 기존 볼륨을 변환하여 지속적으로 사용 가능한 공유를 사용하려면 NetApp Snapshot 기술을 사용하십시오. 자세한 내용은 을 참조하십시오<block ref="25dc0603f84029cfd15a97a37903a54c" category="inline-link-rx"></block>.</block>
  <block id="015dd90c833178044ff327aee63f72ec" category="paragraph"><block ref="015dd90c833178044ff327aee63f72ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9446a98ad14416153cc4d45ab8b531bf" category="section-title">성능</block>
  <block id="ee38206503545cf54ad072dee7f8ab1a" category="paragraph">Azure NetApp Files는 Standard(테라바이트당 16MBps), Premium(테라바이트당 64MBps), Ultra(테라바이트당 128MBps)의 세 가지 서비스 수준을 지원합니다. 데이터베이스 워크로드의 성능을 최적화하려면 적절한 볼륨 크기를 프로비저닝하는 것이 중요합니다. Azure NetApp Files에서는 다음과 같은 요소의 조합을 기반으로 볼륨 성능과 처리량 제한이 있습니다.</block>
  <block id="b87f5218989e854f2889f939a4e2ec06" category="list-text">볼륨이 속한 용량 풀의 서비스 수준입니다</block>
  <block id="9320cce40e9ab4d677bfcc78eddc64d5" category="list-text">볼륨에 할당된 할당량입니다</block>
  <block id="2d98af90367bed299b95066a85be0a17" category="list-text">용량 풀의 서비스 품질(QoS) 유형(자동 또는 수동</block>
  <block id="a6f08c2897faaf4d449d71d87f473ff1" category="inline-link">Azure NetApp Files의 서비스 레벨</block>
  <block id="ac56170d8576092b90989d467f2d383e" category="paragraph">자세한 내용은 을 참조하십시오<block ref="1e8ed0f384e427209ce2e9dfbaed249d" category="inline-link-rx"></block>.</block>
  <block id="79bcc7c0be7625b4b6b95ac8189ec45e" category="paragraph"><block ref="79bcc7c0be7625b4b6b95ac8189ec45e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb24bd760e508043a3cfdfe91ba9489" category="section-title">성능 검증</block>
  <block id="af3948d0fe6860f3a865cd04abebc009" category="inline-link">SQL Server 저장 벤치마크(SB) 도구</block>
  <block id="01384acc34d886b9383610a7494ca75a" category="paragraph">다른 구현 기능과 마찬가지로 VM 및 스토리지를 테스트하는 것이 중요합니다. 스토리지 검증의 경우 HammerDB, Apploader, 등의 도구가 필요합니다<block ref="df8d6ca8d2831e94c0812b2b971f8958" category="inline-link-rx"></block>또는 적절한 읽기/쓰기 혼합이 있는 사용자 지정 스크립트 또는 FIO를 사용해야 합니다. 그러나 대부분의 SQL Server 워크로드는 OLTP 워크로드가 많을 때에도 80%–90% 읽기, 10%–20% 쓰기에 더 가깝습니다.</block>
  <block id="10fde396dd4a669ec17689dd7cf8b599" category="paragraph">성능을 보여주기 위해 프리미엄 서비스 수준을 사용하여 볼륨에 대해 빠른 테스트를 수행했습니다. 이 테스트에서는 애플리케이션 액세스와 데이터 마이그레이션 없이 볼륨 크기가 100GB에서 2TB로 즉석에서 증가했습니다.</block>
  <block id="6fab14b7b6a90422e865a3b09497edaa" category="paragraph"><block ref="6fab14b7b6a90422e865a3b09497edaa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eedfe317eed7692e9d95ba36177a80e9" category="paragraph">이 백서에서 다룬 구축을 위해 HammerDB를 사용하여 실시간 성능 테스트를 수행한 또 다른 예를 살펴보겠습니다. 이 테스트에서는 vCPU 8개, 500GB 프리미엄 SSD, 500GB SMB Azure NetApp Files 볼륨이 포함된 작은 인스턴스를 사용했습니다. HammerDB는 80개의 웨어하우스와 8명의 사용자로 구성되었습니다.</block>
  <block id="c365893719ad3de45f14fa9c19408eca" category="paragraph">다음 차트는 Azure NetApp Files이 비슷한 크기의 볼륨(500GB)을 사용할 때 4배 더 낮은 지연 시간으로 분당 2.6배의 트랜잭션 수를 제공할 수 있음을 보여 줍니다.</block>
  <block id="d50d666921da97fdc14e35f752474e41" category="paragraph">32x vCPU 및 16TB Azure NetApp Files 볼륨으로 더 큰 인스턴스로 크기를 조정하여 추가 테스트를 수행했습니다. 1ms 지연 시간의 일관적 으로 분당 트랜잭션 수가 크게 증가했습니다. HammerDB는 이 테스트를 위해 80개의 웨어하우스와 64명의 사용자로 구성되었습니다.</block>
  <block id="3b38e0407e747349840c72259c5da930" category="paragraph"><block ref="3b38e0407e747349840c72259c5da930" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a39ae09f8be4327fc176cfeb76a0e366" category="section-title">비용 최적화</block>
  <block id="892725223bbd64ebec595545eeaf8c28" category="paragraph">Azure NetApp Files를 사용하면 투명한 볼륨 크기 조정 및 서비스 수준 변경 기능을 다운타임 없이 애플리케이션에 영향을 주지 않습니다. 이 기능은 최대 메트릭으로 데이터베이스 사이징을 수행할 필요가 없는 동적 비용 관리를 가능하게 하는 고유한 기능입니다. 대신, 안정적인 상태의 워크로드를 사용하여 초기 비용을 방지할 수 있습니다. 볼륨 재구성 및 동적 서비스 수준 변경을 통해 데이터 액세스를 유지하면서 I/O를 일시 중지하지 않고 필요 시 Azure NetApp Files 볼륨의 대역폭과 서비스 수준을 거의 즉시 조정할 수 있습니다.</block>
  <block id="44aaafbc17f2a4fcbd6d52e1c8ee0cae" category="paragraph">LogicApp 또는 기능과 같은 Azure PaaS 오퍼링을 사용하면 특정 웹 후크 또는 경고 규칙 트리거를 기반으로 볼륨 크기를 쉽게 조정할 수 있으므로 비용을 동적으로 처리하면서 워크로드 수요를 충족할 수 있습니다.</block>
  <block id="d613d5e1ef7a7f52eed191ef1066a08a" category="paragraph">예를 들어, 안정적인 상태 작업을 위해 250MBps가 필요한 데이터베이스를 예로 들어 보겠습니다. 하지만 이 데이터베이스에는 400Mbps의 피크 처리량도 필요합니다. 이 경우 정상 상태 성능 요구사항을 충족하려면 Premium 서비스 레벨 내에서 4TB 볼륨을 사용하여 구축을 수행해야 합니다. 최대 사용 워크로드를 처리하기 위해 Azure 기능을 사용할 경우 특정 기간 동안 볼륨 크기를 7TB로 늘리고, 볼륨 크기를 줄여 구축이 비용 효율적입니다. 이렇게 구성하면 스토리지의 오버 프로비저닝이 방지됩니다.</block>
  <block id="47373f46adef617d17665b0b94be8f67" category="paragraph">로그 복제 플레이북 예약</block>
  <block id="2c777d857235f251004d6d8d70c9751d" category="list-text">이전에 생성한 작업 템플릿을 복사합니다.</block>
  <block id="3624b34cb634949984bcb28c79fd327f" category="list-text">리소스 → 템플릿 으로 이동합니다.</block>
  <block id="1eb977b1f69b531db931e9c62c1a0de9" category="list-text">ONTAP/CVO 설정 템플릿을 찾은 후 Copy Template을 마우스 오른쪽 버튼으로 클릭합니다</block>
  <block id="048f2ee27b8617cb0e13b6a0b7da956f" category="list-text">복사된 템플릿에서 템플릿 편집 을 클릭하고 이름을 로그 복제 플레이북 으로 변경합니다.</block>
  <block id="b07fb736e8c17cea7e9e3753e7a67fd1" category="list-text">템플릿에 대해 동일한 재고, 프로젝트, 자격 증명을 유지합니다.</block>
  <block id="d4a86123c8e623e35eaa51ab9583e03b" category="list-text">실행할 플레이북으로 ora_replication_logs.yml을 선택합니다.</block>
  <block id="69fa06239fd734936aac1af5250c7f57" category="list-text">변수는 동일하게 유지되지만 CVO 클러스터 IP는 dst_cluster_ip 변수에 설정되어야 합니다.</block>
  <block id="7557bd62e953fb4d48f07977151ea94f" category="list-text">저장 을 클릭합니다.</block>
  <block id="ec7445bbcbadd1f11fe1bc3e5e56eef9" category="list-text">작업 템플릿을 예약합니다.</block>
  <block id="d6e504930da1d0732ea4162514a38e8e" category="list-text">Log Replication Playbook 템플릿을 클릭한 다음 최상위 옵션 집합에서 Schedules를 클릭합니다.</block>
  <block id="1c03188c731004905466903c2eb763c4" category="list-text">추가, 로그 복제에 대한 이름 스케줄 추가, 시간 시작 시 시작 날짜/시간 선택, 로컬 시간대 선택 및 실행 빈도 를 차례로 클릭합니다. 실행 빈도는 대개 SnapMirror 복제가 업데이트됩니다.</block>
  <block id="d23bfe090a9fd09613c7a6573f619c02" category="admonition">마지막 1시간 단위 업데이트까지 복구할 수 있도록 매 시간마다 업데이트되도록 로그 스케줄을 설정하는 것이 좋습니다.</block>
  <block id="6551468cb4811e7add616eea103efea9" category="doc">단계별 배포 절차</block>
  <block id="261e91a1afdfe1123497b1b9ba5ab3e1" category="section-title">AWX/Tower Oracle 데이터 보호</block>
  <block id="32003b051ef9368756d1e9cd79796719" category="section-title">환경의 인벤토리, 그룹, 호스트 및 자격 증명을 생성합니다</block>
  <block id="2c8b94d570dd5a63a27d112e32a1c799" category="paragraph">이 섹션에서는 NetApp 자동화 솔루션을 사용하는 환경을 준비하기 위해 AWX/Ansible 타워에서 인벤토리, 그룹, 호스트, 액세스 자격 증명을 설정하는 방법을 설명합니다.</block>
  <block id="134d501fee5367069f0746f15302ce1f" category="list-text">인벤토리를 구성합니다.</block>
  <block id="af2c7dd4ecef5e42e9bc8f88213d51d9" category="list-text">Resources(리소스) → Inventory(인벤토리) → Add(추가) 로 이동하고 Add Inventory(재고 추가) 를 클릭합니다.</block>
  <block id="56fc26ef1c8ae54dced3529eec65fa26" category="list-text">이름 및 조직 세부 정보를 입력하고 저장 을 클릭합니다.</block>
  <block id="fe0981da08a8d2f4fed2006bafd9fb30" category="list-text">재고 페이지에서 생성된 재고를 클릭합니다.</block>
  <block id="65d119ae335d9e7c9c798b3e6db1b2d0" category="list-text">Groups 하위 메뉴로 이동하여 Add를 클릭합니다.</block>
  <block id="db2b28449b6d868d910cd53527934988" category="list-text">첫 번째 그룹에 대해 Oracle 이름을 입력하고 저장 을 클릭합니다.</block>
  <block id="200e1fa09608b23de5cd04d22d3a5bdb" category="list-text">DR_ORACLE이라는 두 번째 그룹에 대해 이 프로세스를 반복합니다.</block>
  <block id="1e29c17b60e9145858da82263315e402" category="list-text">생성된 Oracle 그룹을 선택하고 Hosts 하위 메뉴로 이동한 다음 Add New Host를 클릭합니다.</block>
  <block id="250d5368537e295251f9ccf63f950087" category="list-text">소스 Oracle 호스트 관리 IP의 IP 주소를 제공하고 Save를 클릭합니다.</block>
  <block id="22dcd973cf7a10ed9d03c5b959e65807" category="list-text">DR_Oracle 그룹에 대해 이 프로세스를 반복하고 DR/대상 Oracle 호스트의 관리 IP/호스트 이름을 추가해야 합니다.</block>
  <block id="1a4eca6a53be80f21117669b80a5dbc8" category="admonition">다음은 ONTAP 온프레미스 또는 AWS의 CVO에 대한 자격 증명 유형 및 자격 증명을 생성하는 지침입니다.</block>
  <block id="cea575677c47839fde1e59dbfc9ad5bb" category="open-title">사내</block>
  <block id="c4053f20c3fe50fe899484a64367439e" category="list-text">자격 증명을 구성합니다.</block>
  <block id="50d33cb309a9ea4bacb0a5541498b670" category="list-text">자격 증명 형식을 만듭니다. ONTAP와 관련된 솔루션의 경우 자격 증명 유형을 사용자 이름 및 암호 항목과 일치하도록 구성해야 합니다.</block>
  <block id="c87e3da0a9f8d5eeacea4eac9bef80ea" category="list-text">Administration → Credential Types로 이동한 후 Add를 클릭합니다.</block>
  <block id="e6bf632438290fdf98265b2b18943118" category="list-text">이름과 설명을 입력합니다.</block>
  <block id="5f5a0974b600f86bd4e77595282fcf70" category="list-text">입력 구성에 다음 내용을 붙여 넣습니다.</block>
  <block id="c048e95ab07253cc1cb87bef130c410b" category="list-text">Injector Configuration(주입기 구성)에 다음 내용을 붙여넣고 Save(저장)를 클릭합니다.</block>
  <block id="9302fe5c60a983a24bb8787c00db4862" category="list-text">ONTAP에 대한 자격 증명을 생성합니다</block>
  <block id="41dcc8a8aaaa79a511ba0ab4e6bde225" category="list-text">Resources → Credentials로 이동한 후 Add를 클릭합니다.</block>
  <block id="0a0aab79fb5a20fa5f830947226ef87c" category="list-text">ONTAP 자격 증명에 대한 이름과 조직 세부 정보를 입력합니다</block>
  <block id="81999e930ad44af27e84682c3ea1e750" category="list-text">이전 단계에서 만든 자격 증명 유형을 선택합니다.</block>
  <block id="1546222d368538c25b5704b5fcf160f5" category="list-text">유형 세부 정보 에서 소스 및 대상 클러스터에 대한 사용자 이름 및 암호를 입력합니다.</block>
  <block id="c4be718383c8ca0aa17633d911fc38fd" category="list-text">저장 을 클릭합니다</block>
  <block id="39f6f9fe82cbf0c0970d13b6a043ad84" category="list-text">Oracle에 대한 자격 증명을 생성합니다</block>
  <block id="30d4be106e7fb63befec4c8c7c815ad0" category="list-text">Oracle의 이름 및 조직 세부 정보를 입력합니다</block>
  <block id="9ef3fcc446a5f500717f9b5e9291bce4" category="list-text">시스템 자격 증명 유형을 선택합니다.</block>
  <block id="9fadc5c4eed350a8a1423628227dad59" category="list-text">유형 세부 정보 에서 Oracle 호스트의 사용자 이름 및 암호를 입력합니다.</block>
  <block id="b4ca3125325138b1dbfc309e6bd67b80" category="list-text">올바른 권한 에스컬레이션 방법을 선택하고 사용자 이름과 암호를 입력합니다.</block>
  <block id="61d6c643401e4a602f3c8b4b6fc0a93c" category="list-text">DR_Oracle 호스트에 대해 다른 자격 증명에 대해 필요한 경우 프로세스를 반복합니다.</block>
  <block id="f7fc367b5de87581ac78fc80805439af" category="open-title">CVO</block>
  <block id="61efb6ce79debd57f1e5eb28b08f94ba" category="list-text">자격 증명 유형을 만듭니다. ONTAP와 관련된 솔루션의 경우 자격 증명 유형을 사용자 이름 및 암호 항목과 일치하도록 구성해야 합니다. 또한 Cloud Central 및 AWS에 대한 항목을 추가합니다.</block>
  <block id="b95cd128bfca5d5c9181a46d0392c360" category="list-text">Injector Configuration(주입기 구성)에 다음 내용을 붙여넣고 Save(저장)를 클릭합니다.</block>
  <block id="75f3f97810b5eef177a5355b86dabfd0" category="list-text">ONTAP/CVO/AWS에 대한 자격 증명을 생성합니다</block>
  <block id="68085bee9e04417d4d9e74101a357a22" category="list-text">유형 세부 정보 아래에 소스 및 CVO 클러스터, Cloud Central/Manager, AWS 액세스/비밀 키 및 Cloud Central 업데이트 토큰의 사용자 이름 및 암호를 입력합니다.</block>
  <block id="922922f515b0ac072e20128999512b50" category="list-text">Oracle에 대한 자격 증명 생성(소스)</block>
  <block id="7ebca140d5dcaa006aeda44b19cfc52e" category="list-text">Oracle 호스트의 이름 및 조직 세부 정보를 입력합니다</block>
  <block id="ca530facf78f2112c60ee838d85b9b5b" category="list-text">Oracle Destination에 대한 자격 증명을 생성합니다</block>
  <block id="063e8368b0de123266b00f2c88e317fb" category="list-text">DR Oracle 호스트의 이름 및 조직 세부 정보를 입력합니다</block>
  <block id="0d28c8cc8415971cf2cd02507176bf94" category="list-text">세부 정보 유형 에 사용자 이름(EC2-USER 또는 기본값에서 변경한 경우 해당 입력) 및 SSH 개인 키를 입력합니다</block>
  <block id="cb8f433dfb62a17f7a02f4d7a8839b1c" category="list-text">올바른 권한 에스컬레이션 방법(sudo)을 선택하고 필요한 경우 사용자 이름과 암호를 입력합니다.</block>
  <block id="51b04d83367483575e89740841d94262" category="section-title">프로젝트를 만듭니다</block>
  <block id="e56fa1e2655db1bc7664a00295bd62a2" category="list-text">Resources → Projects로 이동하여 Add를 클릭합니다.</block>
  <block id="9c78f8d8687776e79018ded982e14c25" category="list-text">이름 및 조직 세부 정보를 입력합니다.</block>
  <block id="4096a1870a258e9d46585f08d4906f21" category="list-text">소스 제어 자격 증명 유형 필드에서 Git 를 선택합니다.</block>
  <block id="791ef966f9be349751448b9066bdd8fa" category="list-text">를 입력합니다 <block ref="1881636a0f344e587cc2202e2db4c5ac" category="inline-link-rx"></block> 소스 제어 URL입니다.</block>
  <block id="99bc2ea435ea8ae0ed38ef3051a4350a" category="list-text">소스 코드가 변경되면 프로젝트를 가끔 동기화해야 할 수 있습니다.</block>
  <block id="e5cac740ce6bd43e6ff83881e150d0f3" category="paragraph">이 섹션에 정의된 변수는 모든 Oracle 호스트, 데이터베이스 및 ONTAP 클러스터에 적용됩니다.</block>
  <block id="87b55102ec2889891b0258253b739244" category="list-text">다음 임베디드 글로벌 변수 또는 VAR 양식에 환경별 매개 변수를 입력합니다.</block>
  <block id="93be2ec6954884b83ac9df8117967949" category="admonition">파란색 항목은 환경에 맞게 변경해야 합니다.</block>
  <block id="285a3bb8fb6f692046facadb3c0984cf" category="paragraph">4개의 개별 플레이북을 실행해야 합니다.</block>
  <block id="37472723bc7712fedddee6d02e29228d" category="list-text">온프레미스 또는 CVO 환경 설정을 위한 플레이북</block>
  <block id="5138c89250c5086accf2d1a5961c9b17" category="list-text">Oracle 바이너리 및 데이터베이스 복제를 위한 일정 계획</block>
  <block id="3e552d6e5b2c316c63eb1fc2081d42a8" category="list-text">일정에 따라 Oracle 로그를 복제하는 데 필요한 Playbook</block>
  <block id="33f4f1514dc2ceb963af16685f4de58c" category="list-text">타겟 호스트에서 데이터베이스를 복구하는 플레이북입니다</block>
  <block id="17ae7167fac3c2364c6ad7b58819a920" category="open-title">ONTAP/CVO 설정</block>
  <block id="cc335cb73dc47f7a9b404288e3b4330f" category="paragraph">ONTAP 및 CVO 설정</block>
  <block id="b1171f0b44b8d9b11ac555972ebc8c3b" category="list-text">작업 템플릿을 작성합니다.</block>
  <block id="0fd181172a82ebe5219e9a30e5d97c0d" category="list-text">Resources → Templates → Add로 이동하여 Add Job Template을 클릭합니다.</block>
  <block id="6bc14a28f101e9d80ecc643ef13ef7fb" category="list-text">ONTAP/CVO 설정의 이름을 입력합니다</block>
  <block id="a7244f663b97629084f004e6c89b4a75" category="list-text">작업 유형을 선택합니다. 실행 은 Playbook을 기반으로 시스템을 구성합니다.</block>
  <block id="daefcb84cec2b58089094a64cefb845f" category="list-text">Playbook의 해당 인벤토리, 프로젝트, 플레이북 및 자격 증명을 선택합니다.</block>
  <block id="57344b3bd58c0e451513e303e45d49b7" category="list-text">사내 환경의 경우 ONTAP_setup.yml 플레이북을 선택하고 CVO 인스턴스로 복제할 때 cvo_setup.yml을 선택합니다.</block>
  <block id="ce150ce9cfe145db199958e7cd2ecce0" category="list-text">4단계에서 복사한 글로벌 변수를 YAML 탭의 템플릿 변수 필드에 붙여 넣습니다.</block>
  <block id="31e2568c13fbdaaad088eb3b665dea9d" category="list-text">작업 템플릿을 시작합니다.</block>
  <block id="56ae7378358ba2b1c55c47283f544991" category="list-text">원하는 템플릿을 클릭한 다음 실행을 클릭합니다.</block>
  <block id="41c1d72990c270d0221458749497c3e6" category="admonition">이 템플릿을 사용하여 다른 Playbook에 복사할 것입니다.</block>
  <block id="16f928d0ebd67060f6b3b2abf0481928" category="open-title">바이너리 및 데이터베이스 볼륨의 복제입니다</block>
  <block id="ea490901c403ce2b2a89f80227d0fb90" category="paragraph">바이너리 및 데이터베이스 복제 플레이북 예약</block>
  <block id="3c96e57d33780bedfb652def025f39de" category="list-text">복사된 템플릿에서 템플릿 편집 을 클릭하고 이름을 바이너리 및 데이터베이스 복제 플레이북으로 변경합니다.</block>
  <block id="f42c6e71dcb07b403b8393d5ab7f7fe4" category="list-text">실행할 플레이북으로 ora_replication_cg.yml을 선택합니다.</block>
  <block id="ce0d20e65f0354847807516cbcc696f6" category="list-text">바이너리 및 데이터베이스 복제 플레이북 템플릿을 클릭한 다음, 최상위 옵션 세트에서 일정을 클릭합니다.</block>
  <block id="d9a6405dc4a6cd71f6d77c749070a5e6" category="list-text">추가 를 클릭하고 바이너리 및 데이터베이스 복제에 대한 이름 일정 추가 를 클릭한 다음 시간 시작 시 시작 날짜/시간을 선택하고 로컬 표준 시간대를 선택한 다음 실행 빈도 를 선택합니다. 실행 빈도는 대개 SnapMirror 복제가 업데이트됩니다.</block>
  <block id="2dc4dec75c83aeb010419dc2a02da40b" category="admonition">로그 볼륨 복제에 대해 별도의 일정이 생성되므로 보다 빈번한 케이던스로 복제할 수 있습니다.</block>
  <block id="b723f9a72bec39ac17d89e51ff0ba336" category="open-title">로그 볼륨의 복제입니다</block>
  <block id="f76dbca531ab83300165aacf97e1b7ff" category="open-title">데이터베이스 복원 및 복구</block>
  <block id="8e43fbf8e210fdbb3e1d59ca59cde628" category="list-text">복사된 템플릿에서 템플릿 편집 을 클릭하고 이름을 복원 및 복구 Playbook 으로 변경합니다.</block>
  <block id="42f2159b893bbf4b6bf098ba9a026a1c" category="list-text">실행할 플레이북으로 ora_recovery.yml을 선택합니다.</block>
  <block id="0a3fe9b740fe79971ae2379eaec4822c" category="admonition">이 플레이북은 원격 사이트에서 데이터베이스를 복원할 준비가 될 때까지 실행할 수 없습니다.</block>
  <block id="b8a177e5fd059f33473cad4d1d073d38" category="list-text">사내 운영 Oracle 데이터베이스 데이터 볼륨은 NetApp SnapMirror 복제를 통해 2차 데이터 센터의 이중 ONTAP 클러스터나 퍼블릭 클라우드의 Cloud Volume ONTAP로 보호됩니다. 완전히 구성된 재해 복구 환경에서는 2차 데이터 센터 또는 퍼블릭 클라우드의 복구 컴퓨팅 인스턴스가 대기 상태이며 재해 발생 시 운영 데이터베이스를 복구할 수 있는 준비가 되어 있습니다. 대기 컴퓨팅 인스턴스는 OS 커널 패치에서 parellel 업데이트를 실행하거나 잠금 단계에서 업그레이드를 실행하여 온프레미스 인스턴스와 동기화된 상태를 유지합니다.</block>
  <block id="57d8ad774cb4fef3d53ee8836bfee761" category="list-text">이 솔루션에서 Oracle 바이너리 볼륨은 타겟 인스턴스에 복제되어 타겟 인스턴스에 마운트하여 Oracle 소프트웨어 스택을 실행하는 것으로 나타났습니다. Oracle을 복구하는 이러한 접근 방식은 재해가 발생한 마지막 순간에 Oracle을 새로 설치하는 데 비해 많은 이점을 제공합니다. 이 제품은 Oracle 설치가 현재 온프레미스 프로덕션 소프트웨어 설치 및 패치 수준 등과 완벽하게 동기화되도록 보장합니다. 그러나 소프트웨어 라이센스가 Oracle과 어떻게 구성되어 있는지에 따라 복구 사이트에서 복제된 Oracle 바이너리 볼륨에 대한 소프트웨어 라이센스가 추가로 부여되거나 적용되지 않을 수 있습니다. 사용자는 동일한 접근 방식을 사용하기 전에 소프트웨어 라이센스 담당자에게 잠재적인 Oracle 라이센스 요구 사항을 평가하는 것이 좋습니다.</block>
  <block id="74eaa493ffed695592003e0844d93c46" category="list-text">대상의 대기 Oracle 호스트는 Oracle 필수 구성 요소 구성으로 구성됩니다.</block>
  <block id="0be4357ac224d44b11800179b23eb202" category="list-text">SnapMirror가 손상되고 볼륨이 쓰기 가능으로 만들어져 대기 Oracle 호스트에 마운트됩니다.</block>
  <block id="69504b415e8aad20e18beca0de96ab6a" category="list-text">Oracle 복구 모듈은 모든 DB 볼륨이 대기 컴퓨팅 인스턴스에 마운트된 후 복구 사이트에서 Oracle을 복구 및 시작하는 다음과 같은 작업을 수행합니다.</block>
  <block id="5e52a9563e31960cdf02c7b83e6495e7" category="list-text">제어 파일 동기화: 중요한 데이터베이스 제어 파일을 보호하기 위해 서로 다른 데이터베이스 볼륨에 중복 Oracle 제어 파일을 구축했습니다. 하나는 데이터 볼륨에 있고 다른 하나는 로그 볼륨에 있습니다. 데이터 및 로그 볼륨은 서로 다른 빈도로 복제되므로 복구 시 동기화되지 않습니다.</block>
  <block id="26b9a788a0ef0527f25f68892b364d19" category="list-text">Oracle 바이너리 다시 연결: Oracle 바이너리가 새 호스트로 재배치되므로 재링크가 필요합니다.</block>
  <block id="b66ad18a7982f7c233e9d0af2f867856" category="list-text">Oracle 데이터베이스 복구: 복구 메커니즘은 Oracle 로그 볼륨에서 마지막으로 사용 가능한 아카이브 로그의 마지막 시스템 변경 번호를 제어 파일에서 검색하고 Oracle 데이터베이스를 복구하여 장애 발생 시 DR 사이트에 복제할 수 있는 모든 비즈니스 트랜잭션을 복구합니다. 그런 다음 복구 사이트에서 사용자 연결 및 비즈니스 트랜잭션을 수행할 수 있도록 데이터베이스가 새로 도입되었습니다.</block>
  <block id="861503fb33ea04fecb13449e713e8ac6" category="admonition">복구 플레이북을 실행하기 전에 /etc/oratab 및 /etc/oraInst.loc을 소스 Oracle 호스트에서 대상 호스트로 복제해야 합니다</block>
  <block id="ff9d8653752bd48bb6b73cf97f207af1" category="summary">SnapCenter DR 워크플로우를 사용하는 하이브리드 클라우드 데이터베이스 솔루션</block>
  <block id="ac2e8778240cb518ee14b1defbf55765" category="doc">재해 복구 워크플로우</block>
  <block id="461887ca64f2d60da58c130a00656a96" category="inline-link-macro">이전: 개발/테스트 환경의 클라우드 용량 증가를 위한 워크플로우</block>
  <block id="b8499237e1a42a05b5306219f80b35ba" category="paragraph"><block ref="b8499237e1a42a05b5306219f80b35ba" category="inline-link-macro-rx"></block></block>
  <block id="8e84608bd62584b2f262d60fd734714f" category="paragraph">기업은 퍼블릭 클라우드를 재해 복구를 위한 실행 가능한 리소스와 대상으로 채택하였습니다. SnapCenter는 이 프로세스를 가능한 한 원활하게 만듭니다. 이 재해 복구 워크플로우는 클론 워크플로우와 매우 유사하지만, 가능한 모든 비즈니스 트랜잭션을 복구하기 위해 클라우드에 복제한 마지막 가용 로그를 통해 데이터베이스 복구가 실행됩니다. 그러나 재해 복구와 관련된 추가적인 사전 구성 및 사후 구성 단계가 있습니다.</block>
  <block id="e230d95c57c5534b3e90b93fddbcb1c9" category="section-title">DR을 위해 사내 Oracle 운영 DB를 클라우드에 클론 복제합니다</block>
  <block id="db9517755259859dbae095126c803544" category="list-text">마지막으로 사용 가능한 로그를 통해 클론 복구가 실행되는지 확인하기 위해 작은 테스트 테이블을 만들고 행을 삽입했습니다. 테스트 데이터는 마지막 사용 가능한 로그로 전체 복구 후 복구됩니다.</block>
  <block id="39f00f2f1a95739a075844dcffac1441" category="paragraph"><block ref="39f00f2f1a95739a075844dcffac1441" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4fd1337293be82f7472d90bc35f51e90" category="list-text">SnapCenter에 Oracle의 데이터베이스 관리 사용자 ID로 로그인합니다. 리소스 탭으로 이동하여 SnapCenter에서 보호 중인 Oracle 데이터베이스를 표시합니다.</block>
  <block id="1ddb1f7854ac534473544de627fc5289" category="paragraph"><block ref="1ddb1f7854ac534473544de627fc5289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e795ef17ab8e08159909afe558c32a1c" category="list-text">Oracle 로그 리소스 그룹을 선택하고 지금 백업 을 클릭하여 Oracle 로그 백업을 수동으로 실행하여 최신 트랜잭션을 클라우드의 대상으로 플러시합니다. 실제 DR 시나리오에서 복구할 수 있는 마지막 트랜잭션은 클라우드에 대한 데이터베이스 로그 볼륨 복제 빈도에 따라 달라지며, 이 빈도는 회사의 RTO 또는 RPO 정책에 따라 달라집니다.</block>
  <block id="e3ea77c81b6559a6984aee62074951ec" category="paragraph"><block ref="e3ea77c81b6559a6984aee62074951ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44d1c907c1d5302eb896d76cae9b5e7f" category="paragraph"><block ref="44d1c907c1d5302eb896d76cae9b5e7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d77575716b9cd49ab1453e367c405abe" category="admonition">비동기식 SnapMirror는 재해 복구 시나리오에서 데이터베이스 로그 백업 간격의 클라우드 대상으로 하지 않은 데이터를 손실합니다. 데이터 손실을 최소화하기 위해 로그 백업을 더 자주 예약할 수 있습니다. 그러나 기술적으로 달성 가능한 로그 백업 빈도에는 제한이 있습니다.</block>
  <block id="c684c2587fa959f3df40953faab1c1a1" category="list-text">보조 미러 백업에서 마지막 로그 백업을 선택하고 로그 백업을 마운트합니다.</block>
  <block id="4d27921136b62a393650eec8f38c5a39" category="paragraph"><block ref="4d27921136b62a393650eec8f38c5a39" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6784de36878125b88feb4c3192d2aa3d" category="paragraph"><block ref="6784de36878125b88feb4c3192d2aa3d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fbfa0a2a63c1090863dedb14664d443c" category="list-text">마지막 전체 데이터베이스 백업을 선택하고 클론 을 클릭하여 클론 워크플로우를 시작합니다.</block>
  <block id="ecafa568fe2f36fee38130d0f80eeafc" category="paragraph"><block ref="ecafa568fe2f36fee38130d0f80eeafc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3aa765536eeb5bd55823afbb43c9efdc" category="list-text">호스트에서 고유한 클론 DB ID를 선택합니다.</block>
  <block id="6d4d1ea488e25d46cd7824491f3f98fb" category="paragraph"><block ref="6d4d1ea488e25d46cd7824491f3f98fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d57d235b31b66e982ae6d433fa33948e" category="list-text">로그 볼륨을 프로비저닝하고 Oracle 플래시 복구 영역 및 온라인 로그에 대해 타겟 DR 서버에 마운트합니다.</block>
  <block id="4ef6ef644cc7510226d8d150ce9cfe73" category="paragraph"><block ref="4ef6ef644cc7510226d8d150ce9cfe73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d5730b3167534121e5ac4fcdf84cf1f" category="paragraph"><block ref="4d5730b3167534121e5ac4fcdf84cf1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6142419cbd2b279a240db52011ea3cab" category="admonition">Oracle 클론 절차에서는 복제 전에 DR 서버에 프로비저닝해야 하는 로그 볼륨을 생성하지 않습니다.</block>
  <block id="b20da77a777ef0a84d95f447b254387c" category="list-text">타겟 클론 호스트 및 위치를 선택하여 데이터 파일, 제어 파일 및 재실행 로그를 배치합니다.</block>
  <block id="326062662ffdb461c61b5ddfc54974bc" category="paragraph"><block ref="326062662ffdb461c61b5ddfc54974bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b126b14adfdc04f12e6a00531155f4a" category="list-text">클론의 자격 증명을 선택합니다. 대상 서버의 Oracle 홈 구성에 대한 세부 정보를 입력합니다.</block>
  <block id="ee4a9d80953ee6db29e5577ef13327ba" category="paragraph"><block ref="ee4a9d80953ee6db29e5577ef13327ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c76f59dc52686a71eb5917bbcabfa212" category="list-text">클론 생성 전에 실행할 스크립트를 지정합니다. 필요한 경우 데이터베이스 매개 변수를 조정할 수 있습니다.</block>
  <block id="31b131b08153ae34a96d1e17fa891e1f" category="paragraph"><block ref="31b131b08153ae34a96d1e17fa891e1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7018f70f78c5e3154b2620e31167c12e" category="list-text">사용 가능한 모든 아카이브 로그를 통해 복구를 실행하여 보조 클라우드 위치로 복제된 마지막 트랜잭션을 회복하려면 복구 옵션으로 취소 를 선택합니다.</block>
  <block id="57fa7fef5a8266470204775391a701d3" category="paragraph"><block ref="57fa7fef5a8266470204775391a701d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6233d74c8f9820a1029624d60ab66049" category="list-text">필요한 경우 e-메일 알림을 위해 SMTP 서버를 구성합니다.</block>
  <block id="a563132424d4d3d255697521a0446bc9" category="paragraph"><block ref="a563132424d4d3d255697521a0446bc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0cd00abfa258b121d480ce7d27e63" category="list-text">DR 클론 요약</block>
  <block id="0f66818ccf8a8dd3d6491b9bcf74c02e" category="paragraph"><block ref="0f66818ccf8a8dd3d6491b9bcf74c02e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4ff014e6bff5ee06349d607c14fcf9e" category="list-text">클론 생성된 DB는 클론 생성 완료 후 즉시 SnapCenter에 등록되고 백업 보호에 사용할 수 있습니다.</block>
  <block id="18eac7477ab0c6038ec443444677a1eb" category="paragraph"><block ref="18eac7477ab0c6038ec443444677a1eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22d74aee547ad10d104f875521cfa6d7" category="section-title">Oracle에 대한 DR 클론 생성 후 검증 및 구성</block>
  <block id="9d58cce71d4c85948ccecfea105367ed" category="list-text">클라우드의 DR 위치에서 플러시, 복제 및 복구된 마지막 테스트 트랜잭션을 검증합니다.</block>
  <block id="1db3ba1f62cbb82a66232de851bad3ce" category="paragraph"><block ref="1db3ba1f62cbb82a66232de851bad3ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="61b3573abc722a493f53ed27503f7eff" category="list-text">플래시 복구 영역을 구성합니다.</block>
  <block id="71ca9fe67f8c3826e171fb227af4f666" category="paragraph"><block ref="71ca9fe67f8c3826e171fb227af4f666" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4005d553f013abc53c6a1a65aed1d65f" category="list-text">사용자 액세스를 위해 Oracle 수신기를 구성합니다.</block>
  <block id="0c79c2a9e4fd1ea908a63d58f1f44917" category="list-text">복제된 볼륨을 복제된 소스 볼륨에서 분리합니다.</block>
  <block id="42e82bb35283d9f2e2b444419f518667" category="list-text">클라우드에서 사내로 역방향 복제를 수행하고 실패한 온프레미스 데이터베이스 서버를 재구성합니다.</block>
  <block id="4ce2420dd00dd0b543e2e51bf7c1c135" category="admonition">클론 분할 시 일반 작업보다 훨씬 높은 임시 스토리지 공간 사용률이 발생할 수 있습니다. 그러나 온프레미스 DB 서버를 재구축한 후에는 추가 공간을 릴리즈할 수 있습니다.</block>
  <block id="0e70133bb418f4025b82a6a35301e209" category="section-title">DR을 위해 사내 SQL 운영 DB를 클라우드에 클론 복제합니다</block>
  <block id="32bfa00a92b9f85d791a43f6d70a35cd" category="list-text">마찬가지로, SQL 클론 복구가 마지막 사용 가능한 로그를 통해 실행되었는지 확인하기 위해 작은 테스트 테이블을 만들고 행을 삽입했습니다. 테스트 데이터는 사용 가능한 마지막 로그로 전체 복구 후 복구됩니다.</block>
  <block id="321bd96e83b00fcd04bfcc72ec4564ff" category="paragraph"><block ref="321bd96e83b00fcd04bfcc72ec4564ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a3b7f1fcf93afdd055ec19e230b54347" category="list-text">SQL Server의 데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인합니다. SQL Server 보호 리소스 그룹을 보여 주는 리소스 탭으로 이동합니다.</block>
  <block id="c9673e38d22c239c3b46259620b7b190" category="paragraph"><block ref="c9673e38d22c239c3b46259620b7b190" category="inline-image-macro-rx" type="image"></block></block>
  <block id="608bfa3334f97023b71f6b7a04742bd6" category="list-text">로그 백업을 수동으로 실행하여 퍼블릭 클라우드의 보조 스토리지에 복제할 마지막 트랜잭션을 플러시합니다.</block>
  <block id="94ca8d0daf1445cae1bbc5a13d7b0c42" category="paragraph"><block ref="94ca8d0daf1445cae1bbc5a13d7b0c42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9b9ced1d8d8e91eb2606cb7d0932fa4" category="list-text">클론에 대한 마지막 전체 SQL Server 백업을 선택합니다.</block>
  <block id="f93fa51d605a26ef233b6fb9c5489266" category="paragraph"><block ref="f93fa51d605a26ef233b6fb9c5489266" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82efcc579f2220a65dbe5cdd64f47253" category="list-text">클론 서버, 클론 인스턴스, 클론 이름 및 마운트 옵션과 같은 클론 설정을 지정합니다. 클론 생성이 수행되는 보조 스토리지 위치는 자동으로 채워집니다.</block>
  <block id="bb5bdefa03845f9483d1e3fcf8d3b40f" category="paragraph"><block ref="bb5bdefa03845f9483d1e3fcf8d3b40f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d84ecf0ed314694d6e3ad9b2a96a198" category="list-text">적용할 모든 로그 백업을 선택합니다.</block>
  <block id="79284af3915a1bc3e4d4d3993acd9042" category="paragraph"><block ref="79284af3915a1bc3e4d4d3993acd9042" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f68fbd76be71ebe267aa207f7bef25f" category="list-text">클론 생성 전후에 실행할 선택적 스크립트를 지정합니다.</block>
  <block id="1f29cf99c49ef1910181e451424c3796" category="paragraph"><block ref="1f29cf99c49ef1910181e451424c3796" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ac43ede08a0b7154673a619b979f17d" category="list-text">e-메일 알림을 원할 경우 SMTP 서버를 지정합니다.</block>
  <block id="e8aa5b543b67c22f0a2a205562794787" category="paragraph"><block ref="e8aa5b543b67c22f0a2a205562794787" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7338d3af995c4a281de85493129cc18" category="list-text">DR 클론 요약 클론 생성된 데이터베이스는 SnapCenter에 즉시 등록되며 백업 보호에 사용할 수 있습니다.</block>
  <block id="332fb27e1cc349fc79252fbfc5de6ad0" category="paragraph"><block ref="332fb27e1cc349fc79252fbfc5de6ad0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8be7490bb89f986a83768e6a71d78ee8" category="paragraph"><block ref="8be7490bb89f986a83768e6a71d78ee8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f01a56e31a650c5bb83408b5238270e" category="section-title">SQL에 대한 DR 클론 생성 후 검증 및 구성</block>
  <block id="029640b7bf09578f05703e407e99b8d7" category="list-text">클론 작업 상태를 모니터링합니다.</block>
  <block id="d5f350d5580b71105a1718557ce88137" category="paragraph"><block ref="d5f350d5580b71105a1718557ce88137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68236fcee9bee8dbdc1c54b7b2d84b34" category="list-text">모든 로그 파일 클론 및 복구를 사용하여 마지막 트랜잭션이 복제 및 복구되었는지 확인합니다.</block>
  <block id="3ebb58ab28579acf2742808bf95fc07e" category="paragraph"><block ref="3ebb58ab28579acf2742808bf95fc07e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50159c53d6f87eb33c314abd9f0bd28f" category="list-text">SQL Server 로그 백업을 위해 DR 서버에 새 SnapCenter 로그 디렉토리를 구성합니다.</block>
  <block id="52320018ddc230fda7bdeccfda8b9f0a" category="section-title">도움을 받을 수 있는 곳</block>
  <block id="2d6962c20ba37b34437afc30e6838e0d" category="inline-link-macro">NetApp Solution Automation 커뮤니티는 Slack 채널을 지원합니다</block>
  <block id="50f8c30e062c542679b96127a844db6a" category="paragraph">이 솔루션 및 사용 사례에 대한 도움이 필요한 경우 에 가입하십시오 <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> 질문 또는 질문을 게시할 수 있는 솔루션 자동화 채널을 찾아보십시오.</block>
  <block id="d83342bb55cac062a4841a3b7a62a7fd" category="summary">이 섹션에서는 이전 섹션에서 설명한 사전 요구 사항을 충족하기 위해 완료해야 하는 작업을 요약합니다. 다음 섹션에서는 사내 및 퍼블릭 클라우드 운영에 모두 필요한 개략적인 작업 목록을 제공합니다. 자세한 프로세스와 절차는 관련 링크를 클릭하여 액세스할 수 있습니다.</block>
  <block id="21475c5fe4cf73cfbf7756ed71e43375" category="doc">시작 개요</block>
  <block id="fa952e93a2f3bc19270cbedd1510f523" category="inline-link-macro">이전: 퍼블릭 클라우드의 사전 요구 사항</block>
  <block id="f50eb88fd106752cf99e25d4a7259bb7" category="paragraph"><block ref="f50eb88fd106752cf99e25d4a7259bb7" category="inline-link-macro-rx"></block></block>
  <block id="f0e69ccbb7ad96f546f7924206944bfa" category="section-title">온프레미스</block>
  <block id="b2e7ae8381268c9d97dc3576aa67da04" category="list-text">SnapCenter에서 데이터베이스 관리자 사용자를 설정합니다</block>
  <block id="e1c4efcd7b5b155c8a6e57d348b6c071" category="list-text">SnapCenter 플러그인 설치 필수 구성 요소</block>
  <block id="cf69df8da81eda7b468d606f3e9aff06" category="list-text">SnapCenter 호스트 플러그인 설치</block>
  <block id="2a6faa57bc6cc0f7a4c90cebd5e63344" category="list-text">DB 리소스 검색</block>
  <block id="2a36af746a3cc41f6964edac717b5206" category="list-text">스토리지 클러스터 피어링 및 DB 볼륨 복제를 설정합니다</block>
  <block id="a227a5da83d0a04e6e8e7e76a89eba09" category="list-text">SnapCenter에 CVO 데이터베이스 스토리지 SVM 추가</block>
  <block id="c615eed91e2ab578525394d0ff0138d9" category="list-text">SnapCenter에서 데이터베이스 백업 정책을 설정합니다</block>
  <block id="8ecb914dad4186dafb38268be6fc8a1f" category="list-text">백업 정책을 구현하여 데이터베이스를 보호합니다</block>
  <block id="3041fe5faf49efefd030e278790b4faf" category="list-text">백업을 검증합니다</block>
  <block id="0bcf61b20ebca1ef90cb7982284867a6" category="list-text">사전 항공편 확인</block>
  <block id="c27b238e54d27696cafed4684c6f1335" category="list-text">AWS에서 Cloud Manager 및 Cloud Volumes ONTAP를 구축하는 단계</block>
  <block id="2bb50575568fc6429e2c1cef751d40f4" category="list-text">데이터베이스 워크로드를 위한 EC2 컴퓨팅 인스턴스 구축</block>
  <block id="bc2dcb446bec0ecd131a2e612dbd1ecd" category="paragraph">자세한 내용을 보려면 다음 링크를 클릭하십시오.</block>
  <block id="7146594a919f2b006b1b0911c7b6d7da" category="inline-link-macro">온프레미스</block>
  <block id="21aa279d0a145dcaab5feaa02df2c02a" category="inline-link-macro">퍼블릭 클라우드 - AWS</block>
  <block id="fd0476c0c92270df2d75402a67cfe0f4" category="paragraph"><block ref="8f0e2d08c6bad9ef491c2061921b9d90" category="inline-link-macro-rx"></block>, <block ref="11145243f1982fd305768240bff5daad" category="inline-link-macro-rx"></block></block>
  <block id="d4c96dcd516adf0c5bde093b0b7b7255" category="summary">이 페이지에서는 NetApp ONTAP 스토리지에 Oracle19c를 구축하는 자동화된 방법에 대해 설명합니다.</block>
  <block id="0e6b1c16527d2792d391c578bbf12efe" category="section-title">CLI 구축 Oracle 19c Database</block>
  <block id="57daddd847cdbab22b7363630de48a2f" category="inline-link-macro">시작하기 및 요구 사항 섹션을 참조하십시오</block>
  <block id="82ba94e85d91493ea6c88423c0b34605" category="paragraph">이 섹션에서는 CLI를 사용하여 Oracle19c 데이터베이스를 준비하고 배포하는 데 필요한 단계를 설명합니다. 을(를) 검토했는지 확인합니다 <block ref="598ea103507880273a5a1840cac102d8" category="inline-link-macro-rx"></block> 적절히 대비했습니다.</block>
  <block id="0f2d7675188dbfc7b9df587588bff71b" category="section-title">Oracle19c repo 를 다운로드합니다</block>
  <block id="4e2b619426350db7e7d5b09c96b8010b" category="section-title">HOSTS 파일을 편집합니다</block>
  <block id="b183e47af1fa85c93e4a4368205c3249" category="paragraph">배포 전에 다음을 완료합니다.</block>
  <block id="c4ab1530ffd8a3306d47c804ca88240c" category="list-text">호스트 파일 na_oracle19c_deploy 디렉토리를 편집합니다.</block>
  <block id="bc1dd0e50a3c20e78cc2d680eaf32378" category="list-text">[ONTAP] 아래에서 IP 주소를 클러스터 관리 IP로 변경합니다.</block>
  <block id="6475f51ce7ff0a21a5635ea50b1f1a86" category="list-text">[Oracle] 그룹에서 Oracle 호스트 이름을 추가합니다. 호스트 이름은 DNS 또는 호스트 파일을 통해 IP 주소로 확인되거나 호스트에 지정되어야 합니다.</block>
  <block id="5c3f5e9dc815ca28c7cf1ff64cdc61a2" category="list-text">이 단계를 완료한 후 변경 사항을 저장합니다.</block>
  <block id="b27994a7bba852ac9a8f1a262413e68b" category="paragraph">다음 예에서는 호스트 파일을 보여 줍니다.</block>
  <block id="1caa2eee0ed6a6c5c6edcbc0320e8671" category="paragraph">이 예에서는 Playbook을 실행하고 두 개의 Oracle DB 서버에 동시에 Oracle 19c를 구축합니다. 하나의 DB 서버만으로 테스트할 수도 있습니다. 이 경우 하나의 호스트 변수 파일만 구성하면 됩니다.</block>
  <block id="d11927d6f93a4edaa78dc52c6e34fd5f" category="admonition">이 플레이북은 구축하는 Oracle 호스트 및 데이터베이스의 수에 관계없이 동일한 방식으로 실행됩니다.</block>
  <block id="030c98564d5fbd7c8672a76e2a593b21" category="section-title">host_name.yml 파일을 host_vars에서 편집합니다</block>
  <block id="86c40bb4891f3e6b34a2eece7bb19532" category="paragraph">각 Oracle 호스트에는 호스트별 변수를 포함하는 호스트 이름으로 식별되는 호스트 변수 파일이 있습니다. 호스트 이름을 지정할 수 있습니다. Host VAR Config 섹션에서 host_vars를 편집 및 복사하고 원하는 host_name.yml 파일에 붙여 넣습니다.</block>
  <block id="5bbe8264b4d6c6787657c66d4017c183" category="section-title">호스트 VAR 구성</block>
  <block id="44505c1007599884b05c0148599ad1b0" category="section-title">VAR.yml 파일을 편집합니다</block>
  <block id="41cdd95196e2753968e0d69375c41825" category="paragraph">VAR.yml 파일은 Oracle 구축을 위해 모든 환경 관련 변수(ONTAP, Linux 또는 Oracle)를 통합합니다.</block>
  <block id="271f9ccf9c8189bb1888d25c7f0e025b" category="list-text">VAR 섹션에서 변수를 편집 및 복사하고 해당 변수를 'VAR.yml' 파일에 붙여 넣습니다.</block>
  <block id="d0db3f5a4a306cff20be4187b3ef3445" category="section-title">VAR</block>
  <block id="78d77851709e21512097cee585c59d0c" category="section-title">플레이북을 실행합니다</block>
  <block id="8f42d9f703ada5b4f1374ca96a4f1cec" category="paragraph">필요한 환경 전제 조건을 완료하고 변수를 VAR.yml과 your_host.yml에 복사하면 이제 Playbook을 배포할 준비가 된 것입니다.</block>
  <block id="6226590ec5d4a109e4b93317425994c1" category="admonition">사용자 환경과 일치하도록 &lt;username&gt;을(를) 변경해야 합니다.</block>
  <block id="24b2767982b51deb19947fb3e94279c6" category="section-title">동일한 Oracle 호스트에 추가 데이터베이스를 구축합니다</block>
  <block id="5cc75d1029461de7ddcd02bbc784af26" category="paragraph">플레이북의 Oracle 부분은 실행 당 Oracle 서버에 단일 Oracle 컨테이너 데이터베이스를 생성합니다. 동일한 서버에 추가 컨테이너 데이터베이스를 만들려면 다음 단계를 수행하십시오.</block>
  <block id="b4a35a2d5c3a4f3efb7c77f6bcd2a905" category="list-text">host_vars 변수를 수정합니다.</block>
  <block id="5641cb71d4e10abef15918c2dd828917" category="list-text">3단계로 돌아가기 - host_vars에서 host_name.yml 파일을 편집합니다.</block>
  <block id="ffcc6e6df9c3839334c063a9223c65b3" category="list-text">Oracle SID를 다른 명명 문자열로 변경합니다.</block>
  <block id="a936a5fabc881eb3591658385409dfb8" category="list-text">수신기 포트를 다른 번호로 변경합니다.</block>
  <block id="24f0029973c35b16fc49847b27215915" category="list-text">EM Express를 설치한 경우 EM Express 포트를 다른 번호로 변경하십시오.</block>
  <block id="365c64de6adc281d7f484029d1356855" category="list-text">수정된 호스트 변수를 복사하여 'host_vars' 아래의 Oracle 호스트 변수 파일에 붙여넣습니다.</block>
  <block id="b64219fd8290ac8a154f733df0825dbb" category="list-text">위의 에 나와 있는 것처럼 "ORACLE_config" 태그를 사용하여 플레이북을 실행합니다 <block ref="1c892654e23ff69bf71caefc702aa8b4" category="inline-xref-macro-rx"></block>.</block>
  <block id="0dd197c8abd1f3c3607887dbc615148f" category="section-title">Oracle 설치를 검증합니다</block>
  <block id="f673434da0f39c1b4366cbc45f67da8a" category="admonition">설치가 예상대로 완료되고 Oracle DB가 시작되면 Oracle 프로세스가 나열됩니다</block>
  <block id="91bcd024d07cb33293902b287b0cc68c" category="paragraph">[oracle@localhost~]$sqlplus/as sysdba</block>
  <block id="b95bce10ef504692a6d971d3a30ac8c4" category="paragraph">SQL* Plus: 릴리스 19.0.0.0.0 - 5월 6일 목요일 프로덕션 12:52:51 2021년 버전 19.8.0.0.0</block>
  <block id="a2494ba30f29d91ff6876152fc693ab3" category="paragraph">Copyright (c) 1982, 2019, Oracle. 모든 권리 보유.</block>
  <block id="ce8b3f5af3f95d98bbbf478e4c37024f" category="paragraph">연결 대상: Oracle Database 19c Enterprise Edition 릴리스 19.0.0.0.0 - 프로덕션 버전 19.8.0.0.0</block>
  <block id="28a359e505158300600d776ae9347cac" category="paragraph">sql&gt; 을 클릭합니다</block>
  <block id="63102463594ac5bd274343651065779d" category="paragraph">sql&gt; v$database에서 이름, log_mode 선택; name log_mode--------- ---------- CDB2 ARCHIVELOG</block>
  <block id="7d8bf5a6b847068ff3c0eb0ca0892acf" category="paragraph">sql &gt; PDB 표시</block>
  <block id="33c7676f0bdcf42bed62c146feaf485c" category="paragraph">sql&gt; col svrname form a30 sql&gt; col dirname form a30 sql&gt; v$dnfs_servers에서 svrname, dirname, nfsversion을 선택합니다.</block>
  <block id="d6bee2dc52f5708cd8af49c1c263c714" category="paragraph">SVRNAME dirname NFSVERSION------------------------------------------------------------ ------------------------------------------------------------ --------------- 172.21.126.200/rhelora03_u02 NFSv3.0 172.21.126.200/rhelora03_uNFSv03 3.0 172.21.126.200/rhelora03_u01 NFSv3.0</block>
  <block id="ea12870da72347cdd45bc11ae4d603dc" category="paragraph">[Oracle@localhost~]$sqlplus system@//localhost:1523/cdb2_pdb1.cie.netapp.com</block>
  <block id="aff680efe40afd832819af131e324051" category="paragraph">SQL* Plus: 릴리스 19.0.0.0.0 - 5월 6일 13:19:57 2021년 11월 19일 버전 19.8.0.0.0의 목요일 프로덕션</block>
  <block id="6c3d252188792733323cf879b5d196cf" category="paragraph">비밀번호 입력: 마지막으로 성공한 로그인 시간: 2021년 5월 5일 17:11:11-04:00</block>
  <block id="531fea2bb939d7c35cad66fde1640511" category="paragraph">sql&gt; show user is "system" sql&gt; show con_name con_name CDB2_PDB1</block>
  <block id="1b6a5f8b328d3175066895d7ff5ea576" category="inline-link-macro">NetApp 솔루션 자동화 커뮤니티는 여유 채널을 지원합니다</block>
  <block id="12f178498803c606c23e7166dcefb0cb" category="paragraph">툴킷에 대한 도움이 필요한 경우 에 가입하십시오 <block ref="f1bb21e2ce6888d898ae31a2098245a1" category="inline-link-macro-rx"></block> 질문 또는 질문을 게시할 수 있는 솔루션 자동화 채널을 찾아보십시오.</block>
  <block id="75b7d47e2aa19968e092ab7ddb108a3f" category="summary">확장 데이터베이스가 있는 All-Cloud 또는 하이브리드 클라우드를 타겟팅하는 경우 모두 Azure NetApp Files는 애플리케이션 계층에 데이터 요구사항을 원활하게 구현하여 TCO를 절감하는 동시에 데이터베이스 워크로드를 구축 및 관리할 수 있는 탁월한 옵션을 제공합니다.</block>
  <block id="d8d2e6021f496c4e4a31a3d5d51c0a97" category="paragraph">이 문서에서는 Azure NetApp Files를 사용하여 Microsoft SQL Server 배포를 계획, 설계, 최적화 및 확장하는 권장 사항에 대해 설명합니다. 이러한 권장 사항은 구현에 따라 크게 다를 수 있습니다. 올바른 솔루션은 구현의 기술 세부사항과 프로젝트의 원동력이 되는 비즈니스 요구 사항 둘 다에 따라 달라집니다.</block>
  <block id="56925354251a536c23de1174d3001595" category="section-title">이점</block>
  <block id="033e6e43f2148e187e072dc7e6585802" category="paragraph">이 문서의 핵심 사항은 다음과 같습니다.</block>
  <block id="b2b363e230905b04f6e9c7263aa93f42" category="list-text">이제 Azure NetApp Files를 사용하여 SQL Server 클러스터에 대한 데이터베이스 및 파일 공유 증인을 호스팅할 수 있습니다.</block>
  <block id="4d6ec76303888bc681d543d1f4593c55" category="list-text">필요 시 언제 어디서나 SQL Server 데이터에 액세스할 수 있도록 애플리케이션 응답 시간을 높이고 99.9999%의 가용성을 제공할 수 있습니다.</block>
  <block id="408e4b7fbec4ba85e097b9393d2b27a7" category="list-text">SQL Server 배포 및 지속적인 관리(예: RAID 스트라이핑)의 전반적인 복잡성을 간단하고 즉각적으로 조정할 수 있습니다.</block>
  <block id="41642b38214243168d907d92759dde36" category="list-text">지능형 운영 기능을 사용하면 SQL Server 데이터베이스를 몇 분 내에 구축하고 개발 주기를 단축할 수 있습니다.</block>
  <block id="61a32d891a5f7bca599a014bc56eec61" category="list-text">Azure 클라우드가 그 목적이라면, Azure NetApp Files는 최적의 구축을 위한 최적의 스토리지 솔루션입니다.</block>
  <block id="a2810b66f557bf43f1c602ecfe7f52b1" category="summary">이 문서에서는 Azure 가상 시스템을 활용하는 Azure NetApp Files의 AOAG(SQL Server Always On Availability Group)를 실시간으로 구축하는 방법에 대해 설명합니다.</block>
  <block id="0ecccb1d48727b6da357728efe7b6375" category="doc">TR-4897: Azure NetApp Files 기반 SQL Server - 실제 배포 보기</block>
  <block id="4eae423bbc6520b4a8fa4d0d4de28b8a" category="paragraph">Niyaz Mohamed, NetApp</block>
  <block id="8ae2b9aab28b6c00df7581f99f9211ef" category="paragraph">IT 조직은 끊임없이 변화합니다. Gartner에 따르면 모든 데이터베이스의 약 75%가 2022년까지 클라우드 기반 스토리지를 필요로 할 것이라고 합니다. 선도적인 RDBMS(관계형 데이터베이스 관리 시스템)인 Microsoft SQL Server는 ERP(전사적 자원 관리)에서 분석, 콘텐츠 관리에 이르기까지 SQL Server를 사용하는 Windows 플랫폼 설계 응용 프로그램 및 조직에 적합합니다. SQL Server는 기업이 대규모 데이터 집합을 관리하는 방식을 혁신시키고 스키마 및 쿼리 성능 요구를 충족하도록 응용 프로그램에 전력을 공급하는 데 도움을 주었습니다.</block>
  <block id="eae371fd2d593d80849fab02c4e8b90b" category="paragraph">대부분의 IT 조직은 클라우드 우선 방식을 따릅니다. 전환 단계의 고객은 현재 IT 환경을 평가한 다음 평가 및 검색 결과를 기반으로 데이터베이스 워크로드를 클라우드로 마이그레이션합니다. 고객의 클라우드 마이그레이션 방향을 결정하는 요인에는 탄력성/버스트, 데이터 센터 이탈, 데이터 센터 통합, 수명 종료 시나리오, 인수 합병, 인수 합병 등 마이그레이션 이유는 각 조직과 각 조직의 비즈니스 우선 순위에 따라 달라질 수 있습니다. 클라우드로 이동할 때 SQL Server 데이터베이스 클라우드 구현의 잠재력을 최대한 활용하려면 적절한 클라우드 스토리지를 선택하는 것이 매우 중요합니다.</block>
  <block id="f9468c81b3d59ac0030570c4f58e95f1" category="section-title">사용 사례</block>
  <block id="cf8b0bda1e058c1f8383f434c4da9b71" category="paragraph">SQL Server 자산을 Azure로 이전하고 Azure Data Factory, Azure IoT Hub 및 Azure Machine Learning과 같은 Azure의 광범위한 PaaS(서비스로서의 플랫폼) 기능과 SQL Server를 통합하면 디지털 혁신을 지원하는 엄청난 비즈니스 가치를 창출할 수 있습니다. 또한 클라우드를 채택하면 각 사업부에서 자본 지출 모델 또는 기존 프라이빗 클라우드 모델을 사용할 때보다 생산성 및 새로운 기능/개선 기능(DevTest 사용 사례)을 더 빠르게 제공할 수 있습니다. 이 문서에서는 Azure 가상 시스템을 활용하는 Azure NetApp Files의 AOAG(SQL Server Always On Availability Group)를 실시간으로 구축하는 방법에 대해 설명합니다.</block>
  <block id="239a02aaaf9289a3093f682835f65f88" category="paragraph">Azure NetApp Files는 지속적으로 사용 가능한 파일 공유를 지원하는 엔터프라이즈급 스토리지를 제공합니다. 지속적으로 사용 가능한 공유는 SMB 파일 공유에서 SQL Server 운영 데이터베이스에 의해 요구되며, 컨트롤러 업그레이드 또는 장애와 같은 운영 중단 시나리오를 포함하여 노드에서 항상 데이터베이스 스토리지에 액세스할 수 있도록 합니다. 지속적으로 사용 가능한 파일 공유를 사용하면 스토리지 노드 간에 데이터를 복제할 필요가 없습니다. Azure NetApp Files은 SMB 3.0 스케일아웃, 영구 핸들 및 투명한 페일오버를 사용하여 다양한 관리 작업을 포함한 계획된 다운타임과 계획되지 않은 다운타임 이벤트에 대한 무중단 운영(NDO)을 지원합니다.</block>
  <block id="f47a858d79de9725a0d6881541748e9b" category="paragraph">클라우드 마이그레이션을 계획할 때는 항상 가장 적합한 사용 방법을 평가해야 합니다. 애플리케이션 마이그레이션에 가장 일반적이고 가장 쉬운 접근 방식은 재호스팅(리프트 및 변속이라고도 함)입니다. 이 문서에 제공된 예제 시나리오에서는 재호스팅 메서드를 사용합니다. Azure NetApp Files가 설치된 Azure 가상 시스템의 SQL Server를 사용하면 온프레미스 하드웨어를 관리할 필요 없이 클라우드에서 전체 버전의 SQL Server를 사용할 수 있습니다. 또한 SQL Server VM(가상 머신)은 사용한 만큼만 비용을 지불하면 라이센스 비용을 절감할 수 있으며 개발, 테스트 및 부동산 갱신 시나리오에 대한 탄력성과 버스팅 기능을 제공합니다.</block>
  <block id="4db58285a0e634acd6843c40f7a6f4e0" category="paragraph">이 문서에 설명된 정보에 대한 자세한 내용은 다음 웹 사이트 링크를 참조하십시오.</block>
  <block id="d53a72004974ee8431ee292856c0bba3" category="list-text">Azure NetApp Files를 사용하는 솔루션 아키텍처</block>
  <block id="653ba0610595f0695c3ceb2c59afed59" category="inline-link"><block ref="653ba0610595f0695c3ceb2c59afed59" category="inline-link-rx"></block></block>
  <block id="d5ec9321fb49816034de6b296ef6baa2" category="paragraph"><block ref="d5ec9321fb49816034de6b296ef6baa2" category="inline-link-rx"></block></block>
  <block id="62b5dbc436fc2540c46476bd8e484c11" category="inline-link"><block ref="62b5dbc436fc2540c46476bd8e484c11" category="inline-link-rx"></block></block>
  <block id="44594562b4f528fe8d864bd3f48ddff6" category="paragraph"><block ref="44594562b4f528fe8d864bd3f48ddff6" category="inline-link-rx"></block></block>
  <block id="7aa91f5f0414f1488ce2f5324e63d12e" category="list-text">Azure NetApp Files를 사용한 Azure 기반 SQL Server 배포 가이드</block>
  <block id="9021ea474df74856b145a78c58c35e05" category="inline-link"><block ref="9021ea474df74856b145a78c58c35e05" category="inline-link-rx"></block></block>
  <block id="52a5313d9aca117b5d167e6be79c5bc7" category="paragraph"><block ref="52a5313d9aca117b5d167e6be79c5bc7" category="inline-link-rx"></block></block>
  <block id="49217b0d4a68c88899c93d24203a34b4" category="list-text">Azure NetApp Files의 내결함성, 고가용성 및 복구 기능</block>
  <block id="9e5e063336d276080a054861016aadd8" category="inline-link"><block ref="9e5e063336d276080a054861016aadd8" category="inline-link-rx"></block></block>
  <block id="7ff89d0ad939652d37cbab9b6f420f65" category="paragraph"><block ref="7ff89d0ad939652d37cbab9b6f420f65" category="inline-link-rx"></block></block>
  <block id="0679a51ae3a4071a6bd3dedbe97fd329" category="summary">이 페이지에서는 NetApp ONTAP 스토리지에 Oracle 데이터 보호를 구축하는 자동화된 방법에 대해 설명합니다.</block>
  <block id="cb59b87e00d11222bfd9159d0d23836f" category="doc">시작하기</block>
  <block id="22e3bbd761fbb7ae69b8035eb12f222d" category="paragraph">이 솔루션은 AWX/Tower 환경에서 실행되도록 설계되었습니다.</block>
  <block id="008ba800d97cb969def651e93f0d93fb" category="section-title">AWX/타워</block>
  <block id="a481f1841043d60245f18522a86731b1" category="paragraph">AWX/Tower 환경의 경우 ONTAP 클러스터 관리 및 Oracle 서버(IP 및 호스트 이름)의 인벤토리 생성, 자격 증명 생성, NetApp Automation GitHub에서 Ansible 코드를 가져오는 프로젝트 구성, 자동화를 시작하는 작업 템플릿 등이 있습니다.</block>
  <block id="ad5310e9dcd8f367be2b92490488d86d" category="list-text">이 솔루션은 프라이빗 클라우드 시나리오(사내-사내), 하이브리드 클라우드(사내-퍼블릭 클라우드 간 Cloud Volumes ONTAP[CVO])에서 실행되도록 설계되었습니다.</block>
  <block id="5055de7b9d28f88e537f99f34959c80c" category="list-text">사용자 환경에 맞는 변수를 입력하고 이를 복사하여 작업 템플릿의 추가 VAR 필드에 붙여 넣습니다.</block>
  <block id="d116f375db402ba471f519c0a4df15dc" category="list-text">추가 VAR이 작업 템플릿에 추가되면 자동화를 시작할 수 있습니다.</block>
  <block id="4d0c05180ba83e5c8a9bbac094c365e2" category="list-text">자동화는 3단계(설정, Oracle 바이너리, 데이터베이스, 로그 및 로그용 복제 일정)와 DR 사이트에서 데이터베이스를 복구하기 위한 4단계로 구성됩니다.</block>
  <block id="936c99ed52ca08a052ebf611285dd998" category="inline-link-macro">CVO 및 Connector 구축을 위한 사전 요구 사항을 수집합니다</block>
  <block id="ec329a9106131eb9bf99b0f9e67b0564" category="list-text">CVO 데이터 보호에 필요한 키 및 토큰을 얻기 위한 자세한 지침은 을 참조하십시오 <block ref="e21f73de51752f791cddc773d1f38740" category="inline-link-macro-rx"></block></block>
  <block id="13716f12996b882bb4c7e0bd84c7c128" category="open-title">strong class="big"&gt;온프레미스&lt;/strong&gt;&lt;strong&gt;|&lt;/strong&gt;</block>
  <block id="0ba29c6a1afacf586b03a26162c72274" category="cell">방법입니다</block>
  <block id="9d5cfca4ad04b54536e5ad15210f7dc2" category="cell">* Ansible 환경 *</block>
  <block id="3f0733e14ebf265f0abf4b32371043ac" category="cell">Ansible v. 2.10 이상</block>
  <block id="3c91a74236fab100f024452f6df13b5e" category="cell">Python 3</block>
  <block id="215b38d177939de20bbb7b7913ce32c1" category="cell">Python 라이브러리 - NetApp-lib-xmltodictt-jmespath</block>
  <block id="d911b17f4f4cdcca62a04ad77aa9403d" category="cell">* ONTAP *</block>
  <block id="72bd33cc372377848ab3bb360deb365e" category="cell">ONTAP 버전 9.8 이상</block>
  <block id="10aadda84b1b1da26c3757dfdb59379d" category="cell">두 개의 데이터 애그리게이트</block>
  <block id="9f998f9668ffe69c62d78760d1c531f0" category="cell">NFS VLAN 및 ifgrp가 생성되었습니다</block>
  <block id="ba5f343281b90f0408008806c66bce86" category="cell">* Oracle 서버 *</block>
  <block id="6f1de5f0d7966ebf5f8d255fe28ebffe" category="cell">RHEL 7/8</block>
  <block id="aa596da3b79631d86c0d35e1c4b03aac" category="cell">Oracle Linux 7/8</block>
  <block id="814e8f57514db6134b6ffcd7a4ce20a6" category="cell">NFS, 공용 및 선택적 관리를 위한 네트워크 인터페이스</block>
  <block id="3ca63226b942aff3abcf62934a91e382" category="cell">소스의 기존 Oracle 환경과 대상(DR 사이트 또는 퍼블릭 클라우드)의 동급 Linux 운영 체제</block>
  <block id="6114118ecf4e8d86a2e7c80bfab462f6" category="open-title">strong class="big"&gt;CVO&lt;/strong&gt;</block>
  <block id="675b1e5a01195fa5d419962701704b96" category="cell">Oracle EC2 인스턴스에 적절한 스왑 공간을 설정합니다. 기본적으로 일부 EC2 인스턴스는 0 스왑으로 구축됩니다</block>
  <block id="2f960df807c8ad51e74c447149eb2033" category="cell">* Cloud Manager/AWS *</block>
  <block id="571f37fae4494df03321c2abe1fcc053" category="cell">AWS 액세스/비밀 키</block>
  <block id="7a5be8c4513f3bd0696db24a6bd977f4" category="cell">NetApp Cloud Manager 계정</block>
  <block id="99e55608ac5f1697eb6804aaf586af09" category="cell">NetApp Cloud Manager 업데이트 토큰</block>
  <block id="ae9205dab0c26cca7762be5149a93923" category="section-title">자동화 세부 정보</block>
  <block id="ba0676e7ae183e2c0bbd54261818154f" category="paragraph">이 자동 배포는 3개의 개별 역할로 구성된 단일 Ansible 플레이북을 통해 설계되었습니다. 역할은 ONTAP, Linux 및 Oracle 구성을 위한 것입니다. 다음 표에서는 자동화되고 있는 작업을 설명합니다.</block>
  <block id="3f9ec2a23fee1cafeb1a700de677caac" category="cell">플레이북</block>
  <block id="ef615563c8e8ea902c7fcac3cd2c4246" category="cell">작업</block>
  <block id="1f959110c5104b300b1a3d5fe3ee80dc" category="cell">* ONTAP_설정 *</block>
  <block id="c0563eda0fb9d63778efe04a13a5d744" category="cell">ONTAP 환경 사전 점검</block>
  <block id="b7ed1e5c864a764f83f035d7f4f774ee" category="cell">소스 클러스터에서 Intercluster LIF 생성(선택 사항)</block>
  <block id="73ddb5848c16203494697871a4e993cd" category="cell">대상 클러스터에 Intercluster LIF 생성(선택 사항)</block>
  <block id="04a35ce053d611d390fc192544fa4899" category="cell">클러스터 및 SVM 피어링 생성</block>
  <block id="4605aea1d05aa2979e72d73dd2c51773" category="cell">대상 SnapMirror 생성 및 지정된 Oracle 볼륨의 초기화</block>
  <block id="0dd4c7b6672d8937b6eb899b454fb7fe" category="cell">* ora_replication_cg *</block>
  <block id="7187aaa97acef94360159347d76a84c9" category="cell">/etc/oratab의 각 데이터베이스에 대해 백업 모드를 활성화합니다</block>
  <block id="f9198142d6e5690166713858ae8a0cdd" category="cell">Oracle 바이너리 및 데이터베이스 볼륨의 스냅샷을 생성합니다</block>
  <block id="23ba14a0a5cf33c38faec5b66fff712e" category="cell">SnapMirror가 업데이트되었습니다</block>
  <block id="114debcae141b96db77c72e8a1e8fadb" category="cell">/etc/oratab에서 각 데이터베이스의 백업 모드를 해제합니다</block>
  <block id="682094861a79bcba0e0ab2e193198762" category="cell">* ora_replication_log *</block>
  <block id="1d03ae98454d1c807318a1e29a4e2736" category="cell">/etc/oratab에 있는 각 데이터베이스의 현재 로그를 전환합니다</block>
  <block id="47e4696811eedec695f727189503e8df" category="cell">Oracle Log 볼륨의 스냅숏입니다</block>
  <block id="86836efae3e3d868a96ae69bcbc987ba" category="cell">* ora_RECOVERY *</block>
  <block id="6ceab4515ef4144abed0f0ce5ed3038f" category="cell">SnapMirror를 꺾습니다</block>
  <block id="a6066c717f63ac99226b48abb4cf1d85" category="cell">NFS를 사용하도록 설정하고 타겟에서 Oracle 볼륨에 대한 접합 경로를 생성합니다</block>
  <block id="aa46cdc29b66725a1180f57d02f0cee3" category="cell">DR Oracle 호스트를 구성합니다</block>
  <block id="dea9253f9b15f57a0c2161848a3c27a3" category="cell">Oracle 볼륨을 마운트하고 확인합니다</block>
  <block id="ee95819ff53983a149759d555a93ba4b" category="cell">Oracle 데이터베이스 복구 및 시작</block>
  <block id="5a6b57bc1fdf2f0e1259ed22f1d027a4" category="cell">* cvo_setup *</block>
  <block id="331c87cd495ffdc9cd55d8b3935a75f5" category="cell">환경 사전 점검</block>
  <block id="5f17c8d8d95282db12506044ba4d6ab9" category="cell">AWS 구성/AWS 액세스 키 ID/비밀 키/기본 지역</block>
  <block id="cef449920fe163cdd74231266cbdf23d" category="cell">AWS 역할 생성</block>
  <block id="85a4bcbc96cde90931ad369de96535b2" category="cell">AWS에서 NetApp Cloud Manager Connector 인스턴스 생성</block>
  <block id="abe14752834b641e86064c7214f6719c" category="cell">AWS에서 CVO(Cloud Volumes ONTAP) 인스턴스 생성</block>
  <block id="c2a9449cd3b0ae879520f450b65b1621" category="cell">NetApp Cloud Manager에 온프레미스 소스 ONTAP 클러스터를 추가하십시오</block>
  <block id="fbb54d6efa6ca64af90fbe2289812be8" category="cell">NFS를 사용하도록 설정하고 타겟 CVO에서 Oracle 볼륨의 접합 경로를 생성합니다</block>
  <block id="bf60025632dd0c4a2cf35e8b33e80619" category="section-title">기본 매개변수</block>
  <block id="3ef6389d9b9aacdce331793dd2a96ce8" category="paragraph">자동화를 간소화하기 위해 필요한 많은 Oracle 매개 변수를 기본값으로 사전 설정하였습니다. 일반적으로 대부분의 배포에서 기본 매개 변수를 변경할 필요는 없습니다. 고급 사용자는 기본 매개 변수를 주의 깊게 변경할 수 있습니다. 기본 매개 변수는 각 역할 폴더의 defaults 디렉토리에 있습니다.</block>
  <block id="794df3791a8c800841516007427a2aa3" category="section-title">라이센스</block>
  <block id="19adadc497199e16f07f9744d43b2899" category="paragraph">GitHub 리포지토리에 설명된 대로 라이센스 정보를 읽어야 합니다. 이 리포지토리의 콘텐츠에 액세스, 다운로드, 설치 또는 사용하면 라이선스 조항에 동의하는 것입니다 <block ref="07d15b3b85718d883b437fb3739e59a7" category="inline-link-macro-rx"></block>.</block>
  <block id="87d624bc8a7f555a711e7214ee002eec" category="paragraph">이 저장소의 컨텐츠에서 파생 저작물을 생성 및/또는 공유하는 데는 특정 제한이 있습니다. 의 약관을 읽었는지 확인하십시오 <block ref="49480c711afcff6aca610d8294731030" category="inline-link-macro-rx"></block> 콘텐츠를 사용하기 전에. 모든 약관에 동의하지 않는 경우 이 리포지토리에서 콘텐츠를 액세스, 다운로드 또는 사용하지 마십시오.</block>
  <block id="a98d844e94ad28c8e0fb089e005d6b9f" category="inline-link-macro">자세한 AWX/Tower 절차를 보려면 여기를 클릭하십시오</block>
  <block id="7e599865fd1cdad0e26add5715f65267" category="paragraph">준비가 되면 를 클릭합니다 <block ref="d28bc5520349bb0598caaa5132432326" category="inline-link-macro-rx"></block>.</block>
  <block id="ac9bef0f960e3a46befd2d06b223b61d" category="summary">이 섹션에서는 개발/테스트 및 DR 작업을 위한 일반적인 하이브리드 클라우드 아키텍처를 설명합니다.</block>
  <block id="fece52c505c48f2979e3fa0c8b6bd8bc" category="paragraph"><block ref="fece52c505c48f2979e3fa0c8b6bd8bc" category="inline-link-macro-rx"></block></block>
  <block id="4085a97aa705c0122bbcec0c84dd97d3" category="paragraph">다음 아키텍처 다이어그램은 개발/테스트 및 재해 복구 작업을 위해 하이브리드 클라우드에서 엔터프라이즈 데이터베이스 작업을 구축하는 일반적인 과정을 보여 줍니다.</block>
  <block id="acb339f710a626679c374df5b90c5416" category="paragraph"><block ref="acb339f710a626679c374df5b90c5416" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cdc302c6d83b60c8ec7ad0b550e55a8" category="paragraph">정상적인 비즈니스 작업에서는 클라우드에 동기화된 데이터베이스 볼륨을 클론 복제하여 개발/테스트 데이터베이스 인스턴스의 애플리케이션 개발 또는 테스트에 마운트할 수 있습니다. 장애가 발생할 경우 클라우드에서 동기화된 데이터베이스 볼륨을 재해 복구를 위해 활성화할 수 있습니다.</block>
  <block id="fbfd3304757c668454a7bdd10f9de200" category="inline-link-macro">다음은 솔루션 요구 사항입니다.</block>
  <block id="ae3b1bce66c4c75d8abf9828ec9f2608" category="paragraph"><block ref="ae3b1bce66c4c75d8abf9828ec9f2608" category="inline-link-macro-rx"></block></block>
  <block id="0f22160e43c900ef7426d8a19e9f482d" category="summary">하이브리드 클라우드 데이터베이스 워크로드를 실행하기 전에 사내와 클라우드 모두에서 특정 사전 요구사항을 구성해야 합니다. 다음 섹션에서는 이 프로세스에 대한 개략적인 요약을 제공하고 다음 링크를 통해 필요한 시스템 구성에 대한 추가 정보를 제공합니다.</block>
  <block id="1dad826770c4d2c619351c974f725b36" category="doc">사전 요구 사항 구성</block>
  <block id="ce38f65c711e7e3047c9350abe42c0c3" category="inline-link-macro">이전: 솔루션 요구 사항.</block>
  <block id="d3fe0eebddd46d46399cb319c7219427" category="paragraph"><block ref="d3fe0eebddd46d46399cb319c7219427" category="inline-link-macro-rx"></block></block>
  <block id="4df40e141b0559f15db8f84f78aed013" category="section-title">온프레미스</block>
  <block id="761883c0d5c55fba5b200ac8ac0d86e5" category="section-title">퍼블릭 클라우드</block>
  <block id="37aa83a33297d9d16b4423be342598bb" category="list-text">커넥터의 네트워크 위치입니다</block>
  <block id="74c043a4451dd260729a23ce96aa1550" category="paragraph">중요 고려 사항:</block>
  <block id="7aee27c83b5e3622c1d8cbd5c2098c60" category="list-text">Cloud Manager Connector는 어디에 구축합니까?</block>
  <block id="43fd5c6fa3d9ba8a215c31f3bf0a9859" category="list-text">Cloud Volume ONTAP 사이징 및 아키텍처</block>
  <block id="7a0e00d70e3b0ff06476a52565f923c4" category="list-text">단일 노드 또는 고가용성?</block>
  <block id="2d0b46fff3ae203a435b167c7111b389" category="paragraph">다음 링크에서 자세한 내용을 확인할 수 있습니다.</block>
  <block id="cfd98f49422c4fba755a2ff74c55a4a0" category="paragraph"><block ref="cfd98f49422c4fba755a2ff74c55a4a0" category="inline-link-macro-rx"></block></block>
  <block id="704849d56e695ab8f9df0b106e0d7e33" category="inline-link-macro">퍼블릭 클라우드</block>
  <block id="96e41b2b281ca4b71edf4ed16e46a2be" category="paragraph"><block ref="96e41b2b281ca4b71edf4ed16e46a2be" category="inline-link-macro-rx"></block></block>
  <block id="7c12725837ee75c4c0a9bbc14f99934d" category="inline-link-macro">다음: 온프레미스 필수 구성 요소.</block>
  <block id="bc57dd30a9059d494c9d76e4b0a9ce8f" category="paragraph"><block ref="bc57dd30a9059d494c9d76e4b0a9ce8f" category="inline-link-macro-rx"></block></block>
  <block id="9ce6d30135c2644ff34390c65af4061b" category="paragraph">조직은 효율성을 높이고, 구현을 앞당기고, 수동 작업을 줄이기 위해 환경을 자동화하고 있습니다. Ansible과 같은 구성 관리 툴을 사용하여 엔터프라이즈 데이터베이스 운영을 간소화하고 있습니다. 이 솔루션에서는 Ansible을 사용하여 NetApp ONTAP을 사용하여 Oracle 19c의 프로비저닝과 구성을 자동화하는 방법을 보여줍니다. 스토리지 관리자, 시스템 관리자 및 DBA가 새 스토리지를 일관성 있게 신속하게 구축하고 데이터베이스 서버를 구성하며 Oracle 19c 소프트웨어를 설치할 수 있도록 함으로써 다음과 같은 이점을 얻을 수 있습니다.</block>
  <block id="5291cb8e681983247b899ce2364188f2" category="list-text">설계 복잡성과 인적 오류를 제거하고 반복 가능한 일관된 구축 및 모범 사례를 구현합니다</block>
  <block id="a90516bf4597e04e1a97bd9cb37087d8" category="list-text">스토리지 프로비저닝, DB 호스트 구성, Oracle 설치 시간 단축</block>
  <block id="a54e59b6b063d8a2bf18acffab877d09" category="list-text">데이터베이스 관리자, 시스템 및 스토리지 관리자의 생산성 향상</block>
  <block id="d18d76441366273feb36bde890ad5e1c" category="list-text">스토리지와 데이터베이스를 손쉽게 확장</block>
  <block id="7d85c5a5f016aefeda6b89687f1307bb" category="paragraph">NetApp은 고객에게 검증된 Ansible 모듈과 역할을 제공하여 Oracle 데이터베이스 환경의 구축, 구성, 라이프사이클 관리를 가속합니다. 이 솔루션은 다음을 지원하기 위한 지침 및 Ansible 플레이북 코드를 제공합니다.</block>
  <block id="547b893b7cd300d6a8335f5b179ad12e" category="list-text">Oracle 데이터베이스용 ONTAP NFS 스토리지를 생성하고 구성합니다</block>
  <block id="36bb01ec9f02292fb44b9f10f57ceae7" category="list-text">RedHat Enterprise Linux 7/8 또는 Oracle Linux 7/8 에 Oracle 19c를 설치합니다</block>
  <block id="548bf87c41c9d3bb76981decbd599c90" category="list-text">ONTAP NFS 스토리지에 Oracle 19c를 구성합니다</block>
  <block id="950496934d91d07bb089d6ed0999b5a9" category="paragraph">자세한 내용을 보거나 시작하려면 아래의 개요 비디오를 참조하십시오.</block>
  <block id="b923f56ad2a53fa1a3ca1160e48f141e" category="section-title">AWX/타워 배포</block>
  <block id="ab81e47672e89830ec16c581f44cb23c" category="list-text">1부: 시작하기, 요구 사항, 자동화 세부 정보 및 초기 AWX/타워 구성</block>
  <block id="cf7bbd18f18fdc73ee49ffea888126c7" category="list-text">2부: 변수 및 Playbook 실행</block>
  <block id="f5e227cfa54c5693c512c6adf41a3772" category="section-title">CLI 배포</block>
  <block id="0b8a09b5974336d1f5e510d18205c03c" category="list-text">1부: 시작하기, 요구사항, 자동화 세부 정보 및 Ansible Control 호스트 설정</block>
  <block id="a10998cc3e1dc7f2a013754d935c4f26" category="summary">NetApp SnapCenter 툴은 RBAC(역할 기반 액세스 제어)를 사용하여 사용자 리소스 액세스 및 권한 부여를 관리하고 SnapCenter 설치를 통해 미리 채워진 역할을 생성합니다. 필요에 따라 사용자 지정 역할을 만들 수도 있습니다.</block>
  <block id="7e3b07f9add4cd78ade3c795a52dfad2" category="doc">온프레미스에서 시작합니다</block>
  <block id="32229cff9e0b41c513b3e3b9e19cec88" category="inline-link-macro">이전: 시작하기 개요</block>
  <block id="6be036b00e3db4159514171a989cacd6" category="paragraph"><block ref="6be036b00e3db4159514171a989cacd6" category="inline-link-macro-rx"></block></block>
  <block id="d30e54646ba482722332f48ddc22bde5" category="section-title">SnapCenter에서 데이터베이스 관리자 설정</block>
  <block id="72f706d19ed0d09889b4fbc7578cd1a3" category="paragraph">NetApp SnapCenter 툴은 RBAC(역할 기반 액세스 제어)를 사용하여 사용자 리소스 액세스 및 권한 부여를 관리하고 SnapCenter 설치를 통해 미리 채워진 역할을 생성합니다. 필요에 따라 사용자 지정 역할을 만들 수도 있습니다. 데이터베이스 백업, 복원 및/또는 재해 복구를 위해 SnapCenter에서 지원하는 각 데이터베이스 플랫폼에 대해 전용 관리 사용자 ID를 갖는 것이 적합합니다. 단일 ID를 사용하여 모든 데이터베이스를 관리할 수도 있습니다. 테스트 사례 및 데모에서는 Oracle과 SQL Server 모두에 대해 각각 전용 관리 사용자를 생성했습니다.</block>
  <block id="27733e8f07432bb94ac7621b28d3b2c8" category="paragraph">특정 SnapCenter 리소스는 SnapCenter 관리자 역할만 사용하여 프로비저닝할 수 있습니다. 그러면 액세스를 위해 리소스를 다른 사용자 ID에 할당할 수 있습니다.</block>
  <block id="64784aa3cec13e83af6e941f8489cf06" category="paragraph">사전 설치 및 구성된 사내 SnapCenter 환경에서는 다음 작업이 이미 완료되었을 수 있습니다. 그렇지 않은 경우 다음 단계에 따라 데이터베이스 관리자 사용자를 생성합니다.</block>
  <block id="c8867eac833e7bb55520105b00139f1a" category="list-text">Windows Active Directory에 관리자 사용자를 추가합니다.</block>
  <block id="dd3e743eb52cbe7c2b6104573a9767e0" category="list-text">SnapCenter CenterAdmin 역할로 부여된 ID를 사용하여 로그인합니다.</block>
  <block id="a6bd76cb24271ba173d16f01bf4108d0" category="list-text">설정 및 사용자 아래의 액세스 탭으로 이동하고 추가 를 클릭하여 새 사용자를 추가합니다. 새 사용자 ID는 1단계에서 Windows Active Directory에서 만든 관리자 사용자에게 연결됩니다. . 필요에 따라 사용자에게 적절한 역할을 할당합니다. 필요에 따라 admin 사용자에게 리소스를 할당합니다.</block>
  <block id="6a67bb048bd14dd348cca7f81b62d699" category="paragraph"><block ref="6a67bb048bd14dd348cca7f81b62d699" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5d2c51e83f473f137861a132554d1916" category="section-title">2.SnapCenter 플러그인 설치 필수 구성 요소입니다</block>
  <block id="7bd973d4d28d6fcf5f50379b33a49758" category="paragraph">SnapCenter는 DB 호스트에서 실행 중인 플러그인 에이전트를 사용하여 백업, 복구, 클론 및 기타 기능을 수행합니다. 플러그인 설치 및 기타 관리 기능을 위해 설정 및 자격 증명 탭에서 구성된 자격 증명을 통해 데이터베이스 호스트 및 데이터베이스에 연결합니다. Linux 또는 Windows와 같은 타겟 호스트 유형과 데이터베이스 유형에 따른 특정 권한 요구 사항이 있습니다.</block>
  <block id="c342f214098114b90cb67297a2ef5dc3" category="paragraph">SnapCenter 플러그인 설치 전에 DB 호스트 자격 증명을 구성해야 합니다. 일반적으로 플러그인 설치를 위한 호스트 연결 자격 증명으로 DB 호스트의 관리자 사용자 계정을 사용합니다. 또한 OS 기반 인증을 사용하여 데이터베이스 액세스에 동일한 사용자 ID를 부여할 수도 있습니다. 반면, DB 관리 액세스를 위해 서로 다른 데이터베이스 사용자 ID를 사용하여 데이터베이스 인증을 사용할 수도 있습니다. OS 기반 인증을 사용하기로 결정한 경우 OS 관리자 사용자 ID에 DB 액세스 권한이 부여되어야 합니다. Windows 도메인 기반 SQL Server 설치의 경우 도메인 관리자 계정을 사용하여 도메인 내의 모든 SQL Server를 관리할 수 있습니다.</block>
  <block id="19df1192effefad83e57653fd3a47415" category="paragraph">SQL Server용 Windows 호스트:</block>
  <block id="e1cc3ce53d7753e33588201db3d3b147" category="list-text">인증에 Windows 자격 증명을 사용하는 경우 플러그인을 설치하기 전에 자격 증명을 설정해야 합니다.</block>
  <block id="a82f1290b72a26d654b93632a1ec50bb" category="list-text">인증에 SQL Server 인스턴스를 사용하는 경우 플러그인을 설치한 후 자격 증명을 추가해야 합니다.</block>
  <block id="63f74bef6650942c6795f96366a39e6a" category="list-text">자격 증명을 설정하는 동안 SQL 인증을 사용하도록 설정한 경우 검색된 인스턴스 또는 데이터베이스에 빨간색 잠금 아이콘이 표시됩니다. 잠금 아이콘이 나타나면 인스턴스 또는 데이터베이스 자격 증명을 지정하여 인스턴스 또는 데이터베이스를 리소스 그룹에 성공적으로 추가해야 합니다.</block>
  <block id="b61dad3bbbf3270bf2dada5c2ac1f775" category="list-text">다음 조건이 충족될 경우 sysadmin 액세스 없이 RBAC 사용자에게 자격 증명을 할당해야 합니다.</block>
  <block id="34cefb5a19894e4f9b1b068544c0f591" category="list-text">자격 증명이 SQL 인스턴스에 할당됩니다.</block>
  <block id="6707464a5871a6aa26dcf785bea4052c" category="list-text">SQL 인스턴스 또는 호스트는 RBAC 사용자에게 할당됩니다.</block>
  <block id="4bc8aac02ff00d874ad8b4ccd4d745ed" category="list-text">RBAC DB 관리자 사용자에게는 리소스 그룹과 백업 권한이 모두 있어야 합니다.</block>
  <block id="9198b455aa67840c7a69c7a54e94301a" category="paragraph">Oracle용 UNIX 호스트:</block>
  <block id="71d53e54a48cfe7de69347bcd854ef30" category="list-text">sshd.conf를 편집하고 sshd 서비스를 다시 시작하여 루트 또는 루트 이외의 사용자에 대해 암호 기반 SSH 연결을 활성화해야 합니다. AWS 인스턴스의 암호 기반 SSH 인증은 기본적으로 해제되어 있습니다.</block>
  <block id="efa873f0464a14d54b066f475ad74480" category="list-text">비루트 사용자에 대한 sudo 권한을 구성하여 플러그인 프로세스를 설치 및 시작합니다. 플러그인을 설치하면 프로세스가 효과적인 루트 사용자로 실행됩니다.</block>
  <block id="82a2174029175f8fbc3f52fea4e18c84" category="list-text">설치 사용자에 대한 Linux 인증 모드를 사용하여 자격 증명을 생성합니다.</block>
  <block id="86b3cc44ebd8e0a9185e48c4f22e81e9" category="list-text">Linux 호스트에 Java 1.8.x(64비트)를 설치해야 합니다.</block>
  <block id="c1e8851d10ecc615c47a47f704569d29" category="list-text">Oracle 데이터베이스 플러그인을 설치하면 Unix용 SnapCenter 플러그인도 설치됩니다.</block>
  <block id="7efb27733d1fb21feae901a41580dced" category="section-title">3.SnapCenter 호스트 플러그인 설치</block>
  <block id="37a5c714defad8175b81b4d49eb0544c" category="admonition">클라우드 DB 서버 인스턴스에 SnapCenter 플러그인을 설치하기 전에 컴퓨팅 인스턴스 구축을 위한 관련 클라우드 섹션에 나와 있는 대로 모든 구성 단계를 완료해야 합니다.</block>
  <block id="283aa502c28fe1c9ff8dadd1700955fc" category="paragraph">다음 단계에서는 SnapCenter 플러그인이 호스트에 설치되어 있는 동안 데이터베이스 호스트를 SnapCenter에 추가하는 방법을 보여 줍니다. 이 절차는 사내 호스트와 클라우드 호스트를 모두 추가하는 데 적용됩니다. 다음 데모에서는 AWS에 상주하는 Windows 또는 Linux 호스트를 추가합니다.</block>
  <block id="81ed46777c39c0d0618953601572fc27" category="section-title">SnapCenter VMware 글로벌 설정을 구성합니다</block>
  <block id="2aa8a40dbbfb6b52621408c81aa5373c" category="paragraph">설정 &gt; 전역 설정 으로 이동합니다. 하이퍼바이저 설정 에서 "VM에 모든 호스트에 대한 iSCSI 직접 연결 디스크 또는 NFS가 있음"을 선택하고 업데이트 를 클릭합니다.</block>
  <block id="4c120331c9eea223eee675b6588d76ee" category="paragraph"><block ref="4c120331c9eea223eee675b6588d76ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1f63a469619859e4cfab52fd63523aca" category="section-title">호스트에 Windows 호스트 및 플러그인 설치를 추가합니다</block>
  <block id="997da6deedab4436b559e3a8f7f05a2e" category="list-text">SnapCenter에 SnapCenterAdmin 권한으로 사용자 ID를 사용하여 로그인합니다.</block>
  <block id="97e7f600216a2e9ae18423777e11ad9c" category="list-text">왼쪽 메뉴에서 호스트 탭을 클릭한 다음 추가를 클릭하여 호스트 추가 워크플로우를 엽니다.</block>
  <block id="35314bae57d7ff62ab36156211c1cc71" category="list-text">호스트 유형에 Windows를 선택합니다. 호스트 이름은 호스트 이름 또는 IP 주소일 수 있습니다. 호스트 이름은 SnapCenter 호스트에서 올바른 호스트 IP 주소로 확인되어야 합니다. 2단계에서 생성한 호스트 자격 증명을 선택합니다. 설치할 플러그인 패키지로 Microsoft Windows 및 Microsoft SQL Server를 선택합니다.</block>
  <block id="b9740ae9eb2ef0fe27e4c541d06a961f" category="paragraph"><block ref="b9740ae9eb2ef0fe27e4c541d06a961f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31efcd689861354799bb539ab2571ebe" category="list-text">Windows 호스트에 플러그인을 설치하면 전체 상태가 "Configure log directory"로 표시됩니다.</block>
  <block id="0e15e25c5ee21469698f72cf35caa7bf" category="paragraph"><block ref="0e15e25c5ee21469698f72cf35caa7bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2aeaa4503c6d72513c0dbe0f205ee3b" category="list-text">호스트 이름을 클릭하여 SQL Server 로그 디렉토리 구성을 엽니다.</block>
  <block id="6fc78660a180b747f815b878c89e3cb0" category="paragraph"><block ref="6fc78660a180b747f815b878c89e3cb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb2b40646a77b4f044e7fa04ea20306" category="list-text">"로그 디렉토리 구성"을 클릭하여 "SQL Server용 플러그인 구성"을 엽니다.</block>
  <block id="5e3bf9ddacfcad12c5cf63614a869ad4" category="paragraph"><block ref="5e3bf9ddacfcad12c5cf63614a869ad4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7143b5d162d385dfb1af07f61c59f65" category="list-text">찾아보기 를 클릭하여 로그 디렉토리를 설정할 수 있도록 NetApp 스토리지를 검색합니다. SnapCenter는 이 로그 디렉토리를 사용하여 SQL Server 트랜잭션 로그 파일을 롤업합니다. 저장을 클릭합니다.</block>
  <block id="50eb49de485da684ac1556947ac46aba" category="paragraph"><block ref="50eb49de485da684ac1556947ac46aba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0d88588bdb07dd412a4ba1d08348b29" category="admonition">DB 호스트에 프로비저닝된 NetApp 스토리지의 경우 CVO의 6단계에 나와 있는 것처럼 SnapCenter에 스토리지(온프레미스 또는 CVO)를 추가해야 합니다.</block>
  <block id="d744af12906d55ab51aa932b3ffcd121" category="list-text">로그 디렉토리가 구성된 후 Windows 호스트 플러그인 전체 상태가 실행 중 으로 변경됩니다.</block>
  <block id="3f7bfffdbb76fd620b0a31d300415528" category="paragraph"><block ref="3f7bfffdbb76fd620b0a31d300415528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41517f2e270a138f4ae92988a4cbdd2" category="list-text">데이터베이스를 관리하는 사용자 ID에 호스트를 할당하려면 설정 및 사용자 아래의 액세스 탭으로 이동하고 데이터베이스 관리 사용자 ID(호스트를 할당해야 하는 sqlldba인 경우)를 클릭한 다음 저장 을 클릭하여 호스트 리소스 할당을 완료합니다.</block>
  <block id="b21f826d2ea15e58b9c8aadccb566cfe" category="paragraph"><block ref="b21f826d2ea15e58b9c8aadccb566cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021de72edbb0f174ffe954c5e5367b80" category="paragraph"><block ref="021de72edbb0f174ffe954c5e5367b80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2fe19c733a6342990513e02264db163" category="section-title">Unix 호스트를 추가하고 호스트에 플러그인을 설치합니다</block>
  <block id="6a0f36be9f208d20c3c1145c3a09b876" category="list-text">왼쪽 메뉴에서 호스트 탭을 클릭하고 추가 를 클릭하여 호스트 추가 워크플로우를 엽니다.</block>
  <block id="dd8c6d773e31c4254eb58b4b5e2ae1be" category="list-text">호스트 유형으로 Linux를 선택합니다. 호스트 이름은 호스트 이름 또는 IP 주소일 수 있습니다. 그러나 SnapCenter 호스트에서 호스트 IP 주소를 수정하려면 호스트 이름을 확인해야 합니다. 2단계에서 만든 호스트 자격 증명을 선택합니다. 호스트 자격 증명에는 sudo 권한이 필요합니다. Oracle Database를 설치할 플러그인으로 선택하여 Oracle 및 Linux 호스트 플러그인을 모두 설치합니다.</block>
  <block id="7d4cdef2144fd1466fae298bd27476d1" category="paragraph"><block ref="7d4cdef2144fd1466fae298bd27476d1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="711730391561a228d41f7fede13ca6e8" category="list-text">기타 옵션 을 클릭하고 "설치 전 검사 건너뛰기"를 선택합니다. 사전 설치 검사를 건너뛰는 것을 확인하는 메시지가 표시됩니다. 예 를 클릭한 다음 저장 을 클릭합니다.</block>
  <block id="3511b18d059f3f300b5fbe827f7273ac" category="paragraph"><block ref="3511b18d059f3f300b5fbe827f7273ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e095a093138c6b1968d313d5f799255a" category="list-text">제출 을 클릭하여 플러그인 설치를 시작합니다. 아래와 같이 지문을 확인하라는 메시지가 표시됩니다.</block>
  <block id="146c4805beb9310e4554842f776cb88b" category="paragraph"><block ref="146c4805beb9310e4554842f776cb88b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53dcda6f2c03efbe73ae5eb311852a8d" category="list-text">SnapCenter는 호스트 검증 및 등록을 수행한 다음 Linux 호스트에 플러그인을 설치합니다. 상태가 플러그인 설치 에서 실행 중 으로 변경됩니다.</block>
  <block id="2636403a6c50748422736d9d84a3e4be" category="paragraph"><block ref="2636403a6c50748422736d9d84a3e4be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="33ea9d9313933c68d640ebb655ec43dc" category="list-text">새로 추가된 호스트를 적절한 데이터베이스 관리 사용자 ID(여기서는 oradba)에 할당합니다.</block>
  <block id="2815d2f5e3b49d9332a320ec997271dd" category="paragraph"><block ref="2815d2f5e3b49d9332a320ec997271dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb6a9566891a97e0f8fbaefbd4878bdd" category="paragraph"><block ref="eb6a9566891a97e0f8fbaefbd4878bdd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b4c839521fd41e845e6e8c3158b809b" category="section-title">4.데이터베이스 리소스 검색</block>
  <block id="45e46a9524f23884445bf542bf464b93" category="paragraph">플러그인 설치가 완료되면 호스트의 데이터베이스 리소스를 즉시 검색할 수 있습니다. 왼쪽 메뉴에서 리소스 탭을 클릭합니다. 데이터베이스 플랫폼 유형에 따라 데이터베이스, 리소스 그룹 등과 같은 다양한 보기를 사용할 수 있습니다. 호스트의 리소스가 검색되지 않고 표시되지 않으면 리소스 새로 고침 탭을 클릭해야 할 수도 있습니다.</block>
  <block id="79fca6395972f8079320d3229822e491" category="paragraph"><block ref="79fca6395972f8079320d3229822e491" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66789731e61fd3d4b6024e5fcb0945e1" category="paragraph">데이터베이스가 처음 검색되면 전체 상태가 "보호되지 않음"으로 표시됩니다. 이전 스크린샷은 아직 백업 정책에 의해 보호되지 않은 Oracle 데이터베이스를 보여 줍니다.</block>
  <block id="68148a1249ca9110d03c698ae152932a" category="paragraph">백업 구성 또는 정책을 설정하고 백업을 실행한 경우 데이터베이스의 전체 상태는 백업 상태를 "Backup Succeeded"로 표시하고 마지막 백업의 타임스탬프를 표시합니다. 다음 스크린샷은 SQL Server 사용자 데이터베이스의 백업 상태를 보여 줍니다.</block>
  <block id="2cdfb74ac3aabfde7e1fae347ed5afc7" category="paragraph"><block ref="2cdfb74ac3aabfde7e1fae347ed5afc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c9616324bc00808729d46fba94ad75" category="paragraph">데이터베이스 액세스 자격 증명이 제대로 설정되어 있지 않으면 빨간색 잠금 단추가 데이터베이스에 액세스할 수 없음을 나타냅니다. 예를 들어, Windows 자격 증명에 데이터베이스 인스턴스에 대한 sysadmin 액세스 권한이 없는 경우 데이터베이스 자격 증명을 다시 구성하여 빨간색 잠금을 해제해야 합니다.</block>
  <block id="dd4606e87689c86d82a694412c5654a5" category="paragraph"><block ref="dd4606e87689c86d82a694412c5654a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="884f07ad394b89553e7d6d1f90fae584" category="paragraph"><block ref="884f07ad394b89553e7d6d1f90fae584" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0024854a814ddd68bcf3907357c46bc2" category="paragraph">Windows 수준 또는 데이터베이스 수준에서 적절한 자격 증명이 구성되면 빨간색 잠금이 사라지고 SQL Server 유형 정보가 수집 및 검토됩니다.</block>
  <block id="95c88e08b2fd416b4514ce2454af2038" category="paragraph"><block ref="95c88e08b2fd416b4514ce2454af2038" category="inline-image-macro-rx" type="image"></block></block>
  <block id="864f4d2595d06e5e8b46b08edb3899e6" category="section-title">스토리지 클러스터 피어링 및 DB 볼륨 복제를 설정합니다</block>
  <block id="785196ec55a9e713ad1a4f962baa31dd" category="paragraph">퍼블릭 클라우드를 타겟 대상으로 사용하여 사내 데이터베이스 데이터를 보호하기 위해 NetApp SnapMirror 기술을 사용하여 사내 ONTAP 클러스터 데이터베이스 볼륨을 클라우드의 CVO에 복제합니다. 그런 다음 복제된 타겟 볼륨을 개발/OPS 또는 재해 복구를 위해 복제할 수 있습니다. 다음은 클러스터 피어링을 설정하고 DB 볼륨 복제를 설정하는 상위 단계입니다.</block>
  <block id="1f1927293f04e4cf0fc91a7e389612eb" category="list-text">온프레미스 클러스터와 CVO 클러스터 인스턴스 모두에서 클러스터 피어링을 위해 인터클러스터 LIF를 구성합니다. 이 단계는 ONTAP 시스템 관리자로 수행할 수 있습니다. 기본 CVO 배포에는 클러스터 간 LIF가 자동으로 구성됩니다.</block>
  <block id="9547803d96e78bbc38305e6300f7a800" category="paragraph">사내 클러스터:</block>
  <block id="2ef6da9ba547bc5361495650ac3fc992" category="paragraph"><block ref="2ef6da9ba547bc5361495650ac3fc992" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3c5b3e342f57b792e2263e69e41677a" category="paragraph">타겟 CVO 클러스터:</block>
  <block id="d94586e4cd285619a4f1ef0e06636dd1" category="paragraph"><block ref="d94586e4cd285619a4f1ef0e06636dd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79d372933b80ed2ca8ca14d8458828af" category="inline-link-macro">시작하기 - AWS 퍼블릭 클라우드</block>
  <block id="6a87ea28950f9209121872c9d2690049" category="list-text">인터클러스터 LIF가 구성된 경우 NetApp Cloud Manager의 끌어서 놓기를 사용하여 클러스터 피어링을 설정하고 볼륨 복제를 설정할 수 있습니다. 을 참조하십시오 <block ref="28783e162df4af496939d6f9f6f31d5f" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="d1567c6c8f0752cbc7deb6d9f639ba12" category="paragraph">또는 ONTAP System Manager를 사용하여 다음과 같이 클러스터 피어링을 수행하고 DB 볼륨 복제를 수행할 수 있습니다.</block>
  <block id="494c0b53ff31502c0c1105881e2e389a" category="list-text">ONTAP 시스템 관리자에 로그인합니다. 클러스터 &gt; 설정 으로 이동하고 피어 클러스터 를 클릭하여 클라우드의 CVO 인스턴스로 클러스터 피어링을 설정합니다.</block>
  <block id="ba770272a0f634af47a5788634e80d54" category="paragraph"><block ref="ba770272a0f634af47a5788634e80d54" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54de72c782c4b4ccc7f2914a858d5356" category="list-text">볼륨 탭으로 이동합니다. 복제할 데이터베이스 볼륨을 선택하고 보호 를 클릭합니다.</block>
  <block id="32588f46a47679329b03194fd2e9084f" category="paragraph"><block ref="32588f46a47679329b03194fd2e9084f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b0aace069b478e8b2b0753f855f2be94" category="list-text">보호 정책을 Asynchronous로 설정합니다. 대상 클러스터와 스토리지 SVM을 선택합니다.</block>
  <block id="7dbec53b432ae53f7e454836ad0dad00" category="paragraph"><block ref="7dbec53b432ae53f7e454836ad0dad00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a2a64fe8af0790615a9344069794e2e" category="list-text">볼륨이 소스와 타겟 간에 동기화되고 복제 관계가 정상 상태인지 확인합니다.</block>
  <block id="97edcd79a5e90d9caafde40fcb586185" category="paragraph"><block ref="97edcd79a5e90d9caafde40fcb586185" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36097c4ad6058de288de8992f89adbb8" category="section-title">CVO 데이터베이스 스토리지 SVM을 SnapCenter에 추가합니다</block>
  <block id="ebcf85d67af3f672ade8bd7b224a8a2b" category="list-text">메뉴에서 스토리지 시스템 탭을 클릭한 다음 새로 만들기를 클릭하여 복제된 타겟 데이터베이스 볼륨을 SnapCenter에 호스팅하는 CVO 스토리지 SVM을 추가합니다. 스토리지 시스템 필드에 클러스터 관리 IP를 입력하고 적절한 사용자 이름과 암호를 입력합니다.</block>
  <block id="41e9c94a0c8cb108959099b8f87adb82" category="paragraph"><block ref="41e9c94a0c8cb108959099b8f87adb82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a27406b63f99780f65572b95f2f72348" category="list-text">추가 옵션을 클릭하여 추가 스토리지 구성 옵션을 엽니다. 플랫폼 필드에서 Cloud Volumes ONTAP 를 선택하고 보조 를 선택한 다음 저장 을 클릭합니다.</block>
  <block id="8a60464ab91cb2499a03c722639c3aee" category="paragraph"><block ref="8a60464ab91cb2499a03c722639c3aee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b474a0a2de59b8e3013112beb48af7b7" category="list-text">에 나와 있는 대로 스토리지 시스템을 SnapCenter 데이터베이스 관리 사용자 ID에 할당합니다 <block ref="8a46cbc3838a53b9205abb25a577bbc8" category="inline-xref-macro-rx"></block>.</block>
  <block id="8691f91a1fe977fd76aa5e53b0f71034" category="paragraph"><block ref="8691f91a1fe977fd76aa5e53b0f71034" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39ec95149453e7bb6b73f1c03228e85c" category="section-title">SnapCenter에서 데이터베이스 백업 정책을 설정합니다</block>
  <block id="37d9f685e375f77a2231e13c88ccc606" category="paragraph">다음 절차에서는 전체 데이터베이스 또는 로그 파일 백업 정책을 만드는 방법을 보여 줍니다. 그런 다음 이 정책을 구현하여 데이터베이스 리소스를 보호할 수 있습니다. RPO(복구 지점 목표) 또는 RTO(복구 시간 목표)는 데이터베이스 및/또는 로그 백업의 빈도를 결정합니다.</block>
  <block id="739184f368f13e142dd034fcdc853594" category="section-title">Oracle에 대한 전체 데이터베이스 백업 정책을 생성합니다</block>
  <block id="94b39254a7aba068b68fec64f6331b0b" category="list-text">SnapCenter에 데이터베이스 관리 사용자 ID로 로그인하고 설정을 클릭한 다음 정책을 클릭합니다.</block>
  <block id="90affc4ffbb767a3d1272be5e1ad8f0c" category="paragraph"><block ref="90affc4ffbb767a3d1272be5e1ad8f0c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a1d144b8c78fc8541b57aa9f0ca863a6" category="list-text">New(새로 만들기) 를 클릭하여 새 백업 정책 생성 워크플로우를 시작하거나 수정할 기존 정책을 선택합니다.</block>
  <block id="29618ae8465c694d23d68e171fe9d905" category="paragraph"><block ref="29618ae8465c694d23d68e171fe9d905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8c9dac29c26006ce512153a9bdabcc95" category="list-text">백업 유형 및 스케줄 빈도를 선택합니다.</block>
  <block id="10e2791563a2891fd7e4e68c5673671b" category="paragraph"><block ref="10e2791563a2891fd7e4e68c5673671b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4df94ad44381c9fb7fe2f8d01dcd16d8" category="list-text">백업 보존 설정을 지정합니다. 이 경우 보관할 전체 데이터베이스 백업 복사본 수가 정의됩니다.</block>
  <block id="6dcc4aa023085480846059b6b1d5e5b3" category="paragraph"><block ref="6dcc4aa023085480846059b6b1d5e5b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fd634020906b35a41e0ba633eddeb96a" category="list-text">클라우드의 2차 위치에 복제할 로컬 기본 스냅샷 백업을 푸시할 2차 복제 옵션을 선택합니다.</block>
  <block id="25ef9e4c73a2da8519e8d232b6a95fcb" category="paragraph"><block ref="25ef9e4c73a2da8519e8d232b6a95fcb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2e3af55a4355bc46e91425ac5701174" category="list-text">백업 실행 전후에 실행할 선택적 스크립트를 지정합니다.</block>
  <block id="326d50fae4f713cebe97d0f6bb23a2d9" category="paragraph"><block ref="326d50fae4f713cebe97d0f6bb23a2d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd009bc210e371d36d466b592179e883" category="list-text">필요한 경우 백업 검증을 실행합니다.</block>
  <block id="0b132e3438f5cf31e90f45e79710f0b9" category="paragraph"><block ref="0b132e3438f5cf31e90f45e79710f0b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba73d3ec3f929ff18665087076291ac" category="list-text">요약.</block>
  <block id="4f92fa99421beeb9f74ee7613de52706" category="paragraph"><block ref="4f92fa99421beeb9f74ee7613de52706" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3594f2789840eda9633139ca530384a" category="section-title">Oracle에 대한 데이터베이스 로그 백업 정책을 생성합니다</block>
  <block id="be763ec2afcb0358426bb0abcae4dd60" category="list-text">데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인하고 설정을 클릭한 다음 정책을 클릭합니다.</block>
  <block id="b0e663a3d363868d6c71ab9ec37940c6" category="list-text">새로 만들기 를 클릭하여 새 백업 정책 생성 워크플로우를 시작하거나 수정할 기존 정책을 선택합니다.</block>
  <block id="fa2687f5a5fbedb43745f649a2e11950" category="paragraph"><block ref="fa2687f5a5fbedb43745f649a2e11950" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0938f6574b189bdac27cdd92abc521c5" category="paragraph"><block ref="0938f6574b189bdac27cdd92abc521c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59480846ec23463481d361bf3026235e" category="list-text">로그 보존 기간을 설정합니다.</block>
  <block id="c8df578fbf71151edda735bc81e8511c" category="paragraph"><block ref="c8df578fbf71151edda735bc81e8511c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04ba33c0584145006ca637b4556aa919" category="list-text">퍼블릭 클라우드의 2차 위치에 복제</block>
  <block id="fdbe42a8484a3e984e4aacb6a31cccef" category="paragraph"><block ref="fdbe42a8484a3e984e4aacb6a31cccef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab9406cbd3a8f082700523fdac8a0c1d" category="list-text">로그 백업 전후에 실행할 선택적 스크립트를 지정합니다.</block>
  <block id="5b04423521e56720f1f5d0291db584ef" category="paragraph"><block ref="5b04423521e56720f1f5d0291db584ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4b55e05a9ae89fe14377b98bc8a8166" category="list-text">백업 검증 스크립트를 지정합니다.</block>
  <block id="c4dc219fd9466ab86c22ac8e859384ea" category="paragraph"><block ref="c4dc219fd9466ab86c22ac8e859384ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2564f2d008c62044da1b7f7397252edf" category="paragraph"><block ref="2564f2d008c62044da1b7f7397252edf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe147647227dfec6603bc76daf30463e" category="section-title">SQL에 대한 전체 데이터베이스 백업 정책을 생성합니다</block>
  <block id="fa726a7e85857bee77ace96dcf7e5316" category="paragraph"><block ref="fa726a7e85857bee77ace96dcf7e5316" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ce2168daff0c9b1a74e59d999d6ead44" category="paragraph"><block ref="ce2168daff0c9b1a74e59d999d6ead44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30637cfd5a5cc820d6bc4116fccfff7e" category="list-text">백업 옵션 및 예약 빈도를 정의합니다. 가용성 그룹으로 구성된 SQL Server의 경우 기본 백업 복제본을 설정할 수 있습니다.</block>
  <block id="b520dcfd25c4b29395bb9b12ac643bb2" category="paragraph"><block ref="b520dcfd25c4b29395bb9b12ac643bb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f74ada8393aecd40e892de04b5b30f8" category="list-text">백업 보존 기간을 설정합니다.</block>
  <block id="4ade95d8122243cda1455b04504d3367" category="paragraph"><block ref="4ade95d8122243cda1455b04504d3367" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1a67a80a7ad9403781b210983ea778d" category="list-text">클라우드의 2차 위치에 백업 복사본을 복제할 수 있습니다.</block>
  <block id="caf8324e53d9bb41b3ecb64f3e3b7dda" category="paragraph"><block ref="caf8324e53d9bb41b3ecb64f3e3b7dda" category="inline-image-macro-rx" type="image"></block></block>
  <block id="17b7b360fc2163537795a34cd8d14d6a" category="list-text">백업 작업 전후에 실행할 선택적 스크립트를 지정합니다.</block>
  <block id="abbc7de57d2b0d5d1c462b7513199253" category="paragraph"><block ref="abbc7de57d2b0d5d1c462b7513199253" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb836d972496d965dd2170ed1480917b" category="list-text">백업 확인을 실행할 옵션을 지정합니다.</block>
  <block id="b4dd01df6b310e6b0814328a86bd6ed6" category="paragraph"><block ref="b4dd01df6b310e6b0814328a86bd6ed6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67cfb8548ccb78172db31d7af494fa02" category="paragraph"><block ref="67cfb8548ccb78172db31d7af494fa02" category="inline-image-macro-rx" type="image"></block></block>
  <block id="02b67ed2348002e614d5a35151577632" category="section-title">SQL에 대한 데이터베이스 로그 백업 정책을 생성합니다.</block>
  <block id="b405195aec7cf62440373fcdc490dec6" category="list-text">데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인하고 설정 &gt; 정책 을 클릭한 다음 새로 만들기 를 클릭하여 새 정책 생성 워크플로를 시작합니다.</block>
  <block id="c236030076b67936a7c1c11d49408838" category="paragraph"><block ref="c236030076b67936a7c1c11d49408838" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acdaf46fc90606d68f3f2b52cca5e95b" category="list-text">로그 백업 옵션 및 스케줄 빈도를 정의합니다. 가용성 그룹으로 구성된 SQL Server의 경우 기본 백업 복제본을 설정할 수 있습니다.</block>
  <block id="19ab604707a9384fa4883cedd5a525f9" category="paragraph"><block ref="19ab604707a9384fa4883cedd5a525f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da00d968a5d810d846ddc815b8f405a4" category="list-text">SQL Server 데이터 백업 정책은 로그 백업 보존을 정의합니다. 여기서 기본값을 사용합니다.</block>
  <block id="783828e5ae6dcfd713966e7301831296" category="paragraph"><block ref="783828e5ae6dcfd713966e7301831296" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d04d89062d3ed67bbc9c4aee35bdba7f" category="list-text">클라우드의 2차 사이트에 로그 백업 복제를 설정합니다.</block>
  <block id="b1968bd01bc5c402dcd27c99ce6326cc" category="paragraph"><block ref="b1968bd01bc5c402dcd27c99ce6326cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="30c50cf9d6726341a29a3caf97dc84e8" category="paragraph"><block ref="30c50cf9d6726341a29a3caf97dc84e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4d9b291b4ffaddb50c99313e530077f" category="paragraph"><block ref="c4d9b291b4ffaddb50c99313e530077f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f28f6c36698b3a4cd47cbeead15eddf2" category="section-title">데이터베이스를 보호하기 위해 백업 정책을 구현합니다</block>
  <block id="37b889cc1b57f66ae9018b6eacb891ba" category="paragraph">SnapCenter는 리소스 그룹을 사용하여 서버에서 호스팅되는 여러 데이터베이스, 동일한 스토리지 볼륨을 공유하는 데이터베이스, 비즈니스 애플리케이션을 지원하는 여러 데이터베이스 등 데이터베이스 리소스의 논리적 그룹으로 데이터베이스를 백업합니다. 단일 데이터베이스를 보호하면 고유한 리소스 그룹이 만들어집니다. 다음 절차에서는 Oracle 및 SQL Server 데이터베이스를 보호하기 위해 섹션 7에서 만든 백업 정책을 구현하는 방법을 보여 줍니다.</block>
  <block id="0603dbbe978e4cd3ee1c45ba96a1aa6f" category="section-title">Oracle의 전체 백업을 위한 리소스 그룹을 생성합니다</block>
  <block id="5f4e02f34bcd7993867c4b3297a171d0" category="list-text">데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인하고 리소스 탭으로 이동합니다. 보기 드롭다운 목록에서 데이터베이스 또는 리소스 그룹을 선택하여 리소스 그룹 만들기 워크플로를 시작합니다.</block>
  <block id="6eac6f96ac8d968dfec8184d16a73d43" category="paragraph"><block ref="6eac6f96ac8d968dfec8184d16a73d43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="98dcf41bcde9cb6c4235a6a7dfe69346" category="list-text">리소스 그룹의 이름과 태그를 입력합니다. 스냅샷 복사본의 명명 형식을 정의하고 구성된 경우 중복 아카이브 로그 대상을 건너뛸 수 있습니다.</block>
  <block id="a75ba82042ae54dd2e68cf6c7a26614c" category="paragraph"><block ref="a75ba82042ae54dd2e68cf6c7a26614c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0cd85a82e6f02b779006b158b9c5f828" category="list-text">리소스 그룹에 데이터베이스 리소스를 추가합니다.</block>
  <block id="3836a8be1f86b6658a7fa6b180e4a72d" category="paragraph"><block ref="3836a8be1f86b6658a7fa6b180e4a72d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cee52cb6702e7590fbef45eccc8fb2df" category="list-text">드롭다운 목록에서 섹션 7에 생성된 전체 백업 정책을 선택합니다.</block>
  <block id="af900bffdda986bc1db955ae78832742" category="paragraph"><block ref="af900bffdda986bc1db955ae78832742" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fe872cd84ea2e9051770379e63f9caf" category="list-text">(+) 기호를 클릭하여 원하는 백업 일정을 구성합니다.</block>
  <block id="9da504fd8ab60cfcc873608530cf5d56" category="paragraph"><block ref="9da504fd8ab60cfcc873608530cf5d56" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdc27a4c5d48dbfc04f81ecac85acd64" category="list-text">Load Locators(로케이터 로드) 를 클릭하여 소스 및 대상 볼륨을 로드합니다.</block>
  <block id="7242164857e43688f8a7bec97559c36e" category="paragraph"><block ref="7242164857e43688f8a7bec97559c36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a752afaf144d06159ca3eec8bb23455f" category="list-text">필요한 경우 이메일 알림에 사용할 SMTP 서버를 구성합니다.</block>
  <block id="b612dc8868902cf8fbf2b1024ad94e65" category="paragraph"><block ref="b612dc8868902cf8fbf2b1024ad94e65" category="inline-image-macro-rx" type="image"></block></block>
  <block id="95633243861715786b64e1554b629435" category="paragraph"><block ref="95633243861715786b64e1554b629435" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f7192b9766e6f09c261f3ca3d3bddc8" category="section-title">Oracle의 로그 백업을 위한 리소스 그룹을 생성합니다</block>
  <block id="1a0cd5de7c84ddbf632838dd9f510d37" category="paragraph"><block ref="1a0cd5de7c84ddbf632838dd9f510d37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0ad3d9537c50952c04b71be3f9d4579" category="paragraph"><block ref="f0ad3d9537c50952c04b71be3f9d4579" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c33c31714f671e112fbe52b660d3e7a4" category="paragraph"><block ref="c33c31714f671e112fbe52b660d3e7a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03955b73285eab0d68e90c627da9726d" category="list-text">드롭다운 목록에서 섹션 7에 생성된 로그 백업 정책을 선택합니다.</block>
  <block id="6286629570d2ca91cf6860e7da6e9073" category="paragraph"><block ref="6286629570d2ca91cf6860e7da6e9073" category="inline-image-macro-rx" type="image"></block></block>
  <block id="88c73129e9a418955658ce5c48d9d8b5" category="list-text">(+) 기호를 클릭하여 원하는 백업 일정을 구성합니다.</block>
  <block id="8cdd30063d988671ffa9240fe171b1ce" category="paragraph"><block ref="8cdd30063d988671ffa9240fe171b1ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eacfd6f10777b8dfb41199e4d4dfa915" category="list-text">백업 검증이 구성된 경우 여기에 표시됩니다.</block>
  <block id="69911c1794125b768effca94c8153987" category="paragraph"><block ref="69911c1794125b768effca94c8153987" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a27fac4b1d49d5468930a56c3a6de56" category="list-text">필요한 경우 e-메일 알림을 위한 SMTP 서버를 구성합니다.</block>
  <block id="fd540644538dcedf1f6543455447728f" category="paragraph"><block ref="fd540644538dcedf1f6543455447728f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="554dbe35f6afa38e8232497f5d05d1c1" category="paragraph"><block ref="554dbe35f6afa38e8232497f5d05d1c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf688c7a95f421447e84a47fd03f3aa2" category="section-title">SQL Server의 전체 백업을 위한 리소스 그룹을 생성합니다</block>
  <block id="d08ef097ee33c4a3506183adeb51c5e7" category="list-text">데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인하고 리소스 탭으로 이동합니다. 보기 드롭다운 목록에서 데이터베이스 또는 리소스 그룹을 선택하여 리소스 그룹 만들기 워크플로를 시작합니다. 리소스 그룹의 이름과 태그를 입력합니다. 스냅샷 복사본의 명명 형식을 정의할 수 있습니다.</block>
  <block id="87d2630813d214672697efc01974d64e" category="paragraph"><block ref="87d2630813d214672697efc01974d64e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ace5324d60cb3faa1863efd675149" category="list-text">백업할 데이터베이스 리소스를 선택합니다.</block>
  <block id="15330fe5b8f32032bd3b30c091d7dc4b" category="paragraph"><block ref="15330fe5b8f32032bd3b30c091d7dc4b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2fc1974f486effa4a60bf216e63a88d5" category="list-text">섹션 7에서 생성한 전체 SQL 백업 정책을 선택합니다.</block>
  <block id="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="paragraph"><block ref="dc34bd5487acb7fcd3dcc3f23b2bbc5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b70beeb570488ba753a620378cacd8" category="list-text">백업 빈도와 정확한 백업 시간을 추가합니다.</block>
  <block id="8fa0a3897bc03e9b1653d17308464031" category="paragraph"><block ref="8fa0a3897bc03e9b1653d17308464031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49252579bd8140847f4bbac20ef89b07" category="list-text">백업 확인을 수행할 경우 보조 백업에 대한 검증 서버를 선택합니다. Load Locator를 클릭하여 보조 스토리지 위치를 채웁니다.</block>
  <block id="355e5eb56524b7365674014ea5868ee6" category="paragraph"><block ref="355e5eb56524b7365674014ea5868ee6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19e819eadb96ee5769ff4c6309352a62" category="paragraph"><block ref="19e819eadb96ee5769ff4c6309352a62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0be278d93ec2e64895e31bf440c54b98" category="paragraph"><block ref="0be278d93ec2e64895e31bf440c54b98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4dd921984d3a8a89e7df5c97875b923" category="section-title">SQL Server의 로그 백업을 위한 리소스 그룹을 생성합니다</block>
  <block id="4e94ca9b995e68691b4e67b82b9f5bce" category="list-text">데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인하고 리소스 탭으로 이동합니다. 보기 드롭다운 목록에서 데이터베이스 또는 리소스 그룹을 선택하여 리소스 그룹 만들기 워크플로를 시작합니다. 리소스 그룹의 이름과 태그를 입력합니다. 스냅샷 복사본의 명명 형식을 정의할 수 있습니다.</block>
  <block id="4e71263f0aec815017fd21a22ddb87d6" category="paragraph"><block ref="4e71263f0aec815017fd21a22ddb87d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="013faf9f6cde83814469c6d583e10702" category="paragraph"><block ref="013faf9f6cde83814469c6d583e10702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23e15d7c127e66b1da1d72072a29e9eb" category="list-text">섹션 7에서 생성한 SQL 로그 백업 정책을 선택합니다.</block>
  <block id="52a8553e4c33eb8353d56286d3845b28" category="paragraph"><block ref="52a8553e4c33eb8353d56286d3845b28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e7cac98c16b45d7e4ebec8786b8fda1" category="list-text">백업 빈도와 정확한 백업 시간을 추가합니다.</block>
  <block id="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="paragraph"><block ref="acfaadb1bfb8a5c0a2c39c1f64291ea3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="68398b6746dde91649e96505d97acc40" category="list-text">백업 확인을 수행할 경우 보조 백업에 대한 검증 서버를 선택합니다. Load Locator를 클릭하여 보조 스토리지 위치를 채웁니다.</block>
  <block id="3bde998a2436b40589b20d91a713d3ee" category="paragraph"><block ref="3bde998a2436b40589b20d91a713d3ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80000e8cb7742af4686df786fdf38249" category="paragraph"><block ref="80000e8cb7742af4686df786fdf38249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d32fb038efa6b409f8dedd0e02a10f26" category="paragraph"><block ref="d32fb038efa6b409f8dedd0e02a10f26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9c72629a46c2e88cf7f6a012167bb16" category="section-title">9.백업 검증</block>
  <block id="d1c55c296cbdaa8d88eda765a6158b62" category="paragraph">데이터베이스 리소스 보호를 위해 데이터베이스 백업 리소스 그룹을 생성한 후에는 미리 정의된 일정에 따라 백업 작업이 실행됩니다. Monitor 탭에서 작업 실행 상태를 확인합니다.</block>
  <block id="5f9af2a4e435e2b39c27f43b580d6d20" category="paragraph"><block ref="5f9af2a4e435e2b39c27f43b580d6d20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57882e224a8cbe8f694da9b1d8fa503e" category="paragraph">리소스 탭으로 이동하고 데이터베이스 이름을 클릭하여 데이터베이스 백업에 대한 세부 정보를 확인하고, 로컬 복사본과 미러 복사본 간에 전환하여 스냅샷 백업이 퍼블릭 클라우드의 2차 위치에 복제되었는지 확인합니다.</block>
  <block id="f9b40afbdb387dd32b8523c95080a898" category="paragraph"><block ref="f9b40afbdb387dd32b8523c95080a898" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28268d417882b5cf7a3d3ee3a15834c8" category="paragraph">이때 운영 장애가 발생할 경우 클라우드의 데이터베이스 백업 복사본을 클론 복제하여 개발/테스트 프로세스를 실행하거나 재해 복구를 수행할 수 있습니다.</block>
  <block id="78b29bbf3f07a44b62307ce90b34904e" category="inline-link-macro">다음:AWS 퍼블릭 클라우드 시작하기</block>
  <block id="7d32c0298884bcc4c0211357748d0e6e" category="paragraph"><block ref="7d32c0298884bcc4c0211357748d0e6e" category="inline-link-macro-rx"></block></block>
  <block id="def8ebf26c2dec5f6af5a00893fae037" category="paragraph">이 솔루션은 AWX/Tower 환경 또는 Ansible 제어 호스트의 CLI에서 실행되도록 설계되었습니다.</block>
  <block id="8ca0a52cf9938328875e0a8803ae71dd" category="list-text">작업 템플릿은 ONTAP_config, Linux_config 및 Oracle_config에 대한 태그를 지정하여 3단계로 실행됩니다.</block>
  <block id="da3d0d670ace8a327170aa25ee29f272" category="section-title">Ansible 제어 호스트를 통해 CLI</block>
  <block id="6a5f01bc22c397ee84e04e48c178e980" category="inline-link-macro">RHEL 7/8 또는 CentOS 7/8 에 대해서는 여기를 클릭하십시오</block>
  <block id="7946c3996884ee105962c5334bfd9fef" category="inline-link-macro">Ubuntu/Debian의 경우 여기를 참조하십시오</block>
  <block id="f5344fe4d88d29ee79ba6110f60cfa9b" category="list-text">Ansible 제어 호스트로 사용할 수 있도록 Linux 호스트를 구성합니다<block ref="8688caf90b0dc445f61be35cbf93ed1a" category="inline-link-macro-rx"></block>, 또는<block ref="2b00e81c1e240a58c4df0e850699511b" category="inline-link-macro-rx"></block></block>
  <block id="28e934ddab7714830f8afe8d3b641dc9" category="list-text">Ansible 제어 호스트를 구성한 후 Ansible 자동화 저장소를 클론 복제할 수 있습니다.</block>
  <block id="f667be8dac02593d217a02ac5bfb18de" category="list-text">ONTAP 클러스터 관리 및 Oracle 서버 관리 IP의 IP 및/또는 호스트 이름으로 hosts 파일을 편집합니다.</block>
  <block id="95bd15e6b4a109de659c54c331c06284" category="list-text">해당 환경에 맞는 변수를 작성하고 복사하여 VAR.yml 파일에 붙여 넣습니다.</block>
  <block id="ca548be3e5f238d32286d43dc4c89f7b" category="list-text">각 Oracle 호스트에는 호스트별 변수를 포함하는 호스트 이름으로 식별되는 변수 파일이 있습니다.</block>
  <block id="87192ebbcab92216d25fd694a282971d" category="list-text">모든 변수 파일이 완료된 후 'ONTAP_config', 'linux_config', 'oracle_config'에 대한 태그를 지정하여 3단계로 플레이북을 실행할 수 있습니다.</block>
  <block id="eebc1357e7d1e88ed4e4908d5ae86c0b" category="cell">Ansible 제어 호스트가 될 AWX/Tower 또는 Linux 호스트</block>
  <block id="0a928fe81d89083ed303ea3d9f1af8c9" category="cell">ONTAP 버전 9.3-9.7</block>
  <block id="515f291f3ecc550c5d13cf31fadba91d" category="cell">Oracle 서버에 Oracle 설치 파일</block>
  <block id="bbbabdbe1b262f75d99d62880b953be1" category="cell">역할</block>
  <block id="9bb642814808cd0cab510ddfb9e5969c" category="cell">ONTAP_구성 * 을 참조하십시오</block>
  <block id="79b814c8267c6b7822e78ab4624db8e0" category="cell">Oracle용 NFS 기반 SVM 생성</block>
  <block id="0c981d6164da0d8e69cdb199966316b0" category="cell">엑스포트 정책 생성</block>
  <block id="99179ac01bbb0236fc540871377c55c4" category="cell">Oracle의 볼륨 생성</block>
  <block id="db738705829d97db1e287ad8ea9e5400" category="cell">NFS LIF 생성</block>
  <block id="089c4c184b079d771501d8ceb0f3bb05" category="cell">Linux_config *</block>
  <block id="3ea572544d30a39d236496578f980d13" category="cell">마운트 지점을 생성하고 NFS 볼륨을 마운트합니다</block>
  <block id="db6c0f994cc39fbf66d58eea6c627e6a" category="cell">NFS 마운트를 확인합니다</block>
  <block id="6a882e7966e7869ab1d2112a0b1c0074" category="cell">OS별 구성</block>
  <block id="6e6d41d1398fafd8809de20e831c9ce3" category="cell">Oracle 디렉토리를 생성합니다</block>
  <block id="6f965a5d44e1653dac9825f465f71c84" category="cell">HugePages를 구성합니다</block>
  <block id="be577868fe0712b7bbb6d5cb5eae613c" category="cell">SELinux 및 방화벽 데몬을 해제합니다</block>
  <block id="bb6f16330211bf24baa83db38b11e4a9" category="cell">시간 기록 서비스를 활성화하고 시작합니다</block>
  <block id="e9e5cefa281d2c696aac82ef9c756f51" category="cell">파일 설명자 하드 제한값을 늘립니다</block>
  <block id="a4acc779f882208c081f943aedfeab5c" category="cell">PAM.d 세션 파일을 생성합니다</block>
  <block id="d03021f9e02b9fa9ebac591ad4bfea08" category="cell">* oracle_config *</block>
  <block id="5e706781d4bf141c80e249a244179235" category="cell">Oracle 소프트웨어 설치</block>
  <block id="1a98fce6d77de1126bf3cb8247747621" category="cell">Oracle Listener를 생성합니다</block>
  <block id="841df7bfbef212936073c6d261d4dba9" category="cell">Oracle 데이터베이스를 생성합니다</block>
  <block id="845a6e024025bb13aafdc167511e5e7d" category="cell">Oracle 환경 구성</block>
  <block id="666113957f940ba4319b4f0d9c3e86c0" category="cell">PDB 상태를 저장합니다</block>
  <block id="264bca6ddd5a16346460d9c21e8f926d" category="cell">인스턴스 아카이브 모드를 활성화합니다</block>
  <block id="620ca5ae835411d2031ca0fdbbbe61a1" category="cell">DNFS 클라이언트를 활성화합니다</block>
  <block id="4d7e6c9b84f6f86cf4817262ad424eeb" category="cell">OS 재부팅 간에 데이터베이스 자동 시작 및 종료를 활성화합니다</block>
  <block id="ebda2606845855cc07ce0ce15ecf8a00" category="paragraph">자동화를 간소화하기 위해 필요한 많은 Oracle 구축 매개 변수를 기본값으로 사전 설정하였습니다. 일반적으로 대부분의 배포에서 기본 매개 변수를 변경할 필요는 없습니다. 고급 사용자는 기본 매개 변수를 주의 깊게 변경할 수 있습니다. 기본 매개 변수는 각 역할 폴더의 defaults 디렉토리에 있습니다.</block>
  <block id="452eff11ca6d680a279a3e81b8dc8974" category="section-title">배포 지침</block>
  <block id="1cf7ad9cd74067dd3f4aee3c1690ea32" category="paragraph">시작하기 전에 다음 Oracle 설치 및 패치 파일을 다운로드하여 구축할 각 DB 서버의 모든 사용자에 대한 읽기, 쓰기 및 실행 액세스 권한이 있는 '/tmp/archive' 디렉토리에 배치합니다. 자동화 작업은 Oracle 설치 및 구성을 위해 특정 디렉토리에 명명된 설치 파일을 찾습니다.</block>
  <block id="5abe869dd828ac1e4527f07db79841a8" category="inline-link-macro">자세한 AWX/Tower 배치 절차를 보려면 여기를 클릭하십시오</block>
  <block id="c3bcf861ccc9247a7c0a9b4749747e4e" category="inline-link-macro">CLI 배포는 여기에서 확인할 수 있습니다</block>
  <block id="f867ea86471dd6849f2c840cf13d1536" category="paragraph">준비가 되면 를 클릭합니다 <block ref="0ecf76284fbf596cdd030af085c16a3b" category="inline-link-macro-rx"></block> 또는 <block ref="42cd9508ebf775e8df0efba80be76af7" category="inline-link-macro-rx"></block>.</block>
  <block id="8f7280c86689be0a39cdf74aa673040d" category="summary">이 솔루션은 하이브리드 클라우드 설정에서 개발/테스트 및 재해 복구 작업에 널리 사용되는 모든 퍼블릭 클라우드에 버스트가 가능한 온프레미스 운영 데이터베이스를 지원하도록 설계되었습니다.</block>
  <block id="132f2888eb2cfdeef2730212f50c53e3" category="doc">SnapCenter 요구 사항</block>
  <block id="e2a7d0854ef572e10255339732bb005d" category="inline-link-macro">이전: 솔루션 아키텍처.</block>
  <block id="b10927905ed5379ba0d73333abdbe06d" category="paragraph"><block ref="b10927905ed5379ba0d73333abdbe06d" category="inline-link-macro-rx"></block></block>
  <block id="185b108b21dccef917f415be6026c91c" category="paragraph">ONTAP 스토리지 클러스터에서 DB 호스트에 제공된 DB 볼륨이 있는 운영 데이터베이스 서버가 사내에서 호스팅된다고 가정합니다. SnapCenter 소프트웨어는 데이터베이스 백업 및 클라우드 데이터 복제를 위해 사내에 설치됩니다. Ansible 컨트롤러를 사용할 것을 권장하지만, 퍼블릭 클라우드의 개발/테스트 인스턴스 또는 대기 DR 인스턴스와 동기화되는 데이터베이스 배포 자동화 또는 OS 커널 및 DB 구성에는 필요하지 않습니다.</block>
  <block id="47099d9ea153f8abfa5b6b70da253b3a" category="cell">* 사내 *</block>
  <block id="d36407241494bfc1e84614ad1b0dd6a4" category="cell">SnapCenter에서 지원하는 모든 데이터베이스 및 버전</block>
  <block id="8c8c8ca7a4093a1210412a3a5e5ad55f" category="cell">SnapCenter v4.4 이상</block>
  <block id="9d9ebf67dab68c3c892de99e981039cf" category="cell">Ansible v2.09 이상</block>
  <block id="62dd4f48e99b13c8a00fbaba684f9592" category="cell">ONTAP 클러스터 9.x</block>
  <block id="d0fdc58e1e05d6cbc8b1beb072bfa235" category="cell">인터클러스터 LIF가 구성되었습니다</block>
  <block id="7135df562bcb25bfdf20e4317b923b88" category="cell">온프레미스에서 클라우드 VPC로 연결(VPN, 상호 연결 등)</block>
  <block id="8c27863f5ffd0e66a9304eaca2e47fde" category="cell">네트워킹 포트 open-ssh 22-tcp 8145, 8146, 10000, 11104, 11105</block>
  <block id="bcb9f3419f724f768e30956a4427261d" category="cell">* 클라우드-AWS *</block>
  <block id="61c90d44785278f980592f082ef500f1" category="inline-link">Cloud Manager 커넥터</block>
  <block id="97bc5062dceccb6827b1e3f0522035f0" category="cell"><block ref="97bc5062dceccb6827b1e3f0522035f0" category="inline-link-rx"></block></block>
  <block id="117bdbda976fe8b3212bc3b6327a0a1b" category="inline-link">Cloud Volumes ONTAP</block>
  <block id="2f077494ceff1f33085c5b163c3673b3" category="cell"><block ref="2f077494ceff1f33085c5b163c3673b3" category="inline-link-rx"></block></block>
  <block id="59b2c9424963f98d73ec69c59dde54cb" category="cell">DB OS EC2 인스턴스를 온프레미스에 일치시킵니다</block>
  <block id="e26786a16da88ee829ab76c48fd3b003" category="cell">* 클라우드 - Azure *</block>
  <block id="c2f8674b07907f393b67a3f9e98d3d56" category="cell"><block ref="c2f8674b07907f393b67a3f9e98d3d56" category="inline-link-rx"></block></block>
  <block id="a8dd724647657a383eb37fd8775ec1a9" category="cell"><block ref="a8dd724647657a383eb37fd8775ec1a9" category="inline-link-rx"></block></block>
  <block id="8bede1f0e559918be01f0646b75b4257" category="cell">DB OS Azure 가상 시스템을 온프레미스에 일치시킵니다</block>
  <block id="b2a454fb4ff03b84162c59d674fdae25" category="cell">* Cloud-GCP *</block>
  <block id="af072236983e991ab34e773871b10236" category="cell"><block ref="af072236983e991ab34e773871b10236" category="inline-link-rx"></block></block>
  <block id="499477cf7953707f63a1b1313c8c065a" category="cell"><block ref="499477cf7953707f63a1b1313c8c065a" category="inline-link-rx"></block></block>
  <block id="2900c5e1ee191606f20d007194e70edf" category="cell">DB OS Google Compute Engine 인스턴스를 온프레미스에 일치시킵니다</block>
  <block id="126b29c0beff0884077277115103a374" category="inline-link-macro">다음: 사전 요구 사항 구성.</block>
  <block id="a6d027dea0e97ba248528210d36e5475" category="paragraph"><block ref="a6d027dea0e97ba248528210d36e5475" category="inline-link-macro-rx"></block></block>
  <block id="d798c6a829fee4b3d8316144e8769e91" category="paragraph">조직은 효율성을 높이고, 구현을 앞당기고, 수동 작업을 줄이기 위해 환경을 자동화하고 있습니다. Ansible과 같은 구성 관리 툴을 사용하여 엔터프라이즈 데이터베이스 운영을 간소화하고 있습니다. 이 솔루션에서는 Ansible을 사용하여 NetApp ONTAP을 통해 Oracle의 데이터 보호를 자동화하는 방법을 보여줍니다. 스토리지 관리자, 시스템 관리자 및 DBA가 오프사이트 데이터 센터 또는 퍼블릭 클라우드에 대한 데이터 복제를 일관되고 신속하게 설정할 수 있도록 함으로써 다음과 같은 이점을 얻을 수 있습니다.</block>
  <block id="1d4694b7ed077df8b2c51d4ef956ce0c" category="list-text">클러스터 간 복제, CVO 인스턴스화 및 Oracle 데이터베이스 복구 구성 시간 단축</block>
  <block id="60bcf8682ddc3583a74e6cd2d95e1ccb" category="list-text">DR 시나리오의 테스트를 쉽게 수행할 수 있는 데이터베이스 복구 워크플로우를 제공합니다.</block>
  <block id="7fa4d3428dbef9829f6325b288c071bc" category="section-title">온프레미스에서 온프레미스 복제까지</block>
  <block id="911a9e8dd85bfeeba31c1ed049e41e1c" category="list-text">소스와 대상에 대한 인터클러스터 LIF를 만듭니다</block>
  <block id="2f4eb56dd9301fc33f559b4345b90eb3" category="list-text">클러스터 및 SVM 피어링 설정</block>
  <block id="2b71f4136dce37491ef0f319f5d1fbd9" category="list-text">Oracle 볼륨의 SnapMirror를 생성하고 초기화합니다</block>
  <block id="20f4a46f5b12b0533f7a2268c4c2bf41" category="list-text">Oracle 바이너리, 데이터베이스 및 로그용 AWX/Tower를 통해 복제 일정을 생성합니다</block>
  <block id="6ef1c2ae7c9ca61a54d88de28349a772" category="list-text">대상에서 Oracle DB를 복원하고 데이터베이스를 온라인 상태로 전환합니다</block>
  <block id="f4ec61d9ffa147f621f854609523a0fb" category="section-title">온프레미스에서 AWS의 CVO로</block>
  <block id="3f155aa6a9345b3e25f3bb44ecccfc0a" category="list-text">AWS 커넥터를 생성합니다</block>
  <block id="1531cb3c2d4db27dcd3bfa2ad4711ec5" category="list-text">AWS에서 CVO 인스턴스를 생성합니다</block>
  <block id="2f159b717f78e9925b219e87cbd20f9a" category="list-text">Cloud Manager에 온프레미스 클러스터 추가</block>
  <block id="df16a1e23dbbcc2f19f07ab1af741617" category="list-text">소스에 대한 인터클러스터 LIF를 만듭니다</block>
  <block id="d1f660bb2bff2f31a46c751115155999" category="list-text">1부: TBD</block>
  <block id="421b47ffd946ca083b65cd668c6b17e6" category="list-text">비디오</block>
  <block id="1ee2253d8fe666dbea54ab3648a62511" category="list-text">2부: TBD</block>
  <block id="68eff5f8d34b801d40ab55f098bc6478" category="inline-link-macro">여기 에서 솔루션 시작 을 확인하십시오</block>
  <block id="e5dec240e8be4a30564a7e8ddc0d568a" category="list-text">준비가 되면 를 클릭합니다 <block ref="a171481e1cde5211da297c03090cb7ce" category="inline-link-macro-rx"></block>.</block>
  <block id="d89002d36151bd13d2bba69f3533ee5f" category="summary">이 솔루션은 NetApp 현장 및 고객에게 NetApp SnapCenter GUI 기반 툴과 퍼블릭 클라우드의 NetApp 스토리지 서비스 CVO를 사용하여 데이터베이스를 하이브리드 클라우드 환경으로 구성, 운영 및 마이그레이션하는 데 필요한 지침과 지침을 제공합니다.</block>
  <block id="8269707c3930f3cbcd49193be33bc125" category="doc">TR-4908: SnapCenter를 지원하는 하이브리드 클라우드 데이터베이스 솔루션 개요</block>
  <block id="7c4d94e1b484fb577b0aeafbec788ea1" category="paragraph">NetApp의 Felix Melligan, Alan Cao</block>
  <block id="268a30b4d0cad062acd42967ce0fab50" category="paragraph">이 솔루션은 NetApp 현장 및 고객에게 NetApp SnapCenter GUI 기반 툴과 퍼블릭 클라우드의 NetApp 스토리지 서비스 CVO를 사용하여 데이터베이스를 하이브리드 클라우드 환경으로 구성, 운영 및 마이그레이션하는 데 필요한 지침과 사용 사례를 제공합니다.</block>
  <block id="e88a2467c8ad8bf481854b1a745a875b" category="list-text">하이브리드 클라우드에서 데이터베이스 개발/테스트 작업</block>
  <block id="3c9552536897a076f75b078a5e2a3703" category="list-text">하이브리드 클라우드에서 데이터베이스 재해 복구</block>
  <block id="a1ac690c228caf22f3228d3a4d8b5cab" category="paragraph">오늘날 많은 엔터프라이즈 데이터베이스는 성능, 보안 및/또는 기타 이유로 여전히 프라이빗 기업 데이터 센터에 있습니다. 기업에서는 이 하이브리드 클라우드 데이터베이스 솔루션을 사용하여 기본 데이터베이스를 사이트에서 운영하는 동시에 개발/테스트 데이터베이스 운영뿐 아니라 재해 복구에 퍼블릭 클라우드를 사용하여 라이센스 및 운영 비용을 절감할 수 있습니다.</block>
  <block id="d900d125b3be40bcb79452d624c38561" category="paragraph">Oracle, SQL Server, SAP HANA 등 많은 엔터프라이즈 데이터베이스 높은 라이센스 및 운영 비용 수행 많은 고객은 개발, 테스트, 운영 또는 재해 복구에 코어를 사용하는지에 관계없이 데이터베이스 환경의 컴퓨팅 코어 수를 기준으로 1회 라이센스 비용 및 연간 지원 비용을 지불합니다. 이러한 환경 중 대부분은 애플리케이션 라이프사이클 동안 완전히 활용하지 못할 수 있습니다.</block>
  <block id="1f49cc83c5c3735827e3353f320f5f7f" category="paragraph">이 솔루션은 고객이 개발, 테스트 또는 재해 복구 전용 데이터베이스 환경을 클라우드로 이동하여 라이센스 대상 코어 수를 잠재적으로 줄일 수 있는 옵션을 제공합니다. 퍼블릭 클라우드의 확장, 이중화, 고가용성, 소비 기반 청구 모델을 활용하면 애플리케이션 사용성이나 가용성에 영향을 주지 않으면서 라이센스 및 운영 비용을 크게 절감할 수 있습니다.</block>
  <block id="1a197dd926608052c7d43edfd09556fa" category="paragraph">NetApp의 용량 기반 CVO 라이센스 모델은 잠재적인 데이터베이스 라이센스 비용 절감 외에도, 고객이 경쟁 스토리지 서비스에서 제공되지 않는 높은 수준의 데이터베이스 관리 효율성을 통해 GB당 스토리지 비용을 절감할 수 있도록 지원합니다. 다음 차트에는 퍼블릭 클라우드에서 사용 가능한 주요 스토리지 서비스의 스토리지 비용 비교가 나와 있습니다.</block>
  <block id="810fba7bc9a3829eb522ebbc24326a08" category="paragraph"><block ref="810fba7bc9a3829eb522ebbc24326a08" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e222eb27a0002f2960d1cf1e14bbf7d" category="paragraph">이 솔루션은 SnapCenter GUI 기반 소프트웨어 툴과 NetApp SnapMirror 기술을 사용하여 하이브리드 클라우드 데이터베이스 운영을 쉽게 설정, 구현, 운영할 수 있다는 것을 보여 줍니다.</block>
  <block id="26cc8c416b5c9fd6bec3dc68e6f2f0c8" category="paragraph">다음 비디오에서는 SnapCenter의 실제 작동 방법을 보여줍니다.</block>
  <block id="edc6673fe24c4867029921bbe72f25cb" category="inline-link">SnapCenter를 사용하여 하이브리드 클라우드에서 Oracle 데이터베이스 백업</block>
  <block id="b10d6cd72b187359c3769fbf5ff10e4c" category="list-text"><block ref="0d160cec2141981b284cd9986321651e" category="inline-link-rx"></block></block>
  <block id="68d9033a95c0ed286c9b7e0e7454cd86" category="inline-link">SnapCenter - Oracle 데이터베이스용 AWS 클라우드에 개발/테스트 클론을 생성할 수 있습니다</block>
  <block id="da8d0116fa67f0499837675277668911" category="list-text"><block ref="da8d0116fa67f0499837675277668911" category="inline-link-rx"></block></block>
  <block id="3b04263461ad5a7b57aa872e093ec9fa" category="paragraph">이 문서의 그림에서는 CVO를 퍼블릭 클라우드의 타겟 스토리지 인스턴스로 보여 주지만, 이 솔루션은 AWS용 FSx ONTAP 스토리지 엔진의 새로운 릴리즈에서 완벽하게 검증되었습니다.</block>
  <block id="c5a6d2f45fc4352f35e95d92c804b6f2" category="paragraph">솔루션 및 사용 사례를 직접 테스트하기 위해 https://labondemand.netapp.com/lod3/labtest/request?nodeid=68761&amp;destination=lod3/testlabs[TL_AWS_004 HCoD:AWS-NW, SnapCenter(OnPrem)^]에서 NetApp Lab-On-Demand SL10680을 요청할 수 있습니다.</block>
  <block id="d31314285161c777a09609cc4fb2d07a" category="inline-link-macro">다음은 솔루션 아키텍처입니다.</block>
  <block id="0830319fc7a6b051bbb0602c2778e67c" category="paragraph"><block ref="0830319fc7a6b051bbb0602c2778e67c" category="inline-link-macro-rx"></block></block>
  <block id="9b64a6dfae1f3fa326b750c2790c79fe" category="summary">이 섹션에서는 Azure NetApp Files SMB 볼륨을 사용하는 AOAG 구성에서 SQL 데이터베이스 자산의 실시간 구축에 대해 설명합니다.</block>
  <block id="5ca1071c67ab704b04ed27747f213551" category="doc">실시간 고수준 참조 디자인</block>
  <block id="bb0357d1c0b3b8ebd31a43c9b30f3745" category="list-text">노드 수: 4</block>
  <block id="7f4f30d96e1d0a820a6962ad6ac994ee" category="list-text">데이터베이스 수: 21</block>
  <block id="f28735e3e5e57049aa575b3f0ec83c61" category="list-text">가용성 그룹 수: 4</block>
  <block id="96fb94ba9fad0b4452c212b21df61eab" category="list-text">백업 보존: 7일</block>
  <block id="a8d1485807d36562316fb8b2254bca57" category="list-text">백업 아카이브: 365일</block>
  <block id="4afa49afd4ebc3638f3e000d65825370" category="admonition">Azure NetApp Files 공유를 통해 Azure 가상 시스템에서 SQL Server와 FCI를 배포하면 데이터의 단일 복사본을 통해 비용 효율적인 모델을 제공할 수 있습니다. 이 솔루션은 파일 경로가 보조 복제본과 다를 경우 추가 파일 작업 문제를 방지할 수 있습니다.</block>
  <block id="ab030ea777250278c4f110a497eeef88" category="paragraph"><block ref="ab030ea777250278c4f110a497eeef88" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4822d9597460a9166778308da312709c" category="paragraph">다음 이미지는 노드에 분산된 AOAG 내의 데이터베이스를 보여 줍니다.</block>
  <block id="af316199cc8e77dcbb6fb560cbc4c44c" category="paragraph"><block ref="af316199cc8e77dcbb6fb560cbc4c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d22a890163762fcf7a4cb7605c29b7e6" category="section-title">데이터 레이아웃</block>
  <block id="35c33dd0c5565dbdba04dc2b313d7a2e" category="paragraph">tempdb와 함께 사용자 데이터베이스 파일(.mdf) 및 사용자 데이터베이스 트랜잭션 로그 파일(.ldf)은 동일한 볼륨에 저장됩니다. 서비스 수준은 울트라입니다.</block>
  <block id="9b7d6479a15395afefc6d7f9e38a4f17" category="paragraph">이 구성은 노드 4개와 AGS 4개로 구성됩니다. 21개의 데이터베이스(동적 AX, SharePoint, RDS 연결 브로커 및 인덱싱 서비스의 일부)는 모두 Azure NetApp Files 볼륨에 저장됩니다. 데이터베이스는 AOAG 노드 간에 균형을 이루어 노드의 리소스를 효과적으로 사용합니다. AOAG 구성에 참여하는 4개의 D32 v3 인스턴스가 WSFC에 추가됩니다. 이러한 4개 노드는 Azure 가상 네트워크에 프로비저닝되며 사내의 경우 마이그레이션되지 않습니다.</block>
  <block id="09a10f0ab048cde1d7b704392ba05d9a" category="list-text">응용 프로그램 및 실행된 쿼리의 특성에 따라 로그에 더 많은 성능 및 처리량이 필요한 경우 데이터베이스 파일을 프리미엄 서비스 수준에 배치하고 로그를 Ultra 서비스 수준에 저장할 수 있습니다.</block>
  <block id="51368a236b969e288242f0b0b615cf74" category="list-text">tempdb 파일이 Azure NetApp Files에 배치된 경우 Azure NetApp Files 볼륨은 사용자 데이터베이스 파일과 분리되어야 합니다. 다음은 AOAG의 데이터베이스 파일 배포 예입니다.</block>
  <block id="2e66f3d288799e6f4235b883bb2f693c" category="list-text">스냅샷 복사본 기반 데이터 보호의 이점을 유지하려면 동일한 볼륨에 데이터와 로그 데이터를 결합하지 않는 것이 좋습니다.</block>
  <block id="1452bcdb4aeb229a2c2e503f9bbba753" category="list-text">보조 데이터베이스의 파일 경로가 해당 기본 데이터베이스의 경로와 다른 경우 기본 복제본에 대해 수행되는 추가 파일 작업이 보조 데이터베이스에서 실패할 수 있습니다. 이 문제는 공유 경로가 운영 노드와 보조 노드에서 다른 경우(컴퓨터 계정이 서로 다르기 때문에) 발생할 수 있습니다. 이 실패로 인해 보조 데이터베이스가 일시 중단될 수 있습니다. 확장 또는 성능 패턴을 예측할 수 없고 나중에 파일을 추가하는 것이 계획이면 Azure NetApp Files를 사용하는 SQL Server 장애 조치 클러스터를 사용할 수 있습니다. 대부분의 구축 환경에서 Azure NetApp Files은 성능 요구사항을 충족합니다.</block>
  <block id="19f59b74448f6a27519db281a44e4b12" category="section-title">마이그레이션</block>
  <block id="cd6b4503e07d15cebc0842bb8da7b765" category="paragraph">온프레미스 SQL Server 사용자 데이터베이스를 Azure 가상 머신의 SQL Server로 마이그레이션하는 방법에는 여러 가지가 있습니다. 마이그레이션은 온라인 또는 오프라인일 수 있습니다. 선택한 옵션은 SQL Server 버전, 비즈니스 요구 사항 및 조직 내에서 정의된 SLA에 따라 다릅니다. 데이터베이스 마이그레이션 프로세스 중에 다운타임을 최소화하려면 AlwaysOn 옵션 또는 트랜잭션 복제 옵션을 사용하는 것이 좋습니다. 이러한 방법을 사용할 수 없는 경우 데이터베이스를 수동으로 마이그레이션할 수 있습니다.</block>
  <block id="2d4221f1ee93c102ca047daac1fba4a7" category="paragraph">시스템 간에 데이터베이스를 이동하는 가장 간단하고 철저한 테스트를 거친 접근 방식은 백업 및 복원입니다. 일반적으로 데이터베이스 백업 후 Azure로 데이터베이스 백업 복사본을 사용하여 시작할 수 있습니다. 그런 다음 데이터베이스를 복원할 수 있습니다. 최상의 데이터 전송 성능을 얻으려면 압축된 백업 파일을 사용하여 데이터베이스 파일을 Azure VM으로 마이그레이션합니다. 이 문서에서 참조되는 고급 설계에서는 Azure 파일 동기화를 사용하여 Azure 파일 저장소에 대한 백업 방식을 사용한 다음 Azure NetApp Files로 복원합니다.</block>
  <block id="623f8382f97ee8df2d7af54439833812" category="admonition">Azure 마이그레이션을 사용하여 SQL Server 워크로드를 검색, 평가, 마이그레이션할 수 있습니다.</block>
  <block id="fbc25f1c70f1a9c133715cac6d66b21b" category="paragraph">마이그레이션을 수행하려면 다음 단계를 따르십시오.</block>
  <block id="d807caa187d2fea33bab50ed1e1c79bb" category="list-text">요구 사항에 따라 연결을 설정합니다.</block>
  <block id="59f59f1aebe4fc18ab054480b3a1098a" category="list-text">온-프레미스 파일 공유 위치에 전체 데이터베이스 백업을 수행합니다.</block>
  <block id="4891d727582d5df766ee6737fe7fb761" category="list-text">Azure 파일 동기화를 사용하여 Azure 파일 공유에 백업 파일을 복사합니다.</block>
  <block id="135899cc34886eb6ce9baf7211d4adb5" category="list-text">원하는 버전의 SQL Server로 VM을 프로비저닝합니다.</block>
  <block id="fbef0b11b7ee9e0d709d3d1c6efbd4d4" category="list-text">명령 프롬프트에서 "copy" 명령을 사용하여 백업 파일을 VM에 복사합니다.</block>
  <block id="b9786aca69df61c5165147929b4ced89" category="list-text">전체 데이터베이스를 Azure 가상 머신의 SQL Server로 복구합니다.</block>
  <block id="e937691d64dcb1188cbbcbcd83d87d2f" category="admonition">21개 데이터베이스를 복원하는 데 약 9시간이 걸렸습니다. 이 접근 방식은 이 시나리오에만 적용됩니다. 그러나 아래 나열된 다른 마이그레이션 기술은 고객의 상황과 요구 사항에 따라 사용할 수 있습니다.</block>
  <block id="2b9d85faa379ef985ae3851810db1403" category="paragraph">온-프레미스 SQL Server에서 Azure NetApp Files로 데이터를 이동하는 기타 마이그레이션 옵션은 다음과 같습니다.</block>
  <block id="90248308f9c24bd3bf817ee129838603" category="list-text">데이터와 로그 파일을 분리하고 Azure Blob 저장소에 복사한 다음 URL에서 ANF 파일 공유가 마운트된 Azure VM의 SQL Server에 연결합니다.</block>
  <block id="82ce70205698ed956d1fce48af1360c0" category="inline-link">Azure 복제본 추가 마법사</block>
  <block id="e5e07f1ff84f0082089e4fec71ed43a4" category="list-text">Always On Availability Group Deployment On-Premises를 사용하는 경우 를 사용합니다<block ref="aea558e3371e9956f5e03828309464a0" category="inline-link-rx"></block> 를 눌러 Azure에서 복제본을 생성한 다음 페일오버를 수행합니다.</block>
  <block id="eedc53c13a9992999dba36bda1b62255" category="inline-link">트랜잭션 복제</block>
  <block id="47a43d904457c52da2918f290a0ae5cb" category="list-text">SQL Server를 사용합니다<block ref="21bf5f41b40b598aae9dd55aa9dcb960" category="inline-link-rx"></block> Azure SQL Server 인스턴스를 구독자로 구성하려면 복제를 사용하지 않도록 설정하고 사용자를 Azure 데이터베이스 인스턴스로 지정합니다.</block>
  <block id="bf4614882fd1000329cfcb76f98f6c17" category="list-text">Windows 가져오기/내보내기 서비스를 사용하여 하드 드라이브를 배송합니다.</block>
  <block id="be062cdcabbb3055334e8f19b4bdf378" category="section-title">백업 및 복구</block>
  <block id="b855582b6472c4fbe2a5f606191e66d6" category="paragraph">백업 및 복구는 모든 SQL Server 배포의 중요한 부분입니다. AOAG와 같은 고가용성 솔루션과 함께 다양한 데이터 장애 및 손실 시나리오에서 신속하게 복구할 수 있는 적절한 안전망을 갖추고 있어야 합니다. SQL Server 데이터베이스 정지 도구, Azure 백업(스트리밍) 또는 Commvault와 같은 타사 백업 도구를 사용하여 데이터베이스의 애플리케이션 정합성이 보장되는 백업을 수행할 수 있습니다.</block>
  <block id="3896e1102f68b0bc974f324bb134f6e6" category="inline-link">SCSQLAPI 도구</block>
  <block id="e372173044ccba12657b2e3dbff1879b" category="paragraph">Azure NetApp Files 스냅샷 기술을 사용하면 성능이나 네트워크 활용도에 영향을 주지 않고 사용자 데이터베이스의 시점(PiT) 복사본을 쉽게 생성할 수 있습니다. 또한 이 기술을 사용하면 스냅샷 복사본을 새 볼륨으로 복원하거나 복원 볼륨 기능을 사용하여 스냅샷 복사본이 생성된 시점의 상태로 빠르게 되돌릴 수 있습니다. Azure NetApp Files 스냅샷 프로세스는 매우 빠르고 효율적이므로 Azure 백업에서 제공되는 스트리밍 백업과 달리 매일 여러 번 백업할 수 있습니다. 특정 날짜에 여러 개의 Snapshot 복사본이 가능하므로 RPO 및 RTO 시간이 크게 줄어들 수 있습니다. 스냅샷 복사본을 생성하기 전에 데이터가 손상되지 않고 디스크에 적절히 플러시되도록 응용 프로그램 일관성을 추가하려면 SQL Server 데이터베이스 정지 도구를 사용합니다 <block ref="b800e9e09a17fc5b41967404ec8e47ac" category="inline-link-rx"></block>; 이 링크에 액세스하려면 NetApp SSO 로그인 자격 증명이 필요합니다.) 이 툴은 PowerShell 내에서 실행할 수 있습니다. PowerShell은 SQL Server 데이터베이스를 중지시키고 애플리케이션 정합성이 보장되는 스토리지 Snapshot 복사본을 백업에 사용할 수 있도록 합니다.</block>
  <block id="04666a337d02195d17089298f5773f4c" category="paragraph">* 참고: *</block>
  <block id="a4d5ac6087b7ce119cfe6b7ad4d77ee5" category="list-text">SCSQLAPI 도구는 2016 및 2017 버전의 SQL Server만 지원합니다.</block>
  <block id="fdcb10d4c2db07cf930247a4f9898ec5" category="list-text">SCSQLAPI 도구는 한 번에 하나의 데이터베이스에서만 작동합니다.</block>
  <block id="2f65ae42dc3aa8b735406a2d56ceb6fb" category="list-text">파일을 별도의 Azure NetApp Files 볼륨에 배치하여 각 데이터베이스에서 격리합니다.</block>
  <block id="879351e17b2cd6d740ac0974e9ff8a5a" category="inline-link">Azure 백업</block>
  <block id="794b24c8957eec03a1402459d32f6810" category="paragraph">SCSQL API의 방대한 제한으로 인해<block ref="10a72c6743c3c6714e03b5537ec15603" category="inline-link-rx"></block> SLA 요구사항을 충족하기 위해 데이터 보호에 사용되었습니다. Azure 가상 머신 및 Azure NetApp Files에서 실행되는 SQL Server의 스트림 기반 백업을 제공합니다. Azure Backup은 빈번한 로그 백업 및 최대 1초의 피트 복구를 통해 15분 RPO를 실현합니다.</block>
  <block id="423e555c5ec3885f2bb5d9d2d6627f63" category="section-title">모니터링</block>
  <block id="fe58430a0bb00057a08eed382c5d82b2" category="paragraph">Azure NetApp Files는 Azure Monitor와 통합되어 시계열 데이터를 제공하며, 할당된 스토리지, 실제 스토리지 사용량, 볼륨 IOPS, 처리량, 디스크 읽기 바이트/초, 디스크 쓰기 바이트/초, 디스크 읽기/초 및 디스크 쓰기/초, 관련 지연 시간 이 데이터를 사용하여 경고 병목 현상을 식별하고 상태 점검을 수행하여 SQL Server 배포가 최적의 구성으로 실행되고 있는지 확인할 수 있습니다.</block>
  <block id="48419e90c914ae5fa935283404de8a2a" category="paragraph">이 HLD에서 ScienceLogic은 적절한 서비스 보안 주체를 사용하여 메트릭을 노출하여 Azure NetApp Files를 모니터링하는 데 사용됩니다. 다음 그림은 Azure NetApp Files 메트릭 옵션의 예입니다.</block>
  <block id="2bede5da6907dcdcebc6a8f407f07467" category="paragraph"><block ref="2bede5da6907dcdcebc6a8f407f07467" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fe292df6373534e554d5a7938bc3c3b" category="section-title">일반 클론을 사용한 DevTest</block>
  <block id="652f67778e6d02c7b5bfe46a3e579f7f" category="paragraph">Azure NetApp Files를 사용하면 응용 프로그램 개발 주기 동안 현재 데이터베이스 구조 및 콘텐츠를 사용하여 구현해야 하는 기능을 테스트하기 위해 데이터베이스의 즉각적인 복사본을 만들 수 있으며, 데이터 웨어하우스를 채울 때 데이터 추출 및 조작 도구를 사용할 수 있습니다. 실수로 삭제하거나 변경한 데이터를 복구할 수도 있습니다. 이 프로세스에서는 Azure Blob 컨테이너에서 데이터를 복사할 필요가 없어 매우 효율적입니다. 볼륨이 복원된 후 읽기/쓰기 작업에 사용할 수 있어 검증 및 출시 시간이 크게 단축됩니다. 이 기능은 애플리케이션 일관성을 위해 SCSQLAPI와 함께 사용해야 합니다. 이 접근 방식은 Azure NetApp Files와 함께 새로운 볼륨으로 복원 옵션을 활용하는 또 다른 연속 비용 최적화 기술을 제공합니다.</block>
  <block id="e4665dd99280634e4b44ff82666fbb9f" category="list-text">새 볼륨 복원 옵션을 사용하여 스냅샷 복사본에서 생성된 볼륨은 용량 풀의 용량을 사용합니다.</block>
  <block id="0031911d8ba66a79d06b9819afd4f082" category="list-text">REST 또는 Azure CLI를 사용하여 복제된 볼륨을 삭제하여 추가 비용을 방지할 수 있습니다(용량 풀을 늘려야 하는 경우).</block>
  <block id="cb4d46fdcb0881652013c495d90ae732" category="section-title">하이브리드 스토리지 옵션</block>
  <block id="e6a1767911a937e11cc1750fcc4256c3" category="paragraph">SQL Server 가용성 그룹의 모든 노드에 대해 동일한 스토리지를 사용하는 것이 권장되지만, 여러 스토리지 옵션을 사용할 수 있는 시나리오가 있습니다. 이 시나리오는 AOAG의 노드가 Azure NetApp Files SMB 파일 공유에 연결되어 있고 두 번째 노드가 Azure 프리미엄 디스크에 연결되어 있는 Azure NetApp Files에 대해 가능합니다. 이 경우 Azure NetApp Files SMB 공유가 사용자 데이터베이스의 기본 복사본을 갖고 있고 프리미엄 디스크가 보조 복사본으로 사용되는지 확인하십시오.</block>
  <block id="009d3d51226fdccd09052934b65100db" category="list-text">이러한 구축에서 페일오버 문제를 방지하려면 SMB 볼륨에서 지속적인 가용성을 활성화해야 합니다. 지속적으로 사용 가능한 속성이 없으므로 스토리지 계층에 백그라운드 유지 관리가 있는 경우 데이터베이스에 장애가 발생할 수 있습니다.</block>
  <block id="918e9d895272e6a326c6585e05ae4c08" category="list-text">데이터베이스의 기본 복사본을 Azure NetApp Files SMB 파일 공유에 유지합니다.</block>
  <block id="1a5c3601eda1cd38072323e418968743" category="section-title">비즈니스 연속성</block>
  <block id="064ea84d2e6072b28bfd7a8b36aed3db" category="paragraph">재해 복구는 일반적으로 모든 구현에서 나중에 고려해야 하는 사안입니다. 그러나 비즈니스에 영향을 주지 않도록 초기 설계 및 구축 단계에서 재해 복구를 해결해야 합니다. Azure NetApp Files를 사용하면 CRR(Cross-Region Replication) 기능을 사용하여 블록 레벨의 볼륨 데이터를 페어링된 영역으로 복제하여 예기치 않은 지역 운영 중단을 처리할 수 있습니다. CRR 지원 대상 볼륨을 읽기 작업에 사용할 수 있으므로 재해 복구 시뮬레이션에 적합합니다. 또한 CRR 대상을 가장 낮은 서비스 수준(예: 표준)으로 할당하여 전체 TCO를 줄일 수 있습니다. 페일오버 발생 시 복제를 깨고 각 볼륨을 읽기/쓰기 가능하게 만들 수 있습니다. 또한 동적 서비스 수준 기능을 사용하여 재해 복구 비용을 크게 줄여 볼륨의 서비스 수준을 변경할 수 있습니다. 이는 Azure 내에서 블록 복제를 사용하는 Azure NetApp Files의 또 다른 고유한 기능입니다.</block>
  <block id="86258094262f66b30d10068d1d9c29d4" category="section-title">장기적인 스냅샷 복사본 아카이브</block>
  <block id="65bd92a3b5fcfea7efeb973a0a2483d8" category="inline-link">AzCopy</block>
  <block id="e6bf440e9e7e787ce92e6f8661daf9e9" category="paragraph">많은 조직에서는 필수 규정 준수 요구 사항으로 데이터베이스 파일의 스냅샷 데이터를 장기간 보존해야 합니다. 이 프로세스는 HLD에서 사용되지 않지만 를 사용하여 간단한 배치 스크립트를 사용하여 쉽게 수행할 수 있습니다<block ref="f326c7b047cd071718d141dba06c550f" category="inline-link-rx"></block> 를 눌러 Azure Blob 컨테이너에 스냅샷 디렉토리를 복사합니다. 예약된 작업을 사용하여 특정 일정에 따라 배치 스크립트를 트리거할 수 있습니다. 이 프로세스는 다음과 같은 단계로 구성되어 있습니다.</block>
  <block id="dfdc6514d824f948d82ee2ac6515603f" category="list-text">AzCopy V10 실행 파일을 다운로드합니다. exe 파일이기 때문에 설치할 것이 없습니다.</block>
  <block id="5434519f37049a19d388fb3edabd08f7" category="list-text">적절한 권한이 있는 컨테이너 수준에서 SAS 토큰을 사용하여 AzCopy에 권한을 부여합니다.</block>
  <block id="73facdc1e77927e1c0d4c2f66c6fedf9" category="list-text">AzCopy가 승인된 후 데이터 전송이 시작됩니다.</block>
  <block id="a2c31034ac77c6ad0ce6dae2a7882d73" category="list-text">배치 파일에서 SAS 토큰에 나타나는 % 문자를 이스케이프해야 합니다. 이 작업은 SAS 토큰 문자열의 기존 % 문자 옆에 % 문자를 추가하여 수행할 수 있습니다.</block>
  <block id="0eed577952fd376af1fa48aa241e3df7" category="inline-link">보안 전송이 필요합니다</block>
  <block id="b2f731ca364e7df30cd69650bdc19d46" category="list-text">를 클릭합니다<block ref="7e9be5c7f255e20f7f3a81046108dcad" category="inline-link-rx"></block> 저장소 계정 설정에 따라 저장소 계정에 대한 연결이 TLS(Transport Layer Security)로 보호되는지 여부가 결정됩니다. 이 설정은 기본적으로 사용됩니다. 다음 배치 스크립트 예제에서는 스냅샷 복사본 디렉토리에서 지정된 Blob 컨테이너로 데이터를 재귀적으로 복제합니다.</block>
  <block id="f2c225fb316953652d9040f71e76717c" category="paragraph">다음 명령 예는 PowerShell에서 실행됩니다.</block>
  <block id="e7cc24e4ddff469c6304653aea869597" category="list-text">Azure NetApp Files에서는 장기 보존을 위한 유사한 백업 기능을 곧 사용할 수 있습니다.</block>
  <block id="03930ecbc2c505278298d571631e23bb" category="list-text">배치 스크립트는 모든 영역의 Blob 컨테이너에 데이터를 복사해야 하는 모든 시나리오에서 사용할 수 있습니다.</block>
  <block id="07ecdeff0f5a70968e882eb4ace6f576" category="paragraph">데이터베이스에 전혀 영향을 주지 않는 볼륨 재구성 및 동적 서비스 수준 변경을 통해 Azure NetApp Files은 Azure에서 지속적인 비용 최적화를 지원합니다. 이 HLD에서는 워크로드 폭증을 처리하기 위해 추가 스토리지의 오버 프로비저닝을 방지하기 위해 이 기능이 광범위하게 사용됩니다.</block>
  <block id="bf511e8b678dd2ecee162930e6c8c9e6" category="paragraph">Azure 경고 로그와 함께 Azure 기능을 만들어 볼륨 크기를 쉽게 조정할 수 있습니다.</block>
  <block id="012b603d852affe4779f095a5c59f0c5" category="summary">퍼블릭 클라우드의 민첩성, 가치 창출 시간, 비용 절감은 모두 기업에서 데이터베이스 애플리케이션 개발 및 테스트 노력을 위해 퍼블릭 클라우드를 채택할 때 의미 있는 가치 제안입니다. SnapCenter보다 더 나은 도구는 없습니다. SnapCenter은 운영 데이터베이스를 사내에서 보호할 수 있을 뿐만 아니라 추가 스토리지를 거의 사용하지 않고 퍼블릭 클라우드에서 애플리케이션 개발 또는 코드 테스트용 복사본을 빠르게 복제할 수 있습니다. 다음은 도구를 사용한 단계별 프로세스의 세부 정보입니다.</block>
  <block id="38da6679588aeb2754e14dd58994685e" category="doc">개발/테스트 급증에 대비하여 클라우드로 전환하는 워크플로우</block>
  <block id="5b9681a3caf5db6230c17718122074d3" category="inline-link-macro">이전:AWS 퍼블릭 클라우드 시작하기</block>
  <block id="e9e59a2a982f81f5f964248f351b2446" category="paragraph"><block ref="e9e59a2a982f81f5f964248f351b2446" category="inline-link-macro-rx"></block></block>
  <block id="4d8a5b6bc9c43ab79e376d1aa4d83217" category="paragraph">퍼블릭 클라우드의 민첩성, 가치 창출 시간, 비용 절감은 모두 데이터베이스 애플리케이션 개발 및 테스트 노력을 위한 퍼블릭 클라우드를 채택하는 기업에게 의미 있는 가치 제안입니다. SnapCenter보다 더 나은 도구는 없습니다. SnapCenter은 운영 데이터베이스를 사내에서도 보호할 수 있을 뿐만 아니라 추가 스토리지를 거의 사용하지 않고 퍼블릭 클라우드에서 애플리케이션 개발 또는 코드 테스트용 복사본을 신속하게 클론 복제할 수 있습니다. 다음은 이 도구를 사용하는 단계별 프로세스에 대한 세부 정보입니다.</block>
  <block id="b47b42841be2e173707ab5884714970b" category="section-title">복제된 스냅샷 백업에서 개발/테스트용 Oracle 데이터베이스의 클론을 생성합니다</block>
  <block id="8d90529d1117b8d3781bd6781acf4e91" category="list-text">Oracle용 데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인합니다. 리소스 탭으로 이동하여 SnapCenter에서 보호 중인 Oracle 데이터베이스를 표시합니다.</block>
  <block id="a95ff2a2ae2905b0bb3bd0efa211a040" category="paragraph"><block ref="a95ff2a2ae2905b0bb3bd0efa211a040" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d539d2e9659870aa79747206fac4769" category="list-text">백업 토폴로지와 세부 정보에 대해 원하는 온-프레미스 데이터베이스 이름을 클릭합니다. 보조 복제 위치가 설정된 경우 연결된 미러 백업이 표시됩니다.</block>
  <block id="20111f4a74a9c065157aa13379000a73" category="paragraph"><block ref="20111f4a74a9c065157aa13379000a73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4a9c1f33e524696d6f3adebf89947bb" category="list-text">미러링된 백업을 클릭하여 미러링된 백업 보기로 전환했습니다. 그러면 2차 미러 백업이 표시됩니다.</block>
  <block id="e1cbaea95bcc154ccf9e8aece7fc73b3" category="paragraph"><block ref="e1cbaea95bcc154ccf9e8aece7fc73b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4726a244c3941457e8f62b49c83d35d1" category="list-text">복제할 미러링된 보조 데이터베이스 백업 복제본을 선택하고 시간 및 시스템 변경 번호 또는 SCN에 의해 복구 지점을 결정합니다. 일반적으로 복구 지점은 전체 데이터베이스 백업 시간 또는 SCN을 지나 클론을 생성해야 합니다. 복구 지점을 결정한 후에는 복구에 필요한 로그 파일 백업을 마운트해야 합니다. 로그 파일 백업은 클론 데이터베이스를 호스팅할 대상 DB 서버에 마운트되어야 합니다.</block>
  <block id="81d132cd1ae26e007bb608e5f8609288" category="paragraph"><block ref="81d132cd1ae26e007bb608e5f8609288" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2dc441031605bf54d78fde13b3efc3c" category="paragraph"><block ref="b2dc441031605bf54d78fde13b3efc3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22a17e5abcfc4b5e70ebdea098cd1891" category="admonition">로그 잘라내기를 사용하도록 설정하고 복구 지점이 마지막 로그 잘라내기 이후에 확장된 경우 여러 아카이브 로그 백업을 마운트해야 할 수 있습니다.</block>
  <block id="e9606676533bbe916f4b4b6824eac195" category="list-text">클론 복제할 전체 데이터베이스 백업 복사본을 강조 표시한 다음 클론 버튼을 클릭하여 DB 클론 워크플로우를 시작합니다.</block>
  <block id="48493c19ee97a291cd320501daf5c721" category="paragraph"><block ref="48493c19ee97a291cd320501daf5c721" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c06d82b497809fcc0fd06d00c6d91a5" category="list-text">전체 컨테이너 데이터베이스 또는 CDB 클론에 대해 적절한 클론 DB SID를 선택합니다.</block>
  <block id="f6ee6a459784097119ec1eee6224152e" category="paragraph"><block ref="f6ee6a459784097119ec1eee6224152e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2c50a030b1c5313fca09568edf8c0f9" category="list-text">클라우드에서 타겟 클론 호스트를 선택하고 데이터 파일, 제어 파일 및 재실행 로그 디렉토리는 클론 워크플로우에 의해 생성됩니다.</block>
  <block id="323554a005f5e77dfaa765ea81e645be" category="paragraph"><block ref="323554a005f5e77dfaa765ea81e645be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="701f017aeafb71656cf2bc3a9bd34862" category="list-text">없음 자격 증명 이름은 OS 기반 인증에 사용되며 데이터베이스 포트를 상관 없이 만듭니다. 타겟 클론 DB 서버에 구성된 적절한 Oracle Home, Oracle OS User 및 Oracle OS Group을 입력합니다.</block>
  <block id="c5237b674d4a9cd38d44c5e546cc51d4" category="paragraph"><block ref="c5237b674d4a9cd38d44c5e546cc51d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="26a911f3c85fc3c73d79253e65bf30e3" category="list-text">클론 작업 전에 실행할 스크립트를 지정합니다. 더 중요한 것은 여기에서 데이터베이스 인스턴스 매개 변수를 조정하거나 정의할 수 있다는 것입니다.</block>
  <block id="56774e452bc62021e52de3e3fea844a2" category="paragraph"><block ref="56774e452bc62021e52de3e3fea844a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09d7240367714707474d63a3a574222b" category="list-text">날짜 및 시간 또는 SCN을 기준으로 복구 지점을 지정합니다. 취소 전까지 는 데이터베이스를 사용 가능한 아카이브 로그까지 복구합니다. 아카이브 로그 볼륨이 마운트된 타겟 호스트에서 외부 아카이브 로그 위치를 지정합니다. 대상 서버 Oracle 소유자가 온-프레미스 운영 서버와 다른 경우 대상 서버 Oracle 소유자가 아카이브 로그 디렉터리를 읽을 수 있는지 확인합니다.</block>
  <block id="6cb86841376102e5b8924f9909b8f570" category="paragraph"><block ref="6cb86841376102e5b8924f9909b8f570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70b171a9c984de6358afb3557fe84586" category="paragraph"><block ref="70b171a9c984de6358afb3557fe84586" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b30b70196320d22207ea0d5d95d2c841" category="paragraph"><block ref="b30b70196320d22207ea0d5d95d2c841" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0421be6f676ac1ddace9e39eeeb54f0f" category="list-text">클론 요약</block>
  <block id="a930a442bf914f516109fbb28bf2fbd1" category="paragraph"><block ref="a930a442bf914f516109fbb28bf2fbd1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d929881b22cd699e243e2343bd707d" category="list-text">클론 생성 후 검증하여 클론 복제된 데이터베이스가 작동하는지 확인해야 합니다. 리스너를 시작하거나 DB 로그 아카이브 모드를 해제하는 등의 일부 추가 작업은 개발/테스트 데이터베이스에서 수행할 수 있습니다.</block>
  <block id="9991775de6f914e5a41601ba523e3193" category="paragraph"><block ref="9991775de6f914e5a41601ba523e3193" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58732c8d9b1293bb6666ef2284840fd3" category="section-title">복제된 Snapshot 백업에서 개발/테스트용 SQL 데이터베이스의 클론을 생성합니다</block>
  <block id="605f2bb9d099f78e26260848db117df7" category="list-text">SQL Server의 데이터베이스 관리 사용자 ID를 사용하여 SnapCenter에 로그인합니다. 리소스 탭으로 이동합니다. 이 탭에는 SnapCenter로 보호되는 SQL Sever 사용자 데이터베이스와 퍼블릭 클라우드의 타겟 대기 SQL 인스턴스가 표시됩니다.</block>
  <block id="d238acd8e02d4df70c9b55828a4b8801" category="paragraph"><block ref="d238acd8e02d4df70c9b55828a4b8801" category="inline-image-macro-rx" type="image"></block></block>
  <block id="39c34a717e197c67b1fc8d678db5815b" category="list-text">백업 토폴로지 및 상세 보기에 사용할 온-프레미스 SQL Server 사용자 데이터베이스 이름을 클릭합니다. 보조 복제 위치가 설정된 경우 연결된 미러 백업이 표시됩니다.</block>
  <block id="8c57a9d29ca9640330e03e6edca2b6e5" category="paragraph"><block ref="8c57a9d29ca9640330e03e6edca2b6e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a5910fa5df5b6482c00b15ae683eef0f" category="list-text">미러링된 백업을 클릭하여 미러링된 백업 보기로 전환합니다. 그러면 보조 미러 백업이 표시됩니다. SnapCenter는 복구를 위해 전용 드라이브에 SQL Server 트랜잭션 로그를 백업하므로 전체 데이터베이스 백업만 여기에 표시됩니다.</block>
  <block id="f8d3ed6786c765a87cec8464a574076a" category="paragraph"><block ref="f8d3ed6786c765a87cec8464a574076a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="368014bae8201ab49d2207a53c907069" category="list-text">백업 복사본을 선택한 다음 클론 버튼을 클릭하여 백업에서 클론 복제를 시작합니다.</block>
  <block id="87dbbaf733c71b9d4e0027ad4a85e709" category="paragraph"><block ref="87dbbaf733c71b9d4e0027ad4a85e709" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75c22c861d423e3f3450da18d56f0599" category="paragraph"><block ref="75c22c861d423e3f3450da18d56f0599" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44258030a87117191bde6d62511ddb9a" category="list-text">클라우드 서버를 타겟 클론 서버, 클론 인스턴스 이름 및 클론 데이터베이스 이름으로 선택합니다. 자동 할당 마운트 지점 또는 사용자 정의 마운트 지점 경로를 선택합니다.</block>
  <block id="7841eed97c9a860bcb6a46b08ea08c11" category="paragraph"><block ref="7841eed97c9a860bcb6a46b08ea08c11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18145dc97ae06034ae9aafa8b98cb36e" category="list-text">로그 백업 시간 또는 특정 날짜 및 시간으로 복구 지점을 결정합니다.</block>
  <block id="b2798123b4d42e447362355b510a424c" category="paragraph"><block ref="b2798123b4d42e447362355b510a424c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b9becceddf802cada91d9e2aa84ac5a" category="list-text">클론 생성 작업 전후에 실행할 선택적 스크립트를 지정합니다.</block>
  <block id="adee0219db450497bd0f545df8d862c7" category="paragraph"><block ref="adee0219db450497bd0f545df8d862c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e41b01ffd717fd3d0b5788e608e50b52" category="list-text">e-메일 알림이 필요한 경우 SMTP 서버를 구성합니다.</block>
  <block id="9b758c550d5da3ecb44f04ae804293d4" category="paragraph"><block ref="9b758c550d5da3ecb44f04ae804293d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc89ae2ec0203249b8e60785a63ca258" category="list-text">클론 요약.</block>
  <block id="ab74d2d908acf5c3e01544cd4b871b73" category="paragraph"><block ref="ab74d2d908acf5c3e01544cd4b871b73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28725828580a55d904e8b2a39f377eb9" category="list-text">작업 상태를 모니터링하고 원하는 사용자 데이터베이스가 클라우드 클론 서버의 대상 SQL 인스턴스에 연결되어 있는지 확인합니다.</block>
  <block id="766259946fc034002a24d5f23655c73e" category="paragraph"><block ref="766259946fc034002a24d5f23655c73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d512bf68b17268adfe539f9722d869b4" category="section-title">사후 클론 구성</block>
  <block id="50d9180ea26c89fbe6506d71d81d3fb1" category="list-text">온프레미스 Oracle 운영 데이터베이스는 일반적으로 로그 아카이브 모드에서 실행됩니다. 이 모드는 개발 또는 테스트 데이터베이스에 필요하지 않습니다. 로그 아카이브 모드를 끄려면 Oracle DB에 sysdba로 로그인하고 로그 모드 변경 명령을 실행한 다음 액세스를 위해 데이터베이스를 시작합니다.</block>
  <block id="b205237d51ff9525496f4b2252942213" category="list-text">Oracle 수신기를 구성하거나 새로 복제된 DB를 사용자 액세스를 위해 기존 수신기에 등록합니다.</block>
  <block id="800699a04cdaa75b2219988799b0a048" category="list-text">SQL Server의 경우 로그 볼륨을 채울 때 SQL Server 개발/테스트 로그 파일을 쉽게 축소할 수 있도록 로그 모드를 Full에서 Easy로 변경합니다.</block>
  <block id="89e018d207fd292a4926870904035c18" category="section-title">클론 데이터베이스를 새로 고칩니다</block>
  <block id="d84550ba9a340ebf4fa6698dff5ba344" category="list-text">복제된 데이터베이스를 떨어뜨리거나 클라우드 DB 서버 환경을 정리합니다. 그런 다음 이전 절차에 따라 새 DB를 새 데이터로 복제합니다. 새 데이터베이스를 복제하는 데는 몇 분 밖에 걸리지 않습니다.</block>
  <block id="1170d6f09309cb8dc382034a34680937" category="inline-link-macro">클론을 새로 고칩니다</block>
  <block id="fef062eeb7771b01e620bb2460b1bf9a" category="list-text">클론 데이터베이스를 종료하고 CLI를 사용하여 클론 새로 고침 명령을 실행합니다. 자세한 내용은 다음 SnapCenter 설명서를 참조하십시오. <block ref="1e4035dee07650c706f8f0714c384872" category="inline-link-macro-rx"></block>.</block>
  <block id="7b88d7d11804db6b079e226a6f043ea7" category="paragraph">이 솔루션 및 사용 사례에 대한 도움이 필요한 경우 에 가입하십시오 <block ref="f9456f3b54a140d5d3858823c684363f" category="inline-link-macro-rx"></block> 질문 또는 질문을 게시할 수 있는 솔루션 자동화 채널을 찾아보십시오.</block>
  <block id="e2a76301a4117f21d6192304aa650018" category="inline-link-macro">다음: 재해 복구 워크플로.</block>
  <block id="28a87ee64d4675e6c24cd960fe71d9bf" category="paragraph"><block ref="28a87ee64d4675e6c24cd960fe71d9bf" category="inline-link-macro-rx"></block></block>
  <block id="c150393fd3b1bd9d801cbd062234f73d" category="section-title">AWX/Tower 구축 Oracle 19c Database</block>
  <block id="3fa16e80574aff03c27de1253474a20f" category="list-text">재고 변수가 있는 경우 변수 필드에 붙여 넣습니다.</block>
  <block id="396641e01a7451ca821b5d7d1377b0c7" category="list-text">ONTAP 그룹 이름을 입력하고 그룹 변수(있는 경우)를 붙여 넣은 다음 저장을 클릭합니다.</block>
  <block id="a4f13b6e4100f2d5db093eb54a3ffe0c" category="list-text">Oracle에 대해 다른 그룹에 대해서도 이 프로세스를 반복합니다.</block>
  <block id="6f29f21d5f3e40494291fb357b9f4f73" category="list-text">생성된 ONTAP 그룹을 선택하고 Hosts 하위 메뉴로 이동한 다음 Add New Host를 클릭합니다.</block>
  <block id="8d92ffd9d0d2b033d05731ec4af50af8" category="list-text">ONTAP 클러스터 관리 IP의 IP 주소를 제공하고 호스트 변수(있는 경우)를 붙여 넣은 다음 저장 을 클릭합니다.</block>
  <block id="f1254ecbe57ff98d850d541b8a1ab988" category="list-text">Oracle 그룹 및 Oracle 호스트 관리 IP/호스트 이름에 대해 이 프로세스를 반복해야 합니다.</block>
  <block id="f11c5853bdca384314b28c9c59f2d6d0" category="list-text">자격 증명 유형을 만듭니다. ONTAP와 관련된 솔루션의 경우 자격 증명 유형을 사용자 이름 및 암호 항목과 일치하도록 구성해야 합니다.</block>
  <block id="1616edbabbc3bbfd22afe144d1929386" category="list-text">다음 내용을 주입기 구성에 붙여넣습니다.</block>
  <block id="cc865c923bcb1c61acf9985311675b93" category="list-text">ONTAP의 이름과 조직 세부 정보를 입력합니다.</block>
  <block id="ea314f484653e7f9f25144ea61d34888" category="list-text">ONTAP에 대해 만든 사용자 지정 자격 증명 유형을 선택합니다.</block>
  <block id="179cae6336461d9f165e8fa87146362a" category="list-text">세부 정보 입력 아래에 사용자 이름, 암호 및 vsadmin_password를 입력합니다.</block>
  <block id="659fb4c811f1a73cf40492056e6d3c3f" category="list-text">자격 증명으로 돌아가기 를 클릭하고 추가 를 클릭합니다.</block>
  <block id="3b9c90c4bf202563a3cdeda5ec78fac2" category="list-text">Oracle의 이름 및 조직 세부 정보를 입력합니다.</block>
  <block id="784148c4a03cf22250dddc5756684e39" category="list-text">를 입력합니다 <block ref="4509731a8f0f86cf7d8a010739dfd7c5" category="inline-link-rx"></block> 소스 제어 URL입니다.</block>
  <block id="14e017f358e18dd612a468713206093f" category="section-title">Oracle host_VAR을 구성합니다</block>
  <block id="05557c38b20e42173356b53f42c92152" category="paragraph">이 섹션에 정의된 변수는 각 개별 Oracle 서버 및 데이터베이스에 적용됩니다.</block>
  <block id="ac886b852fd1b481e9c7e68c217b5e21" category="list-text">다음과 같은 내장된 Oracle hosts 변수 또는 host_vars 양식에 환경별 매개 변수를 입력합니다.</block>
  <block id="e1847b1a99378b07a0df71cf2baac5da" category="list-text">파란색 필드에 모든 변수를 입력합니다.</block>
  <block id="741c92ab2429ff59927918c7a07ad9a5" category="list-text">변수 입력을 완료한 후 양식의 복사 버튼을 클릭하여 AWX 또는 타워로 전송할 모든 변수를 복사합니다.</block>
  <block id="1e1ea51549ac2a644a3e965113c1d370" category="list-text">AWX 또는 Tower로 돌아가서 Resources → Hosts 로 이동한 다음 Oracle 서버 구성 페이지를 선택하여 엽니다.</block>
  <block id="0d630b14098a793ac4586173286d0805" category="list-text">세부 정보 탭에서 편집 을 클릭하고 1단계에서 복사한 변수를 YAML 탭의 변수 필드에 붙여 넣습니다.</block>
  <block id="c6dca9e669d097298fc6059b27f96e09" category="list-text">시스템에 있는 모든 추가 Oracle 서버에 대해 이 프로세스를 반복합니다.</block>
  <block id="7890327bd98d1ec932e453254511754d" category="section-title">글로벌 변수를 설정합니다</block>
  <block id="7d2a3c2ad9ee2eeb7547d205d30b9335" category="list-text">파란색 필드에 모든 변수를 입력합니다.</block>
  <block id="099f04b51539ed973890f1d1af2d5063" category="list-text">변수 입력을 완료한 후 양식의 복사 버튼을 클릭하여 AWX 또는 Tower로 전송할 모든 변수를 다음 작업 템플릿으로 복사합니다.</block>
  <block id="c807b1735c1915c52547b9f7e917b55d" category="section-title">작업 템플릿을 구성하고 시작합니다.</block>
  <block id="c7fa74fb4cbaab9d336a8e55bf164684" category="list-text">이름과 설명을 입력합니다</block>
  <block id="3dcca032e3328f54206079a87830aa27" category="list-text">작업 유형을 선택합니다. Run은 Playbook을 기반으로 시스템을 구성하고 Check는 실제로 시스템을 구성하지 않고 Playbook을 건조하게 실행합니다.</block>
  <block id="b01c6189ccdc531874f3442803680525" category="list-text">All_Playbook.yml을 실행할 기본 플레이북으로 선택합니다.</block>
  <block id="e8f0426d97d09775fb78bdeb793b0b3e" category="list-text">작업 태그 필드에서 시작 시 프롬프트 표시 확인란을 선택합니다.</block>
  <block id="ad7ad1bbc416fda1f9518ff4004d891c" category="list-text">작업 태그를 시작할 때 메시지가 나타나면 requirements_config 를 입력합니다. 작업 태그를 입력하려면 requirements_config 아래의 작업 태그 작성 줄을 클릭해야 할 수도 있습니다.</block>
  <block id="b9ef793a3db3f07ed7dc808f4709c6ca" category="admonition">requirements_config 다른 역할을 실행할 올바른 라이브러리가 있는지 확인합니다.</block>
  <block id="6ac039e55dcf8a249f5122b1fdbbf60e" category="list-text">다음 을 클릭한 다음 시작 을 클릭하여 작업을 시작합니다.</block>
  <block id="06f392c8dfb4783859e67f16fed69bc7" category="list-text">보기 → 작업 을 클릭하여 작업 출력 및 진행률을 모니터링합니다.</block>
  <block id="7f6a02c24592bd309f31b5a72a0f8d6d" category="list-text">작업 태그를 시작할 때 프롬프트가 표시되면 ONTAP_config를 입력합니다. ONTAP_config 바로 아래에 있는 "작업 태그" 생성 라인을 클릭하여 작업 태그를 입력해야 할 수 있습니다.</block>
  <block id="18c003af9ed29d295877baabf7b42ce1" category="list-text">보기 → 작업 을 클릭하여 작업 출력 및 진행률을 모니터링합니다</block>
  <block id="c0029d5cdcaae1ceef3bed244b3ab3c6" category="list-text">ONTAP_config 역할이 완료된 후 Linux_config에 대해 프로세스를 다시 실행하십시오.</block>
  <block id="fc71758268fe1c3aba4b75df3ee0560f" category="list-text">원하는 템플릿을 선택한 다음 실행을 클릭합니다.</block>
  <block id="bbe073bafc2875db8b48e59284636931" category="list-text">Linux_config에서 작업 태그 유형을 시작할 때 메시지가 표시되면 Linux_config 바로 아래의 "작업 태그 생성" 행을 선택하여 작업 태그를 입력해야 할 수 있습니다.</block>
  <block id="bc43b7acafead2cdee67de733ae10b13" category="list-text">보기 → 작업 을 선택하여 작업 출력 및 진행률을 모니터링합니다.</block>
  <block id="e73718535637e07111f6a4925685c0bd" category="list-text">Linux_config 역할이 완료된 후 ORACLE_config에 대해 프로세스를 다시 실행하십시오.</block>
  <block id="574f8726a5cc088da32ab84269c8e0f8" category="list-text">리소스 → 템플릿 으로 이동합니다.</block>
  <block id="252b85bc679cb8ecdccbcd127c65b795" category="list-text">작업 태그 시작 시 메시지가 표시되면 ORACLE_config 를 입력합니다. 작업 태그를 입력하려면 ORACLE_config 바로 아래에 있는 "작업 태그 생성" 행을 선택해야 할 수 있습니다.</block>
  <block id="6757805f64ddba2566927ece0d9f30e1" category="section-title">동일한 Oracle 호스트에 추가 데이터베이스를 구축합니다</block>
  <block id="4edc1d4492ab93edbbb0a67c0c265b84" category="paragraph">플레이북의 Oracle 부분은 실행 당 Oracle 서버에 단일 Oracle 컨테이너 데이터베이스를 생성합니다. 동일한 서버에 추가 컨테이너 데이터베이스를 만들려면 다음 단계를 완료하십시오.</block>
  <block id="a12a0fa7fe728658376da87df04fa7c2" category="list-text">host_vars 변수를 수정합니다.</block>
  <block id="ba52bf2d165115d60675d61a4b84b0c6" category="list-text">2단계 - Configure Oracle host_VAR로 돌아갑니다.</block>
  <block id="d9fa63a6f267402d4cf6068165e04a38" category="list-text">EM Express를 설치할 경우 EM Express 포트를 다른 번호로 변경하십시오.</block>
  <block id="23f5c9b4f57b3075f9890f1bc1896ebe" category="list-text">호스트 구성 세부 정보 탭의 Oracle 호스트 변수 필드에 수정된 호스트 변수를 복사하여 붙여 넣습니다.</block>
  <block id="4d4426a703dd8227727fef5758b680d8" category="list-text">ORACLE_config 태그만 사용하여 구축 작업 템플릿을 시작합니다.</block>
  <block id="0c138556fe4f10d4cdba4c61933afd91" category="doc">Google Cloud Virtualization Engine용 NetApp 솔루션(GCVE)</block>
  <block id="10b5b21ed1ee90eca305b558caf7d03b" category="open-title">마이그레이션</block>
  <block id="21a1e68164f738b8be1dae11d5a694b3" category="open-title">데이터 보호</block>
  <block id="29f8b77f5f7c79b566706e0d55c9de8b" category="doc">Amazon VMC(VMware Managed Cloud)를 위한 NetApp 솔루션</block>
  <block id="7e0686a26bc7a91429819c2aeb7b414a" category="doc">Azure VMware 솔루션용 NetApp 솔루션(AVS)</block>
  <block id="44f55a60cc8f70d1e10efc62b75eeddc" category="doc">하이퍼스케일 솔루션 에서 VMware를 위한 NetApp 솔루션</block>
  <block id="b583dc49832a978014ef0d14fe7ef1ce" category="paragraph">NetApp이 마이그레이션 워크플로우, 클라우드로의 확장/버스팅, 백업/복원, 재해 복구 등 각 하이퍼스케일러에 VMware 환경을 제공하는 솔루션에 대해 자세히 알아보십시오.</block>
  <block id="07b0eade4402d209b5dbe587a8ad3f6f" category="doc">AWS에서 가상화 환경을 구축하고 구성합니다</block>
  <block id="e647d88b9bd859d2c3e943c24b4fef00" category="paragraph">사내 환경과 마찬가지로, AWS에서 VMware Cloud를 계획하는 것은 VM과 마이그레이션을 성공적으로 운영 환경에 구축하는 데 매우 중요합니다.</block>
  <block id="162e9e1fd4657b8d9588a5ae8c8e6e66" category="paragraph">이 섹션에서는 AWS SDDC에서 VMware Cloud를 설정 및 관리하고, NetApp 스토리지를 연결하는 데 사용할 수 있는 옵션과 함께 사용하는 방법을 설명합니다.</block>
  <block id="d6d7fade0a5d1cd7723c64125e595b08" category="paragraph">설치 프로세스는 다음 단계로 나눌 수 있습니다.</block>
  <block id="389544cc8199f2ddd936397695d0dbe9" category="inline-link-macro">VMware Cloud for AWS 구축 및 구성</block>
  <block id="b4f284d3b5bb40ee91901933b8f7ef5f" category="inline-link-macro">VMware Cloud를 FSx ONTAP에 연결합니다</block>
  <block id="4dab2f9796b0af6304d00e21e2b9dfb4" category="inline-link-macro">AWS 기반 VMware 클라우드</block>
  <block id="02b412692a538ee9dc2534f0f9c73dc1" category="paragraph"><block ref="560d5b2cd40977bd7b77b31d7088f657" category="inline-link-macro-rx"></block> AWS 에코시스템의 VMware 기반 워크로드에 클라우드 네이티브 경험을 제공합니다. 각 VMware SDDC(소프트웨어 정의 데이터 센터)는 VPC(Amazon Virtual Private Cloud)에서 실행되며 전체 VMware 스택(vCenter Server 포함), NSX-T 소프트웨어 정의 네트워킹, vSAN 소프트웨어 정의 스토리지, 워크로드에 컴퓨팅 및 스토리지 리소스를 제공하는 하나 이상의 ESXi 호스트를 제공합니다.</block>
  <block id="dc77b78f59a0c38a9a2e8927dc05e916" category="paragraph">이 섹션에서는 AWS에서 VMware Cloud를 설정 및 관리하고, 게스트 내 스토리지에서 AWS에서 NetApp ONTAP용 Amazon FSx 및/또는 Cloud Volumes ONTAP와 함께 사용하는 방법에 대해 설명합니다.</block>
  <block id="3712f34e1b7039d6d9bfb255ecc54445" category="paragraph">설정 프로세스는 다음 세 부분으로 나눌 수 있습니다.</block>
  <block id="f54d8dbbc1cb20fd37a59a4563644ef8" category="inline-link-macro">아마존 웹 서비스 계정</block>
  <block id="4ca1486cd3276884e41ad4b36080c10b" category="list-text">에 등록하십시오 <block ref="ab3390028f6599a1b73b747febbf672d" category="inline-link-macro-rx"></block>.</block>
  <block id="020e995219c3fad42714462fc9368253" category="inline-link-macro">내 VMware</block>
  <block id="4f87cd22b54abb602d4264ede77c75fd" category="list-text">에 등록하십시오 <block ref="6fb1d438d7363efa930c55af527a6c23" category="inline-link-macro-rx"></block> 계정.</block>
  <block id="252c0d3625c410f643362d13f1e35681" category="paragraph">이미 생성된 계정이 없는 경우 시작하려면 AWS 계정이 필요합니다. 이 절차의 여러 단계에 대해 새 계정 또는 기존 계정에 관리 권한이 필요합니다. 자세한 내용은 다음을 참조하십시오 <block ref="d01b332d778720bc2fe2a9a15e6ba01d" category="inline-link-macro-rx"></block> AWS 자격 증명에 대한 자세한 내용은</block>
  <block id="e1ed167660991d514f55d806a323f3b5" category="paragraph">VMware의 클라우드 포트폴리오(AWS의 VMware Cloud 포함)에 액세스하려면 VMware 고객 계정 또는 My VMware 계정이 필요합니다. 아직 생성하지 않은 경우 VMware 계정을 생성합니다 <block ref="aefb6f511cceca70505b3e5bf76155fe" category="inline-link-macro-rx"></block>.</block>
  <block id="60fa505f14fb504e941cbc61b74d644a" category="section-title">VMware 클라우드에서 SDDC 프로비저닝</block>
  <block id="6d931b72d8efc3fd87b7fdd5127cbba7" category="paragraph">VMware 계정을 구성하고 적절한 사이징을 수행한 후에는 AWS에서 VMware Cloud 서비스를 사용하기 위한 확실한 다음 단계로 소프트웨어 정의 데이터 센터를 구축할 수 있습니다. SDDC를 생성하려면 호스팅할 AWS 영역을 선택하고 SDDC에 이름을 지정하고 SDDC에 포함할 ESXi 호스트 수를 지정합니다. 아직 AWS 계정이 없는 경우에도 단일 ESXi 호스트를 포함하는 시작 구성 SDDC를 생성할 수 있습니다.</block>
  <block id="7e70ad389301fa9d8936c18cefd85b53" category="list-text">기존 또는 새로 생성한 VMware 자격 증명을 사용하여 VMware Cloud Console에 로그인합니다.</block>
  <block id="28570a642842f2bfa7db5cc3679fd904" category="paragraph"><block ref="28570a642842f2bfa7db5cc3679fd904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="53722f60844c899c63607413f74e8dd8" category="list-text">AWS 지역, 구축 및 호스트 유형과 SDDC 이름을 구성합니다.</block>
  <block id="5ec07ba481e6291d3af5e3ca61f27f57" category="paragraph"><block ref="5ec07ba481e6291d3af5e3ca61f27f57" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5c464b97b208b8c43e9fdd315c80793" category="list-text">원하는 AWS 계정에 연결하고 AWS Cloud 포메이션 스택을 실행합니다.</block>
  <block id="b6822d593b3a1b683cb4e513b210c080" category="paragraph"><block ref="941b74b5e4d054f44fb05f89bfb30732" category="inline-image-macro-rx" type="image"></block>
<block ref="5ca301c5ba248bc9f9566d74470fcc6b" category="inline-image-macro-rx" type="image"></block>
<block ref="54108005ae53e37fa06b081374d6ea43" category="inline-image-macro-rx" type="image"></block>
<block ref="9f7f4a317cf9d46aa6a2aa8f441279ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59e9afc055ce73e7e6154ea7609eec59" category="admonition">이 검증에는 단일 호스트 구성이 사용됩니다.</block>
  <block id="3f68cef60baccc27cfef6b618e56f809" category="list-text">원하는 AWS VPC를 선택하여 VMC 환경을 에 연결합니다.</block>
  <block id="49e131b27a342d4970e86a31a127d41c" category="paragraph"><block ref="49e131b27a342d4970e86a31a127d41c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="102a37b9412553c4ae6b25a174592fbb" category="list-text">VMC 관리 서브넷을 구성합니다. 이 서브넷에는 vCenter, NSX 등과 같은 VMC 관리 서비스가 포함됩니다. SDDC 환경에 대한 연결이 필요한 다른 네트워크와 겹치는 주소 공간을 선택하지 마십시오. 마지막으로 아래에 기입된 CIDR 크기에 대한 권장 사항을 따르십시오.</block>
  <block id="0e8db488f9554136a65dd18025db8cf0" category="paragraph"><block ref="0e8db488f9554136a65dd18025db8cf0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a541610269aad8edaf8defd851246b08" category="list-text">SDDC 구성을 검토 및 확인한 다음 SDDC 구축 을 클릭합니다.</block>
  <block id="a8246981b8dc3e6123523500b3b1371d" category="paragraph"><block ref="a8246981b8dc3e6123523500b3b1371d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bb7bef7f28887197cfca7059ef2d6d3" category="paragraph">일반적으로 구축 프로세스를 완료하는 데 약 2시간이 소요됩니다.</block>
  <block id="e9dcc1b6680c77f105c83d040009d685" category="paragraph"><block ref="e9dcc1b6680c77f105c83d040009d685" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79b6ae1d041f5cd8b33d3f351b301275" category="list-text">완료되면 SDDC를 사용할 수 있습니다.</block>
  <block id="9013490d3a116eed1c849197a6c8aac0" category="paragraph"><block ref="9013490d3a116eed1c849197a6c8aac0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e149dd16e33c6137fe08782e96c9b226" category="inline-link-macro">VMC 콘솔에서 SDDC를 구축합니다</block>
  <block id="086760513a416fbc6578703211523314" category="paragraph">SDDC 구축에 대한 단계별 가이드는 를 참조하십시오 <block ref="7279ebe13e8b8c4ee89b8961f2bf1157" category="inline-link-macro-rx"></block>.</block>
  <block id="8a69f1bae52e494c6960f92a27390dcf" category="paragraph">VMware Cloud를 FSx ONTAP에 연결하려면 다음 단계를 수행하십시오.</block>
  <block id="7ca6fbd8bbb6725fab7413e4179738f6" category="list-text">VMware 클라우드 구축이 완료되고 AWS VPC에 연결되면 NetApp ONTAP용 Amazon FSx를 원래 연결된 VPC가 아닌 새 VPC에 구축해야 합니다(아래 스크린샷 참조). 연결된 VPC에 FSX(NFS 및 SMB 부동 IP)를 구축하면 FSX에 액세스할 수 없습니다. Cloud Volumes ONTAP와 같은 iSCSI 엔드포인트는 연결된 VPC에서 정상적으로 작동합니다.</block>
  <block id="da6646a18f048724eb432bf61285ca7f" category="paragraph"><block ref="da6646a18f048724eb432bf61285ca7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85dd65f7163e587c050ea8931a368ae" category="list-text">동일한 지역에 추가 VPC를 구축한 다음 NetApp ONTAP용 Amazon FSx를 새 VPC에 구축합니다.</block>
  <block id="c78834afa7d24e921aa4d756d0a6409f" category="paragraph">VMware Cloud Console에서 SDDC 그룹을 구성하면 FSx가 구축된 새 VPC에 연결하는 데 필요한 네트워킹 구성 옵션을 사용할 수 있습니다. 3단계에서 "그룹에 대한 VMware Transit Connect 구성 시 첨부 파일 및 데이터 전송당 비용이 청구됨"이 선택되어 있는지 확인한 다음 그룹 생성 을 선택합니다. 이 프로세스를 완료하는 데 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="f91a2b452c63b5ccfcb4c39c2957c74e" category="paragraph"><block ref="ca83e0582a449c1b4399270025e1cc4a" category="inline-image-macro-rx" type="image"></block>
<block ref="9232dff72050e533bd1e173e5a0dd48c" category="inline-image-macro-rx" type="image"></block>
<block ref="5a108f597862e683ab9463f7c3ba6df6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fae60fbb10da5c3df46ec8ae03cd29b5" category="inline-link-macro">외부 VPC 연결 지침</block>
  <block id="784ad3266f853af20763bb78f5eec87a" category="list-text">새로 생성된 VPC를 방금 생성된 SDDC 그룹에 연결합니다. External VPC 탭을 선택하고 에 따릅니다 <block ref="19928d01a63fe78e1303b296c2046666" category="inline-link-macro-rx"></block> 그룹에. 이 프로세스를 완료하는 데 10-15분 정도 걸릴 수 있습니다.</block>
  <block id="14466a85376e8776f891db4cb3c38c6c" category="paragraph"><block ref="dd1eb585a08c833cec9544c048af36b6" category="inline-image-macro-rx" type="image"></block>
<block ref="38542de5661e382aba9345fe6e5a991b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8acea1c4fcca87631ca127e2bc757f13" category="inline-link-macro">AWS Transit Gateway를 참조하십시오</block>
  <block id="77508ef16874a250b66be2f90fc59918" category="list-text">외부 VPC 프로세스의 일환으로, 리소스 액세스 관리자를 통해 AWS 콘솔을 통해 새 공유 리소스에 대한 메시지가 표시됩니다. 공유 리소스는 입니다 <block ref="ccce2323414354d76e9cea0c1df9221b" category="inline-link-macro-rx"></block> VMware Transit Connect에서 관리합니다.</block>
  <block id="ac81300f843e6b91377e64a8edb819c2" category="paragraph"><block ref="63de05888c0a11205c33fd560dba3bc5" category="inline-image-macro-rx" type="image"></block>
<block ref="0455c56bd9863ddfae4079b5aabd42e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bcf415daee6d6f894a54f025534ba071" category="list-text">Transit Gateway Attachment를 생성합니다.</block>
  <block id="e222d36183b455bb51f289144826c239" category="paragraph"><block ref="e222d36183b455bb51f289144826c239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b6693c4eff7f7923c59277702b441a9" category="list-text">VMC 콘솔에서 VPC 첨부 파일을 수락합니다. 이 프로세스를 완료하는 데 약 10분 정도 걸릴 수 있습니다.</block>
  <block id="64d5d06ed03c085c4f5ce23ff6eeddac" category="paragraph"><block ref="64d5d06ed03c085c4f5ce23ff6eeddac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9b85dc0e557eb865bfa9ae84e251623" category="list-text">External VPC 탭에서 Routes 열의 편집 아이콘을 클릭하고 다음과 같은 필수 경로를 추가합니다.</block>
  <block id="ae6434a5ebe0bad2f978fef8e0ed9efe" category="inline-link-macro">유동 IP</block>
  <block id="06651ace1eab88d681ca9a8852bf26e2" category="list-text">NetApp ONTAP용 Amazon FSx의 부동 IP 범위에 대한 경로입니다 <block ref="14a98976d888daccbd07561411cfd6fa" category="inline-link-macro-rx"></block>.</block>
  <block id="5e16e681111a1a5b2dc805d69827532f" category="list-text">Cloud Volumes ONTAP의 부동 IP 범위에 대한 라우트입니다(해당하는 경우).</block>
  <block id="efffbab523616433e2c1ea67cbcaab53" category="list-text">새로 생성된 외부 VPC 주소 공간의 경로입니다.</block>
  <block id="daa8a39ba75e8ac01fd26d579ce35fd9" category="paragraph"><block ref="daa8a39ba75e8ac01fd26d579ce35fd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="853349bb92eccb477b47eef3b8a5d9e2" category="inline-link-macro">방화벽 규칙</block>
  <block id="499ca5dd26dbcc4c89a04ac771b316a6" category="inline-link-macro">세부 단계</block>
  <block id="14c6314f2ae331d7f9a01ac04a75cd2b" category="list-text">마지막으로 양방향 트래픽을 허용합니다 <block ref="0756551700fd3215666355892b2f3692" category="inline-link-macro-rx"></block> FSx/CVO에 액세스하기 위한 것입니다. 다음 사항을 따르십시오 <block ref="583f77470215de8611ddf3fba5fc6512" category="inline-link-macro-rx"></block> SDDC 워크로드 연결을 위한 컴퓨팅 게이트웨이 방화벽 규칙의 경우</block>
  <block id="098b98cba4d6766e7de663adf0fdabb0" category="paragraph"><block ref="098b98cba4d6766e7de663adf0fdabb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f4480b9caed7d956fd6071b4cce03b9" category="list-text">방화벽 그룹이 관리 및 컴퓨팅 게이트웨이 모두에 대해 구성된 후에는 다음과 같이 vCenter에 액세스할 수 있습니다.</block>
  <block id="f1c1b29fad3f2bdb9d8d054686b86542" category="paragraph"><block ref="f1c1b29fad3f2bdb9d8d054686b86542" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8b86f112029b19bf6451ba4624a4090" category="paragraph">다음 단계에서는 요구 사항에 따라 Amazon FSx ONTAP 또는 Cloud Volumes ONTAP가 구성되어 있는지, 그리고 구축을 최적화하기 위해 vSAN에서 스토리지 구성 요소를 오프로드하기 위해 볼륨이 프로비저닝되었는지 확인합니다.</block>
  <block id="a724b4fc4c5f79672a5c572466d5e001" category="doc">Azure용 NetApp 게스트 연결 스토리지 옵션</block>
  <block id="5f18b04dd7d7089a2177c4c930d8d57f" category="paragraph">Azure는 다음과 같은 구성에서 NetApp 스토리지를 지원합니다.</block>
  <block id="1ffaf40c19facb6829b48b667d1dcaa3" category="inline-link-macro">게스트 연결 스토리지로서의 Azure NetApp Files(ANF)</block>
  <block id="3017a9031d66c55b0258c102decfd1b9" category="inline-link-macro">CVO(Cloud Volumes ONTAP)를 게스트 연결 스토리지로 사용합니다</block>
  <block id="f43b203ec7020e7ea0e408d9d67255fc" category="section-title">AVS(Azure VMware Solution)를 사용하여 Azure NetApp Files 구성</block>
  <block id="f9a184882060f3e5a8b6045e2a53107f" category="paragraph">Azure NetApp Files 공유는 Azure VMware SDDC 솔루션 환경에서 생성된 VM에서 마운트할 수 있습니다. Azure NetApp Files는 SMB 및 NFS 프로토콜을 지원하므로 Linux 클라이언트에 볼륨을 마운트하고 Windows 클라이언트에 매핑할 수도 있습니다. Azure NetApp Files 볼륨은 간단한 5단계를 통해 설정할 수 있습니다.</block>
  <block id="5bb6f16c69df9b9f54bddaaa5e32b415" category="paragraph">Azure NetApp Files 및 Azure VMware 솔루션은 동일한 Azure 지역에 있어야 합니다.</block>
  <block id="8c8b1c25fd4bcb4102a3a834f721ec3e" category="section-title">Azure NetApp Files 볼륨을 생성하고 마운트합니다</block>
  <block id="763b2af90e10e00124392e31d5792be5" category="paragraph">Azure NetApp Files 볼륨을 생성 및 마운트하려면 다음 단계를 수행하십시오.</block>
  <block id="e56fb44cec3cde26b63f919055458c3a" category="list-text">Azure 포털에 로그인하고 Azure NetApp Files에 액세스합니다. Azure NetApp Files 서비스에 대한 액세스를 확인하고 _az 공급자 레지스터--namespace Microsoft.NetApp –wait_명령을 사용하여 Azure NetApp Files 리소스 공급자를 등록합니다. 등록이 완료되면 NetApp 계정을 생성합니다.</block>
  <block id="792c2610bbb56b5803bae91a54f34f51" category="inline-link-macro">Azure NetApp Files 공유</block>
  <block id="a7ad1b2194256789e815facefa65206d" category="paragraph">자세한 단계는 을 참조하십시오 <block ref="8dd8f38a60f74263b1cf35e18285061e" category="inline-link-macro-rx"></block>. 이 페이지에서는 단계별 프로세스를 안내합니다.</block>
  <block id="710954ec785b2a7f67c2ef1c3f2f9d19" category="paragraph"><block ref="710954ec785b2a7f67c2ef1c3f2f9d19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe57bd1c78e967b463574e3089a42968" category="list-text">NetApp 계정을 생성한 후 필요한 서비스 수준과 크기로 용량 풀을 설정합니다.</block>
  <block id="3928a91ce2a9b26c809bec745d6b9daf" category="paragraph">자세한 내용은 을 참조하십시오 <block ref="e7281cc99a6c9a39d5a16325a46f1f7c" category="inline-link-macro-rx"></block>.</block>
  <block id="7ffd44a691267afdf7cc1178ab6115f8" category="paragraph"><block ref="7ffd44a691267afdf7cc1178ab6115f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="42e9b5ee697da49886fd18e89e6ab1af" category="inline-link-macro">Azure NetApp Files에 서브넷 위임</block>
  <block id="ee13d45546639cd210b35ce3665b6885" category="list-text">Azure NetApp Files에 대해 위임된 서브넷을 구성하고 볼륨을 생성하는 동안 이 서브넷을 지정합니다. 위임된 서브넷을 생성하는 자세한 단계는 을 참조하십시오 <block ref="ad52de6b143679c946d36f9e4248f40c" category="inline-link-macro-rx"></block>.</block>
  <block id="70a08a2f18d96817bf63302571e62634" category="paragraph"><block ref="70a08a2f18d96817bf63302571e62634" category="inline-image-macro-rx" type="image"></block></block>
  <block id="96501b128e8ffab4b107cd6ffa7da649" category="list-text">Capacity Pools 블레이드 아래의 Volumes 블레이드를 사용하여 SMB 볼륨을 추가합니다. SMB 볼륨을 생성하기 전에 Active Directory 커넥터가 구성되어 있는지 확인합니다.</block>
  <block id="f676bcdffa60a69ff49ba9ffdbb2b912" category="paragraph"><block ref="f676bcdffa60a69ff49ba9ffdbb2b912" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9095b4995e678294045e2a1501d1db3" category="list-text">검토 + 생성 을 클릭하여 SMB 볼륨을 생성합니다.</block>
  <block id="e48925dc65abf32faa19c5d430cf6d6d" category="paragraph">애플리케이션이 SQL Server인 경우 SMB의 지속적인 가용성을 설정합니다.</block>
  <block id="be1613efbff068fd23ee511fe4e6dc51" category="paragraph"><block ref="be1613efbff068fd23ee511fe4e6dc51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2b999c81e324f553ec9720c334325ee" category="paragraph"><block ref="b2b999c81e324f553ec9720c334325ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe5eed95829ff2b525461ee72a9f3f23" category="inline-link-macro">Azure NetApp Files에 대한 성능 고려 사항</block>
  <block id="2c5ce17dd48f2551465b828065fd8300" category="paragraph">크기 또는 할당량별 Azure NetApp Files 볼륨 성능에 대한 자세한 내용은 을 참조하십시오 <block ref="ffec162f488d413e68dfe18d328e177e" category="inline-link-macro-rx"></block>.</block>
  <block id="bef7cec065f33ededdd1b50d74800b72" category="list-text">연결이 완료되면 볼륨을 마운트하여 애플리케이션 데이터에 사용할 수 있습니다.</block>
  <block id="8b3c17098d0d024937d60849b3bd8edb" category="paragraph">이를 수행하려면 Azure 포털에서 볼륨 블레이드를 클릭한 다음 마운트할 볼륨을 선택하고 마운트 지침을 액세스합니다. 경로를 복사하고 Map Network Drive 옵션을 사용하여 Azure VMware Solution SDDC에서 실행되는 VM에 볼륨을 마운트합니다.</block>
  <block id="413fcfe1d831f95cd95f8f3bb9030eec" category="paragraph"><block ref="413fcfe1d831f95cd95f8f3bb9030eec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e50c675280580c3249f58f2f3eefdb86" category="paragraph"><block ref="e50c675280580c3249f58f2f3eefdb86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13c8bc9575bbdc3a8a30021320abbd69" category="list-text">Azure VMware Solution SDDC에서 실행되는 Linux VM에 NFS 볼륨을 마운트하려면 이 프로세스를 사용합니다. 볼륨 재구성 또는 동적 서비스 수준 기능을 사용하여 워크로드 요구 사항을 충족합니다.</block>
  <block id="ff817c6ff423e680ddf0a8398efdfb5a" category="paragraph"><block ref="ff817c6ff423e680ddf0a8398efdfb5a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da94ac228f6efdf07fe7e43b1441faf2" category="paragraph">자세한 내용은 을 참조하십시오 <block ref="ea07f7f3cbdf3d62072fbe16546616d3" category="inline-link-macro-rx"></block>.</block>
  <block id="1d583a1a8ff1ca8ae3360c7e33ecd984" category="section-title">Azure에 새로운 Cloud Volumes ONTAP 구축</block>
  <block id="ed1019c297fadb83e87437230788320c" category="paragraph">Cloud Volumes ONTAP 공유 및 LUN은 Azure VMware Solution SDDC 환경에서 생성된 VM에서 마운트할 수 있습니다. Cloud Volumes ONTAP는 iSCSI, SMB 및 NFS 프로토콜을 지원하므로 Linux 클라이언트와 Windows 클라이언트에도 볼륨을 마운트할 수 있습니다. Cloud Volumes ONTAP 볼륨은 몇 가지 간단한 단계를 통해 설정할 수 있습니다.</block>
  <block id="3b020916a45973167bc70cb4517bd8c8" category="inline-link-macro">시스템 간 데이터 복제 설정</block>
  <block id="e9cac40069a313b824541cda06c18a06" category="paragraph">재해 복구 또는 마이그레이션을 위해 사내 환경에서 클라우드로 볼륨을 복제하려면 사이트 간 VPN 또는 ExpressRoute를 사용하여 Azure에 대한 네트워크 연결을 설정합니다. 사내의 데이터를 Cloud Volumes ONTAP로 복제하는 작업은 이 문서의 범위를 벗어납니다. 사내 시스템과 Cloud Volumes ONTAP 시스템 간에 데이터를 복제하려면 을 참조하십시오 <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="9eb931a836eecf8e743b47b449c70bc5" category="inline-link-macro">Cloud Volumes ONTAP Sizer</block>
  <block id="165fc07e6910d8748be18ecaaab5392d" category="admonition">사용 <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Cloud Volumes ONTAP 인스턴스의 크기를 정확하게 지정합니다. 또한 Cloud Volumes ONTAP Sizer에서 입력으로 사용할 온프레미스 성능을 모니터링합니다.</block>
  <block id="a1d02afc571062ee1235156b645846f8" category="list-text">NetApp Cloud Central에 로그인 - 패브릭 보기 화면이 표시됩니다. Cloud Volumes ONTAP 탭을 찾아 Cloud Manager로 이동 을 선택합니다. 로그인하면 Canvas 화면이 표시됩니다.</block>
  <block id="1563f27024f7b2b0a96be687f878206d" category="paragraph"><block ref="1563f27024f7b2b0a96be687f878206d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f067fbf4a3196796318f7e878eaa2a3" category="list-text">Cloud Manager 홈 페이지에서 작업 환경 추가를 클릭한 다음 클라우드로 Microsoft Azure를 선택하고 시스템 구성의 유형을 선택합니다.</block>
  <block id="e59c8066b7736d6ede98e2b57d619b60" category="paragraph"><block ref="e59c8066b7736d6ede98e2b57d619b60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="21568dd1e2a5acafeee9d119cd012876" category="list-text">첫 번째 Cloud Volumes ONTAP 작업 환경을 생성할 때 Cloud Manager에서 커넥터를 배포하라는 메시지를 표시합니다.</block>
  <block id="4c3665ca095a8a103c69fac1ac46fb59" category="paragraph"><block ref="4c3665ca095a8a103c69fac1ac46fb59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54ae357a0d5e74ebab86e52641490fc0" category="list-text">커넥터가 생성되면 세부 정보 및 자격 증명 필드를 업데이트합니다.</block>
  <block id="9b971596a6ee599483fd04c84d2ce18d" category="paragraph"><block ref="9b971596a6ee599483fd04c84d2ce18d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf5341803b0061ef190495343f39fa02" category="list-text">환경 이름 및 관리자 자격 증명을 비롯하여 생성할 환경에 대한 세부 정보를 제공합니다. Azure 환경의 리소스 그룹 태그를 선택적 매개 변수로 추가합니다. 작업을 마친 후 계속 을 클릭합니다.</block>
  <block id="350a5c2219e5e14fd23dda8372344842" category="paragraph"><block ref="350a5c2219e5e14fd23dda8372344842" category="inline-image-macro-rx" type="image"></block></block>
  <block id="360a69a0b184770c2409949f2c7e1140" category="list-text">클라우드 데이터 감지, 클라우드 백업 및 Cloud Insights를 포함하여 Cloud Volumes ONTAP 구축을 위한 애드온 서비스를 선택하십시오. 서비스를 선택한 다음 계속 을 클릭합니다.</block>
  <block id="11728d9ffc9e6944adf4891d5543e154" category="paragraph"><block ref="11728d9ffc9e6944adf4891d5543e154" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ee060e03da823e605453fbfa27743d77" category="list-text">Azure 위치 및 연결을 구성합니다. 사용할 Azure 지역, 리소스 그룹, VNET 및 서브넷을 선택합니다.</block>
  <block id="4549d76a3daf0d322686b6d4f6fb1490" category="paragraph"><block ref="4549d76a3daf0d322686b6d4f6fb1490" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1c88093dde70f0165ade30b74c908ad" category="list-text">라이센스 옵션 선택: 사용한 만큼만 지불 또는 BYOL 방식으로 기존 라이센스 사용 이 예에서는 pay-as-you-go 옵션을 사용합니다.</block>
  <block id="10085b1c84507f0da366d741a248d728" category="paragraph"><block ref="10085b1c84507f0da366d741a248d728" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2c782d387cdd1de07d0119c2794edc8" category="list-text">다양한 유형의 워크로드에 사용할 수 있는 사전 구성된 여러 패키지 중 하나를 선택합니다.</block>
  <block id="942b902e3715b75e8e6257349bbe93ff" category="paragraph"><block ref="942b902e3715b75e8e6257349bbe93ff" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4c7055bfbaac9b0236d0bedccfb616d0" category="list-text">Azure 리소스의 활성화 및 할당과 관련된 두 가지 계약에 동의합니다. Cloud Volumes ONTAP 인스턴스를 만들려면 이동을 클릭합니다.</block>
  <block id="c19dadb8117ac0d88e543accbb1c1096" category="paragraph"><block ref="c19dadb8117ac0d88e543accbb1c1096" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b8217eede1f57c19d7d36c1501891b" category="list-text">Cloud Volumes ONTAP를 프로비저닝하면 Canvas 페이지의 작업 환경에 나열됩니다.</block>
  <block id="b6bb322a7578acfb8670b3ce8bc96fc9" category="paragraph"><block ref="b6bb322a7578acfb8670b3ce8bc96fc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="962c53cd54b0b3876e054c2fea4c4ff8" category="section-title">SMB 볼륨을 위한 추가 구성</block>
  <block id="9af22b589cfa398b9a704f786d96a90d" category="list-text">작업 환경이 준비되면 CIFS 서버가 적절한 DNS 및 Active Directory 구성 매개 변수로 구성되어 있는지 확인합니다. 이 단계는 SMB 볼륨을 생성하기 전에 필요합니다.</block>
  <block id="02cbbc24385dbe83fb42a1bd0c5668da" category="paragraph"><block ref="02cbbc24385dbe83fb42a1bd0c5668da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d923f79d8112841c7df8503e86f0af4a" category="list-text">SMB 볼륨을 생성하는 것은 쉬운 프로세스입니다. CVO 인스턴스를 선택하여 볼륨을 생성하고 Create Volume 옵션을 클릭합니다. 적절한 크기를 선택하고 클라우드 관리자가 포함하는 애그리게이트를 선택하거나, 고급 할당 메커니즘을 사용하여 특정 애그리게이트에 배치할 수 있습니다. 이 데모에서는 SMB가 프로토콜로 선택됩니다.</block>
  <block id="a74d409c32c4bc504768c6a7607fc409" category="paragraph"><block ref="a74d409c32c4bc504768c6a7607fc409" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e1a14aa082ec04534624b099e0a4bd9" category="list-text">볼륨 용량 할당 후 볼륨 창 아래에서 사용할 수 있습니다. CIFS 공유가 프로비저닝되므로 사용자 또는 그룹에 파일 및 폴더에 대한 권한을 제공하고 해당 사용자가 공유를 액세스하고 파일을 생성할 수 있는지 확인합니다. 파일 및 폴더 권한이 모두 SnapMirror 복제의 일부로 유지되므로 볼륨이 사내 환경에서 복제된 경우에는 이 단계가 필요하지 않습니다.</block>
  <block id="8923d310a6b50c677ed6f68410181b46" category="paragraph"><block ref="8923d310a6b50c677ed6f68410181b46" category="inline-image-macro-rx" type="image"></block></block>
  <block id="776a8d832701253eb40b056e68086fcd" category="list-text">볼륨을 생성한 후 mount 명령을 사용하여 Azure VMware Solution SDDC 호스트에서 실행 중인 VM에서 공유에 연결합니다.</block>
  <block id="70307f46aa9c37929516c971f3445caa" category="list-text">다음 경로를 복사하고 Map Network Drive 옵션을 사용하여 Azure VMware Solution SDDC에서 실행되는 VM에 볼륨을 마운트합니다.</block>
  <block id="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="paragraph"><block ref="3c58ffcc5a8ac9d8c78ea0f2d5e3ecb0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d1f50043685559ea05d7c21ae5a6d8a" category="paragraph"><block ref="1d1f50043685559ea05d7c21ae5a6d8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27c47ada1e7cb796a499ede048474b99" category="section-title">LUN을 호스트에 연결합니다</block>
  <block id="2e7b38e3108ed39835e616f3a8eef4d9" category="paragraph">LUN을 호스트에 연결하려면 다음 단계를 수행하십시오.</block>
  <block id="2fc81fae057994bbe703cb2892b727c9" category="list-text">Canvas 페이지에서 Cloud Volumes ONTAP 작업 환경을 두 번 클릭하여 볼륨을 생성하고 관리합니다.</block>
  <block id="3a596dcd3d3dd43ed187aea6bea5842e" category="list-text">볼륨 추가 &gt; 새 볼륨 을 클릭하고 iSCSI 를 선택한 다음 이니시에이터 그룹 생성 을 클릭합니다. 계속 을 클릭합니다.</block>
  <block id="06fcf6729491b5106094916e154fb565" category="paragraph"><block ref="06fcf6729491b5106094916e154fb565" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6297ccc26d99397b36875f005bb1b800" category="list-text">볼륨이 프로비저닝되면 볼륨을 선택한 다음 대상 IQN을 클릭합니다. IQN(iSCSI Qualified Name)을 복사하려면 Copy(복사)를 클릭합니다. 호스트에서 LUN으로의 iSCSI 접속을 설정합니다.</block>
  <block id="7af0094f03c81886be499600b8563647" category="paragraph">Azure VMware Solution SDDC에 있는 호스트에 대해 동일한 작업을 수행하려면 다음을 수행합니다.</block>
  <block id="640e587a72f6b61dc8d20a6de477db96" category="list-text">Azure VMware Solution SDDC에서 호스팅되는 VM에 대한 RDP</block>
  <block id="c4b994ff6c03cf45471392a32ff9809b" category="list-text">iSCSI 초기자 속성 대화 상자(서버 관리자 &gt; 대시보드 &gt; 도구 &gt; iSCSI 초기자)를 엽니다.</block>
  <block id="beacd9a0aebca77f6cc20d5cab0fb37c" category="list-text">검색 탭에서 포털 검색 또는 포털 추가 를 클릭한 다음 iSCSI 대상 포트의 IP 주소를 입력합니다.</block>
  <block id="c4ab0fc2a07f004fb45eacc91a07e22c" category="list-text">대상 탭에서 검색된 대상을 선택한 다음 로그온 또는 연결을 클릭합니다.</block>
  <block id="4f04cc11e470becd190503a4cea0e217" category="list-text">다중 경로 활성화 를 선택한 다음 컴퓨터가 시작될 때 이 연결 자동 복원 또는 즐겨찾기 대상 목록에 이 연결 추가 를 선택합니다. 고급 을 클릭합니다.</block>
  <block id="2d5b864b177738fa7a03f083ae03d2a3" category="paragraph">* 참고: * Windows 호스트에는 클러스터의 각 노드에 대한 iSCSI 연결이 있어야 합니다. 기본 DSM은 가장 적합한 경로를 선택합니다.</block>
  <block id="829bd9f13853ee7a86f5805c316df650" category="paragraph"><block ref="829bd9f13853ee7a86f5805c316df650" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f2340e83f93b283dd5fc7023e4e72a2" category="paragraph">SVM(스토리지 가상 머신)의 LUN은 Windows 호스트에 디스크로 표시됩니다. 추가된 새 디스크는 호스트에서 자동으로 검색되지 않습니다. 수동 재검색을 트리거하여 다음 단계를 수행하여 디스크를 검색합니다.</block>
  <block id="d16c566049378cf49448803dfc6ab25d" category="list-text">시작 &gt; 관리 도구 &gt; 컴퓨터 관리를 차례로 클릭하여 Windows 컴퓨터 관리 유틸리티를 엽니다.</block>
  <block id="b1babb2780a260f54d7e9f21602773df" category="list-text">탐색 트리에서 스토리지 노드를 확장합니다.</block>
  <block id="678149d88ae91abbb05c5df448a4e8af" category="list-text">디스크 관리를 클릭합니다.</block>
  <block id="35e2e6c4175353900be410088efcc1b9" category="list-text">작업 &gt; 디스크 다시 검사 를 클릭합니다.</block>
  <block id="d378c726809748df2090ec116c7232b4" category="paragraph"><block ref="d378c726809748df2090ec116c7232b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8a056111a10f9e055d309c54e7ca2bb" category="paragraph">Windows 호스트에서 새 LUN을 처음 액세스할 때 파티션이나 파일 시스템이 없습니다. LUN을 초기화하고 필요에 따라 다음 단계를 완료하여 파일 시스템으로 LUN을 포맷합니다.</block>
  <block id="8db13bd6122ee1a2b04931073cb808d7" category="list-text">Windows 디스크 관리를 시작합니다.</block>
  <block id="18e601e3f0e159e918f7adb9fd89fb99" category="list-text">LUN을 마우스 오른쪽 버튼으로 클릭한 다음 필요한 디스크 또는 파티션 유형을 선택합니다.</block>
  <block id="6b3a58a7b9961d5d214b65da735d2f89" category="list-text">마법사의 지침을 따릅니다. 이 예에서는 드라이브 E:가 마운트되었습니다</block>
  <block id="586f9ee0f7d5544a894ea05b9df312d7" category="paragraph"><block ref="586f9ee0f7d5544a894ea05b9df312d7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ff716a75c3423262418c90aad971f10" category="paragraph"><block ref="6ff716a75c3423262418c90aad971f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6120544c737d67dd31f47d101fe21a84" category="doc">클라우드 공급자에서 가상화 환경 구성</block>
  <block id="f4f7adb7cbe18f2cdd82be75a52b0417" category="paragraph">지원되는 각 하이퍼 스케일러에서 가상화 환경을 구성하는 방법에 대한 자세한 내용은 여기 를 참조하십시오.</block>
  <block id="00ce356ad004b72efc4b99389b52af63" category="paragraph">온프레미스와 마찬가지로 Azure VMware 솔루션 계획은 VM 및 마이그레이션을 생성할 수 있는 성공적인 프로덕션 준비 환경에 매우 중요합니다.</block>
  <block id="491aa8f554f95207a4b7d47f89777e13" category="paragraph">이 섹션에서는 Azure VMware 솔루션을 설정 및 관리하고 NetApp 스토리지를 연결하는 데 사용할 수 있는 옵션과 함께 사용하는 방법을 설명합니다.</block>
  <block id="3d24cd3e433bf1992e011c9f92c3fab6" category="inline-link-macro">리소스 공급자를 등록하고 프라이빗 클라우드를 생성합니다</block>
  <block id="a1123889b6465e93a2209c2a0ca667ef" category="inline-link-macro">새 또는 기존 ExpressRoute 가상 네트워크 게이트웨이에 연결합니다</block>
  <block id="ae1764c7cb70aed2d4548c424d7bf34a" category="inline-link-macro">네트워크 연결을 확인하고 프라이빗 클라우드에 액세스합니다</block>
  <block id="9883d049f97d69a9f2326d61585d8fbe" category="paragraph">온프레미스에서와 마찬가지로, VM 및 마이그레이션을 생성하기 위한 성공적인 프로덕션 준비 환경을 위해서는 Google Cloud VMware Engine(GCVE)을 계획하는 것이 매우 중요합니다.</block>
  <block id="6ad49d2b544134f2192d1612a572bdd6" category="paragraph">이 섹션에서는 GCVE를 설정 및 관리하고 NetApp 스토리지를 연결하는 데 사용할 수 있는 옵션과 함께 사용하는 방법을 설명합니다.</block>
  <block id="a74a86037d1564ce62843a1252f6ad37" category="admonition">게스트 내 저장소는 Cloud Volumes ONTAP 및 Cloud Volumes Services를 GCVE에 연결하는 유일한 지원 방법입니다.</block>
  <block id="11a31c6d83a723b3ea9c348c22e86238" category="inline-link-macro">GCVE 배포 및 구성</block>
  <block id="3e5cc29621d2619be0d7b1569da6909c" category="inline-link-macro">GCVE에 대한 개인 액세스를 활성화합니다</block>
  <block id="ae295ef15cb155f8a1af7d255e34298d" category="doc">AWS를 위한 NetApp 게스트 연결 스토리지 옵션</block>
  <block id="4a7272ea95323d5fef2e377b91b5f16d" category="inline-link-macro">FSX ONTAP를 게스트 연결 스토리지로 사용합니다</block>
  <block id="6e3fe132749fe21d23cf75f00317a6fe" category="section-title">AWS에서 VMware Cloud를 사용하여 NetApp ONTAP용 Amazon FSx를 구성합니다</block>
  <block id="5f19d821dc2e2e3a8e9418909df59733" category="paragraph">NetApp ONTAP용 Amazon FSx 파일 공유 및 LUN은 AWS의 VMware Cloud에서 VMware SDDC 환경 내에 생성된 VM에서 마운트할 수 있습니다. Linux 클라이언트에도 볼륨을 마운트하고 NFS 또는 SMB 프로토콜을 사용하여 Windows 클라이언트에 매핑할 수 있으며, iSCSI를 통해 마운트하면 Linux 또는 Windows 클라이언트에서 LUN에 블록 디바이스로 액세스할 수 있습니다. NetApp ONTAP 파일 시스템용 Amazon FSx는 다음 단계를 통해 빠르게 설정할 수 있습니다.</block>
  <block id="190b27040d3191ccf35bdb35221f0682" category="admonition">AWS 기반 NetApp ONTAP 및 VMware Cloud용 Amazon FSx는 더 나은 성능을 달성하고 가용성 영역 간의 데이터 전송 비용을 방지하려면 동일한 가용성 영역에 있어야 합니다.</block>
  <block id="f8caa19e45e4a42ea7bc10cad5d49ae8" category="section-title">ONTAP 볼륨용 Amazon FSx를 생성하고 마운트합니다</block>
  <block id="e765d7d83fde51af5391c87cc45dccf2" category="paragraph">NetApp ONTAP 파일 시스템용 Amazon FSx를 생성하고 마운트하려면 다음 단계를 완료하십시오.</block>
  <block id="43935f267f64b4ca1a3f1803272df64b" category="inline-link-macro">Amazon FSx 콘솔</block>
  <block id="4d33567207f0232b86c9bec4b4f38d45" category="list-text">를 엽니다 <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block> 파일 시스템 생성 마법사를 시작하려면 파일 시스템 생성 을 선택합니다.</block>
  <block id="df08dda7dc18ddb7de0e9ad5001a9f04" category="list-text">파일 시스템 유형 선택 페이지에서 NetApp ONTAP용 Amazon FSx 를 선택하고 다음 을 선택합니다. 파일 시스템 생성 페이지가 나타납니다.</block>
  <block id="c40ea60211b89b2179fe7a947527ff66" category="paragraph"><block ref="c40ea60211b89b2179fe7a947527ff66" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f29804f0e866cb47ba2fa233a71a54fd" category="list-text">네트워킹 섹션의 VPC(가상 프라이빗 클라우드)에서 경로 테이블과 함께 적절한 VPC 및 기본 서브넷을 선택합니다. 이 경우 드롭다운에서 vmcfsx2.vpc가 선택됩니다.</block>
  <block id="628892e49fa967795d4d8d3269c5bb31" category="paragraph"><block ref="628892e49fa967795d4d8d3269c5bb31" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf9c04e1d81f05e344db236ac47ea588" category="list-text">생성 방법의 경우 표준 작성을 선택합니다. 빠른 만들기를 선택할 수도 있지만 이 문서에서는 표준 만들기 옵션을 사용합니다.</block>
  <block id="e3c13c0fe612a941f86617c0ad730fca" category="paragraph"><block ref="e3c13c0fe612a941f86617c0ad730fca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e47c53bc440aebf2328e497b46953118" category="paragraph"><block ref="e47c53bc440aebf2328e497b46953118" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ed02b1594feb57e5c5c1ca0678086dd" category="list-text">보안 및 암호화 섹션의 암호화 키에 대해 파일 시스템의 유휴 데이터를 보호하는 AWS KMS(Key Management Service) 암호화 키를 선택합니다. 파일 시스템 관리 암호에 fsxadmin 사용자의 보안 암호를 입력합니다.</block>
  <block id="450514d9ec3a47df8e580605e80579b7" category="paragraph"><block ref="450514d9ec3a47df8e580605e80579b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b969656105cc9174e398fa5754382d5b" category="list-text">가상 시스템에서 REST API 또는 CLI를 사용하여 ONTAP를 관리하는 데 vsadmin과 함께 사용할 암호를 지정합니다. 암호를 지정하지 않으면 fsxadmin 사용자를 SVM 관리에 사용할 수 있습니다. Active Directory 섹션에서 Active Directory를 SVM에 가입하여 SMB 공유를 프로비저닝해야 합니다. 기본 스토리지 가상 머신 구성 섹션에서 이 검증에 사용할 스토리지의 이름을 제공합니다. SMB 공유는 자체 관리되는 Active Directory 도메인을 사용하여 프로비저닝됩니다.</block>
  <block id="0b0a8d3b6da586b1c3d7ace81f086743" category="paragraph"><block ref="0b0a8d3b6da586b1c3d7ace81f086743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89a8b582feabb26f60740f7b0a57aaef" category="list-text">기본 볼륨 구성 섹션에서 볼륨 이름 및 크기를 지정합니다. NFS 볼륨입니다. 스토리지 효율성의 경우 사용 을 선택하여 ONTAP 스토리지 효율성 기능(압축, 중복제거, 컴팩션)을 사용하도록 설정하거나 해제 를 선택하여 해제합니다.</block>
  <block id="2cfdc5814e94a8d05a802a6b639158b7" category="paragraph"><block ref="2cfdc5814e94a8d05a802a6b639158b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59ed30f46b9afae4f90b77ac3ed74f8e" category="list-text">파일 시스템 생성 페이지에 표시된 파일 시스템 구성을 검토합니다.</block>
  <block id="08ef5aaea85c8112d5d0e368443ee4fe" category="list-text">파일 시스템 생성 을 클릭합니다.</block>
  <block id="d385818e8551a5f93e9591daf3cf7c22" category="paragraph"><block ref="aae4a315cf943820b378b71447a7994a" category="inline-image-macro-rx" type="image"></block>
<block ref="e34db9249abae41534adba1bed16b8d1" category="inline-image-macro-rx" type="image"></block>
<block ref="f1c6728d54b85d98dd49bf5dc91e4f97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f5cc47067a5c4b536ab91f1a843de82" category="inline-link-macro">NetApp ONTAP용 Amazon FSx 시작하기</block>
  <block id="e37ec80b6a23f377fd957d8c83c7a7b5" category="paragraph">자세한 내용은 을 참조하십시오 <block ref="01eec31289b39ab7b89a00515912c371" category="inline-link-macro-rx"></block>.</block>
  <block id="af62c8c40f4b51eaee5cfbcfdb7bffaa" category="paragraph">위와 같이 파일 시스템을 생성한 후 필요한 크기와 프로토콜을 사용하여 볼륨을 생성합니다.</block>
  <block id="5eb9e90ab2c5435bcefd918c8c8a7304" category="list-text">를 엽니다 <block ref="1f394ea51c20c394ab649ff06aeff5a6" category="inline-link-macro-rx"></block>.</block>
  <block id="4cdc643691b84580850903954cdca1d1" category="list-text">왼쪽 탐색 창에서 파일 시스템 을 선택한 다음 볼륨을 생성할 ONTAP 파일 시스템을 선택합니다.</block>
  <block id="05c0eed2abbd9c20871b6af0eb7b1e38" category="list-text">Volumes 탭을 선택합니다.</block>
  <block id="511e546bcb3da3ea3db700200e857ebf" category="list-text">Create Volume 탭을 선택합니다.</block>
  <block id="328a4173ff8b40f0204a78c6a579b01e" category="list-text">볼륨 생성 대화 상자가 나타납니다.</block>
  <block id="b1734fefd5bf5fc9e481a277d683ca10" category="paragraph">이 섹션에서는 데모용으로 NFS 볼륨을 생성하여 AWS의 VMware 클라우드에서 실행되는 VM에 손쉽게 마운트할 수 있습니다. nfsdemovol01은 아래 그림과 같이 생성됩니다.</block>
  <block id="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="paragraph"><block ref="d32e1c6ca1d9fe2fb3ccb4d26dbc8a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72e172d843c1baf9acb881337f0bb2cc" category="section-title">Linux 클라이언트에 FSx ONTAP 볼륨을 마운트합니다</block>
  <block id="682dccf32ec3d6c1e1ca2548a43c4245" category="paragraph">이전 단계에서 생성한 FSx ONTAP 볼륨을 마운트합니다. AWS SDDC의 VMC 내에 있는 Linux VM에서 다음 단계를 완료합니다.</block>
  <block id="e059ff9407d5207f003eae103b4c7a3a" category="list-text">지정된 Linux 인스턴스에 연결합니다.</block>
  <block id="a8dc83c93fa2350d1419b44103864f2c" category="list-text">SSH(Secure Shell)를 사용하여 인스턴스의 터미널을 열고 적절한 자격 증명을 사용하여 로그인합니다.</block>
  <block id="454d9d1fe6ad680e393543d5e7b11669" category="list-text">다음 명령을 사용하여 볼륨의 마운트 지점에 대한 디렉토리를 만듭니다.</block>
  <block id="9e770ba792bd4db694940294a77cccee" category="list-text">NetApp ONTAP NFS 볼륨용 Amazon FSx를 이전 단계에서 생성한 디렉토리에 마운트합니다.</block>
  <block id="6631f82f4a955cf7fe5644adadf79e47" category="paragraph"><block ref="6631f82f4a955cf7fe5644adadf79e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2774f9046ee4873805e1f044fa12fe85" category="list-text">실행된 후 df 명령을 실행하여 마운트를 확인합니다.</block>
  <block id="d06051412d6da4495ca1a69429ea4fdf" category="paragraph"><block ref="d06051412d6da4495ca1a69429ea4fdf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0927b028b8b35cb7421cd2d29ebac0ab" category="section-title">Microsoft Windows 클라이언트에 FSx ONTAP 볼륨을 연결합니다</block>
  <block id="49a305dd021166bf8a508fb51b3fce24" category="paragraph">Amazon FSx 파일 시스템에서 파일 공유를 관리 및 매핑하려면 공유 폴더 GUI를 사용해야 합니다.</block>
  <block id="0f51d6ad9d95d24bf6d5b0e18d947382" category="list-text">시작 메뉴를 열고 관리자 권한으로 실행 을 사용하여 fsmgmt.msc 를 실행합니다. 이렇게 하면 공유 폴더 GUI 도구가 열립니다.</block>
  <block id="0186f9c0fa21b0c8ab82fadf036afe8f" category="list-text">작업 &gt; 모든 작업 을 클릭하고 다른 컴퓨터에 연결 을 선택합니다.</block>
  <block id="f5cf362d19da392bad46d1cb4bbea453" category="list-text">다른 컴퓨터의 경우 SVM(스토리지 가상 머신)의 DNS 이름을 입력합니다. 예를 들어, FSXSMBTESTING01.FSXTESTING.LOCAL이 이 예제에서 사용됩니다.</block>
  <block id="882da317003fa80717e3939e41c5aa32" category="admonition">TP는 Amazon FSx 콘솔에서 SVM의 DNS 이름을 찾아 Storage Virtual Machines를 선택하고 SVM을 선택한 다음 Endpoints로 스크롤하여 SMB DNS 이름을 찾습니다. 확인 을 클릭합니다. 공유 폴더 목록에 Amazon FSx 파일 시스템이 나타납니다.</block>
  <block id="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="paragraph"><block ref="24cfe5fb05f6bd3b267a7e2d46a1cc44" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd517d0d40877562e2dae460910a5260" category="list-text">공유 폴더 도구의 왼쪽 창에서 공유 를 선택하여 Amazon FSx 파일 시스템에 대한 활성 공유를 표시합니다.</block>
  <block id="e4fb530e581118e4aa66166f33242547" category="paragraph"><block ref="e4fb530e581118e4aa66166f33242547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b994a2e22edf9cb0de792e6a494da514" category="list-text">이제 새 공유를 선택하고 공유 폴더 생성 마법사를 완료합니다.</block>
  <block id="9630a309cdca9ed17b688fe15c03a200" category="paragraph"><block ref="f821d910b54d4df166bfb6c9a0fbeac1" category="inline-image-macro-rx" type="image"></block>
<block ref="1456921fb33e6c835f2ea077607c478a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed3796b20dc1d1a4f1756d0cb0f45489" category="inline-link-macro">SMB 공유 생성</block>
  <block id="dc77f3b6074a456c2be3f16b862db081" category="paragraph">Amazon FSx 파일 시스템에서 SMB 공유를 생성 및 관리하는 방법에 대한 자세한 내용은 를 참조하십시오 <block ref="a85495f11ff3e696252abf798d30d57d" category="inline-link-macro-rx"></block>.</block>
  <block id="470140537c670eb8edb32bf6e8b2bad5" category="list-text">접속이 완료되면 SMB 공유를 연결하고 애플리케이션 데이터에 사용할 수 있습니다. 이 작업을 수행하려면 공유 경로를 복사하고 네트워크 드라이브 매핑 옵션을 사용하여 AWS SDDC의 VMware Cloud에서 실행되는 VM에 볼륨을 마운트합니다.</block>
  <block id="0542af5401c04588abf9b665f31829b6" category="paragraph"><block ref="0542af5401c04588abf9b665f31829b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6c5856c2845517bb6408529fb90b57e" category="section-title">NetApp ONTAP LUN용 FSx를 iSCSI를 사용하여 호스트에 연결합니다</block>
  <block id="716fd43b3bc7735b075d056d4ac18dc4" category="paragraph">FSx의 iSCSI 트래픽은 이전 섹션에 제공된 경로를 통해 VMware Transit Connect/AWS Transit Gateway를 통과합니다. NetApp ONTAP용 Amazon FSx에서 LUN을 구성하려면 찾은 문서를 따르십시오 <block ref="70da71f7286decf7407c5db884b5344a" category="inline-link-macro-rx"></block>.</block>
  <block id="32139f76f200f13f9078d49f80c95815" category="paragraph">Linux 클라이언트에서 iSCSI 데몬이 실행되고 있는지 확인합니다. LUN을 프로비저닝한 후 Ubuntu를 사용한 iSCSI 구성에 대한 자세한 지침을 참조하십시오(예:). <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>.</block>
  <block id="102b54837bec429c2bc9f3f9fee8a857" category="paragraph">이 문서에서는 iSCSI LUN을 Windows 호스트에 연결하는 방법을 설명합니다.</block>
  <block id="29980d065df6792c6cf2015646e8744d" category="section-title">NetApp ONTAP용 FSx에서 LUN 프로비저닝:</block>
  <block id="6da38655de350d44c878e17adb0fd12c" category="list-text">ONTAP 파일 시스템용 FSx의 관리 포트를 사용하여 NetApp ONTAP CLI에 액세스합니다.</block>
  <block id="6f8dec9d607d68b3712504d90548dc7f" category="list-text">사이징 출력에 표시된 대로 필요한 크기의 LUN을 생성합니다.</block>
  <block id="c31d63ac510efc7c433e07d70ef0a11a" category="paragraph">이 예에서는 5G 크기의 LUN(5368709120)을 생성했습니다.</block>
  <block id="e3de6fee1eaf0d0777dc125d42255a4b" category="list-text">특정 LUN에 액세스할 수 있는 호스트를 제어하는 데 필요한 igroup을 생성합니다.</block>
  <block id="8c92602adf53776d90c46162f150dd3c" category="paragraph">두 개의 항목이 표시되었습니다.</block>
  <block id="e71def0bc16c2989d418764ced77c368" category="list-text">다음 명령을 사용하여 LUN을 igroup에 매핑합니다.</block>
  <block id="fd29357379ec9a1916e7512ba9cba2d5" category="list-text">새로 프로비저닝된 LUN을 Windows VM에 연결합니다.</block>
  <block id="15bea41b01d7287439a04eb0c57a5ef5" category="paragraph">새 LUN을 AWS SDDC의 VMware 클라우드에 있는 Windows 호스트에 연결하려면 다음 단계를 수행하십시오.</block>
  <block id="eabaddae6242a6352bd11a6bdf29b55a" category="list-text">AWS SDDC 기반 VMware 클라우드에서 호스팅되는 Windows VM에 대한 RDP</block>
  <block id="debd85c1c5da22a2c5e207ae0ad4b91a" category="list-text">Server Manager &gt; Dashboard &gt; Tools &gt; iSCSI Initiator로 이동하여 iSCSI Initiator Properties 대화 상자를 엽니다.</block>
  <block id="213e827694caf7236290f845284dcc05" category="list-text">대상 탭에서 검색된 대상을 선택한 다음 로그온 또는 연결을 클릭합니다.</block>
  <block id="43237019bec64292757878b08a9d1a63" category="list-text">다중 경로 사용을 선택한 다음 “컴퓨터를 시작할 때 이 연결 자동 복원” 또는 “즐겨찾는 대상 목록에 이 연결 추가”를 선택합니다. 고급 을 클릭합니다.</block>
  <block id="ed010f49a5a1ad0895131daffcd73a3c" category="admonition">Windows 호스트에는 클러스터의 각 노드에 대한 iSCSI 연결이 있어야 합니다. 기본 DSM은 가장 적합한 경로를 선택합니다.</block>
  <block id="6aa775ce454f9bfcd13c7e20b90531e7" category="paragraph"><block ref="6aa775ce454f9bfcd13c7e20b90531e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc2a4ed37392086accdd3db98b75509" category="paragraph">SVM(스토리지 가상 머신)의 LUN은 Windows 호스트에 디스크로 표시됩니다. 추가된 새 디스크는 호스트에서 자동으로 검색되지 않습니다. 수동 재검색을 트리거하여 다음 단계를 수행하여 디스크를 검색합니다.</block>
  <block id="3ba2e4c8502f30b8e6d44fc88ebe784a" category="paragraph"><block ref="3ba2e4c8502f30b8e6d44fc88ebe784a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="405bdc4379d9776fbda741356a79c543" category="paragraph">Windows 호스트에서 새 LUN을 처음 액세스할 때 파티션이나 파일 시스템이 없습니다. LUN을 초기화하고 필요에 따라 다음 단계를 완료하여 파일 시스템으로 LUN을 포맷합니다.</block>
  <block id="605158a22ab35f7223fe6f37b0f761b7" category="list-text">마법사의 지침을 따릅니다. 이 예에서는 드라이브 F:가 마운트되었습니다.</block>
  <block id="848c01bbaad78639e22ba05626884091" category="paragraph"><block ref="848c01bbaad78639e22ba05626884091" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4859596b2360db2dac4c6a687efe10d2" category="section-title">AWS에 새로운 Cloud Volumes ONTAP 인스턴스 구축(직접 구현)</block>
  <block id="ddf355809a57f794eb4f9cff41a1ad86" category="paragraph">Cloud Volumes ONTAP 공유 및 LUN은 AWS SDDC 환경의 VMware 클라우드에서 생성된 VM에서 마운트할 수 있습니다. 또한 볼륨은 네이티브 AWS VM Linux Windows 클라이언트에 마운트할 수 있으며, Cloud Volumes ONTAP는 iSCSI, SMB 및 NFS 프로토콜을 지원하므로 iSCSI를 통해 마운트할 때 Linux 또는 Windows 클라이언트에서 LUN에 블록 디바이스로 액세스할 수 있습니다. Cloud Volumes ONTAP 볼륨은 몇 가지 간단한 단계를 통해 설정할 수 있습니다.</block>
  <block id="091112e3dbffea1fef77b4b6bbcec4d3" category="paragraph">재해 복구 또는 마이그레이션을 위해 사내 환경에서 클라우드로 볼륨을 복제하려면 사이트 간 VPN 또는 DirectConnect를 사용하여 AWS에 대한 네트워크 연결을 설정합니다. 사내의 데이터를 Cloud Volumes ONTAP로 복제하는 작업은 이 문서의 범위를 벗어납니다. 사내 시스템과 Cloud Volumes ONTAP 시스템 간에 데이터를 복제하려면 을 참조하십시오 <block ref="79828109910805ccc09752d766afaae3" category="inline-link-macro-rx"></block>.</block>
  <block id="c4fab68ae07564acd6ecd9b911dfff79" category="admonition">를 사용합니다 <block ref="c41f5eb5365f7790c86bbe0d764bfcac" category="inline-link-macro-rx"></block> Cloud Volumes ONTAP 인스턴스의 크기를 정확하게 지정합니다. 또한, Cloud Volumes ONTAP Sizer에서 입력으로 사용할 온프레미스 성능을 모니터링합니다.</block>
  <block id="44ca838e7d04a1071dc78602ef005cb3" category="list-text">NetApp Cloud Central에 로그인하면 Fabric View 화면이 표시됩니다. Cloud Volumes ONTAP 탭을 찾아 Cloud Manager로 이동 을 선택합니다. 로그인하면 Canvas 화면이 표시됩니다.</block>
  <block id="6b0e3e8cb8d190a2310f526f49f7908f" category="paragraph"><block ref="6b0e3e8cb8d190a2310f526f49f7908f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="613b8a42b8ee051cdae0288a52604a55" category="list-text">Cloud Manager 홈 페이지에서 작업 환경 추가를 클릭한 다음 AWS를 클라우드로 선택하고 시스템 구성의 유형을 선택합니다.</block>
  <block id="1ce9ef4a253b6301539d9cab4fca67b6" category="paragraph"><block ref="1ce9ef4a253b6301539d9cab4fca67b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d1552a04c8237c4a2d938cca2db53683" category="list-text">환경 이름 및 관리자 자격 증명을 비롯하여 생성할 환경에 대한 세부 정보를 제공합니다. 계속 을 클릭합니다.</block>
  <block id="525c0dbff313821edbeaa46a9b5d88dd" category="paragraph"><block ref="525c0dbff313821edbeaa46a9b5d88dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fdbae44a4deac52e923aa6480a3f1f2" category="list-text">클라우드 데이터 감지, 클라우드 백업 및 Cloud Insights를 포함하여 Cloud Volumes ONTAP 구축을 위한 애드온 서비스를 선택하십시오. 계속 을 클릭합니다.</block>
  <block id="7191330ca38db1397356e7619c4baf63" category="paragraph"><block ref="7191330ca38db1397356e7619c4baf63" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5908a77615c1d6294f872ff6f0e9ec5c" category="list-text">HA 배포 모델 페이지에서 여러 가용성 영역 구성을 선택합니다.</block>
  <block id="e2dff93e99a18f3bbf601965a86556d3" category="paragraph"><block ref="e2dff93e99a18f3bbf601965a86556d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5eee77262911549d8a2fd262ee2a983d" category="list-text">지역 및 VPC 페이지에서 네트워크 정보를 입력한 다음 계속 을 클릭합니다.</block>
  <block id="94a6592c275cad51dc739b4ab70338db" category="paragraph"><block ref="94a6592c275cad51dc739b4ab70338db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6f20610782706f69940c617f7154ffe" category="list-text">연결 및 SSH 인증 페이지에서 HA 쌍의 연결 방법과 중재자를 선택합니다.</block>
  <block id="d121b588f00dfd906d6291024c708f8d" category="paragraph"><block ref="d121b588f00dfd906d6291024c708f8d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a012735965bc67df3b6e4c64b7b894f" category="list-text">부동 IP 주소를 지정하고 계속 을 클릭합니다.</block>
  <block id="bc0e2f9513cce33557343a1867d4bdfb" category="paragraph"><block ref="bc0e2f9513cce33557343a1867d4bdfb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b2221e159f51173ae2b52e02587cc42" category="list-text">부동 IP 주소에 대한 라우트를 포함할 적절한 라우트 테이블을 선택한 다음 계속 을 클릭합니다.</block>
  <block id="5486a792746fe5fbf546c327f6be2773" category="paragraph"><block ref="5486a792746fe5fbf546c327f6be2773" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e18f42f3f9ea4d4f2e8df33f334d9939" category="list-text">데이터 암호화 페이지에서 AWS 관리 암호화 를 선택합니다.</block>
  <block id="143c5081e907e69e16f1df952eafae3e" category="paragraph"><block ref="143c5081e907e69e16f1df952eafae3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a25e3ac90ce2b5cc921531efdc5963e" category="list-text">라이센스 옵션 선택: 사용한 만큼만 지불 또는 BYOL 방식으로 기존 라이센스 사용 이 예에서는 pay-as-you-go 옵션을 사용합니다.</block>
  <block id="e3750564d3942e5c1d3cec322e411d5e" category="paragraph"><block ref="e3750564d3942e5c1d3cec322e411d5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df531dd5efab87543ed07d56595eca08" category="list-text">AWS SDDC 기반 VMware 클라우드에서 실행되는 VM에 구축할 워크로드 유형을 기반으로 사용할 수 있는 사전 구성된 패키지 몇 개 중 하나를 선택합니다.</block>
  <block id="30e80bd4d8d23ac64059627389a8b348" category="paragraph"><block ref="30e80bd4d8d23ac64059627389a8b348" category="inline-image-macro-rx" type="image"></block></block>
  <block id="623ce055c6e7272198e998744efd8deb" category="list-text">검토 및 승인 페이지에서 선택 항목을 검토하고 확인합니다. Cloud Volumes ONTAP 인스턴스를 만들려면 이동을 클릭합니다.</block>
  <block id="ce4ab7c38fc244e8d1e30dd47a1c578d" category="paragraph"><block ref="ce4ab7c38fc244e8d1e30dd47a1c578d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc498db1b5b048e74d02bcfa90076dfe" category="paragraph"><block ref="bc498db1b5b048e74d02bcfa90076dfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8427c8fe11e3a00ca10a2cf45a96dd90" category="paragraph"><block ref="8427c8fe11e3a00ca10a2cf45a96dd90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="31574a22471145d2a1ea069062aa95ec" category="list-text">CVO 인스턴스를 선택하여 볼륨을 생성하고 Create Volume 옵션을 클릭합니다. 적절한 크기를 선택하고 클라우드 관리자가 포함하는 애그리게이트를 선택하거나, 고급 할당 메커니즘을 사용하여 특정 애그리게이트에 배치할 수 있습니다. 이 데모에서는 SMB가 프로토콜로 선택됩니다.</block>
  <block id="d657856abbf9bb39436a3f6f849251ea" category="paragraph"><block ref="d657856abbf9bb39436a3f6f849251ea" category="inline-image-macro-rx" type="image"></block></block>
  <block id="976543d01a4b5d38482c487005aadc68" category="list-text">볼륨 용량 할당 후 볼륨 창 아래에서 사용할 수 있습니다. CIFS 공유가 프로비저닝되므로 사용자나 그룹에 파일 및 폴더에 대한 권한을 제공하고 해당 사용자가 공유를 액세스하고 파일을 생성할 수 있는지 확인해야 합니다.</block>
  <block id="eac2d4365044c30420d99e4450f5b3da" category="paragraph"><block ref="eac2d4365044c30420d99e4450f5b3da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ea4081e5d5395a0dd61744757f9abb9" category="list-text">볼륨을 생성한 후 mount 명령을 사용하여 AWS SDDC 호스트의 VMware Cloud에서 실행되는 VM에서 공유에 접속합니다.</block>
  <block id="7786302dcdbb8e27839c1d68acb8c3ba" category="list-text">다음 경로를 복사하고 Map Network Drive 옵션을 사용하여 AWS SDDC의 VMware Cloud에서 실행되는 VM에 볼륨을 마운트합니다.</block>
  <block id="fff9636198d4c8106d5edeb1a72f789c" category="paragraph"><block ref="97606ae260ebd0d0acdf4aac70a2a0b5" category="inline-image-macro-rx" type="image"></block>
<block ref="b4382417b1dd50929cfd78b7e90bc2aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70ac69b194f074f8b2ce79ee769a0c96" category="paragraph">Cloud Volumes ONTAP LUN을 호스트에 연결하려면 다음 단계를 수행하십시오.</block>
  <block id="4a8c2e183609aa00cfce8401be26e193" category="list-text">Cloud Manager Canvas 페이지에서 Cloud Volumes ONTAP 작업 환경을 두 번 클릭하여 볼륨을 생성하고 관리합니다.</block>
  <block id="298c5ecf2fc7c7ab04d3ff27df17c420" category="list-text">볼륨 추가 &gt; 새 볼륨 을 클릭하고 iSCSI 를 선택한 다음 이니시에이터 그룹 생성 을 클릭합니다. 계속 을 클릭합니다.</block>
  <block id="a3f6544e066d08b352bdd873e84efd9f" category="paragraph"><block ref="d08d8d37d464a0090209067a27ccf9bf" category="inline-image-macro-rx" type="image"></block>
<block ref="dd9a8ac9d2dee64126f68f4ab9b10f3f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a9ec38aba893e2a0d701ba2f45a50e" category="paragraph">AWS SDDC의 VMware Cloud에 있는 호스트에 대해 동일한 작업을 수행하려면 다음 단계를 수행하십시오.</block>
  <block id="2cbe60394fdca23a31c3a05a49aba035" category="list-text">RDP를 AWS의 VMware 클라우드에서 호스팅되는 VM에 대한 것입니다.</block>
  <block id="04d63507299c2b866ddad09b32b37fb3" category="list-text">다중 경로 사용 을 선택한 다음 컴퓨터가 시작될 때 이 연결 자동 복원 또는 즐겨찾기 대상 목록에 이 연결 추가 를 선택합니다. 고급 을 클릭합니다.</block>
  <block id="15c42f0d55e1a75b7606d8cd1d0f0840" category="paragraph">를 누릅니다<block ref="f87da6f2c46cbdbedc31faf67374f8f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11f54f9bd2797dc115ca9e98fb0116d" category="paragraph">SVM의 LUN은 Windows 호스트에 디스크로 표시됩니다. 추가된 새 디스크는 호스트에서 자동으로 검색되지 않습니다. 수동 재검색을 트리거하여 다음 단계를 수행하여 디스크를 검색합니다.</block>
  <block id="733dc90ee8ecde5a3fe64fd837d0eec1" category="paragraph"><block ref="733dc90ee8ecde5a3fe64fd837d0eec1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b173d8aceed1850c1882fee5f7479d4" category="paragraph"><block ref="5b173d8aceed1850c1882fee5f7479d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1085f8441673a34397360c417066d18f" category="paragraph">Linux 클라이언트에서 iSCSI 데몬이 실행되고 있는지 확인합니다. LUN을 프로비저닝한 후에는 Linux 배포용 iSCSI 구성에 대한 자세한 지침을 참조하십시오. 예를 들어 Ubuntu iSCSI 구성을 찾을 수 있습니다 <block ref="6e395450a47e52243c1b6632fa351858" category="inline-link-macro-rx"></block>. 확인하려면 셸에서 lsblk cmd 를 실행합니다.</block>
  <block id="7b88883556cc41d9ed2a47bd0cfe1bb4" category="section-title">Linux 클라이언트에 Cloud Volumes ONTAP NFS 볼륨을 마운트합니다</block>
  <block id="af16b968e0e3b3975cdcefb5cdd9858a" category="paragraph">AWS SDDC의 VMC 내에서 DIY(Cloud Volumes ONTAP) 파일 시스템을 VM에서 마운트하려면 다음 단계를 수행하십시오.</block>
  <block id="b3bcde31f03d76e154f81e6b5221b007" category="list-text">SSH(Secure Shell)를 사용하여 인스턴스의 터미널을 열고 적절한 자격 증명을 사용하여 로그인합니다.</block>
  <block id="42d35ecc4606c7783372ab3953fb10d6" category="list-text">다음 명령을 사용하여 볼륨의 마운트 지점에 대한 디렉토리를 만듭니다.</block>
  <block id="2b9f5ac2397a7a0e82ca568de7f62512" category="paragraph"><block ref="c1b4b180fa34b46779c12a4e278fa487" category="inline-image-macro-rx" type="image"></block>
<block ref="cf487bf9f5a361811181e443893feb53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ade1814101b0113034e0f446307b3db3" category="doc">Google Cloud Platform GCVE를 위한 NetApp의 기능</block>
  <block id="addac5e706b2148d9c7b3bbe2d2fcdde" category="paragraph">다음 옵션 중 하나를 선택하여 원하는 콘텐츠의 섹션으로 이동합니다.</block>
  <block id="06262015df4851b380189212274a0e3e" category="inline-link-macro">하이퍼스케일 구성의 VMware</block>
  <block id="7f08237a127b62af444f720f15216cee" category="list-text"><block ref="7f08237a127b62af444f720f15216cee" category="inline-link-macro-rx"></block></block>
  <block id="c774c23e9a97e08bfa096f1cbf18cc17" category="inline-link-macro">NetApp 스토리지 옵션</block>
  <block id="d3fc27ff58dc3a0d839a16af858e7999" category="list-text"><block ref="d3fc27ff58dc3a0d839a16af858e7999" category="inline-link-macro-rx"></block></block>
  <block id="833413440fbbe13837d8b58256cfba65" category="paragraph">온프레미스에서와 마찬가지로 클라우드 기반 가상화 환경을 계획하는 것은 VM 및 마이그레이션을 생성할 수 있는 성공적인 프로덕션 준비 환경에 매우 중요합니다.</block>
  <block id="6eb516b97eae0ab93b8d6aab35fbb764" category="section-title">GCVE용 NetApp 스토리지 옵션</block>
  <block id="94772ee4b241fe0706c3aaef6e3a4505" category="inline-link-macro">지원되는 NetApp 스토리지 옵션</block>
  <block id="67b586cdf9703ba67abe711415768cc0" category="paragraph">를 방문하십시오 <block ref="01a9bd21bfc714c8dec8aabc5b88eda7" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="8f08ff97ca555f50f0d05fdf950a0568" category="paragraph">Google Cloud는 다음과 같은 구성에서 NetApp 스토리지를 지원합니다.</block>
  <block id="9bb210767ccb9c085c816c82f3b6b1cb" category="inline-link-macro">CVS(Cloud Volumes Service)를 게스트 연결 스토리지로 사용합니다</block>
  <block id="5e1c36a2c24e0aaf7844ec890c15e430" category="paragraph">주요 하이퍼 스케일러에서 NetApp 스토리지 지원 조합을 이해합니다.</block>
  <block id="382b0f5185773fa0f67a8ed8056c7759" category="cell">해당 없음</block>
  <block id="a7714bc43e9a27f2c98a38e6b6d7f3d8" category="doc">퍼블릭 클라우드 공급자를 위한 NetApp 스토리지 옵션</block>
  <block id="8db50e5729f7a5d770aaceef947a2982" category="paragraph">세 가지 주요 하이퍼 스케일러의 스토리지로서의 NetApp 옵션에 대해 알아보십시오.</block>
  <block id="60ce80493de8468bdfd597af1c219a9f" category="paragraph">AWS는 다음과 같은 구성에서 NetApp 스토리지를 지원합니다.</block>
  <block id="74eb4c6138d4b8cd8399b01966c5af28" category="section-title">GCP용 NetApp 스토리지 옵션</block>
  <block id="4177c39712dda5976b0ba657b24af234" category="section-title">Google Cloud에 Cloud Volumes ONTAP 배포(직접 수행)</block>
  <block id="2839d8571363b149cc3fd9db82a7183d" category="paragraph">Cloud Volumes ONTAP 공유 및 LUN은 GCVE 프라이빗 클라우드 환경에서 생성된 VM에서 마운트할 수 있습니다. Cloud Volumes ONTAP는 iSCSI, SMB 및 NFS 프로토콜을 지원하기 때문에 iSCSI를 통해 마운트할 때 Linux 또는 Windows 클라이언트에서 볼륨을 Linux 클라이언트 및 Windows 클라이언트에 블록 디바이스로 마운트할 수 있습니다. Cloud Volumes ONTAP 볼륨은 몇 가지 간단한 단계를 통해 설정할 수 있습니다.</block>
  <block id="83f1904115d07e05de148ff5c69277db" category="paragraph">재해 복구 또는 마이그레이션을 위해 사내 환경에서 클라우드로 볼륨을 복제하려면 사이트 간 VPN 또는 Cloud Interconnect를 사용하여 Google Cloud에 대한 네트워크 연결을 설정합니다. 사내의 데이터를 Cloud Volumes ONTAP로 복제하는 작업은 이 문서의 범위를 벗어납니다. 사내 시스템과 Cloud Volumes ONTAP 시스템 간에 데이터를 복제하려면 을 참조하십시오 <block ref="17b5522e2d467cfa8e1eed2f77bb1eff" category="inline-link-macro-rx"></block>.</block>
  <block id="52111b7d24cc23248fa9cf8138732943" category="paragraph"><block ref="52111b7d24cc23248fa9cf8138732943" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67b4a468763f61993484edb54b0d5eaa" category="list-text">Cloud Manager Canvas 탭에서 작업 환경 추가를 클릭한 다음 Google Cloud Platform을 클라우드로 선택하고 시스템 구성 유형을 선택합니다. 다음 을 클릭합니다.</block>
  <block id="da94c5003e26421e5282adb2dc7794bf" category="paragraph"><block ref="da94c5003e26421e5282adb2dc7794bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="956a76d4c71f02e39d36ada071ba66ca" category="list-text">환경 이름 및 관리자 자격 증명을 비롯하여 생성할 환경에 대한 세부 정보를 제공합니다. 작업을 마친 후 계속 을 클릭합니다.</block>
  <block id="786bd072b9aad97a5bb9b71b8988a176" category="paragraph"><block ref="786bd072b9aad97a5bb9b71b8988a176" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f716cee2acaef077786ecfa7a3f8bfe7" category="list-text">데이터 감지 및 규정 준수, 클라우드 백업 등 Cloud Volumes ONTAP 구축을 위한 추가 서비스 를 선택하거나 선택 취소합니다. 그런 다음 계속 을 클릭합니다.</block>
  <block id="03e0c2afea8f7c3aff4a53d66784f843" category="paragraph">힌트: 추가 서비스를 비활성화할 때 확인 팝업 메시지가 표시됩니다. 추가 서비스는 CVO 배포 후 추가/제거할 수 있습니다. 비용을 피하기 위해 처음부터 필요하지 않은 경우 선택을 취소하십시오.</block>
  <block id="d784fbb10e1bdb60322e86126fe6b77a" category="paragraph"><block ref="d784fbb10e1bdb60322e86126fe6b77a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faa5bffdcdb67efcb08e91a60de40950" category="list-text">위치를 선택하고 방화벽 정책을 선택한 다음 확인란을 선택하여 Google Cloud 스토리지에 대한 네트워크 연결을 확인합니다.</block>
  <block id="5eb45a43e8f46d401f435ef2b77fc946" category="paragraph"><block ref="5eb45a43e8f46d401f435ef2b77fc946" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f73472fc9b5e80548aa8910eb7b409d7" category="list-text">라이센스 옵션 선택: 사용한 만큼만 지불 또는 BYOL 방식으로 기존 라이센스 사용 이 예제에서는 Freemium 옵션을 사용합니다. 그런 다음 계속 을 클릭합니다.</block>
  <block id="ef8c5ea172d5c008d091f693a2a4b4bd" category="paragraph"><block ref="ef8c5ea172d5c008d091f693a2a4b4bd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e3f0304199574fcad7150c8cbc80cf" category="list-text">AWS SDDC 기반 VMware 클라우드에서 실행되는 VM에 구축할 워크로드의 유형에 따라 사용할 수 있는 사전 구성된 패키지 몇 개 중 하나를 선택합니다.</block>
  <block id="1cd93d1b6baa56bdec898225ef3fea89" category="paragraph">힌트: 타일 위로 마우스를 가져가 세부 정보를 보거나 구성 변경 을 클릭하여 CVO 구성 요소 및 ONTAP 버전을 사용자 지정합니다.</block>
  <block id="7498ab388fb0a7938d43af30f32657b5" category="paragraph"><block ref="7498ab388fb0a7938d43af30f32657b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcf4e1533222260897c2613078eae18e" category="paragraph"><block ref="fcf4e1533222260897c2613078eae18e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37030c826a75013cff1396c6351d33c0" category="paragraph"><block ref="37030c826a75013cff1396c6351d33c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f10b252acc74e058dc00a78e8c33250" category="paragraph">힌트: 메뉴 아이콘( º)을 클릭하고 고급을 선택하여 더 많은 옵션을 표시하고 CIFS 설정을 선택합니다.</block>
  <block id="0cd857f422db3bb835695ca4400e7afb" category="paragraph"><block ref="0cd857f422db3bb835695ca4400e7afb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c2efcf3ec5fbe68c5a418d6b0d5ed94" category="list-text">SMB 볼륨을 생성하는 것은 쉬운 프로세스입니다. Canvas에서 Cloud Volumes ONTAP 작업 환경을 두 번 클릭하여 볼륨을 생성 및 관리하고 볼륨 생성 옵션을 클릭합니다. 적절한 크기를 선택하고 클라우드 관리자가 포함하는 애그리게이트를 선택하거나, 고급 할당 메커니즘을 사용하여 특정 애그리게이트에 배치할 수 있습니다. 이 데모에서는 CIFS/SMB가 프로토콜로 선택됩니다.</block>
  <block id="597899b3d186b1c50739aeb0a82a2094" category="paragraph"><block ref="597899b3d186b1c50739aeb0a82a2094" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cdd5a747f01838b94117ef6fb699278" category="paragraph">힌트: 볼륨 메뉴(º)를 클릭하여 옵션을 표시합니다.</block>
  <block id="368cd84bdda136cebde14eea38e8a0f2" category="paragraph"><block ref="368cd84bdda136cebde14eea38e8a0f2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f7a0ccac4888fc1553dadeee03d7e99" category="list-text">볼륨을 생성한 후 mount 명령을 사용하여 볼륨 연결 지침을 표시한 다음 Google Cloud VMware Engine의 VM에서 공유에 연결합니다.</block>
  <block id="92890420fd7a7668e3b04db90e8a2ff2" category="paragraph"><block ref="92890420fd7a7668e3b04db90e8a2ff2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5ee926d870d7b6e5ee68e0001a9db42" category="list-text">다음 경로를 복사하고 네트워크 드라이브 매핑 옵션을 사용하여 Google Cloud VMware Engine에서 실행 중인 VM에 볼륨을 마운트합니다.</block>
  <block id="809f33612149b405423b98b77a13d18f" category="paragraph"><block ref="809f33612149b405423b98b77a13d18f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0895b43b6a4f7ded9ce501e420da7cae" category="paragraph">매핑되면 쉽게 액세스할 수 있으며 NTFS 권한을 적절하게 설정할 수 있습니다.</block>
  <block id="2565b7a7d81a362c6b3fc5f32d83075b" category="paragraph"><block ref="2565b7a7d81a362c6b3fc5f32d83075b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="262a1d892164ab4100a969a952274934" category="section-title">Cloud Volumes ONTAP의 LUN을 호스트에 연결합니다</block>
  <block id="049f63d3d6479b8801f942e53b31cfd6" category="paragraph">Cloud Volumes ONTAP LUN을 호스트에 연결하려면 다음 단계를 수행하십시오.</block>
  <block id="b5f2af2dc909b8d634ef7e8dd729c0bc" category="paragraph"><block ref="99dce170472373a603dcc6cab1306eea" category="inline-image-macro-rx" type="image"></block>
<block ref="99eed8d2ce50ff339d9bff41a9fe9a51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4296bb5afd2416d05f951e9d3380e5e4" category="list-text">볼륨이 프로비저닝되면 볼륨 메뉴( º)를 선택한 다음 대상 IQN을 클릭합니다. IQN(iSCSI Qualified Name)을 복사하려면 Copy(복사)를 클릭합니다. 호스트에서 LUN으로의 iSCSI 접속을 설정합니다.</block>
  <block id="5bbe705670fa05ddb0b508acf301a379" category="paragraph">Google Cloud VMware Engine에 상주하는 호스트에 대해 동일한 작업을 수행하려면 다음을 수행합니다.</block>
  <block id="a730e43d2afac8730f77c3fab06bcdc0" category="list-text">Google Cloud VMware Engine에서 호스팅되는 VM에 대한 RDP</block>
  <block id="88c7456aa49f0bfe0258958c4c42a153" category="paragraph"><block ref="88c7456aa49f0bfe0258958c4c42a153" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da663e5eac7f594bcac6564a22726142" category="paragraph"><block ref="da663e5eac7f594bcac6564a22726142" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74edf50412d8a6c920ebdf456ca74d6f" category="paragraph"><block ref="74edf50412d8a6c920ebdf456ca74d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8bce76f68494174fa21e44b39be75e7" category="paragraph">Linux 클라이언트에서 iSCSI 데몬이 실행되고 있는지 확인합니다. LUN을 프로비저닝한 후에는 여기에서 Ubuntu를 사용한 iSCSI 구성에 대한 자세한 지침을 참조하십시오. 확인하려면 셸에서 lsblk cmd 를 실행합니다.</block>
  <block id="5800551032817b82a3780efc5c365b61" category="paragraph"><block ref="5d8610d622621cfaf5f5af9098efada8" category="inline-image-macro-rx" type="image"></block>
<block ref="0e5aea74b7dab4389459e8f03d7961e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a676f5d05c6d1f36341948d03289c3f" category="paragraph">Google Cloud VMware Engine 내의 VM에서 DIY(Cloud Volumes ONTAP) 파일 시스템을 마운트하려면 다음 단계를 수행하십시오.</block>
  <block id="99ff74a348250b7148d219f224bc40b4" category="paragraph">아래 단계에 따라 볼륨을 프로비저닝합니다</block>
  <block id="17d1d28660c0ff68f1ee26c3bc7c2e0d" category="list-text">볼륨 탭에서 새 볼륨 생성 을 클릭합니다.</block>
  <block id="6fa266ccf8c1f303a7ed67b355770afb" category="list-text">새 볼륨 생성 페이지에서 볼륨 유형을 선택합니다.</block>
  <block id="8d7c2959a73ccf424e912497fa729dfa" category="paragraph"><block ref="8d7c2959a73ccf424e912497fa729dfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e89e2106ea79d032d48e99a6498e2584" category="list-text">볼륨 탭에서 마우스 커서를 볼륨 위에 놓고 메뉴 아이콘( º)을 선택한 다음 Mount Command를 클릭합니다.</block>
  <block id="1367b1db6f5a641c16b673b4f75f02de" category="paragraph"><block ref="1367b1db6f5a641c16b673b4f75f02de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8a4175c7cb7e059193f8bdcafc1395b0" category="list-text">복사를 클릭합니다.</block>
  <block id="2432c695bbc97e5283e213ba846e86dc" category="paragraph"><block ref="2432c695bbc97e5283e213ba846e86dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5cbcad6705273d58a27b5b92fdc1700" category="list-text">이전 단계에서 생성한 디렉토리에 Cloud Volumes ONTAP NFS 볼륨을 마운트합니다.</block>
  <block id="f505f299a6f5e1e9f6b91adec6ef8f38" category="paragraph"><block ref="4aa22d1032194bb618fa2b2a8bbc5d82" category="inline-image-macro-rx" type="image"></block>
<block ref="73581b61100d82e506cc05faa5fc45c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c0dd0de38e3c9e55ef5f52e46641376" category="section-title">VMware 엔진을 사용하여 Cloud Volumes Service를 구성합니다</block>
  <block id="8e12272d11d90cdb919c737591f398f6" category="paragraph">Cloud Volumes Service 공유는 VMware 엔진 환경에서 생성된 VM에서 마운트할 수 있습니다. Cloud Volumes Service는 SMB 및 NFS 프로토콜을 지원하므로 Linux 클라이언트에 볼륨을 마운트하고 Windows 클라이언트에 매핑할 수도 있습니다. Cloud Volumes Service 볼륨은 간단한 단계를 통해 설정할 수 있습니다.</block>
  <block id="992031e7435f44536a649bfc9de30683" category="paragraph">Cloud Volume Service 및 Google Cloud VMware Engine 프라이빗 클라우드는 같은 지역에 있어야 합니다.</block>
  <block id="a0c391dc49c440fc9962168353cedde3" category="inline-link-macro">가이드</block>
  <block id="e9676faeb0b33249abc3a47d95e55ed8" category="paragraph">Google Cloud Marketplace에서 NetApp Cloud Volumes Service for Google Cloud를 구매, 활성화 및 구성하려면 다음 세부 정보를 따르십시오 <block ref="c9eb1a9870bc9f20357f50bf16ec5704" category="inline-link-macro-rx"></block>.</block>
  <block id="84c877bb77a313d307054a0824ffff03" category="section-title">CVS NFS 볼륨을 GCVE 프라이빗 클라우드에 생성합니다</block>
  <block id="1ec5bbc38708de3f8cfad6d6ca608742" category="paragraph">NFS 볼륨을 생성 및 마운트하려면 다음 단계를 수행하십시오.</block>
  <block id="ca5470246976d59ea6a32d3e2094059d" category="list-text">Google 클라우드 콘솔 내의 파트너 솔루션에서 Cloud Volumes에 액세스합니다.</block>
  <block id="45ab48bbbad4380f09ef6b41f9eb8f8a" category="paragraph"><block ref="45ab48bbbad4380f09ef6b41f9eb8f8a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46577653160772df2b1548b726d7c9ce" category="list-text">Cloud Volumes Console에서 Volumes 페이지로 이동하고 Create를 클릭합니다.</block>
  <block id="4a43547530a8ef079adc80160de3dde9" category="paragraph"><block ref="4a43547530a8ef079adc80160de3dde9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="825700271a3acfeaf96fa0bfb5f15b65" category="list-text">파일 시스템 생성 페이지에서 차지백 메커니즘에 필요한 볼륨 이름 및 청구 레이블을 지정합니다.</block>
  <block id="8a81559c79124aa1a1cd2093faed73ee" category="paragraph"><block ref="8a81559c79124aa1a1cd2093faed73ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4bbe773302576667095a132b75c48fc" category="list-text">적절한 서비스를 선택합니다. GCVE의 경우 애플리케이션 워크로드 요구 사항에 따라 지연 시간 및 성능 향상을 위해 CVS 성능 및 원하는 서비스 수준을 선택합니다.</block>
  <block id="184fe9f42c4d5eaab1cc6079778040c2" category="paragraph"><block ref="184fe9f42c4d5eaab1cc6079778040c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492d6cb3c36c984d9f52d9461c5b69b" category="list-text">볼륨 및 볼륨 경로에 대해 Google Cloud 영역을 지정합니다. 볼륨 경로는 프로젝트의 모든 클라우드 볼륨에서 고유해야 합니다.</block>
  <block id="594c2b024401023acd7deae8f3cb8ceb" category="paragraph"><block ref="594c2b024401023acd7deae8f3cb8ceb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c4b0697a6c38463b0b06d7dc66b16b74" category="list-text">볼륨의 성능 수준을 선택합니다.</block>
  <block id="aebc437f9bb3656c19ecebe1becc99fa" category="paragraph"><block ref="aebc437f9bb3656c19ecebe1becc99fa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dd9c26fe6b5f33ab2b0002050ff831d8" category="list-text">볼륨의 크기와 프로토콜 유형을 지정합니다. 이 테스트에서는 NFSv3을 사용합니다.</block>
  <block id="e5ba61d9c8c666d452e9e78256762019" category="paragraph"><block ref="e5ba61d9c8c666d452e9e78256762019" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3a8099bd03f7da2c641e049e354ea1" category="list-text">이 단계에서는 볼륨에 액세스할 수 있는 VPC 네트워크를 선택합니다. VPC 피어링을 제자리에 배치했는지 확인합니다.</block>
  <block id="d3dba730ef6d3f046910d94696ca086d" category="paragraph">힌트: VPC 피어링을 수행하지 않은 경우 피어링 명령을 안내하는 팝업 버튼이 표시됩니다. 클라우드 셸 세션을 열고 적절한 명령을 실행하여 VPC를 Cloud Volumes Service 생산자와 동종합니다. 사전에 VPC 피어링을 준비하려는 경우 다음 지침을 참조하십시오.</block>
  <block id="ecf942f7df1f072f5910afb3fa45f36e" category="paragraph"><block ref="ecf942f7df1f072f5910afb3fa45f36e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ed1352ea98f362074fa7855ec6bb89c" category="list-text">적절한 규칙을 추가하여 엑스포트 정책 규칙을 관리하고 해당 NFS 버전의 확인란을 선택합니다.</block>
  <block id="3ae650d16c298e2f5dc9e005a2f8934a" category="paragraph">참고: 내보내기 정책을 추가하지 않으면 NFS 볼륨에 액세스할 수 없습니다.</block>
  <block id="2f6d29a5c21fb51bb181c4b97241a955" category="paragraph"><block ref="2f6d29a5c21fb51bb181c4b97241a955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a194552e035de341a4a7c99a1c687956" category="list-text">Save(저장) 를 클릭하여 볼륨을 생성합니다.</block>
  <block id="fe18028768c2ffc16d5cb32aa5b70d5b" category="paragraph"><block ref="fe18028768c2ffc16d5cb32aa5b70d5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3588b0992732355d67655af9f6450c5d" category="section-title">VMware Engine에서 실행 중인 VM에 NFS 내보내기를 마운트합니다</block>
  <block id="87397baf86d56e19a3bdac712966da5d" category="paragraph">NFS 볼륨 마운트를 준비하기 전에 전용 연결의 피어링 상태가 Active(활성)로 표시되는지 확인합니다. 상태가 Active인 경우 mount 명령을 사용합니다.</block>
  <block id="c9f09539bbf502703a4f5e2d480a5972" category="paragraph">NFS 볼륨을 마운트하려면 다음을 수행합니다.</block>
  <block id="726f902a0b5536d71345114fb942d81b" category="list-text">Cloud Console에서 Cloud Volumes &gt; Volumes로 이동합니다.</block>
  <block id="1feaf778ab1cf141cf92a316d53e1365" category="list-text">볼륨 페이지로 이동합니다</block>
  <block id="76d2df71caae5e1ec3f81822829504f5" category="list-text">NFS 내보내기를 마운트할 NFS 볼륨을 클릭합니다.</block>
  <block id="4fc82f44f951748bf462898e43d08054" category="list-text">오른쪽으로 스크롤하고 자세히 표시 에서 마운트 지침 을 클릭합니다.</block>
  <block id="692afb2fddb72a6cfc89dd1df12945ab" category="paragraph">VMware VM의 게스트 OS 내에서 마운트 프로세스를 수행하려면 다음 단계를 따르십시오.</block>
  <block id="2c7df76595ada01b5b08659283021aa7" category="list-text">SSH 클라이언트 및 SSH를 사용하여 가상 머신에 접속합니다.</block>
  <block id="2b64d099377e2935e786009804205feb" category="list-text">인스턴스에 NFS 클라이언트를 설치합니다.</block>
  <block id="d8aa2b3304fc65e5fd1cae735194aef6" category="list-text">Red Hat Enterprise Linux 또는 SuSE Linux 인스턴스:</block>
  <block id="d610fa6d370a8d35fb4c26359f086aa0" category="list-text">Ubuntu 또는 Debian 인스턴스에서:</block>
  <block id="9bc2e27c16ca55bfc1a7ba94b91a21dc" category="list-text">인스턴스에 "/nimCVSNFSol01"과 같은 새 디렉토리를 생성합니다.</block>
  <block id="9e21b9d85251decc0982b75506826828" category="paragraph"><block ref="9e21b9d85251decc0982b75506826828" category="inline-image-macro-rx" type="image"></block></block>
  <block id="174714918db1cc87ef113e3087cba5da" category="list-text">적절한 명령을 사용하여 볼륨을 마운트합니다. 실습의 명령 예는 다음과 같습니다.</block>
  <block id="1ec7767a139a3f95923511d7bf547a6c" category="paragraph"><block ref="811572ed35d4b134bc0d7769dd80ab6c" category="inline-image-macro-rx" type="image"></block>
<block ref="b780e126200cb608d0de968e965e9c71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3df234dd2e63d779a2d017bb1ef3375d" category="section-title">VMware Engine에서 실행 중인 VM에 SMB 공유 생성 및 마운트</block>
  <block id="400db805dd1f9fc929e5bf72fafb1661" category="paragraph">SMB 볼륨의 경우 SMB 볼륨을 생성하기 전에 Active Directory 연결이 구성되어 있는지 확인합니다.</block>
  <block id="94f9379544859ae4d8990b84731870aa" category="paragraph"><block ref="94f9379544859ae4d8990b84731870aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c62a73033a0e9f64b5b2b311ded0cc5" category="paragraph">AD 연결이 설정되면 원하는 서비스 수준으로 볼륨을 생성합니다. 단계는 적절한 프로토콜을 선택하는 경우를 제외하고 NFS 볼륨을 생성하는 것과 같습니다.</block>
  <block id="228ba1c797822b63cd7c6f54ca40b87e" category="paragraph"><block ref="228ba1c797822b63cd7c6f54ca40b87e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54cd15dd2d6121aa16f0b4b87b46ef2a" category="list-text">적절한 서비스를 선택합니다. GCVE의 경우 워크로드 요구 사항에 따라 지연 시간을 개선하고 성능을 향상시키하려면 CVS 성능 및 원하는 서비스 수준을 선택합니다.</block>
  <block id="b8eb8307790a9b22c2f6997c097b344e" category="paragraph"><block ref="b8eb8307790a9b22c2f6997c097b344e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cb91d5f8a608e41cd1f217e30a536437" category="paragraph"><block ref="cb91d5f8a608e41cd1f217e30a536437" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e5a0a3c08f102d8c49c1d811b71d97f" category="paragraph"><block ref="7e5a0a3c08f102d8c49c1d811b71d97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d1a06f98a1c133a8a0c74cc4222e23b" category="list-text">볼륨의 크기와 프로토콜 유형을 지정합니다. 이 테스트에서는 SMB가 사용됩니다.</block>
  <block id="6eb5a9152f38c77efc6d14902aa7dec8" category="paragraph"><block ref="6eb5a9152f38c77efc6d14902aa7dec8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbde2df6a7c89370edc449dc5705d30c" category="inline-link-macro">지침</block>
  <block id="15adcf662b8b92c623f4256a65f605ed" category="paragraph">힌트: VPC 피어링을 수행하지 않은 경우 피어링 명령을 안내하는 팝업 버튼이 표시됩니다. 클라우드 셸 세션을 열고 적절한 명령을 실행하여 VPC를 Cloud Volumes Service 생산자와 동종합니다. 미리 VPC 피어링을 준비하려는 경우 이를 참조하십시오 <block ref="3b4469537a7b14dcfd28e3d301600ff6" category="inline-link-macro-rx"></block>.</block>
  <block id="7f88d48c3b0283642fe6b1f3f061d0fd" category="paragraph"><block ref="7f88d48c3b0283642fe6b1f3f061d0fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ac40323c41c29fb75f6e19c4c683e47" category="paragraph"><block ref="8ac40323c41c29fb75f6e19c4c683e47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4990031dcfbd871d95ce4ae0321e7156" category="paragraph">SMB 볼륨을 마운트하려면 다음을 수행합니다.</block>
  <block id="fd78728be3a82142558c815267b8daa0" category="list-text">SMB 공유를 매핑할 SMB 볼륨을 클릭합니다.</block>
  <block id="58dc78a5cd30078188f7c605e636a975" category="paragraph">VMware VM의 Windows 게스트 OS 내에서 마운트 프로세스를 수행하려면 다음 단계를 수행하십시오.</block>
  <block id="3dcb4e26f80951bdb3beeb0a03a3ba83" category="list-text">시작 단추를 클릭한 다음 컴퓨터를 클릭합니다.</block>
  <block id="202bba1ab43a099f57e49b350eb2ad1a" category="list-text">네트워크 드라이브 연결 을 클릭합니다.</block>
  <block id="7dea65bdd8e9fbcd8a5b7249c71e1f0b" category="list-text">드라이브 목록에서 사용 가능한 드라이브 문자를 클릭합니다.</block>
  <block id="695179e494f30a851f80409f824a80f8" category="list-text">폴더 상자에 다음을 입력합니다.</block>
  <block id="2653f3365feaf0a8bf80106cba1b9ad8" category="paragraph"><block ref="2653f3365feaf0a8bf80106cba1b9ad8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7cd95358048d9f5d18cf70f66126e1e7" category="paragraph">컴퓨터에 로그온할 때마다 연결하려면 로그인할 때 다시 연결 확인란을 선택합니다.</block>
  <block id="7968f043139de8ff0e5df4451c437426" category="list-text">마침 을 클릭합니다.</block>
  <block id="8902b5e2f0c169ccf7ad8b5c335531e5" category="paragraph"><block ref="8902b5e2f0c169ccf7ad8b5c335531e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="415be703c228d9c6838b18850a1d9f31" category="paragraph">대부분의 IT 조직은 하이브리드 클라우드 우선 접근 방식을 따릅니다. 전환 단계에 있는 이들 조직은 고객이 현재 IT 환경을 평가한 다음 평가 및 검색 결과를 기반으로 워크로드를 클라우드로 마이그레이션하고 있습니다.</block>
  <block id="346972233965e89cf5b17c3907b35f86" category="paragraph">클라우드로 마이그레이션하는 고객의 요인에는 탄력성 및 버스트, 데이터 센터 이탈, 데이터 센터 통합, 수명 종료 시나리오, 인수 합병, 인수 합병 등 이 마이그레이션의 이유는 각 조직 및 각 비즈니스 우선순위에 따라 달라질 수 있습니다. 하이브리드 클라우드로 전환할 때 클라우드 구축과 탄력성의 잠재력을 최대한 활용하려면 클라우드에 적합한 스토리지를 선택하는 것이 매우 중요합니다.</block>
  <block id="0c4a16ed987359b14dc407a858d1a78e" category="section-title">퍼블릭 클라우드의 VMware 클라우드 옵션</block>
  <block id="9789f0612fda153726aa8ad87265e4b9" category="section-title">Azure VMware 솔루션</block>
  <block id="d788a5499d320b05602a6a0805c81403" category="image-alt">AVS</block>
  <block id="c7b818b90803789a74058cfb4396383d" category="paragraph">Azure VMware 솔루션은 Microsoft Azure 퍼블릭 클라우드 내에서 VMware DC를 완벽하게 작동하는 하이브리드 클라우드 서비스입니다. Azure VMware 솔루션은 Microsoft에서 완벽하게 관리 및 지원하는 타사 솔루션으로, Azure 인프라를 활용하는 VMware에서 검증되었습니다. 즉, Azure VMware 솔루션을 구축할 때 고객은 컴퓨팅 가상화를 위한 VMware ESXi, 하이퍼 컨버지드 스토리지를 위한 vSAN을 얻게 됩니다. 네트워킹 및 보안을 위한 NSX는 물론, Microsoft Azure의 세계적인 입지, 동급 최고의 데이터 센터 시설을 활용하고 네이티브 Azure 서비스 및 솔루션의 풍부한 에코시스템에 근접합니다.</block>
  <block id="22b0614f106e2b7c956c60c8fc0d35c3" category="image-alt">VMC</block>
  <block id="8641a2440fc22db60ec877f3a8946fa2" category="paragraph">VMware Cloud on AWS는 기본 AWS 서비스에 최적화된 액세스를 통해 VMware의 엔터프라이즈급 SDDC 소프트웨어를 AWS 클라우드에 제공합니다. VMware Cloud Foundation을 기반으로 하는 AWS 기반 VMware Cloud는 VMware의 컴퓨팅, 스토리지 및 네트워크 가상화 제품(VMware vSphere, VMware vSAN 및 VMware NSX)을 VMware vCenter Server 관리 기능과 통합하여 유연하고 전용 베어 메탈 AWS 인프라에서 실행되도록 최적화되었습니다.</block>
  <block id="8cb69aa5b1609d0a39f0fcd576c07df6" category="section-title">Google Cloud VMware 엔진</block>
  <block id="5292de1147a4b3a1d5c63d057c4b0096" category="image-alt">Gcve</block>
  <block id="1ffd600a1d8e07fe3b4bca16ae02167c" category="paragraph">Google Cloud VMware Engine은 Google Cloud의 고성능 확장형 인프라와 VMware Cloud Foundation 스택(VMware vSphere, vCenter, vSAN 및 NSX-T)을 기반으로 구축된 IaaS(Infrastructure-as-a-Service) 제품입니다 이 서비스를 사용하면 비용, 노력 또는 애플리케이션 재설계 또는 운영 재조정 위험 없이 기존 VMware 워크로드를 온프레미스 환경에서 Google Cloud Platform으로 원활하게 마이그레이션하거나 확장할 수 있습니다. Google에서 판매 및 지원하는 서비스로서 VMware와 긴밀하게 협력하고 있습니다.</block>
  <block id="3310d189628fa6ef843aac57894a6db2" category="admonition">SDDC 프라이빗 클라우드 및 NetApp Cloud Volumes 코로케이션을 통해 최소한의 네트워크 지연 시간으로 최상의 성능을 제공합니다.</block>
  <block id="c771fce16e2ba5df07df53cc5ab0748f" category="section-title">알고 계셨습니까?</block>
  <block id="8bba30129de0461b328be1e49f02b4d9" category="paragraph">사용된 클라우드에 관계없이 VMware SDDC를 구축할 때 초기 클러스터에 포함되는 제품은 다음과 같습니다.</block>
  <block id="7110e7a8682a9bc1c7105b83fe0cd9ea" category="list-text">관리를 위해 vCenter Server 어플라이언스를 사용하여 컴퓨팅 가상화를 위한 VMware ESXi 호스트</block>
  <block id="7d7a80e207de2136f4f19820758703fc" category="list-text">VMware vSAN 하이퍼 컨버지드 스토리지는 각 ESXi 호스트의 물리적 스토리지 자산을 통합합니다</block>
  <block id="d2852e9d73c0ef81033c835719128b81" category="list-text">관리를 위해 NSX Manager 클러스터를 사용하여 가상 네트워킹 및 보안을 위한 VMware NSX</block>
  <block id="afb91ca7e7763c77e44a41cb5ad0f78b" category="paragraph">스토리지 집약적인 워크로드를 호스팅하거나 클라우드 호스팅 VMware 솔루션에서 스케일아웃하려는 고객의 경우 기본 하이퍼 컨버지드 인프라는 확장이 컴퓨팅 및 스토리지 리소스 모두에 있어야 한다는 것을 나타냅니다.</block>
  <block id="fdb27bea654a8d874baecced2be84a1b" category="paragraph">Azure NetApp Files, Amazon FSx for NetApp ONTAP, Cloud Volumes ONTAP(세 가지 주요 하이퍼 스케일러 모두에서 사용 가능) 및 Cloud Volumes Service for Google Cloud와 같은 NetApp Cloud Volumes와 통합함으로써 고객은 이제 스토리지를 개별적으로 확장할 수 있는 옵션을 갖게 됩니다. 필요에 따라 SDDC 클러스터에만 컴퓨팅 노드를 추가할 수 있습니다.</block>
  <block id="2a01d572b1447155c310cabafac3fae9" category="section-title">참고:</block>
  <block id="a752c3529f0285d457f3b33b3c80d9a4" category="list-text">VMware는 불균형 클러스터 구성을 권장하지 않습니다. 따라서 스토리지를 확장한다는 것은 더 많은 호스트를 추가해야 한다는 것을 의미하며, 이는 더 많은 TCO를 의미합니다.</block>
  <block id="1d8249c60cae81d82fc5bfb80167babc" category="list-text">하나의 vSAN 환경만 가능합니다. 따라서 모든 스토리지 트래픽은 운영 워크로드와 직접 경쟁하게 됩니다.</block>
  <block id="c231690c8e9fabbd819ec1805becb157" category="list-text">애플리케이션 요구사항, 성능, 비용을 맞추기 위해 여러 성능 계층을 제공하는 옵션은 없습니다.</block>
  <block id="5d4c92ddd5fe9a6044b25c17d3368207" category="list-text">클러스터 호스트 위에 구축된 vSAN의 스토리지 용량 제한에 매우 쉽게 도달할 수 있습니다. NetApp Cloud Volumes를 사용하여 액티브 데이터 세트를 호스트하거나 영구 스토리지로 계층 쿨러 데이터를 계층화하도록 스토리지를 확장할 수 있습니다.</block>
  <block id="c1cf68955de5fa20274b29fa4a2a863f" category="paragraph">Azure NetApp Files, Amazon FSx for NetApp ONTAP, Cloud Volumes ONTAP(세 가지 주요 하이퍼 스케일러 모두에서 사용 가능) 및 Cloud Volumes Service for Google Cloud를 게스트 VM과 함께 사용할 수 있습니다. 이 하이브리드 스토리지 아키텍처는 게스트 운영 체제 및 애플리케이션 바이너리 데이터를 보관하는 vSAN 데이터스토어로 구성됩니다. 애플리케이션 데이터는 각각 NetApp ONTAP용 Amazon FSx, Cloud Volume ONTAP, Azure NetApp Files 및 Google Cloud용 Cloud Volumes Service와 직접 통신하는 게스트 기반 iSCSI 이니시에이터 또는 NFS/SMB 마운트를 통해 VM에 연결됩니다. 이 구성을 사용하면 vSAN과 같이 스토리지 용량과 관련된 문제를 쉽게 해결할 수 있습니다. 사용 가능한 여유 공간은 사용된 여유 공간 및 스토리지 정책에 따라 달라집니다.</block>
  <block id="1a5208bfffc624ccf99dfcbbf2078050" category="paragraph">AWS의 VMware Cloud에서 3노드 SDDC 클러스터를 살펴보겠습니다.</block>
  <block id="fab7fb31baaec1ccac4fe688e1a4c5d4" category="list-text">3노드 SDDC의 총 물리적 용량은 31.1TB(각 노드당 약 10TB)입니다.</block>
  <block id="ca189b47c3a1dfe1adbd1519688e4cc8" category="list-text">호스트를 추가하기 전에 유지 관리해야 하는 여유 공간 = 25% = (.25 x 31.1TB) = 7.7TB</block>
  <block id="999b2c719df3f3e524bb10fb76521726" category="list-text">여유 공간 차감 후의 가용 물리적 용량 = 23.4TB</block>
  <block id="2e1f3b31385d3304e1cda70b9cd8ed4c" category="list-text">사용 가능한 유효 여유 공간은 적용된 스토리지 정책에 따라 달라집니다.</block>
  <block id="506c2c0c7f5b70af3df68c45c46f45a7" category="paragraph">예를 들면 다음과 같습니다.</block>
  <block id="2f5e6d9b0a4708c4d137ba14ac704a7b" category="list-text">RAID 0 = 유효 여유 공간 = 23.4TB(사용 가능한 물리적 용량/1)</block>
  <block id="df6b502d4d7283ef27d3821b69836c2d" category="list-text">RAID 1 = 유효 여유 공간 = 11.7TB(사용 가능한 물리적 용량/2)</block>
  <block id="921c660c11d4880048f3ef723f079e17" category="list-text">RAID 5 = 유효 여유 공간 = 17.5TB(사용 가능한 물리적 용량/1.33)</block>
  <block id="e3bdc3102c3de4f73860c229550bc6f4" category="paragraph">따라서 NetApp Cloud Volumes를 게스트 연결 스토리지로 사용하면 스토리지를 확장하고 TCO를 최적화하는 동시에 성능 및 데이터 보호 요구사항을 충족할 수 있습니다.</block>
  <block id="571c0d425ce03c2532e7d9f34ca87cb1" category="section-title">기억해야 할 사항</block>
  <block id="8e6eaed3852a3b311ab6ed1b8b6fc239" category="list-text">하이브리드 스토리지 모델에서는 Tier 1 또는 높은 우선 순위의 워크로드를 vSAN 데이터 저장소에 배치하여 호스트 자체의 일부이고 근접하기 때문에 특정 지연 시간 요구 사항을 처리합니다. 트랜잭션 지연 시간이 허용되는 워크로드 VM에 대해 게스트 내 메커니즘을 사용합니다.</block>
  <block id="43ff7a71a2ea2fc47a29d410cd1e4944" category="list-text">NetApp SnapMirror ® 기술을 사용하여 온프레미스 ONTAP 시스템에서 Cloud Volumes ONTAP 또는 NetApp ONTAP용 Amazon FSx로 워크로드 데이터를 복제하여 블록 레벨 메커니즘을 사용하여 손쉽게 마이그레이션할 수 있습니다. Azure NetApp Files 및 Cloud Volumes Services에는 적용되지 않습니다. 데이터를 Azure NetApp Files 또는 Cloud Volumes Services로 마이그레이션하려면 사용되는 파일 프로토콜에 따라 NetApp XCP, Cloud Sync, rysnc 또는 robocopy를 사용하십시오.</block>
  <block id="d3c0fd4b510310b9bd00463208eade94" category="list-text">테스트 결과, 각 SDDC에서 스토리지에 액세스하는 동안 지연 시간이 2-4ms로 더 길어집니다. 스토리지를 매핑할 때 애플리케이션 요구 사항에 이러한 추가 지연 시간을 고려하십시오.</block>
  <block id="b83cf0bc9b65a0fcd5f49d4c96dceea8" category="list-text">테스트 페일오버 및 실제 페일오버 중에 게스트 연결 스토리지를 마운트하려면 iSCSI 이니시에이터가 재구성되고 DNS가 SMB 공유용으로 업데이트되며 NFS 마운트 지점이 fstab에서 업데이트되도록 합니다.</block>
  <block id="1b4048870ed334dbc2e7d6f09a814188" category="list-text">게스트 내 Microsoft MPIO(Multipath I/O), 방화벽 및 디스크 시간 초과 레지스트리 설정이 VM 내에서 올바르게 구성되어 있는지 확인합니다.</block>
  <block id="bf3f0fd9ec5faf81793c3abc5e3b9127" category="admonition">이는 게스트 연결 스토리지에만 적용됩니다.</block>
  <block id="00b23e82efc2ec82b134496e575a934c" category="section-title">NetApp 클라우드 스토리지의 이점</block>
  <block id="80def6ec4d999fc4d082800c8c33f6ec" category="paragraph">NetApp 클라우드 스토리지는 다음과 같은 이점을 제공합니다.</block>
  <block id="2e594db552f7cd9c7f02d87507dbb471" category="list-text">컴퓨팅과 상관없이 스토리지를 확장함으로써 컴퓨팅 및 스토리지 간 밀도 향상</block>
  <block id="479f9f236fc4cffa74f2e94b654bbeeb" category="list-text">호스트 수를 줄여 전체 TCO를 줄일 수 있습니다.</block>
  <block id="108dd736471686a2b8b87154d73cbc5b" category="list-text">컴퓨팅 노드 장애는 스토리지 성능에 영향을 주지 않습니다.</block>
  <block id="a85e0a264279b851fbcec367c181932e" category="list-text">Azure NetApp Files의 볼륨 재구성 및 동적 서비스 수준 기능을 사용하면 안정적인 워크로드 크기를 조정하여 비용을 최적화하고 오버 프로비저닝을 방지할 수 있습니다.</block>
  <block id="4e24ca7789e0b9320e302b8efa2caf9f" category="list-text">Cloud Volumes ONTAP의 스토리지 효율성, 클라우드 계층화 및 인스턴스 유형 수정 기능을 사용하면 스토리지를 최적의 방법으로 추가 및 확장할 수 있습니다.</block>
  <block id="d7a87fa8fc914cf57f38eff05d53faa2" category="list-text">필요 시에만 스토리지 리소스의 초과 프로비저닝을 방지합니다.</block>
  <block id="940eacbcb0faa8c3b1e0d995c154f693" category="list-text">효율적인 스냅샷 복사본 및 복제를 사용하면 성능에 영향을 미치지 않고 복사본을 빠르게 생성할 수 있습니다.</block>
  <block id="a9e4a9fcd1f9bf0a9d0d0b2c0f198db5" category="list-text">Snapshot 복사본에서 빠른 복구를 사용하여 랜섬웨어 공격을 해결할 수 있도록 도와줍니다.</block>
  <block id="caf9b805c37cab661d4e3a26b7f71109" category="list-text">효율적인 증분 블록 전송 기반 지역 재해 복구 및 여러 지역에 걸쳐 통합된 백업 블록 레벨을 제공하여 RPO 및 RTO가 향상됩니다.</block>
  <block id="658fb5ef00749e8af5a974f612adea9b" category="section-title">가정</block>
  <block id="a9e63f2a8549d717b777806268a0c0cb" category="list-text">SnapMirror 기술 또는 기타 관련 데이터 마이그레이션 메커니즘이 사용됩니다. 온프레미스에서 하이퍼스케일러 클라우드에 이르기까지 다양한 연결 옵션이 있습니다. 적절한 경로를 사용하고 관련 네트워킹 팀과 협력하십시오.</block>
  <block id="478a13ed02b948c9cfd89a6197062012" category="admonition">스토리지 계획 및 사이징과 필요한 호스트 수에 대해서는 NetApp 솔루션 설계자와 각각의 하이퍼스케일러 클라우드 설계자를 설득하십시오. Cloud Volumes ONTAP Sizer를 사용하여 스토리지 인스턴스 유형 또는 적절한 서비스 수준을 최적의 처리량으로 확정하기 전에 스토리지 성능 요구사항을 파악하는 것이 좋습니다.</block>
  <block id="c748546b5854ecb146d9caa41d781bdb" category="section-title">상세 아키텍처</block>
  <block id="1a8ac44404b1e5888d83801ac116ff66" category="inline-image-macro">엔터프라이즈 하이브리드 클라우드 아키텍처</block>
  <block id="855b05f645c80247a3f11392cab187c2" category="paragraph"><block ref="855b05f645c80247a3f11392cab187c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="63b9fbe67e7dd9b9f7623683244cb7f8" category="doc">Azure AVS용 NetApp 기능</block>
  <block id="1f0a2077c33b91b3daaaea05c7fadc07" category="section-title">Azure에서 AVS 구성</block>
  <block id="cdac9a2e7f1dc52240712d4a191378e8" category="section-title">AVS용 NetApp 스토리지 옵션</block>
  <block id="cf3ac5a0dae3780b356e57c121b3eab0" category="doc">Google Cloud Platform(GCP)에서 가상화 환경 구축 및 구성</block>
  <block id="fd558e50adcdcb0d667a4790f70f75a9" category="paragraph">GCP에서 GCVE 환경을 구성하려면 GCP 콘솔에 로그인하고 VMware Engine 포털에 액세스합니다.</block>
  <block id="fb33f758c28f8ef8d56e41f74b4c47ab" category="paragraph">“새 사설 클라우드” 버튼을 클릭하고 GCVE 프라이빗 클라우드에 대해 원하는 구성을 입력합니다. “위치”에서 CVS/CVO가 배포된 동일한 지역/영역에 프라이빗 클라우드를 배포하여 최상의 성능과 최저 지연 시간을 보장해야 합니다.</block>
  <block id="63b31ca49de01854f780d1e1722cd1c1" category="paragraph">전제 조건:</block>
  <block id="d79b0ab3cbae1dcd79007a97d26af5b1" category="list-text">VMware Engine Service Admin IAM 역할을 설정합니다</block>
  <block id="72a7f08f840ab91a28a2558393971c47" category="inline-link-macro">VMware Engine API 액세스 및 노드 할당량을 설정합니다</block>
  <block id="88e3e4c9b1c9efec399f7dda7a0c5887" category="list-text"><block ref="88e3e4c9b1c9efec399f7dda7a0c5887" category="inline-link-macro-rx"></block></block>
  <block id="a88d670b04af96a871dad56001e8f742" category="list-text">CIDR 범위가 온-프레미스 또는 클라우드 서브넷과 겹치지 않도록 하십시오. CIDR 범위는 /27 이상이어야 합니다.</block>
  <block id="33d7d6c631c2d2cb3608445ef761fe16" category="paragraph"><block ref="33d7d6c631c2d2cb3608445ef761fe16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65bdc0673006b33d0c876e18a9a98787" category="paragraph">참고: 프라이빗 클라우드를 생성하는 데 30분에서 2시간까지 걸릴 수 있습니다.</block>
  <block id="d77d7a022616e70a9987aa0974241779" category="paragraph">프라이빗 클라우드가 프로비저닝되면 높은 처리량과 짧은 지연 시간의 데이터 경로 연결을 위해 프라이빗 클라우드에 대한 프라이빗 액세스를 구성합니다.</block>
  <block id="256431e41a96deb49bcd86b1ca56393e" category="inline-link-macro">GCP 문서</block>
  <block id="e4cf8d7f33a9dafc85be0439cd8fbc4d" category="paragraph">이렇게 하면 Cloud Volumes ONTAP 인스턴스가 실행 중인 VPC 네트워크가 GCVE 프라이빗 클라우드와 통신할 수 있습니다. 이렇게 하려면 를 따르십시오 <block ref="9cd64b8fb1b43e7f674c1b78b2a86f74" category="inline-link-macro-rx"></block>. 클라우드 볼륨 서비스의 경우 테넌트 호스트 프로젝트 간에 일회성 피어링을 수행하여 VMware 엔진과 Cloud Volumes Service 간에 연결을 설정합니다. 자세한 단계는 다음과 같습니다 <block ref="04a9f04edfdd7b0a53da57f015378c5a" category="inline-link-macro-rx"></block>.</block>
  <block id="e6945148d9a888e52db99c5ebce86868" category="paragraph"><block ref="e6945148d9a888e52db99c5ebce86868" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c3eb3a1c6330fe124fc0706cbdd91df" category="paragraph">CloudOwner@gve.loca l 사용자를 사용하여 vCenter에 로그인합니다. 자격 증명을 액세스하려면 VMware Engine 포털로 이동하여 리소스 로 이동한 다음 적절한 프라이빗 클라우드를 선택합니다. 기본 정보 섹션에서 vCenter 로그인 정보(vCenter Server, HCX Manager) 또는 NSX-T 로그인 정보(NSX Manager)에 대한 보기 링크를 클릭합니다.</block>
  <block id="6f32389268763bedb9e6716b5f0973d0" category="paragraph"><block ref="6f32389268763bedb9e6716b5f0973d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ec2407381a4f65d228483b566b6907f" category="paragraph">Windows 가상 머신에서 브라우저를 열고 vCenter 웹 클라이언트 URL로 이동합니다 <block ref="d325f0342d122dda054a3ca8b0c44019" category="inline-link-rx"></block> admin 사용자 이름을 CloudOwner@gve.loca l 로 사용하여 복사한 암호를 붙여 넣습니다. 마찬가지로 웹 클라이언트 URL을 사용하여 NSX-T Manager에 액세스할 수도 있습니다 <block ref="c694eb5be92097a8fdea8cdda0ad5ea5" category="inline-link-rx"></block> 관리자 사용자 이름을 사용하여 복사한 암호를 붙여 넣어 새 세그먼트를 만들거나 기존 계층 게이트웨이를 수정합니다.</block>
  <block id="3a9cff0eb1abb119c1c264dbfff216f6" category="paragraph">사내 네트워크에서 VMware Engine 프라이빗 클라우드로 연결하려면 클라우드 VPN 또는 Cloud Interconnect를 활용하여 적절한 연결을 설정하고 필요한 포트가 열려 있는지 확인합니다. 자세한 단계는 다음과 같습니다 <block ref="6fe8ac83365e22e24c5c8eb9edc2d548" category="inline-link-macro-rx"></block>.</block>
  <block id="b433f901707e7fd0f6d64371dfca4af9" category="paragraph"><block ref="b433f901707e7fd0f6d64371dfca4af9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="989afab9e0dfcc6d523ddb1d23145834" category="paragraph"><block ref="989afab9e0dfcc6d523ddb1d23145834" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba756c1a2b93ad97a639914aae828a16" category="doc">AWS VMC를 위한 NetApp 솔루션</block>
  <block id="8658ccb747e94ac624861f5761a34716" category="section-title">AWS에서 VMC 구성</block>
  <block id="e9f84da32eb512bd768458a738ed8aa6" category="section-title">VMC용 NetApp 스토리지 옵션</block>
  <block id="f21c97f5b239021bb3f13d148516abb4" category="paragraph">클라우드를 선택하시면 NetApp에서 나머지 작업을 해 드립니다!</block>
  <block id="c1304f98c6be845a236d7a27951ece4f" category="paragraph"><block ref="c1304f98c6be845a236d7a27951ece4f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca4ac823f3f130f3c78d6ac26ba9f46b" category="admonition">특정 하이퍼스케일러의 기능을 보려면 해당 하이퍼스케일러의 적절한 탭을 클릭하십시오.</block>
  <block id="e7441dbfabeaebba75ddd1bf2bcf25e9" category="section-title">사용 사례 #1: 스토리지 최적화</block>
  <block id="b9a8c3d27aa6638e02992c8b76fea769" category="paragraph">RVtools 출력을 사용하여 사이징 작업을 수행할 때 마력(vCPU/vmem) 스케일이 스토리지와 평행하다는 것이 항상 명백합니다. 스토리지 공간에 필요한 드라이브의 크기가 마력을 훨씬 넘어서는 상황에 처하게 되는 경우가 많습니다.</block>
  <block id="cb575e0b8e023ca0a1789ea03bdb86fd" category="paragraph">NetApp Cloud Volumes를 통합하면 간단한 마이그레이션 방식을 통해 vSphere 기반 클라우드 솔루션을 실현할 수 있습니다. 플랫폼 재구축 또는 IP 변경 없이 아키텍처 변경 없이 모든 작업을 수행할 수 있습니다. 또한 이러한 최적화를 통해 vSphere에서 호스트 수를 최소한으로 유지하면서 스토리지 설치 공간을 확장할 수 있으며, 스토리지 계층, 보안 또는 사용 가능한 파일은 변경되지 않습니다. 따라서 구축을 최적화하고 전체 TCO를 35~45% 절감할 수 있습니다. 또한 이러한 통합을 통해 스토리지를 따뜻한 스토리지에서 운영 수준의 성능으로 몇 초 이내에 확장할 수 있습니다.</block>
  <block id="9ae8084cfbf8c00bc50891fe51bb70b4" category="section-title">사용 사례 2: 클라우드 마이그레이션</block>
  <block id="40c30ee45ee11e766ec77dfd0d98cef0" category="paragraph">조직에서는 향후 임대 만료, 자본 지출(capex) 지출에서 운영 비용(opex) 지출로 전환해야 하는 재무 지침, 모든 것을 클라우드로 이동하는 하향식 등 다양한 이유로 애플리케이션을 사내 데이터 센터에서 퍼블릭 클라우드로 마이그레이션해야 한다는 압박을 받고 있습니다.</block>
  <block id="4744ec437cce262edc7110652b69ab21" category="paragraph">속도가 중요한 경우에는 클라우드의 특정 IaaS 플랫폼에 맞게 애플리케이션을 재구성하고 리팩토링하는 작업이 느리고 비용이 많이 들며 종종 몇 달이 소요되기 때문에 간소화된 마이그레이션 방식만 실현 가능합니다. NetApp Cloud Volumes를 게스트 연결 스토리지를 위한 대역폭 효율적인 SnapMirror 복제(애플리케이션 정합성이 보장된 Snapshot 복사본 및 HCX와 함께 RDM 포함, 클라우드 특정 마이그레이션(예 Azure 마이그레이션) 또는 타사 제품으로 VM 복제), 시간이 많이 소요되는 I/O 필터 메커니즘에 의존하는 것보다 훨씬 더 쉽게 전환할 수 있습니다.</block>
  <block id="d393e254c1adb8df50cfc41394c68645" category="section-title">사용 사례 3: 데이터 센터 확장</block>
  <block id="90c724dd3ba1ec0f533f7fb73a10323a" category="paragraph">데이터 센터가 특정 시기별 수요 급증 또는 지속적인 유기적 성장으로 인해 용량 제한에 도달할 경우, NetApp Cloud Volumes와 함께 클라우드 호스팅 VMware로 손쉽게 전환할 수 있습니다. NetApp Cloud Volumes를 활용하면 가용성 영역 및 동적 확장 기능에 걸쳐 고가용성을 제공하여 스토리지를 쉽게 생성, 복제 및 확장할 수 있습니다. NetApp Cloud Volumes를 활용하면 확장 클러스터의 필요성을 극복하여 호스트 클러스터 용량을 최소화할 수 있습니다.</block>
  <block id="0b95336d0f31a3bd4775f96c750bb9bc" category="section-title">사용 사례 4: 클라우드로 재해 복구</block>
  <block id="c2aee451a27e7cf3993f462ee5b760e9" category="paragraph">기존 방식에서는 재해가 발생할 경우 클라우드로 복제된 VM을 복원하기 전에 클라우드의 자체 하이퍼바이저 플랫폼으로 변환해야 합니다. 위기 상황에서 처리할 작업은 아닙니다.</block>
  <block id="772dec0515d132f26bfa87cb31b5758d" category="paragraph">퍼블릭 클라우드 가상화 솔루션과 함께 SnapCenter 및 온프레미스에서 SnapMirror 복제를 사용하여 게스트 연결 스토리지에 NetApp Cloud Volumes를 사용함으로써 재해 복구를 위한 더 나은 접근법을 고안하여, 클라우드 관련 복구 툴과 함께 완전히 일관된 VMware SDDC 인프라에서 VM 복제본을 복구할 수 있습니다(예 Azure Site Recovery) 또는 Veeam과 같은 타사 툴을 사용할 수 있습니다. 또한, 이 접근 방식을 통해 랜섬웨어에서 신속하게 재해 복구 훈련 및 복구를 수행할 수 있습니다. 또한 필요에 따라 호스트를 추가하여 테스트 또는 재해 발생 시 전체 운영 환경으로 확장할 수 있습니다.</block>
  <block id="24d0e6ab8003b406cf7e3f42363acbf5" category="section-title">사용 사례 5: 애플리케이션 현대화</block>
  <block id="59e56fb67c730af04acf8a13665cadb3" category="paragraph">퍼블릭 클라우드에 애플리케이션이 포함된 후에는 강력한 수백 가지 클라우드 서비스를 활용하여 애플리케이션을 현대화하고 확장하려고 할 것입니다. NetApp Cloud Volumes를 사용할 경우 애플리케이션 데이터가 vSAN에 종속되지 않고 Kubernetes를 포함한 광범위한 사용 사례에서 데이터를 이동할 수 있기 때문에 현대화는 쉬운 프로세스입니다.</block>
  <block id="eea420abccd820355b4bddd3524ae083" category="paragraph">All-Cloud와 하이브리드 클라우드 중 무엇을 목표로 하든 NetApp Cloud Volumes는 파일 서비스 및 블록 프로토콜과 함께 애플리케이션 워크로드를 구축 및 관리하는 데 탁월한 옵션을 제공하는 한편, 데이터 요구사항을 애플리케이션 계층에 원활하게 구현하여 TCO를 절감합니다.</block>
  <block id="cd51ff9774803e84c79e8ab19bb7ffd2" category="paragraph">어떤 사용 사례에서든 즐겨 사용하는 클라우드/하이퍼스케일러와 NetApp Cloud Volumes를 함께 사용하여 사내 및 멀티 클라우드 전체의 클라우드 이점, 일관된 인프라 및 운영을 빠르게 실현하고, 워크로드의 양방향 이동성을 제공하며, 엔터프라이즈급 용량과 성능을 실현할 수 있습니다.</block>
  <block id="2993778cba8ea9a69af4ff9dc7e18fb8" category="paragraph">스토리지를 연결하는 데 사용되는 것과 동일한 친숙한 프로세스와 절차입니다. 이는 새로운 이름으로 변경된 데이터의 위치일 뿐입니다. 도구와 프로세스는 그대로 유지되며 NetApp Cloud Volumes는 전체 구축을 최적화하는 데 도움이 됩니다.</block>
  <block id="bb01fec2870d3f698517f8471454637b" category="doc">Azure에서 가상화 환경을 구축하고 구성합니다</block>
  <block id="6a3b9d31df0a58cc23207c2af925ef0f" category="paragraph">Azure VMware 솔루션을 사용하려면 먼저 확인된 구독 내에 리소스 공급자를 등록해야 합니다.</block>
  <block id="58c59ab4d5d488609913efa7b1daaa31" category="list-text">Azure 포털에 로그인합니다.</block>
  <block id="5d704d400396fefbe3427ee665a0ec16" category="list-text">Azure 포털 메뉴에서 모든 서비스를 선택합니다.</block>
  <block id="eff35df9bedc80337261af1399e526a2" category="list-text">모든 서비스 대화 상자에서 구독을 입력한 다음 구독 을 선택합니다.</block>
  <block id="41825376d695df481d13f37e3e1587db" category="list-text">보려면 구독 목록에서 구독을 선택합니다.</block>
  <block id="4d3e5a69b8f8c0bec64cf18db73fff95" category="list-text">리소스 공급자 를 선택하고 검색에 Microsoft.AVS 를 입력합니다.</block>
  <block id="2bf384915bc11a9360bdf9792dc43bf3" category="list-text">리소스 공급자가 등록되지 않은 경우 등록 을 선택합니다.</block>
  <block id="0b4b8a7bf2e1e647f3be6dde423b9b79" category="paragraph"><block ref="0b4b8a7bf2e1e647f3be6dde423b9b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bdb08f4992bb541aec19da4c688d0239" category="paragraph"><block ref="bdb08f4992bb541aec19da4c688d0239" category="inline-image-macro-rx" type="image"></block></block>
  <block id="382da60e8008eed186472cc1a3c3ca37" category="list-text">리소스 공급자를 등록한 후 Azure 포털을 사용하여 Azure VMware Solution 프라이빗 클라우드를 생성합니다.</block>
  <block id="397065cbdc87787d17122a18f5c5088d" category="list-text">새 리소스 만들기 를 선택합니다.</block>
  <block id="39d2b5824a6dce05a74b5a60d5769656" category="list-text">Marketplace 검색 텍스트 상자에 Azure VMware Solution을 입력하고 결과에서 선택합니다.</block>
  <block id="d090262ac8690f612cbc8bd5fc83b11c" category="list-text">Azure VMware 솔루션 페이지에서 생성 을 선택합니다.</block>
  <block id="4a62c7a4f3f3f4a3927621c33c12bb63" category="list-text">기본 탭에서 필드에 값을 입력하고 검토 + 만들기를 선택합니다.</block>
  <block id="7c1ec568c35f8a03d9cfd64b465a4e4f" category="list-text">빠른 시작을 위해 계획 단계에서 필요한 정보를 수집합니다.</block>
  <block id="d61ffacba4094067e86b90bcf3739fcf" category="list-text">기존 리소스 그룹을 선택하거나 프라이빗 클라우드에 대한 새 리소스 그룹을 생성합니다. 리소스 그룹은 Azure 리소스가 배포 및 관리되는 논리적 컨테이너입니다.</block>
  <block id="81d6141ddb9ac3b3888dce83fbf00cf6" category="list-text">CIDR 주소가 고유하며 다른 Azure 가상 네트워크 또는 온-프레미스 네트워크와 겹치지 않도록 하십시오. CIDR은 프라이빗 클라우드 관리 네트워크를 나타내며 vCenter Server 및 NSX-T Manager와 같은 클러스터 관리 서비스에 사용됩니다. /22 주소 공간을 사용하는 것이 좋습니다. 이 예에서는 10.21.0.0/22 가 사용됩니다.</block>
  <block id="266811324b3ca32d24624ba571c07de8" category="paragraph"><block ref="266811324b3ca32d24624ba571c07de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd710e77504d5568fd5079361107a7eb" category="paragraph">프로비저닝 프로세스는 약 4~5시간이 소요됩니다. 프로세스가 완료된 후 Azure 포털에서 프라이빗 클라우드에 액세스하여 성공적으로 배포되었는지 확인합니다. 구축이 완료되면 성공 상태가 표시됩니다.</block>
  <block id="411f20742da0d4f8cdc568d7aee8fab3" category="paragraph">Azure VMware 솔루션 프라이빗 클라우드에는 Azure 가상 네트워크가 필요합니다. Azure VMware 솔루션은 사내 vCenter를 지원하지 않으므로 기존 사내 환경과 통합하려면 추가 단계가 필요합니다. 또한 ExpressRoute 회로 및 가상 네트워크 게이트웨이를 설정해야 합니다. 클러스터 프로비저닝이 완료될 때까지 기다리는 동안 새 가상 네트워크를 생성하거나 기존 가상 네트워크를 사용하여 Azure VMware 솔루션에 연결합니다.</block>
  <block id="aa86eba8b2b706f81a805eb35b834541" category="paragraph"><block ref="aa86eba8b2b706f81a805eb35b834541" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae6569fd64694b91a054cbdfdfef84d2" category="paragraph">새 Azure VNet(Virtual Network)을 생성하려면 Azure VNET Connect 탭을 선택합니다. 또는 가상 네트워크 생성 마법사를 사용하여 Azure 포털에서 수동으로 생성할 수도 있습니다.</block>
  <block id="34b04201ae997eaabb6802b04d5c1708" category="list-text">Azure VMware Solution 프라이빗 클라우드로 이동하고 관리 옵션 아래에서 접속 구성에 액세스합니다.</block>
  <block id="da40ae630b63a930be4e1230efc306e1" category="list-text">Azure VNET Connect를 선택합니다.</block>
  <block id="40292c219898a1253befc6301234575a" category="list-text">새 VNET를 생성하려면 Create New 옵션을 선택합니다.</block>
  <block id="f98e10d9ba9ac83ac2adeacde774d051" category="paragraph">이 기능을 사용하면 VNET를 Azure VMware Solution 프라이빗 클라우드에 연결할 수 있습니다. VNET는 Azure VMware Solution에서 ExpressRoute를 통해 생성된 프라이빗 클라우드에 필요한 구성 요소(예: 점프 박스, Azure NetApp Files와 같은 공유 서비스, 클라우드 볼륨 ONTAP)를 자동으로 생성하여 이 가상 네트워크의 워크로드 간 통신을 지원합니다.</block>
  <block id="0314a97a9eb0aae73531717ef45ad195" category="paragraph">* 참고: * VNET 주소 공간은 사설 클라우드 CIDR과 겹치지 않아야 합니다.</block>
  <block id="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="paragraph"><block ref="5f6ec3e9d299a1b94aaeb9b0e13b1071" category="inline-image-macro-rx" type="image"></block></block>
  <block id="206843027dd7ebe90f425f9ee4765a01" category="list-text">새 VNET에 대한 정보를 제공하거나 업데이트하고 OK(확인) 를 선택합니다.</block>
  <block id="26c6d54522f3fd79684f463116e9634b" category="paragraph"><block ref="26c6d54522f3fd79684f463116e9634b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="027524e66bad6099279342bf8d8f6dd4" category="paragraph">제공된 주소 범위 및 게이트웨이 서브넷이 있는 VNET는 지정된 가입 및 리소스 그룹에 생성됩니다.</block>
  <block id="5ecf2fb7501138eaa14be97a59d2a773" category="inline-link-macro">Azure에서 VMware 프라이빗 클라우드에 대한 네트워킹을 구성합니다</block>
  <block id="5da6ff60860f48de7bb7f4467c28f26f" category="admonition">VNET를 수동으로 생성하는 경우 해당 SKU와 ExpressRoute를 게이트웨이 유형으로 사용하여 가상 네트워크 게이트웨이를 생성합니다. 구축이 완료되면 인증 키를 사용하여 Azure VMware Solution 프라이빗 클라우드가 포함된 가상 네트워크 게이트웨이에 ExpressRoute 연결을 연결합니다. 자세한 내용은 을 참조하십시오 <block ref="4807c1aea8c93bde3104bd4ecfa22a07" category="inline-link-macro-rx"></block>.</block>
  <block id="5c2d9a62bb25b00981f59e22e27bfd17" category="section-title">Azure VMware Solution 프라이빗 클라우드에 대한 네트워크 연결 및 액세스 검증</block>
  <block id="40228f700f5965975e4aff8c6c2ff4b3" category="paragraph">Azure VMware 솔루션에서는 사내 VMware vCenter를 통해 프라이빗 클라우드를 관리할 수 없습니다. 대신, 점프 호스트는 Azure VMware Solution vCenter 인스턴스에 연결하는 데 필요합니다. 지정된 리소스 그룹에 점프 호스트를 생성하고 Azure VMware Solution vCenter에 로그인합니다. 이 점프 호스트는 연결을 위해 생성된 동일한 가상 네트워크의 Windows VM이고 vCenter 및 NSX Manager에 대한 액세스를 제공해야 합니다.</block>
  <block id="d88c36b93ae5dcb2646d56c57f27bf0e" category="paragraph"><block ref="d88c36b93ae5dcb2646d56c57f27bf0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="44f5524c6ac4144dbabf7a4d365b837b" category="paragraph">가상 시스템을 프로비저닝한 후에는 연결 옵션을 사용하여 RDP에 액세스합니다.</block>
  <block id="443f53614721177f7c44df93d426a919" category="paragraph"><block ref="443f53614721177f7c44df93d426a919" category="inline-image-macro-rx" type="image"></block></block>
  <block id="36cb4e54805ffde727ffbc809183608e" category="paragraph">새로 생성된 이 점프 호스트 가상 머신에서 클라우드 관리자 사용자를 사용하여 vCenter에 로그인합니다. 자격 증명에 액세스하려면 Azure 포털로 이동하여 ID로 이동합니다(프라이빗 클라우드 내의 관리 옵션 아래). 프라이빗 클라우드 vCenter 및 NSX-T Manager의 URL 및 사용자 자격 증명은 여기에서 복사할 수 있습니다.</block>
  <block id="9620acd59a8e7ad0f318754391c40c4e" category="paragraph"><block ref="9620acd59a8e7ad0f318754391c40c4e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73d88630b730fa00c46338a0aef4c2d3" category="paragraph">Windows 가상 머신에서 브라우저를 열고 vCenter 웹 클라이언트 URL로 이동합니다 <block ref="2db127a24dc88638a76677b404bda5a4" category="inline-link-rx"></block> 관리자 사용자 이름을 * cloudadmin@vsphere.loca l * 로 사용하고 복사한 암호를 붙여 넣습니다. 마찬가지로 웹 클라이언트 URL을 사용하여 NSX-T Manager에 액세스할 수도 있습니다 <block ref="bb142e18a679100de3817fcefaa25b07" category="inline-link-rx"></block> 관리자 사용자 이름을 사용하여 복사한 암호를 붙여 넣어 새 세그먼트를 만들거나 기존 계층 게이트웨이를 수정합니다.</block>
  <block id="4a6e0ba5b4d42fb0f658bdfdbbea32fc" category="admonition">웹 클라이언트 URL은 프로비저닝된 각 SDDC에 따라 다릅니다.</block>
  <block id="49848931415b32db238a2dd1daddf3a7" category="paragraph"><block ref="49848931415b32db238a2dd1daddf3a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="87f65f698ac6bac1ada03193e1cdabb8" category="paragraph"><block ref="87f65f698ac6bac1ada03193e1cdabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec3eeb836273dbc92b27ce718a90b212" category="inline-link-macro">온프레미스 환경을 Azure VMware 솔루션에 대해 알아보십시오</block>
  <block id="097529edf2feb9ed1237427eaa3b2599" category="paragraph">이제 Azure VMware Solution SDDC가 구축 및 구성되었습니다. ExpressRoute Global Reach를 활용하여 사내 환경을 Azure VMware 솔루션 프라이빗 클라우드에 연결합니다. 자세한 내용은 을 참조하십시오 <block ref="29749340a5d7bf5df1867a3f2d2723a1" category="inline-link-macro-rx"></block>.</block>
  <block id="5f1bd6ade489565bebba9a771b93fe70" category="paragraph">하이브리드 클라우드 또는 클라우드 우선 구축을 계획할 때 IT 조직에 중요한 사용 사례에 대한 개요입니다.</block>
  <block id="0812fc943ecbd9a54d88fb25729d0aa5" category="section-title">보편적인 사용 사례</block>
  <block id="f136615e6f2c1b330afb72bf4a45b4a4" category="paragraph">사용 사례는 다음과 같습니다.</block>
  <block id="3481fb80f122383c65ff8c6c8fd8c943" category="list-text">재해 복구,</block>
  <block id="4127bac8297e2af8866315910651ce47" category="list-text">데이터 센터 유지 관리 중에 워크로드를 호스팅 * 로컬 데이터 센터에서 프로비저닝되는 것 이상의 추가 리소스가 필요한 빠른 증가,</block>
  <block id="20b1c73b5938d2d878aa1d96fee7f1b2" category="list-text">VMware 사이트 확장,</block>
  <block id="5fe13b2b805496310dbaa281d7325877" category="list-text">클라우드로 신속하게 마이그레이션,</block>
  <block id="b278a6d011d590bb350b9cb81c21a732" category="list-text">개발/테스트, 및</block>
  <block id="bc262005b263505cc0464e05c4324687" category="section-title">IT의 여정</block>
  <block id="cfdb9aabb4aedf8cad2e330ba5a516a3" category="paragraph">대부분의 조직은 혁신과 현대화를 향한 여정을 진행 중입니다. 이 프로세스의 일환으로 기업들은 기존 VMware 투자를 활용하는 동시에 클라우드의 이점을 활용하고 마이그레이션 프로세스를 최대한 원활하게 만드는 방법을 모색하고 있습니다. 이 접근 방식은 데이터가 이미 클라우드에 있기 때문에 현대화에 대한 노력을 매우 쉽게 할 수 있습니다.</block>
  <block id="0362604333fcf179ebf8b873f8f8c0ec" category="paragraph">다음 시나리오를 생각해 봅시다.</block>
  <block id="b401aa039e47ba98bfaca10532e40d08" category="paragraph">고객은 CPU와 메모리에 대해 5개의 호스트만 필요로 하지만 스토리지 요구 사항이 많으므로 스토리지 요구 사항을 충족하기 위해 12개의 호스트가 필요합니다. 이 요구사항은 스토리지를 증가하기만 하면 되는 추가 마력을 구매해야 하는 만큼 재무 규모를 넘어주는 결과를 제공합니다.</block>
  <block id="7c25e9d8a9748905f5d456e20a93b413" category="paragraph">클라우드 도입 및 마이그레이션을 계획할 때는 항상 최상의 접근 방식을 평가하고 총 투자 비용을 절감하는 가장 쉬운 방법을 찾는 것이 중요합니다. 모든 애플리케이션 마이그레이션의 가장 일반적이고 쉬운 방법은 가상 머신(VM) 또는 데이터 변환이 없는 재호스팅(리프트 및 변속이라고도 함)입니다. NetApp Cloud Volumes를 VMware SDDC(소프트웨어 정의 데이터 센터)와 함께 사용하는 동시에 vSAN을 보완하는 것은 쉬운 전환 옵션을 제공합니다.</block>
  <block id="3d45b043c5518eca1e47fb4ba8a813da" category="inline-link-macro">RHEL/CentOS에서 CLI 배포를 위해 Ansible Control Node를 설정합니다</block>
  <block id="2afb5cc3404c6c8162722fd41895c2de" category="inline-link-macro">Ubuntu/Debian에서 CLI 배포를 위해 Ansible Control Node를 설정합니다</block>
  <block id="6b8c64be0bad88fb867c6576ac777b25" category="inline-link-macro">타워/AWX 배포용으로 Ansible 타워 또는 AWX를 설치합니다</block>
  <block id="e9dcec3e531a3cec5ee733f23baab91d" category="inline-link-macro">NFS 기반 ONTAP용 Oracle 19c의 자동 구축</block>
  <block id="9efcc0ad3c93b238cc0495e3c87b715f" category="inline-link-macro">Ansible을 사용하여 FlexPod에 Oracle 19c RAC 구축 자동화</block>
  <block id="8d7efa937e97b1a8187ff8f122d9732a" category="inline-link-macro">클라우드 기반 VMware 구축을 위한 스토리지 최적화</block>
  <block id="5a6bd3a9e0048284caf2b5f521d90959" category="list-text"><block ref="5a6bd3a9e0048284caf2b5f521d90959" category="inline-link-macro-rx"></block></block>
  <block id="00d07ce14f227693b9dabba2f52b53a5" category="inline-link-macro">NetApp 기반 클라우드 오퍼링을 사용하여 Azure VMware 솔루션을 시작하십시오</block>
  <block id="ac66988ead29ba5f4ed32ec3894527e7" category="list-text"><block ref="ac66988ead29ba5f4ed32ec3894527e7" category="inline-link-macro-rx"></block></block>
  <block id="dca91c3343cc0ad062506cdd14eb7d41" category="summary">하이브리드 클라우드, 데스크탑 가상화 및 컨테이너 솔루션 자료에 대한 최신 추가 정보</block>
  <block id="120c02d2aa6cda1e3b75902fb4fc0b53" category="doc">하이브리드 클라우드, 데스크탑 가상화 및 컨테이너 솔루션의 새로운 기능</block>
  <block id="07e257430bade6bc5bce1c2170c6fc0d" category="paragraph">최신 하이브리드 클라우드, 데스크탑 가상화 및 컨테이너 솔루션 및 솔루션 자료 개요</block>
  <block id="c1e392a90896851b3319d6075402fd4d" category="cell">* 하이브리드/프라이빗 클라우드 *</block>
  <block id="526cee55e2936716b5481f8a933bd217" category="inline-link-macro">NetApp 및 VMware Tanzu Basic에서 VVOL을 사용하는 방법 1부</block>
  <block id="c2240101c5a3a188541ce87c59265df9" category="cell"><block ref="c2240101c5a3a188541ce87c59265df9" category="inline-link-macro-rx"></block></block>
  <block id="2e933c421900ce4ed68883bfdf00a487" category="inline-link-macro">NetApp 및 VMware Tanzu Basic에서 VVOL을 사용하는 방법, 2부</block>
  <block id="fe72963b1d3021a9f6d8ae34414601c3" category="cell"><block ref="fe72963b1d3021a9f6d8ae34414601c3" category="inline-link-macro-rx"></block></block>
  <block id="4c1c4ad5c7782eafb30ad4704dbf4419" category="inline-link-macro">NetApp 및 VMware Tanzu Basic에서 VVOL을 사용하는 방법, 3부</block>
  <block id="4d066173d8401c92a19650e99dcaae5d" category="cell"><block ref="4d066173d8401c92a19650e99dcaae5d" category="inline-link-macro-rx"></block></block>
  <block id="8ef4e9c7260e8d314760329e07c618ae" category="cell">* 가상화 *</block>
  <block id="2bdc87f51d413e6d2fa23dd26238501f" category="inline-link-macro">ONTAP용 VMware vSphere</block>
  <block id="1f23e5de73e650f12cbafec55d8a98cd" category="cell"><block ref="1f23e5de73e650f12cbafec55d8a98cd" category="inline-link-macro-rx"></block></block>
  <block id="236122c6ab4c764632437a76fa95e5c0" category="cell">* 데스크탑 가상화 *</block>
  <block id="4b47c65474ab7fae9b08ddf38d598971" category="inline-link-macro">NetApp VDS(가상 데스크톱 서비스)가 포함된 하이브리드 클라우드 VDI</block>
  <block id="dea91bec9e85387a496bb2c228fc7dc3" category="cell"><block ref="dea91bec9e85387a496bb2c228fc7dc3" category="inline-link-macro-rx"></block></block>
  <block id="1ebfe0d8e53e3f7f2c37e8b3835c2adf" category="cell">* 컨테이너 *</block>
  <block id="5df9589990c71ed42c69a8bcc053d0d4" category="inline-link-macro">비디오: NetApp Astra Control을 활용하여 사후 분석 및 애플리케이션 복원을 수행합니다</block>
  <block id="51d1589966ca772274944bc0cd6b15bc" category="cell"><block ref="51d1589966ca772274944bc0cd6b15bc" category="inline-link-macro-rx"></block></block>
  <block id="72feee9e055adc523c4c9ca3c1453409" category="inline-link-macro">비디오: Astra Control을 통해 CI/CD 파이프라인에서 데이터 보호</block>
  <block id="3bf54df2b09b6352059075c261817bd0" category="cell"><block ref="3bf54df2b09b6352059075c261817bd0" category="inline-link-macro-rx"></block></block>
  <block id="6be5bc354916244292cf704d8a451541" category="inline-link-macro">비디오: Astra Control Center를 사용한 워크로드 마이그레이션 - NetApp의 Red Hat OpenShift</block>
  <block id="b0fd8947f538fb2988e86d35bac6d6fa" category="cell"><block ref="b0fd8947f538fb2988e86d35bac6d6fa" category="inline-link-macro-rx"></block></block>
  <block id="306a916d056a0d0a4b898b9dca9692ee" category="inline-link-macro">Red Hat OpenShift 기반 NetApp Astra Control Center</block>
  <block id="20c49a9a4d903fa259d4f8820b3755d2" category="cell"><block ref="20c49a9a4d903fa259d4f8820b3755d2" category="inline-link-macro-rx"></block></block>
  <block id="c0a8420c339dd9d57d40448c30a749df" category="inline-link-macro">비디오: NetApp의 Astra Trident 및 SnapMirror-Red Hat OpenShift를 사용하여 워크로드 마이그레이션</block>
  <block id="a43d8fe0429e313d082e6919f1fd2b75" category="cell"><block ref="a43d8fe0429e313d082e6919f1fd2b75" category="inline-link-macro-rx"></block></block>
  <block id="4c37a5afd480a0042f69d7628cadd57d" category="inline-link-macro">NetApp OpenShift를 사용한 Kubernetes용 고급 클러스터 관리</block>
  <block id="119ad672b0d69ab3f968877b6ec83dd3" category="cell"><block ref="119ad672b0d69ab3f968877b6ec83dd3" category="inline-link-macro-rx"></block></block>
  <block id="65cd53ff19e601ea00bf9688be4dd86a" category="inline-link-macro">NetApp ONTAP 기반의 Red Hat OpenShift 가상화</block>
  <block id="ad1cf94aab71c9962e22037ed60d41e9" category="cell"><block ref="ad1cf94aab71c9962e22037ed60d41e9" category="inline-link-macro-rx"></block></block>
  <block id="762a14964ee1713d320b8beefaf55b17" category="inline-link-macro">비디오: OpenShift 가상화 설치 - NetApp과 함께 Red Hat OpenShift</block>
  <block id="5ac70ba9dc4ef90bfb3a829919c8044d" category="cell"><block ref="5ac70ba9dc4ef90bfb3a829919c8044d" category="inline-link-macro-rx"></block></block>
  <block id="aad993afc3c78a3a38ae471fa2ae1060" category="inline-link-macro">비디오: OpenShift 가상화를 통한 가상 머신 구축 - NetApp과 함께 Red Hat OpenShift</block>
  <block id="1c9dc04aa9e0e0aaf52a33af61d8d630" category="cell"><block ref="1c9dc04aa9e0e0aaf52a33af61d8d630" category="inline-link-macro-rx"></block></block>
  <block id="e6ba927c9d14295015e39be05cf54040" category="inline-link-macro">NetApp ONTAP 기반 Red Hat OpenShift의 멀티 테넌시</block>
  <block id="ab439bcac737f2565970fe2612976b75" category="cell"><block ref="ab439bcac737f2565970fe2612976b75" category="inline-link-macro-rx"></block></block>
  <block id="ad95c47343e102dc30ec33fa6f1ccc55" category="inline-link-macro">NetApp을 사용한 NVA-1160-Red Hat OpenShift</block>
  <block id="1043b5153afff839b84d714aa9127913" category="cell"><block ref="1043b5153afff839b84d714aa9127913" category="inline-link-macro-rx"></block></block>
  <block id="0fd00a19fb12bb899dfe7cefbcbbcb79" category="inline-link-macro">Red Hat OpenShift에 NetApp Trident 설치 – Docker의 'toomanyrequest' 문제를 해결하는 방법!</block>
  <block id="43e5d9153d1fc4a35be5f57189605919" category="cell"><block ref="43e5d9153d1fc4a35be5f57189605919" category="inline-link-macro-rx"></block></block>
  <block id="da38226e07ff21f147182bb08be38f6f" category="inline-link-macro">NetApp의 Anthos Bare Metal</block>
  <block id="ac1da2af455fc001ba8b58af0e62d151" category="cell"><block ref="ac1da2af455fc001ba8b58af0e62d151" category="inline-link-macro-rx"></block></block>
  <block id="750b570f7c6cacf7b9f43c1c7919ad96" category="inline-link-macro">AI 블로그: thePub</block>
  <block id="183754618306c7f8d7df04f981d234f0" category="list-text"><block ref="183754618306c7f8d7df04f981d234f0" category="inline-link-macro-rx"></block></block>
  <block id="e9c44bbfd795a5d63d74c6a77afee70d" category="summary">법적 고지 사항은 저작권 선언, 상표, 특허 등에 대한 액세스를 제공합니다.</block>
  <block id="30d965eef5ba25c6b9998ae38270b43e" category="doc">법적 고지</block>
  <block id="6016a2b341113bf496b719905398ecd2" category="section-title">저작권</block>
  <block id="09e95b77ffe81fe465a83ba99efad5c8" category="paragraph"><block ref="09e95b77ffe81fe465a83ba99efad5c8" category="inline-link-rx"></block></block>
  <block id="126a02652da6de02962cf1b654fd6376" category="section-title">상표</block>
  <block id="c4ce4761e466527d26b3e3d5ed1006fd" category="paragraph">NetApp, NetApp 로고, NetApp 상표 페이지에 나열된 마크는 NetApp Inc.의 상표입니다. 기타 회사 및 제품 이름은 해당 소유자의 상표일 수 있습니다.</block>
  <block id="7aa531e9acfe2b98e34d2c92fe9846ff" category="paragraph"><block ref="7aa531e9acfe2b98e34d2c92fe9846ff" category="inline-link-rx"></block></block>
  <block id="be89498d2f8a22ce47c02ba9795fe2af" category="section-title">특허</block>
  <block id="d0b19d36be2c5f16e9aef46c8a452d3d" category="paragraph">NetApp 소유 특허 목록은 다음 사이트에서 확인할 수 있습니다.</block>
  <block id="d7f1fbcf9ce4e42f705add574d262b2c" category="paragraph"><block ref="d7f1fbcf9ce4e42f705add574d262b2c" category="inline-link-rx"></block></block>
  <block id="56c34c6410dd45c5cec44149ad0ce037" category="section-title">개인 정보 보호 정책</block>
  <block id="fc248f74f5e36542f7f5627b8610e9a3" category="paragraph"><block ref="fc248f74f5e36542f7f5627b8610e9a3" category="inline-link-rx"></block></block>
  <block id="c0227cef6f07a8cd2ac72f2945b031aa" category="section-title">오픈 소스</block>
  <block id="9b73989307c1975dfa4d5e1581e4afe8" category="paragraph">통지 파일은 NetApp 소프트웨어에 사용된 타사의 저작권 및 라이센스에 대한 정보를 제공합니다.</block>
  <block id="c8d20ce0b6bb23d912f3368f706d5794" category="summary">NetApp 솔루션은 고객의 가장 중요한 비즈니스 요구사항을 지원하기 위해 NetApp 제품 및 서비스 포트폴리오를 강조하는 전략적 및 기술 역량 집합입니다.</block>
  <block id="fcf140abed196b8eba71c45f21312bce" category="doc">NetApp 솔루션</block>
  <block id="14c4dbb7c61081eee1c499c4cf138c96" category="inline-link-macro">FC를 통해 Cisco UCS 및 NetApp AFF A800을 사용하는 FlexPod 데이터 센터에서 Oracle 19c RAC 데이터베이스</block>
  <block id="760b7d532df381143dc946fd59bf0b62" category="inline-link-macro">Azure NetApp Files 기반 SQL Server</block>
  <block id="33be49f7ebc56eb7d336a201f7ac0df6" category="inline-link-macro">Azure NetApp Files 기반 SAP</block>
  <block id="e131204502a58630f2f72937238604c8" category="section-title">비디오/데모</block>
  <block id="2b1dd692c0da980c4ec2ad9fd523c47d" category="inline-link-macro">Azure NetApp Files의 SQL 고가용성 클러스터</block>
  <block id="95e5ff389c2796a171f904ad5b9322f6" category="list-text">NetApp 및 VMware Cloud Foundation(VCF)</block>
  <block id="81cd1d42ffdb75544144e24cf0f8dc54" category="inline-link-macro">1부: 시작하기</block>
  <block id="837bbffc16dc6e344470df1114a13c87" category="list-text"><block ref="837bbffc16dc6e344470df1114a13c87" category="inline-link-macro-rx"></block></block>
  <block id="0437c596200f9be8466a3200f5cf2438" category="inline-link-macro">2부: VCF 및 ONTAP 주 저장소</block>
  <block id="e361fc9a6477c5857207bca25b3d797f" category="list-text"><block ref="e361fc9a6477c5857207bca25b3d797f" category="inline-link-macro-rx"></block></block>
  <block id="14c9e898417d6b3caceb9c60335c4bb3" category="inline-link-macro">3부: VCF 및 Element Principal storage</block>
  <block id="aa37de763ea804c1fb3fe637fb6ee5ef" category="list-text"><block ref="aa37de763ea804c1fb3fe637fb6ee5ef" category="inline-link-macro-rx"></block></block>
  <block id="fbbcbe8b70235742e3e6aa656c7815d9" category="inline-link-macro">4부: VMware용 ONTAP 툴 및 보조 스토리지</block>
  <block id="de8f12d6d2f85119918d1bbb774d43c8" category="list-text"><block ref="de8f12d6d2f85119918d1bbb774d43c8" category="inline-link-macro-rx"></block></block>
  <block id="ec7f98a3714557d87968dc6a898f7912" category="inline-link-macro">ONTAP와 함께 VMware Tanzu를 사용하여 Kubernetes 여정을 가속화하십시오</block>
  <block id="32e124b0349f41e06bf1e03f11950665" category="list-text"><block ref="32e124b0349f41e06bf1e03f11950665" category="inline-link-macro-rx"></block></block>
  <block id="c5cd657df037c277c37216b73efb0b08" category="summary">가능하면 항상 ONTAP 툴을 사용하여 데이터 저장소와 볼륨을 프로비저닝하십시오. 이렇게 하면 볼륨, 접합 경로, LUN, igroup, 엑스포트 정책이 및 기타 설정은 호환되는 방식으로 구성됩니다.</block>
  <block id="d3b26e9021e83573a3d2a9050400a33a" category="doc">운영 모범 사례</block>
  <block id="f02207fb26160d7e47cf5ea35d07df03" category="section-title">데이터 저장소 및 프로토콜</block>
  <block id="4d15db58f26b374b36c283df6b5a5fc1" category="paragraph">SRM은 SRA를 통해 어레이 기반 복제를 사용할 때 ONTAP 9를 통해 iSCSI, 파이버 채널 및 NFS 버전 3을 지원합니다. SRM은 기존 데이터 저장소 또는 VVOL 데이터 저장소를 사용하는 NFS 버전 4.1에 대한 어레이 기반 복제를 지원하지 않습니다.</block>
  <block id="61f54ceeb0338787a2ee2d801cbc62cd" category="paragraph">접속을 확인하려면 항상 대상 ONTAP 클러스터에서 DR 사이트의 새 테스트 데이터 저장소를 마운트하고 마운트 해제할 수 있는지 확인하십시오. 데이터 저장소 연결에 사용할 각 프로토콜을 테스트합니다. 모범 사례는 ONTAP 툴을 사용하여 테스트 데이터 저장소를 생성하는 것입니다. 이는 SRM의 지시에 따라 모든 데이터 저장소 자동화를 수행하기 때문입니다.</block>
  <block id="0ac3e8abbf45a28af68d22b0f59a973e" category="paragraph">SAN 프로토콜은 각 사이트에서 동종이어야 합니다. NFS와 SAN을 혼합할 수 있지만 SAN 프로토콜을 사이트 내에서 혼합하면 안 됩니다. 예를 들어 사이트 A에서는 FCP를, 사이트 B에서는 iSCSI를 사용할 수 있습니다 사이트 A에서 FCP와 iSCSI를 둘 다 사용해서는 안 됩니다 그 이유는 SRA가 복구 사이트에 혼합 igroup을 생성하지 않으며 SRM은 SRA에 제공된 이니시에이터 목록을 필터링하지 않기 때문입니다.</block>
  <block id="150f8d9d5018ff00285d9aa158451d7b" category="paragraph">이전 가이드에서는 LIF와 데이터 지역성을 만드는 것이 좋습니다. 다시 말해, 볼륨을 물리적으로 소유한 노드에 있는 LIF를 사용하여 데이터 저장소를 항상 마운트합니다. 이는 ONTAP 9의 최신 버전에서 더 이상 필요하지 않습니다. 가능할 때마다 그리고 클러스터 범위 자격 증명이 제공되는 경우 ONTAP 툴은 여전히 데이터에 대한 로컬 LIF의 로드 밸런싱을 수행하지만, 고가용성과 성능이 반드시 필요한 것은 아닙니다.</block>
  <block id="ef6e8713285283721507f92e3c3ec674" category="paragraph">자동 크기 조정이 필요한 비상 용량을 충분히 제공하지 못하는 경우 공간 부족 상태에 있는 경우 가동 시간을 유지하기 위해 스냅샷 복사본을 자동으로 제거하도록 NetApp ONTAP 9를 구성할 수 있습니다. 이 기능의 기본 설정은 SnapMirror에서 만든 스냅샷 복사본을 자동으로 삭제하지 않습니다. SnapMirror Snapshot 복사본이 삭제된 경우 NetApp SRA는 영향을 받는 볼륨의 복제를 역으로 재동기화할 수 없습니다. ONTAP에서 SnapMirror 스냅샷 복사본을 삭제하지 않도록 하려면 스냅샷 자동 삭제 기능을 시험 사용 으로 구성하십시오.</block>
  <block id="774a065cb3548cc61fb0ec3bc1494fbe" category="inline-link">ONTAP 9 문서 센터</block>
  <block id="a4f47f677f45e1e7075186d98e4f3ec1" category="paragraph">SAN 데이터 저장소가 포함된 볼륨의 경우 볼륨 자동 크기 조정을 '확대'로 설정하고 NFS 데이터 저장소의 경우 'grow_shrink'로 설정해야 합니다. 을 참조하십시오<block ref="ee2474fa4563985f2f3ebe16d4e1ab3a" category="inline-link-rx"></block> 특정 구문입니다.</block>
  <block id="e6955db66b8dc4aee170ebdb0b560249" category="section-title">SPBM 및 VVol</block>
  <block id="3077a08ffed60acebf18d37874130d44" category="paragraph">SRM 8.3부터는 VVOL 데이터 저장소를 사용한 VM 보호가 지원됩니다. 다음 스크린샷과 같이 ONTAP 도구 설정 메뉴에서 VVOL 복제가 활성화된 경우 VASA Provider가 SnapMirror 스케줄을 VM 스토리지 정책에 표시합니다.</block>
  <block id="399c1894baf71c0529aa0fba66ea18fb" category="paragraph">다음 예에서는 VVOL 복제 기능을 보여줍니다.</block>
  <block id="b180e7f35111dca8acd6c56cdbcabb3e" category="paragraph"><block ref="b180e7f35111dca8acd6c56cdbcabb3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="be41c3baf700984021c43e2e6b661b0a" category="paragraph">다음 스크린샷에서는 VM 스토리지 정책 생성 마법사에 표시되는 SnapMirror 일정의 예를 보여 줍니다.</block>
  <block id="43c130b36e9e2b3d61409aa974f89fc7" category="paragraph"><block ref="43c130b36e9e2b3d61409aa974f89fc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6292d9eb6ea467a3c3560a65b7f63b5" category="paragraph">ONTAP VASA Provider는 이기종 스토리지로의 페일오버를 지원합니다. 예를 들어, 시스템은 에지 위치의 ONTAP Select에서 코어 데이터 센터의 AFF 시스템으로 페일오버할 수 있습니다. 스토리지의 유사성에 관계없이 항상 복제 가능 VM 스토리지 정책에 대한 스토리지 정책 매핑 및 역매핑을 구성하여 복구 사이트에서 제공되는 서비스가 기대 사항 및 요구 사항을 충족하는지 확인해야 합니다. 다음 스크린샷에서는 샘플 정책 매핑을 보여 줍니다.</block>
  <block id="783a951245ce43eb84161804072a38c6" category="paragraph"><block ref="783a951245ce43eb84161804072a38c6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1eb90dc8f7adfd00c74af3b815e2ac15" category="section-title">VVOL 데이터 저장소의 복제된 볼륨을 생성합니다</block>
  <block id="18231879821321e0aed7de84fe876766" category="paragraph">이전 VVOL 데이터 저장소와 달리 복제된 VVOL 데이터 저장소는 복제를 활성화한 상태로 처음부터 생성해야 하며 SnapMirror 관계가 있는 ONTAP 시스템에서 미리 생성된 볼륨을 사용해야 합니다. 이를 위해서는 클러스터 피어링 및 SVM 피어링 같은 요소를 사전에 구성해야 합니다. 이러한 작업은 ONTAP 관리자가 수행해야 합니다. 따라서 여러 사이트에서 ONTAP 시스템을 관리하는 사람과 vSphere 운영을 주로 담당하는 사이트 간에 책임을 엄격하게 분리할 수 있습니다.</block>
  <block id="0a8c8293003bf411817ef3cedf18a2a9" category="paragraph">vSphere 관리자 대신 새로운 요구 사항이 적용됩니다. 볼륨은 ONTAP 도구의 범위를 벗어나 생성되므로 정기적으로 예약된 재검색 기간까지 ONTAP 관리자가 수행한 변경 사항을 인식하지 못합니다. 이러한 이유로 VVOL과 함께 사용할 볼륨 또는 SnapMirror 관계를 만들 때마다 항상 재검색을 실행하는 것이 모범 사례입니다. 다음 스크린샷과 같이 호스트 또는 클러스터를 마우스 오른쪽 버튼으로 클릭하고 NetApp ONTAP tools &gt; Update Host and Storage Data를 선택하면 됩니다.</block>
  <block id="dd5e006520a09e3975e52f6fb8991fd2" category="paragraph"><block ref="dd5e006520a09e3975e52f6fb8991fd2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="550d51e15336d4a33bcbb0f26a6810f7" category="paragraph">VVOL 및 SRM의 경우 한 가지 주의해야 합니다. 보호 VM과 보호되지 않은 VM을 동일한 VVOL 데이터 저장소에 혼합하지 마십시오. 그 이유는 SRM을 사용하여 DR 사이트로 페일오버할 때 보호 그룹에 속한 VM만 DR에서 온라인 상태로 전환되기 때문입니다. 따라서 SnapMirror를 DR에서 운영 환경으로 다시 되돌릴 때 페일오버되지 않은 VM을 덮어쓰거나 중요한 데이터를 포함할 수 있습니다.</block>
  <block id="6d717f70d89096b731dfc63d7a1379e1" category="section-title">스토리지 쌍 정보</block>
  <block id="6dd3f3008fe81f402905b00c8dca007c" category="paragraph">각 스토리지 쌍에 대해 스토리지 관리자가 생성됩니다. SRM 및 ONTAP 툴을 사용하면 클러스터 자격 증명을 사용해도 SVM의 범위에서 각 어레이 페어링을 수행할 수 있습니다. 따라서 각 테넌트가 관리하기 위해 할당된 SVM에 따라 테넌트 간에 DR 워크플로우를 분할할 수 있습니다. 따라서 특정 클러스터에 대해 여러 어레이 관리자를 생성할 수 있으며 이는 본질적으로 비대칭입니다. 서로 다른 ONTAP 9 클러스터 간에 팬아웃 또는 팬할 수 있습니다. 예를 들어, 클러스터 1의 SVM-A 및 SVM-B를 클러스터 2의 SVM-C, 클러스터 3의 SVM-D 또는 그 반대로 복제할 수 있습니다.</block>
  <block id="2219228418c053eb593ce0a1f318da47" category="paragraph">SRM에서 어레이 쌍을 구성할 때는 항상 ONTAP 툴에 추가한 것과 같은 방법으로 SRM에 어레이 쌍을 추가해야 합니다. 즉, 이들은 동일한 사용자 이름, 암호 및 관리 LIF를 사용해야 합니다. 이 요구 사항은 SRA가 어레이와 제대로 통신하도록 보장합니다. 다음 스크린샷은 ONTAP 툴에 클러스터가 표시되는 방식과 이를 어레이 관리자에 추가하는 방법을 보여 줍니다.</block>
  <block id="7ec48584a43ed8a9b1dda55398d97cf4" category="paragraph"><block ref="7ec48584a43ed8a9b1dda55398d97cf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b34135c8c4d2b14ceb7ebf595f00193" category="section-title">복제 그룹 정보</block>
  <block id="6be59afd3c8bb91501f55a7e77ebe794" category="paragraph">복제 그룹에는 함께 복구되는 가상 머신의 논리적 컬렉션이 포함됩니다. ONTAP 툴 VASA Provider는 자동으로 복제 그룹을 생성합니다. ONTAP SnapMirror 복제는 볼륨 레벨에서 수행되기 때문에 볼륨의 모든 VM이 동일한 복제 그룹에 속해 있습니다.</block>
  <block id="b57ec021fce4e5261ba61df6f0c013af" category="paragraph">복제 그룹과 FlexVol 볼륨 간에 VM을 배포하는 방법은 여러 가지 요소를 고려해야 합니다. 같은 볼륨에서 유사한 VM을 그룹화하면 집계 수준 중복 제거 기능이 없는 이전 ONTAP 시스템에서 스토리지 효율성이 향상되지만 그룹화는 볼륨 크기를 증가시키고 볼륨 I/O 동시성을 줄입니다. 최신 ONTAP 시스템에서는 동일한 애그리게이트에서 FlexVol 볼륨 전체에 VM을 분산하여 애그리게이트 레벨의 중복제거를 활용하고 여러 볼륨 간에 I/O 병렬 처리를 더 효율적으로 수행할 수 있습니다. 아래에 설명된 보호 그룹에 여러 복제 그룹이 포함될 수 있으므로 볼륨에서 VM을 함께 복구할 수 있습니다. 이 레이아웃의 단점은 볼륨 SnapMirror에서는 애그리게이트 중복제거가 적용되지 않으므로 블록을 여러 번 유선으로 전송할 수 있다는 것입니다.</block>
  <block id="c727c1020d3128dd7495a6e3e6f23736" category="paragraph">복제 그룹에 대한 마지막 고려 사항은 각 그룹이 기본적으로 논리적 정합성 보장 그룹이라는 점입니다(SRM 정합성 보장 그룹과 혼동하지 마십시오). 볼륨의 모든 VM이 동일한 스냅샷을 사용하여 함께 전송되기 때문입니다. 따라서 VM이 서로 일치해야 하는 경우 동일한 FlexVol에 VM을 저장하는 것이 좋습니다.</block>
  <block id="9f8a350a2113ea4be6b4e5e5112514a3" category="section-title">보호 그룹 정보</block>
  <block id="df77671ab2743af7f1d1457c200eb12c" category="paragraph">보호 그룹은 보호 사이트에서 함께 복구되는 그룹으로 VM 및 데이터 저장소를 정의합니다. 보호 사이트는 정상적인 정상 상태 작업 중에 보호 그룹에 구성된 VM이 존재하는 곳입니다. SRM이 보호 그룹에 대해 여러 스토리지 관리자를 표시할 수 있지만 보호 그룹은 여러 스토리지 관리자를 포괄할 수 없습니다. 따라서 서로 다른 SVM의 데이터 저장소에 VM 파일을 확장해서는 안 됩니다.</block>
  <block id="b148467d645c3613c1c7a2607764c515" category="section-title">복구 계획에 대해 설명합니다</block>
  <block id="fd28cd9834ad3aa213c4fec2881064b5" category="paragraph">복구 계획은 동일한 프로세스에서 복구할 보호 그룹을 정의합니다. 동일한 복구 계획에서 여러 보호 그룹을 구성할 수 있습니다. 또한 복구 계획 실행을 위한 추가 옵션을 사용하기 위해 단일 보호 그룹을 여러 복구 계획에 포함할 수 있습니다.</block>
  <block id="77aa84394124509e5e4006dcfd18789f" category="paragraph">복구 계획을 사용하면 SRM 관리자가 우선 순위 그룹에 VM을 1(가장 높음)에서 5(가장 낮음)까지 할당하고 3(중간)을 기본값으로 지정하여 복구 워크플로를 정의할 수 있습니다. 우선 순위 그룹 내에서 VM을 종속성에 맞게 구성할 수 있습니다.</block>
  <block id="6d72567442b1f361e3c0e89cbc7dfd6a" category="paragraph">예를 들어, 데이터베이스에 Microsoft SQL Server를 사용하는 Tier-1 비즈니스 크리티컬 애플리케이션을 보유하고 있을 수 있습니다. 따라서 우선 순위 그룹 1에 VM을 배치하기로 결정합니다. 우선 순위 그룹 1 내에서 서비스를 가져오기 위한 주문 계획을 시작합니다. Microsoft SQL Server 전에 Microsoft Windows 도메인 컨트롤러가 부팅되기를 원할 것입니다. 이 경우 응용 프로그램 서버 이전에 온라인 상태가 되어야 합니다. 이러한 모든 VM을 우선 순위 그룹에 추가한 다음 종속성을 설정합니다. 종속성은 지정된 우선 순위 그룹 내에서만 적용되기 때문입니다.</block>
  <block id="030d749269f8866de516a551b0286001" category="paragraph">NetApp은 애플리케이션 팀과 협력하여 페일오버 시나리오에 필요한 운영 순서를 파악하고 그에 따라 복구 계획을 수립하는 것이 좋습니다.</block>
  <block id="cebb1167d3e78885137c837f0abf8026" category="section-title">테스트 대체 작동</block>
  <block id="2772828493452c4a2ff21f8b2b66a1a7" category="paragraph">모범 사례로서, 보호된 VM 스토리지의 구성을 변경할 때마다 항상 테스트 페일오버를 수행하십시오. 이렇게 하면 재해가 발생할 경우 Site Recovery Manager가 예상 RTO 목표 내에서 서비스를 복구할 수 있다는 것을 신뢰할 수 있습니다.</block>
  <block id="6ae8acfc86f5df3426d525fb95767506" category="paragraph">또한, 특히 VM 스토리지를 재구성한 후에는 게스트 내 애플리케이션 기능을 확인하는 것이 좋습니다.</block>
  <block id="bd47371bcd8b3d08d6b4b15481b08d93" category="paragraph">테스트 복구 작업이 수행되면 VM에 대한 전용 테스트 버블 네트워크가 ESXi 호스트에 생성됩니다. 그러나 이 네트워크는 물리적 네트워크 어댑터에 자동으로 연결되지 않으므로 ESXi 호스트 간에 연결을 제공하지 않습니다. DR 테스트 중에 서로 다른 ESXi 호스트에서 실행 중인 VM 간의 통신을 허용하기 위해 DR 사이트의 ESXi 호스트 간에 물리적 전용 네트워크가 생성됩니다. 테스트 네트워크가 전용인지 확인하기 위해 테스트 버블 네트워크를 물리적으로 또는 VLAN 또는 VLAN 태깅을 사용하여 분리할 수 있습니다. VM이 복구될 때 실제 운영 시스템과 충돌할 수 있는 IP 주소를 사용하여 운영 네트워크에 배치할 수 없으므로 이 네트워크를 운영 네트워크와 분리해야 합니다. SRM에서 복구 계획을 생성할 때 생성된 테스트 네트워크를 테스트 중에 VM을 연결할 전용 네트워크로 선택할 수 있습니다.</block>
  <block id="2be58fc410ddf2ba9c350135a617944a" category="paragraph">테스트를 검증하고 더 이상 필요하지 않은 후에는 정리 작업을 수행합니다. 정리 작업을 실행하면 보호된 VM이 초기 상태로 돌아가고 복구 계획이 준비 상태로 재설정됩니다.</block>
  <block id="6f07b53963ee80903f0f13654de2cc3a" category="section-title">페일오버 고려 사항</block>
  <block id="9d33d94019b4a595a1ea232926a4da1b" category="paragraph">이 가이드에 언급된 작업 순서 외에 사이트 장애 조치 시 몇 가지 다른 고려 사항이 있습니다.</block>
  <block id="74abdd5cb502cd65bcf1d7ca484ab0c2" category="paragraph">사이트 간 네트워크 차이는 문제가 될 수 있습니다. 일부 환경에서는 운영 사이트와 DR 사이트 모두에서 동일한 네트워크 IP 주소를 사용할 수 있습니다. 이러한 기능을 확장 가상 LAN(VLAN) 또는 확장 네트워크 설정이라고 합니다. 다른 환경에서는 DR 사이트와 관련하여 운영 사이트에서 서로 다른 네트워크 IP 주소(예: VLAN)를 사용해야 할 수 있습니다.</block>
  <block id="1b41638d2115765dc12f82d77ce70138" category="paragraph">VMware는 이 문제를 해결할 수 있는 여러 가지 방법을 제공합니다. VMware NSX-T Data Center와 같은 네트워크 가상화 기술은 운영 환경의 계층 2에서 계층 7까지 전체 네트워킹 스택을 추상화하여 보다 휴대성이 뛰어난 솔루션을 제공합니다. SRM에서 NSX-T 옵션에 대한 자세한 내용을 읽을 수 있습니다<block ref="99d78d594865360c3d4b527bf0a2a7f6" category="inline-link-rx"></block>.</block>
  <block id="09a74136e56a63c5aba38b89802d9080" category="paragraph">또한 SRM은 VM이 복구될 때 VM의 네트워크 구성을 변경할 수 있는 기능을 제공합니다. 이 재구성에는 IP 주소, 게이트웨이 주소 및 DNS 서버 설정과 같은 설정이 포함됩니다. 복구 시 개별 VM에 적용되는 다양한 네트워크 설정을 복구 계획에 있는 VM의 속성 설정에서 지정할 수 있습니다.</block>
  <block id="99f0a91111e8acb2462e8df5ecf0ab8f" category="paragraph">복구 계획에서 각 VM의 속성을 편집하지 않고도 여러 VM에 서로 다른 네트워크 설정을 적용하도록 SRM을 구성하려면 VMware에서 DR-IP-customizer라는 도구를 제공합니다. 이 유틸리티를 사용하는 방법에 대한 자세한 내용은 VMware 설명서를 참조하십시오<block ref="b959814092e3e6cdc8d22e768887e618" category="inline-link-rx"></block>.</block>
  <block id="3c8c527afa8ce5009c8f707f7fd4fabf" category="section-title">재보호</block>
  <block id="3b496038cb575fc404f8b0783e570f7a" category="paragraph">복구 후에는 복구 사이트가 새 운영 사이트가 됩니다. 복구 작업이 SnapMirror 복제를 중단했기 때문에 새 프로덕션 사이트는 이후의 재해로부터 보호되지 않습니다. 모범 사례는 복구 후 즉시 새 프로덕션 사이트를 다른 사이트로 보호하는 것입니다. 원래 운영 사이트가 작동 중인 경우 VMware 관리자는 원래 운영 사이트를 새 복구 사이트로 사용하여 새 운영 사이트를 보호할 수 있으므로 보호 방향을 효과적으로 바꿀 수 있습니다. 재보호는 비치명적인 오류에서만 사용할 수 있습니다. 따라서 원래 vCenter Server, ESXi Server, SRM Server 및 해당 데이터베이스를 최종적으로 복구할 수 있어야 합니다. 사용할 수 없는 경우 새 보호 그룹과 새 복구 계획을 생성해야 합니다.</block>
  <block id="6d80a3efb80520f47b63dc279e1bea3d" category="section-title">장애 복구</block>
  <block id="2bf236f8aceaaff2b305848df524c42e" category="paragraph">장애 복구 작업은 기본적으로 이전과 다른 방식으로 장애 조치입니다. 모범 사례로서, 원래 사이트가 장애 복구를 시도하기 전에 허용 가능한 수준의 기능으로 복구되었는지 또는 다시 말해 원래 사이트로 장애 조치를 수행하는 것이 좋습니다. 원래 사이트가 여전히 손상된 경우 장애가 충분히 해결될 때까지 페일백을 지연해야 합니다.</block>
  <block id="cb03753531bad31391d7156433b98ae6" category="paragraph">또 다른 장애 복구 모범 사례는 재보호 완료 후 그리고 최종 장애 복구를 수행하기 전에 항상 테스트 장애 조치를 수행하는 것입니다. 이렇게 하면 원래 사이트에 있는 시스템이 작업을 완료할 수 있는지 확인합니다.</block>
  <block id="900a3b65ea54b6dcff72ed0d6ac66fdf" category="section-title">원래 사이트를 다시 보호합니다</block>
  <block id="2a0c13d7b927063987bf931a141f2662" category="paragraph">페일백 후, 모든 이해 관계자(stake 보유자)에게 해당 서비스가 정상 상태로 복구되었는지 확인한 후 다시 재보호를 실행해야 합니다.</block>
  <block id="12d059a2c7519f2e3497b30a71121503" category="paragraph">페일백 후 재보호를 실행하면 기본적으로 환경이 원래 상태로 전환되며, 이때 SnapMirror 복제가 운영 사이트에서 복구 사이트로 다시 실행됩니다.</block>
  <block id="8ce83a5c4c3183c4e25f0d8d7b657ffc" category="summary">이 페이지에서는 VMware vSphere 환경에서 NFS 데이터 저장소를 지원합니다.</block>
  <block id="3769193a46f06731838a6d904cf1da37" category="doc">ONTAP를 사용한 vSphere 기존 파일 스토리지 용량 할당</block>
  <block id="8d3005420a2cb4cc915402d9c5604538" category="paragraph">VMware vSphere는 다음 NFS 프로토콜을 지원하며 두 프로토콜 모두 ONTAP를 지원합니다.</block>
  <block id="78aa97ac78d1291969b5893edcfe448a" category="inline-link-macro">NFS 버전 3</block>
  <block id="fb110cc4ad992a0846c0eaea7fbf2d94" category="list-text"><block ref="fb110cc4ad992a0846c0eaea7fbf2d94" category="inline-link-macro-rx"></block></block>
  <block id="2d6affbd5ec6eb1f6009383ca5ba9b2b" category="inline-link-macro">NFS 버전 4.1</block>
  <block id="3f65d9416139ab7c1ff75966bccf6f7d" category="list-text"><block ref="3f65d9416139ab7c1ff75966bccf6f7d" category="inline-link-macro-rx"></block></block>
  <block id="fc5929c224818a87a89047d2813dd2c5" category="inline-link-macro">이 비교 내용은 NFS 클라이언트 버전입니다</block>
  <block id="ce51dd3c15b8a6638d0c212b990ae643" category="paragraph">올바른 vSphere NFS 버전을 선택하는 데 도움이 필요한 경우 을(를) 확인하십시오 <block ref="8055fbd4933fc4c8b583fa212ff14ff2" category="inline-link-macro-rx"></block>.</block>
  <block id="f2a693e1f056b96566c4551fcab418f2" category="paragraph">vSphere를 사용하면 엔터프라이즈급 NFS 스토리지를 사용하여 ESXi 클러스터의 모든 노드에 대한 데이터 저장소에 대한 동시 액세스를 제공할 수 있습니다. 데이터 저장소 섹션에서 언급한 것처럼, NFS를 vSphere와 함께 사용할 경우 사용 편의성과 스토리지 효율성 가시성의 이점이 있습니다.</block>
  <block id="743fa5a7bc7d4ba215b096e34779d298" category="paragraph">vSphere와 함께 ONTAP NFS를 사용할 때는 다음과 같은 Best Practice를 따르는 것이 좋습니다.</block>
  <block id="265e673c00294cf97a90c3b0d4fcb076" category="list-text">ONTAP 클러스터의 각 노드에서 각 SVM에 대해 단일 논리 인터페이스(LIF)를 사용합니다. 데이터 저장소당 LIF의 과거 권장사항은 더 이상 필요하지 않습니다. 직접 액세스(LIF 및 데이터 저장소 같은 노드의 경우)가 가장 좋기는 하지만, 성능 영향은 일반적으로 최소(마이크로초)이기 때문에 간접 액세스에 대해 걱정할 필요가 없습니다.</block>
  <block id="ae4c5baa79e370d8f601cc7082f8123e" category="list-text">NFSv3과 NFSv4.1 간에는 자동 데이터 저장소가 변환되지 않으므로 새로운 NFSv4.1 데이터 저장소를 생성하고 Storage vMotion을 사용하여 VM을 새 데이터 저장소로 마이그레이션합니다.</block>
  <block id="822366735aef72f1a9429ac86dda7338" category="list-text">액세스 프로토콜:NFS3</block>
  <block id="69abbd5c7cd9c1b3828b9aa5a894ff47" category="list-text">클라이언트 일치 사양: 192.168.42.21</block>
  <block id="bd6cc42f9cd65cca72cbd56d2f4bf43d" category="list-text">ro 액세스 규칙: sys</block>
  <block id="581c470a5099548fc9865a4bab8761f8" category="list-text">rw 액세스 규칙: sys</block>
  <block id="59d5d8c898df18115bd4ced36c6bc0de" category="list-text">슈퍼유저: sys</block>
  <block id="c184ce6b86d2e6fbf8681d61637c101b" category="list-text">VMware VAAI용 NetApp NFS 플러그인을 사용하는 경우 엑스포트 정책 규칙을 생성하거나 수정할 때 프로토콜을 NFS로 설정해야 합니다. VAAI 복제 오프로드가 작동하려면 NFSv4 프로토콜이 필요하며, 프로토콜을 "NFS"로 지정하면 NFSv3 버전과 NFSv4 버전이 모두 자동으로 포함됩니다.</block>
  <block id="4c571520a8128d1692fc709ffbfb2b1e" category="list-text">VMware vSphere용 ONTAP 툴 사용(가장 중요한 모범 사례):</block>
  <block id="b8d278c6184cb65727ca5ae729db92d7" category="list-text">VMware vSphere용 ONTAP 툴을 사용하면 엑스포트 정책의 관리를 자동으로 간소화할 수 있으므로 데이터 저장소를 프로비저닝할 수 있습니다.</block>
  <block id="e4e62770daaf9887c7868fbc8e248a4b" category="list-text">플러그인 마운트 기능을 사용하여 기존 데이터 저장소를 새 서버에 적용합니다.</block>
  <block id="928562eb576ed6ae31cb1a149d3e751a" category="list-text">VMware vSphere용 ONTAP 툴을 사용하지 않는 경우 모든 서버 또는 추가 액세스 제어가 필요한 각 서버 클러스터에 대해 단일 엑스포트 정책을 사용하십시오.</block>
  <block id="7bccab0fa4c0864835c645c9fde7ebf6" category="list-text">ONTAP는 접합을 사용하여 트리에서 볼륨을 정렬하는 유연한 볼륨 네임스페이스 구조를 제공하지만, 이 접근 방식에는 vSphere의 가치가 없습니다. 스토리지의 네임스페이스 계층에 관계없이 데이터 저장소의 루트에 각 VM에 대한 디렉토리를 생성합니다. 따라서 가장 좋은 방법은 SVM의 루트 볼륨에서 vSphere의 볼륨에 대한 접합 경로를 마운트하는 것입니다. 이것이 바로 VMware vSphere용 ONTAP 툴이 데이터 저장소를 프로비저닝하는 방법입니다. 중첩된 연결 경로가 없다는 것은 루트 볼륨 이외의 볼륨에 종속되지 않으며 볼륨을 오프라인으로 전환하거나 의도적으로 파괴하더라도 다른 볼륨에 대한 경로에 영향을 주지 않는다는 것을 의미합니다.</block>
  <block id="ea6fc1288f1d3b21238d29ff28cb867a" category="list-text">NFS 데이터 저장소의 NTFS 파티션에 4K 블록 크기가 적합합니다. 다음 그림에서는 vSphere 호스트에서 ONTAP NFS 데이터 저장소로의 접속을 보여 줍니다.</block>
  <block id="16c864cb4f3b00c59e1124932e49f342" category="paragraph"><block ref="16c864cb4f3b00c59e1124932e49f342" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e54433644e830ed1503561b778e9ded4" category="paragraph">다음 표에는 NFS 버전 및 지원되는 기능이 나와 있습니다.</block>
  <block id="9fb9dac7513c7ef8452aade8a52ad40d" category="cell">vSphere 기능</block>
  <block id="5b12ee0369243579651edca43ff65c85" category="cell">NFSv3</block>
  <block id="de841868c2911da76b8ae2da9fa3166d" category="cell">NFSv4.1</block>
  <block id="64e3cc476958b05086721cd6070004cf" category="cell">vMotion 및 Storage vMotion입니다</block>
  <block id="93cba07454f06a4a960172bbd6e2a435" category="cell">예</block>
  <block id="45a75e44a713fdf94dbf1dbaa0749188" category="cell">내결함성</block>
  <block id="f1e3446c69e4d87279ff7863482f9dcb" category="cell">DRS</block>
  <block id="6ca09f98e8925b2cb78bbf24eccc0186" category="cell">호스트 프로파일</block>
  <block id="ec8420797e3b089812499cce4047ded8" category="cell">Storage DRS를 참조하십시오</block>
  <block id="bafd7322c6e97d25b6299b5d6fe8920b" category="cell">아니요</block>
  <block id="7c19bf1cbe62a87a42857ef0b4fe22ae" category="cell">스토리지 I/O 제어</block>
  <block id="56d43ad1a280ada5e16fd2960ae44b32" category="cell">SRM</block>
  <block id="d595c8f30866b71ea121ced5cde66b1d" category="cell">가상 볼륨</block>
  <block id="6ad5114acf73f68a85c72f11646920cb" category="cell">하드웨어 가속(VAAI)</block>
  <block id="ad37ded9046268d8e5ea7cb253bb5dda" category="cell">Kerberos 인증</block>
  <block id="45701e6ef9bc09dca07f8f4abe661dc6" category="cell">예(AES, krb5i를 지원하도록 vSphere 6.5 이상에서 향상)</block>
  <block id="76969a36155d2f41fc6cc3bd3faff244" category="cell">다중 경로 지원</block>
  <block id="7be2e69e5d19c282db8d81c60a51c862" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP 스토리지 솔루션을 구축하는 모범 사례를 설명합니다.</block>
  <block id="1e6584aafa5ae98aebb88d3ddecdaae5" category="doc">vSphere 관리자를 위한 ONTAP 소개</block>
  <block id="74587fa4ad90f8713c0446529a3670e0" category="section-title">ONTAP for vSphere를 선택해야 하는 이유</block>
  <block id="135b7f440129fbbacbc948adfb10ccec" category="paragraph">NetApp ONTAP는 스토리지 및 데이터 관리 운영을 간소화하고 사내 또는 클라우드에 관계없이 VMware 환경을 분명하게 보완합니다. 수많은 고객들이 vSphere 구축을 위해 ONTAP를 스토리지 솔루션으로 선택한 이유로는 NetApp의 동급 최고의 데이터 보호, 스토리지 효율성 혁신, SAN 기반 및 NAS 기반 VMware 아키텍처 모두에서 뛰어난 성능이 있습니다.</block>
  <block id="f93e431aaf745d4b5e4ecbd6c005b564" category="paragraph">NetApp은 가상화 환경 관리와 관련된 고유한 당면 과제를 해결하는 고객을 지원하기 위해 다양한 VMware 제품의 수많은 VMware 플러그인, 검증 및 자격을 제공합니다. NetApp은 VMware가 가상화를 위해 수행하는 스토리지 및 데이터 관리를 위해 하므로 고객이 물리적 스토리지 관리보다 핵심 역량에 집중할 수 있습니다. VMware와 NetApp은 20년에 가까운 파트너 관계를 유지하고 있으며, VMware Cloud Foundation 및 Tanzu와 같은 새로운 기술이 등장하면서 vSphere의 기반을 지속적으로 지원하는 등 고객 가치를 지속해서 개선하고 있습니다.</block>
  <block id="b4e56252f38c98dde71bd489a93805fc" category="paragraph">고객이 중요하게 고려하는 요소는 다음과 같습니다.</block>
  <block id="d6f750861d7ae27706ca32ed1f4c1ac8" category="list-text">* 유니파이드 스토리지 *</block>
  <block id="04d737333774adefb9817d0115bab79b" category="list-text">* 스토리지 효율성 *</block>
  <block id="c44a0be5f0db0511994f2f8e76afeb25" category="list-text">* 가상 볼륨 및 스토리지 정책 기반 관리 *</block>
  <block id="d78a5fe569360bb327d51dd5060d723c" category="list-text">* 하이브리드 클라우드 *</block>
  <block id="45649dc755190fc40be0b7e38ec84851" category="paragraph">지원되는 NetApp 및 VMware 솔루션에 대한 자세한 내용은 다음 리소스를 참조하십시오.</block>
  <block id="ec1bd76731eb238fa601fb03391f78d4" category="inline-link">NetApp 상호 운용성 매트릭스 툴</block>
  <block id="d46e58d91be6ffba761ab9bd05a46fc5" category="list-text"><block ref="b47ad5992ee82e05d51ff22d87ae20c3" category="inline-link-rx"></block> (IMT). IMT에는 FC/FCoE, iSCSI, NFS 및 CIFS 구성을 구축하는 데 사용할 수 있는 검증된 구성 요소와 버전이 정의되어 있습니다.</block>
  <block id="8034c6a17370dafb5b3f6f5add755c62" category="inline-link">VMware 호환성 가이드 를 참조하십시오</block>
  <block id="f0c67c4d38f07e6eb4bead0202260ddb" category="list-text"><block ref="a9846c61dcf62d503a7738adf47f11be" category="inline-link-rx"></block>. VMware 호환성 가이드 에는 VMware Infrastructure 및 소프트웨어 제품과의 시스템, I/O, 스토리지/SAN 및 백업 호환성 목록이 나와 있습니다</block>
  <block id="0f0b69f9725d17d0a8d3ceebcf33f72f" category="inline-link">VMware용 NetApp ONTAP 툴</block>
  <block id="2be6bbf4ea543b07ab3b9a218eb509cc" category="list-text"><block ref="d1284fbca35bc1b47ead37f18b1c3ba2" category="inline-link-rx"></block>. VMware vSphere용 ONTAP 툴은 VSC, VASA 공급자, SRA(스토리지 복제 어댑터) 확장을 포함한 단일 vCenter Server 플러그인입니다.</block>
  <block id="dcaf091737df278b1b4bdd2e37c10a75" category="summary">NetApp ONTAP는 2002년 현대적인 데이터 센터에 도입된 이후 VMware vSphere 환경을 위한 업계 최고의 스토리지 솔루션이며, 비용을 절감하는 동시에 관리를 단순화하는 혁신적인 기능을 지속적으로 추가하고 있습니다.</block>
  <block id="1fdf67ffe178876efb8b8cacfb0f052b" category="doc">TR-4900: NetApp ONTAP 9를 사용하는 VMware 사이트 복구 관리자</block>
  <block id="cc6ab3d11d2dc330a573866f7c9f67aa" category="paragraph">Chance Bingen, NetApp</block>
  <block id="60398bdc931fc67a9b6d781434c3a15a" category="section-title">vSphere용 ONTAP</block>
  <block id="09d6c6a1868cc36795c7a0f8f84e50c9" category="paragraph">NetApp ONTAP는 2002년 현대적인 데이터 센터에 도입된 이후 VMware vSphere 환경을 위한 업계 최고의 스토리지 솔루션이며, 비용을 절감하는 동시에 관리를 단순화하는 혁신적인 기능을 지속적으로 추가하고 있습니다. 이 문서에서는 최신 제품 정보 및 모범 사례를 포함하여 배포를 간소화하고 위험을 줄이며 지속적인 관리를 단순화하는 VMware의 업계 최고 DR(재해 복구) 소프트웨어인 VMware SRM(Site Recovery Manager)을 위한 ONTAP 솔루션을 소개합니다.</block>
  <block id="e3445c3aa798f5ad98665e33d34dd952" category="paragraph">모범 사례는 가이드 및 호환성 도구와 같은 다른 문서를 보완합니다. 이러한 전문 분야는 연구소 테스트와 NetApp 엔지니어 및 고객의 광범위한 현장 경험을 기반으로 합니다. 권장 모범 사례가 귀사의 환경에 적합하지 않은 경우도 있지만, 일반적으로 대부분의 고객 요구사항을 충족하는 가장 간단한 솔루션입니다.</block>
  <block id="c3edc14dbc5862176444f521372d1744" category="paragraph">이 문서는 ONTAP 9의 최신 릴리즈와 VMware vSphere(NetApp SRA(스토리지 복제 어댑터) 및 VASA 공급자[VP] 포함)용 ONTAP 툴 지원 버전과 함께 사용할 경우 VMware 사이트 복구 관리자 8의 기능에 중점을 둡니다. 4.</block>
  <block id="c40f8c2af56356193284f6b46865d954" category="section-title">SRM에 ONTAP를 사용해야 하는 이유</block>
  <block id="3c41d5be62c97a13079e9c7abf078292" category="paragraph">ONTAP 소프트웨어로 구동되는 NetApp 데이터 관리 플랫폼은 SRM을 위해 가장 널리 채택된 스토리지 솔루션 중 일부입니다. 그 이유는 수많은 기업이 스토리지 효율성, 멀티 테넌시, 서비스 품질 제어, 공간 효율적인 Snapshot 복사본을 사용한 데이터 보호 및 SnapMirror 복제를 제공하는 업계 정의 스토리지 효율성 기능을 제공하는 고성능 보안 통합 프로토콜(NAS 및 SAN 함께) 데이터 관리 플랫폼입니다. 이 모든 기능은 기본 하이브리드 멀티 클라우드 통합을 활용하여 VMware 워크로드를 보호하고 다양한 자동화 및 오케스트레이션 툴을 손쉽게 사용할 수 있도록 지원합니다.</block>
  <block id="0d573b6a27c08499fee406e3db49812f" category="paragraph">어레이 기반 복제에 SnapMirror를 사용하는 경우 ONTAP의 가장 검증되고 성숙된 기술 중 하나를 활용할 수 있습니다. SnapMirror를 사용하면 전체 VM 또는 데이터 저장소가 아닌 변경된 파일 시스템 블록만 복제하여 안전하고 효율성이 높은 데이터 전송을 이용할 수 있습니다. 이러한 블록조차도 중복제거, 압축, 컴팩션과 같은 공간 절약 효과를 활용합니다. 최신 ONTAP 시스템은 이제 버전에 상관없이 SnapMirror를 사용하므로 소스 및 타겟 클러스터를 유연하게 선택할 수 있습니다. SnapMirror는 실제로 재해 복구에 사용할 수 있는 가장 강력한 툴 중 하나가 되었습니다.</block>
  <block id="36b04390d6103d8075862e4b825a485e" category="paragraph">기존 NFS, iSCSI 또는 파이버 채널 연결 데이터 저장소(VVOL 데이터 저장소 지원)를 사용하는 경우 SRM은 재해 복구 또는 데이터 센터 마이그레이션 계획 및 오케스트레이션을 위해 최상의 ONTAP 기능을 활용하는 강력한 타사 오퍼링을 제공합니다.</block>
  <block id="5d111e8a6885460b43ecf1f7abb6377e" category="section-title">SRM이 ONTAP 9를 활용하는 방법</block>
  <block id="16d4ec242c9f020f3a1fade311c776ed" category="paragraph">SRM은 세 가지 주요 구성 요소가 포함된 가상 어플라이언스인 ONTAP for VMware vSphere와 통합하여 ONTAP 시스템의 고급 데이터 관리 기술을 활용합니다.</block>
  <block id="d54038ba1f2a04a5b5f26c96627ae3e7" category="list-text">vCenter 플러그인을 사용하면 이전에 VSC(Virtual Storage Console)라고 부르던 기능을 통해 SAN 또는 NAS를 사용하든지 스토리지 관리 및 효율성 기능을 단순화하고, 가용성을 높이며, 스토리지 비용과 운영 오버헤드를 줄일 수 있습니다. Best Practice를 사용하여 데이터 저장소를 프로비저닝하고 NFS 및 블록 스토리지 환경에 대한 ESXi 호스트 설정을 최적화합니다. 이러한 모든 이점을 누리게 하려면 ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 이 플러그인을 사용하는 것이 좋습니다.</block>
  <block id="a106bb15d6dc2b11535ed4fefc81fbf4" category="list-text">VASA Provider for ONTAP는 VMware VASA(vStorage APIs for Storage Awareness) 프레임워크를 지원합니다. VASA Provider는 vCenter Server를 ONTAP와 연결하여 VM 스토리지를 프로비저닝하고 모니터링할 수 있도록 지원합니다. VVOL(VMware Virtual Volumes)을 통해 스토리지 기능 프로필(VVOL 복제 기능 포함)과 개별 VM VVol 성능을 지원하고 관리할 수 있습니다. 또한 용량을 모니터링하고 프로파일 준수를 위한 알람을 제공합니다. SRM과 함께 VASA Provider for ONTAP를 사용하면 SRM 서버에 SRA 어댑터를 설치할 필요 없이 VVOL 기반 가상 머신을 지원할 수 있습니다.</block>
  <block id="f2007951062862f5f0d593acbb23bcb4" category="list-text">SRA는 SRM과 함께 사용되어 기존 VMFS 및 NFS 데이터 저장소의 프로덕션 및 재해 복구 사이트 간에 VM 데이터 복제를 관리하고 DR 복제본의 무중단 테스트를 수행합니다. 검색, 복구 및 재보호 작업을 자동화할 수 있습니다. SRA 서버 어플라이언스와 Windows SRM 서버용 SRA 어댑터 및 SRM 어플라이언스가 모두 포함됩니다.</block>
  <block id="8ccaa60ee78ecc93c4870b3b2ad15284" category="paragraph">VASA Provider 설정에서 비 VVol 데이터 저장소 및/또는 활성화된 VVol 복제를 보호하기 위해 SRM 서버에 SRA 어댑터를 설치 및 구성한 후에는 재해 복구를 위해 vSphere 환경을 구성하는 작업을 시작할 수 있습니다.</block>
  <block id="0a1e25166326359cd5f50d0ab83e6a37" category="paragraph">SRA 및 VASA Provider는 SRM 서버에 대한 명령 및 제어 인터페이스를 제공하여 VMware VM(가상 시스템)이 포함된 ONTAP FlexVol과 이들을 보호하는 SnapMirror 복제를 관리합니다.</block>
  <block id="38db855935949f86c5db7bfe7d49873e" category="paragraph">SRM 8.3부터 SRM 서버에 새로운 SRM VVol Provider 제어 경로가 도입되어 vCenter Server와 통신하고 SRA를 사용하지 않고도 VASA Provider와 통신할 수 있게 되었습니다. 따라서 VASA는 긴밀한 통합을 위한 완벽한 API를 제공하므로 SRM 서버가 ONTAP 클러스터에 대한 훨씬 더 깊은 제어를 활용할 수 있게 되었습니다.</block>
  <block id="53e971f0dfb3ef96ca359dcb648176b9" category="paragraph">SRM은 NetApp의 독점 FlexClone 기술을 사용하여 DR 사이트에 보호된 데이터 저장소의 거의 즉각적인 복제본을 만들어 DR 계획을 중단 없이 테스트할 수 있습니다. SRM은 안전한 테스트를 위한 샌드박스를 생성하여 실제 재해 발생 시 조직 및 고객이 보호를 받을 수 있도록 함으로써 재해 발생 시 조직의 장애 조치 실행 능력을 확실히 제공합니다.</block>
  <block id="04a8f82007ed4bec45053912a49b6f85" category="paragraph">실제 재해 또는 계획된 마이그레이션이 있는 경우 SRM을 사용하면 최종 SnapMirror 업데이트(선택한 경우)를 통해 데이터 세트에 대한 최신 변경 사항을 보낼 수 있습니다. 그런 다음 미러를 해제하고 데이터 저장소를 DR 호스트에 마운트합니다. 이 시점에서 사전 계획된 전략에 따라 임의의 순서로 VM을 자동으로 켤 수 있습니다.</block>
  <block id="b2560426a08ae6ceb167dad2bfb5e8ae" category="section-title">ONTAP 및 기타 사용 사례를 지원하는 SRM: 하이브리드 클라우드 및 마이그레이션</block>
  <block id="ed4c730bd8636c27d3eaa876c63b3d45" category="inline-link">Equinix의 NetApp 프라이빗 스토리지</block>
  <block id="b422e05bc5c6f52208b66ff51d718b9d" category="paragraph">SRM 배포를 ONTAP 고급 데이터 관리 기능과 통합하면 로컬 스토리지 옵션에 비해 확장성과 성능이 크게 향상됩니다. 그 이상의 것은 하이브리드 클라우드의 유연성을 제공합니다. 하이브리드 클라우드를 사용하면 FabricPool StorageGRID와 같은 사내 S3 저장소일 수 있는를 사용하여 고성능 어레이에서 선호하는 하이퍼스케일러를 사용하여 사용하지 않는 데이터 블록을 계층화하여 비용을 절감할 수 있습니다. 또한 CVO(Cloud Volumes ONTAP) 또는 를 사용하여 소프트웨어 정의 ONTAP Select 또는 클라우드 기반 DR이 있는 에지 기반 시스템에 SnapMirror를 사용할 수도 있습니다<block ref="37a666d3a37f1c4a8c4c8dba379664a4" category="inline-link-rx"></block> AWS(Amazon Web Services), Microsoft Azure 및 GCP(Google Cloud Platform)를 이용하여 클라우드에 완전히 통합된 스토리지, 네트워킹 및 컴퓨팅 서비스 스택을 구축할 수 있습니다.</block>
  <block id="10ae334f731d3c4fabafa8017f7a3ab2" category="paragraph">그런 다음 FlexClone을 사용하여 스토리지 공간을 거의 차지하지 않고 클라우드 서비스 공급자의 데이터 센터 내에서 테스트 대체 작동을 수행할 수 있습니다. 이제 조직을 보호하는 데 드는 비용이 그 어느 때보다 줄어듭니다.</block>
  <block id="12d0cbcf61df7df30bf9b020f6fbb051" category="paragraph">또한 SRM은 SnapMirror를 활용하여 VM을 하나의 데이터 센터에서 다른 데이터 센터로 효율적으로 전송하거나 자체 또는 NetApp 파트너 서비스 공급자의 수를 통해 동일한 데이터 센터 내에서 효율적으로 전송하여 계획된 마이그레이션을 실행하는 데 사용할 수 있습니다.</block>
  <block id="d3ba101543fc97ba1dd9272c87bf65da" category="doc">VVol(Virtual Volumes) 및 SPBM(Storage Policy Based Management)</block>
  <block id="25e09c324ad3c89ee3aa01454fce14cd" category="section-title">VVol 및 SPBM 정보</block>
  <block id="ab3304a5226d57b9bcaf0c7b3f819735" category="paragraph">NetApp은 VVOL(vSphere Virtual Volumes)을 개발하여 초기 설계 파트너로 VMware와 협력하여 VVOL과 VMware VASA(vSphere API for Storage Awareness)를 조기에 지원하고 아키텍처 입력을 제공했습니다. 이 접근 방식은 VM의 세분화된 스토리지 관리를 VMFS에 제공하는 것은 물론, SPBM(Storage Policy-Based Management)을 통한 스토리지 프로비저닝 자동화도 지원했습니다.</block>
  <block id="ce09fc365ce48a9d89c0fdb5222c3909" category="paragraph">SPBM은 가상화 환경에서 사용 가능한 스토리지 서비스와 정책을 통해 프로비저닝된 스토리지 요소 간의 추상화 계층 역할을 하는 프레임워크를 제공합니다. 스토리지 설계자는 이 접근 방식을 통해 VM 관리자가 쉽게 사용할 수 있는 다양한 기능을 갖춘 스토리지 풀을 설계할 수 있습니다. 그런 다음 관리자는 프로비저닝된 스토리지 풀에 대해 가상 머신 워크로드 요구 사항을 일치시킬 수 있으므로 VM별 또는 가상 디스크 레벨의 다양한 설정을 세부적으로 제어할 수 있습니다.</block>
  <block id="2902acda09b9786460c2dd928a2d8f1a" category="paragraph">ONTAP은 스토리지 업계에서 VVOL을 선도하여 단일 클러스터에서 수십만 개의 VVOL을 지원하는 반면, 엔터프라이즈 어레이와 소규모 플래시 어레이 공급업체는 어레이당 수백 개의 VVOL을 지원합니다. NetApp은 또한 VVOL 3.0을 지원함으로써 VM 세부 관리의 발전을 이끌고 있습니다.</block>
  <block id="fda9c21a4aefd4a1f42ad0b195e6ef0a" category="inline-link">TR-4400: ONTAP를 포함한 VMware vSphere 가상 볼륨</block>
  <block id="69173613658292fc2adeb513b12f29ca" category="admonition">VMware vSphere 가상 볼륨, SPBM 및 ONTAP에 대한 자세한 내용은 을 참조하십시오<block ref="354226c2546b1aed39f1c0c484e6a98a" category="inline-link-rx"></block>.</block>
  <block id="5a44477fe5ac4beac2dc6574097cf079" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP 스토리지 iSCSI VMFS 데이터 저장소를 구축하는 단계를 제공합니다.</block>
  <block id="6d5f52fb3cf097647a57da8b55e5b08f" category="doc">ONTAP를 사용한 vSphere 기존 블록 스토리지 프로비저닝</block>
  <block id="7c2d57185437da757ecede58f5a842d4" category="paragraph">VMware vSphere는 ONTAP SAN 프로토콜이 지원되는 다음 VMFS 데이터 저장소 옵션을 지원합니다.</block>
  <block id="c90881491d716de5c0ed7f9f4b09a3ad" category="cell">VMFS 데이터 저장소 옵션</block>
  <block id="a9181ef164a32ec0949c2cf63315ca31" category="cell">ONTAP SAN 프로토콜 지원</block>
  <block id="5903a917b575023b60264c602c220771" category="inline-link-macro">파이버 채널(FC)</block>
  <block id="a4bce6d7794ee38a14e6a6d3785039f9" category="cell"><block ref="a4bce6d7794ee38a14e6a6d3785039f9" category="inline-link-macro-rx"></block></block>
  <block id="a6105c0a611b41b08f1209506350279e" category="cell">예</block>
  <block id="8da5577a58a95e2ebe9c6dd4f19f6c11" category="inline-link-macro">FCoE(Fibre Channel over Ethernet)</block>
  <block id="40b814244a055d57c1af5fd02e4a8747" category="cell"><block ref="40b814244a055d57c1af5fd02e4a8747" category="inline-link-macro-rx"></block></block>
  <block id="e4e1c13bb0b14f6cb7608cbecea948ef" category="inline-link-macro">iSCSI</block>
  <block id="b26caac6068e09e5f849cfcb3e8c0c90" category="cell"><block ref="b26caac6068e09e5f849cfcb3e8c0c90" category="inline-link-macro-rx"></block></block>
  <block id="c38e870d503879d110dbddd5bf388ab2" category="cell">RDMA용 iSCSI 확장(iSER)</block>
  <block id="7fa3b767c460b54a2be4d49030b349c7" category="cell">아니요</block>
  <block id="de5a656362f0d785d2cc7d3097a507ef" category="inline-link-macro">NVMe over Fabric 및 FC(NVMe/FC)</block>
  <block id="71a94ffc9bd97f314990ee2cd7a87154" category="cell"><block ref="71a94ffc9bd97f314990ee2cd7a87154" category="inline-link-macro-rx"></block></block>
  <block id="16d2954ba1640e32b21c312695337233" category="cell">RDMA over Converged Ethernet(NVMe/RoCE)을 통한 NVMe over Fabric</block>
  <block id="344567ba51767dd5805c908c602fb10e" category="admonition">iSER 또는 NVMe/RoCE VMFS가 필요한 경우 SANtricity 기반 스토리지 시스템을 확인하십시오.</block>
  <block id="d4f43ea12f3f521c93fb3dd4d93c428d" category="summary">이 페이지에서는 VMware vSphere 환경에서 VMFS 데이터 저장소용 NetApp ONTAP NVMe/FC 스토리지를 구축하는 단계를 제공합니다.</block>
  <block id="9e433440cdaf3b61716784200e8abf6d" category="doc">vSphere VMFS 데이터 저장소 - ONTAP가 포함된 NVMe/FC</block>
  <block id="bbe48fb854ea022537208eeeff822f91" category="section-title">이 작업에 대해</block>
  <block id="9367f3df6c8d54eba1da3cd9c5fa2776" category="paragraph">이 섹션에서는 NVMe/FC를 사용하여 ONTAP 스토리지로 VMFS 데이터 저장소를 생성하는 방법을 설명합니다.</block>
  <block id="1563a554e82b055714efd37bc6d1fdd6" category="paragraph">자동 프로비저닝의 경우 다음 스크립트 중 하나를 사용합니다. <block ref="a45ba722ee80832fb205d0588df91e01" category="inline-xref-macro-rx"></block>, <block ref="d9559d06f0afa5b213d78afb48b783e7" category="inline-xref-macro-rx"></block>, 또는 <block ref="e5e7d2f44064f3bfeddfdbea251f7835" category="inline-xref-macro-rx"></block>.</block>
  <block id="6ac65708de8f04eeb173ca99f3eb19fa" category="section-title">필요한 것</block>
  <block id="6af0e7a38739ed6e2658342101a7b51e" category="list-text">vSphere 환경 및 ONTAP를 관리하는 데 필요한 기본 기술</block>
  <block id="7890464cdce93f078097395e27132775" category="inline-link-macro">NVMe/FC에 대한 기본 이해</block>
  <block id="c6e7cd589502f52a9398e779ede56d14" category="list-text"><block ref="62a43aa3bd2eb01e27a6091d3017311c" category="inline-link-macro-rx"></block>.</block>
  <block id="5422bc00db54a341b2c538f4cea614c0" category="list-text">{ONTAP_VERSION}을 실행하는 ONTAP 스토리지 시스템(FAS/AFF/CVO/ONTAP Select/ASA</block>
  <block id="fdb8f60c37b623874df816146436f56b" category="list-text">ONTAP 자격 증명(SVM 이름, userID 및 암호)</block>
  <block id="2ec64af43682ffa45eeaf33a86950347" category="list-text">호스트, 타겟, SVM 및 LUN 정보를 위한 ONTAP WWPN</block>
  <block id="62eadfe081f86e1f9a72988a4feb7bfc" category="inline-link-macro">완료된 FC 구성 워크시트</block>
  <block id="f186921a73873df63dc496b515bc2099" category="list-text"><block ref="f186921a73873df63dc496b515bc2099" category="inline-link-macro-rx"></block></block>
  <block id="c4436d4a190778b7ec1e9461f6454bdd" category="list-text">vCenter Server를 선택합니다</block>
  <block id="5fd6c6da49bc906cc217c5aff2041a52" category="list-text">vSphere 호스트 정보({vSphere_version})</block>
  <block id="63fc76a195a29345d466bc86f293ca14" category="list-text">패브릭 스위치</block>
  <block id="60ce38e4967c52c316eff771b7a3c4ec" category="list-text">ONTAP FC 데이터 포트 및 vSphere 호스트가 연결된 경우</block>
  <block id="32086766e64ae646fcadddc3e16b203b" category="list-text">N_port ID 가상화(NPIV) 기능이 활성화된 경우</block>
  <block id="b6e0bd021536c90aa87cfea18d73d453" category="list-text">단일 이니시에이터 타겟 존을 생성합니다.</block>
  <block id="df7f994fb0c494b66708667a64b2c406" category="list-text">각 이니시에이터에 대해 하나의 존(Zone)을 생성합니다(단일 이니시에이터 존).</block>
  <block id="f386e9f209710f55d41a97e9502d1c7c" category="list-text">각 존에 SVM을 위한 ONTAP FC 논리 인터페이스(WWPN)인 타겟을 포함합니다. SVM당 노드당 논리 인터페이스는 2개 이상 있어야 합니다. 물리적 포트의 WWPN을 사용하지 마십시오.</block>
  <block id="71d4977f0fd6be92644e1ff9f8096637" category="section-title">VMFS 데이터 저장소를 프로비저닝합니다</block>
  <block id="c9dd6bad4c7d561872f2e2d498a990bf" category="inline-link">상호 운용성 매트릭스 툴(IMT)</block>
  <block id="a9df884192a193f56d8208439b4d1fca" category="list-text">과의 호환성을 확인하십시오<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block>.</block>
  <block id="f42c50210dcc0a3a69c8258256e75e4b" category="inline-link-macro">NVMe/FC 구성이 지원되는지 확인하십시오.</block>
  <block id="5312bcc81ee6d7bce6549b2089c9d1ac" category="list-text"><block ref="5312bcc81ee6d7bce6549b2089c9d1ac" category="inline-link-macro-rx"></block></block>
  <block id="cfa5eceb5ac37d5ebd3af6f265d9ce4c" category="section-title">ONTAP 작업</block>
  <block id="1a04100ec801e5e2d1708d89eb1159b6" category="inline-link-macro">FCP의 ONTAP 라이센스를 확인합니다.</block>
  <block id="9d17f91ad987b7e7cf2fa7249cd97343" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block>'system license show' 명령어를 이용하여 NVMe_of가 나열되는지 확인한다. 사용권을 추가하려면 'license add-license-code &lt;license code&gt;'를 사용하십시오.</block>
  <block id="7193bed15c5b4f7c80f1f19630b57e1e" category="list-text">SVM에서 NVMe 프로토콜이 활성화되어 있는지 확인합니다.</block>
  <block id="5eabd2d7390fc49cb61f882324bdcac0" category="inline-link-macro">NVMe용 SVM을 구성합니다.</block>
  <block id="3838b8ad26ea53cc8ddea76f2a58b20a" category="list-text"><block ref="3838b8ad26ea53cc8ddea76f2a58b20a" category="inline-link-macro-rx"></block></block>
  <block id="f2fd2de931ce484e947c89ae8207346a" category="list-text">SVM에서 NVMe/FC 논리 인터페이스를 사용할 수 있는지 확인합니다.</block>
  <block id="aa01379022dd5b86e18f436c76f651f5" category="list-text">네트워크 인터페이스 show를 사용하여 FCP 어댑터를 확인합니다.</block>
  <block id="978583cfbb47e2700c599c43b7949a53" category="list-text">GUI로 SVM을 생성할 때 논리 인터페이스는 이 프로세스의 일부입니다.</block>
  <block id="3866119a70b69102c1584c0baa386190" category="list-text">네트워크 인터페이스의 이름을 바꾸려면 네트워크 인터페이스 수정 명령을 사용합니다.</block>
  <block id="6ad7e9002145710745843d16314895e3" category="inline-link-macro">NVMe 네임스페이스 및 하위 시스템을 생성합니다</block>
  <block id="06badf30aa173febc3374aceef25c5ce" category="list-text"><block ref="06badf30aa173febc3374aceef25c5ce" category="inline-link-macro-rx"></block></block>
  <block id="722a3f8fc9c281f41b6ca7a69ca15ec0" category="section-title">VMware vSphere 작업</block>
  <block id="7407e0a15262132133381a890e36e47a" category="inline-link-macro">스토리지 어댑터 정보</block>
  <block id="c6613394adcc7526a48f6e92b61ee067" category="list-text">HBA 드라이버가 설치되어 있는지 확인합니다. VMware 지원 HBA에는 드라이버가 즉시 배포되어 있으며 에서 볼 수 있습니다 <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block></block>
  <block id="9761a89a99469e468e71b7a0087be29d" category="inline-link-macro">vSphere Host NVMe 드라이버 설치 및 검증 작업을 수행합니다</block>
  <block id="926e4d89379d3dde2510965ca53771af" category="list-text"><block ref="926e4d89379d3dde2510965ca53771af" category="inline-link-macro-rx"></block></block>
  <block id="e229fd9b7b8948ddebf276bda8a9145e" category="inline-link-macro">VMFS 데이터 저장소를 생성합니다</block>
  <block id="3dbbea9263919f89335d7ba053f09a39" category="list-text"><block ref="3dbbea9263919f89335d7ba053f09a39" category="inline-link-macro-rx"></block></block>
  <block id="c0ddbacfe0f703e62904558059e40001" category="summary">이 섹션에서는 특정 릴리즈의 ONTAP 및 vSphere에서 지원하는 기능에 대한 지침을 제공합니다. NetApp 상호 운용성 매트릭스와 특정 조합의 릴리즈를 확인하는 것이 좋습니다.</block>
  <block id="737453909be77692f8cfdf08a17cee61" category="doc">ONTAP 및 vSphere 릴리즈별 정보입니다</block>
  <block id="bc8be72fdc9d6054f356bb2b7f80fd12" category="inline-link">NetApp 상호 운용성 매트릭스</block>
  <block id="2f6ae9fa35fbcb0ec3205505ee027642" category="paragraph">이 섹션에서는 특정 릴리즈의 ONTAP 및 vSphere에서 지원하는 기능에 대한 지침을 제공합니다. NetApp은 와 릴리스의 특정 조합을 확인하는 것이 좋습니다<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block>.</block>
  <block id="7912c2100fd9b3b96b0b03e7a068fc9a" category="section-title">ONTAP 릴리스</block>
  <block id="8ee2892e0fb10cc58205a3d682abdb58" category="paragraph">NetApp은 출시 당시 다음과 같은 제품군을 완벽하게 지원합니다.</block>
  <block id="0fcf2ee62acd9eae83b609a0e7ecaa72" category="list-text">ONTAP 9.5</block>
  <block id="7dd2a92fd3f41a5334edf46f95d77e71" category="list-text">ONTAP 9.6</block>
  <block id="3447b91e516e4fc6b5dba827fcb68bee" category="list-text">ONTAP 9.7</block>
  <block id="2abfff2974f589f7a217325f304e0ec5" category="list-text">ONTAP 9.8</block>
  <block id="ee4651b72d795faf25a1382eb1315a95" category="section-title">vSphere 및 ESXi 지원</block>
  <block id="c3123497dcfdcdf46908ad18a51928ca" category="paragraph">NetApp ONTAP는 vSphere ESXi 호스트를 광범위하게 지원합니다. 방금 설명한 네 가지 주요 릴리즈 제품군(9.5, 9.6, 9.7 및 9.8)은 6.0, 6.5 및 7.0(이러한 릴리즈에 대한 업데이트 포함)을 비롯한 최신 vSphere 릴리스의 데이터 스토리지 플랫폼으로 완벽하게 지원됩니다. NFS v3 상호 운용성은 광범위하게 정의되며 NetApp은 NFS v3 표준을 준수하는 하이퍼바이저를 포함하여 모든 클라이언트를 지원합니다. NFSv4.1 지원은 vSphere 6.0에서 7.0으로 제한됩니다.</block>
  <block id="8276b4666ec9fee7d71b01f6ee2b9955" category="paragraph">SAN 환경의 경우 NetApp에서 SAN 구성요소를 광범위하게 테스트합니다. 일반적으로 NetApp은 표준 x86-64 랙 서버와 Cisco UCS 서버를 iSCSI 연결용 표준 이더넷 어댑터와 함께 지원합니다. FC, FCoE 및 NVMe/FC 환경에서는 필요한 HBA 펌웨어 및 드라이버로 인해 지원이 명확하게 정의되었습니다.</block>
  <block id="a9854fb3ed44e3b8e9236c5b70405101" category="paragraph">항상 을 확인하십시오<block ref="50c84d2622d2bc5cc86e7d8724309075" category="inline-link-rx"></block> 특정 하드웨어 및 소프트웨어 구성에 대한 지원을 확인합니다.</block>
  <block id="dd55e255500b9ec15305dc69dfa0e15b" category="section-title">VMware VAAI용 NFS 플러그인</block>
  <block id="eb3ac5aa51c1cacfa31cee70ac6586f0" category="paragraph">ESXi 호스트용 이 플러그인은 VAAI를 사용하여 ONTAP로 작업을 오프로드하는 데 도움이 됩니다. 최신 릴리스인 1.1.2에는 Kerberos(krb5 및 krb5i) 지원을 비롯한 NFSv4.1 데이터 저장소가 지원됩니다. ONTAP 9.5-9.8과 함께 ESXi 6.0, 6.5 및 7.0에서 지원됩니다.</block>
  <block id="b2dd36bd4918e00f8b2e15e6d62a4b94" category="section-title">VASA 공급자</block>
  <block id="15c15a65e1486d45a44c6f61927ef836" category="paragraph">NetApp의 VASA Provider는 VVOL 프로비저닝 및 관리를 지원합니다(섹션 3.7 참조). 최신 VASA Provider 릴리즈는 ESXi 6.0, 6.5 및 7.0과 ONTAP 9.5-9.8을 함께 지원합니다.</block>
  <block id="ed9018b2e8611a3d2c03bb6a205b9715" category="section-title">VMware vSphere용 ONTAP 툴</block>
  <block id="c13550c8bc0f9b77e92bd2533221de9d" category="paragraph">VMware vSphere용 ONTAP 툴은 ONTAP 스토리지를 vSphere와 함께 관리하는 데 있어 매우 중요합니다(모범 사례). 최신 릴리스인 9.8은 ONTAP 9.5-9.8과 함께 vSphere 6.5 및 7.0에서 지원됩니다.</block>
  <block id="a9b73ebef33c98ef5a1044177d2b49f3" category="summary">VMware vCenter Site Recovery Manager는 모든 가상화된 애플리케이션의 재해 복구 관리를 간소화하기 위해 중앙 집중식 복구 계획의 자동화된 오케스트레이션 및 무중단 테스트를 제공하는 재해 복구 솔루션입니다.</block>
  <block id="06f589670c0d0455912cc8bb70b78701" category="paragraph">NetApp ONTAP 시스템에 Site Recovery Manager를 구축하면 재해 복구 비용을 크게 절감하고 복잡성을 줄일 수 있습니다. NetApp은 관리하기 쉽고 확장성이 뛰어난 고성능 스토리지 어플라이언스 및 강력한 소프트웨어 제품을 통해 vSphere 환경을 지원하는 유연한 스토리지 및 데이터 관리 솔루션을 제공합니다.</block>
  <block id="00549aec33ddcae6a708ed7368a7bcd0" category="paragraph">이 가이드에서 제공하는 모범 사례와 권장 사항은 모든 요구사항을 한 가지 솔루션으로 제시되는 것이 아닙니다. 이 문서에는 SRM DR 계획의 계획, 배포 및 관리에 대한 지침을 제공하는 모범 사례와 권장 사항이 포함되어 있습니다. NetApp 스토리지에 VMware vCenter Site Recovery 환경을 계획 및 구축하려면 현지 NetApp VMware 전문가에게 문의하십시오. NetApp VMware 전문가는 vSphere 환경의 요구 사항과 수요를 빠르게 파악하고 그에 따라 스토리지 솔루션을 조정할 수 있습니다.</block>
  <block id="1f82b18dcba5f32a085bc502cdd0c6b7" category="summary">ONTAP를 사용하면 SVM(스토리지 가상 머신)이라는 개념을 통해 보안 멀티 테넌트 환경에서 엄격한 세분화를 제공할 수 있습니다.</block>
  <block id="7520e12a140ccf3de279fe2fd48889e4" category="doc">배포 모범 사례</block>
  <block id="1b4574c516231b685bb37b013b789b06" category="section-title">SMT를 위한 SVM 레이아웃 및 Segmentation</block>
  <block id="446e04546ec0567eeeeef8e07368ab40" category="paragraph">ONTAP를 사용하면 SVM(스토리지 가상 머신)이라는 개념을 통해 보안 멀티 테넌트 환경에서 엄격한 세분화를 제공할 수 있습니다. 한 SVM의 SVM 사용자는 다른 SVM에서 리소스를 액세스하거나 관리할 수 없습니다. 이렇게 하면 동일한 클러스터에서 고유한 SRM 워크플로우를 관리하는 여러 사업부에 대해 별도의 SVM을 생성하여 ONTAP 기술을 활용함으로써 전반적인 스토리지 효율성을 높일 수 있습니다.</block>
  <block id="f98c1d223f34b2fdaf90eab1a3bc6a25" category="paragraph">보안 제어를 개선하면서 성능을 향상할 뿐만 아니라 SVM 범위 계정 및 SVM 관리 LIF를 사용하여 ONTAP를 관리하는 것을 고려해 보십시오. SRA는 물리적 리소스를 포함하여 전체 클러스터의 모든 리소스를 처리할 필요가 없으므로 SVM 범위 연결을 사용할 때 기본적으로 성능이 향상됩니다. 대신, 특정 SVM에 추상화된 논리적 자산만 이해해야 합니다.</block>
  <block id="849d4d5e8a5d5b2747d8375d2ec03b29" category="paragraph">NAS 프로토콜만 사용하는 경우(SAN 액세스 없음), 다음 매개 변수를 설정하여 새로운 NAS 최적화 모드를 활용할 수도 있습니다(SRA 및 VASA는 어플라이언스에서 동일한 백엔드 서비스를 사용하기 때문에 이름이 동일함).</block>
  <block id="05f551a655f40911851a53ba0c721997" category="list-text">"\https://&lt;IP address&gt;:9083"에서 제어판에 로그인하고 웹 기반 CLI 인터페이스를 클릭합니다.</block>
  <block id="b0cc185c73ca964d1429a601551c68f5" category="list-text">vp updateeconfig -key=enable.qtree.discovery-value=true 명령을 실행합니다.</block>
  <block id="5f7e35f90689bef91afe9f01257c61ac" category="list-text">vp updateeconfig -key=enable.optimized.SRA-value=true 명령을 실행합니다.</block>
  <block id="ba2a1e4d95dc56709260e82cca20a789" category="list-text">'vp reloadconfig' 명령어를 실행한다.</block>
  <block id="2d14ca751c8ce5a724606e4f75f02c50" category="section-title">VVOL을 위한 ONTAP 툴 및 고려사항 배포</block>
  <block id="fa3a193f1892cf0f45f4a95a35aa3c4b" category="paragraph">VVOL이 포함된 SRM을 사용하려면 클러스터 범위 자격 증명 및 클러스터 관리 LIF를 사용하여 스토리지를 관리해야 합니다. 이는 VASA Provider가 VM 스토리지 정책에 필요한 정책을 충족하기 위해 기본 물리적 아키텍처를 이해해야 하기 때문입니다. 예를 들어, All-Flash 스토리지가 필요한 정책이 있는 경우 VASA Provider는 모든 All-Flash 시스템을 확인할 수 있어야 합니다.</block>
  <block id="31d279d1cc3bc5a4281567ba697f678d" category="paragraph">또 다른 구축 모범 사례는 관리 중인 VVOL 데이터 저장소에 ONTAP 툴 어플라이언스를 저장하지 않는 것입니다. 어플라이언스가 오프라인이므로 어플라이언스에 대한 스왑 VVol을 생성할 수 없으므로 VASA Provider의 전원을 켤 수 없는 상황이 발생할 수 있습니다.</block>
  <block id="97399fb37deca0d463aa5c7dc8d064a6" category="section-title">ONTAP 9 시스템 관리 모범 사례</block>
  <block id="b4cbecf196108ad163c73c4e4194dde2" category="paragraph">앞서 언급했듯이 클러스터 또는 SVM 범위의 자격 증명 및 관리 LIF를 사용하여 ONTAP 클러스터를 관리할 수 있습니다. 최적의 성능을 위해 VVOL을 사용하지 않을 때마다 SVM 범위 자격 증명을 사용하는 것이 좋습니다. 그러나 이렇게 하면 일부 요구 사항을 인식하고 일부 기능을 사용할 수 없게 됩니다.</block>
  <block id="fec05e53ca7d96aaf3e4c1a1b2502bea" category="list-text">기본 vsadmin SVM 계정에는 ONTAP 툴 작업을 수행하는 데 필요한 액세스 수준이 없습니다. 따라서 새 SVM 계정을 생성해야 합니다.</block>
  <block id="8557644859e03f54860c95ffb0bcfd53" category="list-text">ONTAP 9.8 이상을 사용하는 경우, ONTAP System Manager의 사용자 메뉴와 함께 ONTAP 도구 어플라이언스의 JSON 파일을 사용하여 RBAC 최소 권한 사용자 계정을 "\https://&lt;IP address&gt;:9083/VSC/config/"에서 생성하는 것이 좋습니다. 관리자 암호를 사용하여 JSON 파일을 다운로드합니다. SVM 또는 클러스터 범위 어카운트에 사용할 수 있습니다.</block>
  <block id="a7a83b5e4f375c0585588b9c7ff92219" category="inline-link">NetApp Support 사이트 Toolchest</block>
  <block id="fdfe9ba9104df6a32fff0f859291ea3c" category="paragraph">ONTAP 9.6 이하를 사용하는 경우 에서 사용할 수 있는 RBAC 사용자 작성 도구(RUC)를 사용해야 합니다<block ref="bdbf96c18cf8ac76d01fba7057b81b87" category="inline-link-rx"></block>.</block>
  <block id="ea7a3d08d55dc3e8ecf89d2a5d5e302d" category="list-text">vCenter UI 플러그인, VASA Provider 및 SRA 서버는 모두 완전히 통합된 서비스이므로 ONTAP용 vCenter UI 툴에서 스토리지를 추가하는 것과 동일한 방식으로 SRM에서 SRA 어댑터에 스토리지를 추가해야 합니다. 그렇지 않으면 SRA 서버는 SRA 어댑터를 통해 SRM에서 전송되는 요청을 인식하지 못할 수 있습니다.</block>
  <block id="b473de4177eeaa79a66448798a446db3" category="list-text">SVM 범위 자격 증명을 사용할 때는 NFS 경로 검사가 수행되지 않습니다. 물리적 위치가 SVM에서 논리적으로 추상화되기 때문입니다. 하지만 최신 ONTAP 시스템은 간접 경로를 사용할 때 눈에 띄는 성능 저하가 더 이상 발생하지 않으므로 이는 우려의 원인이 아닙니다.</block>
  <block id="6e62430b92a7c5a0b8512436b163a10d" category="list-text">스토리지 효율성으로 인한 애그리게이트 공간 절약은 보고되지 않을 수 있습니다.</block>
  <block id="93d86aa51e0909549d1b1210f887aef3" category="list-text">지원되는 경우 로드 공유 미러를 업데이트할 수 없습니다.</block>
  <block id="647d380b52e259fe7ed2e2582bc54b27" category="list-text">SVM 범위 자격 증명으로 관리되는 ONTAP 시스템에서는 EMS 로깅이 수행되지 않을 수 있습니다.</block>
  <block id="ce4df831657d2621e80bbef9271c33cd" category="summary">기존 가상 어플라이언스로 전환한 ONTAP 툴은 다양한 새로운 기능, 더 높은 제한, 새로운 VVOL 지원을 제공합니다.</block>
  <block id="45b1565c472fff4046d0f7ddbe1342f2" category="doc">SRM 및 ONTAP 도구의 새로운 기능</block>
  <block id="116d20fc387d73c8e4a86e7998913947" category="section-title">vSphere 및 Site Recovery Manager의 최신 버전입니다</block>
  <block id="aa73b07f008975ca9fcabf87bfafb167" category="paragraph">SRM 8.3 이상 릴리즈와 ONTAP 툴 9.7.1 이상 릴리즈를 사용하면 이제 VMware vSphere 7에서 실행 중인 VM을 보호할 수 있습니다.</block>
  <block id="96ca6fcc2ffdab3c06d0875be8d4fe29" category="paragraph">NetApp은 약 20년 동안 VMware와 긴밀한 파트너 관계를 유지하고 있으며, 최대한 빠른 시일 내에 최신 릴리즈를 지원하기 위해 노력하고 있습니다. 항상 NetApp 상호 운용성 매트릭스 툴(IMT) 에서 적격 소프트웨어의 최신 조합을 확인하십시오.</block>
  <block id="63fe9875fcf8108a4dca29a0795d8674" category="paragraph">NetApp IMT를 찾을 수 있습니다<block ref="dd81e3609a71c92c2a90d9165ca7bb00" category="inline-link-rx"></block>.</block>
  <block id="23a6222620917211381cf4455d9e0a83" category="section-title">VVol 지원(및 SRM을 사용하는 경우에도 SPBM이 중요한 이유)</block>
  <block id="a36269071ceeb480e636654c4620f7fb" category="paragraph">이제 8.3 릴리스로 시작하여 SRM은 VVol 및 어레이 기반 복제를 활용하는 복제의 스토리지 정책 기반 관리(SPBM)를 지원합니다. 이를 위해 VASA 관련 작업을 위해 vCenter 서버의 SMS 서비스와 통신하는 새로운 SRM VVol 공급자 서비스를 포함하도록 SRM 서버가 업데이트되었습니다.</block>
  <block id="4567f5576b4577c63b126cac3f6aa5fa" category="paragraph">이 아키텍처의 한 가지 이점은 모든 것이 VASA를 통해 처리되므로 SRA가 더 이상 필요하지 않는다는 것입니다.</block>
  <block id="e04031e1cecdb6732f91d44b204dbcf3" category="paragraph">SPBM은 vSphere 툴박스에 포함된 강력한 툴로, 프라이빗 및 하이브리드 클라우드 환경의 자동화 프레임워크에서 간편하고 예측 가능하며 일관된 스토리지 서비스를 사용할 수 있습니다. 기본적으로 SPBM을 사용하면 다양한 고객 기반의 요구 사항을 충족하는 서비스 클래스를 정의할 수 있습니다. SRM을 사용하면 강력한 업계 표준 재해 복구 오케스트레이션 및 자동화가 필요한 중요 워크로드에 대한 복제 기능을 고객에게 제공할 수 있습니다.</block>
  <block id="6f1ad7cac2af0e3b92a3936efc393a0e" category="paragraph"><block ref="6f1ad7cac2af0e3b92a3936efc393a0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48e2854d95fac45929940abc72062193" category="section-title">VVOL 아키텍처 2.3 어플라이언스 기반 SRM 서버에 대한 지원</block>
  <block id="925c477f139cce0692e13946a7f75eac" category="paragraph">이제 Photon OS 기반 SRM 서버는 기존 Windows 기반 플랫폼뿐만 아니라 지원됩니다.</block>
  <block id="62c2c4203aebe081ddbc6cdd489f8ad7" category="paragraph">이제 기본 SRM 서버 유형에 관계없이 SRA 어댑터를 설치할 수 있습니다.</block>
  <block id="7cb1700928c008eb817bc79250cc9002" category="section-title">IPv6를 지원합니다</block>
  <block id="ea9aacd1495949730de8eeab11e66459" category="paragraph">IPv6은 이제 다음과 같은 제한 사항으로 지원됩니다.</block>
  <block id="d6d7f3d43de975c07655ebba1936867a" category="list-text">vCenter 6.7 이상</block>
  <block id="eb26ee1a20fe3dbde98204ec8b3ab838" category="list-text">SRM 8.2(8.1, 8.3 및 8)에서는 지원되지 않습니다. 4개 지원)</block>
  <block id="918d32b75f0ab883abba3a8dc0c3ae8d" category="inline-link">상호 운용성 매트릭스 툴</block>
  <block id="02e7e71042609d3158020ab7befe45c6" category="list-text">를 확인하십시오<block ref="218f4ad7153f69cdc5467065434cd2f0" category="inline-link-rx"></block> 최신 버전의 경우.</block>
  <block id="e887aed8f9c3dbecd37e8896d96b6637" category="section-title">향상된 성능</block>
  <block id="3efd4ca8de094abf49f004186cd70fff" category="paragraph">운영 성능은 SRM 작업 실행을 위한 핵심 요구 사항입니다. 최신 RTO 및 RPO의 요구 사항을 충족하기 위해 ONTAP 도구가 포함된 SRA에 두 가지 새로운 개선 사항이 추가되었습니다.</block>
  <block id="bd403c539a0c414afacd7477bf3d311f" category="list-text">* 동시 재보호 작업 지원. * SRA 9.7.1에서 처음 도입된 이 기능을 사용하면 두 개 이상의 복구 계획에서 동시에 재보호를 실행할 수 있으므로 페일오버 또는 마이그레이션 후 데이터 저장소를 재보호하는 데 필요한 시간을 줄이고 RTO 및 RPO 매개 변수를 계속 유지할 수 있습니다.</block>
  <block id="f63b947f655a5aee2cf69d4f30d7f96b" category="list-text">* ONTAP Tools 9.8은 NAS 전용 최적화 모드를 새로 추가했습니다. * SVM 범위 계정을 사용하고 NFS 기반 데이터 저장소만 있는 ONTAP 클러스터에 연결할 때 지원되는 환경에서 NAS 전용 최적화 모드를 사용하여 최대 성능을 실현할 수 있습니다.</block>
  <block id="4a4842d7448ef71eb69b013e560b18bb" category="section-title">더 뛰어난 확장성</block>
  <block id="26738e8d40ae8035805f13bdbf185c30" category="paragraph">ONTAP 도구 SRA는 이제 SRM 8.3 이상에서 사용할 경우 최대 500개의 보호 그룹(PG)을 지원할 수 있습니다.</block>
  <block id="b56265ceb6311e42003e668438136a59" category="section-title">동기식 복제</block>
  <block id="96cb4d41ca97bd9d3d446984d3170a57" category="paragraph">오랫동안 기다려온 새로운 기능은 미션 크리티컬 애플리케이션에 볼륨 세분화 제로 RPO 데이터 복제 솔루션을 제공하는 ONTAP 9.5 이상의 SM-S(SnapMirror Synchronous)입니다. SM-S에는 ONTAP 도구 9.8 이상이 필요합니다.</block>
  <block id="b9832b10a87d0c3793ed3b413ee1d839" category="section-title">REST API 지원</block>
  <block id="0065ce57adc813187a8e9c640ba6223a" category="paragraph">이제 REST API를 통해 SRA 서버 구성을 관리할 수 있습니다. Swagger UI는 자동화 워크플로우 구축을 지원하기 위해 추가되었으며 ONTAP 툴 어플라이언스('https://&lt;appliance&gt;:8143/api/rest/swagger-ui.html#/` )에서 찾을 수 있습니다.</block>
  <block id="9db3527848e891e0a9340c443515e770" category="doc">NetApp 및 VMware 시작하기</block>
  <block id="4b1c76979225b75a8e5f476356ed17e8" category="paragraph">VMware on NetApp: 여정이 시작됩니다!</block>
  <block id="d7b056332bb039010d62c71ede534471" category="paragraph">VMware 환경 혁신을 시작할 준비가 되었으면 최신 솔루션 개요를 살펴보고 최신 기술 솔루션 및 제품 데모를 검토하십시오. 다음 단계로 진행할 준비가 되면 NetApp 및 VMware 전문가 커뮤니티를 통해 데이터 센터 현대화, 하이브리드 클라우드 또는 컨테이너식 애플리케이션 이니셔티브를 계획하고 실행할 수 있습니다.</block>
  <block id="bbaff12800505b22a853e8b7f4eb6a22" category="inline-link-macro">연락처</block>
  <block id="be52ccc9c4dbcee449a6257062c0bcda" category="paragraph">어디서부터 시작해야 할지 잘 모르십니까? <block ref="dcd7ec98fb935d9a5fd8ade723a47456" category="inline-link-macro-rx"></block> NetApp의 VMware 전문가 구성원</block>
  <block id="27b7a196b8196df4eeee9d21ade20a45" category="inline-link-macro">PDF 형식</block>
  <block id="e2fd99d21fbe7a1b2ed6388c40d48b0f" category="admonition">이 페이지에 표시된 내용은 에서도 다운로드할 수 있습니다 <block ref="a182addaadbc8a97de909268c8dc9bf0" category="inline-link-macro-rx"></block>.</block>
  <block id="d3db539e5d56da6e251021138c5fe53f" category="section-title">NetApp과 VMware의 솔루션에 대해 알아보십시오</block>
  <block id="09f93ac387258fa68c085baba3c8fc44" category="inline-link-macro">NetApp과 AMP, VMware: 더욱 유기적으로</block>
  <block id="fb758bbc93c23b25607ef41f302d4eef" category="list-text"><block ref="35ef54e3b8ad8ec505bab4b973f86177" category="inline-link-macro-rx"></block></block>
  <block id="b6741313b8f46ab1018ebd6a361c22a4" category="inline-link-macro">ONTAP 9.8 VMware 개요를 위한 최신 기능</block>
  <block id="d393be6d50183d7362f0adb8bc92ae08" category="list-text"><block ref="d393be6d50183d7362f0adb8bc92ae08" category="inline-link-macro-rx"></block></block>
  <block id="b25a3522acbb33341ccacac99424fcce" category="inline-link-macro">VMware vSphere용 SnapCenter 플러그인 활용</block>
  <block id="a65898b7011ddfb663cdba62f90581c6" category="list-text"><block ref="a65898b7011ddfb663cdba62f90581c6" category="inline-link-macro-rx"></block></block>
  <block id="60b0390f50a5ad13d613d49cfe1bce0b" category="inline-link-macro">NetApp 및 NVMe로 VMware 성능 재정의</block>
  <block id="f6dde7f191b6b8f8351902b139ec8672" category="list-text"><block ref="f6dde7f191b6b8f8351902b139ec8672" category="inline-link-macro-rx"></block></block>
  <block id="c576371db342dc9cb166c73b0e157fb5" category="inline-link-macro">AWS 기반 VMware 클라우드를 위한 저비용 성능 세계</block>
  <block id="89487ceb1ada10e49befbbaed3b714ec" category="list-text"><block ref="89487ceb1ada10e49befbbaed3b714ec" category="inline-link-macro-rx"></block></block>
  <block id="92061b0dd7904e2299ac65ed9bc2d6af" category="inline-link-macro">NetApp의 VMware Tanzu 소개</block>
  <block id="ae7c9beb8e4adca6da75607ee83e2403" category="list-text"><block ref="ae7c9beb8e4adca6da75607ee83e2403" category="inline-link-macro-rx"></block></block>
  <block id="a88a91878fb958db59873117d16ad078" category="inline-link-macro">가상 데스크탑 인프라(VDI): 직원 워크스테이션을 온디맨드로 제공합니다</block>
  <block id="9467ff6388811a059199513a0a484f0b" category="list-text"><block ref="9467ff6388811a059199513a0a484f0b" category="inline-link-macro-rx"></block></block>
  <block id="d5e64137a19403f8c1c89f50546b82c5" category="inline-link-macro">AWS 기반 VMware: 아키텍처 및 서비스 옵션</block>
  <block id="6cb2c8a80e576f132097e4d28cec24cd" category="list-text"><block ref="6cb2c8a80e576f132097e4d28cec24cd" category="inline-link-macro-rx"></block></block>
  <block id="cd4efd0ada1938b240dd48aa08010f04" category="inline-link-macro">NetApp Cloud Volumes Service API를 통한 프로그래밍으로 AWS 경험 최적화</block>
  <block id="f61369e9428a21eb1090be340ef36f16" category="list-text"><block ref="f61369e9428a21eb1090be340ef36f16" category="inline-link-macro-rx"></block></block>
  <block id="6d14f3ca0f5be54f01fd579906dd80bb" category="inline-link-macro">Kubernetes: vSphere 및 Tanzu에서 K8s 실행</block>
  <block id="ef8e103737164442c629df5b5d98769d" category="list-text"><block ref="ef8e103737164442c629df5b5d98769d" category="inline-link-macro-rx"></block></block>
  <block id="7e0caac7f6d493fab662f4f4d65ae213" category="section-title">가상화된 Data Fabric을 구축하세요</block>
  <block id="f1f4041236ed90e2a5e65e9a3c858875" category="section-title">최신 VMware용 NetApp 솔루션을 검토해 보십시오</block>
  <block id="0e8dd76bc961a90df87833953de6d067" category="inline-link-macro">ONTAP 기반의 VMware vSphere: NetApp 솔루션</block>
  <block id="b761cb4d962320708880627e8e2fe971" category="inline-link-macro">ONTAP를 사용하는 VMware vSphere 가상 볼륨</block>
  <block id="5b90454e2bf0f381c8f7fc928ef6fb9e" category="list-text"><block ref="5b90454e2bf0f381c8f7fc928ef6fb9e" category="inline-link-macro-rx"></block></block>
  <block id="3390e3575b3e341afa2b7172ff5b33a7" category="inline-link-macro">VMware vSphere용 SnapCenter 플러그인</block>
  <block id="730c2cf92bbe409c31ef1f39cf25377a" category="list-text"><block ref="730c2cf92bbe409c31ef1f39cf25377a" category="inline-link-macro-rx"></block></block>
  <block id="c375e5bb7184da46adef700a9a36d674" category="inline-link-macro">NetApp의 최신 데이터 보호, VMware vSphere 워크로드 설계 및 검증</block>
  <block id="b54be27467e63a98d65e6b17a914e373" category="list-text"><block ref="902dd483e9192a0b4645b4c8be7acbff" category="inline-link-macro-rx"></block></block>
  <block id="b860a89f6215a92f2320f0afe4e0ee05" category="inline-link-macro">VMware 및 AMP용 NetApp의 최신 데이터 보호 클라우드 연결 플래시 솔루션, SQL Server</block>
  <block id="0ebff16085636352cc1aa1e5b0003bdb" category="list-text"><block ref="ac70b8666634dd9095602966c4c61093" category="inline-link-macro-rx"></block></block>
  <block id="eccda9b55035b56259299545d5781136" category="inline-link-macro">VMware Tanzu &amp; amp; ONTAP를 통해 Kubernetes를 더 빠르게 전환하십시오</block>
  <block id="bb79e474557eb86fc30118354eef0039" category="list-text"><block ref="5dd92e330c2d45255a2025ee1eedd52d" category="inline-link-macro-rx"></block></block>
  <block id="7f8cf1c43494d40e935f5e99e38ce659" category="inline-link-macro">AWS에서 VMware Cloud를 실행하는 데 드는 비용 절감</block>
  <block id="f0d8a1b084d604c4db4319a2c5bbd522" category="list-text"><block ref="f0d8a1b084d604c4db4319a2c5bbd522" category="inline-link-macro-rx"></block></block>
  <block id="5ab6c918ee903c74a7d7c97b2432ebaf" category="section-title">최신 VMware 솔루션의 비디오 데모를 살펴보십시오</block>
  <block id="7128c22bfdae1fe8be75c9a9ee56eca9" category="inline-link-macro">VMware vSphere 및 NetApp ONTAP 모범 사례</block>
  <block id="d2fa143a4aaef3477f2edb0d92676341" category="inline-link-macro">VMware 환경 - NVMe-oF with ONTAP에서 실행하겠습니다</block>
  <block id="207681662de4971035cc8d5c9347c986" category="list-text"><block ref="207681662de4971035cc8d5c9347c986" category="inline-link-macro-rx"></block></block>
  <block id="e9c2b8b8a9962013c07f83742ca35f0e" category="inline-link-macro">ONTAP 도구 및 VMware SRM을 사용한 VVOL 재해 복구</block>
  <block id="8ca7386c3cb63b01ffc6387ba41427ae" category="list-text"><block ref="8ca7386c3cb63b01ffc6387ba41427ae" category="inline-link-macro-rx"></block></block>
  <block id="e308c2a1dacddb5bc6ffa093081111e4" category="inline-link-macro">Data Fabric을 위한 VMware 백업 및 복구</block>
  <block id="9934e59457fa5f31d39a58f1d55ac5d5" category="list-text"><block ref="9934e59457fa5f31d39a58f1d55ac5d5" category="inline-link-macro-rx"></block></block>
  <block id="c10a86f3b9530baf3bed3b02aaaf873f" category="section-title">VMware용 유연한 하이브리드 클라우드 및 현대화된 애플리케이션 인프라를 구축합니다</block>
  <block id="554cfab3938e21d9270bd6b75931f96f" category="section-title">비디오</block>
  <block id="f20368920280b50131814db2f83fda66" category="inline-link-macro">NetApp All Flash FAS를 기반으로 VMware 데이터 저장소 설계</block>
  <block id="8ff6498eeabd53b4271d75f543dc3bc4" category="list-text"><block ref="8ff6498eeabd53b4271d75f543dc3bc4" category="inline-link-macro-rx"></block></block>
  <block id="f1c2408ffc6e67ac6b34eb8da2b3039c" category="list-text"><block ref="f1c2408ffc6e67ac6b34eb8da2b3039c" category="inline-link-macro-rx"></block></block>
  <block id="253d309203cf1f2c1bb57255bd0a5bdc" category="inline-link-macro">VMware VM을 Google Cloud로 마이그레이션합니다</block>
  <block id="7518aab5e189037f632ee46ea9e3cf07" category="video-title">VMware Tanzu용 동적 영구 NetApp 스토리지 구축 1부</block>
  <block id="f86bf601d6e42c44cf076ea1772ae13c" category="video-title">VMware Tanzu용 동적 영구 NetApp 스토리지 구축 2부</block>
  <block id="bf5c12d4eed319d2dc2b2b7279944f71" category="video-title">Deploying Dynamic Persistent NetApp Storage for VMware Tanzu, 3을 참조하십시오</block>
  <block id="d6b9ea32b921a9f56de32062ba4b94f3" category="section-title">블로그</block>
  <block id="a398d57165e21c951dd9c9def41598a9" category="inline-link-macro">AWS 기반 VMware 클라우드: Fujitsu가 CVO를 사용하여 수백만 달러를 절약하는 방법</block>
  <block id="d750d47d5e87a6c526e7b40e12eab95b" category="list-text"><block ref="d750d47d5e87a6c526e7b40e12eab95b" category="inline-link-macro-rx"></block></block>
  <block id="3ca2b14e719d79aed66780282e879db4" category="section-title">NetApp 및 VMware 전문가에게 문의하십시오</block>
  <block id="20475522c77401af1c203f23942ffda5" category="inline-link-macro">VMware 솔루션 토론 포럼에 참여하십시오</block>
  <block id="1dccc60a61431b3ef3f48709a0f68de7" category="list-text"><block ref="1dccc60a61431b3ef3f48709a0f68de7" category="inline-link-macro-rx"></block></block>
  <block id="a5810200dda7a3f37fc7eae5378cc8f3" category="inline-link-macro">시작하려면 NetApp 글로벌 서비스 팀에 문의하십시오</block>
  <block id="efb954cbfdbe0c54f04c904a2719b98a" category="list-text"><block ref="efb954cbfdbe0c54f04c904a2719b98a" category="inline-link-macro-rx"></block></block>
  <block id="a7ba4bd9aa10b0456b8f13ef40a2d1d5" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP 스토리지 FCoE VMFS 데이터 저장소를 구축하는 단계를 제공합니다.</block>
  <block id="1937a4bfde18bb02682d378132d0b6a9" category="doc">vSphere VMFS 데이터 저장소 - ONTAP를 사용하는 이더넷 스토리지 프로토콜을 통한 Fibre Channel</block>
  <block id="66439ac6171413528646918952bff23e" category="paragraph">이 섹션에서는 FCoE(Fibre Channel over Ethernet) 전송 프로토콜을 사용하여 ONTAP 스토리지로 VMFS 데이터 저장소를 생성하는 방법에 대해 설명합니다.</block>
  <block id="6b70d8f91894fa50b3c04af804f090b6" category="list-text">vSphere 환경 및 ONTAP를 관리하는 데 필요한 기본 기술</block>
  <block id="b087c7e1213b84e69de1a6e5214cd942" category="list-text">{ONTAP_VERSION}을 실행하는 ONTAP 스토리지 시스템(FAS/AFF/CVO/ONTAP Select</block>
  <block id="d9da372e69584852a9808bfa9fcc99a9" category="inline-link-macro">지원되는 FCoE 조합</block>
  <block id="b61947ecee08267d1f6930ccbd646d52" category="list-text"><block ref="b61947ecee08267d1f6930ccbd646d52" category="inline-link-macro-rx"></block></block>
  <block id="08b42ec45ef1147093b9161cc743b0a0" category="inline-link-macro">완성된 구성 워크시트</block>
  <block id="bcf78e9148ebbc12ed4a54d2149cc2bc" category="list-text"><block ref="bcf78e9148ebbc12ed4a54d2149cc2bc" category="inline-link-macro-rx"></block></block>
  <block id="24c066a87410cc7b08ad4b5ca45565d7" category="list-text">vCenter Server 자격 증명</block>
  <block id="c7f58b1f94665d7ebf6f107970d1b91b" category="list-text">vSphere 호스트 정보입니다</block>
  <block id="cdce6351191da46d795898e4570b8da2" category="list-text">{vSphere_version}</block>
  <block id="80ba2a0b5b5ae31742a18c682e724b6e" category="list-text">ONTAP FC 데이터 포트 또는 vSphere 호스트가 연결된 경우</block>
  <block id="52dd4b667b031cd80a33b9d176e43827" category="list-text">N_port ID 가상화(NPIV) 기능이 활성화된 경우</block>
  <block id="46fdd1539543376bfbbf2cc6da976539" category="list-text">단일 이니시에이터 단일 타겟 존을 생성합니다.</block>
  <block id="d7b3fbe677a7bffd7e387a3578d6b481" category="inline-link-macro">FC/FCoE 조닝 구성</block>
  <block id="434da439fcd2a7729ac67cef537d6651" category="list-text"><block ref="434da439fcd2a7729ac67cef537d6651" category="inline-link-macro-rx"></block></block>
  <block id="9068992a529de63b07b7c2250be12f87" category="list-text">네트워크 스위치</block>
  <block id="5d914ccaef7b5404838cb47cff27fa11" category="list-text">FCoE 지원</block>
  <block id="b74438cda33fca6618da9e30ef5fee5d" category="list-text">DCB 지원</block>
  <block id="69b788fe29f78e1fb439efd1bec08ab6" category="inline-link-macro">FCoE에 대한 점보 프레임입니다</block>
  <block id="e92f4c11834e879e94fa441894d8e9c9" category="list-text"><block ref="e92f4c11834e879e94fa441894d8e9c9" category="inline-link-macro-rx"></block></block>
  <block id="503023bddb3bd1c7803b35b4ace6aa7a" category="list-text">구축, 구성 및 바로 사용할 수 있는 VMware vSphere용 ONTAP 툴</block>
  <block id="42cdbee955a0e208306a321b74a948b1" category="section-title">VMFS 데이터 저장소를 프로비저닝합니다</block>
  <block id="f067d14dc86c5c0ec984803b3485a7a6" category="inline-link-macro">FCoE 구성이 지원되는지 확인합니다</block>
  <block id="79d164739c1e0aaf7f56e13c2a4c66ac" category="list-text"><block ref="4201ef99768aac8f72883e5cb6ec656f" category="inline-link-macro-rx"></block>.</block>
  <block id="7fcd357d480b8eaa4a38cdbbddfd6c97" category="list-text"><block ref="7fcd357d480b8eaa4a38cdbbddfd6c97" category="inline-link-macro-rx"></block></block>
  <block id="f2a0a9000f5ff3910235e570c0ac5e44" category="list-text">'system license show' 명령을 사용하여 FCP가 나열되는지 확인합니다.</block>
  <block id="8b3434ec0db76b4d537ae9c645aa913c" category="list-text">사용권을 추가하려면 'license add-license-code &lt;license code&gt;'를 사용하십시오.</block>
  <block id="e5b8ca3e9ff580bcc9315fabcb34312e" category="list-text">SVM에서 FCP 프로토콜이 활성화되어 있는지 확인합니다.</block>
  <block id="169e237a691059b9ac1933f0e7be8f56" category="inline-link-macro">기존 SVM에서 FCP를 확인합니다.</block>
  <block id="5bb60b756067a0334c310be1e2260c3b" category="list-text"><block ref="5bb60b756067a0334c310be1e2260c3b" category="inline-link-macro-rx"></block></block>
  <block id="fab6621b43b19a018afc1860a5b85c21" category="inline-link-macro">기존 SVM에서 FCP를 구성합니다.</block>
  <block id="7d4ca3fa89beb77990d305e17ed9ba64" category="list-text"><block ref="7d4ca3fa89beb77990d305e17ed9ba64" category="inline-link-macro-rx"></block></block>
  <block id="015c565181667d59b83b7761e35682d1" category="inline-link-macro">FCP를 사용하여 새 SVM을 생성합니다.</block>
  <block id="de4606f963140e2d2d0a3df251ffd646" category="list-text"><block ref="de4606f963140e2d2d0a3df251ffd646" category="inline-link-macro-rx"></block></block>
  <block id="2d6fd01ea0767b50e214a74ff1fcfae0" category="list-text">SVM에서 FCP 논리 인터페이스를 사용할 수 있는지 확인합니다.</block>
  <block id="46f04290f169589dff914e050d1a987b" category="list-text">GUI로 SVM을 생성할 때 논리 인터페이스는 이 프로세스의 일부입니다.</block>
  <block id="ee7f4720a3fc60686c4a9f7429a60cbc" category="list-text">네트워크 인터페이스의 이름을 바꾸려면 네트워크 인터페이스 수정 을 사용합니다.</block>
  <block id="6e67c7d604ae439f60ceb51480fdbb1c" category="inline-link-macro">LUN을 생성하고 매핑합니다</block>
  <block id="e4eeb9421963195597743339d2f38ff6" category="list-text"><block ref="96e32c32f267ac1d65d603f36f017a41" category="inline-link-macro-rx"></block>VMware vSphere용 ONTAP 툴을 사용하는 경우 이 단계를 건너뛰십시오.</block>
  <block id="e4f7ebeb9544fb23a73028ab714ca87c" category="section-title">VMware vSphere 작업</block>
  <block id="f6c0391a150cfd40a68682285c56e835" category="inline-link-macro">스토리지 어댑터 정보입니다</block>
  <block id="60f05805eb8189d665c19856d5388e3c" category="list-text">HBA 드라이버가 설치되어 있는지 확인합니다. VMware 지원 HBA에는 드라이버가 기본적으로 배포되어 있으며 에서 볼 수 있습니다 <block ref="c5f1cce809af8cfecf09908d33f4c097" category="inline-link-macro-rx"></block>.</block>
  <block id="c57f32bc5ce6f95f5f9bec8260ecdb08" category="inline-link-macro">ONTAP 툴을 사용하여 VMFS 데이터 저장소를 프로비저닝합니다</block>
  <block id="b3a5f140339b1ca0940c5875b2a76d0b" category="list-text"><block ref="89ebfed741bd060c10a4a1472581f4e2" category="inline-link-macro-rx"></block>.</block>
  <block id="fa7b524ea902bff51145e4279b653d84" category="summary">이 페이지에서는 비디오 및 자습서에 대한 소개 및 설명을 제공합니다.</block>
  <block id="4267881eb271396086a3cc1387da9a3a" category="section-title">NetApp과 VMware Tanzu</block>
  <block id="2dd739333b022cfeccd93e19c8c39d83" category="paragraph">VMware Tanzu를 사용하면 vSphere 또는 VMware Cloud Foundation을 통해 Kubernetes 환경을 구축, 관리 및 관리할 수 있습니다. 고객은 VMware의 이 제품 포트폴리오를 통해 요구사항에 가장 적합한 VMware Tanzu 에디션을 선택하여 단일 제어 플레인에서 모든 관련 Kubernetes 클러스터를 관리할 수 있습니다.</block>
  <block id="f8d0723a562ed498a977795477b75cb0" category="inline-link">VMware Tanzu 개요</block>
  <block id="2d3e9ef8ae693e8ff80c4d6e70f0a876" category="paragraph">VMware Tanzu에 대한 자세한 내용은 를 참조하십시오<block ref="1951d4038519ab642a1c0f8898cecfe0" category="inline-link-rx"></block>. 이 리뷰에서는 VMware Tanzu에 대한 사용 사례, 추가 기능 및 기타 정보를 제공합니다.</block>
  <block id="31c49b154032d3d6039542b651e0f3d4" category="list-text"><block ref="31c49b154032d3d6039542b651e0f3d4" category="inline-link-rx"></block></block>
  <block id="fcf1189eaf4e4e32d27ee5174d63ae3c" category="list-text"><block ref="fcf1189eaf4e4e32d27ee5174d63ae3c" category="inline-link-rx"></block></block>
  <block id="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="list-text"><block ref="5963b1ea39cb7cc8a0a4f5ce7c5ef816" category="inline-link-rx"></block></block>
  <block id="20cf4402cce1622d010e58ef54b0c753" category="section-title">NetApp 및 Red Hat OpenShift의 조합</block>
  <block id="0454c59b86dfb678c92c2c7480958d1c" category="paragraph">엔터프라이즈 Kubernetes 플랫폼인 Red Hat OpenShift를 사용하면 오픈 하이브리드 클라우드 전략으로 컨테이너 기반 애플리케이션을 실행할 수 있습니다. Red Hat OpenShift는 주요 퍼블릭 클라우드 또는 자가 관리 소프트웨어에서 클라우드 서비스로 사용할 수 있으며 컨테이너 기반 솔루션을 설계할 때 고객이 필요로 하는 유연성을 제공합니다.</block>
  <block id="2426b725f5be26f50931584ae804c2eb" category="inline-link">Red Hat OpenShift 개요</block>
  <block id="ad973740d0b3378d367abba8a74a610e" category="paragraph">Red Hat OpenShift에 대한 자세한 내용은 다음을 참조하십시오<block ref="dc6de73076240cafa99651f2d6acfef4" category="inline-link-rx"></block>. 제품 설명서 및 배포 옵션을 검토하여 Red Hat OpenShift에 대해 자세히 알아볼 수도 있습니다.</block>
  <block id="3699cb747ce71b2fed488fef61ad35be" category="inline-link">워크로드 마이그레이션 - NetApp의 Red Hat OpenShift</block>
  <block id="ade88b04ec62ed28eb857e48bc32cef5" category="list-text"><block ref="ade88b04ec62ed28eb857e48bc32cef5" category="inline-link-rx"></block></block>
  <block id="68d13ef3d87e892878a6e6cbb44d1f21" category="inline-link">RHV 기반 Red Hat OpenShift Deployment: NetApp 기반 Red Hat OpenShift</block>
  <block id="a2f2cd3053597e34724347a57620122b" category="list-text"><block ref="a2f2cd3053597e34724347a57620122b" category="inline-link-rx"></block></block>
  <block id="2093983846bbd6cd7e3d486531259f7d" category="summary">이 페이지에서는 ONTAP 및 VMware vSphere에서 사용할 수 있는 하이브리드 클라우드 기능에 대해 설명합니다.</block>
  <block id="df94231e8c7a2b7372365ba3eb8ad621" category="doc">ONTAP 및 vSphere 기반의 하이브리드 클라우드</block>
  <block id="c689fcb3c54ae34ac006a005e03aad07" category="section-title">하이브리드 클라우드에 대해 알아보십시오</block>
  <block id="cc81a55aaf5bd2bdf603a2aea92a875a" category="paragraph">ONTAP 솔루션은 사내 프라이빗 클라우드, 퍼블릭 클라우드 인프라 또는 두 클라우드의 장점인 하이브리드 클라우드를 사용하든 데이터 관리를 간소화하고 최적화할 수 있도록 Data Fabric을 구축할 수 있도록 도와줍니다. 고성능 All-Flash 시스템으로 시작한 다음 디스크 또는 클라우드 스토리지 시스템과 커플하여 데이터 보호 및 클라우드 컴퓨팅을 지원합니다.</block>
  <block id="9afb01441ce427bb3863eaccd46b9b5d" category="paragraph">Azure, AWS, IBM 또는 Google 클라우드 중에서 선택하여 비용을 최적화하고 종속 문제를 방지합니다. OpenStack 및 컨테이너 기술에 대한 고급 지원을 필요에 따라 활용합니다.</block>
  <block id="8a61dac106bf2a7f3b869c8ff58c4ce5" category="paragraph">데이터 보호는 고객이 클라우드 여정을 시작할 때 가장 먼저 시도하는 경우가 많습니다. 주요 데이터의 비동기식 복제만큼 간편하게 보호할 수 있으며 전체 핫 백업 사이트만큼 복잡해질 수 있습니다. 데이터 보호는 기본적으로 NetApp SnapMirror 기술을 기반으로 합니다.</block>
  <block id="d059ff0a497ad1427248dbb8f770b1d5" category="paragraph">일부 고객은 전체 워크로드를 클라우드로 이동하도록 선택합니다. 이는 단순히 클라우드를 데이터 보호에 사용하는 것보다 더 복잡할 수 있지만 클라우드 기반 스토리지를 사용하기 위해 애플리케이션을 재작성할 필요가 없기 때문에 ONTAP를 사용하면 손쉽게 이전할 수 있습니다. 클라우드의 ONTAP는 사내 ONTAP처럼 작동합니다. 사내 ONTAP 시스템은 더 적은 물리적 공간에 더 많은 데이터를 저장하고 거의 사용되지 않는 데이터를 계층화하여 스토리지 비용을 절감할 수 있는 데이터 효율성 기능을 제공합니다. 하이브리드 클라우드 구성을 사용하거나 전체 워크로드를 클라우드로 이동할 때 ONTAP은 스토리지 성능 및 효율성을 극대화합니다.</block>
  <block id="ad622d292f56f20b32a61fe1b8bd2f56" category="paragraph">또한 NetApp은 ONTAP용 클라우드 기반 백업(SnapMirror 클라우드, Cloud Backup Service 및 Cloud Sync), 스토리지 계층화 및 아카이빙 툴(FabricPool)을 제공하여 운영 비용을 줄이고 광범위한 클라우드 활용을 지원합니다.</block>
  <block id="49c437176039e1c910728eac1f332689" category="paragraph">다음 그림은 샘플 하이브리드 클라우드 사용 사례를 보여줍니다.</block>
  <block id="e61ead4102c89a9758572df81301a1d2" category="inline-image-macro">하이브리드 클라우드</block>
  <block id="9188eeccf6b5386d9573cea87cf05102" category="paragraph"><block ref="9188eeccf6b5386d9573cea87cf05102" category="inline-image-macro-rx" type="image"></block></block>
  <block id="293f510d2162f186910d817d97121159" category="inline-link">ONTAP과 클라우드</block>
  <block id="3963100a9d31ca50911a23ac5c87aca1" category="admonition">ONTAP 및 하이브리드 클라우드에 대한 자세한 내용은 를 참조하십시오<block ref="92883b1d8840f28e1ad4810811bf56b5" category="inline-link-rx"></block> ONTAP 9 문서 센터</block>
  <block id="01a7d7174ccc6593753679eefec17d49" category="summary">이 페이지에서는 VMware vSphere 환경에서 기본 ONTAP 기능을 자동화할 때의 이점에 대해 설명합니다.</block>
  <block id="1406aa071af210d31c6a2951fe66ddcc" category="doc">ONTAP 및 vSphere 자동화 소개</block>
  <block id="8e2b0503a0ad76f57c96738d7f0a3b0d" category="section-title">VMware 자동화</block>
  <block id="b5845209cb81dad561de4abe6e4481c4" category="paragraph">자동화는 VMware ESX의 첫 날부터 VMware 환경을 관리하는 데 있어 필수적인 요소입니다. 코드로 인프라를 구축하고 프라이빗 클라우드 운영으로 사례를 확장하는 기능은 확장, 유연성, 셀프 프로비저닝 및 효율성에 관한 문제를 해결하는 데 도움이 됩니다.</block>
  <block id="f7c9a2e2ec395a7e4b605bb3df40abf8" category="paragraph">자동화는 다음 범주로 구성할 수 있습니다.</block>
  <block id="cba6f5a209d4f2ac1839f1c1e0a10051" category="list-text">* 가상 인프라 구축 *</block>
  <block id="f41d0733c4edc0bf273a3d0587efb21e" category="list-text">* 게스트 시스템 작동 *</block>
  <block id="7f2a4b0fa787b1f058accb56cc377af8" category="list-text">* 클라우드 운영 *</block>
  <block id="290a03d97ea4e48144d20f313e0a0826" category="paragraph">관리자는 인프라 자동화와 관련하여 다양한 옵션을 사용할 수 있습니다. 호스트 프로필 등의 기본 vSphere 기능 또는 가상 머신에 대한 사용자 지정 사양을 VMware 소프트웨어 구성 요소, 운영 체제 및 NetApp 스토리지 시스템의 사용 가능한 API에 사용할 수 있는지 여부와 관계없이, 관련 설명서와 지침을 참조할 수 있습니다.</block>
  <block id="217dd73ccc3bd89b5d4e35d0bf50ea6c" category="paragraph">Data ONTAP 8.0.1 이상은 ESX 호스트가 ESX 4.1 이상을 실행하는 경우 VAAI(VMware vSphere APIs for Array Integration) 기능을 지원합니다. VAAI는 VMware vSphere ESXi 호스트와 스토리지 디바이스 간의 통신을 지원하는 API 세트입니다. 이러한 기능은 ESX 호스트에서 스토리지 시스템으로 작업을 오프로드하고 네트워크 처리량을 늘리는 데 도움이 됩니다. ESX 호스트는 올바른 환경에서 자동으로 기능을 활성화합니다. VAAI 카운터에 포함된 통계를 확인하여 시스템에서 VAAI 기능을 사용하는 범위를 결정할 수 있습니다.</block>
  <block id="16123583d64fd438c5d7f5b61a1c1d2f" category="paragraph">VMware 환경 구축을 자동화하는 가장 일반적인 시작 지점은 프로비저닝 블록 또는 파일 기반 데이터 저장소입니다. 해당 자동화를 개발하기 전에 실제 작업의 요구 사항을 매핑하는 것이 중요합니다.</block>
  <block id="a78bd4dd1db96affe0c2889376cccf53" category="paragraph">VMware 환경 자동화에 대한 자세한 내용은 다음 리소스를 참조하십시오.</block>
  <block id="ebd98e15bf07fe37dfdc879f9d0d1f48" category="inline-link">NetApp 펍</block>
  <block id="6123648b7dec055b609781b4d47c1b26" category="list-text"><block ref="6c65ff4f1dfb7aa26df896b1c9c849eb" category="inline-link-rx"></block>. NetApp 구성 관리 및 자동화:</block>
  <block id="7c4272bef0cc405b65fc74e3791664bc" category="inline-link">VMware용 Ansible Galaxy 커뮤니티</block>
  <block id="59fb42204e71850f7fd7024e5e6a1058" category="list-text"><block ref="c471bcaf7efa6fb129f37edaa7c41a56" category="inline-link-rx"></block>. VMware를 위한 Ansible 리소스 모음입니다.</block>
  <block id="1ec695bd70399ce37180f1d84a33d151" category="inline-link">VMware {code} 리소스</block>
  <block id="489c5322cef99651507b070e2240b6a8" category="list-text"><block ref="77e0562f07512a7a248241b7170b6944" category="inline-link-rx"></block>. 포럼, 설계 표준, 샘플 코드 및 개발자 도구를 비롯하여 소프트웨어 정의 데이터 센터를 위한 솔루션을 설계하는 데 필요한 리소스입니다.</block>
  <block id="c9b6ad26821d78c27282a65584d5f485" category="summary">NetApp은 온프레미스와 클라우드 모두에서 강력한 가상화 환경을 위한 다수의 모범 사례와 솔루션을 제공합니다.</block>
  <block id="ba64ee63cc4950b57bfb868fabec0db3" category="doc">가상화를 위한 NetApp 솔루션</block>
  <block id="334af7a3f788d83aa889d1ca7bd769f5" category="summary">이 페이지에서는 ONTAP의 스토리지 효율성을 설명합니다.</block>
  <block id="c13f924c3ceac59a16a8a1ea96d43c91" category="doc">ONTAP 스토리지 효율성</block>
  <block id="241a4f0482dfad2f5fc79419b18356c0" category="section-title">이야기를 자세히 알아보십시오</block>
  <block id="185081022bfbcfda8db4798eb4eed8c0" category="paragraph">NetApp은 운영 워크로드에 대한 중복 제거 기능을 최초로 제공했지만 이 분야에서 최초이자 마지막 기술이 아니었습니다. 공간 효율적인 데이터 보호 메커니즘인 ONTAP 스냅샷 복사본에서 시작되어, 성능 저하 없이 VM의 읽기/쓰기 복사본을 즉시 만들어 운영 및 백업을 지원합니다. NetApp은 계속해서 중복제거, 압축, 제로 블록 중복제거 등과 같은 인라인 기능을 제공하여 고가의 SSD에서 최대한의 스토리지를 짜내었습니다. 가장 최근에 ONTAP은 컴팩션을 추가하여 스토리지 효율성을 강화합니다.</block>
  <block id="d019495551b4899a9019567122f1e076" category="list-text">* 인라인 제로 블록 중복제거. * 제로 블록 전체에서 낭비되는 공간을 없앱니다.</block>
  <block id="7634d08ecc5702f74271a3313502ec02" category="list-text">* 인라인 압축 * 데이터 블록을 압축하여 필요한 물리적 스토리지의 양을 줄입니다.</block>
  <block id="8b7bb53489bfc2a6808c1d76314fa0d4" category="list-text">* 인라인 데이터 중복 제거. * 디스크에 있는 기존 블록을 사용하여 들어오는 블록을 제거합니다.</block>
  <block id="b762ae2f528b0eca55e7be3f599e909d" category="list-text">* 인라인 데이터 컴팩션 * 소규모 I/O 작업과 파일을 각 물리적 블록에 압축</block>
  <block id="fba6442665875d123719f22baafc619d" category="inline-image-macro">스토리지 효율성</block>
  <block id="f468c00b41afc3485647008dcf80cba1" category="paragraph"><block ref="f468c00b41afc3485647008dcf80cba1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8405ea940cfeab85adddf9d3ed915a97" category="paragraph">중복제거, 데이터 압축, 데이터 컴팩션을 함께 실행하거나 독립적으로 실행하여 FlexVol 볼륨에서 최적의 공간 절약 효과를 달성할 수 있습니다. 이러한 기능을 결합하여 고객은 VSI의 경우 최대 5:1, VDI의 경우 최대 30:1의 비용을 절감할 수 있었습니다.</block>
  <block id="b8c11cd315128247329c3d878c2143fe" category="inline-link">중복제거, 데이터 압축, 데이터 컴팩션을 사용하여 스토리지 효율성을 높입니다</block>
  <block id="65bbb718266195d68e8d1accfc443e28" category="admonition">ONTAP 스토리지 효율성에 대한 자세한 내용은 를 참조하십시오<block ref="f358a7faf94e9f579d11f8fc4efdbdec" category="inline-link-rx"></block> ONTAP 9 문서 센터</block>
  <block id="02d4482d332e1aef3437cd61c9bcc624" category="doc">문의하기</block>
  <block id="3dd3a0a8eebc543e239dc4af5d76b322" category="paragraph">이 기술 보고서에 대한 의견이 있으십니까?</block>
  <block id="3c48757505a122bf371d1bf0105b6871" category="paragraph">이메일 주소는 doccomments@netapp.com 으로 보내주시고 제목 줄에 TR-4597을 포함시키십시오.</block>
  <block id="3b2287aeb862e195f44c02694fff89fe" category="summary">SnapCenter를 사용하면 여러 작업에 적용할 수 있는 백업 정책을 생성할 수 있습니다. 이러한 정책은 스케줄, 보존, 복제 및 기타 기능을 정의할 수 있습니다. VMware 스냅샷을 생성하기 전에 하이퍼바이저의 I/O 중지 기능을 활용하는 VM 정합성 보장 스냅샷을 옵션으로 선택할 수 있습니다.</block>
  <block id="b1c93d491ba776d955eb2e3b90908fb9" category="doc">기타 vSphere 기능</block>
  <block id="7e7397a7b79323762c61941fc0e6b5f9" category="section-title">데이터 보호</block>
  <block id="343775d7b18c4ca0af9b7fad57690839" category="paragraph">VM을 백업하고 신속하게 복구하는 것은 ONTAP for vSphere의 탁월한 강점 중 하나로서, vCenter에서 VMware vSphere용 SnapCenter 플러그인을 사용하여 이러한 기능을 쉽게 관리할 수 있습니다. Snapshot 복사본을 사용하여 성능에 영향을 주지 않고 VM 또는 데이터 저장소의 빠른 복사본을 만든 다음 SnapMirror를 사용하여 보조 시스템으로 보내 장기적인 오프 사이트 데이터 보호를 제공할 수 있습니다. 이러한 접근 방식은 변경된 정보만 저장하여 스토리지 공간과 네트워크 대역폭을 최소화합니다.</block>
  <block id="0aef2da721f0ab14676f8d6ffb9e7e8c" category="inline-link">권장</block>
  <block id="8cc688149346249b3a92e59282755f3e" category="paragraph">SnapCenter를 사용하면 여러 작업에 적용할 수 있는 백업 정책을 생성할 수 있습니다. 이러한 정책은 스케줄, 보존, 복제 및 기타 기능을 정의할 수 있습니다. VMware 스냅샷을 생성하기 전에 하이퍼바이저의 I/O 중지 기능을 활용하는 VM 정합성 보장 스냅샷을 옵션으로 선택할 수 있습니다. 그러나 VMware 스냅샷의 성능 때문에 게스트 파일 시스템을 중지해야 하는 경우가 아니면 일반적으로 이러한 스냅샷을 사용하지 않는 것이 좋습니다. 대신 ONTAP 스냅샷 복사본을 일반 보호에 사용하고 SnapCenter 플러그인과 같은 애플리케이션 툴을 사용하여 SQL Server 또는 Oracle 등의 트랜잭션 데이터를 보호합니다. 이러한 스냅샷 복사본은 VMware(정합성 보장) 스냅샷과 다르며 장기 보호에 적합합니다. VMware 스냅샷은 전용입니다<block ref="75f5ad475d959e2ecb55267e1a9a54f1" category="inline-link-rx"></block> 성능 및 기타 효과로 인한 단기 사용.</block>
  <block id="26aae91a7d92b32a60b1fbc86c29ee81" category="paragraph">이러한 플러그인은 물리적 환경과 가상 환경 모두에서 데이터베이스를 보호하는 확장된 기능을 제공합니다. vSphere를 사용하면 RDM LUN에 데이터가 저장되어 있는 SQL Server 또는 Oracle 데이터베이스, 게스트 OS에 직접 연결된 iSCSI LUN 또는 VMFS 또는 NFS 데이터 저장소의 VMDK 파일을 보호할 수 있습니다. 플러그인을 사용하면 다양한 유형의 데이터베이스 백업을 지정할 수 있고, 온라인 또는 오프라인 백업을 지원하고, 로그 파일과 함께 데이터베이스 파일을 보호할 수 있습니다. 플러그인은 백업 및 복구 외에도 개발 또는 테스트 용도로 데이터베이스 클론 복제도 지원합니다.</block>
  <block id="1556ba0bf6ea4783cda0ff40e96f0265" category="paragraph">다음 그림은 SnapCenter 구축의 예를 보여 줍니다.</block>
  <block id="54ee9d8cd5db70a761321f3e7d168445" category="paragraph"><block ref="54ee9d8cd5db70a761321f3e7d168445" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c1bef29e8dc34a00e17b06c221d5efe" category="paragraph">향상된 재해 복구 기능을 위해 ONTAP용 NetApp SRA를 VMware Site Recovery Manager와 함께 사용하는 것이 좋습니다. 데이터 저장소를 DR 사이트로 복제할 수 있을 뿐만 아니라, 복제된 데이터 저장소를 클론 복제하여 DR 환경에서 무중단 테스트를 수행할 수도 있습니다. SRA에 내장된 자동화를 통해 운영 중단이 해결된 후 재해 복구 및 운영 재보호 작업도 쉽게 수행할 수 있습니다.</block>
  <block id="650062685b0df8284f1b87f62fa3f9f3" category="inline-link">TR-4128</block>
  <block id="886a3fd32ec402d87ea2b090f8f701b2" category="paragraph">마지막으로, 최고 수준의 데이터 보호를 위해 NetApp MetroCluster를 사용하는 VMware vMSC(vSphere Metro Storage Cluster) 구성을 고려해 보십시오. vMSC는 동기식 복제와 스토리지 기반 클러스터링이 결합된 VMware 인증 솔루션으로, 고가용성 클러스터의 이점을 동일하게 제공하고 별도의 사이트에 분산하여 사이트 재해로부터 보호합니다. NetApp MetroCluster은 단일 스토리지 구성 요소 장애로부터 투명하게 복구하고 사이트 재해 발생 시 단일 명령 복구를 통해 동기식 복제를 위한 비용 효율적인 구성을 제공합니다. vMSC는 에 자세히 설명되어 있습니다<block ref="737e6eedc4568d5bb72c6a6cf1fe681a" category="inline-link-rx"></block>.</block>
  <block id="752d71c042ef775879f6db705ccf6b31" category="section-title">공간 재확보</block>
  <block id="d490382851fbc5bd6720046bf9bc0c03" category="paragraph">VM이 데이터 저장소에서 삭제될 때 공간을 다른 용도로 재확보할 수 있습니다. NFS 데이터 저장소를 사용할 경우 VM이 삭제될 때 공간이 즉시 재확보됩니다. 물론 이 방법은 볼륨이 씬 프로비저닝될 때만 의미가 있습니다. 즉, 볼륨 보장이 없음으로 설정됩니다. 하지만 VM 게스트 OS 내에서 파일이 삭제되면 NFS 데이터 저장소에서 공간이 자동으로 재확보되지 않습니다. LUN 기반 VMFS 데이터 저장소의 경우 ESXi 및 게스트 OS에서 VAAI UNMAP 프리미티브를 스토리지에 발급하여(씬 프로비저닝을 사용하는 경우 다시) 공간을 재확보할 수 있습니다. 릴리스에 따라 이 지원은 수동 또는 자동입니다.</block>
  <block id="6a2bff0a8d10ca0fc6c782e7978f696a" category="inline-link">2057513</block>
  <block id="8927aab76c49d1deb0b407fd261d5aa6" category="inline-link">저장 공간 재확보</block>
  <block id="99a66df20e19a8e18fae37a7f714750a" category="section-title">VM 및 데이터 저장소 클론 생성</block>
  <block id="d355cf5d1a16095124a54902f7cf49db" category="paragraph">스토리지 객체를 클론 복제하면 추가 VM 프로비저닝, 백업/복구 작업 등과 같은 추가 사용을 위한 복사본을 빠르게 생성할 수 있습니다. vSphere에서 VM, 가상 디스크, VVOL 또는 데이터 저장소를 복제할 수 있습니다. 복제된 개체는 대개 자동화된 프로세스를 통해 추가로 사용자 지정할 수 있습니다. vSphere는 전체 복제본 클론과 연결된 클론을 모두 지원하며, 이 클론에서는 원래 객체와 별도로 변경 사항을 추적합니다.</block>
  <block id="78f8f8d69825dfe8e6085151fa565f28" category="paragraph">연결된 클론은 공간을 절약하는 데 좋지만 vSphere에서 VM에 대해 처리하는 I/O 양을 늘려 해당 VM 및 호스트의 성능에 영향을 줄 수 있습니다. 이것이 바로 NetApp 고객이 스토리지 시스템 기반 복제본을 사용하여 두 가지 기능을 최대한 활용하는 경우가 많은 이유입니다. 즉, 스토리지를 효율적으로 사용하고 성능을 향상시킬 수 있습니다.</block>
  <block id="17e1a153b5d05c5a642c93ba9ce3c6de" category="paragraph">다음 그림은 ONTAP 클론을 보여 줍니다.</block>
  <block id="8ee3cd3dba25fb32f1bc38cb528ac998" category="paragraph"><block ref="8ee3cd3dba25fb32f1bc38cb528ac998" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76ee7355875ad5e9f56186ff7da961f6" category="paragraph">클론 복제는 일반적으로 VM, VVOL 또는 데이터 저장소 레벨의 다양한 메커니즘을 통해 ONTAP 소프트웨어를 실행하는 시스템으로 오프로드될 수 있습니다. 여기에는 다음이 포함됩니다.</block>
  <block id="3b6d066ffdecb2beb542ef68e773d4ae" category="list-text">NetApp VASA(vSphere APIs for Storage Awareness) 공급자를 사용하여 VVOL을 이동합니다. ONTAP 클론은 최소한의 I/O 효과로 vCenter에서 관리하는 VVOL 스냅샷 복사본을 생성 및 삭제하는 데 사용됩니다. vCenter를 사용하여 VM을 복제할 수도 있으며, 단일 데이터 저장소/볼륨 내에서 또는 데이터 저장소/볼륨 간에 ONTAP로 오프로드됩니다.</block>
  <block id="059e5a6b7f963e9876ba0129dc1b667d" category="list-text">VAAI(vSphere API – Array Integration)를 사용한 vSphere 클론 생성 및 마이그레이션 SAN 및 NAS 환경 모두에서 VM 클론 복제 작업을 ONTAP로 오프로드할 수 있습니다(NetApp은 NFS용 VAAI를 지원하기 위해 ESXi 플러그인을 제공합니다). vSphere는 NAS 데이터 저장소의 콜드(전원이 꺼진) VM에 대한 작업만 오프로드하는 반면, 핫 VM(클론 생성 및 Storage vMotion)에 대한 작업도 SAN에 오프로드됩니다. ONTAP는 소스, 대상 및 설치된 제품 라이센스를 기반으로 가장 효율적인 방식을 사용합니다. 이 기능은 VMware Horizon View에서 사용할 수도 있습니다.</block>
  <block id="a603c207c7b5801942ff108502676c12" category="list-text">SRA(VMware Site Recovery Manager와 함께 사용) 이 경우 클론은 DR 복제본의 복구를 중단 없이 테스트하는 데 사용됩니다.</block>
  <block id="bb300d356d258c084dbe5da2ca367e08" category="list-text">SnapCenter와 같은 NetApp 툴을 사용한 백업 및 복구 VM 클론은 백업 작업을 확인하는 데 사용되며 개별 파일을 복제할 수 있도록 VM 백업을 마운트하는 데 사용됩니다.</block>
  <block id="524b5b8bc03312baeafbea86df667c4b" category="paragraph">ONTAP 오프로드 클론 복제는 VMware, NetApp 및 타사 툴에서 호출할 수 있습니다. ONTAP로 오프로드되는 클론에는 여러 가지 이점이 있습니다. 대부분의 경우 오브젝트 변경에만 스토리지가 필요한 공간 효율적이며, 데이터를 읽고 쓰는 데는 추가 성능 영향이 없으며, 고속 캐시에서 블록을 공유하여 성능을 향상할 수도 있습니다. 또한 CPU 사이클과 네트워크 I/O를 ESXi 서버에서 오프로드합니다. FlexClone 라이센스가 있는 경우 FlexVol 볼륨을 사용하는 기존 데이터 저장소 내에서 복사 오프로드를 빠르고 효율적으로 수행할 수 있지만, FlexVol 볼륨 간의 복사 속도가 느려질 수 있습니다. VM 템플릿을 클론의 소스로 유지 관리하는 경우 빠르고 공간 효율적인 클론을 위해 데이터 저장소 볼륨(폴더 또는 콘텐츠 라이브러리를 사용하여 구성) 내에 배치하는 것이 좋습니다.</block>
  <block id="f3968368501d882b3969da59138db6e2" category="paragraph">ONTAP 내에서 직접 볼륨 또는 LUN을 복제하여 데이터 저장소를 복제할 수도 있습니다. NFS 데이터 저장소를 사용하면 FlexClone 기술을 통해 전체 볼륨을 클론 복제할 수 있으며, ONTAP에서 클론을 내보내고 ESXi에서 다른 데이터 저장소로 마운트할 수 있습니다. VMFS 데이터 저장소의 경우 ONTAP는 LUN 내에 하나 이상의 LUN을 포함하여 볼륨 또는 전체 볼륨 내에서 LUN을 클론 복제할 수 있습니다. VMFS를 포함하는 LUN은 ESXi 이니시에이터 그룹(igroup)에 매핑한 다음 ESXi에 의해 재서명하여 일반 데이터 저장소로 마운트하고 사용해야 합니다. 일부 임시 사용 사례에서는 재서명 없이 클론 생성된 VMFS를 마운트할 수 있습니다. 데이터 저장소의 클론을 생성한 후에는 해당 데이터 저장소 내의 VM을 개별적으로 클론 복제된 VM처럼 등록, 재구성 및 사용자 지정할 수 있습니다.</block>
  <block id="1c12a8dd266e356901d22c0b7711369d" category="paragraph">경우에 따라 라이센스가 부여된 추가 기능을 사용하여 백업용 SnapRestore 또는 FlexClone과 같은 복제를 향상시킬 수 있습니다. 이러한 라이센스는 라이센스 번들에 추가 비용 없이 포함되는 경우가 많습니다. VVOL 클론 복제 작업은 물론 VVOL(하이퍼바이저에서 ONTAP으로 오프로드됨)의 관리되는 스냅샷 복사본을 지원하려면 FlexClone 라이센스가 필요합니다. FlexClone 라이센스는 데이터 저장소/볼륨 내에서 사용할 때 특정 VAAI 기반 클론을 개선할 수도 있습니다. 블록 복사본 대신 즉각적이고 공간 효율적인 복사본을 생성합니다. 또한 SRA에서는 DR 복제본의 복구를 테스트할 때, 클론 작업을 위한 SnapCenter 및 개별 파일을 복원할 백업 복사본을 찾아볼 때 사용됩니다.</block>
  <block id="6d30b2619de7fa18e965516b291a1937" category="section-title">스토리지 효율성 및 씬 프로비저닝</block>
  <block id="616c027f14ee5f1bbc866171c4017141" category="paragraph">NetApp은 운영 워크로드를 위한 최초의 중복제거, 압축을 강화하고 작은 파일 및 I/O를 효율적으로 저장하는 인라인 데이터 컴팩션 등의 스토리지 효율성 혁신을 통해 업계를 선도하고 있습니다. ONTAP는 인라인 및 백그라운드 중복제거와 인라인 및 백그라운드 압축을 모두 지원합니다.</block>
  <block id="8f105eeb6dc3fc4ce0d4758aeab4a256" category="paragraph">다음 그림은 ONTAP 스토리지 효율성 기능이 결합된 결과를 보여 줍니다.</block>
  <block id="4b7a9b58ab55917c054d5a636481a8b8" category="paragraph"><block ref="4b7a9b58ab55917c054d5a636481a8b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8e89f9787f44321e33f85595321efc66" category="paragraph">vSphere 환경에서 ONTAP 스토리지 효율성을 사용하는 방법은 다음과 같습니다.</block>
  <block id="c2eea4e122397fa75d749bdbdcd4302d" category="list-text">데이터 중복 제거 절감 효과는 데이터의 공통성을 기반으로 합니다. ONTAP 9.1 이전 버전에서는 데이터 중복제거가 볼륨 레벨에서 작동되지만 ONTAP 9.2 이상의 애그리게이트 중복제거 기능을 사용하면 AFF 시스템의 애그리게이트에서 모든 볼륨에서 데이터가 중복 제거됩니다. 더 이상 단일 데이터 저장소 내에서 유사한 운영 체제 및 유사한 애플리케이션을 그룹화하지 않아도 절감 효과를 극대화할 수 있습니다.</block>
  <block id="59eb554aa77d0e4dfdc304b3b914dd76" category="list-text">블록 환경에서 중복 제거의 이점을 실현하려면 LUN을 씬 프로비저닝해야 합니다. LUN이 여전히 VM 관리자가 프로비저닝된 용량을 차지하는 것으로 보이더라도 중복 제거 절약 효과가 다른 요구에 사용될 볼륨으로 반환됩니다. 씬 프로비저닝된 FlexVol 볼륨에 이러한 LUN을 구축하는 것이 좋습니다. VMware vSphere용 ONTAP 툴은 LUN보다 볼륨 크기를 약 5% 더 크게 조정합니다.</block>
  <block id="1e84230a4e75abc233d64344b14fd511" category="list-text">NFS FlexVol 볼륨에는 씬 프로비저닝도 권장(및 기본값)되어 있습니다. NFS 환경에서는 씬 프로비저닝된 볼륨을 사용하는 스토리지 및 VM 관리자 모두가 중복제거 절약 효과를 즉시 확인할 수 있습니다.</block>
  <block id="b26ed63d0f1199652537e2c4b6752130" category="list-text">씬 프로비저닝은 VM에도 적용되며, NetApp은 일반적으로 일반 파일 대신 씬 프로비저닝된 VMDK를 권장합니다. 씬 프로비저닝을 사용할 때는 ONTAP vSphere, ONTAP 또는 기타 사용 가능한 툴을 사용하여 사용 가능한 공간을 모니터링하여 공간 부족 문제를 방지해야 합니다.</block>
  <block id="041f3a2c9d939c181dbd2a95595455d0" category="list-text">ONTAP 시스템에서 씬 프로비저닝을 사용할 경우 성능 저하가 발생하지 않습니다. 데이터는 사용 가능한 공간에 작성되므로 쓰기 성능과 읽기 성능이 극대화됩니다. 이러한 사실에도 불구하고 Microsoft 장애 조치 클러스터링 또는 기타 지연 시간이 짧은 애플리케이션과 같은 일부 제품은 보장되거나 고정 프로비저닝이 필요할 수 있으며, 지원 문제를 피하기 위해 이러한 요구사항을 따르는 것이 좋습니다.</block>
  <block id="473c8efc5f9b8640820a9cc1f9c84862" category="list-text">중복 제거를 최대한 절약하기 위해서는 하드 디스크 기반 시스템에서 백그라운드 중복제거를 예약하거나 AFF 시스템에서 자동 백그라운드 중복제거를 사용하는 것이 좋습니다. 그러나 예약된 프로세스는 실행 시 시스템 리소스를 사용하므로 주말과 같이 사용량이 적은 시간에 일정을 계획하거나 자주 실행하여 변경된 데이터 처리 양을 줄이는 것이 좋습니다. AFF 시스템에서 자동 백그라운드 중복 제거를 수행하면 전경 작업에 미치는 영향이 훨씬 적습니다. 백그라운드 압축(하드 디스크 기반 시스템의 경우)도 리소스를 사용하므로 성능 요구사항이 제한적인 2차 워크로드에만 고려해야 합니다.</block>
  <block id="dd76252ea7a50def2a98f218cb1505b4" category="inline-link">KB 문서를 참조하십시오</block>
  <block id="ac2fab512a521d04e53c7257ef490187" category="list-text">NetApp AFF 시스템은 주로 인라인 스토리지 효율성 기능을 사용합니다. 7-Mode Transition Tool, SnapMirror 또는 Volume Move와 같은 블록 복제를 사용하는 NetApp 툴을 사용하여 데이터를 해당 데이터 위치로 이동할 경우, 압축 및 컴팩션 스캐너를 실행하여 효율성 절약 효과를 극대화하는 것이 좋습니다. 이 NetApp Support를 검토하십시오<block ref="a24ae202a787a3e4695f02339b72bb57" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="af21d2d4e0d0faaa6435e780ed7fbc49" category="list-text">스냅샷 복사본은 압축 또는 중복제거에 의해 줄어들 수 있는 블록을 잠글 수 있습니다. 예약된 백그라운드 효율성 또는 일회성 스캐너를 사용할 때는 다음 스냅샷 복사본을 생성하기 전에 이러한 작업이 실행되고 완료되었는지 확인하십시오. 스냅샷 복사본 및 보존을 검토하여 백그라운드 또는 스캐너 작업을 실행하기 전에 필요한 스냅샷 복사본만 보존하는지 확인합니다.</block>
  <block id="8f4468ee9f4f074a9f705cd8240de3d9" category="paragraph">다음 표에는 여러 유형의 ONTAP 스토리지에서 가상화된 워크로드를 위한 스토리지 효율성 지침이 나와 있습니다.</block>
  <block id="68eaabb91b0d1c52be44217a24f27b91" category="cell">워크로드</block>
  <block id="84f3306d313cbbe707b0df3807aa77ef" category="cell">스토리지 효율성 지침</block>
  <block id="c8984126713ed072b9cb0a44a162be4d" category="cell">AFF</block>
  <block id="5325da9878854628027602da18e5fc14" category="cell">Flash Pool을 참조하십시오</block>
  <block id="9aa1187640093122ffdb7e1c18f8586d" category="cell">하드 디스크 드라이브</block>
  <block id="9bbf225892f3ce69fc504d145abe3ded" category="cell">VDI 및 SVI</block>
  <block id="1be6174441cf80d01c59eb7a9c004498" category="paragraph">운영 워크로드 및 보조 워크로드에는 다음 사용:</block>
  <block id="738b6df06bc30a1f2fa6d500095bfceb" category="list-text">적응형 인라인 압축</block>
  <block id="f801303ba7009e27cce2fe9a73dc5ebe" category="list-text">인라인 중복제거</block>
  <block id="f94a70bfe4407315e07db5e64706e531" category="list-text">백그라운드 중복제거</block>
  <block id="95f3762d2d933ff2c0f6e30ef2c767c9" category="list-text">인라인 데이터 컴팩션</block>
  <block id="22be9b04282591df89574efb0e9d2315" category="paragraph">운영 워크로드에는 다음 사용:</block>
  <block id="e37f23785e68eb0a9d5afd7457b0903e" category="paragraph">보조 워크로드에는 다음 사용:</block>
  <block id="7901e1160498e7aff40dc0f858411c54" category="list-text">적응형 백그라운드 압축</block>
  <block id="be0ec3d9251292dd856ea0924ecc6873" category="section-title">서비스 품질(QoS)</block>
  <block id="f437881fa7e42bf0e4563bbec8176f81" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템에서는 ONTAP 스토리지 QoS 기능을 사용하여 파일, LUN, 볼륨 또는 전체 SVM과 같은 다양한 스토리지 개체에 대해 Mbps 또는 IOPS 단위로 처리량을 제한할 수 있습니다.</block>
  <block id="fb4aa9631cd742ae8a88f672b4464b37" category="paragraph">처리량 제한은 다른 워크로드에 영향을 주지 않도록 구축하기 전에 알 수 없거나 워크로드를 테스트하는 데 유용합니다. 이러한 워크로드는 식별된 후 대규모 워크로드를 제한하는 데 사용할 수도 있습니다. ONTAP 9.2의 SAN 오브젝트 및 ONTAP 9.3의 NAS 오브젝트에 대해 일관된 성능을 제공하기 위해 IOPS를 기반으로 하는 최소 서비스 레벨도 지원됩니다.</block>
  <block id="3e4a2dc31acddb628ba286d25b1bd36e" category="paragraph">NFS 데이터 저장소를 사용하면 QoS 정책을 전체 FlexVol 볼륨 또는 해당 볼륨 내의 개별 VMDK 파일에 적용할 수 있습니다. ONTAP LUN을 사용하는 VMFS 데이터 저장소의 경우 FlexVol가 VMFS 파일 시스템을 인식하지 못하기 때문에 QoS 정책을 LUN 또는 개별 LUN을 포함하는 ONTAP 볼륨에 적용할 수 있지만 개별 VMDK 파일은 적용할 수 없습니다. VVOL을 사용할 경우 스토리지 용량 프로파일 및 VM 스토리지 정책을 사용하여 개별 VM에 최소 및/또는 최대 QoS를 설정할 수 있습니다.</block>
  <block id="534ecd446aac2f9c809eef9064f44aab" category="paragraph">개체에 대한 QoS 최대 처리량 제한은 Mbps 및/또는 IOPS로 설정할 수 있습니다. 둘 다 사용되는 경우 첫 번째 제한에 도달한 값은 ONTAP에 의해 적용됩니다. 워크로드에는 여러 개체가 포함될 수 있으며 QoS 정책을 하나 이상의 워크로드에 적용할 수 있습니다. 정책이 여러 워크로드에 적용될 경우 워크로드는 정책의 총 한도를 공유합니다. 중첩된 개체는 지원되지 않습니다(예: 볼륨 내의 파일은 각각 고유한 정책을 가질 수 없음). QoS 최소값을 IOPS에서만 설정할 수 있습니다.</block>
  <block id="040f184b126879657b253b6d258661d9" category="paragraph">현재 ONTAP QoS 정책을 관리하고 객체에 적용하는 데 사용할 수 있는 툴은 다음과 같습니다.</block>
  <block id="de134183bea5df515a6756a539ce6f18" category="list-text">ONTAP CLI를 참조하십시오</block>
  <block id="6ad5e0a20f49ad6a370454bb3afc9a9e" category="list-text">ONTAP 시스템 관리자</block>
  <block id="8e23e05fc0865e950d6a3581e0dd8ce9" category="list-text">OnCommand Workflow Automation</block>
  <block id="5ecb6b24c169667ff1a176768115659e" category="list-text">Active IQ Unified Manager</block>
  <block id="8cc4e713850f67a131e9dbf8b997f61e" category="list-text">ONTAP를 위한 NetApp PowerShell Toolkit</block>
  <block id="fcdb48d0d22627e4910a8352c80bd87a" category="list-text">VMware vSphere VASA Provider용 ONTAP 툴</block>
  <block id="e6defd03e0f49585b6d47614713e97f7" category="paragraph">NFS에서 VMDK에 QoS 정책을 할당하려면 다음 지침을 따르십시오.</block>
  <block id="10509998e8d4c4d7be30fc1d0b6b2a1e" category="list-text">이 정책은 vmname.vmdk(가상 디스크 설명자 파일) 또는 vmname.vmx(VM 설명자 파일)가 아닌 실제 가상 디스크 이미지가 포함된 vmname-flat.vmdk에 적용해야 합니다.</block>
  <block id="2175e0e29bc4b213fa8b9c7afd591b6b" category="list-text">가상 스왑 파일("vmname.vswp")과 같은 다른 VM 파일에는 정책을 적용하지 마십시오.</block>
  <block id="8230e9b5c1e9862fedb2c69f7cc5d3d1" category="list-text">vSphere 웹 클라이언트를 사용하여 파일 경로(데이터 저장소 &gt; 파일)를 찾을 때는 "-flat.vmdk" 및 "의 정보가 결합된다는 점에 유의하십시오. VMDK를 표시하고 이름이 인 파일을 하나만 표시합니다. VMDK로, 그러나 -flat.vmdk의 크기입니다. 파일 이름에 -flat를 추가하여 올바른 경로를 가져옵니다.</block>
  <block id="1d4614aca13104c98d5d8cc2d415b941" category="paragraph">VMFS 및 RDM을 포함하여 LUN에 QoS 정책을 할당하려면 ONTAP vSphere용 ONTAP 툴 홈 페이지의 스토리지 시스템 메뉴에서 SVM(SVM으로 표시됨), LUN 경로 및 일련 번호를 확인할 수 있습니다. 스토리지 시스템(SVM)을 선택한 다음 관련 오브젝트 &gt; SAN을 선택합니다. ONTAP 툴 중 하나를 사용하여 QoS를 지정할 때 이 접근 방식을 사용합니다.</block>
  <block id="8ce0096ff26ebe0a38466de6a64f461d" category="paragraph">VMware vSphere 또는 Virtual Storage Console 7.1 이상을 위한 ONTAP 툴을 VVOL 기반 VM에 최대 및 최소 QoS를 손쉽게 할당할 수 있습니다. VVol 컨테이너의 저장소 용량 프로필을 생성할 때 성능 기능에서 최대 및/또는 최소 IOPS 값을 지정한 다음 VM의 저장소 정책으로 이 SCP를 참조합니다. VM을 생성하거나 기존 VM에 정책을 적용할 때 이 정책을 사용합니다.</block>
  <block id="421c9efa4ff1b039a5378be7bc1e2e49" category="paragraph">FlexGroup 데이터 저장소는 VMware vSphere 9.8 이상용 ONTAP 툴을 사용할 때 향상된 QoS 기능을 제공합니다. 데이터 저장소 또는 특정 VM의 모든 VM에 대해 QoS를 쉽게 설정할 수 있습니다. 자세한 내용은 이 보고서의 FlexGroup 섹션을 참조하십시오.</block>
  <block id="77bb2ba950959bd3f1c55da523ace0be" category="section-title">ONTAP QoS 및 VMware SIOC</block>
  <block id="b2e21dac6070ea83831ff6521a66a447" category="paragraph">ONTAP QoS 및 VMware vSphere 스토리지 I/O 제어(SIOC)는 vSphere 및 스토리지 관리자가 ONTAP 소프트웨어를 실행하는 시스템에서 호스팅되는 vSphere VM의 성능을 관리하는 데 함께 사용할 수 있는 보완 기술입니다. 다음 표에 나와 있는 것처럼 각 툴마다 고유한 강점이 있습니다. VMware vCenter와 ONTAP의 범위가 서로 다르기 때문에 한 시스템에서 일부 객체를 보고 관리할 수 있으며 다른 객체는 볼 수 없습니다.</block>
  <block id="5ad234cb2cde4266195252a23ca7d84e" category="cell">속성</block>
  <block id="b8b8d1ba8fa345f03438a90f29af5784" category="cell">ONTAP QoS를 참조하십시오</block>
  <block id="c2a4cb962db2a4a6782b69864f0e411c" category="cell">VMware SIOC</block>
  <block id="aa628d5a66888444926b4dc042458200" category="cell">활성화 시</block>
  <block id="688b10fcfff927dee65634e3b3636064" category="cell">정책이 항상 활성화되어 있습니다</block>
  <block id="a981c4aa67c29ff2d36fc614d8b28808" category="cell">경합이 있을 때 활성(데이터 저장소 지연 시간이 임계값을 초과함)</block>
  <block id="f46e64a82c96db56f3d6657d4fb53f00" category="cell">단위 유형</block>
  <block id="878b4223bb85b95d8caf0429d9406cd5" category="cell">IOPS, MBps</block>
  <block id="3e189a34f422a141311dad231f9ad5b5" category="cell">IOPS, 공유</block>
  <block id="7367a0ec46339213625cbc77d56a9572" category="cell">vCenter 또는 애플리케이션 범위</block>
  <block id="1faff19290bb64ce8ff6bc1220496881" category="cell">다양한 vCenter 환경, 기타 하이퍼바이저 및 애플리케이션</block>
  <block id="1e664a3cc0ab109fcabcc81b488cebb1" category="cell">단일 vCenter Server</block>
  <block id="ebccc9f5c939841d86e5382988dfcc47" category="cell">VM에서 QoS를 설정하시겠습니까?</block>
  <block id="cddd0980ce99890d2ea90288f6b03117" category="cell">VMDK는 NFS에만 해당합니다</block>
  <block id="928629d8a2a889f5274cad9940a06da0" category="cell">NFS 또는 VMFS의 VMDK입니다</block>
  <block id="305e85b992089534091855224f60cf75" category="cell">LUN(RDM)에 QoS를 설정하시겠습니까?</block>
  <block id="e798014243cf5682e7fb3aaf4ee7cecf" category="cell">LUN(VMFS)에서 QoS를 설정하시겠습니까?</block>
  <block id="9cd021ea9d3c88de723fe9a2e50a2380" category="cell">볼륨에 QoS를 설정하시겠습니까(NFS 데이터 저장소)?</block>
  <block id="c352b53c32380efcf4436926da6d0414" category="cell">SVM(테넌트)에서 QoS를 설정하시겠습니까?</block>
  <block id="86aad9b5d177180a5b9e828a8e05e819" category="cell">정책 기반 방식</block>
  <block id="b31c76176f26196c6379a9bcce212d99" category="cell">예. 정책의 모든 워크로드에서 공유하거나 정책의 각 워크로드에 전체적으로 적용할 수 있습니다.</block>
  <block id="1ff33557bad923d68973872cacf2e43a" category="cell">예, vSphere 6.5 이상에서 가능합니다.</block>
  <block id="d5f1465492190ee9d30a09b36f64f4b7" category="cell">라이센스가 필요합니다</block>
  <block id="4cec76d82991abd453484c23f7e3788a" category="cell">ONTAP에 포함되어 있습니다</block>
  <block id="6bb36803f4670824ff9ebdf665654829" category="cell">엔터프라이즈급 플러스</block>
  <block id="400cc516a4a40acd605aef2cfd4ba4c0" category="section-title">VMware 스토리지 분산 리소스 스케줄러입니다</block>
  <block id="06604b0172f4ae639ffe8c44fa7c77d8" category="paragraph">VMware SDRS(Storage Distributed Resource Scheduler)는 현재 입출력 지연 시간 및 공간 사용량을 기반으로 스토리지에 VM을 배치하는 vSphere 기능입니다. 그런 다음 데이터 저장소 클러스터(Pod라고도 함)의 데이터 저장소 간에 VM 또는 VMDK를 중단 없이 이동하여 VM 또는 VMDK를 데이터 저장소 클러스터에 배치할 최상의 데이터 저장소를 선택합니다. 데이터 저장소 클러스터는 vSphere 관리자의 관점에서 단일 소비 단위로 집계되는 유사한 데이터 저장소의 모음입니다.</block>
  <block id="5735cfd4d72f50fd28717ac30361b503" category="paragraph">SDRS를 VMware vSphere용 NetApp ONTAP 툴과 함께 사용하는 경우 먼저 플러그인을 사용하여 데이터 저장소를 생성한 다음 vCenter를 사용하여 데이터 저장소 클러스터를 생성한 다음 여기에 데이터 저장소를 추가해야 합니다. 데이터 저장소 클러스터가 생성된 후 세부 정보 페이지의 프로비저닝 마법사에서 추가 데이터 저장소를 데이터 저장소 클러스터에 직접 추가할 수 있습니다.</block>
  <block id="b028cce2007c32457c41f20d2954c0c2" category="paragraph">SDRS에 대한 기타 ONTAP 모범 사례는 다음과 같습니다.</block>
  <block id="d11eff5be5178b7ba95b06270611ffc8" category="list-text">클러스터의 모든 데이터 저장소는 동일한 유형의 스토리지(예: SAS, SATA 또는 SSD)를 사용하고 모든 VMFS 또는 NFS 데이터 저장소이며 복제 및 보호 설정이 동일해야 합니다.</block>
  <block id="76db7ce67615bbc16da685df79ed0aa9" category="list-text">기본(수동) 모드에서 SDRS 사용을 고려하십시오. 이 접근 방식을 통해 권장 사항을 검토하고 적용 여부를 결정할 수 있습니다. VMDK 마이그레이션의 영향을 숙지하십시오.</block>
  <block id="97f4ed95cb52bb29629002a25cb5039f" category="list-text">SDRS에서 VMDK를 데이터 저장소 간에 이동할 경우 ONTAP 클론 생성 또는 중복 제거를 통한 공간 절약이 손실됩니다. 중복제거를 재실행하여 이러한 절약 효과를 다시 실현할 수 있습니다.</block>
  <block id="cc1aa351f771fc36d1542fa93e1fac8e" category="list-text">SDRS에서 VMDK를 이동한 후에는 공간이 이동한 VM에 의해 잠기기 때문에 소스 데이터 저장소에서 스냅샷 복사본을 다시 생성하는 것이 좋습니다.</block>
  <block id="09a99cbc4fb85d10c7af970e79032a05" category="list-text">동일한 애그리게이트에서 데이터 저장소 간에 VMDK를 이동하는 것은 효과가 거의 없으며 SDRS는 애그리게이트를 공유할 수 있는 다른 워크로드를 파악할 수 없습니다.</block>
  <block id="a30850531baecbfbe4486d4be9e79e30" category="section-title">스토리지 정책 기반 관리 및 VVOL</block>
  <block id="f2606439d8a3fed353e38254458c0a32" category="paragraph">VASA(VMware vSphere APIs for Storage Awareness)를 사용하면 스토리지 관리자가 잘 정의된 기능을 사용하여 데이터 저장소를 쉽게 구성할 수 있으며 VM 관리자는 필요할 때마다 상호 작용하지 않고도 데이터 저장소를 사용하여 VM을 프로비저닝할 수 있습니다. 이 접근 방식을 통해 가상화 스토리지 운영을 간소화하고 많은 사소한 작업을 피할 수 있는 방법을 살펴보시기 바랍니다.</block>
  <block id="ad0bd815b4fb6f01acc94f160af3dca7" category="paragraph">VASA 이전에는 VM 관리자가 VM 스토리지 정책을 정의할 수 있었지만 대개 문서 또는 명명 규칙을 사용하여 스토리지 관리자와 협력하여 적절한 데이터 저장소를 식별해야 했습니다. 스토리지 관리자는 VASA를 통해 성능, 계층화, 암호화, 복제를 비롯한 다양한 스토리지 기능을 정의할 수 있습니다. 볼륨 또는 볼륨 세트에 대한 기능 세트를 SCP(Storage Capability Profile)라고 합니다.</block>
  <block id="a3af04d147e48682c8be6bd0c1b66520" category="paragraph">SCP는 VM 데이터 VVol에 대한 최소 및/또는 최대 QoS를 지원합니다. 최소 QoS는 AFF 시스템에서만 지원됩니다. VMware vSphere용 ONTAP 툴에는 ONTAP 시스템에서 VVOL을 위한 VM 레벨의 세분화된 성능과 논리적 용량을 보여주는 대시보드가 포함되어 있습니다.</block>
  <block id="4240fa68f6d9919e6d039c4038175025" category="paragraph">다음 그림은 VMware vSphere 9.8 VVol 대시보드를 위한 ONTAP 툴을 보여 줍니다.</block>
  <block id="d3fcb217aa8b45eb8a95f8958c1f7746" category="paragraph"><block ref="d3fcb217aa8b45eb8a95f8958c1f7746" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6257d346f635c1b16a2f39df0830a48" category="paragraph">스토리지 용량 프로필을 정의한 후에는 요구 사항을 식별하는 스토리지 정책을 사용하여 VM을 프로비저닝하는 데 사용할 수 있습니다. VM 스토리지 정책과 데이터 저장소 스토리지 용량 프로파일 간의 매핑을 통해 vCenter에서 선택할 수 있는 호환 데이터 저장소 목록을 표시할 수 있습니다. 이러한 방식을 스토리지 정책 기반 관리라고 합니다.</block>
  <block id="ca100a4ba1d4641f17806479f93c8b1a" category="paragraph">VASA는 스토리지를 쿼리하고 스토리지 기능 집합을 vCenter에 반환하는 기술을 제공합니다. VASA 공급업체 공급자는 스토리지 시스템 API 및 구성 요소 및 vCenter에서 인식할 수 있는 VMware API 간의 변환을 제공합니다. NetApp의 VASA Provider for ONTAP은 VMware vSphere 어플라이언스 VM을 위한 ONTAP 툴의 일부로 제공되며, vCenter 플러그인을 통해 VVOL 데이터 저장소를 프로비저닝하고 관리할 수 있을 뿐만 아니라 스토리지 기능 프로필(SCP)을 정의할 수 있습니다.</block>
  <block id="dad160104969c39365dd2cd4c98dd300" category="inline-link">TR-4400</block>
  <block id="79f0d5feb7ec25a16c407f3f585eabb2" category="paragraph">ONTAP는 VMFS 및 NFS VVOL 데이터 저장소를 모두 지원합니다. SAN 데이터 저장소와 VVOL을 함께 사용하면 VM 수준 정밀도와 같은 NFS의 몇 가지 이점이 있습니다. 다음은 고려해야 할 몇 가지 모범 사례이며 에서 추가 정보를 찾을 수 있습니다<block ref="4f23d4db151ca74200684ac8aef53fed" category="inline-link-rx"></block>:</block>
  <block id="bd490c925219bcb312338a370589bf70" category="list-text">VVOL 데이터 저장소는 여러 클러스터 노드의 여러 FlexVol 볼륨으로 구성될 수 있습니다. 가장 간단한 방법은 볼륨에 기능이 다른 경우에도 단일 데이터 저장소를 사용하는 것입니다. SPBM은 호환 볼륨이 VM에 사용되는지 확인합니다. 하지만 모든 볼륨은 단일 ONTAP SVM에 속하고 단일 프로토콜을 사용하여 액세스해야 합니다. 각 프로토콜당 하나의 LIF로 충분합니다. 스토리지 기능이 릴리즈별로 다를 수 있으므로 단일 VVOL 데이터 저장소 내에서 여러 ONTAP 릴리즈를 사용하는 것은 피하십시오.</block>
  <block id="0cc956d6da91fefae9dad9b2c8c9519b" category="list-text">VMware vSphere용 ONTAP 툴을 사용하여 VVOL 데이터 저장소를 만들고 관리합니다. 데이터 저장소와 해당 프로필을 관리하는 것 외에도 필요한 경우 데이터 저장소에 액세스하기 위한 프로토콜 엔드포인트가 자동으로 생성됩니다. LUN을 사용하는 경우 LUN PES는 LUN ID 300 이상을 사용하여 매핑됩니다. ESXi 호스트 고급 시스템 설정 Disk.MaxLUN이 300보다 높은 LUN ID 번호를 허용하는지 확인합니다(기본값은 1,024). vCenter에서 ESXi 호스트를 선택한 다음 구성 탭을 선택하고 고급 시스템 설정 목록에서 Disk.MaxLUN을 찾아 이 단계를 수행합니다.</block>
  <block id="fac85f355a1eb47127ef1b94e7603924" category="list-text">VMware vSphere를 위한 VASA Provider, vCenter Server(어플라이언스 또는 Windows 기반) 또는 ONTAP 툴을 VVOL 데이터 저장소에 설치하거나 마이그레이션하지 마십시오. 상호 의존하기 때문에 정전이 발생하거나 기타 데이터 센터가 중단될 경우 이를 관리할 수 없습니다.</block>
  <block id="27bd00c8827fc3d77d1b5650103b676f" category="list-text">VASA Provider VM을 정기적으로 백업합니다. VASA Provider가 포함된 기존 데이터 저장소의 시간별 스냅샷 복사본을 최소한 생성합니다. VASA Provider 보호 및 복구에 대한 자세한 내용은 다음을 참조하십시오<block ref="9d642870dca1748c69f7aa0b6fb95a89" category="inline-link-rx"></block>.</block>
  <block id="2d2d2e356f9ab117b7d2a58d42cc5988" category="paragraph">다음 그림은 VVol 구성 요소를 보여줍니다.</block>
  <block id="6aadcb77504dae1dbfed2e4d1c969158" category="paragraph"><block ref="6aadcb77504dae1dbfed2e4d1c969158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce8b0e3e0d7dc7f39c62fb74a28b3bf" category="section-title">클라우드 마이그레이션 및 백업</block>
  <block id="4fe11b4a91ff38ec9933009a15dd5b0b" category="paragraph">ONTAP의 또 다른 강점은 하이브리드 클라우드를 광범위하게 지원하여 사내 프라이빗 클라우드의 시스템을 퍼블릭 클라우드 기능과 병합하는 것입니다. 다음은 vSphere와 함께 사용할 수 있는 몇 가지 NetApp 클라우드 솔루션입니다.</block>
  <block id="67464b4510c09197c8a5e16ba6702435" category="list-text">* Cloud Volumes. * NetApp Cloud Volumes Service for AWS 또는 GCP 및 Azure NetApp Files for ANF는 주요 퍼블릭 클라우드 환경에서 고성능 멀티 프로토콜 관리 스토리지 서비스를 제공합니다. VMware Cloud VM 게스트가 직접 사용할 수 있습니다.</block>
  <block id="0ac7b95ec26051fb8842ae35427ecc22" category="list-text">* Cloud Volumes ONTAP. * NetApp Cloud Volumes ONTAP 데이터 관리 소프트웨어는 선택한 클라우드에서 데이터에 제어, 보호, 유연성 및 효율성을 제공합니다. Cloud Volumes ONTAP는 NetApp ONTAP 스토리지 소프트웨어를 기반으로 하는 클라우드 네이티브 데이터 관리 소프트웨어입니다. Cloud Manager와 함께 사용하면 사내 ONTAP 시스템과 함께 Cloud Volumes ONTAP 인스턴스를 구축하고 관리할 수 있습니다. 고급 NAS 및 iSCSI SAN 기능과 함께 스냅샷 복사본 및 SnapMirror 복제를 포함한 통합 데이터 관리를 활용하십시오.</block>
  <block id="2a11701c0c01affc0ce96eb0d0c16ed9" category="list-text">* 클라우드 서비스. * Cloud Backup Service 또는 SnapMirror 클라우드를 사용하여 퍼블릭 클라우드 스토리지를 사용하는 사내 시스템의 데이터를 보호합니다. Cloud Sync를 사용하면 NAS, 오브젝트 저장소 및 Cloud Volumes Service 스토리지에서 데이터를 마이그레이션하고 동기화 상태를 유지할 수 있습니다.</block>
  <block id="fa9b5353337118a51ced7968bccc02a0" category="inline-link">VM의 스냅샷 복사본을 더 많이 저장합니다</block>
  <block id="c79f1f00e1e3c8f100e8604eec888859" category="list-text">* FabricPool. * FabricPool는 ONTAP 데이터를 빠르고 쉽게 계층화할 수 있도록 지원합니다. 스냅샷 복사본의 콜드 블록은 퍼블릭 클라우드 또는 프라이빗 StorageGRID 오브젝트 저장소의 오브젝트 저장소로 마이그레이션할 수 있으며, ONTAP 데이터에 다시 액세스할 때 자동으로 호출됩니다. 또는 SnapVault에서 이미 관리하는 데이터를 보호하기 위해 개체 계층을 세 번째 수준으로 사용할 수도 있습니다. 이 접근 방식을 통해 다음을 수행할 수 있습니다<block ref="1d0add9d2d81e2d7e790f727021e53aa" category="inline-link-rx"></block> 주요 및/또는 보조 ONTAP 스토리지 시스템</block>
  <block id="1a7072854c9dd945a98f4314b3f77408" category="list-text">* ONTAP Select. * NetApp 소프트웨어 정의 스토리지를 사용하여 프라이빗 클라우드를 인터넷으로 원격 시설 및 사무소로 확장할 수 있습니다. ONTAP Select를 사용하여 블록 및 파일 서비스와 엔터프라이즈 데이터 센터에서 사용하는 vSphere 데이터 관리 기능을 지원할 수 있습니다.</block>
  <block id="79aec220098057ef8c0e46281a45d6c2" category="paragraph">VM 기반 애플리케이션을 설계할 때는 미래의 클라우드 이동성을 고려해 보십시오. 예를 들어, 애플리케이션과 데이터 파일을 함께 배치하는 대신 데이터에 대해 별도의 LUN 또는 NFS 내보내기를 사용합니다. 따라서 VM 및 데이터를 클라우드 서비스로 별도로 마이그레이션할 수 있습니다.</block>
  <block id="af63597853dc0983258c8f86a12aae0b" category="section-title">vSphere 데이터 암호화</block>
  <block id="eb969673f581d94df982f8e2a6001f30" category="paragraph">오늘날, 암호화를 통해 유휴 데이터를 보호해야 하는 요구가 증가하고 있습니다. 처음에는 재무 및 의료 정보에 집중했지만 파일, 데이터베이스 또는 기타 데이터 유형에 저장된 모든 정보를 보호하는 데 관심이 높아지고 있습니다.</block>
  <block id="77652ecf0c76f1d4194171dc720320be" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템을 사용하면 유휴 데이터를 쉽게 보호할 수 있습니다. NetApp 스토리지 암호화(NSE)는 ONTAP가 포함된 자체 암호화 디스크 드라이브를 사용하여 SAN 및 NAS 데이터를 보호합니다. NetApp은 또한 디스크 드라이브에서 볼륨을 암호화하는 단순한 소프트웨어 기반 접근 방식으로 NetApp 볼륨 암호화 및 NetApp 애그리게이트 Encryption도 제공합니다. 이 소프트웨어 암호화는 특수 디스크 드라이브 또는 외부 키 관리자가 필요하지 않으며 ONTAP 고객이 추가 비용 없이 사용할 수 있습니다. 클라이언트 또는 애플리케이션을 중단하지 않고 업그레이드하거나 사용할 수 있으며 온보드 키 관리자를 포함하여 FIPS 140-2 레벨 1 표준에 따라 검증을 받았습니다.</block>
  <block id="937a352e0f824ff55e4cd50c8e3b051e" category="paragraph">VMware vSphere에서 실행되는 가상화된 애플리케이션의 데이터를 보호하기 위한 몇 가지 접근 방식이 있습니다. 한 가지 방법은 게스트 OS 수준에서 VM 내부의 소프트웨어로 데이터를 보호하는 것입니다. vSphere 6.5와 같은 최신 하이퍼바이저는 VM 수준에서 암호화를 지원하는 또 다른 대안으로, 그러나 NetApp 소프트웨어 암호화는 간단하고 쉬우며 다음과 같은 이점을 제공합니다.</block>
  <block id="92fbd315c4413db381567a775570b78c" category="list-text">* 가상 서버 CPU에 영향을 미치지 않습니다. * 일부 가상 서버 환경에서는 애플리케이션에 사용할 수 있는 모든 CPU 사이클이 필요하지만 하이퍼바이저 레벨 암호화를 위해서는 최대 5배의 CPU 리소스가 필요하다는 결과가 있습니다. 암호화 소프트웨어가 암호화 작업 부하를 오프로드하기 위해 인텔의 AES-NI 명령 집합을 지원하는 경우에도(NetApp 소프트웨어 암호화처럼) 이전 서버와 호환되지 않는 새로운 CPU의 요구 사항으로 인해 이 접근 방식이 실현 불가능할 수 있습니다.</block>
  <block id="6abee98aea26f85e6f0fe8d4db70f998" category="list-text">* 온보드 키 관리자가 포함되어 있습니다. * NetApp 소프트웨어 암호화는 추가 비용 없이 온보드 키 관리자를 포함하므로 구입 및 사용이 복잡한 고가용성 키 관리 서버 없이 쉽게 시작할 수 있습니다.</block>
  <block id="c216121021de8554d33503ef6616b256" category="list-text">* 스토리지 효율성에 영향을 미치지 않습니다. * 데이터 중복 제거 및 압축과 같은 스토리지 효율성 기술이 현재 널리 사용되고 있으며 플래시 디스크 미디어를 비용 효율적으로 사용하는 데 핵심적인 역할을 합니다. 그러나 암호화된 데이터는 일반적으로 중복제거되거나 압축할 수 없습니다. NetApp 하드웨어 및 스토리지 암호화는 다른 접근법과는 달리 낮은 수준에서 작동하며 업계 최고의 NetApp 스토리지 효율성 기능을 충분히 활용할 수 있도록 합니다.</block>
  <block id="5f9aa8333f218d1c21e67c8608a48672" category="list-text">* 데이터스토어의 세분화된 암호화. * NetApp Volume Encryption을 사용하면 각 볼륨에 고유한 AES 256비트 키를 사용할 수 있습니다. 변경해야 하는 경우 단일 명령을 사용하여 변경할 수 있습니다. 이 접근 방식은 테넌트가 여러 개이거나 서로 다른 부서 또는 애플리케이션에 대해 독립적인 암호화를 증명해야 하는 경우에 유용합니다. 이 암호화는 개별 VM을 관리하는 것보다 훨씬 쉬운 데이터 저장소 수준에서 관리됩니다.</block>
  <block id="088124cfa6d59c647e63177c5a4af318" category="paragraph">소프트웨어 암호화를 쉽게 시작할 수 있습니다. 라이센스를 설치한 후 암호를 지정하여 온보드 키 관리자를 구성한 다음 새 볼륨을 생성하거나 스토리지 측 볼륨 이동을 수행하여 암호화를 설정합니다. NetApp은 향후 VMware 툴 릴리즈에서 암호화 기능에 대한 통합 지원을 추가하기 위해 노력하고 있습니다.</block>
  <block id="c95fa5b56a01e5c1a80c540c1ab1a750" category="paragraph">Active IQ Unified Manager는 가상 인프라의 VM에 대한 가시성을 제공하고 가상 환경에서 스토리지 및 성능 문제를 모니터링하고 문제를 해결할 수 있도록 지원합니다.</block>
  <block id="be75250c2f30870dc1e359b4ade2a767" category="paragraph">ONTAP 기반의 일반적인 가상 인프라 구축에는 컴퓨팅, 네트워크 및 스토리지 계층 전체에 분산된 다양한 구성 요소가 있습니다. VM 애플리케이션의 성능 지연은 각 계층의 다양한 구성 요소에 의해 발생하는 지연 시간의 조합으로 인해 발생할 수 있습니다.</block>
  <block id="d1734f6f2e65a1488896f74695db5254" category="paragraph">다음 스크린샷은 Active IQ Unified Manager 가상 머신 보기를 보여 줍니다.</block>
  <block id="8aa017c9f67ad32dd7301ecf52b61d72" category="paragraph"><block ref="8aa017c9f67ad32dd7301ecf52b61d72" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2118336fa447fcc0f213cb8c40c516af" category="paragraph">Unified Manager는 가상 환경의 기본 하위 시스템을 토폴로지 뷰에서 제공하므로 컴퓨팅 노드, 네트워크 또는 스토리지에서 지연 시간 문제가 발생했는지 여부를 확인할 수 있습니다. 또한 개선 단계를 수행하고 기본 문제를 해결하는 데 성능 지연이 발생하는 특정 개체를 중점적으로 보여 줍니다.</block>
  <block id="d8a78b994fcd4e04901203a2e7bc6414" category="paragraph">다음 스크린샷은 AIQUM 확장 토폴로지를 보여줍니다.</block>
  <block id="e9659be2b7d3d69eccdb443ed2acec75" category="paragraph"><block ref="e9659be2b7d3d69eccdb443ed2acec75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e69b470437a857bf2d9517ce4ef8d2c1" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP 스토리지 FC VMFS 데이터 저장소를 구축하는 단계를 제공합니다.</block>
  <block id="91d9498cf61618ef81368a106318efd2" category="doc">vSphere VMFS 데이터 저장소 - ONTAP를 사용하는 Fibre Channel 스토리지 백엔드</block>
  <block id="b6e52e53cc59b8620dcdc05f2b812be4" category="paragraph">이 섹션에서는 ONTAP FC(Fibre Channel) 스토리지를 사용하여 VMFS 데이터 저장소를 생성하는 방법에 대해 설명합니다.</block>
  <block id="0335588c7903659bdeaa310c8f7bcdf4" category="list-text">{ONTAP_VERSION}을 실행하는 ONTAP 스토리지 시스템(FAS/AFF/CVO/ONTAP Select/ASA</block>
  <block id="f2a03b032017931383878c3ef48cdb0a" category="list-text">호스트, 타겟 및 SVM, LUN 정보의 ONTAP WWPN</block>
  <block id="d0a36a0dcdef62d026caa08afbaa4a42" category="inline-link-macro">작성한 FC 구성 워크시트</block>
  <block id="5c42144bb611ba366591a823d4c2955e" category="list-text"><block ref="5c42144bb611ba366591a823d4c2955e" category="inline-link-macro-rx"></block></block>
  <block id="6c2e28f86b2049d110f0e73e9bb78709" category="list-text">ONTAP FC 데이터 포트 및 vSphere 호스트가 연결된 경우</block>
  <block id="5a1cb943a687396a356750829002d982" category="list-text">각 존에 SVM을 위한 ONTAP FC 논리 인터페이스(WWPN)인 타겟을 포함합니다. SVM당 노드당 논리 인터페이스는 2개 이상 있어야 합니다. 물리적 포트의 WWPN을 사용하지 마십시오.</block>
  <block id="acd7065eaa19f6ad949216b6dcca52b6" category="list-text">구축, 구성 및 바로 사용할 수 있는 VMware vSphere용 ONTAP 툴</block>
  <block id="d13dd15101d292f5b2c56e5be828fec8" category="section-title">VMFS 데이터 저장소를 프로비저닝합니다</block>
  <block id="95877ca095b0f0a0a981f8a12d234ad5" category="paragraph">VMFS 데이터 저장소를 프로비저닝하려면 다음 단계를 수행하십시오.</block>
  <block id="94dafc85e46c3bc0d374c052b1075890" category="list-text">과(와) 호환 여부를 점검하십시오<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="195e1a47999aff0fbaa4eb8d97be6c40" category="inline-link-macro">FCP 구성이 지원됩니다</block>
  <block id="e1b87801d0d31fd947fb52aa411c2815" category="list-text">를 확인합니다 <block ref="a0240d867f430aa7cc80ec129fc2bdb1" category="inline-link-macro-rx"></block>.</block>
  <block id="0b3f75b021ef6bdc0a532e2d9b2a9d74" category="inline-link-macro">FCP에 대한 ONTAP 라이센스가 있는지 확인합니다.</block>
  <block id="3c56f50608e95955ed2e1a3fb8b1dad1" category="list-text"><block ref="3c56f50608e95955ed2e1a3fb8b1dad1" category="inline-link-macro-rx"></block></block>
  <block id="e7dc6b39e7e5bd6df8fa93e90a426161" category="list-text">'system license show' 명령을 사용하여 FCP가 나열되는지 확인합니다.</block>
  <block id="f8aa00b1a94d3290ba6ac653b792dd8a" category="list-text">라이센스를 추가하려면 "licen se add-license-code &lt;license code&gt;"를 사용합니다.</block>
  <block id="86a53381cefd41dcca81850274f0203a" category="list-text">SVM에서 FCP 프로토콜이 활성화되어 있는지 확인합니다.</block>
  <block id="0d195904efc6cfb176bbc04e93c2947d" category="inline-link-macro">FCP를 사용하여 새 SVM을 생성합니다.</block>
  <block id="df062a6cafa16aee5f7ea64ea6991776" category="list-text"><block ref="df062a6cafa16aee5f7ea64ea6991776" category="inline-link-macro-rx"></block></block>
  <block id="5aab5d056538757626dd0562a563471a" category="list-text">SVM에서 FCP 논리 인터페이스를 사용할 수 있는지 확인합니다.</block>
  <block id="f89eac3d097d3dae5c0159f0da84b1c7" category="list-text">GUI로 SVM을 생성할 때 논리 인터페이스는 이 프로세스의 일부입니다.</block>
  <block id="946b60eb8bd4945ad82b28fd9ccd3c63" category="list-text">네트워크 인터페이스의 이름을 바꾸려면 네트워크 인터페이스 수정 을 사용합니다.</block>
  <block id="52fa81ab62bea2599ed516f01925678d" category="inline-link-macro">LUN 생성 및 매핑</block>
  <block id="c8ecf540bebb63423545ecd3d02c6ca0" category="list-text"><block ref="a2b18e9ce335dd856363e6613d961c1a" category="inline-link-macro-rx"></block> VMware vSphere용 ONTAP 툴을 사용하는 경우 이 단계를 건너뛰십시오.</block>
  <block id="25d85157bcfdbb601bbda056cd3a5bc6" category="list-text">HBA 드라이버가 설치되어 있는지 확인합니다. VMware 지원 HBA에는 드라이버가 기본적으로 배포되어 있으며 에서 볼 수 있어야 합니다 <block ref="57f7eb139c8bc258309d8e16d3df13fe" category="inline-link-macro-rx"></block>.</block>
  <block id="6fe85aae6e8fa231a1f417edfeef3759" category="doc">vSphere VMFS 데이터 저장소 - ONTAP를 사용하는 iSCSI 스토리지 백엔드</block>
  <block id="4f6f7882fc7b858bc0eb3e3a41991494" category="paragraph">이 섹션에서는 ONTAP iSCSI 스토리지를 사용하여 VMFS 데이터 저장소를 생성하는 방법에 대해 설명합니다.</block>
  <block id="383b1f30f341cb0eff11db96d70e9f50" category="list-text">vSphere 환경 및 ONTAP를 관리하는 데 필요한 기본 기술</block>
  <block id="47c341511ad626bfba98caeaa0762774" category="list-text">iSCSI를 위한 ONTAP 네트워크 포트, SVM 및 LUN 정보</block>
  <block id="f76f5dc5c6861d7938aa8d60b08976c8" category="inline-link-macro">완료된 iSCSI 구성 워크시트</block>
  <block id="275e54409e966e03b62ee630e4856daa" category="list-text"><block ref="275e54409e966e03b62ee630e4856daa" category="inline-link-macro-rx"></block></block>
  <block id="c7e4d06c6b5e45fbb711be2b15976173" category="list-text">iSCSI VMkernel 어댑터 IP 정보</block>
  <block id="980e76f4fd03b06bfe740133284e92a9" category="list-text">ONTAP 시스템 네트워크 데이터 포트 및 연결된 vSphere 호스트를 사용합니다</block>
  <block id="3a6f48cf422509b67592ce2a0b4dd558" category="list-text">iSCSI에 대해 구성된 VLAN입니다</block>
  <block id="44786c36009327ad04469602f3f96832" category="list-text">(선택 사항) ONTAP 네트워크 데이터 포트에 대해 구성된 Link Aggregation입니다</block>
  <block id="f3a29486bed19a90f2da6d007818b427" category="section-title">단계</block>
  <block id="881de4e9f9e9dba55f3d9f09d3fc8eac" category="inline-link-macro">iSCSI 구성이 지원되는지 확인합니다.</block>
  <block id="6a2fb6d042919f5807315156f926ab10" category="list-text"><block ref="6a2fb6d042919f5807315156f926ab10" category="inline-link-macro-rx"></block></block>
  <block id="e103d9cdc55ef0be25a4fd8054bc28bc" category="list-text">다음 ONTAP 및 vSphere 작업을 완료합니다.</block>
  <block id="f04a1b9690234d25ff072d6719666947" category="inline-link-macro">iSCSI에 대한 ONTAP 라이센스를 확인합니다</block>
  <block id="41bf6980693d9ba9f5e7a797fe2f4417" category="list-text"><block ref="0767ceac1f7ac130ade75fb7fae3fc53" category="inline-link-macro-rx"></block>.</block>
  <block id="3ffc628bd3f213f0998146fb5262f366" category="list-text">'system license show' 명령어를 사용하여 iSCSI가 나열되는지 확인한다.</block>
  <block id="d1b0a5732b3cb229ef0f788fbb095f05" category="list-text">사용권을 추가하려면 'license add-license-code &lt;license code&gt;'를 사용하십시오.</block>
  <block id="97035bc2443de65f877c3fddd838c6ae" category="inline-link-macro">SVM에서 iSCSI 프로토콜이 활성화되어 있는지 확인합니다.</block>
  <block id="3807dbdaab3b890b6a293c99c7b46f63" category="list-text"><block ref="3807dbdaab3b890b6a293c99c7b46f63" category="inline-link-macro-rx"></block></block>
  <block id="cb66a92bc9fa6195f8b2914bcf868664" category="list-text">SVM에서 iSCSI 네트워크 논리 인터페이스를 사용할 수 있는지 확인합니다.</block>
  <block id="da91d0d17d1f671a0af23e7ebb96ec92" category="admonition">GUI를 사용하여 SVM을 생성할 때 iSCSI 네트워크 인터페이스도 생성됩니다.</block>
  <block id="da6a83da2309e8dbd81bb5b55c7c9602" category="list-text">네트워크 인터페이스를 보거나 변경하려면 네트워크 인터페이스 명령을 사용합니다.</block>
  <block id="53fd22677faa2085c1fc51f1d116faff" category="admonition">노드당 두 개의 iSCSI 네트워크 인터페이스를 사용하는 것이 좋습니다.</block>
  <block id="69fea75e454b43e67ba176dddb604159" category="inline-link-macro">iSCSI 네트워크 인터페이스를 생성합니다.</block>
  <block id="1bc0e04873be7c6291aef492ff2785cc" category="list-text"><block ref="d503e168b9096ac416caa1c8f13ab28a" category="inline-link-macro-rx"></block> 기본 데이터 블록 서비스 정책을 사용할 수 있습니다.</block>
  <block id="bd494b2c15d88a1dfa29c308b39e8f6e" category="inline-link-macro">데이터 iSCSI 서비스가 서비스 정책에 포함되어 있는지 확인합니다.</block>
  <block id="c436a9a899f5e1cfacf8828c90931ca9" category="list-text"><block ref="24788d985e181b3194881517c2ec7650" category="inline-link-macro-rx"></block> 네트워크 인터페이스 service-policy show를 사용하여 확인할 수 있습니다.</block>
  <block id="c0e1d066d0482fc5cc1554edaa3f36b2" category="inline-link-macro">점보 프레임이 활성화되었는지 확인합니다.</block>
  <block id="a355e4512cfabb746ee4c05a87a61107" category="list-text"><block ref="a355e4512cfabb746ee4c05a87a61107" category="inline-link-macro-rx"></block></block>
  <block id="5ccd820a879b8d1daef5e44125431184" category="inline-link-macro">LUN을 생성하고 매핑합니다.</block>
  <block id="c49b54ab60508b16176724eeb8118049" category="list-text"><block ref="3a73ce9b9237c3e09863bf7b049ce423" category="inline-link-macro-rx"></block> VMware vSphere용 ONTAP 툴을 사용하는 경우 이 단계를 건너뛰십시오. 각 LUN에 대해 이 단계를 반복합니다.</block>
  <block id="5c9b297b088335a8562568dc59549c7d" category="list-text">iSCSI VLAN에 사용할 수 있는 NIC가 하나 이상 있는지 확인합니다. 성능 및 내결함성을 향상시키기 위해 2개의 NIC가 선호됩니다.</block>
  <block id="fe9e58c95c20042a4032ef737d6e8400" category="inline-link-macro">vSphere 호스트에서 사용할 수 있는 물리적 NIC의 수를 확인합니다.</block>
  <block id="96cf3cacac94299a7630f48f5cf5b7e3" category="list-text"><block ref="96cf3cacac94299a7630f48f5cf5b7e3" category="inline-link-macro-rx"></block></block>
  <block id="87d3329dab6e8f24601b6f45d40614ea" category="inline-link-macro">iSCSI 이니시에이터를 구성합니다.</block>
  <block id="536d7ac288972152b209e6f004917285" category="list-text"><block ref="95a6e2e5fae04247474cdc6a729342fc" category="inline-link-macro-rx"></block> 일반적인 사용 사례는 소프트웨어 iSCSI 이니시에이터입니다.</block>
  <block id="fd823eb37045485458bb3d5d52ddc46f" category="inline-link-macro">iSCSI에 대한 TCPIP 스택을 사용할 수 있는지 확인합니다</block>
  <block id="875d65383afa504aad11a619d920adc7" category="list-text"><block ref="025b4ff12eca60b6c5b5be76597b5e95" category="inline-link-macro-rx"></block>.</block>
  <block id="e45f6655250b094b5a8370ff511869c3" category="inline-link-macro">iSCSI 포트 그룹을 사용할 수 있는지 확인합니다</block>
  <block id="4c93429599cf15be2af5aa0f59131c17" category="list-text"><block ref="5e67546a702454fa060946b3e582d0e9" category="inline-link-macro-rx"></block>.</block>
  <block id="b7b554d373b5992838a126134a03ba0d" category="list-text">일반적으로 업링크 포트가 여러 개인 단일 가상 스위치를 사용합니다.</block>
  <block id="879d70f2184599f483fd94f0f274163f" category="list-text">1:1 어댑터 매핑을 사용합니다.</block>
  <block id="9f60e3586ab900b8f879404be003b539" category="list-text">iSCSI VMkernel 어댑터가 NIC 수와 일치하도록 설정되어 있고 IP가 할당되어 있는지 확인합니다.</block>
  <block id="3e6e09b1cda3200c7407173a3473a103" category="inline-link-macro">iSCSI 소프트웨어 어댑터를 iSCSI VMkernel 어댑터에 바인딩합니다.</block>
  <block id="70d687ef257c5d00e0d85844c0101c77" category="list-text"><block ref="70d687ef257c5d00e0d85844c0101c77" category="inline-link-macro-rx"></block></block>
  <block id="187fbd973609969af8f47e857f8579c4" category="inline-link-macro">ONTAP 툴을 사용하여 VMFS 데이터 저장소를 프로비저닝합니다</block>
  <block id="1e9df60603ff2a9fe2495b189aecc647" category="list-text"><block ref="efecd5d76f6fc92c9c9a8111cf809724" category="inline-link-macro-rx"></block>. 모든 데이터 저장소에 대해 이 단계를 반복합니다.</block>
  <block id="5f4723c28ea2b13a27b86c1116720a8a" category="inline-link-macro">하드웨어 가속 지원을 확인합니다.</block>
  <block id="aa0cfa24dd578f0629299a21b453583c" category="list-text"><block ref="aa0cfa24dd578f0629299a21b453583c" category="inline-link-macro-rx"></block></block>
  <block id="1d3fa7ee382266d716ba7a360f30f188" category="paragraph">이러한 작업이 완료되면 VMFS 데이터 저장소가 가상 머신 프로비저닝에 사용할 준비가 된 것입니다.</block>
  <block id="53001b412ce4896686a413a19f6dcc5f" category="listing-title">Ansible 플레이북</block>
  <block id="963739e9818c0bf4d8959b5cdf6a7956" category="summary">SRA 및 기존 데이터스토어에 사용되는 것과 VVol 복제를 사용할 때는 SRM 내 워크플로우가 크게 다릅니다.</block>
  <block id="56687c1a324f03f5d1429500efea710e" category="doc">VVOL 복제 사용 시 SRM 문제 해결</block>
  <block id="14acf40cbe69d8682b4c844ac7fbf7f6" category="paragraph">SRA 및 기존 데이터스토어에 사용되는 것과 VVol 복제를 사용할 때는 SRM 내 워크플로우가 크게 다릅니다. 예를 들어, 어레이 관리자 개념은 없습니다. 따라서 Discovery와 Discovery의 명령은 결코 볼 수 없습니다.</block>
  <block id="ef74d715544e3b067a6bec3218ac5044" category="paragraph">문제 해결 시 아래 나열된 새 워크플로를 이해하는 것이 좋습니다.</block>
  <block id="47f0942d341ee10381b2eff35089d75d" category="list-text">queryReplicationPeer: 두 오류 도메인 간의 복제 계약을 검색합니다.</block>
  <block id="136a299aae29998a147852cb0cba5b4a" category="list-text">queryFaultDomain: 오류 도메인 계층을 검색합니다.</block>
  <block id="c071098c5df923c31f6245e4db2f3861" category="list-text">queryReplicationGroup: 소스 또는 타겟 도메인에 있는 복제 그룹을 검색합니다.</block>
  <block id="792cfe9ad3a3dc8528080a262e92989a" category="list-text">SyncReplicationGroup: 소스와 대상 간의 데이터를 동기화합니다.</block>
  <block id="39afb1e1e3b180a6230e07bb8571667e" category="list-text">queryPointInTimeReplica: 타겟의 시점 복제본을 검색합니다.</block>
  <block id="9fb25fe2ff084dc9ccfb99eaccba7212" category="list-text">testFailoverReplicationGroupStart: 테스트 대체 작동을 시작합니다.</block>
  <block id="bd4e1dacaca4c37a53b5286b6ae0239d" category="list-text">testFailoverReplicationGroupStop: 테스트 대체 작동을 종료합니다.</block>
  <block id="887f376a43cf9de1d6e14a8d69e588f6" category="list-text">PromoteReplicationGroup: 현재 테스트 중인 그룹을 프로덕션 환경으로 승격합니다.</block>
  <block id="17ab16c5c0786ff381e6a085318bad9b" category="list-text">prepareFailoverReplicationGroup: 재해 복구를 준비합니다.</block>
  <block id="665dd64ebcc4016bda94e0e8020d8c8e" category="list-text">failoverReplicationGroup: 재해 복구를 실행합니다.</block>
  <block id="6936cf00e30b7cd4421225113a023c3e" category="list-text">reverseReplicateGroup: 역방향 복제를 시작합니다.</block>
  <block id="61ac8950a043e6998b458d4f8171154c" category="list-text">queryMatchingContainer: 지정된 정책으로 프로비저닝 요청을 충족할 수 있는 컨테이너(호스트 또는 복제 그룹과 함께)를 찾습니다.</block>
  <block id="05c9efdc056d2af4640bc441ab61b53a" category="list-text">queryResourceMetadata: VASA 공급자에서 모든 리소스의 메타데이터를 검색하며 리소스 사용률을 queryMatchingContainer 함수에 대한 응답으로 반환할 수 있습니다.</block>
  <block id="01fa56986f885c588b1be8c206623de8" category="paragraph">VVOL 복제 구성 시 가장 일반적인 오류는 SnapMirror 관계를 검색하지 못하는 것입니다. 이 문제는 볼륨 및 SnapMirror 관계가 ONTAP 도구 모음 외부에서 생성되기 때문에 발생합니다. 따라서 항상 SnapMirror 관계가 완전히 초기화되었는지, 그리고 복제된 VVol 데이터 저장소를 생성하기 전에 두 사이트의 ONTAP 도구에서 재검색을 실행하는 것이 좋습니다.</block>
  <block id="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link"><block ref="9bf6b8df29f265cdaf3246f6645ca922" category="inline-link-rx"></block></block>
  <block id="bc0f3321a29c580fa0e3cca0c00ee7cd" category="list-text">VMware 제품 설명서<block ref="3bdcd80def6a1e2849d8b38049a04af9" category="inline-link-rx"></block></block>
  <block id="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link"><block ref="fa4af55c3fdbce23e96d2cf73261fa5b" category="inline-link-rx"></block></block>
  <block id="0f185ccd88416daec4eee0a846d110b8" category="list-text">NetApp 제품 설명서<block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="93b698fac9d8f378474fb0765494c4e6" category="doc">vSphere를 위한 ONTAP 기능</block>
  <block id="9985b4390c40137573e6da05caf85874" category="section-title">프로토콜</block>
  <block id="98f770b0af18ca763421bac22b4b6805" category="section-title">피처</block>
  <block id="99dd82c3472eab7ec4ea64a848fe032d" category="paragraph">가상화된 워크로드를 관리하는 데 유용한 ONTAP 기능이 많이 있습니다. 추가 제품 라이센스가 필요한 일부 제품에 대해서는 다음 섹션에서 설명합니다. 그 외 일부는 ONTAP를 비롯한 전체 NetApp 포트폴리오의 독립 실행형 툴로 패키징되어 있습니다.</block>
  <block id="671534601eb09388581f095632f815b2" category="paragraph">기본 ONTAP 기능에 대한 자세한 내용은 다음과 같습니다.</block>
  <block id="dbef3659822e80f91a3a561ed6d0b0cd" category="list-text">* 스토리지 효율성 * ONTAP는 인라인 및 백그라운드 중복제거 및 압축, 제로 블록 중복제거, 데이터 컴팩션을 지원합니다.</block>
  <block id="287c4830bc87771bdf2b3ae9880ab67e" category="list-text">* 볼륨 및 LUN 이동. * vSphere 데이터 저장소와 VVOL을 지원하는 볼륨 및 LUN을 ONTAP 클러스터 내에서 중단 없이 이동하여 성능과 용량의 균형을 맞추거나 무중단 유지보수 및 업그레이드를 지원할 수 있습니다.</block>
  <block id="ba96d4d48c1ff15e2732b37e2e7a435c" category="list-text">* QoS. * QoS를 사용하면 개별 LUN, 볼륨 또는 파일의 성능을 관리할 수 있습니다. 이 기능은 알 수 없거나 부족한 VM을 제한하거나 중요한 VM에 충분한 성능 리소스가 확보되도록 하는 데 사용할 수 있습니다.</block>
  <block id="28f638810590337576cbbe9979329c21" category="list-text">* FabricPool. * 이 기능은 사용 빈도가 낮은 데이터를 블록 레벨에서 별도의 오브젝트 저장소로 자동으로 계층화하고, 사용 빈도가 높은 플래시 스토리지를 사용합니다.</block>
  <block id="ff8a0108cd7cd5019bfee6b6be672b17" category="inline-link">ONTAP REST API</block>
  <block id="9455a10ec937dafee664ae1e0e4fd98c" category="inline-link">Ansible 모듈</block>
  <block id="85402a535d923d0511a02d404893d1ba" category="section-title">ONTAP 라이센스</block>
  <block id="4a9fdcb14826a67d38a7b84170c54ea9" category="paragraph">가상화된 워크로드를 관리하는 데 유용한 일부 ONTAP 기능은 추가 비용 없이 라이센스 번들 또는 별도 구매 없이 추가 라이센스가 필요합니다. 많은 고객의 경우 가장 비용 효율적인 방법은 라이센스 번들과 함께 사용하는 것입니다. vSphere와 관련된 주요 라이센스 및 라이센스 사용 방법은 다음과 같습니다.</block>
  <block id="c598be4d4f9f8c476e7f51d6ef5ff139" category="list-text">FlexClone *. * FlexClone은 ONTAP 볼륨 및 파일의 즉각적이고 공간 효율적인 클론을 지원합니다. 이 클론 복제는 VMware vSphere Storage API – 어레이 통합(VAAI), 백업 검증 및 복구(SnapCenter 소프트웨어), VVOL 클론 복제 및 스냅샷 복사본에 의해 스토리지 시스템으로 오프로드되는 경우에 사용됩니다. 사용 방법은 다음과 같습니다.</block>
  <block id="25d6e9f6ac28ecf0d97aaf9f6609f4d4" category="list-text">VAAI는 ONTAP에서 vSphere 클론 및 마이그레이션(Storage vMotion) 작업을 지원하기 위해 오프로드된 복제본을 지원합니다. FlexClone 라이센스를 사용하면 NetApp FlexVol 볼륨 내에서 빠른 클론을 생성할 수 있지만, 라이센스가 없는 경우에는 더 느린 블록 복사본을 사용하여 복제할 수 있습니다.</block>
  <block id="6f9f0acae1b8d33078f1c061dcc662a3" category="list-text">VVOL 기능을 사용하려면 FlexClone 라이센스가 필요합니다. 단일 데이터 저장소 또는 데이터 저장소 간에 VVOL을 클론 복제할 수 있으며, 스토리지 시스템으로 오프로드되는 VVOL의 vSphere 관리 스냅샷 복사본을 사용할 수 있습니다.</block>
  <block id="4370ed35c8063100f2a5b8da39b82668" category="list-text">SRA(스토리지 복제 어댑터)는 VMware Site Recovery Manager와 함께 사용되며, NAS 환경과 SAN 환경 모두에서 복구를 테스트하려면 FlexClone 라이센스가 필요합니다. SRA는 FlexClone 없이 검색, 복구 및 재보호 워크플로우에 사용할 수 있습니다.</block>
  <block id="3117cf0d132cfe6180ee3db3d5250f7f" category="list-text">* SnapRestore. * SnapRestore 기술을 사용하면 데이터를 복사하지 않고도 제자리에서 볼륨을 즉시 복구할 수 있습니다. 검증 및 복원 작업을 위해 데이터 저장소를 마운트하는 데 사용되는 SnapCenter와 같은 NetApp 백업 및 복구 툴에 필요합니다.</block>
  <block id="a30ea87a20e5dd5b267ec41f29219a1d" category="list-text">SnapMirror. * SnapMirror 기술을 사용하면 ONTAP 온프레미스와 클라우드 간에 데이터를 간단하고 빠르게 복제할 수 있습니다. SnapMirror는 블록 복제 성능을 통해 논리 복제의 버전 유연성을 지원하며 변경된 데이터만 보조 시스템으로 전송합니다. 미러 및/또는 볼트 정책으로 데이터를 보호할 수 있으므로 재해 복구뿐만 아니라 백업을 위한 장기 데이터 보존이 가능합니다. SnapMirror는 비동기 및 동기 관계를 지원하며, ONTAP 9.8은 SnapMirror 비즈니스 연속성을 통해 투명한 애플리케이션 장애 조치를 도입했습니다.</block>
  <block id="23862d7fc14d71369b9feaeb8d7f98b9" category="paragraph">SnapMirror는 Site Recovery Manager를 사용한 SRA 복제에 필요합니다. SnapCenter에서 2차 스토리지 시스템으로 스냅샷 복사본을 복제할 수도 있습니다.</block>
  <block id="0fdef6775eeade832499deceb497e1d8" category="list-text">* SnapCenter. * SnapCenter 소프트웨어는 애플리케이션 정합성을 보장하는 데이터 보호 및 클론 관리를 위한 확장 가능한 유니파이드 플랫폼 및 플러그인 제품군을 제공합니다. SnapCenter 라이센스는 AFF 및 FAS 시스템용 데이터 보호 라이센스 번들에 포함되어 있습니다. VMware vSphere용 SnapCenter 플러그인은 FAS, AFF, Cloud Volumes ONTAP 또는 ONTAP Select와 같은 스토리지 시스템을 사용하는 경우 무료로 제공됩니다. 그러나 SnapRestore 및 FlexClone 라이센스가 필요합니다.</block>
  <block id="a20c69bb9262b2ab09ca5248996e7d63" category="list-text">* MetroCluster. * NetApp MetroCluster는 캠퍼스 또는 도심 지역에서 고가용성 및 재해 복구를 결합하여 사이트 재해와 하드웨어 운영 중단을 모두 방지하는 동기식 복제 솔루션입니다. 데이터 무손실(0 RPO) 및 빠른 복구(RTO(분 이내)를 제공하는 투명한 장애 복구 기능을 갖춘 솔루션을 제공합니다. vSphere Metro Storage Cluster 구성의 일부로 vSphere 환경에서 사용됩니다.</block>
  <block id="ee8cc65cae83009c275cd4748f4c58ae" category="section-title">ONTAP용 가상화 툴</block>
  <block id="7b0abbba24b3ff594f013e524b352ef1" category="paragraph">NetApp은 ONTAP 및 vSphere와 함께 사용하여 가상화 환경을 관리할 수 있는 몇 가지 독립 실행형 소프트웨어 툴을 제공합니다. 다음 툴은 ONTAP 라이센스와 함께 추가 비용 없이 제공됩니다. 그림 1을 참조하여 vSphere 환경에서 이러한 툴이 함께 작동하는 방식을 보여 줍니다.</block>
  <block id="a1c13ec555198266776a3a7b904810dd" category="paragraph">다음 그림에서는 vSphere용 ONTAP 툴을 보여 줍니다.</block>
  <block id="f7e876d450acee7c9ed7b18438440fb2" category="paragraph"><block ref="f7e876d450acee7c9ed7b18438440fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93ac3f76e97265952e309b2cbb980030" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP NFS 버전 4 데이터 저장소를 구축하는 단계를 제공합니다.</block>
  <block id="11bbb95c80fd3935828f1472bade3ae4" category="doc">vSphere NFS 데이터 저장소 - ONTAP 버전 4.1</block>
  <block id="0a339846bb9d45c2252cf84f27f8390e" category="paragraph">이 섹션에서는 ONTAP NAS 스토리지를 사용하여 NFS 버전 4.1 데이터 저장소를 생성하는 방법을 설명합니다.</block>
  <block id="d5ffdd3b223c5bb3d1d66e5756977564" category="list-text">vSphere 환경 및 ONTAP를 관리하는 데 필요한 기본 기술</block>
  <block id="a65c730562f6a5feffebe8a600829c71" category="list-text">{ONTAP_VERSION}을 실행하는 ONTAP 스토리지 시스템(FAS/AFF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp Files</block>
  <block id="d5ba6255ccf331629f7b1b4598223d33" category="list-text">ONTAP 자격 증명(SVM 이름, userID, 암호)</block>
  <block id="190ba592a6988abfd7566be9b5c8217a" category="list-text">NFS용 ONTAP 네트워크 포트, SVM 및 LUN 정보</block>
  <block id="d5cb637f6500cfa77d4190ebdfd8cce0" category="inline-link-macro">완성된 NFS 구성 워크시트</block>
  <block id="915142cb27ebec8265b54739a95840b5" category="list-text"><block ref="915142cb27ebec8265b54739a95840b5" category="inline-link-macro-rx"></block></block>
  <block id="8e7f2b8f8c015d7ce248683387c1daf5" category="list-text">vSphere 호스트 정보 {vSphere_version}</block>
  <block id="d7850596008b347e3797ad7dcb7252e5" category="list-text">NFS VMkernel 어댑터 IP 정보입니다</block>
  <block id="7d0a7cdd836d94b19d4ecbce81ba2c1e" category="list-text">ONTAP 시스템 네트워크 데이터 포트, vSphere 호스트 및 연결을 통해</block>
  <block id="a7fb6a7233e9c40554334921be362af1" category="list-text">NFS에 대해 구성된 VLAN</block>
  <block id="d4e890b3139e840bac898dc24d2330a3" category="list-text">구축, 구성 및 바로 사용할 수 있는 VMware vSphere용 ONTAP 툴</block>
  <block id="f2f6f93a63f235f63bf8a14ad398ddd0" category="inline-link">상호 운용성 매트릭스 툴(IMT).</block>
  <block id="2c364f266e330209041f2cf854afab91" category="list-text">과(와) 호환 여부를 점검하십시오<block ref="975c7893d48b02c6727b59b0582d74bc" category="inline-link-rx"></block></block>
  <block id="bc295a5edde99316e021476fd74118c6" category="inline-link-macro">NFS 구성이 지원되는지 확인합니다.</block>
  <block id="564210524eadeca61542a5680bf0afca" category="list-text"><block ref="564210524eadeca61542a5680bf0afca" category="inline-link-macro-rx"></block></block>
  <block id="863feef43abaa752e441459bd37722c3" category="list-text">아래에 제공된 ONTAP 및 vSphere 작업을 완료합니다.</block>
  <block id="1b2d2406823c016e35ebeddf0ec29c66" category="inline-link-macro">NFS에 대한 ONTAP 라이센스를 확인합니다</block>
  <block id="7209cd833425a764d216b4e565ac65c6" category="list-text"><block ref="7209cd833425a764d216b4e565ac65c6" category="inline-link-macro-rx"></block></block>
  <block id="55d2948d4abb6ad9ea1e2b6a5b73460b" category="list-text">system license show 명령을 사용하여 NFS가 나열되는지 확인합니다.</block>
  <block id="0a5e80a3066e5036387d5026a58fe582" category="inline-link-macro">NFS 구성 워크플로우를 따릅니다</block>
  <block id="4b9e38c0f910614d9be47f85cf0f07bc" category="list-text"><block ref="4b9e38c0f910614d9be47f85cf0f07bc" category="inline-link-macro-rx"></block></block>
  <block id="4344c7f5d714fb1797033b7d9cca43fd" category="inline-link-macro">vSphere용 NFS 클라이언트 구성 워크플로우를 따릅니다.</block>
  <block id="c9fb47d82da1089992044972b4b65103" category="paragraph"><block ref="c9fb47d82da1089992044972b4b65103" category="inline-link-macro-rx"></block></block>
  <block id="883a5adf98ba177c28c5bc7d95e28763" category="paragraph">이러한 작업이 완료되면 NFS 데이터 저장소가 가상 머신 프로비저닝에 사용할 준비가 된 것입니다.</block>
  <block id="c2ffe02d76c4f089648f1647b43e4ee5" category="doc">모범 사례</block>
  <block id="ff53ee8001042abcefe5c912d0b5012f" category="section-title">vSphere 데이터 저장소 및 프로토콜 기능</block>
  <block id="14eae6ee278098bfad4f8a10fd6c1195" category="list-text">FCoE 를 참조하십시오</block>
  <block id="26bcb9f1cb6f391f4b2c18e676bb458d" category="list-text">NVMe/FC</block>
  <block id="1d1a594959ec615f56516f5d0f5e8ddb" category="list-text">NFS 를 참조하십시오</block>
  <block id="0f2f72ef3f176b98134caf100a06cf5f" category="inline-link">VMware 구성 최대값</block>
  <block id="9da73946f1bc3be4a41898d06c9d2e8b" category="cell">기능/특징</block>
  <block id="c982f804d02e2d7e937f125d2cac1024" category="cell">FC/FCoE</block>
  <block id="520d0db389f362bf79ef56ca0af3dcab" category="cell">형식</block>
  <block id="99a3142584ca8ad0a3afadeaa6f2ef69" category="cell">VMFS 또는 RDM(Raw Device Mapping)</block>
  <block id="26aae26f61844ac20ab7b04ba6f5c515" category="cell">VMFS 또는 RDM</block>
  <block id="8dc6d0c66219ddb809322c0d248e55e6" category="cell">최대 데이터 저장소 또는 LUN 수</block>
  <block id="2774ddb6f193789c5d9a480b9e53a38d" category="cell">256개 마운트 기본 NFS. MaxVolumes는 8입니다. VMware vSphere용 ONTAP 툴을 사용하여 256으로 늘리십시오.</block>
  <block id="51c0dc217976e27de06e262947947a62" category="cell">최대 데이터 저장소 크기입니다</block>
  <block id="856c997f909830b8249756c07dc9452b" category="cell">64TB</block>
  <block id="8e5d3a4b085389c59a1a7af7c4067a9b" category="cell">FlexGroup 볼륨에서 100TB FlexVol 볼륨 이상</block>
  <block id="d10549beb2f7bd1e91e5ef8965edd84a" category="cell">62TB</block>
  <block id="9aa56a79640231adaec83bc53e59c929" category="cell">LUN 또는 파일 시스템당 최적의 큐 크기</block>
  <block id="edc5121cb9b42a76b718b8ece9d67437" category="paragraph">다음 표에는 지원되는 VMware 스토리지 관련 기능이 나와 있습니다.</block>
  <block id="130b78bfd6c9b050a912fec77e285e3f" category="cell">용량/기능</block>
  <block id="6c1a84b789b54fd42511ce582be94d21" category="cell">마이그레이션</block>
  <block id="e95b58d02782c970bb339c6cc587ff39" category="cell">마이그레이션</block>
  <block id="0486e0e3dc3e86859f43b6d8e32b8071" category="cell">VMware HA</block>
  <block id="8be6bd7f20474cbefdd496cb9fd495ca" category="cell">SDRS(Storage Distributed Resource Scheduler)</block>
  <block id="4244919a64848265426dfd82a14f8248" category="cell">VMware VADP(vStorage APIs for Data Protection) 지원 백업 소프트웨어</block>
  <block id="28c2f8ab9cdbf296aa4261bc3c58ba0d" category="cell">VM 내의 MSCS(Microsoft Cluster Service) 또는 장애 조치 클러스터링</block>
  <block id="01a9a3b8d0fcae3055dc91935e8ec6c6" category="cell">예 *</block>
  <block id="aa7f77e663b832d5b0e544c5511e680c" category="cell">지원되지 않습니다</block>
  <block id="aa18abedec09bd4f85e612c307e2eaa6" category="cell">내결함성</block>
  <block id="bfd52522de4ac6efd6f680e0e754eeb5" category="cell">사이트 복구 관리자</block>
  <block id="17d495427086fa21259b9df40b27e00a" category="cell">씬 프로비저닝된 VM(가상 디스크)</block>
  <block id="4ee7af004efef335d6a14c60ee758f5e" category="cell">예 VAAI를 사용하지 않을 때 NFS의 모든 VM에 대해 이 설정이 기본값입니다.</block>
  <block id="13bc264ff420559de4156ec40980a4b9" category="cell">VMware 기본 다중 경로</block>
  <block id="8339c514e73f5cced3b83d504d60441b" category="inline-link">Windows Server 장애 조치 클러스터링에 대한 설치</block>
  <block id="a06819d91a165d0491c5816c54b41234" category="paragraph">다음 표에는 지원되는 ONTAP 스토리지 관리 기능이 나와 있습니다.</block>
  <block id="f8d61013f1a3bbf1342f4ced3279c7cf" category="cell">데이터 중복제거</block>
  <block id="72167540968147afed9deb59f0e9fe00" category="cell">어레이에 대한 비용 절감</block>
  <block id="9a5473a6abaea16b736f096913a749be" category="cell">데이터 저장소의 절감 효과</block>
  <block id="6cd880eabbec3488232c6cba3fbcf998" category="cell">씬 프로비저닝</block>
  <block id="5caeb11c4ed379b808d7f7cdca7cfbf0" category="cell">데이터 저장소 또는 RDM</block>
  <block id="8a5227cc82d14862956938caffc1acf2" category="cell">데이터 저장소</block>
  <block id="b71ba22dcd42deceac87150206f7bd12" category="cell">데이터 저장소 크기를 조정합니다</block>
  <block id="c6b792bfd7aac8067d36337e67d11545" category="cell">성장만 하십시오</block>
  <block id="29e23534878bb63341e0b689426b7fb0" category="cell">확장, 자동 확장 및 축소</block>
  <block id="76021405cc62a4b8c542e7f65e3d24ed" category="cell">Windows, Linux 애플리케이션용 SnapCenter 플러그인(게스트)</block>
  <block id="c0b3c629432c82a9e8500242abb35eaf" category="cell">VMware vSphere용 ONTAP 툴을 사용하여 모니터링 및 호스트 구성</block>
  <block id="5a915a8215e9a66bcff0f034e8adff18" category="cell">VMware vSphere용 ONTAP 툴을 사용하여 프로비저닝</block>
  <block id="6495c7cda42bf1b80bc1c2af6166ef58" category="paragraph">다음 표에는 지원되는 백업 기능이 나와 있습니다.</block>
  <block id="1208a2df45bea7d2edea13f0b0cbc686" category="cell">ONTAP 스냅샷 복사본</block>
  <block id="bf22a1b5bc2b72a75825094826a942de" category="cell">SRM은 복제된 백업에서 지원됩니다</block>
  <block id="60d3f7d9f265eb34e826da352cb545be" category="cell">volume SnapMirror를 선택합니다</block>
  <block id="fabf31a57c142c986c5d88cb089b3d7b" category="cell">VMDK 이미지 액세스</block>
  <block id="40b655e79545b3922b8095be28d59428" category="cell">VADP 지원 백업 소프트웨어</block>
  <block id="8215e73d220182794dfbd75ad494c727" category="cell">VADP 지원 백업 소프트웨어, vSphere Client 및 vSphere Web Client 데이터 저장소 브라우저</block>
  <block id="d7605580ecad0fcb4528789d74cdcad5" category="cell">VMDK 파일 레벨 액세스</block>
  <block id="906ece32da286d6c4b323bc0d6443b7c" category="cell">VADP 지원 백업 소프트웨어, Windows만 해당</block>
  <block id="d17e2fa63a62622f88bf170612132383" category="cell">VADP 지원 백업 소프트웨어 및 타사 애플리케이션</block>
  <block id="4e3d259d82a536e12c5c9c948b62e26a" category="cell">NDMP 세분성</block>
  <block id="90d45e02e50c81603c36a4e4ad3649d9" category="cell">데이터 저장소 또는 VM</block>
  <block id="54b3e11ce37eaaa9884f4086e72dd2be" category="section-title">스토리지 프로토콜 선택</block>
  <block id="4bbd62e7748dbf2416c644698342b5f9" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템은 모든 주요 스토리지 프로토콜을 지원하므로 고객은 기존 및 계획된 네트워킹 인프라, 직원 기술에 따라 환경에 가장 적합한 프로토콜을 선택할 수 있습니다. NetApp 테스트 결과, 유사한 회선 속도에서 실행되는 프로토콜 간에는 일반적으로 차이가 거의 없으므로 원시 프로토콜 성능보다 네트워크 인프라 및 직원 기능에 초점을 맞추는 것이 가장 좋습니다.</block>
  <block id="0212b4e8bc965dcd8a7ff771dd96bf21" category="paragraph">프로토콜 선택을 고려할 때 다음과 같은 요소가 유용할 수 있습니다.</block>
  <block id="c0ab9c6170165211885267a562d057a2" category="list-text">* 현재 고객 환경 * IT 팀은 일반적으로 이더넷 IP 인프라 관리에 능숙하지만, 모든 팀이 FC SAN 패브릭 관리에 능숙하지는 않습니다. 그러나 스토리지 트래픽용으로 설계되지 않은 범용 IP 네트워크를 사용하면 제대로 작동하지 않을 수 있습니다. 현재 보유하고 있는 네트워킹 인프라, 계획된 개선 사항, 이를 관리할 직원의 기술 및 가용성을 고려하십시오.</block>
  <block id="774f1348caf3e145710073eb634c4fa1" category="list-text">* 손쉬운 설정 * FC 패브릭의 초기 구성(추가 스위치 및 케이블 연결, 조닝, HBA 및 펌웨어의 상호 운용성 검증) 외에도 블록 프로토콜은 LUN 생성 및 매핑과 게스트 OS의 검색 및 포맷이 필요합니다. NFS 볼륨을 생성 및 내보낸 후에는 ESXi 호스트에 의해 마운트되며 사용할 수 있습니다. NFS에는 특별한 하드웨어 검증 또는 관리 펌웨어가 없습니다.</block>
  <block id="bf5169ce5bb544313eaf17435f756da2" category="list-text">* 손쉬운 관리. * SAN 프로토콜을 사용할 경우 더 많은 공간이 필요한 경우 LUN 증가, 새로운 크기를 검색하기 위한 재검색, 파일 시스템 확장 등 몇 가지 단계가 필요합니다. LUN을 증대할 수는 있지만 LUN 크기를 줄이는 것은 불가능하므로 사용하지 않는 공간을 복구하려면 추가 작업이 필요합니다. NFS를 사용하면 위나 아래로 쉽게 사이징할 수 있으며, 이러한 크기 조정은 스토리지 시스템에서 자동화할 수 있습니다. SAN은 게스트 OS TRIM/UNMAP 명령을 통해 공간 재확보를 제공하여 삭제된 파일의 공간을 어레이로 반환할 수 있도록 합니다. 이러한 유형의 공간 재확보는 NFS 데이터 저장소에서 더 어렵습니다.</block>
  <block id="530c759326761c6ac026b313985b255f" category="list-text">* 스토리지 공간 투명성. * 씬 프로비저닝이 즉시 절약 효과를 반환하므로 NFS 환경에서는 일반적으로 스토리지 사용률을 쉽게 확인할 수 있습니다. 마찬가지로, 같은 데이터 저장소 또는 다른 스토리지 시스템 볼륨에 있는 다른 VM에 대해서도 중복 제거 및 클론 생성 절약 효과를 즉시 사용할 수 있습니다. 일반적으로 VM 밀도는 NFS 데이터 저장소에서 더 높으며, 관리할 데이터 저장소 수를 줄여 데이터 중복 제거 비용을 절감할 수 있습니다.</block>
  <block id="16ee928b12bc598bf52b0f312879ec95" category="section-title">데이터 저장소 레이아웃</block>
  <block id="6104c8ef7be4222a76596ab6a22bb422" category="inline-link-macro">권장되는 ESXi 호스트 및 기타 ONTAP 설정</block>
  <block id="066ed1c180617b2f9028c1f789078de4" category="paragraph">ONTAP 스토리지 시스템은 VM 및 가상 디스크용 데이터 저장소를 유연하게 생성할 수 있습니다. VSC를 사용하여 vSphere용 데이터 저장소를 프로비저닝할 때는 섹션에 나와 있는 ONTAP 모범 사례가 많이 적용되지만 <block ref="311a0f5ed21de3c81d57d9c08f2ace49" category="inline-link-macro-rx"></block>) 다음은 고려해야 할 몇 가지 추가 지침입니다.</block>
  <block id="dc4d78be836807b32c7ef7f42028b1ef" category="list-text">FlexVol 볼륨 데이터 저장소의 적절한 크기는 약 4TB에서 8TB입니다. 이 크기는 성능, 관리 용이성 및 데이터 보호 측면에서 우수한 균형 점입니다. 작게 시작하고(예: 4TB) 필요에 따라 데이터 저장소를 최대 100TB까지 확장할 수 있습니다. 작은 데이터 저장소가 백업이나 재해 발생 후 복구 속도가 빨라지므로 클러스터 간에 빠르게 이동할 수 있습니다. ONTAP 자동 크기 조정을 사용하면 사용된 공간이 변경될 때 볼륨을 자동으로 확대 및 축소할 수 있습니다. VMware vSphere 데이터 저장소 용량 할당 마법사용 ONTAP 툴은 새 데이터 저장소에 대해 기본적으로 자동 크기 조정을 사용합니다. System Manager 또는 명령줄을 사용하여 확장 및 축소 임계값과 최대 및 최소 크기를 추가로 사용자 지정할 수 있습니다.</block>
  <block id="c74cab014e402128efd8102b941c0b0c" category="list-text">기존 게스트 운영 체제(OS)는 최고의 성능과 스토리지 효율성을 위해 스토리지 시스템과 조율해야 했습니다. 그러나 Red Hat과 같은 Microsoft 및 Linux 배포업체에서 제공하는 최신 공급업체 지원 OS는 더 이상 가상 환경에서 파일 시스템 파티션을 기본 스토리지 시스템의 블록과 일치시킬 필요가 없습니다. 조정이 필요한 이전 OS를 사용하는 경우 NetApp 지원 기술 자료에서 "VM 정렬"을 사용하는 문서를 검색하거나 NetApp 세일즈 또는 파트너 담당자에게 TR-3747 사본을 요청합니다.</block>
  <block id="3c8b400142a84af9ebe6262bce512ccb" category="list-text">게스트 OS 내에서 조각 모음 유틸리티를 사용하지 마십시오. 성능 이점이 없으며 스토리지 효율성 및 스냅샷 복사본 공간 사용에 영향을 줍니다. 또한 게스트 OS에서 가상 데스크톱에 대한 검색 인덱싱을 해제하는 것도 고려하십시오.</block>
  <block id="14abb814748566a24367c4459a54840b" category="list-text">ONTAP은 혁신적인 스토리지 효율성 기능으로 업계에서 최고의 가용성을 제공하므로 사용 가능한 디스크 공간을 최대한 활용할 수 있습니다. AFF 시스템은 기본 인라인 중복제거 및 압축을 사용해 이 효율성을 더욱 높여줍니다. 데이터는 애그리게이트 내 모든 볼륨에서 중복 제거되므로, 더 이상 단일 데이터 저장소 내에서 유사한 운영 체제 및 유사한 애플리케이션을 그룹화할 필요가 없으며 절약 효과를 극대화할 수 있습니다.</block>
  <block id="154cd001dd3ef8eabdf209f4faf2ddde" category="inline-link">TR-3633: Data ONTAP 기반 Oracle 데이터베이스</block>
  <block id="8f2f733fd8f32e7aaa1ee62e48a55117" category="list-text">경우에 따라 데이터 저장소가 필요하지 않을 수도 있습니다. 최상의 성능과 관리 효율성을 얻으려면 데이터베이스 및 일부 애플리케이션과 같은 높은 I/O 애플리케이션에 데이터 저장소를 사용하지 마십시오. 대신 게스트에 의해 또는 RDM을 통해 관리되는 NFS 또는 iSCSI 파일 시스템과 같은 게스트 소유 파일 시스템을 고려해 보십시오. 구체적인 애플리케이션 지침은 해당 애플리케이션에 대한 NetApp 기술 보고서를 참조하십시오. 예를 들면, 다음과 같습니다.<block ref="8cb1dd6561aaa08584e14e742f429a3e" category="inline-link-rx"></block> 에는 유용한 세부 정보와 함께 가상화에 대한 섹션이 있습니다.</block>
  <block id="6cda576d2fd323c1a728b7ac67d6034f" category="list-text">1등급 디스크(또는 개선된 가상 디스크)는 vSphere 6.5 이상을 사용하는 VM과 독립적으로 vCenter 관리 디스크를 사용할 수 있습니다. 주로 API에서 관리되지만, VVOL은 특히 OpenStack 또는 Kubernetes 툴로 관리할 때 유용합니다. ONTAP 및 VMware vSphere용 ONTAP 툴을 통해 지원됩니다.</block>
  <block id="71318121439b39fdf872bb0bd57494f2" category="section-title">데이터 저장소 및 VM 마이그레이션</block>
  <block id="e8824ce2062c6d1fc536163f7b8940bd" category="paragraph">다른 스토리지 시스템의 기존 데이터 저장소에서 ONTAP로 VM을 마이그레이션할 때 다음 몇 가지 사항을 염두에 두어야 합니다.</block>
  <block id="73b729fbc964c7d78dd90b64aaaeb785" category="list-text">Storage vMotion을 사용하여 대량의 가상 머신을 ONTAP로 이동합니다. 이 접근 방식은 실행 중인 VM에 중단 없이 적용할 수 있을 뿐만 아니라 인라인 중복제거 및 압축과 같은 ONTAP 스토리지 효율성 기능을 사용하여 마이그레이션 시 데이터를 처리할 수 있습니다. vCenter 기능을 사용하여 인벤토리 목록에서 여러 VM을 선택한 다음 적절한 시간에 마이그레이션을 예약합니다(작업을 클릭하는 동안 Ctrl 키 사용).</block>
  <block id="008116a0d875d0de070d1a10314abbaa" category="list-text">적절한 대상 데이터 저장소로 마이그레이션을 신중하게 계획할 수 있지만, 대개 대량으로 마이그레이션한 다음 필요에 따라 나중에 구성하는 것이 더 간단합니다. 서로 다른 스냅샷 일정 등과 같은 특정 데이터 보호 요구사항이 있는 경우 이 접근 방식을 사용하여 다른 데이터 저장소로 마이그레이션할 수 있습니다.</block>
  <block id="616b2180a0659911fed5aa758dba722c" category="list-text">대부분의 VM 및 해당 스토리지는 실행 중(핫) 마이그레이션될 수 있지만 다른 스토리지 시스템에서 ISO, LUN 또는 NFS 볼륨과 같은 연결된(데이터 저장소 아님) 스토리지를 마이그레이션하려면 콜드 마이그레이션이 필요할 수 있습니다.</block>
  <block id="fbb88da5639930a05f510729e473a216" category="inline-link">TR-4534</block>
  <block id="282806c282d96fdf15b71278587f2bfe" category="list-text">보다 신중한 마이그레이션이 필요한 가상 머신에는 연결된 스토리지를 사용하는 데이터베이스와 애플리케이션이 포함됩니다. 일반적으로 응용 프로그램의 도구를 사용하여 마이그레이션을 관리합니다. Oracle의 경우 RMAN 또는 ASM과 같은 Oracle 툴을 사용하여 데이터베이스 파일을 마이그레이션할 수 있습니다. 을 참조하십시오<block ref="6b3f565e7a7ce633fa62f4114c295216" category="inline-link-rx"></block> 를 참조하십시오. 마찬가지로 SQL Server의 경우 SQL Server Management Studio 또는 SnapManager for SQL Server 또는 SnapCenter와 같은 NetApp 툴을 사용하는 것이 좋습니다.</block>
  <block id="00f47a68ebd81ba943b17dbc30d78db6" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 가장 중요한 Best Practice는 VMware vSphere용 ONTAP 툴 플러그인(이전의 가상 스토리지 콘솔)을 설치하고 사용하는 것입니다. 이 vCenter 플러그인을 사용하면 SAN 또는 NAS를 사용할 때 스토리지 관리를 간소화하고, 가용성을 높이고, 스토리지 비용과 운영 오버헤드를 줄일 수 있습니다. 데이터 저장소를 프로비저닝하는 모범 사례를 사용하고 다중 경로 및 HBA 시간 초과를 위해 ESXi 호스트 설정을 최적화합니다(부록 B에 설명되어 있음). vCenter 플러그인이기 때문에 vCenter 서버에 연결하는 모든 vSphere 웹 클라이언트에서 사용할 수 있습니다.</block>
  <block id="21eddd0bd26d119e0602b3ceb65aff45" category="paragraph">이 플러그인은 vSphere 환경에서 다른 ONTAP 툴을 사용하는 데에도 도움이 됩니다. VMware VAAI용 NFS 플러그인을 설치하면 VM 클론 복제 작업을 위해 ONTAP로 복사본 오프로드를 수행하고, 일반 가상 디스크 파일의 공간 예약 및 ONTAP 스냅샷 복사본 오프로드를 수행할 수 있습니다.</block>
  <block id="80303385ad0f7147caa1af6d2162852b" category="paragraph">플러그인은 ONTAP용 VASA Provider의 다양한 기능을 위한 관리 인터페이스이기도 하여, VVOL을 통한 스토리지 정책 기반 관리를 지원합니다. VMware vSphere용 ONTAP 툴을 등록한 후 이를 사용하여 스토리지 기능 프로필을 생성하고 이를 스토리지에 매핑하며 시간이 지남에 따라 데이터 저장소가 프로파일을 준수하는지 확인합니다. VASA Provider는 VVOL 데이터 저장소를 생성하고 관리하는 인터페이스도 제공합니다.</block>
  <block id="9baea886f208a41896164d4ade5b3fde" category="paragraph">일반적으로, vCenter 내에서 VMware vSphere 인터페이스에 ONTAP 툴을 사용하여 기존 데이터 저장소와 VVOL 데이터 저장소를 프로비저닝하면 모범 사례를 따를 수 있습니다.</block>
  <block id="6161d374e9022f89382fd63b4be15aa1" category="section-title">일반 네트워킹</block>
  <block id="f0cd6847f2a7a0773ad0b58d0f9dc67d" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 네트워크 설정을 구성하는 것은 다른 네트워크 구성과 마찬가지로 간단합니다. 다음은 고려해야 할 몇 가지 사항입니다.</block>
  <block id="9600865cce7d923667012211ddac46de" category="list-text">스토리지 네트워크 트래픽을 다른 네트워크와 분리합니다. 전용 VLAN 또는 스토리지에 개별 스위치를 사용하면 별도의 네트워크를 구축할 수 있습니다. 스토리지 네트워크가 업링크와 같은 물리적 경로를 공유하는 경우 충분한 대역폭을 확보하기 위해 QoS 또는 추가 업링크 포트가 필요할 수 있습니다. 호스트를 스토리지에 직접 연결하지 마십시오. 스위치를 사용하여 이중화 경로를 갖게 되고 VMware HA가 별도의 작업 없이 작동할 수 있습니다.</block>
  <block id="7c4904daaa282388097ad83bf382e1a5" category="list-text">원하는 경우 점보 프레임을 사용할 수 있으며 네트워크에서 지원됩니다(특히 iSCSI 사용 시). 사용하는 경우 스토리지와 ESXi 호스트 간 경로에서 모든 네트워크 디바이스, VLAN 등에 동일하게 구성되었는지 확인합니다. 그렇지 않으면 성능 또는 연결 문제가 나타날 수 있습니다. MTU는 ESXi 가상 스위치, VMkernel 포트 및 각 ONTAP 노드의 물리적 포트 또는 인터페이스 그룹에서도 동일하게 설정되어야 합니다.</block>
  <block id="8b6e7f43d1d697e8f99164f0aa2ab1b6" category="inline-link">TR-4182</block>
  <block id="3745abd352adaa2cdec42c798060eef6" category="list-text">ONTAP 클러스터 내의 클러스터 네트워크 포트에서 네트워크 흐름 제어를 사용하지 않도록 설정하는 것만 좋습니다. NetApp은 데이터 트래픽에 사용되는 나머지 네트워크 포트에 대한 모범 사례를 위해 다른 권장사항을 제공하지 않습니다. 필요에 따라 활성화하거나 비활성화해야 합니다. 을 참조하십시오<block ref="bdfb81665a0ef86d871a52c0e6ebc591" category="inline-link-rx"></block> 흐름 제어에 대한 자세한 배경 정보</block>
  <block id="730a8287f758961d602b1b050bbe2751" category="list-text">ESXi 및 ONTAP 스토리지 어레이가 이더넷 스토리지 네트워크에 연결되어 있는 경우, 이러한 시스템이 RSTP(Rapid Spanning Tree Protocol) 에지 포트로 연결되거나 Cisco PortFast 기능을 사용하여 연결되는 이더넷 포트를 구성하는 것이 좋습니다. Cisco PortFast 기능을 사용하고 ESXi 서버 또는 ONTAP 스토리지 어레이에 802.1Q VLAN 트렁킹을 사용하는 환경에서는 스패닝 트리 포트패스트 트렁크 기능을 활성화하는 것이 좋습니다.</block>
  <block id="ac4976538e1fc8726f77afc202561afc" category="list-text">Link Aggregation에 대해 다음 모범 사례를 따르는 것이 좋습니다.</block>
  <block id="2432030fc6183a1a6c52cf5e93f3e9ae" category="paragraph">다음 표에는 네트워크 구성 항목에 대한 요약과 설정이 적용되는 위치가 나와 있습니다.</block>
  <block id="7d74f3b92b19da5e606d737d339a9679" category="cell">항목</block>
  <block id="1aa66ef3a8e34a7a538960a80d2e1e31" category="cell">ESXi</block>
  <block id="bbc155fb2b111bf61c4f5ff892915e6b" category="cell">스위치</block>
  <block id="6c3a6944a808a7c0bbb6788dbec54a9f" category="cell">노드</block>
  <block id="0b7e67b6cdcf0432b624d53588d520fb" category="cell">SVM</block>
  <block id="75ba8d70e3692ba200f0e0df37b4d2ae" category="cell">IP 주소입니다</block>
  <block id="ee6c0f25c2881cc69947a2ef23be5b8c" category="cell">VMkernel</block>
  <block id="e11f298a5bd5344d2d975b5157c27b69" category="cell">아니요**</block>
  <block id="d6f0876f76c273b8962b749c36153157" category="cell">Link Aggregation</block>
  <block id="fabd320b3b2249377e53e93099e27657" category="cell">가상 스위치</block>
  <block id="b1b40427c8eb8d0a083ddb16e250325b" category="cell">아니요 *</block>
  <block id="9881f82f0dd89588831f9d1682bd5492" category="cell">VLAN</block>
  <block id="5fc0d231160fa9650ea5c877f146bbe6" category="cell">VMkernel 및 VM 포트 그룹</block>
  <block id="39a3e05f380e583ae2887c79c7443f11" category="cell">흐름 제어</block>
  <block id="220071ab44b426f80ef21f1c552c363c" category="cell">NIC</block>
  <block id="6f2c08412f489e52a17a30217f50b3c1" category="cell">스패닝 트리</block>
  <block id="4b1c0df98ba3f3d1681c3c3dbdc97746" category="cell">MTU(점보 프레임의 경우)</block>
  <block id="7d6feaf896df4a937157d4ee5b91f4e1" category="cell">가상 스위치 및 VMkernel 포트(9000)</block>
  <block id="0110e50bd8629573701e73a4ba8b056f" category="cell">예(최대로 설정)</block>
  <block id="061ff5255adf00e4ae68469f43a7bf55" category="cell">예(9000)</block>
  <block id="bcc0e5a3e08cd34e80692195d056b06d" category="cell">페일오버 그룹</block>
  <block id="a4d1a66a448e327c12d3e287098a31d5" category="cell">예(생성)</block>
  <block id="465d5674eb6808b997037470f4dace73" category="cell">예(선택)</block>
  <block id="50ecdab93bf5a2f1bfb4cd8f81b9bd3d" category="paragraph">** 이러한 디바이스에는 자체 관리 IP 주소가 있지만 이러한 주소는 ESXi 스토리지 네트워킹의 맥락에서 사용되지 않습니다.</block>
  <block id="efd0bde36323238fec688b9cdf0c75a3" category="section-title">SAN(FC, FCoE, NVMe/FC, iSCSI), RDM</block>
  <block id="29cdd488736a6111699f7348320bbed7" category="paragraph">vSphere에서는 블록 스토리지 LUN을 사용하는 세 가지 방법이 있습니다.</block>
  <block id="8982d243303f9d1a8c2470b7d55278e6" category="list-text">VMFS 데이터 저장소 사용</block>
  <block id="9a0098c8c1be287e8d1da1aaf3bd2e59" category="list-text">RDM(Raw Device Mapping) 사용</block>
  <block id="93e209176746ac6f25c618631a02643b" category="list-text">VM 게스트 OS에서 소프트웨어 이니시에이터에 의해 액세스 및 제어되는 LUN입니다</block>
  <block id="c25dc676ca39a05ee6067ac9a50dbce0" category="paragraph">VMFS는 공유 스토리지 풀인 데이터 저장소를 제공하는 고성능 클러스터 파일 시스템입니다. VMFS 데이터 저장소는 FC, iSCSI, FCoE 또는 NVMe 네임스페이스를 사용하여 액세스할 수 있는 LUN으로 구성할 수 있으며 NVMe/FC 프로토콜을 통해 액세스할 수 있습니다. VMFS를 사용하면 클러스터의 모든 ESX 서버에서 기존 LUN에 동시에 액세스할 수 있습니다. ONTAP 최대 LUN 크기는 일반적으로 16TB입니다. 따라서 64TB의 최대 크기 VMFS 5 데이터 저장소(이 섹션의 첫 번째 표 참조)는 16TB LUN 4개를 사용하여 생성됩니다(모든 SAN 어레이 시스템은 64TB의 최대 VMFS LUN 크기를 지원합니다). ONTAP LUN 아키텍처에는 작은 개별 큐 깊이가 없기 때문에 ONTAP의 VMFS 데이터 저장소는 상대적으로 간단한 방식으로 기존 스토리지 아키텍처보다 더 큰 규모로 확장할 수 있습니다.</block>
  <block id="43f67f108e50dab0978a343603cbfec9" category="paragraph">vSphere에는 NMP(기본 경로 다중화)라고 하는 여러 스토리지 디바이스 경로에 대한 기본 지원이 포함되어 있습니다. NMP는 지원되는 스토리지 시스템의 스토리지 유형을 감지하고 NMP 스택을 자동으로 구성하여 사용 중인 스토리지 시스템의 기능을 지원합니다.</block>
  <block id="6bf646772584de04f877d166e564b5ff" category="paragraph">NMP 및 NetApp ONTAP는 모두 ALUA(Asymmetric Logical Unit Access)를 지원하여 최적화된 경로와 최적화되지 않은 경로를 협상합니다. ONTAP에서 ALUA에 최적화된 경로는 액세스하는 LUN을 호스팅하는 노드의 타겟 포트를 사용하여 직접 데이터 경로를 따릅니다. vSphere와 ONTAP 모두에서 ALUA는 기본적으로 사용하도록 설정되어 있습니다. NMP는 ONTAP 클러스터를 ALUA로 인식하며 ALUA 스토리지 어레이 유형 플러그인('VMW_SATP_ALUA')을 사용하고 라운드 로빈 경로 선택 플러그인('VMW_PSP_RR')을 선택합니다.</block>
  <block id="b284ee628d89c3e804c4def2a90f0520" category="paragraph">ESXi 6은 최대 256개의 LUN과 최대 1,024개의 LUN 총 경로를 지원합니다. 이러한 제한을 초과하는 LUN 또는 경로는 ESXi에서 표시되지 않습니다. 최대 LUN 수를 가정할 때 경로 제한에서는 LUN당 경로 수를 4개까지 지정할 수 있습니다. 대규모 ONTAP 클러스터에서는 LUN 제한보다 먼저 경로 제한에 도달할 수 있습니다. 이 제한을 해결하기 위해 ONTAP은 릴리즈 8.3 이상에서 선택적 LUN 맵(SLM)을 지원합니다.</block>
  <block id="8466b1e5abb4751e931c5feb1af4e469" category="inline-link">TR-4080</block>
  <block id="4157f0c23fc104508f492dc846f187f3" category="list-text">SLM은 기본적으로 활성화되어 있습니다. 포트 세트를 사용하지 않는 경우 추가 구성이 필요하지 않습니다.</block>
  <block id="597f1433ad810b3b86c7ae0f8f95afa8" category="list-text">Data ONTAP 8.3 이전에 생성된 LUN의 경우 'lun mapping remove-reporting-nodes' 명령을 실행하여 보고 노드를 제거하고 LUN 소유 노드 및 해당 HA 파트너에 대한 LUN 액세스를 제한하여 SLM을 수동으로 적용합니다.</block>
  <block id="43919b4d4d6d446ed498e26bff62db84" category="paragraph">블록 프로토콜(iSCSI, FC 및 FCoE)은 고유한 이름과 함께 LUN ID 및 일련 번호를 사용하여 LUN에 액세스합니다. FC 및 FCoE는 WWNs 및 WWPN(Worldwide Name)을 사용하며 iSCSI는 IQN(iSCSI Qualified Name)을 사용합니다. 스토리지 내 LUN의 경로는 블록 프로토콜에는 의미가 없으며 프로토콜의 어느 곳에도 표시되지 않습니다. 따라서 LUN만 포함된 볼륨은 내부적으로 마운트할 필요가 없으며, 데이터 저장소에 사용되는 LUN이 포함된 볼륨에는 접합 경로가 필요하지 않습니다. ONTAP의 NVMe 하위 시스템은 비슷하게 작동합니다.</block>
  <block id="ed0e76ed86e852bd7317a09d856ec4e8" category="paragraph">기타 모범 사례:</block>
  <block id="93586ad57931e0f16fff61cdba9d77df" category="list-text">가용성과 이동성을 극대화하기 위해 ONTAP 클러스터의 각 노드에서 논리 인터페이스(LIF)를 생성해야 합니다. ONTAP SAN 모범 사례는 노드당 물리적 포트 2개와 LIF를 각 패브릭에 대해 하나씩 사용하는 것입니다. ALUA는 경로를 구문 분석하고 활성 최적화(직접) 경로와 최적화되지 않은 활성 경로를 식별하는 데 사용됩니다. ALUA는 FC, FCoE 및 iSCSI에 사용됩니다.</block>
  <block id="b3cebb7381bddbabb1e950a46d264190" category="list-text">iSCSI 네트워크의 경우 여러 가상 스위치가 있을 때 NIC 티밍을 사용하여 서로 다른 네트워크 서브넷에 있는 여러 VMkernel 네트워크 인터페이스를 사용합니다. 또한 여러 물리적 스위치에 연결된 여러 물리적 NIC를 사용하여 HA를 제공하고 처리량을 늘릴 수 있습니다. 다음 그림은 다중 경로 연결의 예입니다. ONTAP에서 둘 이상의 스위치에 연결된 2개 이상의 링크를 사용하여 페일오버에 단일 모드 인터페이스 그룹을 구성하거나 LACP 또는 다중 모드 인터페이스 그룹과 함께 다른 Link-Aggregation 기술을 사용하여 HA와 링크 집계의 이점을 제공합니다.</block>
  <block id="2968b9f3c141bf23bc73d0e6e15a174a" category="list-text">대상 인증을 위해 ESXi에서 CHAP(Challenge-Handshake Authentication Protocol)를 사용하는 경우 ONTAP에서 CLI('vserver iSCSI security create') 또는 System Manager(스토리지 &gt; SVM &gt; SVM 설정 &gt; 프로토콜 &gt; iSCSI에서 이니시에이터 보안 편집)를 사용하여 CHAP를 구성해야 합니다.</block>
  <block id="d31f2e075df4ca75ca0874fa08f74b12" category="list-text">VMware vSphere용 ONTAP 툴을 사용하여 LUN 및 igroup을 생성하고 관리합니다. 이 플러그인은 서버의 WWPN을 자동으로 확인하여 적절한 igroup을 생성합니다. 또한 모범 사례에 따라 LUN을 구성하고 올바른 igroup에 매핑합니다.</block>
  <block id="de78559e8aed2cd62fbf852f73dc58c2" category="inline-link">물리적 및 가상 호환성 모드</block>
  <block id="905221150fdd103b5241870a0a1f2c42" category="list-text">RDM은 관리하기가 더 어려우며 앞에서 설명한 대로 제한된 경로도 사용할 수 있으므로 주의해서 사용해야 합니다. ONTAP LUN은 둘 다 지원합니다<block ref="27e1f8e5a88cfbb2836b083145b004c9" category="inline-link-rx"></block> RDM</block>
  <block id="636da39a2033c6179a718983c5ce1222" category="inline-link">ONTAP NVMe/FC 호스트 구성 가이드</block>
  <block id="81ef6507a13da5635951bc5b533deb59" category="inline-link">TR-4684</block>
  <block id="15483b0826bb9a4b11d1c89af2029c5c" category="list-text">vSphere 7.0에서 NVMe/FC를 사용하는 방법에 대한 자세한 내용은 다음을 참조하십시오<block ref="6b4ed262d14e47ef641cd57b65c32c38" category="inline-link-rx"></block> 및<block ref="7a29b2f31035a451d5b068728d2b79a7" category="inline-link-rx"></block>다음 그림에서는 vSphere 호스트에서 ONTAP LUN으로의 다중 경로 연결을 보여 줍니다.</block>
  <block id="f9fd9ea22ea7a2e8ec9e95254a449831" category="paragraph"><block ref="f9fd9ea22ea7a2e8ec9e95254a449831" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54452390cac5f65f3bcec580ba079531" category="section-title">FlexGroup</block>
  <block id="f203949f2e35204098b66b9c1519b66e" category="paragraph">ONTAP 9.8은 vSphere에서 FlexGroup 데이터 저장소를 지원하며, VMware vSphere 9.8 릴리즈용 ONTAP 툴도 추가로 지원합니다. FlexGroup은 대규모 데이터 저장소의 생성을 간소화하고 여러 구성 볼륨을 자동으로 생성하여 ONTAP 시스템의 성능을 극대화합니다. 전체 ONTAP 클러스터의 강력한 기능을 갖춘 확장 가능한 단일 vSphere 데이터 저장소에 FlexGroup with vSphere를 사용하십시오.</block>
  <block id="6829bc8d3038be0130fd2b409ad5e560" category="paragraph">ONTAP 9.8은 vSphere 워크로드를 사용한 광범위한 시스템 테스트 외에도 FlexGroup 데이터 저장소를 위한 새로운 복제 오프로드 메커니즘도 추가합니다. 이렇게 하면 향상된 복제 엔진을 사용하여 소스 및 대상 모두에서 액세스할 수 있도록 하면서 백그라운드에서 구성 요소간에 파일을 복사할 수 있습니다. 여러 복사본은 필요할 때 규모에 따라 구성 요소 내에서 즉시 사용 가능한 공간 효율적인 파일 클론을 사용합니다.</block>
  <block id="760383437e8e5cbe4a2560753da783fb" category="paragraph">또한 ONTAP 9.8은 FlexGroup 파일에 대한 새로운 파일 기반 성능 메트릭(IOPS, 처리량, 지연 시간)을 추가하며, 이러한 메트릭은 VMware vSphere 대시보드 및 VM 보고서용 ONTAP 툴에서 확인할 수 있습니다. VMware vSphere 플러그인용 ONTAP 툴을 사용하면 최대 및/또는 최소 IOPS의 조합을 사용하여 서비스 품질(QoS) 규칙을 설정할 수도 있습니다. 데이터 저장소의 모든 VM에 대해 또는 특정 VM에 대해 개별적으로 설정할 수 있습니다.</block>
  <block id="50783a97403d748762dff691da2d3723" category="paragraph">다음은 NetApp에서 개발한 몇 가지 추가 모범 사례입니다.</block>
  <block id="d190c5fcdf8146c1dd7aad1140be4e64" category="list-text">FlexGroup 프로비저닝 기본값을 사용합니다. VMware vSphere용 ONTAP 툴은 vSphere 내에서 FlexGroup를 생성 및 마운트하기 때문에 권장되지만, ONTAP System Manager 또는 명령줄은 특수한 요구 사항에 사용될 수 있습니다. 또한 vSphere에서 테스트한 구성 요소이므로 노드당 구성 멤버 수와 같은 기본값을 사용합니다.</block>
  <block id="9f3fa65c2cc36eabd2228b984c30c5e1" category="list-text">FlexGroup 데이터 저장소를 사이징할 때 FlexGroup는 더 큰 네임스페이스를 생성하는 여러 개의 작은 FlexVol 볼륨으로 구성되어 있습니다. 따라서 가장 큰 가상 머신의 크기를 최소 8배 이상 사이징해야 합니다. 예를 들어 환경에 6TB VM이 있는 경우 48TB 이하의 크기로 FlexGroup 데이터 저장소를 구성할 수 있습니다.</block>
  <block id="5fbee6b763967c822bb1e4a31665b11d" category="list-text">FlexGroup에서 데이터 저장소 공간을 관리할 수 있도록 허용합니다. vSphere 데이터 저장소에서 자동 크기 조정 및 Elastic Sizing을 테스트했습니다. 데이터 저장소가 전체 용량에 근접하면 VMware vSphere용 ONTAP 툴 또는 다른 툴을 사용하여 FlexGroup 볼륨의 크기를 조정할 수 있습니다. FlexGroup는 용량 및 inode의 균형을 유지하며, 용량이 허용하는 경우 폴더(VM) 내의 파일에 우선 순위를 지정합니다.</block>
  <block id="f5f11bb6aa98d02453eca36d5d1d2e19" category="list-text">FlexGroup vSphere 데이터 저장소 지원은 9.8 릴리즈에서 VM 1,500대까지 테스트되었습니다.</block>
  <block id="f48591b3ae898f29a551a2995a7dcfe8" category="list-text">복제 오프로드에 VMware VAAI용 NFS 플러그인을 사용하십시오. FlexGroup 데이터 저장소 내에서 클론 생성이 향상되지만 FlexVol는 FlexGroup 및/또는 ONTAP 볼륨 간에 VM을 복제할 때 ESXi 호스트 복제본보다 성능이 크게 향상되지는 않습니다.</block>
  <block id="57a0d1deb8da99d321814990d26d21ed" category="list-text">VMware vSphere 9.8용 ONTAP 툴을 사용하여 ONTAP 메트릭(대시보드 및 VM 보고서)을 사용하여 FlexGroup VM의 성능을 모니터링하고 개별 VM의 QoS를 관리할 수 있습니다. 이러한 메트릭은 현재 ONTAP 명령 또는 API를 통해 사용할 수 없습니다.</block>
  <block id="ad971da24ec0a38449ebf31e4e2c9332" category="list-text">QoS(최대/최소 IOPS)는 개별 VM 또는 해당 시점에 데이터 저장소의 모든 VM에 설정할 수 있습니다. 모든 VM에서 QoS를 설정하면 별도의 VM별 설정이 대체됩니다. 설정은 향후 새 VM이나 마이그레이션된 VM으로 확장되지 않습니다. 새 VM에 QoS를 설정하거나 데이터 저장소의 모든 VM에 QoS를 다시 적용하십시오.</block>
  <block id="3c9d41390700cbdfb2c273f00df0d6fd" category="list-text">SnapCenter Plug-in for VMware vSphere 릴리즈 4.4는 운영 스토리지 시스템의 FlexGroup 데이터 저장소에 있는 VM의 백업 및 복구를 지원합니다. FlexGroup를 보조 시스템에 복제하기 위해 SnapMirror를 수동으로 사용할 수 있지만 SCV 4.4는 보조 복사본을 관리하지 않습니다.</block>
  <block id="0416d04b345b434b120840c30ddaf0a1" category="paragraph">NetApp은 NetApp 테스트를 기반으로 ONTAP에서 올바르게 동작하도록 ESXi 호스트 다중 경로와 HBA 시간 초과 설정 세트를 개발했습니다. 이러한 설정은 VMware vSphere용 ONTAP 툴을 사용하여 쉽게 설정할 수 있습니다. 요약 대시보드의 호스트 시스템 윈도우에서 설정 편집 을 클릭하거나 vCenter에서 호스트를 마우스 오른쪽 버튼으로 클릭한 다음 ONTAP 도구 &gt; 권장 값 설정 으로 이동합니다. 다음은 9.8 릴리즈의 현재 권장되는 호스트 설정입니다.</block>
  <block id="73663d0d00956f0632e4ae75d811d53f" category="cell">VMFS3. HardwareAcceleratedLocking</block>
  <block id="1b50110aedae4d8d2043a4eb9beb20af" category="cell">VMFS3.EnableBlockDelete 를 참조하십시오</block>
  <block id="571cc1d48c6d1ff3cf7e3a54cb035753" category="cell">* NFS 설정 *</block>
  <block id="c3b49a515dd0046685e06092642aa139" category="cell">NET.TcpipHeapSize</block>
  <block id="504e96cc79e7efe30a8271cea152d9d1" category="cell">net.TcpipHeapMax</block>
  <block id="5f1e7b6431061565550e292d05c73588" category="cell">NFS.MaxVolumes</block>
  <block id="3058676a1cf088aa4a73312ac36f2a58" category="cell">NFS41.MaxVolumes</block>
  <block id="62c07f94c64184ee5d530e4c0917093f" category="cell">vSphere 6.0 이상, 256으로 설정</block>
  <block id="18e1fb6924459470760771b20ab0c379" category="cell">NFS.HeartbeatMaxFailures 를 참조하십시오</block>
  <block id="1aa26eb281359ba3b9a9a4b83a09ed46" category="cell">NFS.HeartbeatFrequency 를 선택합니다</block>
  <block id="eb4182715f8cde98563dc59ea36461d3" category="cell">NFS.HeartbeatTimeout</block>
  <block id="45aa5481fa55802a29a96aefd2f5dab1" category="cell">모든 NFS 구성에 대해 5로 설정합니다.</block>
  <block id="54a08b15243d9078d3b5a47f8242da6f" category="cell">SunRPC.MaxConnPerIP입니다</block>
  <block id="9a9ccbecb3f315797ff8e709d85a0e18" category="cell">vSphere 7.0 이상, 128로 설정</block>
  <block id="c0b3fd5512c2093847f753f398290f30" category="cell">* FC/FCoE 설정 *</block>
  <block id="2e556ad678160413b32dcca55c7d1f5f" category="cell">경로 선택 정책</block>
  <block id="117704664d6cada78ac3107380f63d23" category="cell">Disk.QFullSampleSize 를 참조하십시오</block>
  <block id="f66a3c183f0e736240b77f8b755c880e" category="cell">Disk.QFullThreshold를 참조하십시오</block>
  <block id="19c08de7404551288e1274186e039ef4" category="cell">Emulex FC HBA 시간 초과</block>
  <block id="b4dbfc2d52627e923cbb563a31ff756d" category="cell">기본값을 사용합니다.</block>
  <block id="d46cddda4da7ec11f17472d11df95b68" category="cell">QLogic FC HBA 시간 초과</block>
  <block id="19b5aaf3e2cb86809996ca63a2a416b0" category="cell">iSCSI 설정 *</block>
  <block id="fb55ee99c04280ac638757869929785d" category="paragraph">ONTAP 툴은 ONTAP FlexVol 볼륨 및 LUN을 생성할 때 특정 기본 설정도 지정합니다.</block>
  <block id="5938fe448c8661febcef3f4e779e3adb" category="cell">스냅숏 예비 공간(-percent-snapshot-space)</block>
  <block id="cfcd208495d565ef66e7dff9f98764da" category="cell">0</block>
  <block id="7218aec62575561a6de1cae8d5658390" category="cell">분할 예약(-fractional-reserve)</block>
  <block id="3a7e09ff0fa38663ffe6d91324ea75d9" category="cell">액세스 시간 업데이트(-atime-update)</block>
  <block id="f8320b26d30ab433c5a54546d21f414c" category="cell">거짓</block>
  <block id="e93200d5b0d16915bf04236790544b2f" category="cell">최소 미리 읽기(-min-readahead)</block>
  <block id="eee57b9c7d333899f3df6ffd10ec50df" category="cell">예약된 스냅샷 복사본</block>
  <block id="fd18465573ec21a6218982055981f6b1" category="cell">스토리지 효율성</block>
  <block id="00d23a76e43b46dae9ec7aa9dcbebb32" category="cell">활성화됨</block>
  <block id="f65fd63b63c9e9f25bf6bc141e83de34" category="cell">볼륨 보장</block>
  <block id="c2410aebdf425dabcc65e546e506b03e" category="cell">없음(씬 프로비저닝됨)</block>
  <block id="f97c03bf3e9580446d70d479f5aad1e0" category="cell">볼륨 자동 크기 조정</block>
  <block id="d89f4f8b1d7c18847b88b46142f61535" category="cell">grow_shrink</block>
  <block id="ace72ec54e17777d27eb8bdb9d57e782" category="cell">LUN 공간 예약</block>
  <block id="b9f5c797ebbf55adccdd8539a65a0241" category="cell">사용 안 함</block>
  <block id="514aa7792a71ab4ab677eb2385131aae" category="cell">LUN 공간 할당</block>
  <block id="0464f851d84d05f0a9db9051354e5581" category="section-title">기타 호스트 다중 경로 구성 고려 사항</block>
  <block id="5fcb3de72ca1920517439049153d961d" category="paragraph">현재 사용 가능한 ONTAP 툴에 의해 구성되어 있지 않지만, NetApp에서는 다음과 같은 구성 옵션을 고려할 것을 권장합니다.</block>
  <block id="840731ae1cb9e4b23e19f645ab018b6f" category="inline-link">2069356)을 참조하십시오</block>
  <block id="5073fc9da327263a7db04fd449991e6a" category="list-text">고성능 환경에서 또는 단일 LUN 데이터 저장소에서 성능을 테스트할 때는 라운드 로빈(VMW_PSP_RR) 경로 선택 정책(PSP)의 로드 밸런싱 설정을 기본 IOPS 설정인 1000에서 값 1로 변경하는 것이 좋습니다. VMware KB를 참조하십시오<block ref="f3f4762788a6845119bdb5b9c9179bda" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="1ea3eb55b985cf75e100607ee8bd935d" category="inline-link">경로 선택 플러그인 및 정책</block>
  <block id="249afbf456bd04d574e8d362d5bf133c" category="list-text">vSphere 6.7 업데이트 1에서 VMware는 라운드 로빈 PSP에 새로운 지연 시간 로드 밸런싱 메커니즘을 도입했습니다. 새로운 옵션은 I/O에 가장 적합한 경로를 선택할 때 I/O 대역폭과 경로 지연 시간을 고려합니다 한 경로에 다른 경로보다 더 많은 네트워크 홉이 있거나 NetApp All SAN 어레이 시스템을 사용하는 경우와 같이 비등가 경로 연결이 있는 환경에서 이 홉을 사용하면 도움이 될 수 있습니다. 을 참조하십시오<block ref="f5ecc69f2970e2e9c8638ad278ec38f7" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="d336a329d910c32fb90337a372f596fc" category="summary">NetApp ONTAP 소프트웨어는 약 20년 동안 VMware vSphere 환경을 위한 최고의 스토리지 솔루션으로, 혁신적인 기능을 지속적으로 추가하여 관리를 단순화하는 동시에 비용을 절감했습니다. 이 문서에서는 구축을 간소화하고 위험을 줄이며 관리를 단순화하는 최신 제품 정보 및 모범 사례를 비롯하여 vSphere용 ONTAP 솔루션에 대해 소개합니다.</block>
  <block id="952fd691754e388c7b7ba473cf410aff" category="doc">TR-4597: ONTAP용 VMware vSphere</block>
  <block id="b4191f5f6b40e39be6030dbbc9052330" category="paragraph">Karl Konnerth, NetApp</block>
  <block id="bfa7e7fc7c6bf4cc4e4c5c74b09763eb" category="paragraph">모범 사례는 가이드 및 호환성 목록 등의 다른 문서를 보완합니다. 이러한 전문 분야는 연구소 테스트와 NetApp 엔지니어 및 고객의 광범위한 현장 경험을 기반으로 합니다. 모든 환경에서 작동하는 유일한 지원 방법은 아니지만 일반적으로 대부분의 고객 요구를 충족하는 가장 간단한 솔루션입니다.</block>
  <block id="18b198d3d2381f05dd78bab3c8cec60c" category="paragraph">이 문서에서는 vSphere 6.0 이상에서 실행되는 최신 ONTAP(9.x) 릴리즈의 기능에 대해 중점적으로 설명합니다. 섹션을 참조하십시오 <block ref="4c9a6d8ccb9dfca3b5ae6e43e9663c99" category="inline-link-macro-rx"></block> 특정 릴리스와 관련된 자세한 내용은 를 참조하십시오.</block>
  <block id="4b401b0a40ae220c77961312c8238cdb" category="paragraph">수많은 고객들이 vSphere를 위한 스토리지 솔루션으로 ONTAP을 선택한 이유는 SAN 및 NAS 프로토콜을 모두 지원하는 유니파이드 스토리지 시스템, 공간 효율적인 NetApp Snapshot 복사본을 사용한 강력한 데이터 보호 기능 등 다양합니다. 애플리케이션 데이터를 관리하는 데 유용한 다양한 툴이 제공됩니다. 하이퍼바이저와 별도로 스토리지 시스템을 사용하면 다양한 기능을 오프로드하고 vSphere 호스트 시스템에 대한 투자를 극대화할 수 있습니다. 이렇게 하면 호스트 리소스가 애플리케이션 워크로드에 집중되도록 할 뿐 아니라 스토리지 작업에서 애플리케이션에 미치는 랜덤 성능 영향을 방지할 수 있습니다.</block>
  <block id="0f50acddbdbb9aa9712a471f2276e655" category="paragraph">ONTAP와 vSphere를 함께 사용하면 호스트 하드웨어 및 VMware 소프트웨어 비용을 절감할 수 있습니다. 또한 일관된 고성능을 통해 저렴한 비용으로 데이터를 보호할 수 있습니다. 가상화된 워크로드는 이동적이기 때문에 Storage vMotion을 사용하여 동일한 스토리지 시스템에서 VMFS, NFS 또는 VVol 데이터 저장소 간에 VM을 이동하는 다양한 접근 방식을 탐색할 수 있습니다.</block>
  <block id="90977175b761542615a11f2b96cc4cbd" category="paragraph">고객이 오늘날 가치를 제공하는 주요 요소는 다음과 같습니다.</block>
  <block id="dc4489aacb3c4d74b8253c49732b73e9" category="list-text">* 유니파이드 스토리지. * ONTAP 소프트웨어를 실행하는 시스템은 여러 가지 중요한 방식으로 통합됩니다. 이 접근 방식은 원래 NAS 및 SAN 프로토콜을 모두 갖추고 있으며, ONTAP는 NAS에서 그 원래 강점이 되었던 SAN을 위한 선도적인 플랫폼이 되었습니다. vSphere 환경에서 이 접근 방식은 가상 데스크톱 인프라(VDI)와 가상 서버 인프라(VSI)의 통합 시스템을 의미할 수도 있습니다. ONTAP 소프트웨어를 실행하는 시스템은 일반적으로 기존 엔터프라이즈 어레이보다 VSI 비용이 저렴하지만, 동일한 시스템에서 VDI를 처리할 수 있는 고급 스토리지 효율성 기능이 있습니다. 또한 ONTAP는 SSD에서 SATA에 이르는 다양한 스토리지 미디어를 통합하여 손쉽게 클라우드로 확장할 수 있습니다. 성능 향상을 위해 플래시 어레이 1개, 아카이브용 SATA 어레이 및 클라우드용 개별 시스템을 구입할 필요가 없습니다. ONTAP는 이러한 모든 것을 하나로 묶습니다.</block>
  <block id="ec8cd066c60323f007135b1f083b64de" category="list-text">* 가상 볼륨 및 스토리지 정책 기반 관리 * NetApp은 VVol(vSphere Virtual Volumes) 개발 과정에서 VMware와 초기 설계 파트너 관계를 맺고, VVOL과 VMware VASA(vSphere API for Storage Awareness)를 구조적 입력 및 조기 지원합니다. 이 접근 방식은 VMFS에 세분화된 VM 스토리지 관리를 제공할 뿐만 아니라 스토리지 정책 기반 관리를 통한 스토리지 프로비저닝 자동화도 지원합니다. 스토리지 설계자는 이 접근 방식을 통해 VM 관리자가 쉽게 사용할 수 있는 다양한 기능을 갖춘 스토리지 풀을 설계할 수 있습니다. ONTAP은 VVOL 스케일의 스토리지 산업을 선도하며 단일 클러스터에서 수십만 개의 VVOL을 지원하는 반면, 엔터프라이즈 어레이와 소규모 플래시 어레이 공급업체는 어레이당 수백 개의 VVOL을 지원합니다. NetApp은 또한 VVOL 3.0을 지원함으로써 세부적인 VM 관리 기능의 혁신을 이끌고 있습니다.</block>
  <block id="fd5311fb87e61b58d3c3d278df26af4f" category="list-text">*스토리지 효율성.* NetApp은 프로덕션 작업 부하에 대해 중복 제거 기능을 최초로 제공했지만 이 분야에서 이 혁신은 처음이거나 마지막 기술이 아니었습니다. 공간 효율적인 데이터 보호 메커니즘인 ONTAP 스냅샷 복사본에서 시작되어, 성능 저하 없이 VM의 읽기/쓰기 복사본을 즉시 만들어 운영 및 백업을 지원합니다. NetApp은 계속해서 중복제거, 압축, 제로 블록 중복제거 등과 같은 인라인 기능을 제공하여 고가의 SSD에서 최대한의 스토리지를 짜내었습니다. 가장 최근에 ONTAP은 컴팩션을 사용하여 소규모 I/O 작업 및 파일을 디스크 블록에 포장한 기능을 추가했습니다. 이러한 기능을 결합하여 고객은 VSI의 경우 최대 5:1, VDI의 경우 최대 30:1의 비용을 절감할 수 있었습니다.</block>
  <block id="bb73602f3344c326a7b63c94db24362a" category="list-text">* 하이브리드 클라우드. * 사내 프라이빗 클라우드, 퍼블릭 클라우드 인프라 또는 둘 모두의 장점인 하이브리드 클라우드에 사용하건 간에, ONTAP 솔루션을 사용하면 데이터 패브릭을 구축하여 데이터 관리를 간소화하고 최적화할 수 있습니다. 고성능 All-Flash 시스템으로 시작한 다음 디스크 또는 클라우드 스토리지 시스템과 커플하여 데이터 보호 및 클라우드 컴퓨팅을 지원합니다. Azure, AWS, IBM 또는 Google 클라우드 중에서 선택하여 비용을 최적화하고 종속 문제를 방지합니다. OpenStack 및 컨테이너 기술에 대한 고급 지원을 필요에 따라 활용합니다. 또한 NetApp은 ONTAP용 클라우드 기반 백업(SnapMirror 클라우드, Cloud Backup Service 및 Cloud Sync), 스토리지 계층화 및 아카이빙 툴(FabricPool)을 제공하여 운영 비용을 줄이고 광범위한 클라우드 활용을 지원합니다.</block>
  <block id="0c157ce4e4fd6289dbf0b282993c2f80" category="list-text">* 그 이상. * NetApp AFF A-Series 어레이의 탁월한 성능을 활용하여 가상화 인프라를 가속하고 비용을 관리하십시오. 스케일아웃 ONTAP 클러스터를 사용하면 유지보수, 업그레이드, 스토리지 시스템 전체 교체 등 운영 중단 없이 완벽하게 수행할 수 있습니다. 추가 비용 없이 NetApp 암호화 기능으로 유휴 데이터를 보호합니다. 세분화된 서비스 품질 기능을 통해 성능이 비즈니스 서비스 수준을 충족하는지 확인합니다. 이 모든 기능은 업계 최고의 엔터프라이즈 데이터 관리 소프트웨어인 ONTAP와 함께 제공되는 광범위한 기능의 일부입니다.</block>
  <block id="3e4627f6667f830baceaaf35890b575a" category="summary">이 문서에 설명된 정보에 대해 자세히 알아보려면 다음 문서 및/또는 웹 사이트를 검토하십시오.</block>
  <block id="092bf78f9c97ba171b8232ddff585392" category="doc">추가 정보</block>
  <block id="7d9ee37e3155d571b441d63bcbc54709" category="inline-link"><block ref="7d9ee37e3155d571b441d63bcbc54709" category="inline-link-rx"></block></block>
  <block id="52c629361849219069b336f56f1556d0" category="list-text">TR-4400: ONTAP를 포함한 VMware vSphere 가상 볼륨<block ref="b7bf139d6051615d8c8e01b6b63dacc3" category="inline-link-rx"></block></block>
  <block id="18df8e05a5400abd9d0980b1c5bc9ef3" category="list-text">ONTAP 9용 TR-4015 SnapMirror 구성 모범 사례 가이드<block ref="e361bd9d6f7b20da762bc23fcb3d09c2" category="inline-link-rx"></block></block>
  <block id="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link"><block ref="cbe2f6eb2a73f4a2c871a06264f10dc7" category="inline-link-rx"></block></block>
  <block id="249b98331fa56dc46bf6ba51dc6c39d5" category="list-text">RBAC ONTAP용 사용자 생성기<block ref="6b15b91279acfce2bbee060bdb17db43" category="inline-link-rx"></block></block>
  <block id="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link"><block ref="c88037eb28ae3cceb0e32c2cd3c322d7" category="inline-link-rx"></block></block>
  <block id="1a57e0f74e725c1a5e2d53b4d4b4460d" category="list-text">VMware vSphere 리소스를 위한 ONTAP 툴<block ref="80c496cd9ab75e5683007d8f66ca6fbf" category="inline-link-rx"></block></block>
  <block id="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link"><block ref="9aa6e8f8fac5c131e5924ee033660d29" category="inline-link-rx"></block></block>
  <block id="91a48e1708df22b7464bced79c745ad2" category="list-text">VMware Site Recovery Manager 설명서<block ref="92ad802ced4838839b492be6d0bf427d" category="inline-link-rx"></block></block>
  <block id="014a2413d22e5ac39371ac1333e38898" category="paragraph">을 참조하십시오<block ref="99cfde592e1d7fa7832b186d73ee4002" category="inline-link-rx"></block> NetApp Support 사이트에서 본 문서에 기술된 제품과 기능 버전이 귀사의 환경에서 지원되는지 확인하십시오. NetApp IMT에는 NetApp이 지원하는 구성을 설계하는 데 사용할 수 있는 제품 구성요소 및 버전이 정의되어 있습니다. 구체적인 결과는 게시된 기술사양과 그에 따른 고객 설치 환경에 따라 달라집니다.</block>
  <block id="93b94e62ad8cb02a1d1a7b0944a5445d" category="summary">이 문서에서는 VMware vSphere용 ONTAP 툴의 제품 보안에 대해 설명합니다.</block>
  <block id="289953e1dbd51c07cae2ecf1e6fb88a1" category="doc">WP-7353: VMware vSphere용 ONTAP 툴 - 제품 보안</block>
  <block id="595319f89334a6a0b8edd4f81172fc71" category="paragraph">Chance Bingen, Dan Tullege, Jenn Schrie, NetApp</block>
  <block id="7ab9df3e4e38ca227c1b48b0f6740675" category="section-title">안전한 개발 활동</block>
  <block id="1a79eb278bc02ebdbd2ab32925e316f6" category="paragraph">NetApp ONTAP Tools for VMware vSphere를 사용한 소프트웨어 엔지니어링에서는 다음과 같은 안전한 개발 활동을 활용합니다.</block>
  <block id="39e5fc9eb192f011ab14dae6c2974c4e" category="list-text">* 위협 모델링. * 위협 모델링의 목적은 소프트웨어 개발 수명 주기 초기에 피처, 부품 또는 제품의 보안 결함을 발견하기 위한 것입니다. 위협 모델은 응용 프로그램의 보안에 영향을 주는 모든 정보의 구조적 표현입니다. 본질적으로 보안 렌즈를 통해 응용 프로그램과 환경을 볼 수 있습니다.</block>
  <block id="9f16ab3a50bca32d19c4729319035c8d" category="list-text">* DAST(Dynamic Application Security Testing). * 이 기술은 실행 중인 응용 프로그램의 취약한 상태를 감지하도록 설계되었습니다. DAST는 웹 활성화 애플리케이션의 노출된 HTTP 및 HTML 인터페이스를 테스트합니다.</block>
  <block id="267bed0525e4dab477e4c24ca5a1794e" category="list-text">* 타사 코드 통화. * 오픈 소스 소프트웨어(OSS)를 통한 소프트웨어 개발의 일환으로 제품에 통합된 OSS와 관련된 보안 취약점을 해결해야 합니다. 이는 새로운 OSS 버전에 새로 발견된 취약점이 언제든지 보고될 수 있기 때문에 지속적인 노력입니다.</block>
  <block id="db7bc87c89c1ee76d313865a32fc0e06" category="list-text">* 취약성 검사. * 취약성 검사의 목적은 NetApp 제품이 고객에게 공개되기 전에 NetApp 제품의 알려진 공통 보안 취약점을 감지하는 것입니다.</block>
  <block id="1a4c104571630526efc77b84e82380fe" category="list-text">* 침투 테스트 * 침투 테스트는 시스템, 웹 응용 프로그램 또는 네트워크를 평가하여 공격자가 악용할 수 있는 보안 취약점을 찾는 프로세스입니다. NetApp의 침투 테스트(펜 테스트)는 승인되고 신뢰할 수 있는 타사 기업의 그룹에 의해 수행됩니다. 이러한 테스트 범위에는 정교한 악용 방법이나 도구를 사용하는 악의적인 침입자나 해커에 유사한 응용 프로그램 또는 소프트웨어에 대한 공격이 포함됩니다.</block>
  <block id="7e98fc3ea1ec077cfd1727a58e9c9020" category="section-title">제품 보안 기능</block>
  <block id="85d61648687f15050da0b86741b90358" category="paragraph">VMware vSphere용 NetApp ONTAP 툴에는 각 릴리즈에 다음과 같은 보안 기능이 포함되어 있습니다.</block>
  <block id="dff88c2ef0b49b09246ffd6f9ec55195" category="list-text">* 로그인 배너. * SSH는 기본적으로 비활성화되어 있으며 VM 콘솔에서 활성화된 경우 1회만 로그인할 수 있습니다. 사용자가 로그인 프롬프트에 사용자 이름을 입력하면 다음 로그인 배너가 표시됩니다.</block>
  <block id="399875025e8e96cc13102a4dd72f2434" category="paragraph">경고:* 이 시스템에 대한 무단 액세스는 금지되며 법률로 기소됩니다. 이 시스템에 액세스하면 무단 사용이 의심되는 경우 사용자의 조치를 모니터링할 수 있다는 데 동의하는 것입니다.</block>
  <block id="2d8330ed99c80a842ffbd1362e038e5e" category="paragraph">사용자가 SSH 채널을 통해 로그인을 완료하면 다음 텍스트가 표시됩니다.</block>
  <block id="677528ad13d460c058ac50e8a62092cf" category="list-text">* 역할 기반 액세스 제어(RBAC). * 두 가지 유형의 RBAC 컨트롤이 ONTAP 도구에 연결되어 있습니다.</block>
  <block id="ac38773d017495a97d5b88f242578cb8" category="list-text">기본 vCenter Server 권한</block>
  <block id="31cedac82fef311cb790a12f96897223" category="list-text">vCenter 플러그인별 권한 자세한 내용은 을 참조하십시오<block ref="e5f6920797dbff91ef59367270a82669" category="inline-link-rx"></block>.</block>
  <block id="5d32469f8a65b884a8f70abf95fe485a" category="list-text">* 암호화된 통신 채널. * 모든 외부 통신은 TLS 버전 1.2를 사용하여 HTTPS를 통해 이루어집니다.</block>
  <block id="600d4f98483fae8e58054f976d7e0c0e" category="list-text">* 최소 포트 노출. * 필요한 포트만 방화벽에서 열립니다.</block>
  <block id="0406f8902379502d1eba01f043c232b7" category="paragraph">다음 표에서는 열려 있는 포트의 세부 정보를 설명합니다.</block>
  <block id="69fc9fe9cbb7709e97a433352aecf77d" category="cell">TCP v4/V6 포트 번호</block>
  <block id="86408593c34af77fdd90df932f8b5261" category="cell">기능</block>
  <block id="d16c4afdc5f340936b747baf91efc843" category="cell">REST API용 HTTPS 연결</block>
  <block id="1f4deeb2f64336d4ff65ea3d2b4ffe2f" category="cell">HTTPS 연결</block>
  <block id="5852f8019b572f4cdef5bab783fa799f" category="cell">https 연결을 통한 SOAP에 사용되는 HTTPS 연결 클라이언트가 ONTAP 도구 API 서버에 연결할 수 있도록 이 포트를 열어야 합니다.</block>
  <block id="f4e339608b243f9b57b78ffaf061b498" category="cell">SSH(기본적으로 비활성화됨)</block>
  <block id="ef34781e03f49b5db5dd8fa267c4c41b" category="cell">HTTPS 연결 - VP 및 SRA - 루프백에서만 내부 연결</block>
  <block id="4a0724da5c6f4e4817663ae822550800" category="cell">VP SNMP 트랩 패킷입니다</block>
  <block id="60135f95267c6e0711bf5a2858dfff2f" category="cell">Derby 데이터베이스 포트, 이 컴퓨터와 자체 사이에서만, 외부 연결은 허용되지 않음 -- 내부 연결만</block>
  <block id="bf6184406d1e18fffc86ecf770fbb391" category="inline-link">KB 문서를 참조하십시오</block>
  <block id="fedac49792829de4ff38fcf7a3846faa" category="list-text">* CA(인증 기관) 서명 인증서 지원. * VMware vSphere용 ONTAP 툴은 CA 서명 인증서를 지원합니다. 자세한 내용은 다음을 참조하십시오<block ref="0903a062b2072644a9b744a7fece4216" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="9fca19988370da2a459b24505e9d23d5" category="list-text">* 감사 로깅. * 지원 번들은 다운로드할 수 있으며 매우 자세히 설명되어 있습니다. ONTAP 도구는 모든 사용자 로그인 및 로그아웃 활동을 별도의 로그 파일에 기록합니다. VASA API 호출은 전용 VASA 감사 로그(로컬 CXF.log)에 기록됩니다.</block>
  <block id="7d60a2806aedd934b75cce55d6693689" category="list-text">암호 정책 * 다음 암호 정책을 따릅니다.</block>
  <block id="f82f7513742f08b9d2784923213bdc75" category="list-text">암호는 로그 파일에 기록되지 않습니다.</block>
  <block id="83040c348e071499488a8128db207545" category="list-text">암호는 일반 텍스트로 전달되지 않습니다.</block>
  <block id="bc319862df3312f423a50fece7730db9" category="list-text">암호는 설치 과정 중에 구성됩니다.</block>
  <block id="853c2ea85b86882d0ea73b606a9800a4" category="list-text">암호 기록은 구성 가능한 매개 변수입니다.</block>
  <block id="b3d3877bc96752ae50a409c72597d47a" category="list-text">최소 암호 사용 기간은 24시간으로 설정됩니다.</block>
  <block id="fb0bdec50022a37424a405b53da7c9c8" category="list-text">암호 필드에 대한 자동 완성 기능이 비활성화됩니다.</block>
  <block id="3a04f054be8ad983ea82fd5079519810" category="list-text">ONTAP 도구는 SHA256 해싱을 사용하여 저장된 모든 자격 증명 정보를 암호화합니다.</block>
  <block id="62783f5d69cb5d3cb22b077c1d2b8777" category="cell">2021년 11월</block>
  <block id="b1c770f25b823d4453567c0ff9d7cf67" category="summary">이 페이지에서는 VMware vSphere 환경에 NetApp ONTAP NFS 버전 3 데이터 저장소를 구축하는 단계를 제공합니다.</block>
  <block id="168dbfe414d4d4089585360152953a57" category="doc">vSphere NFS 데이터 저장소 - 버전 3(ONTAP 포함</block>
  <block id="2be27a78c84ba5629cd9f2c22983240a" category="paragraph">ONTAP NAS 스토리지를 사용하여 NFS 버전 3 데이터 저장소를 생성합니다.</block>
  <block id="106a118b8a267220cb2c40a4bb68b684" category="list-text">vSphere 환경 및 ONTAP를 관리하는 데 필요한 기본 기술입니다.</block>
  <block id="00c46d0ea9cdf9a5a37b8af04896741f" category="list-text">ONTAP 9.8 이상을 실행하는 ONTAP 스토리지 시스템(FAS/AFF/CVO/ONTAP Select/Cloud Volume Service/Azure NetApp Files</block>
  <block id="a9ab6317871b5547fc7bf0dd22151f00" category="list-text">vSphere 7.0 이상에 대한 vSphere 호스트 정보입니다</block>
  <block id="0675fa9a38b420775f29ec7a62d9a8a0" category="list-text">ONTAP 시스템 네트워크 데이터 포트 및 연결된 vSphere 호스트를 사용합니다</block>
  <block id="4b18348d39655902cd0e183596a82856" category="list-text">과의 호환성을 확인하십시오<block ref="3028580b30f2b1d483aad9f9a7a65c7a" category="inline-link-rx"></block></block>
  <block id="c54d1c547e26987b98af73634278c77a" category="inline-link-macro">NFS에 대한 ONTAP 라이센스를 확인합니다.</block>
  <block id="8174503ab9e5dc2fe2f74068f651770d" category="list-text"><block ref="8174503ab9e5dc2fe2f74068f651770d" category="inline-link-macro-rx"></block></block>
  <block id="5d3f3e14f3096740cb085fa81836d595" category="list-text">'system license show' 명령어를 사용하여 NFS가 나열되는지 확인한다.</block>
  <block id="135850bb72d05ca77b8b8f846429fe71" category="inline-link-macro">NFS 구성 워크플로우를 따릅니다.</block>
  <block id="01a85c06aae02abe9083e7e02d90661f" category="list-text"><block ref="01a85c06aae02abe9083e7e02d90661f" category="inline-link-macro-rx"></block></block>
  <block id="2281b9d958567868b171298a8df5cdee" category="inline-link-macro">vSphere에 대한 NFS 클라이언트 구성의 워크플로우를 따릅니다.</block>
  <block id="c80c5160cfe2127b3ab167103b20488c" category="paragraph"><block ref="c80c5160cfe2127b3ab167103b20488c" category="inline-link-macro-rx"></block></block>
  <block id="63d5049791d9d79d86e9a108b0a999ca" category="section-title">참조하십시오</block>
  <block id="160f88ca0bed5b24e94c809f4e22f1e7" category="summary">ONTAP 9에서는 클러스터의 물리적 구성 요소가 클러스터 관리자에게 표시되지만 클러스터를 사용하는 애플리케이션과 호스트에는 직접 표시되지 않습니다.</block>
  <block id="89fafdb11a7e8cd8abebb1d4df053dad" category="doc">복제 토폴로지</block>
  <block id="be01acd2f018d38f9446f06b99ee4a2a" category="paragraph">ONTAP 9에서는 클러스터의 물리적 구성 요소가 클러스터 관리자에게 표시되지만 클러스터를 사용하는 애플리케이션과 호스트에는 직접 표시되지 않습니다. 물리적 구성 요소는 논리적 클러스터 리소스가 구성되는 공유 리소스 풀을 제공합니다. 애플리케이션과 호스트는 볼륨 및 LIF가 포함된 SVM을 통해서만 데이터에 액세스합니다.</block>
  <block id="7758fc02779ee5917b0a09ee22b52221" category="paragraph">각 NetApp SVM은 VMware vCenter Site Recovery Manager에서 어레이로 취급됩니다. SRM은 특정 어레이 간(또는 SVM 간) 복제 레이아웃을 지원합니다.</block>
  <block id="58c0b55a67f4331cc49b073a7183e06c" category="paragraph">단일 VM은 VMDK(Virtual Machine Disk) 또는 RDM 같은 데이터를 소유할 수 없습니다. 이러한 데이터를 여러 SRM 스토리지에서 소유할 수 없는 이유는 다음과 같습니다.</block>
  <block id="880aeda0b58c0b30120b6319ae5f3beb" category="list-text">SRM에는 개별 물리적 컨트롤러가 아닌 SVM만 표시됩니다.</block>
  <block id="6f55124e085dbeb640e4cb8ad2c97905" category="list-text">SVM은 하나의 클러스터에서 여러 노드에 걸쳐 있는 LUN 및 볼륨을 제어할 수 있습니다.</block>
  <block id="39d9903201320a83d45d3b36d512f051" category="cell">모범 사례</block>
  <block id="d86019fe4ba86b184ac71cf24a22f0c6" category="cell">지원 가능성을 확인하려면 이 규칙을 염두에 두십시오. SRM 및 NetApp SRA를 사용하여 VM을 보호하려면 VM의 모든 부분이 하나의 SVM에만 존재해야 합니다. 이 규칙은 보호 사이트와 복구 사이트 모두에 적용됩니다.</block>
  <block id="2e4472d35f80aa8b7eca52ae3dd43dc6" category="section-title">지원되는 SnapMirror 레이아웃</block>
  <block id="d070ad9d8397892aa7f317cbb9046661" category="paragraph">다음 그림은 SRM 및 SRA에서 지원하는 SnapMirror 관계 레이아웃 시나리오를 보여 줍니다. 복제된 볼륨의 각 VM은 각 사이트의 한 SRM 어레이(SVM)에만 데이터를 소유합니다.</block>
  <block id="39d3085abe6ccb914d8535de8a5f3e37" category="paragraph"><block ref="39d3085abe6ccb914d8535de8a5f3e37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ae7670cf947a397bdf6a882fbcc912a" category="paragraph"><block ref="1ae7670cf947a397bdf6a882fbcc912a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="111d3212464dba203cbd675a0338dcbc" category="paragraph"><block ref="111d3212464dba203cbd675a0338dcbc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5dc3a606b05b41db22793ed3c1a72db" category="paragraph"><block ref="c5dc3a606b05b41db22793ed3c1a72db" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86cf5bd2bdb1b1d67f8f907f41099509" category="section-title">지원되는 Array Manager 레이아웃입니다</block>
  <block id="aacc8f18d659f75715d91a983e872233" category="paragraph">SRM에서 ABR(스토리지 기반 복제)을 사용하면 다음 스크린샷과 같이 보호 그룹이 단일 스토리지 쌍으로 격리됩니다. 이 경우 복구 현장에서는 VM1과 VM2를 VM3과 VM4로 들여다봅니다. 그러나 보호 그룹을 생성할 때는 두 스토리지 쌍 중 하나만 선택할 수 있습니다.</block>
  <block id="68a1b289711a591ed50627014cd01ce9" category="paragraph"><block ref="68a1b289711a591ed50627014cd01ce9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ceb46f3e1c6c7995de4ec5f05601227" category="section-title">지원되지 않는 레이아웃입니다</block>
  <block id="611b9b35ac984f20e6594baec9181dbf" category="paragraph">지원되지 않는 구성에는 개별 VM이 소유하는 여러 SVM에 데이터(VMDK 또는 RDM)가 있습니다. 다음 그림에 표시된 예에서 VM1은 두 SVM에 데이터가 있으므로 SRM을 사용하여 보호할 수 있도록 VM1을 구성할 수 없습니다.</block>
  <block id="5c251a65e8394fbeaf104ba1a1cad2e1" category="paragraph"><block ref="5c251a65e8394fbeaf104ba1a1cad2e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="paragraph"><block ref="f5f5fe64e0e9d0ae7ce2a0777d0ccf62" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69851ac8c2fa81b32799efc8522798d5" category="paragraph">개별 NetApp 볼륨이 하나의 소스 SVM에서 동일한 SVM의 여러 대상 또는 서로 다른 SVM에 복제된 모든 복제 관계를 SnapMirror 팬아웃(fan-out)이라고 합니다. SRM에서는 팬아웃이 지원되지 않습니다. 다음 그림에 표시된 예제에서 VM1은 SnapMirror를 사용하여 두 개의 다른 위치로 복제되므로 SRM에서 보호용으로 구성할 수 없습니다.</block>
  <block id="688890bdbdfd2d73a05a09883f3c4b40" category="paragraph"><block ref="688890bdbdfd2d73a05a09883f3c4b40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f88384b0d5cdcdc25895c644126c1b0" category="section-title">SnapMirror 계단식 배열</block>
  <block id="7ebde774ad43c45667d5544308a6d688" category="paragraph">SRM은 소스 볼륨이 타겟 볼륨에 복제되고 해당 타겟 볼륨도 SnapMirror를 통해 다른 타겟 볼륨으로 복제되는 SnapMirror 관계의 다중 구간 기능을 지원하지 않습니다. 다음 그림에 표시된 시나리오에서는 사이트 간 장애 조치에 SRM을 사용할 수 없습니다.</block>
  <block id="2990fc44e9ba827a397e96e1c278a02a" category="paragraph"><block ref="2990fc44e9ba827a397e96e1c278a02a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd15e818d377a0a5cf6ebc429555f79" category="section-title">SnapMirror 및 SnapVault</block>
  <block id="d440734d1f5d9c6e59aa97f7cbbcd525" category="paragraph">NetApp SnapVault 소프트웨어를 사용하면 NetApp 스토리지 시스템 간에 엔터프라이즈 데이터를 디스크 기반으로 백업할 수 있습니다. SnapVault와 SnapMirror는 동일한 환경에 공존할 수 있지만 SRM은 SnapMirror 관계의 페일오버만 지원합니다.</block>
  <block id="7878dfbf4b6ad3bc60d095cf89d79202" category="admonition">NetApp SRA는 'Mirror-vault' 정책 유형을 지원합니다.</block>
  <block id="883e69a285ae2d5fd23c80cd29285804" category="paragraph">SnapVault는 처음부터 ONTAP 8.2를 위해 재구축되었습니다. 이전 Data ONTAP 7-Mode 사용자에게도 유사한 점이 있긴 하지만, 이 버전의 SnapVault에서는 여러 가지 기능이 크게 향상되었습니다. 한 가지 중요한 발전은 SnapVault 전송 중에 운영 데이터의 스토리지 효율성을 유지할 수 있는 기능입니다.</block>
  <block id="9bc21373e0e299579a7ac86dcd4f513d" category="paragraph">중요한 아키텍처 변화는 ONTAP 9의 SnapVault가 7-Mode SnapVault와 마찬가지로 qtree 레벨이 아닌 볼륨 레벨에서 복제된다는 점입니다. 이 설정은 SnapVault 관계의 소스가 볼륨이어야 하며 해당 볼륨이 SnapVault 보조 시스템의 자체 볼륨으로 복제되어야 함을 의미합니다.</block>
  <block id="f7b20cbc14027c7711d53d03a84f31af" category="paragraph">SnapVault가 사용되는 환경에서 특히 이름이 인 스냅샷 복사본이 운영 스토리지 시스템에 생성됩니다. 구축된 구성에 따라 명명된 스냅샷 복사본을 SnapVault 일정에 따라 운영 시스템이나 NetApp Active IQ Unified Manager 같은 애플리케이션에 의해 생성할 수 있습니다. 그런 다음 기본 시스템에서 생성된 명명된 스냅샷 복사본이 SnapMirror 대상에 복제되고, 생성된 스냅샷 복사본은 SnapVault 대상에 복제됩니다.</block>
  <block id="5dd37b7cd36f7d38ba2e6a63c603be4c" category="paragraph">소스 볼륨은 DR 사이트의 SnapMirror 대상에 복제되는 계단식 구성으로 생성할 수 있으며, 이 구성에서는 볼륨을 SnapVault 타겟에 저장할 수 있습니다. 한 대상이 SnapMirror 대상이고 다른 대상이 SnapVault 대상인 팬아웃 관계에 소스 볼륨을 생성할 수도 있습니다. 그러나 SRM 페일오버 또는 복제 반전이 발생할 경우 SnapMirror 대상 볼륨을 볼트의 소스로 사용하도록 SRA는 SnapVault 관계를 자동으로 재구성하지 않습니다.</block>
  <block id="5bc66b9c84b3f7cc0b375e729376b68d" category="inline-link">ONTAP 9용 TR-4015 SnapMirror 구성 모범 사례 가이드.</block>
  <block id="0d510e96259254d285c6aaeb8458f45d" category="paragraph">SnapMirror 및 SnapVault for ONTAP 9에 대한 최신 정보는 를 참조하십시오<block ref="32e7c991f675bf983c547a2a174c2caf" category="inline-link-rx"></block></block>
  <block id="75f8a2d99eea9f336120aec69d8c1010" category="cell">SnapVault 및 SRM이 동일한 환경에서 사용되는 경우 SnapVault 백업이 일반적으로 DR 사이트의 SnapMirror 대상에서 수행되는 SnapMirror와 SnapVault 다중 구간 구성을 사용하는 것이 좋습니다. 재해가 발생할 경우 이 구성을 사용하면 운영 사이트에 액세스할 수 없습니다. 복구 사이트에서 SnapVault 대상을 유지하면 복구 사이트에서 운영 중인 동안 SnapVault 백업을 계속할 수 있도록 장애 조치 후 SnapVault 백업을 재구성할 수 있습니다.</block>
  <block id="e082a67e3ddd7f4f92096536440cbb34" category="paragraph">VMware 환경에서 각 데이터 저장소에는 UUID(Universal Unique Identifier)가 있으며 각 VM에는 고유한 MOID(Managed Object ID)가 있습니다. 이러한 ID는 장애 조치 또는 장애 복구 중에 SRM에 의해 유지되지 않습니다. 데이터 저장소 UUID 및 VM MOID는 SRM에서 페일오버 중에 유지되지 않으므로 이러한 ID에 의존하는 모든 애플리케이션은 SRM 페일오버 후에 재구성해야 합니다. 애플리케이션의 예로는 SnapVault 복제를 vSphere 환경과 조정하는 NetApp Active IQ Unified Manager가 있습니다.</block>
  <block id="657a41cce55646ab17754ac1427970af" category="paragraph">다음 그림은 SnapVault 계단식으로 구성된 SnapMirror를 보여 줍니다. SnapVault 대상이 DR 사이트 또는 운영 사이트의 운영 중단으로 인해 영향을 받지 않는 3차 사이트에 있는 경우, 페일오버 후 백업을 계속할 수 있도록 환경을 재구성할 수 있습니다.</block>
  <block id="b56afb9a43332c671116b9fa3d597867" category="paragraph"><block ref="b56afb9a43332c671116b9fa3d597867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e068178460f103498576eac8ddb7fb82" category="paragraph">다음 그림에서는 SRM을 사용하여 SnapMirror 복제를 기본 사이트로 되돌린 후의 구성을 보여 줍니다. 또한 SnapVault 백업이 현재 SnapMirror 소스에서 발생하도록 환경이 재구성되었습니다. 이 설정은 SnapMirror SnapVault 팬아웃 구성입니다.</block>
  <block id="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="paragraph"><block ref="0ffa07ffd89b136d0ed8f2ac5ebcabb8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4607a4ee7e1830ab6ba0007df206956" category="paragraph">SRM이 페일백을 수행하고 SnapMirror 관계의 두 번째 반전을 수행한 후 운영 데이터가 기본 사이트로 돌아갑니다. 이 데이터는 SnapMirror 및 SnapVault 백업을 통해 DR 사이트로 페일오버 전의 방식과 동일하게 보호됩니다.</block>
  <block id="63fd1f18d5d53fa97fd05a7fd96090b4" category="section-title">Site Recovery Manager 환경에서 Qtree 사용</block>
  <block id="2d88570ceb2de0d8699a068b0140454b" category="paragraph">qtree는 NAS에 대한 파일 시스템 할당량을 적용할 수 있는 특수 디렉토리입니다. ONTAP 9에서는 qtree를 생성할 수 있으며 qtree는 SnapMirror로 복제된 볼륨에 존재할 수 있습니다. 그러나 SnapMirror에서는 개별 qtree 또는 qtree 레벨 복제의 복제를 허용하지 않습니다. 모든 SnapMirror 복제는 볼륨 레벨에만 있습니다. 이러한 이유로 SRM에서는 qtree를 사용하지 않는 것이 좋습니다.</block>
  <block id="345cb3f040f9f7f3f1a4261ed260aa79" category="section-title">FC 및 iSCSI 혼합 환경</block>
  <block id="a60b166c2b69b4fdfbb733dc2193668a" category="paragraph">지원되는 SAN 프로토콜(FC, FCoE 및 iSCSI)을 통해 ONTAP 9는 LUN 서비스를 제공합니다. 즉, LUN을 생성하여 연결된 호스트에 매핑할 수 있습니다. 클러스터는 여러 컨트롤러로 구성되며, 개별 LUN에 대한 다중 경로 I/O를 통해 관리되는 여러 논리적 경로가 있습니다. 호스트에서 ALUA(Asymmetric Logical Unit Access)가 사용되므로 LUN에 대한 최적화된 경로가 선택되고 데이터 전송을 위해 활성화됩니다. LUN에 대한 최적화된 경로(예: 포함된 볼륨이 이동됨)가 변경되면 ONTAP 9가 자동으로 해당 변경 사항을 인식하고 중단 없이 조정합니다. 최적화된 경로를 사용할 수 없게 되면 ONTAP는 무중단으로 다른 사용 가능한 경로로 전환할 수 있습니다.</block>
  <block id="b9921ac732e72656bc2836f83bb09522" category="paragraph">VMware SRM 및 NetApp SRA는 한 사이트에서 FC 프로토콜을 사용하고 다른 사이트에서는 iSCSI 프로토콜을 사용할 수 있도록 지원합니다. 하지만 동일한 ESXi 호스트 또는 동일한 클러스터의 다른 호스트에 FC 연결 데이터 저장소와 iSCSI 연결 데이터 저장소를 함께 사용할 수는 없습니다. SRM 페일오버 또는 테스트 페일오버 중에 SRM은 요청에 따라 ESXi 호스트의 모든 FC 및 iSCSI 이니시에이터를 포함하므로 SRM에서는 이 구성이 지원되지 않습니다.</block>
  <block id="fccd44a96243e459128798803dca70aa" category="cell">SRM 및 SRA는 보호 사이트와 복구 사이트 간에 혼합 FC 및 iSCSI 프로토콜을 지원합니다. 그러나 각 사이트는 동일한 사이트에서 두 프로토콜을 모두 구성하지 않고 FC 또는 iSCSI 프로토콜을 하나만 사용하여 구성해야 합니다. FC와 iSCSI 프로토콜을 동일한 사이트에 모두 구성해야 하는 경우 일부 호스트는 iSCSI를 사용하고 다른 호스트는 FC를 사용하는 것이 좋습니다. 또한 이 경우에는 VM이 호스트 그룹 또는 다른 그룹으로 페일오버되도록 SRM 리소스 매핑을 설정하는 것이 좋습니다.</block>
  <block id="f5852a230bef6cf666f848c5a2137db2" category="doc">ONTAP 유니파이드 스토리지</block>
  <block id="0dc14c0a294efec0c8cab98ebffa39f0" category="section-title">유니파이드 스토리지 정보</block>
  <block id="d00516b816f266ee64e7b1de5af59ff2" category="paragraph">ONTAP 소프트웨어를 실행하는 시스템은 여러 가지 중요한 방식으로 통합됩니다. 이 접근 방식은 원래 하나의 스토리지 시스템에서 NAS 및 SAN 프로토콜을 모두 지원한다는 것을 언급했으며, ONTAP는 NAS에서 그 원래 강점과 함께 SAN을 위한 최고의 플랫폼이 되었습니다. SVM(스토리지 가상 머신)은 클라이언트가 ONTAP 소프트웨어를 실행하는 시스템에 액세스할 수 있도록 지원하는 논리적 구성입니다. SVM은 논리 인터페이스(LIF)를 통해 여러 데이터 액세스 프로토콜을 통해 데이터를 동시에 제공할 수 있습니다. SVM은 CIFS 및 NFS와 같은 NAS 프로토콜을 통해 파일 레벨 데이터 액세스를 지원하고, iSCSI, FC/FCoE, NVMe와 같은 SAN 프로토콜을 통해 블록 레벨 데이터 액세스를 제공합니다. SVM은 SAN 및 NAS 클라이언트에 데이터를 동시에 독립적으로 제공할 수 있습니다.</block>
  <block id="92515b597b8c0784d6000b89ee47c5fd" category="inline-image-macro">유니파이드 스토리지</block>
  <block id="d6154a0901f9ca6bb5d8fb15c113581e" category="paragraph"><block ref="d6154a0901f9ca6bb5d8fb15c113581e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d59082aeee25c59b01266eaef6cb14" category="paragraph">vSphere 환경에서 이 접근 방식은 가상 데스크톱 인프라(VDI)와 가상 서버 인프라(VSI)의 통합 시스템을 의미할 수도 있습니다. ONTAP 소프트웨어를 실행하는 시스템은 일반적으로 기존 엔터프라이즈 어레이보다 VSI 비용이 저렴하지만, 동일한 시스템에서 VDI를 처리할 수 있는 고급 스토리지 효율성 기능이 있습니다. 또한 ONTAP는 SSD에서 SATA에 이르는 다양한 스토리지 미디어를 통합하여 손쉽게 클라우드로 확장할 수 있습니다. 성능 향상을 위해 플래시 어레이 1개, 아카이브용 SATA 어레이 및 클라우드용 개별 시스템을 구입할 필요가 없습니다. ONTAP는 이러한 모든 것을 하나로 묶습니다.</block>
  <block id="e9e0f5f2c513c7138ea70b4c929d6fef" category="inline-link">스토리지 가상화</block>
  <block id="54c9439ad8fb4842a5a86c34d2401e36" category="admonition">SVM, 유니파이드 스토리지 및 클라이언트 액세스에 대한 자세한 내용은 를 참조하십시오<block ref="2843f934dec816d79f9c394ad0533c28" category="inline-link-rx"></block> ONTAP 9 문서 센터</block>
  <block id="b278438874f41a76068d02368e65aa3e" category="doc">이 리포지터리 정보</block>
  <block id="404af48e0cb5f84306fbd93fac2ff8be" category="paragraph">NetApp Solutions 저장소를 간략하게 소개 - 특정 솔루션을 찾는 위치 및 이 저장소 사용 방법</block>
  <block id="45ac6b09a3b8f5ea07ca656ca8dea987" category="section-title">리포지터리의 탐색</block>
  <block id="c28e40ef527e43509a0fcd3b114ff824" category="paragraph">리포지토리의 탐색은 페이지의 왼쪽에 표시되는 기본 사이드바에 의해 관리됩니다. 솔루션은 NetApp 솔루션을 위한 "기술 타워"로 정의된 상위 수준의 기술 영역으로 분류됩니다.</block>
  <block id="e9982e506e30915713c7485a2e77633b" category="section-title">Technology Towers 개요</block>
  <block id="d67372be0bd12a2ddbcf795ccfacc7de" category="cell">* 섹션 *</block>
  <block id="f14c276c07197ebef1394a5a219087a1" category="cell">* 설명 *</block>
  <block id="d83d094e8e3ce7450bf099061814d148" category="cell">Red Hat Ansible을 사용한 솔루션 자동화 시작 개요</block>
  <block id="6174d88cc7c0409df3e035a5c9d089cb" category="section-title">Change Log(로그 변경)</block>
  <block id="a0067ab2420cbaebc335efc5c2433c45" category="inline-link-macro">변경 로그</block>
  <block id="bea4c2c8eb82d05891ddd71584881b56" category="section-title">피드백</block>
  <block id="fb6b632cdd61e02434568081cbbf0fae" category="paragraph">을(를) 사용하십시오 <block ref="a5f81f398e43efd62a061a201309bfa7" category="inline-link-macro-rx"></block> 콘텐츠의 변경을 요청하거나 콘텐츠에 대한 피드백을 제공합니다. 귀하의 피드백이 적절하게 처리되도록 최대한 구체적으로 적어 주십시오.</block>
  <block id="89185de94c95d958df7a1d1f328c5d3d" category="summary">마이그레이션은 마이그레이션 계획 및 완료를 위해 따라야 할 단계가 다릅니다. NetApp XCP를 사용하여 타사 NAS 스토리지나 직접 연결된 NAS 내보낸 스토리지에서 데이터를 마이그레이션하려면 이 섹션에 제공된 마이그레이션 지침을 따르십시오.</block>
  <block id="ee5b035493cdde88f6472904ffe00677" category="doc">마이그레이션 워크플로우</block>
  <block id="33af37ca0d75bc0783cc87782a94cb6e" category="inline-link-macro">그 전에 NetApp XCP가 있습니다.</block>
  <block id="c6f303d52bc03c848b2dde21f1b31f9d" category="paragraph"><block ref="c6f303d52bc03c848b2dde21f1b31f9d" category="inline-link-macro-rx"></block></block>
  <block id="5b312b66520bbb17746eeb5c9959e4ef" category="paragraph">다음 그림에서는 NAS에서 NetApp NAS로의 마이그레이션 워크플로우를 보여 줍니다.</block>
  <block id="228d4a26c37192668bb7f7bf0d81ce40" category="paragraph"><block ref="228d4a26c37192668bb7f7bf0d81ce40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8df17c51ab4a9817f3fe7cea57052110" category="paragraph">NAS에서 NetApp NAS로 마이그레이션 워크플로우는 다음 단계를 포함합니다.</block>
  <block id="3bd3dda9341b512ee536cc6e48d51a69" category="list-text">NAS 공유 및 데이터를 검색합니다.</block>
  <block id="7800ed0aa4aebf1d63fd7120c2bcf538" category="list-text">데이터를 스캔하고 보고서를 생성하여 데이터의 레이아웃을 찾습니다.</block>
  <block id="8e9880476ad79e202d93a0a7d0bb5f5b" category="list-text">xCP Copy 명령을 실행하여 기준을 생성합니다. 더 빠른 마이그레이션을 위해 더 많은 XCP 인스턴스를 선택하고 하위 폴더 레벨에서 워크로드를 분할하여 병렬 마이그레이션 작업을 시작합니다.</block>
  <block id="57324e972ea87c8e788d9831e510bc6d" category="list-text">증분 업데이트의 경우 컷오버 기간에 대한 변경률이 낮아질 때까지 xCP 동기화를 사용하십시오.</block>
  <block id="3812202d715addac73d7122672d3c8d0" category="list-text">xCP 동기화 명령을 실행하여 마이그레이션을 완료하여 소스를 읽기 전용으로 표시하여 최종 동기화를 수행합니다.</block>
  <block id="2c1d8a91f274a7723f6ad2ffefc81b62" category="list-text">데이터가 올바르게 전송되었는지 확인하려면 xCP verify 명령을 실행하여 소스와 대상을 비교합니다.</block>
  <block id="b98a6acc7ef428f1ae11e5177447df8c" category="paragraph">클라우드의 경우, 온프레미스와 클라우드 간의 연결이 직접 연결(AWS), ExpressRoute(Azure), 클라우드 인터커넥트(GCP) 인 경우에도 유사한 사내 마이그레이션 워크플로우를 따를 수 있습니다.</block>
  <block id="8f4cde54f5af74d15d142ad98344aab6" category="paragraph">다음 그림에서는 사내에서 클라우드로 마이그레이션 워크플로우를 보여 줍니다.</block>
  <block id="9d1b3862e72bece8266c1c8b1098c696" category="paragraph"><block ref="9d1b3862e72bece8266c1c8b1098c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e2fef7fa18bd688132425321b9188bb" category="paragraph">온프레미스와 클라우드 간에 직접 인터넷 연결이 없는 경우 트럭과 같은 오프라인 데이터 전송 방법을 통해 사내 데이터를 클라우드로 전송해야 합니다. 각 클라우드 서비스 공급자마다 다른 용어를 사용하여 데이터를 데이터 센터로 이동하는 방법이 있습니다.</block>
  <block id="9e76bcaf48df4797c2e546f778fd72f8" category="paragraph">다음 그림은 ExpressRoute 없이 사내 및 Azure용 Data Mover 솔루션을 보여 줍니다.</block>
  <block id="e13bab0261f71ca4765f8b68cea20a43" category="paragraph"><block ref="e13bab0261f71ca4765f8b68cea20a43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423066080659363cc444ec5dee611f48" category="paragraph">다양한 클라우드 서비스 공급자의 각 구성 요소와 함께 유사한 아키텍처를 사용할 수 있습니다.</block>
  <block id="050572d01f21dded8086b49419066add" category="inline-link-macro">다음: 파일 분석.</block>
  <block id="ae292ee37a105844872f831698fb440f" category="paragraph"><block ref="ae292ee37a105844872f831698fb440f" category="inline-link-macro-rx"></block></block>
  <block id="ddf97b6ffb913bd772848e3ebecfc8c1" category="summary">이 섹션에서는 NetApp XCP 데이터 전송을 위한 구축 단계에 대해 설명합니다.</block>
  <block id="8388066510b59c8d3387373b6969a7af" category="doc">배포 단계</block>
  <block id="c6310b144c1666a29ec7cacf1c0dceab" category="inline-link-macro">이전: 파일 분석.</block>
  <block id="57c4917a0617c8b675e6cc1dbad5c7fe" category="paragraph"><block ref="57c4917a0617c8b675e6cc1dbad5c7fe" category="inline-link-macro-rx"></block></block>
  <block id="8449c94058b7c2e686c3e19f7e772a65" category="section-title">테스트 베드 세부 정보</block>
  <block id="94cb70bde9d89f0b10ffdca34b0bec22" category="paragraph">다음 표에는 이 배포 및 성능 검증에 사용된 테스트 베드 세부 정보가 나와 있습니다.</block>
  <block id="57419d904381619fcf00bc94e4ce26f1" category="cell">xCP 버전 1.7</block>
  <block id="0bf2dca8ce9b94406660e58b59a3dbbd" category="list-text">Linux 서버 1개 - Linux(RHEL 7.9 또는 RHEL 8)</block>
  <block id="d85d793ce9fe1772209fa5e17fb29449" category="list-text">Windows 서버 1대 – Windows Server 2019 표준</block>
  <block id="91ea491db15b6d672d79b23fb98eb089" category="cell">소스 볼륨의 NetApp AFF 스토리지 어레이 HA 쌍</block>
  <block id="23ec9249d03285a513eaaf182a7bcd49" category="list-text">AFF8080</block>
  <block id="80fdc6d88149270be735269f2ff65645" category="cell">타겟 볼륨을 위한 NetApp AFF 스토리지 어레이 HA 쌍</block>
  <block id="203165a49e3a391bdbc44e3a05d54279" category="list-text">ONTAP 9</block>
  <block id="28712ee052ea500eba0cdbb1d847277f" category="cell">Fujitsu PRIMERGY RX2540 서버</block>
  <block id="539c5af1c2682685cd076697aaa6c700" category="cell">각각 * 48 CPU * 인텔 제온 * 256GB 물리적 메모리 * 10GbE 듀얼 포트가 장착되어 있습니다</block>
  <block id="0cc5c79089d6ca0752529568758efc4c" category="cell">10GbE</block>
  <block id="76e3e2a4e56301dafc50613d96fd624e" category="section-title">구축 단계 - NAS</block>
  <block id="2879e817640f94636340918850eb6903" category="inline-link">NetApp XCP 사용자 가이드</block>
  <block id="f2dd54ec57ec5464ee3aa191a48a8a43" category="paragraph">데이터 전송에 NetApp XCP를 배포하려면 먼저 대상 위치에 XCP 소프트웨어를 설치하고 활성화합니다. 에서 세부 정보를 검토할 수 있습니다<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>. 이렇게 하려면 다음 단계를 완료하십시오.</block>
  <block id="62e9f0426675b856daf874c75830c213" category="inline-link-macro">"XCP의 필수 구성 요소"</block>
  <block id="4f6583b152ef684b4492414bcdcdf877" category="list-text">섹션에 설명된 대로 필수 구성 요소를 충족합니다 <block ref="958d961a425946e5195ca036cea97fab" category="inline-link-macro-rx"></block></block>
  <block id="c58c8903e33903d2e630277aa3a78795" category="inline-link">NetApp XCP(다운로드) 페이지</block>
  <block id="2d1acef34bb45f2c1878c6b576f3b400" category="list-text">에서 XCP 소프트웨어를 다운로드합니다<block ref="13844fc5dba1627d28169d2acfff11e2" category="inline-link-rx"></block>.</block>
  <block id="8319752fe43598ddb329e536217c1cb5" category="list-text">다운로드한 xCP tar 파일을 xCP 서버에 복사합니다.</block>
  <block id="c9b8e059d1597eaead43d286e91c91e3" category="list-text">tar 파일의 압축을 풉니다.</block>
  <block id="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link"><block ref="9f2a2420f596ae9cccb1b900cd8ee187" category="inline-link-rx"></block></block>
  <block id="19f1deecf23a78878eb01c772b9233e0" category="list-text">에서 라이센스를 다운로드합니다<block ref="4da39fde529d1b69f60873c302229eed" category="inline-link-rx"></block> xCP 서버에 복사합니다.</block>
  <block id="3df11515e644382207c1430c36ea48bb" category="list-text">라이센스를 활성화합니다.</block>
  <block id="ad7984249c2054b4da5fd3b57b1b91ef" category="list-text">소스 NFS 포트와 대상 NFS 서버를 찾습니다. 기본 포트는 2049입니다.</block>
  <block id="79fe861b8c719b1a534bdbcace1444a2" category="list-text">NFS 연결을 확인합니다. NFS 서버 포트에 대한 텔넷을 사용하여 NFS 서버(소스 및 대상 모두)를 확인합니다.</block>
  <block id="5e471de79dbe02105770bcf04bc501d5" category="list-text">카탈로그를 구성합니다.</block>
  <block id="67005679d502da10622f2104421e894b" category="list-text">NFS 볼륨을 생성하고 XCP 카탈로그용 NFS를 내보냅니다. xCP 카탈로그에 운영 체제 NFS 내보내기를 활용할 수도 있습니다.</block>
  <block id="d6f2a18783592d1858e3e5bdcabd4567" category="list-text">NFS 내보내기를 확인합니다.</block>
  <block id="39b638480b201a7448774e8186012e4e" category="list-text">업데이트: xcp.ini`.</block>
  <block id="9d44d1309af47903754b16c403f68774" category="list-text">xCP 쇼를 사용하여 소스 NAS 내보내기를 찾습니다. 공략 대상:</block>
  <block id="fbff9a42f0ba33571594cb39da93ef4b" category="list-text">(선택 사항) 소스 NAS 데이터를 스캔합니다.</block>
  <block id="82d1938e7390e37babdea8d6fd359156" category="paragraph">소스 NAS 데이터를 스캔하면 데이터 레이아웃을 이해하고 마이그레이션 시 발생할 수 있는 문제를 찾을 수 있습니다. xCP 스캔 작업 시간은 파일 수와 디렉토리 깊이에 비례합니다. NAS 데이터에 익숙한 경우 이 단계를 건너뛸 수 있습니다.</block>
  <block id="c6e94e11da5ba5bce0f27b8c782e4110" category="list-text">xCP 스캔 보고서를 확인하십시오. 읽을 수 없는 폴더와 읽을 수 없는 파일을 주로 검색합니다.</block>
  <block id="6a6a10773cfc849f638ac0137a5f08d6" category="list-text">(선택 사항) inode를 변경합니다. inode 수를 보고 카탈로그 및 대상 볼륨 모두에 대해 마이그레이션하거나 복제할 파일 수에 따라 번호를 수정합니다(필요한 경우).</block>
  <block id="342779baf0b15fdf377f142c987e896a" category="list-text">대상 볼륨을 스캔합니다.</block>
  <block id="a88831977a2b62e982b722f6fa6662b5" category="list-text">소스 및 대상 볼륨 공간을 확인합니다.</block>
  <block id="4b14d92fd07932987cf7416eb7f604ca" category="list-text">xCP COPY를 사용하여 소스에서 대상으로 데이터를 복사하고 요약을 확인합니다.</block>
  <block id="506aae448569ed08125f41ed940eb00b" category="admonition">기본적으로 XCP는 데이터를 복사할 수 있는 7개의 병렬 프로세스를 생성합니다. 이 기능은 조정할 수 있습니다.</block>
  <block id="5c46a2da3e6e0423829946fe877c50b8" category="admonition">소스 볼륨은 읽기 전용을 사용하는 것이 좋습니다. 실시간으로 소스 볼륨은 활성 상태의 라이브 파일 시스템입니다. NetApp XCP는 애플리케이션에 의해 지속적으로 변경되는 라이브 소스를 지원하지 않으므로 'XCP 복사' 작업이 실패할 수 있습니다.</block>
  <block id="0f7dbc07af0b5c3ba51ff604b81ebe8a" category="paragraph">Linux의 경우 xCP Linux가 카탈로그 작성을 수행하기 때문에 xCP에 인덱스 ID가 필요합니다.</block>
  <block id="764363dd147880ab6aca242a0417562e" category="list-text">(선택 사항) 타겟 NetApp 볼륨의 inode를 확인합니다.</block>
  <block id="ab3ba5fb62db279b7d07bac650a6c2d2" category="list-text">xCP 동기화를 사용하여 증가분 업데이트를 수행합니다.</block>
  <block id="6cdfbe571ba2209e0a76f3bcabfee9f6" category="paragraph">이 문서의 경우 실시간으로 시뮬레이션하기 위해 소스 데이터에 있는 100만 개의 파일 이름이 바뀐 다음 XCP 동기화를 사용하여 업데이트된 파일을 대상으로 복사했습니다. Windows의 경우 xCP는 소스 경로와 대상 경로를 모두 필요로 합니다.</block>
  <block id="13475b4ca9a916769b9d63f4fddfa18d" category="list-text">데이터 전송을 확인합니다. 'xCP verify'를 사용하면 소스와 대상의 데이터가 동일한지 확인할 수 있습니다.</block>
  <block id="1cd06f171a5a99926a67bd673014f765" category="paragraph">xCP 문서는 'CAN', '카피', '동기화', 'fy' 작업에 대한 여러 가지 옵션(예)을 제공합니다. 자세한 내용은 를 참조하십시오<block ref="ae77d8ba86ab9e3027c314c6b4922595" category="inline-link-rx"></block>.</block>
  <block id="efa146517859e051c07fabac4c88d3e7" category="admonition">Windows 고객은 ACL(액세스 제어 목록)을 사용하여 데이터를 복사해야 합니다. NetApp은 'xCP copy -acl -frodbackuser\&lt;사용자 이름&gt; -frodbackgroup\&lt;사용자 이름 또는 groupname&gt;&lt;source&gt;&lt;destination&gt;' 명령을 사용할 것을 권장합니다. 성능을 극대화하려면 ACL이 있는 SMB 데이터와 NFS와 SMB가 모두 액세스할 수 있는 데이터를 가진 소스 볼륨을 고려할 때 타겟은 NTFS 볼륨이어야 합니다. xCP(NFS 버전)를 사용하여 Linux 서버에서 데이터를 복사하고 Windows 서버에서 '-ACL' 및 '-NoData' 옵션을 사용하여 xCP(SMB 버전) 동기화를 실행하여 소스 데이터에서 타겟 SMB 데이터로 ACL을 복사합니다.</block>
  <block id="85760de676a9f74f28f26115c39c9a0b" category="inline-link">'감사 및 보안 로그 관리' 정책 구성</block>
  <block id="a0251b301ad566d86ffa3916c5510295" category="paragraph">자세한 단계는 을 참조하십시오<block ref="06fdba77988da3047baf401e4fdefca5" category="inline-link-rx"></block>.</block>
  <block id="0957326f089aaf98a5b7b9110a2675cd" category="section-title">구축 단계 - HDFS/MapRFS 데이터 마이그레이션</block>
  <block id="1f43fc63f63aad0b707e06b0753182a1" category="paragraph">이 섹션에서는 HDFS/MapRFS에서 NFS로, 그 반대로 데이터를 마이그레이션하는 Hadoop Filesystem Data Transfer to NAS라는 새로운 XCP 기능에 대해 설명합니다.</block>
  <block id="368666825ffae5710ab122fb63937cee" category="paragraph">MapRFS/HDFS 기능의 경우 루트가 아닌 사용자 환경에서 다음 절차를 수행해야 합니다. 일반적으로 비루트 사용자는 HDFS, MapR 또는 HDFS 및 MapRFS 파일 시스템을 변경할 수 있는 권한이 있는 사용자입니다.</block>
  <block id="9adbc05b1436b3e8962253577f1e6441" category="list-text">CLI에서 CLASSPATH, HADOOP_HOME, NHDFS_LIBJVM_PATH, LB_LIBRARY_PATH 및 NHDFS_LIBHDFS_PATH 변수를 설정하거나, 'xCP' 명령과 함께 사용자의 .bashrc 파일을 설정합니다.</block>
  <block id="2a0eda7a7937e303f9e18a57a033fcb8" category="list-text">NHDFS_LIBHDFS_path는 libhdfs.so 파일을 가리킵니다. 이 파일은 HDFS API를 제공하여 Hadoop 배포의 일부로 HDFS/MapRFS 파일 및 파일 시스템을 상호 작용하고 조작합니다.</block>
  <block id="13682a0461e750a2dfb4e86c2ddc1165" category="list-text">NHDFS_LIBJVM_PATH는 libjvm.so 파일을 가리킵니다. JRE 위치에 있는 공유 Java 가상 머신 라이브러리입니다.</block>
  <block id="60ce276a5dde3f2d2e92b1986a2eb339" category="list-text">CLASSPATH는 (Hadoop classpath –glob) 값을 사용하는 모든 jar 파일을 가리킵니다.</block>
  <block id="84cbf778b2572cae5eba01d0ca330078" category="list-text">ld_library_path는 Hadoop 기본 라이브러리 폴더 위치를 가리킵니다.</block>
  <block id="68207eb9f168add2309e88b5223d57c6" category="paragraph">Cloudera 클러스터에 기반한 다음 샘플을 참조하십시오.</block>
  <block id="91328810a5559a740f522f4c5a1da5f1" category="paragraph">이번 릴리즈에서는 HDFS에서 NFS로 운영 및 데이터 마이그레이션을 수행하는 XCP 스캔, 복사 및 검증을 지원합니다. 데이터 레이크 클러스터 단일 작업자 노드 및 여러 작업자 노드에서 데이터를 전송할 수 있습니다. 1.8 릴리즈에서는 루트 및 비루트 사용자가 데이터 마이그레이션을 수행할 수 있습니다.</block>
  <block id="dee4c2c7e685015e9f3cc1ad197f3ab5" category="section-title">구축 단계 - 루트 이외의 사용자가 HDFS/MaprFS 데이터를 NetApp NFS로 마이그레이션합니다</block>
  <block id="5983f77acc016b8138698b32b0ab0405" category="list-text">배포 단계의 1-9 단계에서 설명한 것과 동일한 단계를 따릅니다.</block>
  <block id="c2765e27844a39bfc897cb964eec8711" category="list-text">다음 예에서는 사용자가 데이터를 HDFS에서 NFS로 마이그레이션합니다.</block>
  <block id="e6f549e8013d1f24b8756cd11ff3083e" category="list-text">HDFS에서 폴더 및 파일('Hadoop fs-copyFromLocal' 사용)을 생성합니다.</block>
  <block id="2433ce85404dd68893a2e4abb99843e4" category="list-text">HDFS 폴더에서 권한을 확인합니다.</block>
  <block id="befab6065ddb441f0b260ac75a8e84c8" category="list-text">NFS에서 폴더를 생성하고 권한을 확인합니다.</block>
  <block id="02341ea695e862c3a2d89461b1b8bf37" category="list-text">xCP를 사용하여 HDFS에서 NFS로 파일을 복사하고 권한을 확인합니다.</block>
  <block id="d2bac014bbd39f6954893239102c5678" category="inline-link-macro">다음: 사이징 지침</block>
  <block id="b49cd7fb5a227da1698c527804f31bbb" category="paragraph"><block ref="b49cd7fb5a227da1698c527804f31bbb" category="inline-link-macro-rx"></block></block>
  <block id="dc0b758a04bbb9e380300887d831e4e1" category="summary">이 섹션에서는 XCP 작업의 성능을 향상시키는 데 도움이 되는 튜닝 매개 변수 몇 가지를 제공합니다.</block>
  <block id="9db3ca538820d0cfb7b44ef80f16ca98" category="doc">성능 튜닝</block>
  <block id="7931b9aae255139b42cb605b3b62a6db" category="inline-link-macro">이전: 사이징 지침</block>
  <block id="0ff4824165c6661bc016402e35d2a9fe" category="paragraph"><block ref="0ff4824165c6661bc016402e35d2a9fe" category="inline-link-macro-rx"></block></block>
  <block id="ec6136417c258c9b7f95c39765c5ca51" category="paragraph">이 섹션에서는 XCP 작업의 성능을 향상시키는 데 도움이 되는 튜닝 매개 변수 몇 가지를 제공합니다.</block>
  <block id="dd10b781bf6dd686a8631401ce0fba96" category="list-text">더 나은 확장을 위해 여러 xCP 인스턴스에 워크로드를 분산하려면 마이그레이션 및 데이터 전송을 위해 각 xCP 인스턴스에 대한 하위 폴더를 분할합니다.</block>
  <block id="37e9b10f81fe31cb6b80609f724b34f8" category="list-text">xCP는 최대 CPU 리소스를 사용할 수 있습니다. CPU 코어가 많을수록 성능이 향상됩니다. 따라서 xCP 서버에 더 많은 CPU가 있어야 합니다. 실습은 128GB RAM 및 48배 코어 CPU를 테스트했으며, 이는 8개의 CPU와 8GB RAM보다 뛰어난 성능을 제공했습니다.</block>
  <block id="a02c6dbd226d5506c1b4b07f6d383615" category="list-text">'-parallel' 옵션이 포함된 xCP 복제본은 CPU 수에 따라 달라집니다. 대부분의 XCP 데이터 전송 및 마이그레이션 작업에는 기본 병렬 스레드 수(7개)가 충분할 수 있습니다. xCP Windows의 경우 기본적으로 병렬 프로세스의 수는 CPU 수와 같습니다. '-parallel' 옵션의 최대 개수는 코어 수보다 작거나 같아야 합니다.</block>
  <block id="740950b0e27cdd5def3c4295d5840851" category="list-text">10GbE는 데이터 전송을 시작하는 데 적합합니다. 그러나 25GbE 및 100GbE로 테스트하여 데이터 전송 성능이 향상되었고 대용량 파일 크기 데이터 전송에 권장됩니다.</block>
  <block id="a174d00dcd4849e0653429de84c71cde" category="list-text">Azure NetApp Files의 경우 성능은 서비스 수준에 따라 다릅니다. 자세한 내용은 Azure NetApp Files 서비스 수준 및 성능 세부 정보를 보여 주는 다음 표를 참조하십시오.</block>
  <block id="6d59be48f566a73e053e12167b279be5" category="cell">서비스 레벨</block>
  <block id="eb6d8ae6f20283755b339c0dc273988b" category="cell">표준</block>
  <block id="8d5e7e72f12067991186cdf3cb7d5d9d" category="cell">프리미엄</block>
  <block id="7057376a419b3334cc7b8b7a9f064abb" category="cell">초대형</block>
  <block id="0b85467ebafa7ca3c47e82dc38184484" category="cell">처리량</block>
  <block id="adcda45ec4de9aeb48e1893272b078d1" category="cell">16MBps/테라바이트(TB)</block>
  <block id="93209d2e9d1ed8d87a279cef886b5021" category="cell">64MBps/TB</block>
  <block id="f646efbbd60d091e92b32611965c4f1c" category="cell">128MBps/TB</block>
  <block id="4a9cc851fc41c5762618832386fa4937" category="cell">워크로드 유형</block>
  <block id="11969136028e1ffaeed70de5e59bde33" category="cell">범용 파일 공유, 이메일, 웹</block>
  <block id="76ab8c335a6bb24396ea1953bac75705" category="cell">BMS, 데이터베이스 및 애플리케이션</block>
  <block id="9dab8e594b90062c0612cbb1676234ba" category="cell">지연 시간에 민감한 애플리케이션</block>
  <block id="0a568304277380e4cfb0f2d2abbd99b4" category="cell">성능 설명</block>
  <block id="c55268b956eecd1d58f60723a410c808" category="cell">표준 성능: TB당 1,000 IOPS(16K I/O) 및 16MBps/TB</block>
  <block id="536d2154a9035458ae8efd38b24f3ea7" category="cell">프리미엄 성능 – TB당 4,000 IOPS(16k I/O) 및 TB당 64MBps</block>
  <block id="91ff77656b0dc231fcbe8f488a15a253" category="cell">탁월한 성능: TB당 8,000 IOPS(16k I/O) 및 128MBps/TB</block>
  <block id="121bc30e927e8a3d918fc90c0ec18fee" category="paragraph">처리량 및 워크로드 유형에 따라 적합한 서비스 수준을 선택해야 합니다. 대부분의 고객은 프리미엄 레벨에서 시작하고 워크로드에 따라 서비스 수준을 변경합니다.</block>
  <block id="f44706d8f59ec82b48b083fb246a4fc7" category="inline-link-macro">다음은 고객 시나리오입니다.</block>
  <block id="bb0eaaf9fa62e9175efd3145f00946ea" category="paragraph"><block ref="bb0eaaf9fa62e9175efd3145f00946ea" category="inline-link-macro-rx"></block></block>
  <block id="b25f76deff236f93a3afa73c8a5b2a2c" category="summary">이 사용 사례는 수백만 개의 소규모 사내 파일을 클라우드로 마이그레이션하는 가장 큰 NetApp 관광 산업 고객을 기반으로 합니다.</block>
  <block id="4b1739353c6d18cea69ed6a274b7135f" category="doc">xCP Data Mover를 사용하여 수백만 개의 작은 파일을 유연한 스토리지로 마이그레이션합니다</block>
  <block id="2b2142a0bf2476846ad59f7952380ca1" category="inline-link-macro">이전: ONTAP NFS에 대한 고성능 컴퓨팅.</block>
  <block id="c81efa558deea51a126490ba8d09b59a" category="paragraph"><block ref="c81efa558deea51a126490ba8d09b59a" category="inline-link-macro-rx"></block></block>
  <block id="bb29cc4e9e4447f7bad1e81c1c5a9a1f" category="paragraph">이 사용 사례는 사내-클라우드 데이터 마이그레이션을 위한 가장 큰 NetApp 관광 산업 고객을 기반으로 합니다. COVID-19는 여행 업계의 수요를 감소시켰습니다. 따라서 고객은 온프레미스 환경의 하이엔드 스토리지에서 수요 가격 책정 애플리케이션에 대한 자본 비용을 절감하려고 합니다. 이 고객은 수백만 개의 작은 파일을 클라우드로 마이그레이션하는 엄격한 SLA를 보유하고 있습니다.</block>
  <block id="81ec900a5387f7a686d1451adaddf399" category="paragraph">다음 그림은 Azure NetApp Files 소용량 파일을 위한 사내의 데이터 마이그레이션을 보여 줍니다.</block>
  <block id="214c5e9894032cde0e65b576e32294b9" category="paragraph"><block ref="214c5e9894032cde0e65b576e32294b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="099a60093e7de3795f557974125ce82b" category="inline-link">NetApp XCP Data Mover 솔루션: 사내에서 클라우드로</block>
  <block id="50d4edabefc40ad9614b567197696a2e" category="paragraph">자세한 내용은 를 참조하십시오<block ref="2c0eb3741003532ef113837d4b882a9a" category="inline-link-rx"></block> 블로그:</block>
  <block id="3242fe890cd89c89373a1bd576cef03a" category="inline-link-macro">다음으로 xCP Data Mover를 사용하여 대용량 파일을 마이그레이션합니다.</block>
  <block id="c32441c7755c153b58450a597193448b" category="paragraph"><block ref="c32441c7755c153b58450a597193448b" category="inline-link-macro-rx"></block></block>
  <block id="5dc302565fd7f552e134618ee18d2be2" category="summary">이 솔루션은 특정 날짜를 기준으로 데이터를 복사해야 하는 고객을 기반으로 합니다.</block>
  <block id="07f04efd2f421076b9aa06c4fee83be5" category="doc">특정 날짜 기반 스캔 및 데이터 복사</block>
  <block id="7af90e46070dd59c121e31e1525d4af2" category="inline-link-macro">이전: 파일을 복제합니다.</block>
  <block id="7f58802ce1d6245244bb449cd961f0f3" category="paragraph"><block ref="7f58802ce1d6245244bb449cd961f0f3" category="inline-link-macro-rx"></block></block>
  <block id="e0b5216bc931e3e5fd7efb74ad10b1d3" category="paragraph">이 솔루션은 특정 날짜를 기준으로 데이터를 복사해야 하는 고객을 기반으로 합니다. 다음 세부 정보를 확인합니다.</block>
  <block id="c277b447e2e86b92f26c7dbcf8fecdf2" category="inline-link-macro">다음: SMB/CIFS 공유에서 CSV 파일 생성</block>
  <block id="7a9653d25343b8ddab24257e57b5be7a" category="paragraph"><block ref="7a9653d25343b8ddab24257e57b5be7a" category="inline-link-macro-rx"></block></block>
  <block id="89bddd14a9f02aeace6d5ffadf25e4f3" category="summary">이 문서에서는 NetApp XCP 모범 사례 지침과 테스트 시나리오 기반 솔루션을 제공합니다. 이 모범 사례는 사내 마이그레이션 워크플로와 클라우드, 파일 시스템 분석, 문제 해결, XCP의 성능 튜닝 등에 대해 다룹니다.</block>
  <block id="e7b1326bcbbf0b5513213b2373b5721a" category="doc">TR-4863: NetApp XCP에 대한 모범 사례 지침 - Data Mover, 파일 마이그레이션 및 분석</block>
  <block id="439be0f3df9ab229e224aa3c8dbeca77" category="paragraph">NetApp의 Karthikeyan Nagalingam입니다</block>
  <block id="88d20f11fbf1788b5271fcc5d5297a41" category="paragraph">이 문서에서는 NetApp XCP 모범 사례 지침과 테스트 시나리오 기반 솔루션을 제공합니다. 이 모범 사례는 사내 마이그레이션 워크플로와 클라우드, 파일 시스템 분석, 문제 해결, XCP 성능 튜닝 등에 대해 다룹니다. 테스트 시나리오 섹션에서는 고객 사용 사례와 요구 사항, XCP를 사용하는 NetApp 솔루션 및 고객에게 제공되는 혜택에 대해 설명합니다.</block>
  <block id="842b5068483a5cd5b058644a5d000f1c" category="inline-link-macro">다음으로 NetApp XCP를 살펴보겠습니다.</block>
  <block id="10dbc4bbbec11552354dca73bcd59c78" category="paragraph"><block ref="10dbc4bbbec11552354dca73bcd59c78" category="inline-link-macro-rx"></block></block>
  <block id="322bc614a8031f8c334d233f8221a4ab" category="summary">이 섹션에서는 7-Mode에서 작동하는 NetApp Data ONTAP에서 ONTAP로 데이터를 마이그레이션하기 위한 자세한 단계를 제공합니다.</block>
  <block id="30ee25b2188724428e827e97bab504fe" category="doc">7-Mode에서 ONTAP로 데이터 마이그레이션</block>
  <block id="aecfc9b89f609bfde217a6cf8fc0b00a" category="inline-link-macro">이전: SMB/CIFS 공유에서 CSV 파일 생성</block>
  <block id="6da13b2cdb445320dc3e29759119f4e8" category="paragraph"><block ref="6da13b2cdb445320dc3e29759119f4e8" category="inline-link-macro-rx"></block></block>
  <block id="3ec8186e1900b95154cccf8ccea38023" category="section-title">7-Mode NFSv3 스토리지를 NFS 데이터용 ONTAP으로 전환하는 중입니다</block>
  <block id="e70a6b3d23d1e0da94c71a9ea26747d1" category="paragraph">이 섹션에서는 소스 7-Mode NFSv3 내보내기를 ONTAP 시스템으로 전환하기 위한 다음 표의 단계별 절차를 제공합니다.</block>
  <block id="cad365d13740342c8f6199feb7229137" category="paragraph">NetApp은 소스 7-Mode NFSv3 볼륨을 내보내고 클라이언트 시스템에 마운트했으며 XCP가 Linux 시스템에 이미 설치되어 있다고 가정합니다.</block>
  <block id="b40dbfa52a308abff927380b983cd868" category="list-text">대상 ONTAP 시스템이 정상인지 확인합니다.</block>
  <block id="39745ae9472f91abcd9e844389157858" category="list-text">대상 시스템에 하나 이상의 비루트 Aggregate가 있는지 확인합니다. Aggregate는 정상 상태입니다.</block>
  <block id="47e01226b4fdf549d938eb5c6196970d" category="paragraph">데이터 집계가 없는 경우 'storage aggr create' 명령을 사용하여 새 데이터 애그리게이트를 생성합니다.</block>
  <block id="5c52d0e31e44663ee633be681387faa1" category="list-text">타겟 클러스터 시스템에 SVM(스토리지 가상 머신)을 생성합니다.</block>
  <block id="426b5839edbb7a7772be396e7eaceace" category="list-text">타겟 SVM에서 FCP, iSCSI, NDMP 및 CID 프로토콜을 제거합니다.</block>
  <block id="d03930721e424cdac105ccd0172f7dbe" category="paragraph">이 SVM에서 NFS가 허용되는 프로토콜인지 확인합니다.</block>
  <block id="4d6b5eb9160c3c34e9ff5535c403cea9" category="list-text">대상 SVM에서 새 읽기-쓰기 데이터 볼륨을 생성합니다. 보안 스타일, 언어 설정 및 용량 요구 사항이 소스 볼륨과 일치하는지 확인합니다.</block>
  <block id="a2cebf1e91b2a266a58458873c8980fd" category="list-text">데이터 LIF를 생성하여 NFS 클라이언트 요청을 처리합니다.</block>
  <block id="6817d90b89495074e679248b56128378" category="paragraph">LIF가 성공적으로 생성되었는지 확인합니다.</block>
  <block id="3a014fae7f5d70cc01c593a8401140ee" category="list-text">필요한 경우 SVM으로 정적 경로를 생성합니다.</block>
  <block id="84bb87c2987a4b39ea23430f38570808" category="paragraph">라우트가 성공적으로 생성되었는지 확인합니다.</block>
  <block id="54b19b8b3b6de7bce018de598a1645ea" category="list-text">SVM 네임스페이스에서 타겟 NFS 데이터 볼륨을 마운트합니다.</block>
  <block id="6365adb4324221d944bc90c4663dfe5a" category="paragraph">볼륨이 성공적으로 마운트되었는지 확인합니다.</block>
  <block id="991398c32a43bcf95d7fa14129a6fcb0" category="paragraph">"volume create" 명령을 사용하여 볼륨 마운트 옵션(접합 경로)을 지정할 수도 있습니다.</block>
  <block id="6c02d24a81dd4d9b1ad7a15079b4f122" category="list-text">타겟 SVM에서 NFS 서비스를 시작합니다.</block>
  <block id="e210fe657c5d46e3e11ca263d1a18af7" category="paragraph">서비스가 시작되고 실행 중인지 확인합니다.</block>
  <block id="304683b37151feda067e3acfde300057" category="list-text">기본 NFS 엑스포트 정책이 타겟 SVM에 적용되었는지 확인</block>
  <block id="353fde8a37910716dc00dec81475c0d5" category="list-text">필요한 경우 타겟 SVM을 위한 맞춤형 엑스포트 정책을 새로 생성합니다.</block>
  <block id="174608facfdad6448222d6d46c87fba5" category="paragraph">새 사용자 지정 엑스포트 정책이 성공적으로 생성되었는지 확인합니다.</block>
  <block id="4007cf260b496d35ba0e925f1e7a183d" category="list-text">NFS 클라이언트에 대한 액세스를 허용하도록 엑스포트 정책 규칙을 수정합니다.</block>
  <block id="5f249df749512e129505d18fd47d7010" category="list-text">클라이언트가 볼륨에 액세스할 수 있는지 확인합니다.</block>
  <block id="94a80f56f92334f07fd30337692ca889" category="list-text">Linux NFS 서버에 연결합니다. NFS에서 내보낸 볼륨의 마운트 지점을 생성합니다.</block>
  <block id="725ae014e8d8f66f0f2d477fa656ba32" category="list-text">이 마운트 지점에서 타겟 NFSv3 내보낸 볼륨을 마운트합니다.</block>
  <block id="a345b19bdd483ecd745a2e643b756bc6" category="admonition">NFSv3 볼륨은 내보내야 하지만 반드시 NFS 서버에 의해 마운트되는 것은 아닙니다. 마운트될 수 있는 경우 xCP Linux 호스트 클라이언트는 이러한 볼륨을 마운트합니다.</block>
  <block id="b5b2af7fb88c03cfd258cdd77fc6fbe1" category="paragraph">마운트 지점이 성공적으로 생성되었는지 확인합니다.</block>
  <block id="8d3ac4d5ea9c5d5c45d7322512d7b778" category="list-text">NFS에서 내보낸 마운트 지점에 테스트 파일을 생성하여 읽기-쓰기 액세스를 설정합니다.</block>
  <block id="07e483b5917b8a9e91a22b2ebc20961a" category="admonition">읽기-쓰기 테스트가 완료된 후 타겟 NFS 마운트 지점에서 파일을 삭제합니다.</block>
  <block id="09280cd628b820e696b87163b3fe0fde" category="list-text">xCP가 설치된 Linux 클라이언트 시스템에 연결합니다. xCP 설치 경로로 이동합니다.</block>
  <block id="86de6eeea329a50737c7056637f43e49" category="list-text">xCP Linux 클라이언트 호스트 시스템에서 'xCP show' 명령을 실행하여 소스 7-Mode NFSv3 내보내기를 쿼리합니다.</block>
  <block id="080173849f5fec049b214897a2882295" category="list-text">소스 NFSv3 내보낸 경로를 검색하고 해당 파일 구조의 통계를 인쇄합니다.</block>
  <block id="df86b239e412ba3ba7192b581381b444" category="paragraph">xCP의 캔, 복사, 동기화 작업 중에는 소스 NFSv3 내보내기를 읽기 전용 모드로 설정하는 것이 좋습니다.</block>
  <block id="695efe20ffcfc7c261e44cbb1b62cc78" category="list-text">타겟 ONTAP 시스템에서 NFSv3 내보내기에 소스 7-Mode NFSv3 내보내기를 복사합니다.</block>
  <block id="50515e001679292835a498c6bd3f3c31" category="list-text">복제가 완료된 후 소스 및 타겟 NFSv3 내보내기에 동일한 데이터가 있는지 확인합니다. xCP Verify 명령을 실행합니다.</block>
  <block id="70d6a53ca7c3c592cb4099e2988c226c" category="paragraph">xCP verify가 소스와 대상 데이터의 차이를 발견하면 요약에 해당 파일이나 디렉토리가 없습니다 라는 오류가 보고됩니다. 이 문제를 해결하려면 'xCP sync' 명령을 실행하여 소스 변경 내용을 대상에 복사합니다.</block>
  <block id="505d73172f49d62bd99779ab53aa5eeb" category="list-text">그전과 그 동안 다시 한번 도전하라. 소스에 새 데이터나 업데이트된 데이터가 있는 경우 증분 업데이트를 수행합니다. xCP sync 명령을 실행합니다.</block>
  <block id="887abb0b5917a0a6b0c47f5ef3eca1ce" category="list-text">이전에 중단된 복사 작업을 다시 시작하려면 xCP resume 명령을 실행합니다.</block>
  <block id="f807709818ec3fbc508863a00ea17044" category="paragraph">'SUME'가 파일 복사를 완료한 후 소스와 대상 스토리지에 동일한 데이터가 있도록 'riry'를 다시 실행하십시오.</block>
  <block id="d78900410b9203071958256c3d6a7701" category="list-text">NFSv3 클라이언트 호스트는 7-Mode 스토리지에서 프로비저닝된 소스 NFSv3 내보내기를 마운트 해제하고 ONTAP에서 타겟 NFSv3 엑스포트를 마운트해야 합니다. 컷오버에 중단이 필요합니다.</block>
  <block id="6bd42ffcfd349b793e9f6c6f00c18cd8" category="section-title">7-Mode 볼륨 Snapshot 복사본을 ONTAP로 전환 중</block>
  <block id="fefac3d628a2abc2d1677e073a0688e7" category="paragraph">이 섹션에서는 소스 7-Mode 볼륨의 NetApp Snapshot 복사본을 ONTAP로 전환하기 위한 절차를 다룹니다.</block>
  <block id="721e28a3edb434ca3d7f37307126504c" category="admonition">NetApp은 소스 7-Mode 볼륨을 내보내서 클라이언트 시스템에 마운트하고 Linux 시스템에 XCP가 이미 설치되어 있다고 가정합니다. 스냅샷 복사본은 마지막 스냅샷 복사본 이후의 증분 변경 사항을 기록하는 볼륨의 시점 이미지입니다. 7-Mode 시스템에서 소스로 '-snap' 옵션을 사용합니다.</block>
  <block id="e18566c8fe02de3e35e48df30daa5189" category="paragraph">* 경고: * 기본 스냅샷 복사본을 유지합니다. 기본 복사본이 완료된 후에는 기본 스냅샷 복사본을 삭제하지 마십시오. 추가 동기화 작업을 위해서는 기본 스냅샷 복사본이 필요합니다.</block>
  <block id="50bdf0eaa7b3716343ae0345a98e1a5f" category="list-text">타겟 클러스터 시스템에 SVM을 생성합니다.</block>
  <block id="2e4b636c74015de6d92a2eb874c15a88" category="list-text">타겟 SVM에서 FCP, iSCSI, NDMP 및 CIFS 프로토콜을 제거합니다.</block>
  <block id="c45e0bc468a9249c2954fa84c21f833e" category="list-text">필요한 경우 SVM으로 정적 경로를 생성합니다.</block>
  <block id="f35ea333881cef53fcd944d5a052be9d" category="paragraph">볼륨이 성공적으로 마운트되었는지 확인합니다.</block>
  <block id="71c0d546c4569fd9a5798bdbc9729ab6" category="paragraph">"volume create" 명령을 사용하여 볼륨 마운트 옵션(접합 경로)을 지정할 수도 있습니다.</block>
  <block id="7ec3f8d8dd165416936305e1ca1530f0" category="list-text">기본 NFS 엑스포트 정책이 타겟 SVM에 적용되는지 확인합니다.</block>
  <block id="f69801ea46df8aed1b26399a9330f459" category="list-text">대상 시스템의 NFS 클라이언트에 대한 액세스를 허용하도록 엑스포트 정책 규칙을 수정합니다.</block>
  <block id="9fee35c8bded36b1931a6addb7635a81" category="list-text">클라이언트가 타겟 볼륨에 액세스할 수 있는지 확인합니다.</block>
  <block id="7633c6765c7399ce0f1ecbca891fb11c" category="paragraph">xCP 스캔, 복사, 동기화 작업 중에 소스 NFSv3 내보내기를 읽기 전용 모드로 설정하는 것이 좋습니다. '동기화' 동작에서는 '-snap' 옵션을 해당 값으로 전달해야 합니다.</block>
  <block id="486e9eb5a73ed3d87e070761d3ceeefe" category="list-text">소스 7-Mode NFSv3 스냅샷(기본)을 타겟 ONTAP 시스템의 NFSv3 내보내기에 복사합니다.</block>
  <block id="160bb3a75d27ad175143123df09bce76" category="admonition">추가 동기화 작업을 위해 이 기본 스냅샷을 유지합니다.</block>
  <block id="97ba1a5f7ee8f9243390e46469b6e8f3" category="list-text">복제가 완료된 후 소스 및 타겟 NFSv3 내보내기에 동일한 데이터가 있는지 확인합니다. xCP Verify 명령을 실행합니다.</block>
  <block id="44842ca325a3ba46b3b4703a79fab171" category="paragraph">만약 원본과 대상 데이터의 차이를 발견한다면, 요약에는 '해당 파일 또는 디렉토리 없음' 오류가 보고된다. 이 문제를 해결하려면 'xCP sync' 명령을 실행하여 소스 변경 내용을 대상에 복사합니다.</block>
  <block id="030bc6fe403e876e1c932987ece73d61" category="list-text">그전과 그 동안 다시 한번 도전하라. 소스에 새 데이터나 업데이트된 데이터가 있는 경우 증분 업데이트를 수행합니다. 변동분이 있는 경우 이러한 변경 사항에 대한 새 스냅샷 복사본을 생성하고 동기화 작업을 위한 '-snap' 옵션을 사용하여 해당 스냅샷 경로를 전달합니다.</block>
  <block id="b29cfae254be5e3cfc339ed594ea9378" category="paragraph">'-snap' 옵션과 스냅샷 경로를 사용하여 xCP sync 명령을 실행합니다.</block>
  <block id="2885d0e1370007423656773743ce189b" category="admonition">이 작업을 수행하려면 기본 스냅샷이 필요합니다.</block>
  <block id="121dba07a28112a093b812991271c895" category="list-text">NFSv3 클라이언트 호스트는 7-Mode 스토리지에서 프로비저닝된 소스 NFSv3 내보내기를 마운트 해제하고 ONTAP에서 타겟 NFSv3 내보내기를 마운트해야 합니다. 이 컷오버에는 중단이 필요합니다.</block>
  <block id="6db55966f4a2b44c31ed7672f14d023e" category="section-title">NetApp 7-Mode에서 NetApp 스토리지 시스템으로 ACLv4 마이그레이션</block>
  <block id="8f81754856c547fbd3e5295b9da06cc7" category="paragraph">이 섹션에서는 소스 NFSv4 내보내기를 ONTAP 시스템으로 전환하기 위한 단계별 절차를 설명합니다.</block>
  <block id="fd58e84bd534e0ff49a00942e9ee2002" category="admonition">NetApp은 소스 NFSv4 볼륨을 내보내고 클라이언트 시스템에 마운트하며 Linux 시스템에 XCP가 이미 설치되어 있다고 가정합니다. 소스는 ACL을 지원하는 NetApp 7-Mode 시스템이어야 합니다. ACL 마이그레이션은 NetApp에서 NetApp으로의 마이그레이션만 지원합니다. 이름에 특수 문자가 있는 파일을 복사하려면 소스 및 대상이 UTF-8 인코딩 언어를 지원하는지 확인하십시오.</block>
  <block id="88464fae780b488ca9d39f305a3b3777" category="section-title">소스 NFSv4 내보내기를 ONTAP로 마이그레이션하기 위한 사전 요구 사항</block>
  <block id="078b760bc7ad8cae447a095cc53029af" category="paragraph">소스 NFSv4 내보내기를 ONTAP로 마이그레이션하기 전에 다음과 같은 사전 요구 사항이 충족되어야 합니다.</block>
  <block id="abb629da0d811e197b383d473d19f265" category="list-text">대상 시스템에 NFSv4가 구성되어 있어야 합니다.</block>
  <block id="09e4d7a665b5df121af76a08951028cf" category="list-text">NFSv4 소스와 타겟을 XCP 호스트에 마운트해야 합니다. 소스 및 타겟 스토리지와 일치하는 NFS v4.0을 선택하고 소스 및 타겟 시스템에서 ACL이 설정되었는지 확인합니다.</block>
  <block id="c36e1764174e8e6a7791e7afd73f3294" category="list-text">xCP에서는 ACL 처리를 위해 xCP 호스트에 소스/타겟 경로를 마운트해야 합니다. 다음 예에서는 '/mnt/vol1' 경로에 vol1(10.63.5.56:/vol1)이 마운트되었습니다.</block>
  <block id="baa4716341f52ff4d0642ca1398e16f1" category="section-title">하위 디렉터리 옵션</block>
  <block id="66f63b7de79aaf05b47a1b63467b2a84" category="paragraph">하위 디렉터리와 함께 사용할 수 있는 두 가지 옵션은 다음과 같습니다.</block>
  <block id="5d1498ef6a2ee01cb9031bbf8a8dadc4" category="list-text">xCP가 하위 디렉토리 '(/vol1/dir1/DIR11')에서 작업하려면 전체 경로('10.63.5.56:/vol1/dir1/DIR11')를 xCP 호스트에 마운트합니다.</block>
  <block id="39b3225d42725e9616ca3fee7aa7cbb6" category="paragraph">전체 경로가 마운트되지 않은 경우 xCP에서 다음 오류를 보고합니다.</block>
  <block id="84274fa575b6d9b0177512a818215d91" category="list-text">아래 예와 같이 하위 디렉토리 구문('mount:subdirectory/qtree/.snapshot')을 사용합니다.</block>
  <block id="8dd9bb3f47ac0b27a42761c265b0c720" category="paragraph">NetApp 7-Mode에서 NetApp 스토리지 시스템으로 ACCv4를 마이그레이션하려면 다음 단계를 완료하십시오.</block>
  <block id="b2f12804e995a318c2272527efb05774" category="paragraph">SVM이 성공적으로 생성되었는지 확인합니다.</block>
  <block id="b887d08ec971525ffbfec7f19d01d72d" category="list-text">기본 NFS 엑스포트 정책이 타겟 SVM에 적용되었는지 확인</block>
  <block id="1c94e1638450716cd57f55bafd07e60f" category="paragraph">정책 규칙이 수정되었는지 확인합니다.</block>
  <block id="132fa7c123291d5007311a22ff8f5654" category="list-text">이 마운트 지점에서 타겟 NFSv4 내보낸 볼륨을 마운트합니다.</block>
  <block id="c686c09824f51c6e681d87d1deb44c71" category="admonition">NFSv4 볼륨을 내보내야 하지만 반드시 NFS 서버에 의해 마운트되는 것은 아닙니다. 마운트될 수 있는 경우 xCP Linux 호스트 클라이언트는 이러한 볼륨을 마운트합니다.</block>
  <block id="e943b6ad310412b689f42adec28acf3a" category="paragraph">파일이 생성되었는지 확인합니다.</block>
  <block id="35ce5d99ee6b9bb871da972e459e7259" category="list-text">xCP Linux 클라이언트 호스트 시스템에서 'xCP show' 명령을 실행하여 소스 NFSv4 내보내기를 쿼리합니다.</block>
  <block id="97cc35dcdaf8c5c5fa0e936cd31e9907" category="list-text">소스 NFSv4 내보낸 경로를 검색하고 해당 파일 구조의 통계를 인쇄합니다.</block>
  <block id="5073080976611febfcee79295d42232e" category="paragraph">xCP 스캔, 복사, 동기화 작업 중에 소스 NFSv4 내보내기를 읽기 전용 모드로 설정하는 것이 좋습니다.</block>
  <block id="f120bcab91519def54b7b66ee0fbecfe" category="list-text">타겟 ONTAP 시스템의 NFSv4 내보내기에 소스 NFSv4 내보내기를 복제합니다.</block>
  <block id="39ff9cab7c62e62bf182a632271eb700" category="list-text">'복제'가 완료된 후 소스 및 대상 NFSv4 내보내기에 동일한 데이터가 있는지 확인합니다. xCP Verify 명령을 실행합니다.</block>
  <block id="977c8a5f0f7f70041a1c6359c72cb1cd" category="paragraph">만약 원본과 대상 데이터의 차이를 발견한다면, 요약에는 '해당 파일 또는 디렉토리 없음' 오류가 보고된다. 이 문제를 해결하려면 'xCP sync' 명령을 실행하여 소스 변경 내용을 대상에 복사합니다.</block>
  <block id="29aee025cf0bcad3c355bd0aad4516e6" category="admonition">이 작업의 경우 이전 복제 인덱스 이름 또는 번호가 필요합니다.</block>
  <block id="ee0fd4f8758695ad7502bee81363478a" category="list-text">이전에 중단된 '복사' 작업을 다시 시작하려면 xCP resume 명령을 실행합니다.</block>
  <block id="cdc35fb8de987dae3f48c142ffcb0686" category="section-title">CIFS 데이터를 위한 7-Mode SMB 스토리지를 ONTAP로 전환</block>
  <block id="74efc43b80fa7a84f709780789176e0d" category="paragraph">이 섹션에서는 소스 7-Mode SMB 공유를 ONTAP 시스템으로 전환하기 위한 단계별 절차를 다룹니다.</block>
  <block id="f6f758220d5d00061aaa03b99e14785b" category="admonition">NetApp은 7-Mode 및 ONTAP 시스템에 SMB 라이센스가 있다고 가정합니다. 타겟 SVM이 생성되고, 소스 및 타겟 SMB 공유가 내보내지고, XCP가 설치 및 라이센스가 부여됩니다.</block>
  <block id="281c766457d5499048f9440f61957421" category="list-text">SMB 공유에서 파일 및 디렉토리를 검색합니다.</block>
  <block id="95c490ed8cb5d13c961fc2c50c372940" category="list-text">소스에서 대상 SMB 공유로 파일(ACL 포함 또는 제외)을 복사합니다. 다음 예제에서는 ACL이 포함된 복제본을 보여 줍니다.</block>
  <block id="dc056263ce0a29568cee559ae8ec35dc" category="admonition">데이터 Aggregate가 없으면 storage 'aggr create' 명령을 사용하여 새 Aggregate를 생성합니다.</block>
  <block id="7c34f7c35c71ba790649c5563408e77e" category="list-text">소스와 대상의 파일을 동기화합니다.</block>
  <block id="974c1ef10ec8fef5b3ff19989555d061" category="list-text">파일이 올바르게 복사되었는지 확인합니다.</block>
  <block id="8ae319b52e88ea41e78a01efdaab2143" category="inline-link-macro">다음: 소스 스토리지 상자에서 ONTAP로 ACL을 사용한 CIFS 데이터 마이그레이션</block>
  <block id="b6ea874ca7f1192a99c58fa3ff1199ba" category="paragraph"><block ref="b6ea874ca7f1192a99c58fa3ff1199ba" category="inline-link-macro-rx"></block></block>
  <block id="7ed4381f9a10813d06ebeaf5c947c2c1" category="summary">NetApp XCP 파일 분석 GUI는 백엔드에서 XCP를 사용하여 파일 시스템 검사를 실행하고 모든 NAS(NFS, SMB) 파일 시스템에 대한 그래프 및 보기와 같은 통계를 시각화하는 데 도움이 됩니다.</block>
  <block id="250a5d043009990eb69a399d7c630462" category="doc">파일 분석</block>
  <block id="47461303c8b8cbeb3e7558e2a9a1ca70" category="inline-link-macro">이전: 마이그레이션 워크플로우.</block>
  <block id="685a7e894721315c196897b76f95b8ce" category="paragraph"><block ref="685a7e894721315c196897b76f95b8ce" category="inline-link-macro-rx"></block></block>
  <block id="0f2604fbc18e6e91ba050460e6557361" category="paragraph">NetApp XCP 파일 분석 GUI는 백엔드에서 XCP를 사용하여 파일 시스템 검사를 실행하고 모든 NAS(NFS, SMB) 파일 시스템에 대한 그래프 및 보기와 같은 통계를 시각화하는 데 도움이 됩니다. 1.6에서 시작하는 xCP는 구성 및 systemctl 옵션을 사용하여 간단한 배포 단계를 통해 서비스로 실행할 수 있습니다. xCP 구성 옵션은 Postgres 및 웹 서버를 설치 및 구성하고 자격 증명을 수집하는 방법을 안내합니다. systemctl 옵션은 GUI의 REST API 통신을 위한 서비스로 xCP를 실행합니다.</block>
  <block id="914cb171c700c273306e8265b56f4973" category="paragraph">다음 그림에서는 xCP 파일 분석 흐름을 보여 줍니다.</block>
  <block id="538e51b99e800ab65e133b5d57b2dc7f" category="paragraph"><block ref="538e51b99e800ab65e133b5d57b2dc7f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bcdbf2b32a87f7efd13f706d43954d5" category="inline-link">NetApp XCP 1.6은 개방형 파일 분석 및 인프라 개선을 제공합니다</block>
  <block id="46742b2c1e11cf6a3e230ec3da7e6800" category="admonition">xCP 파일 분석의 상위 수준 아키텍처, 통계 보기와 같은 GUI 기반 대시보드 보기, 파일 배포 보기 세부 정보에 대한 자세한 내용은 블로그 게시물 을 참조하십시오<block ref="924a0428223d35821b584a5368c0e3e5" category="inline-link-rx"></block>.</block>
  <block id="21bd6427119f8d9a06a7c5bce95d28ac" category="paragraph">XCP 1.6에는 사용자 지정 그래프를 위한 GUI가 제한되어 있습니다. 필요한 그래프를 생성하려면 CLI를 사용하여 일치하는 필터로 'xCP' 스캔 명령을 실행할 수 있습니다. 다음 예를 참조하십시오.</block>
  <block id="168c81694a3b19988d829a9baeda23fd" category="list-text">xCP 스캔, -match 필터를 사용한 후 1년 이상 수정된 파일 목록을 생성합니다.</block>
  <block id="de615506a73ca5960be54d36ba7fcd5b" category="list-text">1년 이상 된 파일이 사용하는 공간을 찾습니다.</block>
  <block id="d2d1f03d5f19a1229103a85cc9224a61" category="list-text">1년 전에 수정된 데이터의 총 크기 및 그래픽 보기를 찾습니다.</block>
  <block id="d706f3d28ee3e74f9a6829c882169af8" category="paragraph">다음 보고서는 1년 전에 수정된 파일의 사용자 지정 예제 스캔입니다.</block>
  <block id="4d614048a495643d1c641a86e53b78d3" category="paragraph"><block ref="4d614048a495643d1c641a86e53b78d3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59a703e67b19adc4bdb1373c25fbca94" category="inline-link-macro">다음: 배포 단계.</block>
  <block id="54e4262e01c029cac8932a431c7e3d3f" category="paragraph"><block ref="54e4262e01c029cac8932a431c7e3d3f" category="inline-link-macro-rx"></block></block>
  <block id="945407c0c602d0c34ead1ebb5427a84b" category="summary">NetApp XCP를 사용하여 GPFS에서 NFS로 데이터를 마이그레이션하여 GPU에서 데이터를 처리할 수 있습니다. AI는 일반적으로 네트워크 파일 시스템의 데이터를 처리합니다.</block>
  <block id="1f797a3a419cdffd442fc4b662974908" category="doc">고성능 컴퓨팅에서 ONTAP NFS로</block>
  <block id="95160fc4cfa09139af600f92561c7ef9" category="inline-link-macro">이전: 데이터 레이크에서 ONTAP NFS로,</block>
  <block id="9d82d327cabd66bd4cccb55cb5ed28ec" category="paragraph"><block ref="9d82d327cabd66bd4cccb55cb5ed28ec" category="inline-link-macro-rx"></block></block>
  <block id="a4a4d9553ba807d3f28f8f25ea56cfec" category="paragraph">이 사용 사례는 현장 조직의 요청을 기반으로 합니다. 일부 NetApp 고객은 고성능 컴퓨팅 환경에서 데이터를 가지고 있으며, 교육 모델을 위한 데이터 분석을 제공하고 연구 조직에서 대량의 디지털 데이터를 통찰하고 이해할 수 있도록 지원합니다. NetApp 현장 엔지니어는 IBM의 GPFS에서 NFS로 데이터를 추출하기 위한 자세한 절차가 필요합니다. NetApp XCP를 사용하여 GPFS에서 NFS로 데이터를 마이그레이션하여 GPU에서 데이터를 처리할 수 있습니다. AI는 일반적으로 네트워크 파일 시스템의 데이터를 처리합니다.</block>
  <block id="409f476aa8c516a92f8d6a42e21db5a0" category="inline-link">XCP를 사용하여 데이터 레이크와 고성능 컴퓨팅에서 ONTAP NFS로 데이터를 이동합니다</block>
  <block id="0ce008ed1a75e69e9f21d1ad29ed23dd" category="paragraph">ONTAP NFS 활용 사례에 대한 고성능 컴퓨팅, 녹화된 데모 및 테스트 결과에 대한 자세한 내용은 를 참조하십시오<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> 블로그:</block>
  <block id="6cef4abedb8153458ee404a47b193489" category="inline-link">TR-4732: 인공 지능에 대한 빅 데이터 분석 데이터</block>
  <block id="fb64727a5df67d0ceff6f0a11b531ab5" category="paragraph">NetApp XCP를 사용하여 MapR-FS 데이터를 ONTAP NFS로 이동하는 방법에 대한 자세한 내용은 부록 A: GPFS에서 NFS로 GPFS를 참조하십시오. 자세한 단계는 에 나와 있습니다<block ref="e760c508aca9c545c45aba81e95e5593" category="inline-link-rx"></block>.</block>
  <block id="1b5c563b4edac6a7e8566fac62f90b34" category="inline-link-macro">다음으로 xCP Data Mover를 사용하여 수백만 개의 작은 파일을 유연한 스토리지로 마이그레이션합니다.</block>
  <block id="0461d449643091f3bbb27cfbb215c6f2" category="paragraph"><block ref="0461d449643091f3bbb27cfbb215c6f2" category="inline-link-macro-rx"></block></block>
  <block id="0706a8a70e2892183b45c55ef1394714" category="summary">이 섹션에서는 NFS용 100만 개의 다른 파일 크기로 XCP 복사 및 XCP 동기화 작업을 수행하는 대략적인 시간을 제공합니다.</block>
  <block id="137e4d3e0bc5586af6fc7ca9441511e1" category="doc">사이징 지침</block>
  <block id="f688414f56f567909ca9a570f161016e" category="inline-link-macro">이전: 배포 단계.</block>
  <block id="fb58e731328976afe8beac53cbe55ee7" category="paragraph"><block ref="fb58e731328976afe8beac53cbe55ee7" category="inline-link-macro-rx"></block></block>
  <block id="5224a4cb1d59edb5630ae27e640409e9" category="section-title">테스트에 따른 예상 시간</block>
  <block id="7e9b65699b01d35aeff9dc16008da7a5" category="paragraph">xCP 복사 및 동기화 작업에 대한 테스트에서는 구축에 사용된 것과 동일한 테스트 베드를 사용했습니다. 8K, 16K, 1MB 파일 3개 세트로 100만 개의 파일을 만들어 실시간으로 변경을 수행했습니다. xCP 동기화 기능은 소스에서 파일 레벨의 타겟으로 차등 증가분 업데이트를 수행했습니다. 증분 업데이트 작업은 기존 파일 및 폴더 이름 바꾸기, 기존 파일에 데이터 추가, 파일 및 폴더 삭제, 추가 하드, 소프트 및 멀티링크 포함 등 네 가지 작업 중 하나 이상을 수행합니다. 테스트를 위해 이름 바꾸기, 추가, 삭제 및 링크 작업에 초점을 맞추었습니다. 즉, 100만 개 파일에서 10% ~ 90%의 변경률로 이름 바꾸기, 추가, 삭제 등의 수정 작업을 수행했습니다.</block>
  <block id="1112334374c9149cc8ad8e80a76f2e56" category="paragraph">다음 그림에서는 xCP 복사 작업의 결과를 보여 줍니다.</block>
  <block id="d6852faef2642951731c8d64e3009dbe" category="paragraph"><block ref="d6852faef2642951731c8d64e3009dbe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58fe8c2d511caf443cb23313cb89181b" category="paragraph">다음 그림에서는 xCP Sync 이름 바꾸기 및 링크 작업의 결과를 보여 줍니다.</block>
  <block id="319b9e8dee4108359b7ef17af2fb492d" category="paragraph"><block ref="319b9e8dee4108359b7ef17af2fb492d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2186640ac8cac7be2b0f3940d871bf04" category="paragraph">파일 크기는 이름이 바뀐 소스 파일을 전송하는 xCP 동기화 완료 시간과 일치하지 않으며, 그래프가 선형입니다.</block>
  <block id="de54b82b6e27abb7d6f924e14d40a351" category="paragraph">링크 유형은 소프트 링크, 하드 링크 및 멀티 링크입니다. 소프트 링크는 일반 파일로 간주됩니다. xCP 동기화 작업을 완료하는 데 소요되는 시간은 파일 크기와 관련이 없습니다.</block>
  <block id="db3eb29ec347d79a716c6235063b1955" category="paragraph">다음 그림은 XCP 동기화 추가 및 삭제 작업의 결과를 보여 줍니다.</block>
  <block id="feeff6134484088b1b404089dc5f92d9" category="paragraph"><block ref="feeff6134484088b1b404089dc5f92d9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f64c7d081568c95905b16364c19e1be1" category="paragraph">추가 및 삭제 작업의 경우 작은 파일 크기에 비해 파일 크기가 크면 시간이 더 오래 걸립니다. 작업을 완료하는 데 걸리는 시간은 추가 및 삭제 변경 비율에 비례합니다.</block>
  <block id="ecc8d4faf16ec3b08a8badd1d71421d3" category="section-title">xCP 1.6.1 과 xCP 1.5 비교</block>
  <block id="f599c9e924e3b854abd0ab58126fed43" category="paragraph">이전 버전에 비해 XCP 1.6.3 및 1.7은 향상된 성능을 제공합니다. 다음 섹션에서는 XCP 1.6.3 및 1.7(8K, 16K 및 1MB 파일)의 동기화 성능 비교를 보여 줍니다.</block>
  <block id="b53776fdc2fd9fc721aaa6f03fd3d6a0" category="paragraph">다음 그림은 XCP 1.6.3의 XCP 동기화 성능과 1.7(100만 개 파일의 8K 크기)의 결과를 보여 줍니다.</block>
  <block id="ded6c17dda87ca50a7ecde2418543075" category="paragraph"><block ref="ded6c17dda87ca50a7ecde2418543075" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09a0804a78587affdd9192afd0f8c80c" category="paragraph">다음 그림은 XCP 1.6.1 및 1.5의 XCP 동기화 성능(1백만 개 파일의 16K 크기)의 결과를 보여 줍니다.</block>
  <block id="b2733f54373c0149b19c3b37afbcb7da" category="paragraph"><block ref="b2733f54373c0149b19c3b37afbcb7da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b201508f1de849d630f98c0001fdc29" category="paragraph">다음 그림은 XCP 1.6.1에 대한 XCP 동기화 성능 결과와 1백만 개 파일의 1MB 크기의 1.5를 비교한 결과를 보여 줍니다.</block>
  <block id="e7770abf0d9a0789407ea0a0e81cc5a6" category="paragraph"><block ref="e7770abf0d9a0789407ea0a0e81cc5a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71c6a3c1c59fc41b371a18011d1d5c9b" category="paragraph">xCP 1.7의 성능은 평균적으로 xCP 1.6.3에서 'xCP 동기화' 차등 증분 업데이트의 XCP 1.6.3과 비슷했습니다. 즉, 100만 개 파일의 1MB 크기로 이름 바꾸기, 추가, 링크 및 삭제 작업을 수행할 수 있었습니다.</block>
  <block id="61b90da0c91ea6cb7c16bfaca41b4920" category="paragraph">이러한 성능 검증을 기반으로 사내 및 클라우드에서 데이터 마이그레이션에 XCP 1.7을 사용하는 것이 좋습니다.</block>
  <block id="dd6275237d7504aabd0c206384365206" category="inline-link-macro">다음: 성능 조정.</block>
  <block id="cb619c90f7b537d24a1473acda746a47" category="paragraph"><block ref="cb619c90f7b537d24a1473acda746a47" category="inline-link-macro-rx"></block></block>
  <block id="69f55c7d7266874ad1ed57caf459c979" category="summary">이 사용 사례는 우리가 수행한 가장 큰 재무 고객 개념 증명(CPOC)을 기반으로 합니다. 역사적으로 우리는 NetApp NIPAM(In-Place 분석 모듈)을 사용하여 분석 데이터를 NetApp ONTAP AI로 이동시켰습니다. 하지만 최근 NetApp XCP의 향상된 기능과 향상된 성능, 고유한 NetApp Data Mover 솔루션 접근 방식 덕분에 NetApp XCP를 사용하여 데이터 마이그레이션을 다시 수행할 수 있게 되었습니다.</block>
  <block id="5084e1c3bd53b6115df08f4c40aadbe6" category="doc">데이터 레이크에서 ONTAP NFS로</block>
  <block id="ae8dcf06c5337995ca840fbd543188fc" category="inline-link-macro">이전: 고객 시나리오.</block>
  <block id="82f418da831bb7ca7897e30f8bc5525a" category="paragraph"><block ref="82f418da831bb7ca7897e30f8bc5525a" category="inline-link-macro-rx"></block></block>
  <block id="b1a11a01b3bdf3150e0240a1f037cdf5" category="section-title">고객의 당면 과제 및 요구사항</block>
  <block id="9ed16d5ac47c336caaf9ca2b75930d78" category="paragraph">주목해야 할 고객 과제 및 요구사항은 다음과 같습니다.</block>
  <block id="b6976e1a47e217f1a7c746e8f57e327c" category="list-text">정형, 비정형, 준정형 데이터, 로그, 데이터, 데이터 등 다양한 데이터 유형을 그리고 데이터 레이크에 있는 머신 간 데이터를 활용하여 AI 시스템을 사용하면 예측 작업을 위해 이러한 모든 유형의 데이터를 처리할 수 있습니다. 데이터가 데이터 레이크 네이티브 파일 시스템에 있으면 프로세스가 어렵습니다.</block>
  <block id="d85cb5080a9e99841f0ff6c36abdadad" category="list-text">고객의 AI 아키텍처는 HDFS(Hadoop Distributed File System) 및 HCFS(Hadoop Compatible File System)의 데이터에 액세스할 수 없으므로 AI 작업에 데이터를 사용할 수 없습니다. AI에는 NFS와 같이 이해하기 쉬운 파일 시스템 형식의 데이터가 필요합니다.</block>
  <block id="982b6c87ace8f5b95c0523bd0557f4e2" category="list-text">대량의 데이터와 높은 처리량으로 인해 데이터 레이크에서 데이터를 이동하려면 일부 특별한 프로세스가 필요하며, 데이터를 AI 시스템으로 이동하는 데 비용 효율적인 방법이 필요합니다.</block>
  <block id="d73e7d11401e9256a0dea0d1e174e1de" category="section-title">Data Mover 솔루션</block>
  <block id="b0a9a6f2387f2a23e13931f68fc509c1" category="paragraph">이 솔루션에서 MapR 파일 시스템(MapR-FS)은 MapR 클러스터의 로컬 디스크에서 생성됩니다. MapR NFS 게이트웨이는 가상 IP가 있는 각 데이터 노드에서 구성됩니다. 파일 서버 서비스는 MapR-FS 데이터를 저장하고 관리합니다. NFS 게이트웨이는 가상 IP를 통해 NFS 클라이언트에서 Map-FS 데이터에 액세스할 수 있도록 합니다. MapR 데이터 노드당 XCP 인스턴스가 실행되고 지도 NFS 게이트웨이에서 NetApp ONTAP NFS로 데이터를 전송합니다. 각 xCP 인스턴스는 특정 소스 폴더 세트를 대상 위치로 전송합니다.</block>
  <block id="01e1c2900284f91d77ea71ffd32c6d18" category="paragraph">다음 그림은 XCP를 사용하는 MapR 클러스터용 NetApp Data Mover 솔루션을 보여 줍니다.</block>
  <block id="a7dcdfa2099e01480afb3c060c679f10" category="paragraph"><block ref="a7dcdfa2099e01480afb3c060c679f10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4084b5f9c9bab8db38eb6e04a3b3a4cc" category="paragraph">고객 사용 사례, 녹화된 데모 및 테스트 결과에 대한 자세한 내용은 를 참조하십시오<block ref="c5fcc47a7dd315afaa32fcdac46ffd7d" category="inline-link-rx"></block> 블로그:</block>
  <block id="520ef13ea64298a652262e37756b6bd4" category="paragraph">NetApp XCP를 사용하여 MapR-FS 데이터를 ONTAP NFS로 이동하는 방법에 대한 자세한 내용은 의 부록 B를 참조하십시오<block ref="c952a09d2ff4403056a594c41db26c8d" category="inline-link-rx"></block>.</block>
  <block id="b4dd66db226c58dbbcc8455a7576d491" category="inline-link-macro">다음: ONTAP NFS에 대한 고성능 컴퓨팅.</block>
  <block id="9ebf542ce4a3a8a997eb85e5b6e086ed" category="paragraph"><block ref="9ebf542ce4a3a8a997eb85e5b6e086ed" category="inline-link-macro-rx"></block></block>
  <block id="7776aec966d5a0c71bd4e8230f9470b8" category="summary">이 사용 사례는 TV 네트워크 고객을 기반으로 합니다. 고객은 Oracle RMAN(Recovery Manager) 백업 파일을 클라우드로 마이그레이션하고 심장박동기 소프트웨어가 설치된 Azure NetApp Files를 사용하여 Oracle EBS(E-Business Suite) 애플리케이션을 실행하려고 했습니다. 또한 고객은 데이터베이스 백업 파일을 주문형 클라우드 스토리지로 마이그레이션하고 대용량 파일(각각 25GB~50GB 범위)을 Azure로 전송하길 원했습니다.</block>
  <block id="8108bac490ceb375198c578e8a439026" category="doc">xCP Data Mover를 사용하여 대용량 파일을 마이그레이션합니다</block>
  <block id="adec666d077f4afe1b4f2b8720ed1247" category="inline-link-macro">이전: XCP Data Mover를 사용하여 수백만 개의 작은 파일을 유연한 스토리지로 마이그레이션합니다.</block>
  <block id="d6be3aed77745a993a24266eaf05084d" category="paragraph"><block ref="d6be3aed77745a993a24266eaf05084d" category="inline-link-macro-rx"></block></block>
  <block id="06470d7a09a56d555bad98bdf38a6cad" category="paragraph">다음 그림에서는 대용량 파일의 경우 사내에서 Azure NetApp Files으로 데이터를 마이그레이션하는 방법을 보여 줍니다.</block>
  <block id="1b95efe3eae02043da6528de3cf9caf8" category="inline-link-macro">다음: 파일을 복제합니다.</block>
  <block id="76fdb34470826293aaf52b30bf98fce0" category="paragraph"><block ref="76fdb34470826293aaf52b30bf98fce0" category="inline-link-macro-rx"></block></block>
  <block id="24992328317a5b7b3c00507eb27776df" category="paragraph"><block ref="24992328317a5b7b3c00507eb27776df" category="inline-link-macro-rx"></block></block>
  <block id="d4f4c40bd169a262676284f5da7a191a" category="cell">2020년 10월</block>
  <block id="035fe4f74f99e66d6525774bf40236f9" category="summary">이 섹션에서는 NetApp XCP를 사용하여 데이터를 마이그레이션하기 위한 모범 사례, 지침 및 권장 사항을 다룹니다.</block>
  <block id="52f7ac44cac2d8d1a3f005648d7521e3" category="doc">모범 사례 지침 및 권장사항</block>
  <block id="b5a13e4f32bf69c6814808ff6a11eb9b" category="inline-link-macro">이전: 소스 스토리지 상자에서 ONTAP로 ACL을 사용한 CIFS 데이터 마이그레이션</block>
  <block id="a930ea4d6e07241178b9fe2f3c054fd2" category="paragraph"><block ref="a930ea4d6e07241178b9fe2f3c054fd2" category="inline-link-macro-rx"></block></block>
  <block id="1cce79308861dd86d5e56af13afefaf2" category="list-text">IMT에서 지원하는 XCP 클라이언트 운영 체제를 사용합니다. IMT 지원 클라이언트는 NetApp의 검증을 받았습니다.</block>
  <block id="ec653488c4b3b9bb00702a4fb937f5b4" category="list-text">Linux 운영 체제에서 루트 사용자로 xCP를 실행하여 마이그레이션을 수행합니다. sudo 사용자로 xCP 명령을 실행할 수 있지만 xCP에서는 지원되지 않습니다.</block>
  <block id="8c8f6415908fe0a235f0850d80a398a4" category="list-text">클라이언트당 한 개의 xCP 인스턴스만 실행합니다. 기술적으로 동일한 호스트에서 여러 XCP를 다른 위치에서 실행할 수 있지만 이는 지원되지 않습니다. 실제로 많은 인스턴스를 실행하면 오류가 발생할 수 있습니다.</block>
  <block id="cac486281cae3e805e89a64673c47eb3" category="list-text">현재 XCP 버전에서는 라이브 소스가 지원되지 않습니다. 소스 NetApp 볼륨이 활성 상태이고 애플리케이션 및 사용자가 지속적으로 변경하는 경우 소스 볼륨의 스냅샷을 생성하여 마이그레이션을 수행해야 합니다.</block>
  <block id="c1f9797ffa66b762cf07348c6bc4a005" category="list-text">모든 증분 동기화에 대해 다른 이름을 사용하여 새 스냅샷을 생성하는 것이 가장 좋습니다. 이렇게 하면 장애 발생 시 스냅샷 이름을 기반으로 증분 마이그레이션 경로를 쉽게 생성할 수 있습니다.</block>
  <block id="1309895bb5c78406c77a6cc2800160eb" category="list-text">스냅샷 기반 마이그레이션을 수행하는 경우에는 컷오버가 완료될 때까지 스냅샷 기반 마이그레이션을 계속하는 것이 좋습니다.</block>
  <block id="cc9954d8dc3e80c40af9d0a7ca3de005" category="list-text">천만 개 이상의 파일이 있고 50% 이상의 증분 데이터 변경이 있는 경우 설치 및 관리 가이드에서 권장하는 최소 구성보다 더 많은 코어 수와 메모리를 사용하는 것이 좋습니다.</block>
  <block id="f6cb936ed9c08627956daed52c6c3323" category="inline-link-macro">다음: 문제 해결.</block>
  <block id="58c815a6f6adf3657aa40f96cb5f2d08" category="paragraph"><block ref="58c815a6f6adf3657aa40f96cb5f2d08" category="inline-link-macro-rx"></block></block>
  <block id="a01ed8ff3f6e9e3ac0c0068a083281f2" category="summary">이 섹션에서는 NetApp XCP를 사용한 데이터 마이그레이션에 대한 문제 해결 지침을 제공합니다.</block>
  <block id="231cf4c70d866b616c21baddaeed0696" category="doc">문제 해결</block>
  <block id="ae638a1049211e9956348a48a85bd359" category="inline-link-macro">이전: 모범 사례 지침 및 권장 사항</block>
  <block id="e19cdddb31b62a88048cfee77eb96e9d" category="paragraph"><block ref="e19cdddb31b62a88048cfee77eb96e9d" category="inline-link-macro-rx"></block></block>
  <block id="95109c432d89e67182659615993ba75d" category="section-title">오류 1: xCP가 NFS3 오류와 함께 실패했습니다. 70: xcp.log 파일의 오래된 파일 오류입니다</block>
  <block id="99b1b0e3547443c29793187326a64dbc" category="paragraph">* 이유 및 지침. *</block>
  <block id="0774d3e8b775fcc34e680b302e85f3c1" category="paragraph">소스 폴더를 마운트하고 폴더가 있는지 확인합니다. 파일이 없거나 제거된 경우 '파일 핸들 표시' 오류가 발생하며, 이 경우 오류를 무시할 수 있습니다.</block>
  <block id="8fefb715a66a069c9e9318a58ecfdaee" category="section-title">오류 2: NetApp NFS 대상 볼륨에 공간이 있지만 xCP NFS 오류 28: 장치에 공간이 남아 있지 않습니다</block>
  <block id="bba52daa861e8093e201c3939f43057f" category="list-text">df 명령을 실행하거나 스토리지를 확인하여 NFS 대상 볼륨의 공간을 확인합니다.</block>
  <block id="20183145becc54cc822a80107f92f13d" category="list-text">스토리지 컨트롤러의 inode를 확인합니다.</block>
  <block id="fe3a96130e3ec3092026a84e4dd12e50" category="list-text">inode를 사용하는 경우 다음 명령을 실행하여 inode 수를 늘립니다.</block>
  <block id="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="paragraph"><block ref="00f1ec7e4f2acc8a9e2c5a06b2d62607" category="inline-link-macro-rx"></block></block>
  <block id="1357196e1dc18c4ad43fe26a6c1b30ad" category="inline-link-macro">이전: 성능 조정.</block>
  <block id="33672b776ede62bd1269689ea61e45aa" category="paragraph"><block ref="33672b776ede62bd1269689ea61e45aa" category="inline-link-macro-rx"></block></block>
  <block id="1ebf7a1cb4f3826913a58c19018c694e" category="paragraph">이 섹션에서는 고객 시나리오 및 아키텍처에 대해 설명합니다.</block>
  <block id="b58464d62b5399c457b8a1fcf6bbcd27" category="inline-link-macro">다음: ONTAP NFS로 데이터 레이크 전환</block>
  <block id="a24139c6a89df9b0694c3ea695639ace" category="paragraph"><block ref="a24139c6a89df9b0694c3ea695639ace" category="inline-link-macro-rx"></block></block>
  <block id="c4e9391c8d60f1f326246cd6b6705492" category="summary">NetApp은 단일 볼륨 또는 여러 볼륨에서 중복 파일을 찾기 위한 요청을 받았습니다. NetApp은 다음과 같은 솔루션을 제공했습니다.</block>
  <block id="2e4e5fbe1f8f460b943ac3ed031c9dcf" category="doc">중복 파일</block>
  <block id="f89d6874c6cf2c5de0dae9564728c7cf" category="inline-link-macro">이전: XCP Data Mover를 사용하여 대용량 파일을 마이그레이션합니다.</block>
  <block id="6c8f161effcb72b9425f626e8733146b" category="paragraph"><block ref="6c8f161effcb72b9425f626e8733146b" category="inline-link-macro-rx"></block></block>
  <block id="dc4b36d55f5f1f0af63ed899a010c8f1" category="paragraph">단일 볼륨의 경우 다음 명령을 실행합니다.</block>
  <block id="2d2f31777cf3433071b9bcd33f39279a" category="paragraph">여러 볼륨의 경우 다음 명령을 실행합니다.</block>
  <block id="fdefb3eaaab41fef36db24700d399ef2" category="inline-link-macro">다음: 특정 날짜 기반 스캔 및 데이터 복사.</block>
  <block id="769f411db097d478d8d10a821946e501" category="paragraph"><block ref="769f411db097d478d8d10a821946e501" category="inline-link-macro-rx"></block></block>
  <block id="485f9678c52b78d051ddff564d873eb9" category="summary">이 섹션의 명령은 CSV 형식으로 데이터를 덤프합니다. 크기 열의 합계를 합산하여 데이터의 총 크기를 구할 수 있습니다.</block>
  <block id="92f6d6878e37105d20e75151b95d4e6a" category="doc">SMB/CIFS 공유에서 CSV 파일 생성</block>
  <block id="bab825782f37e3f0cd908b20bc8aa74c" category="inline-link-macro">이전: 특정 날짜 기반 스캔 및 데이터 복사.</block>
  <block id="ad80673543d1d2744f55966060c4579b" category="paragraph"><block ref="ad80673543d1d2744f55966060c4579b" category="inline-link-macro-rx"></block></block>
  <block id="d122031c67144a65ca4721f8324ae0b3" category="paragraph">다음 명령을 실행하면 데이터가 CSV 형식으로 덤프됩니다. 크기 열의 합계를 합산하여 데이터의 총 크기를 구할 수 있습니다.</block>
  <block id="1bed902c0754e4abc7598b7f1a0450e0" category="paragraph">출력은 다음 예와 비슷해야 합니다.</block>
  <block id="f7c322db5a6c805aed8a38858c7ba770" category="paragraph">하위 디렉토리 세 개를 심층 검색하고 정렬 순서를 제공하려면 xCP -du 명령을 실행하여 각 디렉토리 수준에서 하위 디렉토리 세 개의 깊이까지 크기를 덤프합니다.</block>
  <block id="7c12bd6fa64456eb3a61460a4bbb98e6" category="paragraph">정렬하려면 정보를 CSV 파일로 덤프하고 정보를 정렬합니다.</block>
  <block id="d0ecdc77c2c944d380e9fef0e01eb119" category="paragraph">이것은 '-FMT' 명령을 사용하는 사용자 정의 보고서입니다. 모든 디렉토리를 검색하여 디렉토리 이름, 경로 및 디렉토리 크기를 CSV 파일로 덤프합니다. 스프레드시트 응용 프로그램에서 크기 열을 정렬할 수 있습니다.</block>
  <block id="c2e9a8d6d376247b10a1ab4624bd2610" category="inline-link-macro">다음: 7-Mode에서 ONTAP로 데이터 마이그레이션</block>
  <block id="7155e60f207d105fa4db5d15efdce133" category="paragraph"><block ref="7155e60f207d105fa4db5d15efdce133" category="inline-link-macro-rx"></block></block>
  <block id="2246a929033f1d77a86efa97dda42849" category="inline-link-macro">이전: 문제 해결.</block>
  <block id="49c4600bab96ae4bda03f252b43985b4" category="paragraph"><block ref="49c4600bab96ae4bda03f252b43985b4" category="inline-link-macro-rx"></block></block>
  <block id="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link"><block ref="464fbe5e9ea5b377de3943b7d1e73632" category="inline-link-rx"></block></block>
  <block id="eba010943793fb5b647ad292a452b3ff" category="list-text">NetApp XCP 블로그<block ref="2639c38af267ba997fc1d85740cfc9a6" category="inline-link-rx"></block></block>
  <block id="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link"><block ref="6ae1587e2fb0d146cd960f45d3f1fc13" category="inline-link-rx"></block></block>
  <block id="fb8d9f206204f9562c2a67c6b37a7d1b" category="list-text">NetApp XCP 사용자 가이드<block ref="05f41a166d52148335e3a0df2eafec23" category="inline-link-rx"></block></block>
  <block id="e2c2bd378a3ae3740034d637754af7e2" category="inline-link"><block ref="e2c2bd378a3ae3740034d637754af7e2" category="inline-link-rx"></block></block>
  <block id="79b44e54a5eac82beac2de86249cd862" category="list-text">bigdata Analytics 데이터를 인공 지능으로 분석 – AI용 Data Mover 솔루션<block ref="79ced727b5c9638c0385a25671803fba" category="inline-link-rx"></block></block>
  <block id="9ebf058ce7a44ad4517e7033db8a90a7" category="paragraph"><block ref="9ebf058ce7a44ad4517e7033db8a90a7" category="inline-link-macro-rx"></block></block>
  <block id="3d5c39f585b0e679dbfe0855d556f0af" category="summary">NetApp XCP는 멀티스레드와 맞춤형 기능을 사용하여 데이터를 전송합니다. 데이터 이동 또는 마이그레이션, 파일 시스템 분석, 빠른 디렉토리 트리 삭제와 같은 세 가지 주요 활용 사례에 맞게 설계되었습니다.</block>
  <block id="211c181ce8e8cb0472af3095c66dc5eb" category="paragraph"><block ref="211c181ce8e8cb0472af3095c66dc5eb" category="inline-link-macro-rx"></block></block>
  <block id="6416bf9c9c9445fbe2e15f69fa8371d2" category="paragraph">NetApp XCP는 멀티스레드와 맞춤형 기능을 사용하여 데이터를 전송합니다. 데이터 이동 또는 마이그레이션, 파일 시스템 분석, 빠른 디렉토리 트리 삭제의 세 가지 주요 활용 사례에 맞게 설계되었습니다.</block>
  <block id="7817bd783e8db0557909483f54288eae" category="section-title">데이터 이동 또는 마이그레이션</block>
  <block id="a7786f240f16aadfd675c46be438f64e" category="paragraph">NetApp XCP는 모든 NAS에서 NetApp NAS로 데이터를 전송합니다. 이 프로세스는 스캔, 복사, 동기화 및 검증의 네 가지 주요 작업으로 구성됩니다. 데이터 모니터링 및 전송에 도움이 되는 몇 가지 추가 기능이 있습니다.</block>
  <block id="1c026a57d7676d346dd0d44a2f595c1d" category="list-text">* 스캔. * NAS 및 MapR/HDFS 데이터의 상위 레벨 레이아웃을 제공합니다.</block>
  <block id="59e4194e1b171063beeb99722a68e7af" category="list-text">* Copy. * 기준 데이터 전송을 수행합니다.</block>
  <block id="a75ddee1308f2f19e478595122434544" category="list-text">* Sync. * 증분 데이터 전송을 수행합니다.</block>
  <block id="ae4ab572ec7de44b385c01df54f00d17" category="list-text">* verify. * 대상에 대한 철저한 검증을 수행합니다.</block>
  <block id="8ddbaa98ade9dcd56d4960b7abd22525" category="list-text">* Show (선택 사항). * NAS 공유를 검색합니다.</block>
  <block id="4f4544fb0f8ed8f32e27a8b8651a46e6" category="paragraph">다음 그림에서는 xCP 데이터 마이그레이션 및 복제 작업을 보여 줍니다.</block>
  <block id="6d97d3e510fc0fba449ece8ddd3f3d10" category="paragraph"><block ref="6d97d3e510fc0fba449ece8ddd3f3d10" category="inline-image-macro-rx" type="image"></block></block>
  <block id="657bad21acd4ceb926477ced53a4ec55" category="section-title">파일 시스템 분석</block>
  <block id="65424b0dc0515cfa3b67e71712012db0" category="paragraph">NetApp XCP는 기본적으로 비정형 데이터를 식별, 조사 및 분석하여 통찰력을 향상합니다. 이 인사이트를 활용하여 더 나은 계획을 세우고, 높은 가치의 디지털 자산을 운영하며, 보고 및 평가를 통해 데이터 거버넌스를 구현하려는 엔터프라이즈 고객에게 중요한 요구사항입니다.</block>
  <block id="03c5a03e8b03794f5fa193e72245496c" category="paragraph">중요한 데이터를 처리하는 고객은 NetApp XCP를 사용하여 다음과 같은 일반적인 운영 질문에 답변할 수 있습니다.</block>
  <block id="6ad28c778baa08cff585599e160c12c8" category="list-text">내 데이터는 어디에 있습니까?</block>
  <block id="5eccfafcfad0fb3dcd5f4f1036fed9f9" category="list-text">보유한 데이터의 양과 파일 형식은 무엇입니까?</block>
  <block id="b1c54971a6211d7b7e3d074bff16b4c9" category="list-text">어떤 데이터가 활발히 사용되고 있으며 얼마나 휴면 상태입니까?</block>
  <block id="6b2c974b2ada5fba492b8dcda598b1f9" category="paragraph">다음 그림에서는 GUI에서 제공되는 NetApp XCP 파일 분석 통신을 보여 줍니다.</block>
  <block id="81ff19b428c80049b09f8e1e6e55cfde" category="paragraph"><block ref="81ff19b428c80049b09f8e1e6e55cfde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2a6c498fb90ee345d997f888fce3b18" category="section-title">삭제</block>
  <block id="4125c56415a1c3b98b49ee7f8c2ebfc3" category="paragraph">스토리지 팀과 EDA(Electronic Design Automation) 워크로드에서는 오래된 데이터나 스토리지 공간 복구를 위해 청소해야 하는 테스트 데이터 등 큰 디렉토리를 정리하는 데 매우 어려울 수 있습니다. xCP는 전체 디렉토리 트리를 삭제할 수 있는 빠른 삭제 기능을 제공합니다. NetApp XCP 삭제 기능은 지정된 NAS 경로에서 파일과 폴더를 제거합니다. 일치 필터를 사용하여 특정 파일 및 폴더 집합을 삭제할 수 있습니다. 많은 수의 파일 및 폴더의 경우 삭제를 확인하는 데 필요 없는 강제 옵션을 사용할 수 있습니다.</block>
  <block id="ecfd5328aaeaeb8ab72037598049a32c" category="section-title">라이브 소스 마이그레이션 지원</block>
  <block id="2d3aa3941d30870beb3abde613ce14b1" category="paragraph">xCP 1.7에 포함된 라이브 소스 마이그레이션 지원을 통해 사용 중인 데이터 소스(읽기 및 쓰기 작업)에서 마이그레이션할 수 있습니다. xCP는 복사 및 동기화 실행 등 마이그레이션 작업 중에 사용 중인 파일을 삭제하며, 건너뛴 파일 정보는 xCP 로그에 캡처됩니다.</block>
  <block id="286a0f56c729672b0709605c558d0008" category="paragraph">이 기능은 소스의 변경 사항을 지원하지만 대상의 변경 사항은 지원하지 않습니다. 마이그레이션 중에는 대상이 활성 상태가 아니어야 합니다. 라이브 소스 마이그레이션 지원은 NFS 마이그레이션에만 사용할 수 있습니다.</block>
  <block id="2c346a482fcf83bd03d1d51f65d58b8d" category="admonition">라이브 소스 마이그레이션에는 특별한 설정이 필요하지 않습니다.</block>
  <block id="ba41152bc4991a294ab26fbe691d52e3" category="section-title">xCP 사전 요구 사항</block>
  <block id="010e3e2a3d44100784dac368cdb601c0" category="paragraph">NetApp XCP를 구축하려면 다음과 같은 사전 요구사항이 충족되어야 합니다.</block>
  <block id="b76760dcfae800f7180ec4e8c57a8e2f" category="list-text">다음 명령을 실행하여 NFS 서버가 사용하는 NFS 포트를 확인합니다.</block>
  <block id="a9a9fca38da059af5a55e2fc58ef3851" category="list-text">사내 또는 클라우드 인스턴스(예: Azure, AWS 또는 Google 가상 머신[VM] 인스턴스)와 같은 XCP 작업을 실행하는 위치에 액세스하려면 NFS 포트의 방화벽 포트를 엽니다.</block>
  <block id="b22a57ce186f512ec584f5aac1d3de34" category="list-text">텔넷 명령 "&lt;온프레미스 NFS 데이터 LIF IP 또는 NAS IP&gt;2049"를 사용하여 XCP 서버에서 NFS 포트에 액세스할 수 있는지 확인합니다. 기본 포트는 2049입니다. 환경에 다른 포트가 있는 경우 해당 IP를 사용하십시오.</block>
  <block id="e54a7adb3b7e28ed3d693d972fc48fd0" category="list-text">NFS의 경우 'howmount -e &lt;nas ip&gt;' 명령을 사용하여 xCP 서버에서 공유에 액세스할 수 있는지 확인하십시오.</block>
  <block id="da7f6a983e12f3b14b965ea651990ca9" category="list-text">대상 볼륨의 inode 수를 소스 파일의 파일 수(파일 수)보다 많이 늘립니다.</block>
  <block id="71858e85f290ec0f6955841bab9f3aef" category="inline-link">NetApp XCP 라이센스 포털</block>
  <block id="14324adbfb79ad4b6832f6a02a1275db" category="list-text">에서 xCP 라이센스를 다운로드합니다<block ref="eab886d42d2df7a710066e6d9bf6f5f5" category="inline-link-rx"></block>.</block>
  <block id="7481213bd7173438d06de418474e428b" category="list-text">mysupport.netapp.com 에 NetApp 계정이 있어야 하며, 그렇지 않은 경우 무료로 등록할 수 있습니다.</block>
  <block id="d25e9f08475ddf6a2701e7cfbd67ff06" category="list-text">라이센스를 다운로드하여 준비하십시오.</block>
  <block id="b9611b870758eac97bd0c3bcb3fc8026" category="list-text">XCP 카탈로그용 클라우드에서 각 Azure NetApp 볼륨 또는 Cloud Volume Service(프리미엄 서비스 수준)에 대해 온프레미스에 NFS 공유를 하나 만드십시오.</block>
  <block id="3d19c697861d11cce0f1d78d41cfea64" category="list-text">NAS 볼륨을 생성하고 데이터 대상에 대한 공유를 구성합니다.</block>
  <block id="4f2a304b9680876edc7cb61b5c4c7134" category="list-text">여러 xCP 인스턴스의 경우 여러 소스 폴더 또는 파일에서 대상으로 데이터를 전송하려면 하나 이상의 서버 또는 클라우드 인스턴스가 있어야 합니다.</block>
  <block id="adc4e34febc2f5919cfa03870630c2fc" category="list-text">maxdir 크기(기본값은 308MB)는 단일 폴더에서 최대 파일 수(약 100만)를 정의합니다. 파일 수를 늘리려면 maxdir 크기 값을 늘리십시오. 값을 늘리면 추가 CPU 사이클에 영향을 줍니다.</block>
  <block id="a1552408599f6e2171495d55ae375802" category="list-text">클라우드에서 ExpressRoute(Azure), Direct Connect(AWS), Cloud Interconnect(GCP) 등을 사용하는 것이 좋습니다.</block>
  <block id="fb41b0ab70237465636fc4267d1c00dd" category="inline-link-macro">다음: 마이그레이션 워크플로우.</block>
  <block id="7480aca6b5f94dc27cc94b015284d5e9" category="paragraph"><block ref="7480aca6b5f94dc27cc94b015284d5e9" category="inline-link-macro-rx"></block></block>
  <block id="7e0710b4cb48030b7a4c065128b88194" category="summary">이 섹션에서는 소스에서 타겟 ONTAP 시스템으로 보안 정보가 포함된 CIFS 데이터를 마이그레이션하는 단계별 절차에 대해 설명합니다.</block>
  <block id="82f0875c37eacadc40a7a7fb2a6b6313" category="doc">소스 스토리지 상자에서 ONTAP로 ACL을 사용한 CIFS 데이터 마이그레이션</block>
  <block id="0f17f55a868185c28a66d0817a780f53" category="inline-link-macro">이전: 7-Mode에서 ONTAP로 데이터 마이그레이션</block>
  <block id="99b2c0d3f328317650f8748e47c7bedb" category="paragraph"><block ref="99b2c0d3f328317650f8748e47c7bedb" category="inline-link-macro-rx"></block></block>
  <block id="c55bb6c3381ca2d8a4016e387cc62883" category="list-text">데이터 LIF를 생성하여 SMB 클라이언트 요청을 처리합니다.</block>
  <block id="5368b7f480b92b4a2a9b475e6e9cf953" category="list-text">SVM 네임스페이스에서 타겟 데이터 볼륨을 마운트합니다.</block>
  <block id="18f8848c17d02fd34b293885d5d3a215" category="list-text">타겟 SVM에서 CIFS 서비스를 시작합니다.</block>
  <block id="cf1269d629dc2110f2ae65edf8662b79" category="list-text">기본 엑스포트 정책이 타겟 SVM에 적용되는지 확인합니다.</block>
  <block id="74e1ca9e0b551a7349207f3d546b9f51" category="list-text">CIFS 클라이언트에 대한 액세스를 허용하도록 엑스포트 정책 규칙을 수정합니다.</block>
  <block id="3c19a2ac394a25f9ace05db18ad86c8b" category="paragraph">정책 규칙이 수정되었는지 확인합니다.</block>
  <block id="876afc73f4771f46cfc9dba7fb687744" category="list-text">xCP가 설치된 Windows 클라이언트 시스템에 연결합니다. xCP 설치 경로로 이동합니다.</block>
  <block id="e73a44af938fa16a4816d3639d2f3b69" category="list-text">xCP Windows 클라이언트 호스트 시스템에서 'xCP show' 명령을 실행하여 소스 노드 SMB 내보내기를 쿼리합니다.</block>
  <block id="7132ef955ec5e0151ccd0790da2551d7" category="list-text">복사에 대한 도움말 명령을 실행합니다.</block>
  <block id="268b71a144890a49d97f8ca062fd48f9" category="list-text">대상 ONTAP 시스템에서 fallback-user와 fallback-group 인수 경로 값으로 제공해야 하는 로컬 사용자 및 로컬 그룹 이름 목록을 가져옵니다.</block>
  <block id="ac9ad1198db0fb6f730a1f3aa97c35ab" category="list-text">소스에서 ACL이 포함된 CIFS 데이터를 타겟으로 마이그레이션하려면 '-acl' 및 '-fallback-user/group' 옵션을 사용하여 'xCP copy' 명령을 실행합니다.</block>
  <block id="a53e836d6264ad1778a4e1a7ae34f58c" category="paragraph">'fallback-user/group' 옵션의 경우 Active Directory 또는 로컬 사용자/그룹에서 대상 시스템으로 찾을 수 있는 사용자 또는 그룹을 지정합니다.</block>
  <block id="9aa080e55cad2c9968cc50de60a3f88e" category="list-text">xCP copy로 인해 'fallback security principal을 가져오지 못했습니다'라는 오류 메시지가 나타나면 hosts 파일('C:\Windows\System32\drivers\etc\hosts')에 대상 상자를 추가합니다.</block>
  <block id="b7ceaa0e08e9de5bf76572a50529f752" category="paragraph">NetApp 스토리지 대상 상자 항목에 대해 다음 형식을 사용합니다.</block>
  <block id="569ccf25ad533b79cf2f639f0326d943" category="list-text">호스트 파일에 대상 상자 항목을 추가한 후에도 "오류 FAILED FAILED FAILED FAILED FALLBACK SURITY"라는 오류 메시지가 계속 표시되면 대상 시스템에 사용자/그룹이 존재하지 않는 것입니다.</block>
  <block id="4a909d1b3a171fdcddc8da070e839ecc" category="list-text">루트 폴더를 사용하거나 사용하지 않고 ACL을 사용하여 CIFS 데이터를 마이그레이션하려면 "xCP 복제본"을 사용합니다.</block>
  <block id="a4ebb620bc1fbff4f93249967cd47f4b" category="paragraph">루트 폴더가 없으면 다음 명령을 실행합니다.</block>
  <block id="f6c1a65a9150853333bf43b4a6dc9e5b" category="paragraph">루트 폴더에서 다음 명령을 실행합니다.</block>
  <block id="154ef40d43f003733406aef6be0ada62" category="inline-link-macro">다음: 모범 사례 지침 및 권장 사항</block>
  <block id="7fd167e59284838d9e36c5c99e4d2943" category="paragraph"><block ref="7fd167e59284838d9e36c5c99e4d2943" category="inline-link-macro-rx"></block></block>
  <block id="d82dd9b3245382b365106db0568113e8" category="summary">NetApp 솔루션 자동화를 통해 고객은 수많은 일반 인프라 및 애플리케이션 작업의 구축, 구성, 실행을 자동화할 수 있습니다.</block>
  <block id="a123daaac5749e4d0965aca160f0adfd" category="doc">NetApp 솔루션 자동화</block>
  <block id="d1029167179320d8b6d70b11c3d01bd3" category="list-text">Ansible 제어 노드 요구사항:</block>
  <block id="9ced761647f5d80fe615526ffff63937" category="list-text">다음 패키지가 설치된 Ubuntu/Debian 시스템:</block>
  <block id="ca60b3698dd3d27a5f91e4dc0a1a2546" category="list-text">3장</block>
  <block id="4ce3ea126bb844d4f8c4ce1a65cbe3ae" category="list-text">Pip3</block>
  <block id="881cbd1ce3fdb52f73a82f8674a2a364" category="list-text">Ansible(버전 2.10.0 이상)</block>
  <block id="0bcc70105ad279503e31fe7b3f47b665" category="list-text">기트</block>
  <block id="6e3d8a0ff7934b777031953fe936bac8" category="paragraph">위 요구 사항이 설치되지 않은 새 Ubuntu/Debian 시스템이 있는 경우 다음 단계에 따라 해당 시스템을 Ansible 제어 노드로 설정합니다.</block>
  <block id="532d3723890df934cc5c2c39477405a2" category="list-text">sh 파일을 만듭니다</block>
  <block id="e95a2c08843a70246648b7107a26cec4" category="list-text">파일에 아래 내용을 붙여 넣습니다</block>
  <block id="86c8310d98a974adb7ac7c4025dd8b5c" category="list-text">파일을 실행 파일로 만듭니다</block>
  <block id="22db3e24628482683b9bf06c38e497ee" category="list-text">스크립트를 루트로 실행합니다.</block>
  <block id="b9b07f10c0ce1735548942e3abaa3447" category="summary">이 페이지에서는 NetApp Cloud Manager를 통해 CVO 및 Cloud Manager Connector 구축에 필요한 업데이트 토큰 및 액세스/비밀 키를 수집하는 데 필요한 자세한 정보를 제공합니다.</block>
  <block id="bcc03f70ea2e77a98ddb6e8267e4892f" category="paragraph">AWX/Ansible Tower를 통해 Ansible 플레이북을 사용하여 CVO 및 커넥터의 자동 배포를 구성하려면 다음 정보가 필요합니다.</block>
  <block id="193fc1c355935356ecd5d07811792512" category="section-title">AWS에서 액세스/비밀 키 획득</block>
  <block id="60b6439418495e0d1821d169b7d4b885" category="list-text">Cloud Manager에 CVO 및 Connector를 구축하려면 AWS 액세스/암호 키가 필요합니다. IAM --&gt; 사용자 --&gt; 사용자 이름 --&gt; 보안 자격 증명 --&gt; 액세스 키 생성을 실행하여 AWS 콘솔에서 키를 획득합니다.</block>
  <block id="ad1cc06192440312813c412c9cf08bc5" category="list-text">액세스 키를 복사하여 Connector 및 CVO 구축에 사용하도록 안전하게 보관합니다.</block>
  <block id="4ba9f13f5b12512f3651d5ea2d3ffa05" category="admonition">키를 분실한 경우 다른 액세스 키를 생성하고 분실한 키를 삭제할 수 있습니다</block>
  <block id="ad35fbaef240a8ec1f43e8a0d5e15099" category="image-alt">토큰 새로 고침</block>
  <block id="89d8fe92eb33da3c73df38422c3fa73e" category="section-title">NetApp Cloud Central에서 업데이트 토큰 획득</block>
  <block id="3d7e1d21530a3a98c74b0b7484c84516" category="list-text">에서 계정 자격 증명을 사용하여 Cloud Central 계정에 로그인합니다<block ref="ddbd83acb6424bbb7fa6878eff0976a1" category="inline-link-rx"></block></block>
  <block id="a95c6d24569073e45c394bcbd6a2c0e4" category="list-text">새로 고침 토큰을 생성하고 배포를 위해 저장합니다.</block>
  <block id="ecd636681b83fa2697020594594aea14" category="section-title">클라이언트 ID를 가져오는 중입니다</block>
  <block id="2a1ed6ca97aeb484a26d6e0d625af96b" category="list-text">API 페이지에 액세스하여 에서 클라이언트 ID를 복사합니다<block ref="06324b77583872f7e211b3e7ec3f882f" category="inline-link-rx"></block>.</block>
  <block id="1093ef7993a1f3824edbf581bb54b571" category="list-text">오른쪽 위 모서리에 있는 "인증 방법 알아보기"를 클릭합니다.</block>
  <block id="622dcb1fafb9f30d36b32341e23ae7a0" category="list-text">로그인 시 사용자 이름/암호가 필요한 경우 나타나는 인증 창에서 일반 액세스에서 클라이언트 ID를 복사합니다. SSO를 사용하는 페더레이션 사용자는 "토큰 새로 고침 탭"에서 클라이언트 ID를 복사해야 합니다.</block>
  <block id="76525f0f34b48475e5ca33f71d296f3b" category="image-alt">클라이언트 ID입니다</block>
  <block id="6090065e2462d5f96ebac132568bdf46" category="section-title">AWS에서 키 쌍 획득</block>
  <block id="294b903c23e96b98876b04f51502cec4" category="list-text">AWS 콘솔에서 "키 쌍"을 검색하고 "PEM"이 있는 키 쌍을 생성합니다. KEY_PAIR의 이름을 기억하시고, 이 이름을 사용하여 커넥터를 전개해 보겠습니다.</block>
  <block id="ddb20e807acdf5ddf189dd213ff6d0cf" category="image-alt">키 쌍</block>
  <block id="3ce1d7d6e1b4509256dd2574b6b5d290" category="section-title">계정 ID를 획득하는 중입니다</block>
  <block id="8f19980a36fbde35540547e8f630c9e5" category="list-text">Cloud Manager에서 계정 -&gt; 계정 관리 를 클릭한 다음 AWX 변수에 사용할 계정 ID를 복사합니다.</block>
  <block id="5c263f30899f93ff7ccd457ad3eb956f" category="list-text">다음 패키지가 설치된 RHEL/CentOS 시스템:</block>
  <block id="7b643b0eef9cf1199195fa05b77fc3c8" category="paragraph">위의 요구사항을 설치하지 않은 새로운 RHEL/CentOS 시스템을 사용하는 경우 다음 단계를 따라 해당 시스템을 Ansible 제어 노드로 설정하십시오.</block>
  <block id="d2052f202108defaf6afc7831ba59362" category="list-text">RHEL-8/RHEL-7용 Ansible 리포지토리를 지원합니다</block>
  <block id="61fbc2f21db84f17551fda6893429d16" category="list-text">RHEL-8의 경우(아래 명령을 루트로 실행)</block>
  <block id="77cd42f765e6b40764459a64a979f90c" category="list-text">RHEL-7의 경우(아래 명령을 루트로 실행)</block>
  <block id="d78228187c1a83d3bb4d8e97cd657807" category="paragraph">자동화를 통해 NetApp 솔루션의 소비가 단순화됩니다.</block>
  <block id="90305bb6fba97091f683e8b82f9bf805" category="summary">NetApp 솔루션 자동화를 통해 고객은 많은 일반 인프라 및 애플리케이션 작업의 구축, 구성 및 실행을 자동화할 수 있습니다.</block>
  <block id="2aa17d37bd2483f97468ab7653396786" category="paragraph">이 섹션에서는 NetApp 자동화 솔루션을 사용하는 환경을 준비하기 위해 AWX/Ansible 타워에서 매개 변수를 구성하는 데 필요한 단계를 설명합니다.</block>
  <block id="0fb1db9928d7fc107d96c13f1918b639" category="list-text">Resources(리소스) → Inventory(인벤토리) → Add(추가) 로 이동하여 Add Inventory(재고 추가) 를 클릭합니다.</block>
  <block id="2623b8eb8fcaecc009c3b78cc6e7d391" category="list-text">이름 및 조직 세부 정보를 입력하고 저장 을 클릭합니다.</block>
  <block id="cc243ac3e015aef331656a4bff40241c" category="list-text">인벤토리 페이지에서 방금 만든 인벤토리 리소스를 클릭합니다.</block>
  <block id="b0ddb214e9aa4a84bc80e6af8c6b2adf" category="list-text">재고 변수가 있는 경우 변수 필드에 붙여 넣습니다.</block>
  <block id="5d7863780eab69b6b968cfc9dc6e66bc" category="list-text">그룹 하위 메뉴로 이동하여 추가 를 클릭합니다.</block>
  <block id="ec51931bb91bc912d609f2099974dfd9" category="list-text">그룹 이름을 입력하고 그룹 변수에 복사한 다음(필요한 경우) 저장 을 클릭합니다.</block>
  <block id="8f9cbdc13fdcb31ff345f10ba333ac59" category="list-text">생성된 그룹을 클릭하고 Hosts 하위 메뉴로 이동한 다음 Add New Host를 클릭합니다.</block>
  <block id="98e7a99b463b825a87899d25486e46ea" category="list-text">호스트의 호스트 이름과 IP 주소를 입력하고 필요한 경우 호스트 변수를 붙여 넣은 다음 Save(저장) 를 클릭합니다.</block>
  <block id="3caf9a56384a30eb8dee819e3abc14d6" category="list-text">자격 증명 유형을 만듭니다. ONTAP, Element, VMware 또는 기타 HTTPS 기반 전송 연결과 관련된 솔루션의 경우 자격 증명 유형을 사용자 이름 및 암호 항목과 일치하도록 구성해야 합니다.</block>
  <block id="615b6214c17105ae4915a8c8a632025b" category="list-text">Administration → Credential Types로 이동하여 Add를 클릭합니다.</block>
  <block id="846bb9303e5cc4395e96eba0d4c7d50a" category="list-text">다음 내용을 입력 구성에 붙여 넣습니다.</block>
  <block id="333a40c5632e0507a83f6a191f0b69b3" category="list-text">다음 내용을 주입기 구성에 붙여넣습니다.</block>
  <block id="e31908e83a96aee8550446309c4ef7e0" category="list-text">자격 증명을 구성합니다.</block>
  <block id="de06c7b54d4158f81a8c4d4a02b61eb0" category="list-text">Resources → Credentials 로 이동하고 Add 를 클릭합니다.</block>
  <block id="e5b5f57b6910910a3f9a486e88088608" category="list-text">올바른 자격 증명 유형을 선택합니다. 표준 SSH 로그인을 사용하려면 Machine 유형을 선택하거나 직접 생성한 사용자 지정 자격 증명 유형을 선택합니다.</block>
  <block id="9256ee926473942ba849050ef0450b7f" category="list-text">다른 해당 세부 정보를 입력하고 저장 을 클릭합니다.</block>
  <block id="29d192f714134f2e257058cfcf763722" category="list-text">프로젝트를 구성합니다.</block>
  <block id="1b892b7661c6a3ae2b57cbf4233c3af5" category="list-text">Resources → Projects 로 이동한 후 Add 를 클릭합니다.</block>
  <block id="936784ca62c93ca666e77fd10733247c" category="list-text">소스 제어 자격 증명 유형 으로 Git 를 선택합니다.</block>
  <block id="9f4fd9b4a4c75c02d1b469e8dd75d9fb" category="list-text">특정 솔루션에 해당하는 소스 제어 URL(또는 git 클론 URL)을 붙여 넣습니다.</block>
  <block id="95acbbc0424478165cdbe3a62849cbc3" category="list-text">필요한 경우 Git URL이 액세스를 제어하는 경우 소스 제어 자격 증명 에서 해당 자격 증명을 만들고 연결합니다.</block>
  <block id="a934d780fa0cb0e8495a0a1cabd0f501" category="list-text">작업 템플릿을 구성합니다.</block>
  <block id="10c610c9225adcc92ca1b284b5bbb04b" category="list-text">이름과 설명을 입력합니다.</block>
  <block id="e33edf61d02fc69c2087dcc3c42177e1" category="list-text">작업 유형을 선택합니다. Run은 Playbook을 기반으로 시스템을 구성하고 Check는 실제로 시스템을 구성하지 않고 Playbook을 건조하게 실행합니다.</block>
  <block id="57cf64ce7890d12e5a41d18b83979ffd" category="list-text">Playbook의 해당 인벤토리, 프로젝트 및 자격 증명을 선택합니다.</block>
  <block id="fc6b15b1dd73bb25477aed453b9a02f2" category="list-text">작업 템플릿의 일부로 실행할 플레이북을 선택합니다.</block>
  <block id="9a7d90740af07bcdd2c628a6f6ae966c" category="list-text">일반적으로 런타임에는 변수를 붙여 넣습니다. 따라서 런타임 중에 변수를 채우라는 프롬프트를 표시하려면 변수 필드에 해당하는 시작 시 프롬프트 확인란을 선택합니다.</block>
  <block id="3454f07e6f81a48099e0d144ca38ec7a" category="list-text">필요에 따라 다른 세부 정보를 입력하고 Save(저장) 를 클릭합니다.</block>
  <block id="0b55c84dbc04b54418b0d507f7b8f669" category="list-text">실행 시 메시지가 표시되면 변수를 입력하고 다시 시작 을 클릭합니다.</block>
  <block id="56b4cb3c337694fdafc2164dddad87fa" category="summary">GPU는 일반적으로 반복적인 산술 계산을 수행하여 그래픽 시각화(렌더링)에 사용됩니다. 이 반복적 컴퓨팅 기능은 AI 및 딥 러닝 사용 사례에 자주 사용됩니다.</block>
  <block id="ca32c5a534baaf5f6dc3e6e6fed62450" category="doc">GPU 고려 사항</block>
  <block id="ceeb28ce3b9ce753f02856fffb7ba66c" category="paragraph">그래픽 집약적 애플리케이션의 경우, Microsoft Azure는 VM당 1~4개의 GPU가 장착된 NVIDIA Tesla M60 카드 기반의 NV 시리즈를 제공합니다. 각 NVIDIA Tesla M60 카드에는 각각 8GB의 GDDR5 메모리가 탑재된 Maxwell 기반 GPU 2개가 포함되어 있습니다(총 16GB).</block>
  <block id="cb433c3099845f0ac8f3ba53d162db7b" category="admonition">NVIDIA 라이센스는 NV 시리즈에 포함됩니다.</block>
  <block id="0f0c98cc175dc7cda319a35afcd199e5" category="paragraph"><block ref="0f0c98cc175dc7cda319a35afcd199e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ead26a90008a32871b53cb37bbe8431a" category="paragraph">NetApp HCI 사용 시 H615C GPU에는 NVIDIA Tesla T4 카드 3개가 포함되어 있습니다. 각 NVIDIA Tesla T4 카드에는 16GB GDDR6 메모리가 탑재된 Touring 기반 GPU가 있습니다. VMware vSphere 환경에서 사용할 경우 가상 머신은 전용 프레임 버퍼 메모리가 있는 각 VM과 GPU를 공유할 수 있습니다. NetApp HCI H615C의 GPU에서 광선 트레이싱을 사용하여 빛 반사를 포함한 사실적인 이미지를 생성할 수 있습니다. GPU 기능에 대한 라이센스가 있는 NVIDIA 라이센스 서버가 필요합니다.</block>
  <block id="148811d448421f6a42c549400b7201c0" category="paragraph"><block ref="148811d448421f6a42c549400b7201c0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc6992cca0b3d14a85c456d0890f3e37" category="paragraph">GPU를 사용하려면 NVIDIA 라이센스 포털에서 다운로드할 수 있는 적절한 드라이버를 설치해야 합니다. Azure 환경에서는 NVIDIA 드라이버를 GPU 드라이버 확장으로 사용할 수 있습니다. 다음으로, 원격 데스크톱 서비스 세션에 GPU 하드웨어를 사용하려면 다음 스크린샷의 그룹 정책을 업데이트해야 합니다. H.264 그래픽 모드의 우선 순위를 지정하고 인코더 기능을 활성화해야 합니다.</block>
  <block id="5b0ff68b017720dd46aa6d1923fdfa95" category="paragraph"><block ref="5b0ff68b017720dd46aa6d1923fdfa95" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d7d3d3d6dd94c69620cd3edfb005691c" category="paragraph">WebGL 샘플을 실행할 때 작업 관리자 또는 NVIDIA-SMI CLI를 사용하여 GPU 성능 모니터링을 검증합니다. GPU, 메모리 및 인코더 리소스가 사용되고 있는지 확인합니다.</block>
  <block id="d13ca37d387c1bb473c0343278d0477d" category="paragraph"><block ref="d13ca37d387c1bb473c0343278d0477d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f2b53ac98ef55a900849ead654ca636" category="paragraph">가상 데스크톱 서비스를 통해 NetApp HCI H615C에 가상 머신을 배포하려면 H615C 호스트가 있는 vCenter 클러스터 리소스를 사용하여 사이트를 정의합니다. VM 템플릿에는 필요한 vGPU 프로필이 첨부되어 있어야 합니다.</block>
  <block id="818fad61fba48977b2293819f37e950a" category="paragraph">공유 다중 세션 환경의 경우 여러 동종 vGPU 프로필을 할당하는 것이 좋습니다. 하지만 고급 전문가용 그래픽 애플리케이션의 경우 각 VM을 격리하도록 사용자 전용으로 유지하는 것이 더 좋습니다.</block>
  <block id="a2db30df8af33b0e661aaed00ce2c1d3" category="paragraph">GPU 프로세서는 QoS 정책에 따라 제어할 수 있으며, 각 vGPU 프로필은 전용 프레임 버퍼를 가질 수 있습니다. 그러나 인코더 및 디코더는 각 카드에 대해 공유됩니다. GPU 카드에 vGPU 프로필을 배치하는 작업은 vSphere 호스트 GPU 할당 정책에 의해 제어되며, 이는 성능(VM 분산) 또는 통합(그룹 VM)을 강조할 수 있습니다.</block>
  <block id="9411dea29d318927759a55cff454b3dd" category="inline-link-macro">다음은 업계를 위한 솔루션입니다.</block>
  <block id="ee3f381f10f3f075a22913a348a89edf" category="paragraph"><block ref="ee3f381f10f3f075a22913a348a89edf" category="inline-link-macro-rx"></block></block>
  <block id="7d37fde7375502ef1013412159477502" category="summary">NetApp은 Azure NetApp Files와의 신속한 통합을 포함하여 WVD 또는 원격 애플리케이션을 사용한 가상 데스크톱의 빠른 프로비저닝을 포함하여 많은 클라우드 서비스를 제공합니다.</block>
  <block id="28850fd0c108cc5f990fc4b4b52ab60d" category="doc">NetApp 가상 데스크톱 서비스 개요</block>
  <block id="c70675dc3857ae45ab2475f60c0f1f85" category="paragraph">NetApp은 WVD 또는 원격 애플리케이션을 사용한 가상 데스크톱의 빠른 프로비저닝, Azure NetApp Files과의 신속한 통합을 포함하여 다양한 클라우드 서비스를 제공합니다.</block>
  <block id="8b32dee3fc7d9223248420cb828c5527" category="paragraph">기존에는 고객에게 원격 데스크톱 서비스를 제공하고 제공하는 데 몇 주가 소요되었습니다. 프로비저닝 외에도 애플리케이션, 사용자 프로필, 공유 데이터 및 그룹 정책 객체를 관리하는 것이 어려워 정책을 적용하기가 어려울 수 있습니다. 방화벽 규칙은 복잡성을 높이고 별도의 기술 집합 및 도구가 필요합니다.</block>
  <block id="0276a1f5f692f2e9635f3733b371cf70" category="paragraph">Microsoft Azure Windows Virtual Desktop 서비스를 통해 Microsoft는 원격 데스크톱 서비스 구성 요소에 대한 유지 관리를 수행하므로 고객은 클라우드에서 작업 공간을 프로비저닝하는 데 집중할 수 있습니다. 고객은 VDI 환경을 관리하기 위한 특별한 기술이 필요한 전체 스택을 프로비저닝하고 관리해야 합니다.</block>
  <block id="51db16f7b26a08952beb43836ad3f31d" category="paragraph">NetApp VDS를 사용할 경우 고객은 브로커, 게이트웨이, 에이전트 등과 같은 아키텍처 구성 요소를 설치할 위치를 걱정하지 않고 가상 데스크톱을 빠르게 구축할 수 있습니다. 환경을 완벽하게 제어해야 하는 고객은 프로페셔널 서비스 팀과 협력하여 목표를 달성할 수 있습니다. 고객은 VDS를 서비스로 소비하므로 주요 비즈니스 과제에 집중할 수 있습니다.</block>
  <block id="139562ef7df2deed82d586ebe297a082" category="paragraph">NetApp VDS는 AWS, Azure, GCP 또는 프라이빗 클라우드 환경에서 다중 배포를 중앙에서 관리할 수 있는 서비스형 소프트웨어 오퍼링입니다. Microsoft Windows Virtual Desktop은 Microsoft Azure에서만 사용할 수 있습니다. NetApp VDS는 다른 환경에서 Microsoft 원격 데스크톱 서비스를 조정합니다.</block>
  <block id="fd9a0083b0a0e084ce6fb8d2ca64272f" category="paragraph">Microsoft는 Azure에서 Windows Virtual Desktop 환경에서만 Windows 10에 대한 다중 세션을 제공합니다. 인증 및 ID는 가상 데스크톱 기술에 의해 처리됩니다. WVD는 Active Directory와 동기화된 Azure Active Directory(AD Connect 포함) 및 Active Directory에 연결된 세션 VM이 필요합니다. RDS에는 사용자 ID 및 인증과 VM 도메인 연결 및 관리를 위한 Active Directory가 필요합니다.</block>
  <block id="416feb9f77def2ffedaab40a538d47e5" category="paragraph">다음 그림에 샘플 구축 토폴로지가 나와 있습니다.</block>
  <block id="e377917f3505cdb9fc72b74164df5928" category="paragraph"><block ref="e377917f3505cdb9fc72b74164df5928" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d271ca257d56879fcc9ed95d82aabaa7" category="paragraph">각 배포는 Active Directory 도메인과 연결되며 작업 영역 및 응용 프로그램에 대한 액세스 진입점을 클라이언트에 제공합니다. Active Directory 도메인이 여러 개인 서비스 공급자 또는 엔터프라이즈에는 일반적으로 더 많은 구축이 있습니다. 여러 지역에 걸쳐 있는 단일 Active Directory 도메인에는 일반적으로 여러 사이트를 포함하는 단일 배포가 있습니다.</block>
  <block id="9ea3c4f34057d91531ae286e3efe62c3" category="paragraph">Azure의 WVD에 대해 Microsoft는 NetApp VDS에서 소비되는 서비스형 플랫폼을 제공합니다. 다른 환경의 경우 NetApp VDS가 Microsoft 원격 데스크톱 서비스의 구현 및 구성을 조정합니다. NetApp VDS는 WVD Classic 및 WVD 암을 모두 지원하며 기존 버전을 업그레이드할 때에도 사용할 수 있습니다.</block>
  <block id="3e8cd47ad0ab71d0b3891f85212ccdbc" category="paragraph">각 배포에는 Cloud Workspace Manager(REST API 엔드포인트), HTML 5 게이트웨이(VDS 관리 포털에서 VM에 연결), RDS 게이트웨이(클라이언트의 액세스 지점) 및 도메인 컨트롤러로 구성된 자체 플랫폼 서비스가 있습니다. 다음 그림은 RDS 구현을 위한 VDS Control Plane 아키텍처를 보여 줍니다.</block>
  <block id="38606818aeffd06d174e51013afc23a1" category="paragraph"><block ref="38606818aeffd06d174e51013afc23a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e58cad6a2c8c8ff1a585bf8d6ca94560" category="paragraph">RDS 구현의 경우 NetApp VDS는 고객 로고 및 이미지를 포함하도록 커스터마이징할 수 있는 클라이언트 소프트웨어를 사용하여 Windows 및 브라우저에서 쉽게 액세스할 수 있습니다. 사용자 자격 증명을 기반으로 승인된 작업 공간 및 애플리케이션에 대한 사용자 액세스를 제공합니다. 게이트웨이 세부 정보를 구성할 필요가 없습니다.</block>
  <block id="c2dcf4d443be38a737d1e580fb4b86ec" category="paragraph">다음 그림은 NetApp VDS 클라이언트를 보여 줍니다.</block>
  <block id="8e7d56f1d99fdc8080a747bf8b1eda75" category="paragraph"><block ref="8e7d56f1d99fdc8080a747bf8b1eda75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71110c8ffc8b198bc951f6e587fbcddf" category="paragraph">Azure WVD 구현에서 Microsoft는 클라이언트의 액세스 진입점을 처리하며 다양한 OS에 기본적으로 제공되는 Microsoft WVD 클라이언트에서 사용할 수 있습니다. 웹 기반 포털에서 액세스할 수도 있습니다. 클라이언트 소프트웨어의 구성은 GPO(그룹 정책 개체)나 고객이 선호하는 다른 방법으로 처리해야 합니다.</block>
  <block id="9e4318c1c6ae62544ba67e7c0fe55649" category="paragraph">다음 그림은 Azure WVD 구현을 위한 VDS Control Plane 아키텍처를 보여 줍니다.</block>
  <block id="ba9e4c82a95db68279bffa8ca8a8803f" category="paragraph"><block ref="ba9e4c82a95db68279bffa8ca8a8803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d648a5d4acf66674fb86cc7be05bd5e" category="paragraph">NetApp VDS는 필요한 구성 요소의 배포 및 구성 외에도 사용자 관리, 응용 프로그램 관리, 리소스 확장 및 최적화를 처리합니다.</block>
  <block id="3ea30729e0e7f0d666400ccc1a6f7bc3" category="paragraph">NetApp VDS는 사용자를 생성하거나 기존 사용자 계정에 클라우드 작업 공간 또는 응용 프로그램 서비스에 대한 액세스 권한을 부여할 수 있습니다. 이 포털은 암호 재설정 및 구성 요소 하위 집합 관리 위임에도 사용할 수 있습니다. 헬프데스크 관리자 또는 레벨 3 기술자는 문제 해결을 위해 사용자 세션을 섀도잉하거나 포털 내에서 서버에 연결할 수 있습니다.</block>
  <block id="061d5215d4dd8b8e2b7d9f2498a4a8c3" category="paragraph">NetApp VDS는 사용자가 만든 이미지 템플릿을 사용하거나 클라우드 기반 프로비저닝을 위해 시장에서 기존 템플릿을 사용할 수 있습니다. 관리할 이미지 수를 줄이려면 기본 이미지를 사용할 수 있으며, 필요한 추가 응용 프로그램을 제공된 프레임워크를 사용하여 쇼콜라티, MSIX 앱 연결, PowerShell 등과 같은 명령줄 도구를 포함하도록 프로비저닝할 수 있습니다. 사용자 정의 스크립트도 기계 수명 주기 이벤트의 일부로 사용할 수 있습니다.</block>
  <block id="91d75bd7e517ef4b563021e6d23d8cb9" category="inline-link-macro">다음: NetApp HCI 개요</block>
  <block id="3806ab54895f78b6c34b626314f84e6e" category="paragraph"><block ref="3806ab54895f78b6c34b626314f84e6e" category="inline-link-macro-rx"></block></block>
  <block id="a3af49b9146a6a36e8bea4c525797782" category="summary">이 페이지에서는 DCConfig Tool, TestVdc Tools 및 로그 파일에 대해 설명합니다.</block>
  <block id="d56ee3058d1c4ab634cd3e1e606f2064" category="doc">도구 및 로그</block>
  <block id="626b1761e15913fc6f955e1d76a0ac10" category="section-title">DCConfig 도구</block>
  <block id="65bbb1c25836b86f699bd2141a545958" category="paragraph">DCCconfig 도구는 사이트를 추가하기 위해 다음과 같은 하이퍼바이저 옵션을 지원합니다.</block>
  <block id="2c76e52255da65e5fcf88143f91aa431" category="paragraph"><block ref="2c76e52255da65e5fcf88143f91aa431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da2595b668536baaea606e674ade5181" category="paragraph"><block ref="da2595b668536baaea606e674ade5181" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2eb34c5311117b56d2c8eb33494052a3" category="paragraph">공유 데이터에 대한 작업 영역별 드라이브 문자 매핑은 GPO를 사용하여 처리할 수 있습니다. Professional Services 또는 지원 팀은 고급 탭을 사용하여 Active Directory OU 이름, FSLogix 배포를 설정하거나 해제하는 옵션, 다양한 시간 초과 값 등의 설정을 사용자 지정할 수 있습니다.</block>
  <block id="8688a5dde644921ea673f5bc2dde55c3" category="paragraph"><block ref="8688a5dde644921ea673f5bc2dde55c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6c93f3609bb3be799ed32b6a601d5fc" category="section-title">Command Center(이전 테스트 VDC 도구)</block>
  <block id="46433f623976c5af8ebdc7ab92816a48" category="inline-link-macro">Command Center 개요</block>
  <block id="bf69b43c185864d35a461d8f1c3ea56e" category="paragraph">Command Center 및 필요한 역할을 시작하려면 을 참조하십시오 <block ref="d7ce3bd63a8a34b9b1630abb82acb951" category="inline-link-macro-rx"></block>.</block>
  <block id="b425cca2998cc4a7041a0baf7681e912" category="paragraph">다음 작업을 수행할 수 있습니다.</block>
  <block id="b462233b13790bce7e4c6449d02cf930" category="list-text">작업 영역의 SMB 경로를 변경합니다.</block>
  <block id="ee347a7998de9774369e6853f1ed7bcc" category="paragraph"><block ref="ee347a7998de9774369e6853f1ed7bcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c524c01ee30f2f1597bb3e90c721dd8c" category="list-text">컬렉션 프로비저닝을 위해 사이트를 변경합니다.</block>
  <block id="ccb9931a262a0b169576103526fa2ab2" category="paragraph"><block ref="ccb9931a262a0b169576103526fa2ab2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="af6ba12de0b8c93d5f768c83143c7d99" category="section-title">로그 파일</block>
  <block id="017b9aa293da801da252c728736f02db" category="inline-link-macro">자동화 로그</block>
  <block id="580acc766c3f0e464b462d271028dc32" category="paragraph"><block ref="5f6615a18cd0f2f0bcfb7578db5d1c9e" category="inline-image-macro-rx" type="image"></block>확인합니다 <block ref="11597d7347faee3da56e0e01d5ba1de2" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="881784d32d0ec795e6fd477e7c0fe8f7" category="paragraph"><block ref="881784d32d0ec795e6fd477e7c0fe8f7" category="inline-link-macro-rx"></block></block>
  <block id="7b0f97bc4856c6b0645650d13b53acb5" category="summary">사내 리소스와 클라우드 리소스 간에 연결이 존재하는 경우 NetApp Virtual Desktop Service를 온프레미스로 확장할 수 있습니다. 엔터프라이즈는 Express Route 또는 사이트 간 IPsec VPN 연결을 사용하여 Microsoft Azure에 대한 링크를 설정할 수 있습니다. 전용 링크를 사용하거나 IPsec VPN 터널을 사용하여 다른 클라우드에 대한 링크를 만들 수도 있습니다.</block>
  <block id="995d0ae58fc48c0007c3a45046221736" category="doc">하이브리드 클라우드 환경</block>
  <block id="610e3513c7222cae8d2a7c450741211a" category="paragraph">솔루션 검증을 위해 다음 그림에 나와 있는 환경을 사용했습니다.</block>
  <block id="0d9e9a129d4eb3389af12248eb017ef1" category="paragraph"><block ref="0d9e9a129d4eb3389af12248eb017ef1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60ca94382604fd3deb8a198feed31f1b" category="paragraph">사내에서 관리, 원격 데스크톱 세션 호스트 등을 위해 여러 VLAN을 구성했습니다. 172.21.146-150.0/24 서브넷에 있었으며 Microsoft 원격 라우팅 액세스 서비스를 사용하여 회사 네트워크로 라우팅되었습니다. 또한 다음 작업도 수행했습니다.</block>
  <block id="b613a58cb27d96b09550b74a616e43d8" category="list-text">Microsoft 라우팅 및 원격 액세스 서버(RRAS, IPchicken.com 식별)의 공용 IP를 확인했습니다.</block>
  <block id="b0aa9d967a62cfeb9427c31c3968fb31" category="list-text">Azure Subscription에 가상 네트워크 게이트웨이 리소스(경로 기반 VPN)를 만들었습니다.</block>
  <block id="2db3e884a3b1d82162c06df081b8e8f0" category="list-text">Microsoft RRAS 서버의 공용 IP에 대한 로컬 네트워크 게이트웨이 주소를 제공하는 연결을 만들었습니다.</block>
  <block id="ac7b5e31749488bdca809cc69e83bcec" category="list-text">RRAS에서 VPN 구성을 완료하여 VPN 게이트웨이를 만드는 동안 제공된 사전 공유 인증을 사용하여 가상 인터페이스를 만들었습니다. 올바르게 구성된 경우 VPN은 연결됨 상태여야 합니다. Microsoft RRAS 대신 pfSense 또는 기타 관련 도구를 사용하여 사이트 간 IPsec VPN 터널을 만들 수도 있습니다. 이 터널은 경로 기반이므로, 구성된 특정 서브넷에 따라 트래픽을 리디렉션합니다.</block>
  <block id="064b2713bd54ad7c04715d629ea8d77e" category="paragraph">Microsoft Azure Active Directory는 OAuth를 기반으로 ID 인증을 제공합니다. 엔터프라이즈 클라이언트 인증에는 일반적으로 NTLM 또는 Kerberos 기반 인증이 필요합니다. Microsoft Azure Active Directory 도메인 서비스는 ADConnect를 사용하여 Azure Active Directory와 사내 도메인 컨트롤러 간에 암호 해시 동기화를 수행합니다.</block>
  <block id="c9ced395d02e614104c13dc687b8d960" category="paragraph">이 하이브리드 VDS 솔루션 검증을 위해 NetApp은 처음에 Microsoft Azure에 구축되었고 vSphere에 추가 사이트를 추가했습니다. 이 접근 방식의 장점은 플랫폼 서비스가 Microsoft Azure에 배포되어 포털을 통해 즉시 백업된다는 것입니다. 사이트 사이트 사이트 VPN 링크가 다운된 경우에도 어디서나 서비스에 쉽게 액세스할 수 있습니다.</block>
  <block id="759e5787427ba679d146727a04400c46" category="paragraph">다른 사이트를 추가하기 위해 DCConfig라는 도구를 사용했습니다. 해당 애플리케이션의 바로 가기는 클라우드 작업 공간 관리자(CWMgr) VM의 데스크톱에서 사용할 수 있습니다. 이 응용 프로그램을 시작한 후 데이터센터 사이트 탭으로 이동하여 새 데이터센터 사이트를 추가하고 아래 표시된 대로 필요한 정보를 입력합니다. URL이 vCenter IP를 가리킵니다. 구성을 추가하기 전에 CWMgr VM이 vCenter와 통신할 수 있는지 확인합니다.</block>
  <block id="ae5bd963078c278284e2aabaefb99232" category="admonition">VMware vSphere 환경과의 통신을 활성화하려면 CloudWorkspace Manager에 vSphere PowerCLI 5.1이 설치되어 있어야 합니다.</block>
  <block id="e0072a2f037098ba3ee9ec9e1113f1ee" category="paragraph">다음 그림에서는 사내 데이터 센터 사이트 구성을 보여 줍니다.</block>
  <block id="30efb5f8dd999c0f737bf30327346d6f" category="paragraph"><block ref="30efb5f8dd999c0f737bf30327346d6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f823fddfaa31c0b2b910c651849fe1e0" category="paragraph">특정 클러스터, 호스트 이름 또는 사용 가능한 RAM 공간을 기반으로 컴퓨팅 리소스에 사용할 수 있는 필터링 옵션이 있습니다. 스토리지 리소스의 필터링 옵션에는 데이터 저장소의 최소 여유 공간 또는 데이터 저장소당 최대 VM이 포함됩니다. 정규식을 사용하여 데이터 저장소를 제외할 수 있습니다. 저장 버튼을 클릭하여 구성을 저장합니다.</block>
  <block id="40cf95c01dfbdb8adc110507697330bf" category="paragraph">구성을 검증하려면 테스트 버튼을 클릭하거나 하이퍼바이저 로드 를 클릭하고 vSphere 섹션 아래의 드롭다운을 선택합니다. 적절한 값으로 채워야 합니다. 기본 프로비저닝 사이트에 대해 기본 하이퍼바이저를 yes로 설정하는 것이 가장 좋습니다.</block>
  <block id="b081b97ab471a870119bb85e196c0d63" category="paragraph">VMware vSphere에서 생성된 VM 템플릿은 VDS에서 프로비저닝 컬렉션으로 사용됩니다. 프로비저닝 컬렉션은 공유 및 VDI의 두 가지 형태로 제공됩니다. 공유 프로비저닝 수집 유형은 모든 서버에 단일 리소스 정책이 적용되는 원격 데스크톱 서비스에 사용됩니다. VDI 유형은 리소스 정책이 개별적으로 할당된 WVD 인스턴스에 사용됩니다. 프로비저닝 컬렉션의 서버에는 다음 세 가지 역할 중 하나를 할당할 수 있습니다.</block>
  <block id="9a0b479d2d7eaed435c14e20818841d9" category="list-text">* TSDATA. * 터미널 서비스와 데이터 서버 역할의 조합.</block>
  <block id="286b69ba39f77189135fbf4c39786e12" category="list-text">* TS. * 터미널 서비스(세션 호스트)</block>
  <block id="0b39ab3df8d28606b4bb8f5891022692" category="list-text">데이터. * 파일 서버 또는 데이터베이스 서버. 서버 역할을 정의할 때는 VM 템플릿 및 스토리지(데이터 저장소)를 선택해야 합니다. 선택한 데이터 저장소를 특정 데이터 저장소로 제한하거나 데이터 사용량을 기준으로 데이터 저장소를 선택하는 최소 사용 옵션을 사용할 수 있습니다.</block>
  <block id="fb89cc64fafb0e1626269bc00c07ae73" category="paragraph">각 배포에는 활성 사용자, 고정, 서버 로드 또는 사용자 수를 기준으로 클라우드 리소스 할당에 대한 VM 리소스 기본값이 있습니다.</block>
  <block id="d00f03f39f8119980cb5240353d345b1" category="inline-link-macro">다음: Login VSI를 사용한 단일 서버 로드 테스트</block>
  <block id="af5c949297d5415f4710bd1af3f1e7a7" category="paragraph"><block ref="af5c949297d5415f4710bd1af3f1e7a7" category="inline-link-macro-rx"></block></block>
  <block id="0581202e42d61d6dfe4875c70d00cdac" category="summary">NetApp 가상 데스크톱 서비스는 비즈니스 과제를 해결하기 위해 가상 데스크톱과 애플리케이션 환경을 손쉽게 제공합니다. VDS를 NetApp HCI로 확장하여 인라인 중복제거, 컴팩션, 씬 프로비저닝 및 압축을 비롯한 VDS 환경에서 강력한 NetApp 기능을 사용할 수 있습니다.</block>
  <block id="33491606222aecbfbdfa3fc8f13ffded" category="paragraph">NetApp 가상 데스크톱 서비스는 비즈니스 과제를 해결하기 위해 가상 데스크톱과 애플리케이션 환경을 손쉽게 제공합니다. VDS 환경을 온프레미스 ONTAP 환경으로 확장하여 VDS 환경에서 빠른 복제, 인라인 중복제거, 컴팩션, 씬 프로비저닝 등 강력한 NetApp 기능을 사용할 수 있습니다. 제공합니다. 이러한 기능으로 All-Flash 스토리지를 통해 스토리지 비용을 절감하고 성능을 향상할 수 있습니다. VMware vSphere 하이퍼바이저를 사용하면 가상 볼륨 및 vSphere API for Array 통합을 통해 서버 프로비저닝 시간을 최소화할 수 있습니다. 고객은 하이브리드 클라우드를 사용하여 까다로운 워크로드에 적합한 환경을 선택하고 비용을 절감할 수 있습니다. 온-프레미스를 실행하는 데스크톱 세션은 정책에 따라 클라우드 리소스에 액세스할 수 있습니다.</block>
  <block id="df6f0981c6f92ef3adb9059f5b387e4a" category="paragraph"><block ref="df6f0981c6f92ef3adb9059f5b387e4a" category="inline-link-macro-rx"></block></block>
  <block id="48a2bc9c10adbea95074594015793272" category="summary">작업 공간은 온프레미스 또는 모든 지원 클라우드 환경에서 호스팅되는 원격 데스크톱 세션을 공유할 수 있는 데스크톱 환경으로 구성되어 있습니다. Microsoft Azure를 사용하면 Windows Virtual Desktops에서 데스크톱 환경을 영구적으로 구축할 수 있습니다. 각 작업 영역은 특정 조직 또는 클라이언트와 연결됩니다.</block>
  <block id="1da2374b50f497e208c8dab11e6b2c98" category="doc">작업 영역 관리</block>
  <block id="fb67e63246489555a7e8929a138ced4c" category="paragraph">작업 공간은 데스크톱 환경으로 구성되며, 온프레미스 또는 지원되는 클라우드 환경에서 호스팅되는 원격 데스크톱 세션을 공유할 수 있습니다. Microsoft Azure를 사용하면 Windows Virtual Desktops에서 데스크톱 환경을 영구적으로 구축할 수 있습니다. 각 작업 영역은 특정 조직 또는 클라이언트와 연결됩니다. 새 작업 영역을 만들 때 사용할 수 있는 옵션은 다음 그림에 나와 있습니다.</block>
  <block id="42a6c6312ce8b92836d9e74d89998e89" category="paragraph"><block ref="42a6c6312ce8b92836d9e74d89998e89" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d49083c2604eac2881e01b4acea428e" category="admonition">각 작업 영역은 특정 배포와 연결됩니다.</block>
  <block id="2a1fdca12b05c0f5292a8670b24cb478" category="paragraph">작업 영역에는 관련 앱 및 앱 서비스, 공유 데이터 폴더, 서버 및 WVD 인스턴스가 포함됩니다. 각 작업 영역은 암호 복잡성 적용, 다단계 인증, 파일 감사 등과 같은 보안 옵션을 제어할 수 있습니다.</block>
  <block id="f29490b04a344e19674ee8d1db337d14" category="paragraph">작업 영역은 추가 서버의 전원을 켜거나, 서버당 사용자 수를 제한하거나, 특정 기간(항상 켜짐/꺼짐)에 사용 가능한 리소스에 대한 일정을 설정할 수 있는 작업 부하 일정을 제어할 수 있습니다. 필요에 따라 리소스를 구성할 수도 있습니다.</block>
  <block id="5a70681d968007936b9d092ba1a93313" category="paragraph">필요한 경우 작업 공간에서 배포 VM 리소스 기본값을 재정의할 수 있습니다. WVD, WVD 호스트 풀(세션 호스트 및 앱 그룹 포함) 및 WVD 작업 공간은 클라우드 작업 공간 관리 제품군 포털에서 관리할 수도 있습니다. WVD 호스트 풀에 대한 자세한 내용은 다음을 참조하십시오<block ref="283c24f69dac0d05b60b041138870b19" category="inline-link-rx"></block>.</block>
  <block id="ff13351bb4dc0c877064ec1672d6723f" category="inline-link-macro">다음: 애플리케이션 관리</block>
  <block id="bb974af58c318849f0fce8f7c3ecdf37" category="paragraph"><block ref="bb974af58c318849f0fce8f7c3ecdf37" category="inline-link-macro-rx"></block></block>
  <block id="868ab86f19065016e9a2f077c5ec1ede" category="summary">작업 작업자는 사용 가능한 응용 프로그램 목록에서 응용 프로그램을 빠르게 시작할 수 있습니다. 앱 서비스는 원격 데스크톱 서비스 세션 호스트에서 애플리케이션을 게시합니다. WVD를 통해 앱 그룹은 다중 세션 Windows 10 호스트 풀에서 유사한 기능을 제공합니다.</block>
  <block id="c775b248c55d253008c58d1ecd60e66f" category="doc">EUC(End User Computing)/VDI(Virtual Desktop Infrastructure) 솔루션</block>
  <block id="599725d881295777d3740ac33e953ced" category="paragraph">온프레미스 또는 클라우드에서 가상 데스크톱을 구축하려는 경우 NetApp은 다양한 EUC/VDI 솔루션을 통해 고객의 요구사항을 해결할 수 있습니다.</block>
  <block id="75fc33fcc3ef968fd3bf30c8da19bf9b" category="section-title">NetApp VDS(가상 데스크톱 서비스)</block>
  <block id="0593c3151fa252cdb4e997dd1255c608" category="paragraph">NetApp VDS(가상 데스크톱 서비스)는 주요 퍼블릭 클라우드 및 프라이빗 클라우드에서 RDS(원격 데스크톱 서비스)를 조정합니다.</block>
  <block id="3b96d802308faf1d6ff7e5563ea3d29b" category="paragraph">VDS에 사용 가능한 솔루션:</block>
  <block id="dede82866780d163734b443c5f4d484e" category="inline-link-macro">NetApp 가상 데스크톱 서비스 기반의 하이브리드 클라우드 VDI</block>
  <block id="2ccf8775db4706ac42c0a600eca82163" category="list-text"><block ref="2ccf8775db4706ac42c0a600eca82163" category="inline-link-macro-rx"></block></block>
  <block id="d4a0768ddf4ac449658ace06000fa76e" category="section-title">VMware Horizon을 통한 최종 사용자 컴퓨팅</block>
  <block id="959f3d9cc20e0e9bfbc01c2d36cdc894" category="paragraph">NetApp은 다양한 컴퓨팅 구성을 포괄하는 VMware Horizon용 아키텍처를 검증했습니다. 사용 가능한 솔루션은 다음과 같습니다.</block>
  <block id="3acc5e85d752378c6f1b9154f379b475" category="inline-link-macro">VMware를 통한 최종 사용자 컴퓨팅(설계 가이드)</block>
  <block id="01606c27121f18cf231b4700ddf252e1" category="list-text"><block ref="01606c27121f18cf231b4700ddf252e1" category="inline-link-macro-rx"></block></block>
  <block id="87e25a8d0e462ac8d7158e587f376605" category="inline-link-macro">VMware 및 NVIDIA GPU를 이용하는 최종 사용자 컴퓨팅(설계 가이드)</block>
  <block id="4e5b466ff852e362d888b555cdcf62b7" category="list-text"><block ref="4e5b466ff852e362d888b555cdcf62b7" category="inline-link-macro-rx"></block></block>
  <block id="d840a196af6c9e07c3ac3b20b15fb724" category="inline-link-macro">VMware 및 NVIDIA GPU를 이용하는 최종 사용자 컴퓨팅(구축 가이드)</block>
  <block id="06e0780100d16763670aed1df8526b2e" category="list-text"><block ref="06e0780100d16763670aed1df8526b2e" category="inline-link-macro-rx"></block></block>
  <block id="f93781578174ca3309bd3ac126884af4" category="inline-link-macro">3D 그래픽용 VMware를 통한 최종 사용자 컴퓨팅</block>
  <block id="128fc080215971e783f68c8be31bd85d" category="list-text"><block ref="128fc080215971e783f68c8be31bd85d" category="inline-link-macro-rx"></block></block>
  <block id="18dbdef148da0fb68861cf1b6aeeeb40" category="summary">서비스 공급자와 엔터프라이즈 가상 데스크톱 관리자는 NetApp VDS가 포함된 하이브리드 VDI를 통해 사용자에게 영향을 주지 않으면서 리소스를 다른 클라우드 환경으로 쉽게 확장할 수 있습니다. NetApp HCI에 사내 리소스가 있다면 GPU 리소스를 더 효과적으로 제어할 수 있으며, 필요에 따라 컴퓨팅 또는 스토리지 노드를 확장할 수 있습니다.</block>
  <block id="0fe8a299bf61a0d1bbca5d975dc94fcc" category="paragraph">서비스 공급자와 엔터프라이즈 가상 데스크톱 관리자는 NetApp VDS가 포함된 하이브리드 VDI를 통해 사용자에게 영향을 주지 않으면서 리소스를 다른 클라우드 환경으로 쉽게 확장할 수 있습니다. 사내 리소스의 효율적인 제어를 통해 리소스를 더욱 효율적으로 관리하고 다양한 선택 옵션(컴퓨팅, GPU, 스토리지, 네트워크)을 제공하여 요구사항을 충족할 수 있습니다.</block>
  <block id="f9bfa55b1c8ab8884a1452fa3c9cb975" category="list-text">클라우드 환경으로 전환하여 원격 데스크톱 및 애플리케이션에 대한 수요 급증</block>
  <block id="6b53dc409ecc50a533e93345ddf1f2ee" category="list-text">플래시 스토리지 및 GPU 리소스로 사내에서 원격 데스크톱 및 애플리케이션을 호스팅하여 장시간 실행되는 동안 TCO 절감</block>
  <block id="f1de7e15d0b0c3caaafa1a47204338c7" category="list-text">클라우드 환경 전반에서 원격 데스크톱 및 애플리케이션의 관리 용이성</block>
  <block id="f9ce5b54f5428c82364a39f17156cc4f" category="list-text">사내 리소스와 함께 서비스형 소프트웨어 모델을 사용하여 원격 데스크톱 및 애플리케이션을 경험해 보십시오</block>
  <block id="675ee473db5bbe3911c19a4e43f8ec3f" category="list-text">하이브리드 VDS의 요구사항을 이해하려는 EUC/VDI 설계자</block>
  <block id="a7f381741a2ff77b61bc4b7bc2e3d04f" category="list-text">원격 데스크톱 및 애플리케이션 요구를 지원하는 NetApp 파트너</block>
  <block id="efa648658230830c2b9ac1a0647002d7" category="list-text">원격 데스크톱 및 애플리케이션 요구를 해결하려는 기존 NetApp HCI 고객</block>
  <block id="2fa4089eb34d18d2b64eaab8eed9692d" category="inline-link-macro">다음으로, NetApp 가상 데스크탑 서비스 개요를 살펴보겠습니다</block>
  <block id="bf817f81e35d1d9f2620def86f22dcc3" category="paragraph"><block ref="bf817f81e35d1d9f2620def86f22dcc3" category="inline-link-macro-rx"></block></block>
  <block id="0ccea8702c360d2d159b0e8477fe81d6" category="summary">H610C 또는 H615C를 사용하는 경우 라이센스를 재판매할 수 있는 NVIDIA 파트너로부터 GPU 라이센스를 구입해야 합니다.</block>
  <block id="1f26c520bd4eba393348dedea38da7b7" category="doc">NVIDIA 라이센싱</block>
  <block id="b548ee560d6fa4ee980d777df0300d09" category="inline-link">파트너 로케이터</block>
  <block id="72d760f4e8266e660fa7126e42f63bbe" category="paragraph">H610C 또는 H615C를 사용하는 경우 라이센스를 재판매할 수 있는 NVIDIA 파트너로부터 GPU 라이센스를 구입해야 합니다. NVIDIA 파트너는 을(를) 통해 확인할 수 있습니다<block ref="32da44153625c96a28e5bf10161bbc42" category="inline-link-rx"></block>. 가상 GPU(vGPU) 또는 Tesla와 같은 역량을 검색합니다.</block>
  <block id="7709fb92e99b3458d440c5212792a0de" category="paragraph">NVIDIA vGPU 소프트웨어는 다음 4가지 버전으로 제공됩니다.</block>
  <block id="31473f257c4cfabfcba0c506fefcf4ca" category="list-text">NVIDIA GRID Virtual PC(GRID vPC)</block>
  <block id="75cc5be2167cc23ca9d32aa78a164907" category="list-text">NVIDIA GRID 가상 애플리케이션(GRID vApp)</block>
  <block id="53b933a69a5adecaa6c8c8817d2d87a5" category="list-text">NVIDIA Quadro 가상 데이터 센터 워크스테이션(Quadro vDWS)</block>
  <block id="2d655109b3aad5a539482617b4aa3b6b" category="list-text">NVIDIA 가상 컴퓨팅 서버(vComputeServer)</block>
  <block id="38f26d9fb2d58dd577140e84010a059d" category="section-title">그리드 가상 PC</block>
  <block id="e43876de331b666ca7fd1c7bbb8a844d" category="paragraph">이 제품은 Microsoft Windows 응용 프로그램, 브라우저, 고화질 비디오 및 다중 모니터 지원을 위한 뛰어난 사용자 환경을 제공하는 가상 데스크톱을 원하는 사용자에게 적합합니다. NVIDIA GRID Virtual PC는 가상 환경에서 기본 경험을 제공하여 모든 PC 애플리케이션을 최대 성능으로 실행할 수 있도록 지원합니다.</block>
  <block id="06a4851adc711a27ef53d0577d69e210" category="section-title">그리드 가상 애플리케이션</block>
  <block id="2c20bf668630521a8f76995b0c04c398" category="paragraph">Grid vApps는 RDSH(Remote Desktop Session Host) 또는 기타 애플리케이션 스트리밍 또는 세션 기반 솔루션을 배포하는 조직을 위한 것입니다. Microsoft Windows 응용 프로그램을 최대 성능으로 제공하도록 설계된 Windows Server 호스팅 RDSH 데스크톱은 GRID vApp에서도 지원됩니다.</block>
  <block id="5de115addc6579e1d30075a2a92c9ae7" category="section-title">Quadro 가상 데이터 센터 워크스테이션</block>
  <block id="74fec534073fb87750193748093ada5a" category="paragraph">이 에디션은 Dassault CATIA, SOLIDWORKS, 3Dexeite, Siemens NX, PTC Creo, Schlumberger Petrel 또는 Autodesk Maya. NVIDIA Quadro vDWS를 사용하면 사용자는 모든 장치에서 모든 기능과 성능을 갖춘 전문가용 그래픽 응용 프로그램에 액세스할 수 있습니다.</block>
  <block id="fb5cc5533386fd1b00e6b986dec8cba1" category="section-title">NVIDIA 가상 컴퓨팅 서버</block>
  <block id="087877c8284ea313c79d65cb22d48329" category="paragraph">많은 조직에서 인공 지능(AI), 딥 러닝(DL), 데이터 과학과 같은 컴퓨팅 집약적인 서버 워크로드를 실행합니다. 이러한 사용 사례에서 NVIDIA vComputeServer 소프트웨어는 NVIDIA GPU를 가상화하여 오류 수정 코드, 페이지 폐기, NVLink를 통한 P2P, 다중 vGPU 등의 기능을 통해 컴퓨팅 집약적인 서버 워크로드를 가속화합니다.</block>
  <block id="e1f54ed77362f191ac08c4db8d9c44cd" category="admonition">Quadro vDWS 라이센스를 사용하면 GRID vPC 및 NVIDIA vComputeServer를 사용할 수 있습니다.</block>
  <block id="d685cba160011e42327272678904bcbc" category="inline-link-macro">다음: 배포</block>
  <block id="fed95bc65003dcb3d5ee273e3926bb25" category="paragraph"><block ref="fed95bc65003dcb3d5ee273e3926bb25" category="inline-link-macro-rx"></block></block>
  <block id="bf6d8e47240024519d1dbb6f5582ce66" category="summary">그래픽 워크스테이션은 일반적으로 제조, 의료, 에너지, 미디어 및 엔터테인먼트, 교육, 아키텍처 등 그래픽 집약적 애플리케이션의 경우 이동성이 제한되는 경우가 많습니다.</block>
  <block id="942cd85feff07ce32d619d2f724254a8" category="doc">솔루션을 제공합니다</block>
  <block id="fb987436787e4263bfee440b93703026" category="paragraph">이동성 문제를 해결하기 위해 가상 데스크톱 서비스는 유연한 GPU 구성 옵션을 포함하여 작업 근로자, 전문 사용자, 클라우드 또는 NetApp HCI에서 하드웨어 리소스를 사용하는 등 모든 유형의 근로자를 위한 데스크톱 환경을 제공합니다. VDS를 사용하면 랩톱, 태블릿 및 기타 모바일 장치를 통해 어디에서나 작업 환경에 액세스할 수 있습니다.</block>
  <block id="68ae3286d2356ff8dd51c2a397ca20eb" category="paragraph">ANSYS Fluent, ANSYS Mechanical, Autodesk AutoCAD, Autodesk Inventor, Autodesk 3DS Max, Dassault Systèmes SOLIDWORKS, Dassault Systèmes CATIA, PTC Creo, Siemens PLM NX 등 2021년 1월 기준 다양한 클라우드에서 사용할 수 있는 GPU가 다음 표에 나열되어 있습니다.</block>
  <block id="f5168df5bb95078acdfb440f5975a601" category="cell">GPU 모델</block>
  <block id="1668ca1bd914c1d847f23b491319ac91" category="cell">Microsoft Azure를 참조하십시오</block>
  <block id="b314ebdba178173db01ffda8d3a5af67" category="cell">Google Compute(GCP)</block>
  <block id="943ca3782b28d89aff2f86a50b332b3c" category="cell">AWS(Amazon Web Services)</block>
  <block id="8df8a98ff17d4d77329f5da80da051e8" category="cell">사내(NetApp HCI)</block>
  <block id="aaba9e920b39aa997c69800a9e589cd4" category="cell">NVIDIA M60</block>
  <block id="e095ad80d900786110d53ecd5cbd3e3e" category="cell">NVIDIA T4</block>
  <block id="c909ed1507c6d5537f0cc0966e83d3f1" category="cell">NVIDIA P100</block>
  <block id="c015c1cc95335d3b867c145c056df10b" category="cell">NVIDIA P4</block>
  <block id="e8130bb14c9382769c22861fb54683b3" category="paragraph">다른 사용자 및 전용 개인 데스크톱과의 공유 데스크톱 세션도 사용할 수 있습니다. 가상 데스크톱은 GPU를 1~4개 가질 수 있거나 NetApp HCI를 통해 부분 GPU를 활용할 수 있습니다. NVIDIA T4는 광범위한 사용자 워크로드의 요구사항을 충족할 수 있는 다기능 GPU 카드입니다. NetApp HCI H615C의 각 GPU 카드에는 서버당 16GB의 프레임 버퍼 메모리와 3개의 카드가 있습니다. 단일 H615C 서버에서 호스팅할 수 있는 사용자 수는 사용자 워크로드에 따라 다릅니다.</block>
  <block id="4d8b78a5288c49df59136421211718c9" category="cell">사용자/서버</block>
  <block id="704316eb872cbca84a8b30d74c2708a4" category="cell">표시등(4GB)</block>
  <block id="6f3a945a32dd8eba9f2fae42715f7246" category="cell">보통(8GB)</block>
  <block id="adb5e5b63d256f3854fc7276b3e8d14a" category="cell">중량지(16GB)</block>
  <block id="bd40934d28717a37aa4087f1622d8f0b" category="cell">H615C</block>
  <block id="c20ad4d76fe97759aa27a0c99bff6710" category="cell">12</block>
  <block id="1679091c5a880faf6fb5e6087eb1b2dc" category="cell">6</block>
  <block id="eccbc87e4b5ce2fe28308fd9f2a7baf3" category="cell">3</block>
  <block id="8938ba807f25f2cd88559b9f84bbc3de" category="paragraph">사용자 유형을 확인하려면 사용자가 일반적인 작업을 수행하는 응용 프로그램으로 작업하는 동안 GPU 프로파일러 도구를 실행합니다. GPU 프로파일러는 메모리 요구 사항, 디스플레이 수 및 사용자가 요구하는 해상도를 캡처합니다. 그런 다음 요구 사항을 충족하는 vGPU 프로필을 선택할 수 있습니다.</block>
  <block id="1b014a2b6e4c329b9696aae7afac88db" category="paragraph">GPU가 장착된 가상 데스크톱은 최대 8K의 디스플레이 해상도를 지원할 수 있으며, nView 유틸리티는 단일 모니터를 여러 영역으로 분할하여 여러 데이터 세트에서 작업할 수 있습니다.</block>
  <block id="30f1a84c728d67b9606115a1531aa9c3" category="paragraph">ONTAP 파일 스토리지를 사용하면 다음과 같은 이점을 실현할 수 있습니다.</block>
  <block id="826f3d14d0c34cd0f8ced37e07a1537d" category="list-text">관리 입력 없이도 4천억 개의 파일로 스토리지를 최대 20PB까지 확장할 수 있는 단일 네임스페이스입니다</block>
  <block id="1d7ab3c9a162bc81b216bdc0948094f2" category="list-text">글로벌 파일 캐시로 전 세계를 확장할 수 있는 네임스페이스</block>
  <block id="2d4169e0cb52db60fd11576990b38a54" category="list-text">관리되는 NetApp 스토리지를 통한 안전한 멀티 테넌시</block>
  <block id="a44c13ec320997e84b87b0fef150c39f" category="list-text">NetApp FabricPool를 사용하여 콜드 데이터를 오브젝트 저장소로 마이그레이션</block>
  <block id="3749fba0ca78e5e5c70f899da89be2c3" category="list-text">파일 시스템 분석을 통한 빠른 파일 통계</block>
  <block id="63d0ec819ea12b4e83e0ef4a1cd2bb1c" category="list-text">스토리지 클러스터를 최대 24노드로 확장하여 용량과 성능 향상</block>
  <block id="818a13118ddb0908ba00c1b7ca18dc2c" category="list-text">할당량을 통해 스토리지 공간을 제어하고 QoS 제한을 통해 성능을 보장할 수 있습니다</block>
  <block id="ef94cd0a62341c72316393b1044582f8" category="list-text">암호화를 통한 데이터 보호</block>
  <block id="c1e36bb7dca3b0da98164eb5956e3f0f" category="list-text">데이터 보호 및 규정 준수에 대한 광범위한 요구사항 충족</block>
  <block id="6a632279908ad5d56ab46a826de6c9f2" category="list-text">유연한 비즈니스 연속성 옵션 제공</block>
  <block id="3c2622109ae4dc55b73e9bb6516e5616" category="paragraph"><block ref="3c2622109ae4dc55b73e9bb6516e5616" category="inline-link-macro-rx"></block></block>
  <block id="2cdacde3c74a59c779ff64324954b86f" category="summary">NetApp VDS(가상 데스크톱 서비스)는 주요 퍼블릭 클라우드 및 프라이빗 클라우드에서 RDS(원격 데스크톱 서비스)를 조정합니다. VDS는 Microsoft Azure에서 WVD(Windows Virtual Desktop)를 지원합니다. VDS는 SMB 파일 공유 설정(사용자 프로필, 공유 데이터 및 사용자 홈 드라이브의 경우), Windows 기능, 응용 프로그램 및 에이전트 설치, 방화벽 및 정책 등을 포함하여 WVD 또는 RDS 배포 후 수행해야 하는 많은 작업을 자동화합니다.</block>
  <block id="acb7add6e3cf0ca01c52e60466c321ca" category="doc">TR-4861: 가상 데스크탑 서비스를 지원하는 하이브리드 클라우드 VDI</block>
  <block id="3d564c1c20cf4265a5094ead9dc937f6" category="paragraph">NetApp, Suresh Thoppay</block>
  <block id="bb6a5b934db24610665e58e743983ae4" category="paragraph">사용자는 전용 데스크톱, 공유 데스크톱 및 원격 응용 프로그램에 대해 VDS를 사용합니다. VDS는 데스크톱의 응용 프로그램 관리를 자동화하기 위한 스크립트 이벤트를 제공하며 관리할 이미지 수를 줄입니다.</block>
  <block id="38e3c8e108e8e361d0712cdfe23e0b38" category="paragraph">VDS는 퍼블릭 및 프라이빗 클라우드 환경 전반의 배포를 처리하기 위한 단일 관리 포털을 제공합니다.</block>
  <block id="9abac747d764180a5fe55920e00e887d" category="section-title">고객 가치</block>
  <block id="07d07e20c1ad9bd1a3e99e2303879ff9" category="paragraph">2020년에 원격 인력이 급증함에 따라 비즈니스 연속성 요구사항이 달라졌습니다. IT 부서는 가상 데스크톱을 신속하게 프로비저닝해야 하는 새로운 과제에 직면하여 프로비저닝 민첩성과 원격 관리, 그리고 사내 및 클라우드 리소스를 손쉽게 프로비저닝할 수 있는 하이브리드 클라우드의 TCO 이점을 필요로 합니다. 다음과 같은 기능을 갖춘 하이브리드 클라우드 솔루션이 필요합니다.</block>
  <block id="44ff202cbab5f506b48c6021b19c4b1c" category="list-text">COVID 이후 작업 공간의 현실을 해결하고 글로벌 역학으로 유연한 작업 모델을 지원합니다</block>
  <block id="53f994926861d0a62f2893b66d8b2025" category="list-text">작업 근로자부터 고급 사용자에 이르기까지 모든 직원의 작업 환경 배포를 단순화하고 가속화함으로써 교대 근무 환경을 지원합니다</block>
  <block id="831955bd9eabf6724f4e4b01acbb833c" category="list-text">물리적 위치에 관계없이 풍부하고 안전한 VDI 리소스를 제공하여 인력을 모바일화합니다</block>
  <block id="ab02aa4712e65c237e92874eeef51ecd" category="list-text">하이브리드 클라우드의 구축 간소화</block>
  <block id="074890ea8810b95d9b381027ff9baef2" category="list-text">위험 감소 관리를 자동화 및 단순화합니다</block>
  <block id="5eed1e48d8861a1192e8694a3d24021b" category="inline-link-macro">다음으로, 사용 사례를 살펴보겠습니다</block>
  <block id="60e1de201d0c183e889577e990975f1a" category="paragraph"><block ref="60e1de201d0c183e889577e990975f1a" category="inline-link-macro-rx"></block></block>
  <block id="53cf9d36e61cc97b118ae4cc9589bac3" category="summary">NetApp VDS Cloud Workspace Management Suite 포털을 사용하면 사내, 관리 사용자, 애플리케이션 카탈로그 및 스크립트 이벤트에 대해 정의된 사이트를 비롯한 다양한 VDS 배포를 중앙에서 관리할 수 있습니다. 이 포털은 필요한 경우 응용 프로그램을 수동으로 프로비저닝하고 문제 해결을 위해 모든 시스템에 연결할 수 있도록 관리자가 사용합니다.</block>
  <block id="e68a6dedaba6faaba6e7afd9197edc4f" category="doc">관리 포털</block>
  <block id="76368893e7696218fc60d77f96235f35" category="paragraph">NetApp VDS Cloud Workspace Management Suite 포털을 사용할 수 있습니다<block ref="1640f4040bca8395064a2ee51cb5f0ae" category="inline-link-rx"></block> 및 다음 버전을 사용할 수 있습니다<block ref="b6375c31f2253ef964d998b5762ba440" category="inline-link-rx"></block>.</block>
  <block id="02655da204b103696191f5d52c33427f" category="paragraph">이 포털을 사용하면 온프레미스, 관리 사용자, 애플리케이션 카탈로그 및 스크립트 이벤트가 정의된 사이트를 비롯한 다양한 VDS 배포를 중앙에서 관리할 수 있습니다. 이 포털은 필요한 경우 응용 프로그램을 수동으로 프로비저닝하고 문제 해결을 위해 모든 시스템에 연결할 수 있도록 관리자가 사용합니다.</block>
  <block id="0499b0532cd51452b57a028f3973d9fa" category="paragraph">서비스 공급자는 이 포털을 사용하여 자신의 채널 파트너를 추가하고 자신의 클라이언트를 관리할 수 있습니다.</block>
  <block id="8af19d014b76fa90ffc0c0477bd47be5" category="inline-link-macro">다음: 사용자 관리</block>
  <block id="631d677d75a0b47f9fe24a201cc8cb85" category="paragraph"><block ref="631d677d75a0b47f9fe24a201cc8cb85" category="inline-link-macro-rx"></block></block>
  <block id="91af64270656f51ceebeabc4b79ecb07" category="summary">NetApp VDS는 필요한 코드베이스에 따라 사용 가능한 설정 앱을 사용하여 Microsoft Azure에 배포할 수 있습니다.</block>
  <block id="29707848401dd26f02baed07b9a416c1" category="paragraph">NetApp VDS는 필요한 코드베이스에 따라 사용 가능한 설정 앱을 사용하여 Microsoft Azure에 배포할 수 있습니다. 현재 릴리스를 사용할 수 있습니다<block ref="deb5bc0c1293f06a53a77d04b921abbd" category="inline-link-rx"></block> 출시 예정인 제품의 미리 보기를 사용할 수 있습니다<block ref="b5073644bfe6db36c388c6bdbca64b49" category="inline-link-rx"></block>.</block>
  <block id="201e09e85ad81db8a19ef9f20c05d1a5" category="inline-link">이 비디오</block>
  <block id="c4e1987e3c1416cefd772fd61f28dfb4" category="paragraph">을 참조하십시오<block ref="f8270911b627accef36841f0608bc58d" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="4c9affd9b517fc81a601ea0861dc5399" category="inline-link-macro">다음: 하이브리드 클라우드 환경</block>
  <block id="2045518eb8a77a5284f073d0387f9a58" category="paragraph"><block ref="2045518eb8a77a5284f073d0387f9a58" category="inline-link-macro-rx"></block></block>
  <block id="b5ed404fa434aeee227f550cddf89892" category="inline-link">NetApp 클라우드</block>
  <block id="d823edbaf98641c5959f3a596de3df66" category="list-text"><block ref="d823edbaf98641c5959f3a596de3df66" category="inline-link-rx"></block></block>
  <block id="b1eb0510d1bc6ffab71faa53637ecde2" category="inline-link">NetApp VDS 제품 설명서</block>
  <block id="c5b41ed257411dffc1cc80a4c00cf17c" category="list-text"><block ref="c5b41ed257411dffc1cc80a4c00cf17c" category="inline-link-rx"></block></block>
  <block id="272427e7f4e6650df3749f83086acde6" category="inline-link">VPN 게이트웨이를 사용하여 온프레미스 네트워크를 Azure에 연결합니다</block>
  <block id="c460b4e40e6d4709ed15a2e8dba39833" category="list-text"><block ref="c460b4e40e6d4709ed15a2e8dba39833" category="inline-link-rx"></block></block>
  <block id="440e11297e8634c052b1bfd29a90309c" category="inline-link">Azure 포털</block>
  <block id="8284aff5fcde6ba43a0ca21712739cae" category="list-text"><block ref="8284aff5fcde6ba43a0ca21712739cae" category="inline-link-rx"></block></block>
  <block id="8867b143d669949d3948e3816324ec75" category="inline-link">Microsoft Windows 가상 데스크톱</block>
  <block id="0db816b3393ed224b26131285b4e3dff" category="list-text"><block ref="0db816b3393ed224b26131285b4e3dff" category="inline-link-rx"></block></block>
  <block id="7c033f9cfba6e06ff2ee6cb852ce10f4" category="inline-link">Azure NetApp Files 등록</block>
  <block id="aff481c4855a001492901fbefcab7d17" category="list-text"><block ref="aff481c4855a001492901fbefcab7d17" category="inline-link-rx"></block></block>
  <block id="57eae0e26c1c0bbaec9110d010f68f7a" category="summary">NetApp HCI는 스토리지 노드와 컴퓨팅 노드의 혼합으로 구성된 하이브리드 클라우드 인프라입니다. 모델에 따라 2랙 유닛 또는 단일 랙 유닛으로 사용할 수 있습니다. VM 배포에 필요한 설치 및 구성은 NDE(NetApp Deployment Engine)를 통해 자동으로 수행되며 컴퓨팅 클러스터는 VMware vCenter를 통해 관리되며 스토리지 클러스터는 NDE를 사용하여 구축된 vCenter 플러그인을 통해 관리됩니다.</block>
  <block id="855faa205a8f23993f1a0fe1ac2cde2f" category="doc">NetApp HCI 개요</block>
  <block id="95404d16cb98456e438a61d79a0a31d9" category="paragraph">NetApp HCI는 스토리지 노드와 컴퓨팅 노드의 혼합으로 구성된 하이브리드 클라우드 인프라입니다. 모델에 따라 2랙 유닛 또는 단일 랙 유닛으로 사용할 수 있습니다. VM 배포에 필요한 설치 및 구성은 NDE(NetApp Deployment Engine)를 통해 자동으로 수행되며 컴퓨팅 클러스터는 VMware vCenter를 통해 관리되며 스토리지 클러스터는 NDE를 사용하여 구축된 vCenter 플러그인을 통해 관리됩니다. mNode라는 관리 VM은 NDE의 일부로 구축됩니다.</block>
  <block id="b6ab683d50d83f639ae697569117a54b" category="paragraph">NetApp HCI는 다음 기능을 처리합니다.</block>
  <block id="d15278d453245d004f8fd55cff421171" category="list-text">버전 업그레이드</block>
  <block id="b783caf332f2c3190dcb6ced64290f5a" category="list-text">이벤트를 vCenter에 푸시하는 중입니다</block>
  <block id="79adeb760f6909dd746e1e7adae6cd58" category="list-text">vCenter 플러그인 관리</block>
  <block id="a45e04274259a13dff2a10641a0fd97f" category="list-text">지원을 위한 VPN 터널</block>
  <block id="227590ca6f7ff3f3cc72e49cf277625f" category="list-text">NetApp Active IQ 수집기</block>
  <block id="b0088ee645cccd0951013eb53d0b3816" category="list-text">NetApp Cloud Services를 온프레미스로 확장하여 하이브리드 클라우드 인프라를 지원합니다. 다음 그림은 HCI 구성 요소를 보여줍니다.</block>
  <block id="1a811712e3bea62b6f5bd1851b149fc3" category="paragraph"><block ref="1a811712e3bea62b6f5bd1851b149fc3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4725a4744390b735ea1bb4e3fc99b686" category="section-title">스토리지 노드</block>
  <block id="65f0d96af236e344bd739fd20df1fa5d" category="paragraph">스토리지 노드는 반폭 또는 전폭 랙 유닛으로 사용할 수 있습니다. 처음에는 최소 4개의 스토리지 노드가 필요하며, 클러스터는 최대 40개 노드까지 확장될 수 있습니다. 스토리지 클러스터를 여러 컴퓨팅 클러스터에서 공유할 수 있습니다. 모든 스토리지 노드에는 쓰기 성능을 향상시키기 위한 캐시 컨트롤러가 포함되어 있습니다. 단일 노드는 4K 블록 크기로 50K 또는 100K IOPS를 제공합니다.</block>
  <block id="d31f04e865057f7055f2d8287b92ba2d" category="paragraph">NetApp HCI 스토리지 노드는 최소, 최대 및 버스트 QoS 제한을 제공하는 NetApp Element 소프트웨어를 실행합니다. 스토리지 노드 하나는 총 용량의 1/3을 초과할 수 없지만 스토리지 클러스터는 스토리지 노드 혼합을 지원합니다.</block>
  <block id="0f66538edca95cf4d42667cfa5d6a362" category="section-title">컴퓨팅 노드</block>
  <block id="449aaf51a6dfa9c0e17423ae5938d674" category="inline-link">VMware 호환성 가이드 를 참조하십시오</block>
  <block id="1046a3e2377d26c40f75eb2cd2f268da" category="admonition">NetApp은 에 나열된 모든 컴퓨팅 서버에 연결된 스토리지를 지원합니다<block ref="72cc7e3e2b2d7f777e05aa309ef5f733" category="inline-link-rx"></block>.</block>
  <block id="bc1a52314ab38efacf0a83e9df0b01cc" category="paragraph">컴퓨팅 노드는 반폭, 전폭 및 2개의 랙 유닛 크기로 제공됩니다. NetApp HCI H410C 및 H610C는 확장 가능한 인텔 Skylake 프로세서를 기반으로 합니다. H615C는 확장 가능한 2세대 인텔 Cascade Lake 프로세서를 기반으로 합니다. GPU를 포함하는 두 가지 컴퓨팅 모델이 있습니다. H610C에는 NVIDIA M10 카드 2개가 포함되어 있으며 H615C에는 NVIDIA T4 카드 3개가 포함되어 있습니다.</block>
  <block id="683876986e8fe1045fa768b4a8675ea9" category="paragraph"><block ref="683876986e8fe1045fa768b4a8675ea9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9667ae1b4be7e4c088e175844fd675e6" category="paragraph">NVIDIA T4에는 실시간 광선 추적을 제공하는 데 필요한 계산 능력을 제공하는 40개의 RT 코어가 있습니다. 이제 디자이너와 엔지니어가 사용하는 동일한 서버 모델을 사용하여 실제 작업에서와 마찬가지로 표면에서 가볍게 튀어 나오는 실사적 이미지를 만들 수 있습니다. 이 RTX 가능 GPU는 초당 최대 5기가파이의 실시간 광선 추적 성능을 제공합니다. NVIDIA T4를 Quadro vDWS(Quadro Virtual Data Center Workstation) 소프트웨어와 함께 사용하면 아티스트가 위치와 상관없이 모든 장치에서 정확한 그림자, 반사 및 굴절 기능을 갖춘 실사적 설계를 만들 수 있습니다.</block>
  <block id="bee5034948808ff859affdc8ba03b52c" category="paragraph">Tensor 코어를 사용하여 딥 러닝 추론 워크로드를 실행할 수 있습니다. 이러한 워크로드를 실행할 때 Quadro vDWS 기반 NVIDIA T4는 CPU 전용 서버로 구동되는 VM보다 최대 25배 빠른 성능을 제공합니다. 랙 유닛 하나에 NVIDIA T4 카드 3개를 장착한 NetApp H615C는 그래픽 및 컴퓨팅 집약적인 워크로드에 이상적인 솔루션입니다.</block>
  <block id="1f99f286804bf2f5a91a1cdd1733decf" category="paragraph">다음 그림은 NVIDIA GPU 카드를 나열하고 이러한 카드를 비교합니다.</block>
  <block id="67c0c3f98979352a9ed10f0de3d551f3" category="paragraph"><block ref="67c0c3f98979352a9ed10f0de3d551f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3b4fc2931642829391b479ea5fb1e9d" category="paragraph">M10 GPU는 지식 근로자 사용 사례에 가장 적합한 TCO 솔루션입니다. 하지만 가상 워크스테이션, 그래픽 성능, 실시간 대화형 렌더링, 추론 등 다양한 사용 사례에서 사용할 수 있는 GPU로 표준화가 필요한 경우 T4를 사용하면 좋습니다. T4를 사용하면 IT 부서는 동일한 GPU 리소스를 활용하여 혼합 워크로드를 실행할 수 있습니다. 예를 들어, 낮 동안에는 VDI를 실행하고 야간에는 컴퓨팅 워크로드를 실행하기 위해 리소스를 다른 용도로 재활용할 수 있습니다.</block>
  <block id="bdced20c33601e0149aecb44114cfdc5" category="paragraph">H610C 컴퓨팅 노드는 크기가 두 개의 랙 유닛이며 H615C는 크기가 한 개의 랙 유닛으로, 전력을 더 적게 소모합니다. H615C는 H.264 및 H.265(High Efficiency Video Coding[HEVC]) 4:4:4 인코딩 및 디코딩을 지원합니다. 또한 점점 더 많은 주요 instrean VP9 디코더를 지원합니다. YouTube에서 제공하는 WebM 컨테이너 패키지에서도 비디오에 VP9 코덱을 사용합니다.</block>
  <block id="fe046fc197d12a64da1ea78423a2a809" category="paragraph">컴퓨팅 클러스터의 노드 수는 VMware에서 결정하며, 현재 96개의 VMware vSphere 7.0 Update 1이 사용되고 있습니다. EVC(Enhanced vMotion Compatibility)가 활성화된 경우 클러스터에서 서로 다른 컴퓨팅 노드 모델을 혼합할 수 있습니다.</block>
  <block id="f0bee2b90db3a99440b1a724c49ce1a2" category="inline-link-macro">다음은 NVIDIA 라이센싱입니다</block>
  <block id="e0bca2831f4cccfcaebc75e9555a1719" category="paragraph"><block ref="e0bca2831f4cccfcaebc75e9555a1719" category="inline-link-macro-rx"></block></block>
  <block id="c6aaad7e04b9605d83a2a2aa661fc1b4" category="summary">NetApp VDS를 사용하면 관리자가 작업을 다른 사용자에게 위임할 수 있습니다. 배포된 서버에 연결하여 문제를 해결하고, 로그를 보고, 감사 보고서를 실행할 수 있습니다. 고객 지원, 헬프데스크 또는 레벨 3 기술자는 사용자 세션을 섀도잉하고, 프로세스 목록을 보고, 필요한 경우 프로세스를 종료할 수 있습니다.</block>
  <block id="d1c59e5cbf684efb4f69f300e72a4ac9" category="doc">운영 관리</block>
  <block id="787e198d8fa4e242ef62df0a63fc0f5d" category="inline-link">실패한 VDA 작업 문제 해결 페이지</block>
  <block id="8086a7a818fcf045c7b05845b97629ed" category="paragraph">VDS 로그 파일에 대한 자세한 내용은 를 참조하십시오<block ref="0ecc734e7dc5f9a5685babbaab9faaa5" category="inline-link-rx"></block>.</block>
  <block id="88a80237ffcd0c20f5f4d4e7f9eda875" category="inline-link">VDA 구성 요소 및 사용 권한 페이지</block>
  <block id="000ea3efdd5a83f774a0c189fa2dcdc3" category="paragraph">필요한 최소 권한에 대한 자세한 내용은 를 참조하십시오<block ref="573c5bde2dc73c6cb4f63bbc5571c0e2" category="inline-link-rx"></block>.</block>
  <block id="81bb80b99b1ba5d80f9ba049cbd0c42f" category="inline-link">가상 머신 클론 생성 페이지</block>
  <block id="91aa73f3df8edb27ce6b20c984ff5d3e" category="paragraph">서버를 수동으로 복제하려면 를 참조하십시오<block ref="837d5521d53fff809b7ef3ad6b17ecfa" category="inline-link-rx"></block>.</block>
  <block id="7d71ba8ea6767ea10d7cd61cbd787f89" category="inline-link">디스크 공간 자동 증가 기능 페이지</block>
  <block id="abf872062b9eb23bdf6d671c27508d96" category="paragraph">VM 디스크 크기를 자동으로 늘리려면 를 참조하십시오<block ref="627eb07506141f4255cfbedd7fe89646" category="inline-link-rx"></block>.</block>
  <block id="cc6d8546c611bac5ab11fa1a5948ac1d" category="inline-link">최종 사용자 요구 사항 페이지</block>
  <block id="e148ddcb2ae92c77834ae7f48df04786" category="paragraph">클라이언트를 수동으로 구성할 게이트웨이 주소를 식별하려면 를 참조하십시오<block ref="3a5e891ac91af8fef1ca1458249fe76e" category="inline-link-rx"></block>.</block>
  <block id="b4f83b03956523a39e8bbbd0895f0f29" category="section-title">Cloud Insights</block>
  <block id="efb9afc2e01262d41bf1fa60ddc36414" category="paragraph">NetApp Cloud Insights는 NetApp 및 기타 타사 인프라 구성 요소에서 실행되는 인프라 및 애플리케이션에 대한 완벽한 가시성을 제공하는 웹 기반 모니터링 툴입니다. Cloud Insights은 프라이빗 클라우드와 퍼블릭 클라우드를 모두 지원하여 리소스 모니터링, 문제 해결 및 최적화를 지원합니다.</block>
  <block id="4894eb73d4d2ad7eaebb0968e871cb70" category="paragraph">에이전트 없이 데이터 수집기로부터 메트릭을 수집하려면 인수 단위 VM(Windows 또는 Linux)만 프라이빗 클라우드에 설치해야 합니다. 에이전트 기반 데이터 수집기를 사용하면 Windows 성능 모니터 또는 텔레그라프가 지원하는 모든 입력 에이전트에서 사용자 지정 메트릭을 가져올 수 있습니다.</block>
  <block id="32e49e2645f559763ede8e346bbcb816" category="paragraph">다음 그림은 Cloud Insights VDS 대시보드를 보여 줍니다.</block>
  <block id="cb9ecf4f0010c9ec12b73a00e06a9237" category="paragraph"><block ref="cb9ecf4f0010c9ec12b73a00e06a9237" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3bd1406c323c740b5b2f2a7615ad62ca" category="paragraph">NetApp Cloud Insights에 대한 자세한 내용은 를 참조하십시오<block ref="5fdb6e8524eb99916602753c65f2f24e" category="inline-link-rx"></block>.</block>
  <block id="8a883bd6e43add9d94d923704bc177a7" category="inline-link-macro">다음: 도구 및 로그</block>
  <block id="28f1e69837c0c21f4dcb8260d6ab5e97" category="paragraph"><block ref="28f1e69837c0c21f4dcb8260d6ab5e97" category="inline-link-macro-rx"></block></block>
  <block id="60ece3fee8421729100872ec44f1cda9" category="summary">배포의 일부로 파일 서비스 방법을 선택하여 사용자 프로필, 공유 데이터 및 홈 드라이브 폴더를 호스팅할 수 있습니다. 사용 가능한 옵션은 파일 서버, Azure 파일 또는 Azure NetApp Files입니다. 그러나 배포 후에는 Command Center 툴을 사용하여 SMB 공유를 가리키도록 이 선택 사항을 수정할 수 있습니다. NetApp ONTAP을 사용하여 호스팅하면 여러 가지 이점이 있습니다.</block>
  <block id="568483e9bd85504f3c9dcef24ecd3235" category="doc">데이터 관리</block>
  <block id="1b8c33cc721641b8b0555f2d7b5c2773" category="inline-link-macro">NetApp ONTAP을 사용하여 호스팅하면 여러 가지 이점이 있습니다</block>
  <block id="ef9fd867f3eaed93e0806bd027825218" category="inline-link">데이터 계층 변경</block>
  <block id="698e77d7e678617a2ae27ca2525bfbf7" category="paragraph">배포의 일부로 파일 서비스 방법을 선택하여 사용자 프로필, 공유 데이터 및 홈 드라이브 폴더를 호스팅할 수 있습니다. 사용 가능한 옵션은 파일 서버, Azure 파일 또는 Azure NetApp Files입니다. 그러나 배포 후에는 Command Center 툴을 사용하여 SMB 공유를 가리키도록 이 선택 사항을 수정할 수 있습니다. <block ref="50056d02f0a90e2e837160c093f1b22b" category="inline-link-macro-rx"></block>. SMB 공유를 변경하는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="336429df384a16f14c12cbc8dba62525" category="inline-link-rx"></block>.</block>
  <block id="24e6e2f6171b43a847fe194a9a9b5cd0" category="section-title">글로벌 파일 캐시</block>
  <block id="ce29b83c61cdf6a56b49dbde9a4d57e0" category="paragraph">사용자가 글로벌 네임스페이스 내의 여러 사이트에 분산되어 있는 경우 글로벌 파일 캐시를 사용하면 자주 액세스하는 데이터의 지연 시간을 줄일 수 있습니다. 글로벌 파일 캐시 구축은 프로비저닝 수집 및 스크립트 기반 이벤트를 사용하여 자동화할 수 있습니다. 글로벌 파일 캐시는 읽기 및 쓰기 캐시를 로컬에서 처리하며 여러 위치에 걸쳐 파일 잠금을 유지합니다. 글로벌 파일 캐시는 Azure NetApp Files를 비롯한 모든 SMB 파일 서버에서 사용할 수 있습니다.</block>
  <block id="87db7a122a37ab4a28f2223fa123a5be" category="paragraph"><block ref="87db7a122a37ab4a28f2223fa123a5be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d726de6a27bb533c6c8c44ea508dffa8" category="paragraph">글로벌 파일 캐시를 사용하려면 다음이 필요합니다.</block>
  <block id="2f28046ff208122796d51bafd8d4bc9c" category="list-text">관리 서버(License Management Server)</block>
  <block id="83168e6cb289d732cc78427b51f93153" category="list-text">코어</block>
  <block id="e7704357fe6a312ecafae725be93b8c2" category="list-text">데이터를 캐시할 디스크 용량이 충분한 에지</block>
  <block id="d70c88e6a13ca1af40b966d8d7d831c4" category="inline-link">GFC 설명서</block>
  <block id="154c48fd725e7207d36baa74bba5fd7a" category="paragraph">소프트웨어를 다운로드하고 Edge의 디스크 캐시 용량을 계산하려면 을 참조하십시오<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="1afc494dd7d35016d9524e06b68dbf2a" category="paragraph">검증을 위해 NetApp HCI의 에지 리소스와 Azure의 동일한 VM에 핵심 및 관리 리소스를 배포했습니다. 코어는 대용량 데이터 액세스가 필요하고 에지는 코어의 서브셋이라는 점에 유의하십시오. 소프트웨어를 설치한 후 사용하기 전에 활성화된 라이센스를 활성화해야 합니다. 이렇게 하려면 다음 단계를 완료하십시오.</block>
  <block id="70366038f1d44fef6c71f615b677b9cf" category="list-text">라이센스 구성 섹션에서 여기를 클릭 링크를 사용하여 라이센스 활성화를 완료합니다. 그런 다음 코어를 등록합니다.</block>
  <block id="a51a182b58a11b12770fbd2bd9643852" category="paragraph"><block ref="a51a182b58a11b12770fbd2bd9643852" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d666527802938c89b9f895300aea220b" category="list-text">글로벌 파일 캐시에 사용할 서비스 계정을 제공합니다. 이 계정에 필요한 사용 권한은 를 참조하십시오<block ref="83d5530c5afeb5a227ac8c2985566e4d" category="inline-link-rx"></block>.</block>
  <block id="ab698dd081619e8f6dc264df6c99b73e" category="paragraph"><block ref="ab698dd081619e8f6dc264df6c99b73e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12b1486d5cfb9e0c5394a50e2515b53c" category="list-text">새 백엔드 파일 서버를 추가하고 파일 서버 이름 또는 IP를 제공합니다.</block>
  <block id="ffeac1f6b14ca75f608539cb6c673f37" category="paragraph"><block ref="ffeac1f6b14ca75f608539cb6c673f37" category="inline-image-macro-rx" type="image"></block></block>
  <block id="643c94b6eb5664ed3cca98d31d7dbd39" category="list-text">가장자리에서 캐시 드라이브에는 드라이브 문자 D가 있어야 합니다 그렇지 않으면 diskpart.exe 를 사용하여 볼륨을 선택하고 드라이브 문자를 변경합니다. 라이센스 서버에 Edge로 등록합니다.</block>
  <block id="e9b41aa1ac49113064748a9c6e0f48a9" category="paragraph"><block ref="e9b41aa1ac49113064748a9c6e0f48a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="156666d997fd17a94bed67fe95334273" category="paragraph">코어 자동 구성이 활성화된 경우 라이센스 관리 서버에서 핵심 정보가 자동으로 검색됩니다.</block>
  <block id="891d862f33aaeafcd8ecc43e102febd3" category="paragraph"><block ref="891d862f33aaeafcd8ecc43e102febd3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a2184b1f206fd35eeb448e9937bdabe7" category="paragraph">클라이언트 컴퓨터에서 파일 서버의 공유에 액세스하는 데 사용한 관리자는 UNC 경로 "\\&lt;edge server name&gt;\FASTDATA\&lt;core server name&gt;\&lt;backend file server name&gt;\&lt;share name&gt;"을 사용하여 GFC 에지를 사용하여 액세스할 수 있습니다. 관리자는 에지 위치에서 사용자 드라이브 매핑을 위한 사용자 로그로ontscript 또는 GPO에 이 경로를 포함할 수 있습니다.</block>
  <block id="a08e5ca253097ac5ad7741e20d9dd090" category="paragraph">전 세계 사용자에게 투명한 액세스를 제공하기 위해 관리자는 파일 서버 공유 및 에지 위치를 가리키는 링크를 사용하여 DFS(Microsoft Distributed Filesystem)를 설정할 수 있습니다.</block>
  <block id="0c9f570b7b5b34f0fbdab873e122d432" category="paragraph"><block ref="0c9f570b7b5b34f0fbdab873e122d432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b9e8ad2bf50c8da3a637a8858d3a1391" category="paragraph">사용자가 사이트에 연결된 서브넷을 기반으로 Active Directory 자격 증명을 사용하여 로그인하면 DFS 클라이언트가 해당 링크를 사용하여 데이터에 액세스합니다.</block>
  <block id="6a6b2107f2b5daadfd13df04f769a587" category="paragraph"><block ref="6a6b2107f2b5daadfd13df04f769a587" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8aabec6a7d3f54b83478824808357c91" category="paragraph">파일 아이콘은 파일이 캐시되었는지 여부에 따라 달라집니다. 캐시되지 않은 파일은 아이콘의 왼쪽 아래 모서리에 회색 X가 표시됩니다. 에지 위치의 사용자가 파일에 액세스하면 해당 파일이 캐시되고 아이콘이 변경됩니다.</block>
  <block id="1014b6d5d432758e9041c845e4da7830" category="paragraph"><block ref="1014b6d5d432758e9041c845e4da7830" category="inline-image-macro-rx" type="image"></block></block>
  <block id="610eee89db61eda57b4b6da39d799845" category="paragraph">파일이 열려 있고 다른 사용자가 모서리 위치에서 같은 파일을 열려고 하면 다음과 같은 선택 메시지가 표시됩니다.</block>
  <block id="5a31b6c180e91d3c3d3c1053bbab642c" category="paragraph"><block ref="5a31b6c180e91d3c3d3c1053bbab642c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1c6f3b21447f91b42ceee404afc53720" category="paragraph">사용자가 원본 사본을 사용할 수 있을 때 알림을 받는 옵션을 선택하면 사용자에게 다음과 같은 알림이 표시됩니다.</block>
  <block id="922c6f30fa0f74f32df2fac11a3bf378" category="paragraph"><block ref="922c6f30fa0f74f32df2fac11a3bf378" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b9bc3a03a8ae9cef2c5a66238e5ab25" category="inline-link">Talon 및 Azure NetApp Files 배포에 대한 비디오</block>
  <block id="e725329a19c23f541a0bdbead9c9b1e7" category="paragraph">자세한 내용은 다음을 참조하십시오<block ref="92818ea025c5b78ace999366164c2c46" category="inline-link-rx"></block>.</block>
  <block id="fc95bd8bc19564339fe05c7bad1b7662" category="section-title">SaaS 백업</block>
  <block id="482cadbeebfa6f9c4f062c1f2724d546" category="paragraph">NetApp VDS는 Exchange, SharePoint 및 Microsoft OneDrive를 포함하여 Salesforce 및 Microsoft Office 365에 대한 데이터 보호를 제공합니다. 다음 그림은 NetApp VDS가 이러한 데이터 서비스에 SaaS Backup을 제공하는 방식을 보여줍니다.</block>
  <block id="0e3aff181138166393e5e5e698c994d2" category="paragraph"><block ref="0e3aff181138166393e5e5e698c994d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4cde65566156674196c087d89ded5c3b" category="paragraph">Microsoft Office 365 데이터 보호 데모를 보려면 을 참조하십시오<block ref="158107d7e819a2ef8c2e8f24519fc9a9" category="inline-link-rx"></block>.</block>
  <block id="a067b7082c28e7dbf856ab55b29d1acb" category="paragraph">Salesforce 데이터 보호 데모를 보려면 를 참조하십시오<block ref="dd6e5767407887626a36af7b68defda9" category="inline-link-rx"></block>.</block>
  <block id="2cb2b89213bccd89f81cfbb17b2e070b" category="inline-link-macro">다음: 작업 관리</block>
  <block id="1f3d3eae36241941c6f7a1eaf3615eac" category="paragraph"><block ref="1f3d3eae36241941c6f7a1eaf3615eac" category="inline-link-macro-rx"></block></block>
  <block id="64241e0b33fb869cb12ff8e1ec74f806" category="summary">NetApp VDS는 ID 인증을 위해 Azure Active Directory를 사용하고 NTLM/Kerberos 인증을 위해 Azure Active Directory 도메인 서비스를 사용합니다. ADConnect 도구를 사용하여 온프레미스 Active Directory 도메인을 Azure Active Directory와 동기화할 수 있습니다.</block>
  <block id="92726ab5faeb2cb9208eaac9af0346bd" category="doc">사용자 관리</block>
  <block id="c758de7e1477d6707c6709441d41a5e9" category="paragraph">포털에서 새 사용자를 추가하거나 기존 사용자에 대해 클라우드 작업 영역을 활성화할 수 있습니다. 작업 영역 및 응용 프로그램 서비스에 대한 사용 권한은 개별 사용자 또는 그룹별로 제어할 수 있습니다. 관리 포털에서 관리 사용자를 정의하여 포털, 작업 영역 등에 대한 권한을 제어할 수 있습니다.</block>
  <block id="b1bb3db86aec5efef6f7cc0d0d7c6331" category="paragraph">다음 그림은 NetApp VDS의 사용자 관리를 보여 줍니다.</block>
  <block id="ed5018356119de97fa1ab09c0eeab65a" category="paragraph"><block ref="ed5018356119de97fa1ab09c0eeab65a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1350c851c78a6cdb31c6fe46ddb499c2" category="paragraph">각 작업 영역은 다음 그림과 같이 Cloud Workspace OU 아래의 고유한 Active Directory 조직 단위(OU)에 있습니다.</block>
  <block id="a5484d6de39aa020af1aa382d6d52c5e" category="paragraph"><block ref="a5484d6de39aa020af1aa382d6d52c5e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3fad2f68853fae9ef870ed5535896790" category="paragraph">자세한 내용은 을 참조하십시오<block ref="b5d59c719b42a4e7d2b711482aa2f54d" category="inline-link-rx"></block> NetApp VDS의 사용자 권한 및 사용자 관리</block>
  <block id="48a8649f1ce9d97848d70480ce7fea9c" category="paragraph">데이터 센터에 대한 API 호출을 사용하여 Active Directory 그룹을 CRAUserGroup으로 정의하면 해당 그룹의 모든 사용자가 UI를 사용하여 관리할 수 있도록 CloudWorkspace로 가져옵니다. 클라우드 작업 영역이 사용자에 대해 활성화되면 VDS는 사용자 홈 폴더, 설정 권한, 사용자 속성 업데이트 등을 만듭니다.</block>
  <block id="9e30d1bf5e5278a123ad0ddab43066b7" category="paragraph">VDI User Enabled(VDI 사용자 활성화) 가 선택된 경우 VDS는 해당 사용자 전용의 단일 세션 RDS 시스템을 생성합니다. 프로비저닝할 템플릿과 데이터 저장소를 묻는 메시지가 표시됩니다.</block>
  <block id="093d2ddf98cacaf853b6f986ca9bd647" category="paragraph"><block ref="093d2ddf98cacaf853b6f986ca9bd647" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46bccf4889fab263d6edc63e631883a7" category="inline-link-macro">다음: 작업 영역 관리</block>
  <block id="e98fdb0b8697a2cf005527be51872d0d" category="paragraph"><block ref="e98fdb0b8697a2cf005527be51872d0d" category="inline-link-macro-rx"></block></block>
  <block id="aaca2e6fe88c6861582a8d1a20acfd4f" category="summary">가상 데스크톱 서비스용 ONTAP 기능.</block>
  <block id="bc9c47c8423d4537fdbf118b09a80084" category="doc">가상 데스크톱 서비스용 ONTAP 기능</block>
  <block id="472986236003195075a1428fe6103f4c" category="paragraph">다음 ONTAP 기능을 사용하면 가상 데스크톱 서비스에 적합합니다.</block>
  <block id="6128a47ce6baa55dbad9293234f2f65c" category="list-text">* 스케일아웃 파일 시스템. * ONTAP FlexGroup 볼륨은 20PB 이상으로 확장할 수 있으며 단일 네임스페이스 내에서 4천억 개 이상의 파일을 포함할 수 있습니다. 클러스터는 최대 24개의 스토리지 노드를 포함할 수 있으며, 각 노드는 사용된 모델에 따라 유연하게 네트워크 인터페이스 카드 수를 지정할 수 있습니다.</block>
  <block id="960f11687b64143d44db7f4ffcb33ef2" category="paragraph">사용자의 가상 데스크톱, 홈 폴더, 사용자 프로필 컨테이너, 공유 데이터 등을 필요에 따라 확장할 수 있으며 파일 시스템 제한에 대한 우려 없이 확장할 수 있습니다.</block>
  <block id="ab7ad572d2251b9b27fa0213fde8531f" category="list-text">* 파일 시스템 분석 * XCP 툴을 사용하여 공유 데이터에 대한 통찰력을 얻을 수 있습니다. ONTAP 9.8+ 및 ActiveIQ Unified Manager 를 사용하면 파일 메타데이터 정보를 쉽게 쿼리하고 검색하고 콜드 데이터를 식별할 수 있습니다.</block>
  <block id="885f3e34ca03dc8ff35c0bac51b384f7" category="list-text">* 클라우드 계층화. * 콜드 데이터를 클라우드의 오브젝트 저장소 또는 데이터 센터의 S3 호환 스토리지로 마이그레이션하고</block>
  <block id="fb38ee94b865e67571a08316a3baac38" category="list-text">* 파일 버전. * 사용자는 NetApp ONTAP 스냅샷 복사본으로 보호되는 파일을 복구할 수 있습니다. ONTAP 스냅샷 복사본은 변경된 블록만 기록하므로 매우 공간 효율적입니다.</block>
  <block id="9b7db1dd6f422e5f07ded1d3b7b04d90" category="list-text">* 글로벌 네임스페이스. * ONTAP FlexCache 기술을 사용하면 파일 스토리지를 원격 캐싱할 수 있으므로 ONTAP 스토리지 시스템이 포함된 여러 위치에서 공유 데이터를 보다 쉽게 관리할 수 있습니다.</block>
  <block id="827aa7cb1ad6ddbf99e040efe34725a8" category="list-text">* 시큐어 멀티 테넌시 지원. * 단일 물리적 스토리지 클러스터는 각각 고유한 볼륨, 스토리지 프로토콜, 논리적 네트워크 인터페이스, ID 및 인증 도메인, 관리 사용자 등을 갖춘 여러 가상 스토리지 어레이로 제공할 수 있습니다. 따라서 테스트, 개발, 운영 등과 같은 여러 사업부와 환경 간에 스토리지 어레이를 공유할 수 있습니다.</block>
  <block id="6c36afe01468d888b334a4432dcac4b2" category="paragraph">성능을 보장하기 위해 적응형 QoS를 사용하여 사용된 공간 또는 할당된 공간에 따라 성능 수준을 설정하고 할당량을 사용하여 스토리지 용량을 제어할 수 있습니다.</block>
  <block id="b1a678f5f86de8ff8a5b9b1c4b3772b8" category="list-text">* VMware 통합. * VMware vSphere용 ONTAP 툴은 데이터 저장소 프로비저닝, vSphere 호스트 모범 사례 구현 및 ONTAP 리소스 모니터링을 위한 vCenter 플러그인을 제공합니다.</block>
  <block id="9b12997ae1d332c9003c444a6ff8918a" category="paragraph">ONTAP는 SCSI/파일 작업을 스토리지 시스템으로 오프로드하기 위해 VAAI(vStorage APIs for Array Integration)를 지원합니다. ONTAP는 또한 블록 및 파일 프로토콜에 대해 VASA(vStorage APIs for Storage Awareness) 및 가상 볼륨을 지원합니다.</block>
  <block id="025e05e390f2d7ef7708bb42d81e1eeb" category="paragraph">VMware vSphere용 SnapCenter 플러그인을 사용하면 스토리지 시스템의 Snapshot 기능을 사용하여 가상 머신을 쉽게 백업 및 복원할 수 있습니다.</block>
  <block id="3452f822915108b5d640f3288959e7fd" category="paragraph">ActiveIQ Unified Manager는 vSphere 환경에서 완벽한 스토리지 네트워크 가시성을 제공합니다. 관리자는 ONTAP에서 호스팅되는 가상 데스크톱 환경에서 발생할 수 있는 지연 시간 문제를 쉽게 식별할 수 있습니다.</block>
  <block id="c9559fb9abb51cf76cc973d06c7e730c" category="list-text">* 보안 규정 준수. * ActiveIQ Unified Manager 를 사용하면 모든 정책 위반에 대한 알림을 통해 여러 ONTAP 시스템을 모니터링할 수 있습니다.</block>
  <block id="875c0a88cb08e888c642bbcc19cb33a2" category="list-text">* 멀티 프로토콜 지원. * ONTAP는 블록(iSCSI, FC, FCoE 및 NVMe/FC), 파일(NFSv3, NFSv4.1, SMB2.x, SMB3.x) 및 오브젝트(S3) 스토리지 프로토콜</block>
  <block id="4ac79aa8e1431a96a08ba58c1e17a104" category="list-text">* 자동화 지원. * ONTAP는 VDS 관리 포털을 통해 작업을 자동화하는 REST API, Ansible 및 PowerShell 모듈을 제공합니다.</block>
  <block id="ba5e495048f0fa35302184aa505386a9" category="inline-link-macro">다음: 데이터 관리</block>
  <block id="51688bc4609022e20e8c1cb051fb4489" category="paragraph"><block ref="51688bc4609022e20e8c1cb051fb4489" category="inline-link-macro-rx"></block></block>
  <block id="aa08bd8b0522ea3a5e9ace598db7162c" category="doc">애플리케이션 관리</block>
  <block id="f83a66a518ff3f3f44725a09d9666710" category="paragraph">사무실 근로자가 파워 유저를 위해 서비스 보드를 사용하여 필요한 애플리케이션을 수동으로 프로비저닝하거나 NetApp VDS의 스크립트 기반 이벤트 기능을 사용하여 자동으로 프로비저닝할 수 있습니다.</block>
  <block id="546d3f7d3bb8a664a6ba4a3fb2f68c30" category="inline-link">NetApp Application Entitlement 페이지</block>
  <block id="175ba74f5b7d0ecd3f531c5fce21a240" category="paragraph">자세한 내용은 를 참조하십시오<block ref="03e02ecfc967e94041a86f599e14ac44" category="inline-link-rx"></block>.</block>
  <block id="fd324b11a163d2dae6bf3f9654381d16" category="inline-link-macro">다음: 가상 데스크탑 서비스를 위한 ONTAP 기능</block>
  <block id="25838148a81bcaa2b7e931ef8cd65a13" category="paragraph"><block ref="25838148a81bcaa2b7e931ef8cd65a13" category="inline-link-macro-rx"></block></block>
  <block id="3a1e041969ddc2d8e0e399260d9159a7" category="doc">Login VSI를 사용한 단일 서버 로드 테스트</block>
  <block id="12d80b6f529069c8b2bc8d45947a0379" category="paragraph">NetApp 가상 데스크톱 서비스는 Microsoft 원격 데스크톱 프로토콜을 사용하여 가상 데스크톱 세션 및 애플리케이션에 액세스하고 Login VSI 툴은 특정 서버 모델에서 호스팅할 수 있는 최대 사용자 수를 결정합니다. Login VSI는 특정 간격으로 사용자 로그인을 시뮬레이션하고 문서 열기, 메일 읽기 및 작성, Excel 및 PowerPoint 작업, 문서 인쇄, 파일 압축, 임의 나누기 등의 사용자 작업을 수행합니다. 그런 다음 응답 시간을 측정합니다. 서버 사용률이 낮으면 사용자 응답 시간이 낮고 사용자 세션이 더 추가되면 시간이 늘어납니다. Login VSI는 초기 사용자 로그인 세션을 기준으로 기준을 결정하며 사용자 응답이 기준으로부터 2초를 초과할 경우 최대 사용자 세션을 보고합니다.</block>
  <block id="4be1d7a9b1a8d85ed7d1cf5c72b23928" category="paragraph">NetApp 가상 데스크톱 서비스는 Microsoft 원격 데스크톱 프로토콜을 활용하여 가상 데스크톱 세션 및 애플리케이션에 액세스합니다. 특정 서버 모델에서 호스팅할 수 있는 최대 사용자 수를 결정하기 위해 Login VSI 툴을 사용했습니다. Login VSI는 특정 간격으로 사용자 로그인을 시뮬레이션하고 문서 열기, 메일 읽기 및 작성, Excel 및 PowerPoint 작업, 문서 인쇄, 파일 압축, 임의 나누기 등의 사용자 작업을 수행합니다. 응답 시간도 측정합니다. 서버 사용률이 낮으면 사용자 응답 시간이 낮고 사용자 세션이 더 추가되면 시간이 늘어납니다. Login VSI는 초기 사용자 로그인 세션을 기준으로 기준을 결정하며 사용자 응답이 기준으로부터 2초를 초과할 경우 최대 사용자 세션을 보고합니다.</block>
  <block id="481e9968651d6bd0d36d67a776a0f32a" category="paragraph">다음 표에는 이 검증에 사용된 하드웨어가 나와 있습니다.</block>
  <block id="e93f994f01c537c4e2f7d8528c3eb5e9" category="cell">카운트</block>
  <block id="8417ade953d75aa6fa3c64813e005e17" category="cell">NetApp HCI H610C</block>
  <block id="ec1d568aa57f1e1231acef5759640fc6" category="cell">런처, AD, DHCP 등을 위한 클러스터 내 3개. 부하 테스트용 서버 1대</block>
  <block id="5b68b81817d64cfa84c65e2e185efe97" category="cell">NetApp HCI H615C</block>
  <block id="c36af9ab64be0b8bd4d5097f58b8a5ba" category="cell">2x24C Intel Xeon Gold 6282 @ 2.1GHz. 1.5TB RAM</block>
  <block id="825c03a9f78635bec804883dde1bd6bf" category="paragraph">다음 표에는 이 검증에 사용된 소프트웨어가 나와 있습니다.</block>
  <block id="f5bf48aa40cad7891eb709fcf1fde128" category="cell">제품</block>
  <block id="f80ee94fe4a9c10f8d85e442e7521687" category="cell">NetApp VDS 5.4</block>
  <block id="d9cc1f843ea62c12a3e59afbbdc2f9ce" category="cell">오케스트레이션</block>
  <block id="bb15f84d3b96a9b33719b8a71bc62207" category="cell">VM 템플릿 Windows 2019 1809</block>
  <block id="f6a3c0d463e2ae697b02a9893e2062a3" category="cell">RDSH용 서버 OS</block>
  <block id="5a264c4e5b7b75d4ead67bf3ff7988bc" category="cell">Login VSI</block>
  <block id="5227da0541209a94c7dc0a07cf3e0740" category="cell">4.1.32.1</block>
  <block id="123995603a5e237810bf85a8e3c73f2e" category="cell">VMware vSphere 6.7 업데이트 3</block>
  <block id="1b21b0d71706897b69f108572c444d40" category="cell">하이퍼바이저</block>
  <block id="2752fcc90cb7cc7439b827d762e89166" category="cell">VMware vCenter 6.7 업데이트 3F</block>
  <block id="436bc441be68b676a199df5c1ea02263" category="cell">VMware 관리 툴</block>
  <block id="9ad541af6dac1be0c6655522128a386c" category="paragraph">Login VSI 테스트 결과는 다음과 같습니다.</block>
  <block id="17126aef3e415713552604218f448967" category="cell">VM 구성</block>
  <block id="084abcce930cefa047af15fc0836639a" category="cell">Login VSI 기준</block>
  <block id="8bb9799dff9f679e2305879f7dc1a9f0" category="cell">Login VSI 최대</block>
  <block id="e49775052ecbe49b489c84d0b09e916e" category="cell">H610C</block>
  <block id="a9cc7da7b66d8162a44a176bb1109440" category="cell">vCPU 8개, 48GB RAM, 75GB 디스크, 8Q vGPU 프로파일</block>
  <block id="28267ab848bcf807b2ed53c3a8f8fc8a" category="cell">799</block>
  <block id="8f85517967795eeef66c225f7883bdcb" category="cell">178</block>
  <block id="4052d2c7017812dc33333a4dc7e83dc9" category="cell">vCPU 12개, 128GB RAM, 75GB 디스크</block>
  <block id="eefc9e10ebdc4a2333b42b2dbb8f27b6" category="cell">763</block>
  <block id="7a614fd06c325499f1680b9896beedeb" category="cell">272</block>
  <block id="71c62dd6d64bb960471819c829a777fd" category="paragraph">하위 NUMA 경계 및 하이퍼스레딩을 고려할 때 VM 테스트 및 구성에 선택된 8개의 VM은 호스트에서 사용 가능한 코어에 의존했습니다.</block>
  <block id="0f57e9c52f3aa2d44da0de48ac87443a" category="paragraph">H610C에서는 RDP 프로토콜을 사용하여 사용자 세션에 연결하는 10개의 시작 관리자 VM을 사용했습니다. 다음 그림에서는 Login VSI 연결 정보를 보여 줍니다.</block>
  <block id="ad1351ac01d5fe0ac5546c8a2fd2d170" category="paragraph"><block ref="ad1351ac01d5fe0ac5546c8a2fd2d170" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dba4e8b5ffc06c0ccce673fd6f48159" category="paragraph">다음 그림에서는 H610C의 활성 세션과 Login VSI 응답 시간을 비교하여 보여 줍니다.</block>
  <block id="8d58d21e6be9e4be37d3c42935a380b5" category="paragraph"><block ref="8d58d21e6be9e4be37d3c42935a380b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65f671ed80b2c6f0cc371ab295230a3a" category="paragraph">다음 그림에서는 H615C에 대한 Login VSI 응답 시간과 활성 세션을 비교하여 보여 줍니다.</block>
  <block id="72cce33d21386089f9a521f893c14d41" category="paragraph"><block ref="72cce33d21386089f9a521f893c14d41" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c29ae1e9123280c1975dbc407f3eca3" category="paragraph">다음 그림에서는 H615C vSphere 호스트 및 VM에 대한 Login VSI 테스트 중에 Cloud Insights의 성능 메트릭을 보여 줍니다.</block>
  <block id="d64755ae2a4094876fbaf88a161ddec2" category="paragraph"><block ref="d64755ae2a4094876fbaf88a161ddec2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ab628831ed501803e9da2a64f12dd6e" category="inline-link-macro">다음: 관리 포털</block>
  <block id="20fcc4e371ed448b0d5ffee3f4aecb43" category="paragraph"><block ref="20fcc4e371ed448b0d5ffee3f4aecb43" category="inline-link-macro-rx"></block></block>
  <block id="c4ff33edf6e94fb434fb59e4ad2c286b" category="inline-link-macro">SnapCenter 기반의 하이브리드 클라우드 데이터베이스 솔루션</block>
  <block id="fc25c016a8fb35a621842044a8d4f2e7" category="inline-link-macro">하이브리드 클라우드에서 Oracle 데이터베이스 인프라를 자동화합니다</block>
  <block id="e7f098b026755d10f2c3f16d0ff0b1db" category="inline-link-macro">설계 가이드</block>
  <block id="1027b152cc3e8165ce099ede9548be95" category="cell"><block ref="1027b152cc3e8165ce099ede9548be95" category="inline-link-macro-rx"></block></block>
  <block id="dfb1e9c5f4c5835e6e1a4173130a49c9" category="inline-link-macro">구축 가이드</block>
  <block id="983044e3ba861493c43c08b9285c3125" category="cell"><block ref="983044e3ba861493c43c08b9285c3125" category="inline-link-macro-rx"></block></block>
  <block id="d91f70a15d40fe5795af6ded9555e095" category="cell"><block ref="d91f70a15d40fe5795af6ded9555e095" category="inline-link-macro-rx"></block></block>
  <block id="8e9465b5d4318c8ef9039dfe684619d5" category="cell"><block ref="8e9465b5d4318c8ef9039dfe684619d5" category="inline-link-macro-rx"></block></block>
  <block id="c232cfc0ae9806d3ad6d34a51df58229" category="section-title">NetApp의 Red Hat OpenShift</block>
  <block id="145706f4acca44c289ff5ca8cc5b2b86" category="inline-link-macro">NetApp AI 솔루션</block>
  <block id="895a85fc0a1a565ac547acc1bc9740f3" category="inline-link-macro">MLOps를 참조하십시오</block>
  <block id="9480fd8950471a46e6b29b165ba7ae41" category="summary">NetApp Astra Control Center는 NetApp의 신뢰할 수 있는 데이터 보호 기술을 기반으로 하는 온프레미스 환경에 구축된 상태 저장 Kubernetes 작업 부하를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스를 제공합니다.</block>
  <block id="3d210170d7f07fe3c907e8ac619f003a" category="doc">NetApp Astra Control Center 개요</block>
  <block id="9b0d9ae1197ded2c7d52147e5056475d" category="paragraph">NetApp Astra Control Center는 사내 환경에 구축되어 NetApp 데이터 보호 기술을 기반으로 하는 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공합니다.</block>
  <block id="c4a7756da710a87248298a14bd0c21e6" category="paragraph"><block ref="c4a7756da710a87248298a14bd0c21e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f0358bd53d50b55aa0509189dd381ca9" category="paragraph">NetApp Astra Control Center는 NetApp ONTAP 스토리지 시스템에 스토리지 클래스 및 스토리지 백엔드를 구축하고 구성하는 Astra Trident 스토리지 오케스트레이터가 구축된 Red Hat OpenShift 클러스터에 설치할 수 있습니다.</block>
  <block id="8cc4d72a7129322eb1f39ea9b9cfb2f6" category="inline-link-macro">이 문서는 여기 에서 확인할 수 있습니다</block>
  <block id="1c2ddd920580e1a7860afb96d7ac352e" category="paragraph">Astra Control Center를 지원하는 Astra Trident의 설치 및 구성은 를 참조하십시오 <block ref="a581b27b235a239b8b186164c4dbebd1" category="inline-link-macro-rx"></block>.</block>
  <block id="876ae62d75901b9ef80277fd884aa5e9" category="paragraph">클라우드 연결 환경에서 Astra Control Center는 Cloud Insights를 사용하여 고급 모니터링 및 원격 측정 기능을 제공합니다. Cloud Insights 연결이 없을 경우 제한된 모니터링 및 원격 측정(7일 메트릭)을 사용할 수 있으며 개방형 메트릭 엔드포인트를 통해 Kubernetes 기본 모니터링 툴(Prometheus 및 Grafana)으로 내보낼 수 있습니다.</block>
  <block id="54a5ba4de846d3c3ba8c0322f5139893" category="paragraph">Astra Control Center는 NetApp AutoSupport 및 Active IQ 에코시스템에 완전히 통합되어 사용자를 지원하고, 문제 해결을 지원하며, 사용 통계를 표시합니다.</block>
  <block id="34610c3089a79a0b0e58bcc24da4c16c" category="paragraph">Astra Control Center의 유료 버전 외에 90일 평가판 라이센스가 제공됩니다. 평가 버전은 이메일과 커뮤니티(Slack 채널)를 통해 지원됩니다. 고객은 이러한 기술 자료 및 기타 기술 자료 문서와 제품 내 지원 대시보드에서 제공되는 문서에 액세스할 수 있습니다.</block>
  <block id="b3d5fa878980b3f5b771ced3fa94111a" category="inline-link-macro">Astra 웹 사이트</block>
  <block id="83d307afe7b187cee5d096f65402182f" category="paragraph">NetApp Astra Control Center를 시작하려면 을 방문하십시오 <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="7f9648de128837be473a3b24e53ff823" category="section-title">Astra Control Center 설치 필수 구성 요소</block>
  <block id="8ffc0d45ec909884b280603fd2556021" category="list-text">하나 이상의 Red Hat OpenShift 클러스터 버전 4.6 EUS 및 4.7이 현재 지원됩니다.</block>
  <block id="526a5a0f546838d61791ded926113f71" category="list-text">각 Red Hat OpenShift 클러스터에 이미 Astra Trident가 설치 및 구성되어 있어야 합니다.</block>
  <block id="e7a6c3c568d213db46836511343c4965" category="list-text">ONTAP 9.5 이상을 실행 중인 NetApp ONTAP 스토리지 시스템 하나 이상</block>
  <block id="7433dd0f15704f71764248a0ca105fad" category="admonition">단일 사이트에 OpenShift를 설치할 때마다 전용 SVM을 설치하여 영구 스토리지로 사용하는 것이 가장 좋습니다. 다중 사이트 배포에는 추가 스토리지 시스템이 필요합니다.</block>
  <block id="c927c560df09d5ca001f99cd07b14700" category="list-text">Trident 스토리지 백엔드는 각 OpenShift 클러스터에서 ONTAP 클러스터에서 지원하는 SVM과 함께 구성해야 합니다.</block>
  <block id="67a56d728807272d2a01df50c6548f4f" category="list-text">스토리지 프로비저닝자로 Astra Trident가 있는 각 OpenShift 클러스터에 구성된 기본 StorageClass입니다.</block>
  <block id="dda5c1363ac68168c83f72fc2645f51f" category="list-text">부하 분산 및 OpenShift 서비스 노출을 위해 각 OpenShift 클러스터에 로드 밸런서를 설치하고 구성해야 합니다.</block>
  <block id="e32d2cb3312c2c7797ca52bd8d6ff26f" category="admonition">링크를 참조하십시오 <block ref="0065297854ca0573913043e80b99a2d1" category="inline-link-macro-rx"></block> 이 목적을 위해 검증된 로드 밸런서에 대한 정보를 제공합니다.</block>
  <block id="7dbcc72cc3a693b8f89b064e38ed7a23" category="list-text">NetApp Astra Control Center 이미지를 호스팅하도록 프라이빗 이미지 레지스트리를 구성해야 합니다.</block>
  <block id="aa32c16385a1b749687956188e4f0d9a" category="admonition">링크를 참조하십시오 <block ref="9d2000c3bba4885fe5f36ed192264583" category="inline-link-macro-rx"></block> 이를 위해 OpenShift 전용 레지스트리를 설치하고 구성합니다.</block>
  <block id="3123a26626e19f387157faf3a8e35e86" category="list-text">Red Hat OpenShift 클러스터에 대한 Cluster Admin 액세스 권한이 있어야 합니다.</block>
  <block id="537f97bbcef0e2e67d6840aa5845aa65" category="list-text">NetApp ONTAP 클러스터에 대한 관리 액세스 권한이 있어야 합니다.</block>
  <block id="0507b40de1fbd59b7a77b9054689e92b" category="list-text">Docker 또는 podman, tridentctl 및 OC 또는 kubtl 도구가 설치되어 있고 $PATH에 추가된 관리 워크스테이션입니다.</block>
  <block id="abfe00e88b26a267771078e0295b1573" category="admonition">Docker 설치는 20.10 이상의 Docker 버전이 있어야 하며, 팟맨 설치에는 3.0 이상의 팟맨 버전이 있어야 합니다.</block>
  <block id="8c7c70cb991e0295e289054b79308c5d" category="section-title">Astra Control Center를 설치합니다</block>
  <block id="121c2592ea226f655d357a8ecd8caf2e" category="inline-link">Astra 등록 사이트입니다</block>
  <block id="ba6df9237a2774d7ca28cdf134cf9314" category="admonition">Astra Control 평가판 라이센스를 시작하려면 를 방문하십시오<block ref="dd61f8f3fbfa8ca8b0a268b985d55b0e" category="inline-link-rx"></block>.</block>
  <block id="ccab5cf8842d06d8d4e2f7f778657c4b" category="list-text">tar ball의 압축을 풀고 작업 디렉토리를 결과 폴더로 변경합니다.</block>
  <block id="29fc4f6574f437e623e4eb9d47136931" category="list-text">설치를 시작하기 전에 Astra Control Center 이미지를 이미지 레지스트리로 밀어 넣으십시오.</block>
  <block id="25b4e951c048e2ae39554f36af8824b9" category="admonition">Docker 또는 Podman에서 이 작업을 수행할 수 있습니다. 두 가지 모두에 대한 지침은 이 단계에서 제공합니다.</block>
  <block id="abe31bcfb59f2265c2fb97dde407366c" category="open-title">포더맨</block>
  <block id="e83d8437c3befea11906e730883605bf" category="list-text">조직/네임스페이스/프로젝트 이름을 사용하여 레지스트리 FQDN을 환경 변수 '궤도'로 내보냅니다.</block>
  <block id="9acf317cba8637e151b8daae04e3e998" category="list-text">레지스트리에 로그인합니다.</block>
  <block id="e2f745ac603721ed9903b0acea00d059" category="admonition">kubadmin 사용자를 사용하여 개인 레지스트리에 로그인하는 경우 암호 대신 토큰을 사용하십시오. podman login -u odman login -u opp -user -p token- TLS -verify=false astra-registry.apps.ocp-vmw.cie.netapp.com`</block>
  <block id="e4b91f5b748fa6ef8813d2871257b134" category="admonition">또는 서비스 계정을 만들고, 레지스트리 편집기 및/또는 레지스트리 뷰어 역할(푸시/풀 액세스 필요 여부에 따라)을 할당하고, 서비스 계정의 토큰을 사용하여 레지스트리에 로그인할 수 있습니다.</block>
  <block id="a53846d7be2355a59af69a47e2cf4637" category="list-text">쉘 스크립트 파일을 작성하고 다음 내용을 붙여 넣습니다.</block>
  <block id="ad3318a786149147666e961c291c6875" category="admonition">레지스트리에 신뢰할 수 없는 인증서를 사용하는 경우 셸 스크립트를 편집하고 podman 푸시 명령 "podman push $registry/$(echo$astraImage|SED's/^\////')--tls-verify=false"를 사용하십시오.</block>
  <block id="326c4e96ff06709dede5c03038f00e78" category="list-text">파일을 실행 파일로 만듭니다.</block>
  <block id="ed85c18933b4b240788294af279f8624" category="list-text">쉘 스크립트를 실행합니다.</block>
  <block id="05b6053c41a2130afd6fc3b158bda4e6" category="open-title">Docker 를 참조하십시오</block>
  <block id="ad533c54cadd80fbf8f60e58b7d3abd6" category="admonition">kubadmin 사용자를 사용하여 개인 레지스트리에 로그인하는 경우 암호 대신 토큰(docker login -u OCP -user -p token astra-registry.apps.ocp-vmw.cie.netapp.com` 대신 토큰을 사용합니다.</block>
  <block id="f39d61476380fc033f45c2d744596b00" category="list-text">그런 다음 이미지 레지스트리 TLS 인증서를 OpenShift 노드에 업로드합니다. 이렇게 하려면 TLS 인증서를 사용하여 OpenShift-config 네임스페이스에 configmap을 만들고 이를 클러스터 이미지 구성에 패치하여 인증서를 신뢰할 수 있도록 합니다.</block>
  <block id="508ca0ca5ae419c052d9a8487bb0b2d0" category="admonition">경로를 사용하여 수신 운영자의 기본 TLS 인증서가 있는 OpenShift 내부 레지스트리를 사용하는 경우 이전 단계를 따라 인증서를 경로 호스트 이름에 패치해야 합니다. 수신 운영자로부터 인증서를 추출하기 위해 'OC extract secret/router-ca--keys=tls.crt-n openshift-ingrator' 명령어를 사용할 수 있다.</block>
  <block id="6589da0279dd02b9b1d177e0ff5f457b" category="list-text">Astra Control Center Operator 설치를 위한 Namespace 'NetApp-acc-operator'를 생성합니다.</block>
  <block id="e3990b0b892faaf03261a0a1bcd00b9b" category="list-text">"NetApp-acc-operator" 네임스페이스에서 자격 증명을 사용하여 이미지 레지스트리에 로그인하기 위한 암호를 만듭니다.</block>
  <block id="4324c8f0a70a221bdde33868774e5a76" category="list-text">Astra Control Center의 모든 자료 집합인 Astra Control Center Operator CR "Astra_control_center_operator_deploy.YAML"을 편집합니다. 운영자 CR에서 "acc-operator-controller-manager"의 배포 정의를 찾아 이미지를 레지스트리에 푸시하는 동안 제공된 조직 이름과 함께 레지스트리의 FQDN을 입력합니다(이 예에서는 astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra`). 'Astra_image_registry'라는 텍스트를 바꾸고 'imagePullSecrets' 섹션에서 방금 만든 비밀의 이름을 입력합니다. 조작자의 기타 세부 사항을 확인하고 저장하고 닫습니다.</block>
  <block id="a27cc132b2f3001f3e9df9c40dad4bfb" category="list-text">다음 명령어를 실행해 운용자를 생성한다.</block>
  <block id="685fe82295261a8902e709081b6c9599" category="list-text">모든 Astra Control Center 리소스를 설치하기 위한 전용 네임스페이스를 만듭니다.</block>
  <block id="6d71c41a686bcfc0b0866044afd43f2b" category="list-text">해당 네임스페이스에서 이미지 레지스트리에 액세스하기 위한 암호를 만듭니다.</block>
  <block id="25eb68598d15a49d385089020950412c" category="list-text">Astra Control Center CRD 파일 "Astra_control_center_min YAML"을 편집하여 FQDN, 이미지 레지스트리 세부 정보, 관리자 이메일 주소 및 기타 세부 정보를 입력합니다.</block>
  <block id="d689979a6af0f5660231db187d212950" category="list-text">이를 위해 생성된 네임스페이스에서 Astra Control Center CRD를 생성합니다.</block>
  <block id="42b9bde28896d6478a324770641ac301" category="admonition">이전 파일 Astra_control_center_min YAML은 Astra Control Center CRD의 최소 버전이다. PVC 생성을 위한 기본값 이외의 스토리지 클래스 정의 또는 메일 알림에 대한 SMTP 세부 정보 제공 등 더 많은 제어 권한을 가진 CRD를 생성하려면 "Astra_control_center.YAML" 파일을 편집하고 필요한 세부 정보를 입력한 후 CRD 생성에 사용합니다.</block>
  <block id="e3cd33ca69b8e508c973939783f528db" category="list-text">설치가 완료되는 데 몇 분 정도 걸릴 수 있습니다. NetApp-Astra-cc 네임스페이스의 모든 Pod와 서비스가 실행 중인지 확인합니다.</block>
  <block id="9904a774f242f31a5ae37c8f75bda92b" category="list-text">설치가 완료되었는지 확인하려면 'acc-operator-controller-manager' 로그를 확인하십시오.</block>
  <block id="4af39dbe40f8a0467bbdd739a971f0ea" category="admonition">다음 메시지는 Astra Control Center가 성공적으로 설치되었음을 나타냅니다.</block>
  <block id="c27deb19babf146e6377dce25b1e70e7" category="list-text">Astra Control Center에 로그인하기 위한 사용자 이름은 CRD 파일에 제공된 관리자의 이메일 주소이며 암호는 Astra Control Center UUID에 추가된 문자열 ACC- 입니다. 다음 명령을 실행합니다.</block>
  <block id="57a7aa2eaf00ddaa73ef6b49299ade6e" category="admonition">이 예에서 암호는 'ACC-345c55a5-bf2e-21f0-84b8-b6f2bce5e95f'입니다.</block>
  <block id="5946314197ad84982efa6561d9da8302" category="list-text">traefik 서비스 로드 밸런서 IP를 가져옵니다.</block>
  <block id="298a1e8781e536e60684ab1700c60962" category="list-text">Astra Control Center CRD 파일에서 제공하는 FQDN을 가리키는 DNS 서버의 entry를 traefik 서비스의 'external-ip'에 추가한다.</block>
  <block id="0c64767e085896708adcbcc1c32c55fe" category="inline-image-macro">ACC GUI에 대한 DNS 항목을 추가합니다</block>
  <block id="1c278e58c0255ae1f09fc4fa520160b6" category="paragraph"><block ref="1c278e58c0255ae1f09fc4fa520160b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0f436b7e192eae471d7abf1265bb4c02" category="list-text">FQDN을 검색하여 Astra Control Center GUI에 로그인합니다.</block>
  <block id="cc2ba6bb5620162b64bafdca9f089718" category="inline-image-macro">Astra Control Center 로그인</block>
  <block id="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="paragraph"><block ref="9af9ac4a3dd2ab221c2c5e2bf2aaee2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="19bae630567610f1955167595b8daae3" category="list-text">CRD에 제공된 관리자 이메일 주소를 사용하여 처음으로 Astra Control Center GUI에 로그인할 경우 비밀번호를 변경해야 합니다.</block>
  <block id="90fbead2d113af1a2680805778908d98" category="inline-image-macro">Astra Control Center 필수 암호 변경</block>
  <block id="247e9fd0170ec4d9550de59ebd54787b" category="paragraph"><block ref="247e9fd0170ec4d9550de59ebd54787b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c62383e1115b208212b5a634214ae37" category="list-text">Astra Control Center에 사용자를 추가하려면 계정 &gt; 사용자 로 이동하여 추가 를 클릭하고 사용자 세부 정보를 입력한 다음 추가 를 클릭합니다.</block>
  <block id="0dd5915bd7ca0f5d34df18bf7a183d50" category="inline-image-macro">Astra Control Center에서 사용자를 생성합니다</block>
  <block id="0ea309ed2f56bdc52dd6184b9043e683" category="paragraph"><block ref="0ea309ed2f56bdc52dd6184b9043e683" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a37ba7c36c036650f5e1e7ded5232245" category="list-text">Astra Control Center를 사용하려면 모든 IT 기능에 대한 라이센스가 필요합니다. 라이센스를 추가하려면 계정 &gt; 라이센스 로 이동하고 라이센스 추가 를 클릭한 다음 라이센스 파일을 업로드합니다.</block>
  <block id="54936e9fda3da1e56a25c0056f054bce" category="inline-image-macro">Astra Control Center에서 라이센스를 추가합니다</block>
  <block id="02fd0244de299d20dfbaf9113b883030" category="paragraph"><block ref="02fd0244de299d20dfbaf9113b883030" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2044ecf5033cd4a7b9530b83075af99e" category="admonition">NetApp Astra Control Center의 설치 또는 구성 관련 문제가 발생할 경우 알려진 문제에 대한 기술 자료를 이용할 수 있습니다<block ref="d775d2705bd260971e4d33c3d1094402" category="inline-link-rx"></block>.</block>
  <block id="9204faa817ce36107d052d3cd7c886c7" category="inline-link-macro">다음: Red Hat OpenShift Clusters: NetApp과 함께 Red Hat OpenShift를 등록하십시오.</block>
  <block id="8d167505bef11e381036abf56e79f457" category="paragraph"><block ref="8d167505bef11e381036abf56e79f457" category="inline-link-macro-rx"></block></block>
  <block id="344aeea955e7674b99b8e8db2354133d" category="doc">Astra Control Center를 사용한 워크로드 마이그레이션: NetApp의 Red Hat OpenShift</block>
  <block id="8fe3ce682e72fe87e56e5b11e1c2cd36" category="inline-link-macro">다음: 추가 정보: NetApp의 Red Hat OpenShift</block>
  <block id="5dbd13d011610e2b4d57bd4ca3fd685f" category="paragraph"><block ref="5dbd13d011610e2b4d57bd4ca3fd685f" category="inline-link-macro-rx"></block></block>
  <block id="eed1ab12478f3384bfca66e2b382aefc" category="doc">NetApp ONTAP를 사용하여 Red Hat OpenShift Virtualization 배포</block>
  <block id="7dc3a10e876dbab2b177f35c0b436f3a" category="list-text">RHCOS 작업자 노드가 있는 베어 메탈 인프라에 설치된 Red Hat OpenShift 클러스터(버전 4.6 이상</block>
  <block id="b5762731ee8c7a3d9a7ce9abe3804cf0" category="list-text">설치 관리자가 제공한 인프라(IPI)를 통해 OpenShift 클러스터를 설치해야 합니다.</block>
  <block id="7ed0bc09bfa62b64806b6b5c2f4378c7" category="list-text">VM에 대한 HA를 유지하기 위해 시스템 상태 점검을 구축합니다</block>
  <block id="43b1ab0e04b8f87e603cc790967d2886" category="list-text">NetApp ONTAP 클러스터</block>
  <block id="dc7ec0964c3d39892e26bbe1593a79e2" category="list-text">OpenShift 클러스터에 설치된 Astra Trident</block>
  <block id="d4c321b9edd8d817bdc7ca442e71e3af" category="list-text">ONTAP 클러스터에서 SVM으로 구성된 Trident 백엔드</block>
  <block id="e909486a42368b2659780687c3b4a31b" category="list-text">OpenShift 클러스터에 구성된 StorageClass로, Astra Trident를 프로비저닝자로 사용합니다</block>
  <block id="cfcf3a62902e36f3d966271cc090b65c" category="list-text">Red Hat OpenShift 클러스터에 대한 클러스터 관리자 액세스</block>
  <block id="af91af16b4791d61bb2e9206807a658d" category="list-text">NetApp ONTAP 클러스터에 대한 관리 액세스</block>
  <block id="e281839ef9ef6cb1eadcc2aa7d6d63be" category="list-text">tridentctl 및 OC 도구가 설치되고 $PATH에 추가된 관리 워크스테이션</block>
  <block id="314f04ff1024e623d43e0cda9a9df410" category="paragraph">OpenShift Virtualization은 OpenShift 클러스터에 설치된 운영자에 의해 관리되기 때문에 클러스터에 대한 하드웨어 요구 사항을 계획하는 동안 메모리, CPU 및 스토리지에 추가적인 오버헤드를 부과합니다. 설명서를 참조하십시오<block ref="f9421eaa4175c3e9f421a9acaf6f00d6" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="be51a7d8687b0a6254a274c1e0100052" category="paragraph">필요한 경우 노드 배치 규칙을 구성하여 OpenShift 가상화 운영자, 컨트롤러 및 VM을 호스팅하는 OpenShift 클러스터 노드의 하위 집합을 지정할 수도 있습니다. OpenShift 가상화를 위한 노드 배치 규칙을 구성하려면 설명서를 참조하십시오<block ref="325820076f9012df5bb7261c397a527f" category="inline-link-rx"></block>.</block>
  <block id="a805b74dbb589c916a1ebf0e08601665" category="paragraph">OpenShift 가상화를 지원하는 스토리지의 경우 전용 StorageClass를 사용하여 특정 Trident 백엔드의 스토리지를 요청한 다음, 전용 SVM을 통해 지원하는 것이 좋습니다. 이를 통해 OpenShift 클러스터에서 VM 기반 워크로드에 제공되는 데이터와 관련하여 멀티 테넌시의 수준을 유지할 수 있습니다.</block>
  <block id="adb787dc1bae0d1c8dee5bd61d49c235" category="inline-link-macro">다음: 연산자를 통해 배포합니다.</block>
  <block id="6166597c75dc82b2cc8c50a0d5d74400" category="paragraph"><block ref="6166597c75dc82b2cc8c50a0d5d74400" category="inline-link-macro-rx"></block></block>
  <block id="d55adbfc40b7bcdb0606eb0bd4d88cae" category="summary">이 섹션은 Astra Trident에서 제공하는 영구 저장소를 사용하여 개인 이미지 레지스트리를 만들고 구성하는 데 사용됩니다.</block>
  <block id="8252479af4b1df9b77ceaf67fa8cd07d" category="doc">개인 이미지 레지스트리 만들기</block>
  <block id="9c864113b9e4202e111b818a53d4f506" category="inline-link">키.오</block>
  <block id="4b4141875f954447d204e6f73d93e2a0" category="inline-link">DockerHub를 참조하십시오</block>
  <block id="508888fd9f92f35e5edd97bd8083e289" category="paragraph">같은 공용 레지스트리를 사용하여 대부분의 Red Hat OpenShift 배포에 사용됩니다<block ref="b9eeebbe4a68a648d570ea2173e5ef99" category="inline-link-rx"></block> 또는<block ref="0252a6b70cc5017fa1445a78532155b6" category="inline-link-rx"></block> 고객의 대부분의 요구사항을 충족합니다. 그러나 고객이 자신의 개인 또는 사용자 지정 이미지를 호스팅하려는 경우가 있습니다.</block>
  <block id="00a3f196d7f27a1f41f5d6a7f48759d0" category="paragraph">이 절차에서는 Astra Trident 및 NetApp ONTAP에서 제공하는 영구 볼륨의 지원을 받는 개인 이미지 레지스트리 만들기에 대해 설명합니다.</block>
  <block id="d9d5e29b1b83dd9c215f5ea158ca2475" category="admonition">Astra Control Center에는 Astra 컨테이너에 필요한 이미지를 호스팅하기 위한 레지스트리가 필요합니다. 다음 섹션에서는 Red Hat OpenShift 클러스터에 비공개 레지스트리를 설정하고 Astra Control Center 설치를 지원하는 데 필요한 이미지를 푸시하는 단계를 설명합니다.</block>
  <block id="3434f6853d017037506e47f83a18c3eb" category="section-title">개인 이미지 레지스트리를 만드는 중입니다</block>
  <block id="8b2aacc194c3dc4c36ce93a57e31685c" category="list-text">현재 기본 스토리지 클래스에서 기본 주석을 제거하고 OpenShift 클러스터의 기본값으로 Trident 지원 스토리지 클래스에 주석을 추가합니다.</block>
  <block id="9b1c6f527a1a481b925397807f319e71" category="list-text">'sepec' 부분에 다음과 같은 저장 매개변수를 입력하여 Imageregfollection 연산자를 편집합니다.</block>
  <block id="9ef71cd5ccaeb28206cd64b1d184019c" category="list-text">사용자 지정 호스트 이름을 사용하여 OpenShift 경로를 생성하기 위해 'sepec' 섹션에 다음 매개 변수를 입력합니다. 저장하고 종료합니다.</block>
  <block id="e0b23bc469102cf89472e5734da92a23" category="admonition">위 라우트 구성은 루트에 대한 사용자 지정 호스트 이름을 원하는 경우에 사용됩니다. OpenShift가 기본 호스트 이름을 사용하여 경로를 만들도록 하려면 'sepec' 섹션 ddefaultRoute: true'에 다음 매개 변수를 추가할 수 있습니다.</block>
  <block id="625bd6ae5e3ac822b187b90d50edb553" category="sidebar-title">사용자 지정 TLS 인증서</block>
  <block id="08e414328e39f86009287c06a5f23d23" category="paragraph">루트에 사용자 지정 호스트 이름을 사용하는 경우 기본적으로 OpenShift Ingress 연산자의 기본 TLS 구성을 사용합니다. 그러나 루트에 사용자 지정 TLS 구성을 추가할 수 있습니다. 이렇게 하려면 다음 단계를 완료하십시오.</block>
  <block id="60d14675c3111738a4ed19528764a7b1" category="list-text">루트의 TLS 인증서 및 키로 암호를 만듭니다.</block>
  <block id="47f7f890b5c1bcb52ae163771dbf35b0" category="list-text">Imageregfollerator를 편집하고 다음 파라미터를 'sepec' 섹션에 추가합니다.</block>
  <block id="9199ff34349c38138ad0275e447e6588" category="list-text">상상의 궤변운영자를 다시 편집하고 운영자의 관리상태를 마노화 상태로 변경합니다. 저장하고 종료합니다.</block>
  <block id="2bc42a1a9a963d9a3ff2118466e5db07" category="list-text">모든 전제 조건이 충족되면 개인 이미지 레지스트리에 대해 PVC, POD 및 서비스가 생성됩니다. 몇 분 후에 레지스트리가 가동되어야 합니다.</block>
  <block id="1f3713e339193dd15865ca74785eaa2c" category="list-text">수신 운영자 OpenShift 레지스트리 경로에 기본 TLS 인증서를 사용하는 경우 다음 명령을 사용하여 TLS 인증서를 가져올 수 있습니다.</block>
  <block id="295132dd97e1047a7c09e6a48054c469" category="list-text">OpenShift 노드가 레지스트리에 액세스하여 이미지를 가져올 수 있도록 하려면 OpenShift 노드의 Docker 클라이언트에 인증서를 추가합니다. TLS 인증서를 사용하여 OpenShift-config 네임스페이스에 configmap을 만들고 이를 클러스터 이미지 구성에 패치하여 인증서를 신뢰할 수 있도록 합니다.</block>
  <block id="98f3e484001465a59149c551e8d88cf0" category="list-text">OpenShift 내부 레지스트리는 인증에 의해 제어됩니다. 모든 OpenShift 사용자는 OpenShift 레지스트리에 액세스할 수 있지만 로그인한 사용자가 수행할 수 있는 작업은 사용자 권한에 따라 다릅니다.</block>
  <block id="561d4c8140016564eee98ecbc20f9add" category="list-text">사용자 또는 사용자 그룹이 레지스트리에서 이미지를 가져올 수 있도록 하려면 사용자에게 레지스트리 뷰어 역할이 할당되어 있어야 합니다.</block>
  <block id="88167e36ea0f872788407d0e01fc1382" category="list-text">사용자 또는 사용자 그룹이 이미지를 쓰거나 푸시할 수 있도록 하려면 사용자에게 레지스트리 편집기 역할이 할당되어 있어야 합니다.</block>
  <block id="5ba9e8f3c64be4c82249856cac87a071" category="list-text">OpenShift 노드가 레지스트리에 액세스하고 이미지를 푸시 또는 풀려면 풀 비밀을 구성해야 합니다.</block>
  <block id="86e93d266c168d718105c402f43fc91e" category="list-text">그런 다음 이 풀 암호는 serviceaccount에 패치하거나 해당 pod 정의에서 참조할 수 있습니다.</block>
  <block id="fe2033a9e377624583baa802ffd9ce6d" category="list-text">서비스 계정에 패치를 적용하려면 다음 명령을 실행합니다.</block>
  <block id="59bd1dbdd3278e23e67bcabffbc4d55a" category="list-text">POD 정의의 Pull Secret을 참조하려면, 'sepec' 부분에 다음 파라미터를 추가한다.</block>
  <block id="c0c3b4069e9a2e249507f67a6a2a3b07" category="list-text">OpenShift 노드 이외의 워크스테이션에서 이미지를 푸시하거나 풀려면 다음 단계를 완료하십시오.</block>
  <block id="18f8bf05a7a278e63d921de74d2a5966" category="list-text">Docker 클라이언트에 TLS 인증서를 추가합니다.</block>
  <block id="312eaa3acf94b813cfe857f63a602724" category="list-text">OC 로그인 명령을 사용하여 OpenShift에 로그인합니다.</block>
  <block id="cb4744e00672fbf6eba33b1b86d23ae0" category="list-text">podman/docker 명령을 사용하여 OpenShift 사용자 자격 증명을 사용하여 레지스트리에 로그인합니다.</block>
  <block id="53557215e4d209eda16495dbe5f7c505" category="paragraph">+참고: kubadmin 사용자를 사용하여 개인 레지스트리에 로그인하는 경우 암호 대신 토큰을 사용합니다.</block>
  <block id="aa20d170f1ff336ec9079cf6dd1ccee3" category="list-text">이미지를 밀거나 당깁니다.</block>
  <block id="7f3417590f5bba5cf5eb34fb288135f1" category="inline-link-macro">다음으로: 솔루션 검증/사용 사례: NetApp 및 Red Hat OpenShift</block>
  <block id="7a38916784a7216f98837f315958c175" category="paragraph"><block ref="7a38916784a7216f98837f315958c175" category="inline-link-macro-rx"></block></block>
  <block id="b1a934cbded2602c4186fb43d7c8a986" category="paragraph">특정 사용 사례에 따라 컨테이너 및 가상 머신(VM)이 서로 다른 유형의 애플리케이션에 대한 최적의 플랫폼 역할을 할 수 있습니다. 따라서 많은 조직에서 일부 워크로드를 컨테이너와 VM에서 실행합니다. 조직에서는 VM용 하이퍼바이저 및 애플리케이션용 컨테이너 오케스트레이터라는 별도의 플랫폼을 관리해야 하기 때문에 추가적인 과제에 직면하게 됩니다.</block>
  <block id="7652dcfa1608f7891f4e5c9b462354be" category="paragraph">이러한 과제를 해결하기 위해 Red Hat은 OpenShift 버전 4.6부터 OpenShift Virtualization(이전의 컨테이너 네이티브 가상화)을 도입했습니다. OpenShift Virtualization 기능을 사용하면 동일한 OpenShift Container Platform 설치에서 컨테이너와 함께 가상 시스템을 실행 및 관리할 수 있으므로, 하이브리드 관리 기능을 통해 운영자를 통해 VM의 배포 및 관리를 자동화할 수 있습니다. OpenShift에서 VM을 생성하는 것 외에도 Red Hat은 OpenShift 가상화를 통해 VMware vSphere, Red Hat 가상화 및 Red Hat OpenStack Platform 배포에서 VM 가져오기를 지원합니다.</block>
  <block id="269bac1ed5128eacc45c06318333642a" category="image-alt">OpenShift 가상화</block>
  <block id="bf4e72937ad57bd2f780561c81d25d53" category="paragraph">NetApp ONTAP에서 지원하는 ACstra Trident의 도움을 받아 실시간 VM 마이그레이션, VM 디스크 클로닝, VM 스냅샷 등의 특정 기능도 OpenShift Virtualization에서 지원됩니다. 이러한 각 워크플로의 예는 이 문서의 뒷부분에서 해당 섹션에서 설명합니다.</block>
  <block id="8a5bcb32f7cb878beee68d6f84b3ada7" category="paragraph">Red Hat OpenShift Virtualization에 대한 자세한 내용은 설명서를 참조하십시오<block ref="3339eb5909b80aa35681f9f3f9478c17" category="inline-link-rx"></block>.</block>
  <block id="2bd77ae4e72f37c837a2da8cfa83e210" category="inline-link-macro">다음: 배포 전제 조건.</block>
  <block id="3a86ddb85761278fa813d15edecbc2b1" category="paragraph"><block ref="3a86ddb85761278fa813d15edecbc2b1" category="inline-link-macro-rx"></block></block>
  <block id="35be109b995061abd3392d1b01fd0e9a" category="summary">Red Hat OpenStack Platform은 안전하고 안정적인 프라이빗 OpenStack 클라우드를 생성, 배포 및 확장할 수 있는 통합 기반을 제공합니다.</block>
  <block id="5f6a8f3661e7319797d4eab6792350e6" category="doc">Red Hat OpenStack Platform의 OpenShift</block>
  <block id="639813d9aa126816c3f9e9de2a45ce17" category="paragraph">OSP는 컴퓨팅, 스토리지 및 네트워킹 리소스를 관리하는 제어 서비스 모음을 통해 구현된 서비스형 인프라(IaaS) 클라우드입니다. 이 환경은 관리자와 사용자가 OpenStack 리소스를 제어, 프로비저닝 및 자동화할 수 있는 웹 기반 인터페이스를 통해 관리됩니다. 또한, OpenStack 인프라는 광범위한 명령줄 인터페이스와 API를 통해 관리자 및 최종 사용자를 위한 전체 자동화 기능을 지원합니다.</block>
  <block id="dc34aa9761794ceabad79dc29944976e" category="paragraph">OpenStack 프로젝트는 6개월마다 업데이트된 릴리즈를 제공하는, 빠르게 개발된 커뮤니티 프로젝트입니다. 초기 Red Hat OpenStack Platform은 모든 업스트림 릴리스와 함께 새 릴리스를 게시하고 모든 3차 릴리스에 대한 장기적인 지원을 제공함으로써 이 릴리스 주기를 따라가고 있습니다. 최근, OSP 16.0 릴리스(OpenStack Train 기반)를 통해 Red Hat은 릴리즈 번호를 따라가지 않고 새로운 기능을 하위 릴리즈로 백포팅했습니다. 최신 릴리즈는 Red Hat OpenStack Platform 16.1로, Ussuri 및 Victoria의 업스트림 릴리스에서 지원되는 고급 기능을 포함합니다.</block>
  <block id="737c38dd225185612ac8fa148ae9583e" category="inline-link">Red Hat OpenStack Platform 웹 사이트</block>
  <block id="19fb2090425be8f78441166e8f1d8d6f" category="paragraph">OSP에 대한 자세한 내용은 를 참조하십시오<block ref="9c79780f89511512bd5bf54ce21d04de" category="inline-link-rx"></block>.</block>
  <block id="e2ab8aafc6151adfa655ffd5d2425e7d" category="section-title">OpenStack 서비스</block>
  <block id="ffd7a6889e6ea6965969472250235082" category="paragraph">OpenStack 플랫폼 서비스는 컨테이너로 구축되며, 상호 서비스를 격리하고 간편하게 업그레이드할 수 있습니다. OpenStack 플랫폼은 Kolla로 구축 및 관리되는 컨테이너 세트를 사용합니다. 서비스 배포는 Red Hat Custom Portal에서 컨테이너 이미지를 가져와 수행합니다. 이러한 서비스 컨테이너는 Podman 명령을 사용하여 관리되며 Red Hat OpenStack Director를 통해 배포, 구성 및 관리됩니다.</block>
  <block id="f5fdcf6d68d437c59942a35d79b8c7b1" category="paragraph"><block ref="f5fdcf6d68d437c59942a35d79b8c7b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2ba7e785c49050f48da9aacc45c2b85" category="cell">서비스</block>
  <block id="7adea0d9c77aabccd8bb67ae0a832d59" category="cell">프로젝트 이름</block>
  <block id="2938c7f7e560ed972f8a4f68e80ff834" category="cell">대시보드</block>
  <block id="85fb7708d989f936cb51ef53a8af080f" category="cell">수평선</block>
  <block id="d5a9efab6df20a9e132b774795775dde" category="cell">OpenStack 서비스를 관리하는 데 사용하는 웹 브라우저 기반 대시보드</block>
  <block id="c9c5c65fb4af9cf90eb99b3b84424189" category="cell">아이덴티티</block>
  <block id="1ce2096c300f78bbb8389ca2603e6dd9" category="cell">키스톤</block>
  <block id="91c68681aadba9c0e8308f7d0b3cc416" category="cell">OpenStack 서비스의 인증 및 권한 부여와 사용자, 프로젝트, 역할 관리를 위한 중앙 집중식 서비스</block>
  <block id="e7a39f4cb0dd0ffaaffe8fb0319dec67" category="cell">OpenStack 네트워킹</block>
  <block id="88fac409baf592beb25e285d8663edcb" category="cell">중성자</block>
  <block id="0283e46fd80198d441eb742b88cf96f1" category="cell">OpenStack 서비스의 인터페이스 간 연결을 제공합니다.</block>
  <block id="4f0550f066ae72bb8c24fc3f59c323bf" category="cell">블록 스토리지</block>
  <block id="a7173cc5cdd0e31df00cd34f058b1d33" category="cell">신더</block>
  <block id="597dab3a2b3c74e3c266b2f65ec28619" category="cell">가상 머신(VM)에 대한 영구 블록 스토리지 볼륨을 관리합니다.</block>
  <block id="a623a8d0366bf079411aa30be45b2d10" category="cell">컴퓨팅</block>
  <block id="6e747c4965495f2e26bf17e647aa0083" category="cell">노바</block>
  <block id="f13c04e9c49274cd31bd8092c8f50304" category="cell">컴퓨팅 노드에서 실행 중인 VM을 관리하고 프로비저닝합니다.</block>
  <block id="10ec3a0506fab7073649337ca7be7979" category="cell">살펴보기</block>
  <block id="d9ff71ddcb6bbbe8ad48ae8b678369d4" category="cell">VM 이미지 및 볼륨 스냅샷과 같은 리소스를 저장하는 데 사용되는 레지스트리 서비스입니다.</block>
  <block id="670aaecb1a526fbed439dad3ec353a96" category="cell">오브젝트 스토리지</block>
  <block id="ae832e9b5bda2699db45f3fa6aa8c556" category="cell">스위프트</block>
  <block id="41c380458dfcdc118ef573a2d98c6acb" category="cell">사용자가 파일과 임의 데이터를 저장 및 검색할 수 있습니다.</block>
  <block id="aa96a21412def0d916f43b639424f8e4" category="cell">원격 측정</block>
  <block id="8fb4b5e28f192236eaa9e4972f810dbd" category="cell">Ceilometer를 참조하십시오</block>
  <block id="ed622b9c64858cc66a01c58893b5d39d" category="cell">클라우드 리소스의 사용량을 측정합니다.</block>
  <block id="7d486371bb65b0633535ceba4189d8ed" category="cell">열</block>
  <block id="abaa6ebae60b74638c54a43f3341db8e" category="cell">리소스 스택의 자동 생성을 지원하는 템플릿 기반 오케스트레이션 엔진입니다.</block>
  <block id="19c939070c0b6ebbb52e1e0119b15301" category="section-title">네트워크 설계</block>
  <block id="5ddbd3cec63b14995bf6a5823b692de7" category="paragraph">NetApp OpenShift with NetApp 솔루션은 두 개의 데이터 스위치를 사용하여 25Gbps의 기본 데이터 연결을 제공합니다. 또한 스토리지 노드의 대역 내 관리를 위해 1Gbps에서 연결을 제공하는 두 개의 추가 관리 스위치와 IPMI 기능의 대역 외 관리를 사용합니다.</block>
  <block id="b81a67bf2ab52e16a62a9c71454c90ee" category="paragraph">IPMI 기능은 Red Hat OpenStack Director에서 아이러닉 베어 메탈 프로비저닝 서비스를 사용하여 Red Hat OpenStack Platform을 배포하는 데 필요합니다.</block>
  <block id="f1744781b12c15ad3b748bea44d9582b" category="section-title">VLAN 요구 사항</block>
  <block id="c546b983b02d8654c5b245147d99dcf0" category="paragraph">NetApp의 Red Hat OpenShift는 가상 VLAN(Local Area Network)을 사용하여 네트워크 트래픽을 논리적으로 다른 용도로 분리할 수 있도록 설계되었습니다. 이 구성은 고객의 요구에 맞게 확장하거나 특정 네트워크 서비스에 대한 추가 격리를 제공할 수 있습니다. 다음 표에는 NetApp 솔루션의 유효성을 검사하는 동안 솔루션을 구현하는 데 필요한 VLAN이 나와 있습니다.</block>
  <block id="87495e311a3944910e3cc0c7bee3d754" category="cell">VLAN</block>
  <block id="261addf78c7b2c961032b3dd08ba0b1f" category="cell">목적</block>
  <block id="05808f0e86c04c2a062c2e041f9e0827" category="cell">VLAN ID입니다</block>
  <block id="b7dff125c9fce628900142990708436f" category="cell">대역외 관리 네트워크</block>
  <block id="414b4843c124e72b43bccf2948a53a41" category="cell">물리적 노드 관리 및 아론용 IPMI 서비스에 사용되는 네트워크.</block>
  <block id="567f5ee3e60ecdd5338b39cab0006510" category="cell">향상시킵니다</block>
  <block id="e8cbca2d71bd2aeff622a07b4ffad6c2" category="cell">컨트롤러 노드에서 볼륨을 직접 매핑하여 Swift와 같은 인프라 서비스를 지원하는 데 사용되는 네트워크입니다.</block>
  <block id="757b505cfd34c64c85ca5b5690ee5293" category="cell">201</block>
  <block id="e103375dfc18f23e4fc072903e894fe9" category="cell">스토리지 Cinder</block>
  <block id="0bdfa6389eb47674a02f6049f342785d" category="cell">블록 볼륨을 매핑하고 환경에 구축된 가상 인스턴스에 직접 연결하는 데 사용되는 네트워크입니다.</block>
  <block id="854d6fae5ee42911677c739ee1734486" category="cell">202</block>
  <block id="772d9a23b79ccb504fa0590644934c3b" category="cell">내부 API</block>
  <block id="e44f5f63400b0975b884dc2980ee3a61" category="cell">API 통신, RPC 메시지 및 데이터베이스 통신을 사용하여 OpenStack 서비스 간의 통신에 사용되는 네트워크.</block>
  <block id="34ed066df378efacc9b924ec161e7639" category="cell">301</block>
  <block id="6252d0571760e3d285e2e41a2b1e7743" category="cell">테넌트</block>
  <block id="ea414c629935302b115bf3dabf5f827c" category="cell">Neutron은 VXLAN을 통한 터널링을 통해 각 테넌트에 자체 네트워크를 제공합니다. 네트워크 트래픽은 각 테넌트 네트워크 내에서 격리됩니다. 각 테넌트 네트워크에는 연결된 IP 서브넷이 있으며, 네트워크 네임스페이스는 여러 테넌트 네트워크에서 충돌을 일으키지 않고 동일한 주소 범위를 사용할 수 있음을 의미합니다.</block>
  <block id="577bcc914f9e55d5e4e4f82f9f00e7d4" category="cell">302)를 참조하십시오</block>
  <block id="bfd15aa26ba0ced782240c4a8b7e517e" category="cell">스토리지 관리</block>
  <block id="cdc529b5e11a981e4597195c5f1c53b5" category="cell">OpenStack Object Storage(Swift)는 이 네트워크를 사용하여 참여하는 복제본 노드 간에 데이터 객체를 동기화합니다. 프록시 서비스는 사용자 요청과 기본 스토리지 계층 간의 중간 인터페이스 역할을 합니다. 프록시는 들어오는 요청을 수신하고 요청된 데이터를 검색하는 데 필요한 복제본을 찾습니다.</block>
  <block id="11b9842e0a271ff252c1903e7132cd68" category="cell">303</block>
  <block id="5214f1e2490f3878e307fd6f81f9f77f" category="cell">PXE 를 참조하십시오</block>
  <block id="16d856c79e739181f35adfe5b791c650" category="cell">OpenStack Director는 OSP Overcloud 설치를 조율하기 위해 아이러니한 베어 메탈 프로비저닝 서비스의 일부로 PXE 부팅을 제공합니다.</block>
  <block id="966b6dfb6b0819cc10644bea3115cf20" category="cell">3484</block>
  <block id="b206a1b4ea1097761f78e8876f6da779" category="cell">외부</block>
  <block id="f2feccaa3f5d086f0b16010ff463e369" category="cell">공개적으로 제공되는 네트워크로, 그래픽 관리용 OpenStack Dashboard(Horizon)를 호스팅하고 퍼블릭 API를 사용하여 OpenStack 서비스를 관리할 수 있습니다.</block>
  <block id="dfeb9598fbfb97cc6bbcc0aff2c785d6" category="cell">3485</block>
  <block id="7b9993fac4b9a60605aa2884eb40f4a3" category="cell">대역내 관리 네트워크</block>
  <block id="32223320445c4cf46444e40ebde18b7e" category="cell">SSH 액세스, DNS 트래픽 및 NTP(Network Time Protocol) 트래픽과 같은 시스템 관리 기능에 대한 액세스를 제공합니다. 이 네트워크는 컨트롤러 노드가 아닌 노드의 게이트웨이 역할도 합니다.</block>
  <block id="ab4f2b5fd96ca65349119909c1eada2d" category="cell">3486</block>
  <block id="35b5078b5953437a59ffd4f77c464800" category="section-title">네트워크 인프라 지원 리소스</block>
  <block id="0bad9231e1bf61bc343a986739f155c1" category="paragraph">OpenShift Container Platform을 배포하기 전에 다음 인프라를 구축해야 합니다.</block>
  <block id="f2260a90424f1d412334d1b3467abd22" category="list-text">전체 호스트 이름 확인을 제공하는 DNS 서버가 하나 이상 있어야 합니다.</block>
  <block id="d70672769aa84f2a999291a645e67355" category="list-text">솔루션의 서버에 대해 시간을 동기화할 수 있는 NTP 서버가 3개 이상 있습니다.</block>
  <block id="478a3526bd6097c6b7a330fd6aae410e" category="list-text">(선택 사항) OpenShift 환경을 위한 아웃바운드 인터넷 연결</block>
  <block id="a181412a291a7d0ae8a71300abf746b8" category="section-title">운영 구축 모범 사례</block>
  <block id="0f19aa91cffca51fd061e34dee1e5c79" category="paragraph">이 섹션에는 이 솔루션을 운영 환경에 구축하기 전에 고려해야 하는 몇 가지 모범 사례가 나와 있습니다.</block>
  <block id="9a14258452ea5da50d562e08e5b9291c" category="section-title">최소 3개의 컴퓨팅 노드를 포함하는 OSP 프라이빗 클라우드에 OpenShift를 배포합니다</block>
  <block id="493fd05bc58266bcd8394072cbe81748" category="paragraph">이 문서에 설명된 검증된 아키텍처는 OSP 컨트롤러 노드 3개와 OSP 컴퓨팅 노드 2개를 구축하여 HA 운영에 적합한 최소 하드웨어 구축을 보여줍니다. 이 아키텍처는 두 컴퓨팅 노드가 가상 인스턴스를 시작하고 구축된 VM이 두 하이퍼바이저 간에 마이그레이션할 수 있는 내결함성 구성을 보장합니다.</block>
  <block id="ebe803a768c48af52bca59e6ab7df9bf" category="paragraph">Red Hat OpenShift는 처음에 3개의 마스터 노드와 함께 배포되기 때문에 2노드 구성으로 인해 같은 노드를 차지하는 마스터가 2개 이상 생길 수 있으며, 이로 인해 특정 노드를 사용할 수 없게 되면 OpenShift에 장애가 발생할 수 있습니다. 따라서 OpenShift 마스터를 균등하게 배포하고 솔루션에서 추가적인 내결함성을 얻을 수 있도록 최소 3개의 OSP 컴퓨팅 노드를 구축하는 것이 Red Hat의 모범 사례입니다.</block>
  <block id="7a595c63e0ebc069af3da46e3d1c8fee" category="section-title">가상 머신/호스트 선호도를 구성합니다</block>
  <block id="bbfdc160550acbcdb4791a961a165d5d" category="paragraph">VM/호스트 선호도를 활성화하여 여러 하이퍼바이저 노드에 OpenShift 마스터를 분산시킬 수 있습니다.</block>
  <block id="cb346122cae28dfb1fcf0811f46296a2" category="paragraph">유사성은 VM 및/또는 호스트 세트에 대한 규칙을 정의하는 방법으로, VM이 그룹의 동일한 호스트 또는 호스트에서 함께 실행되는지 아니면 다른 호스트에서 실행되는지를 결정합니다. VM 및/또는 동일한 매개 변수와 조건 집합을 가진 호스트로 구성된 선호도 그룹을 생성하여 VM에 적용됩니다. 선호도 그룹의 VM이 그룹의 동일한 호스트에서 실행되는지, 아니면 다른 호스트에서 개별적으로 실행되는지에 따라 선호도 그룹의 매개 변수는 양의 선호도 또는 음의 선호도를 정의할 수 있습니다. Red Hat OpenStack Platform에서는 서버 그룹을 생성하고 필터를 구성하여 호스트 친화성 및 반유사성 규칙을 생성하고 적용할 수 있으므로 서버 그룹의 Nova에서 구축한 인스턴스가 서로 다른 컴퓨팅 노드에 배포됩니다.</block>
  <block id="9c0af999b760fac2aa82d9d105fa7a7e" category="paragraph">서버 그룹에는 배치를 관리할 수 있는 최대 10개의 가상 인스턴스가 기본적으로 있습니다. Nova에 대한 기본 할당량을 업데이트하여 이 할당량을 수정할 수 있습니다.</block>
  <block id="de5bd213c3df23736df75636241f96de" category="admonition">OSP 서버 그룹에 대해 특정 하드 선호도/반선호도 제한이 있습니다. 별도의 노드에 구축할 리소스가 충분하지 않거나 노드 공유를 허용하는 리소스가 충분하지 않으면 VM이 부팅되지 않습니다.</block>
  <block id="8aea038e418642b1735131358c24a866" category="inline-link">OpenStack 인스턴스에 대해 선호도 및 반유사성을 구성하려면 어떻게 합니까?</block>
  <block id="d90e13a49726d9175649113d81f4caa7" category="paragraph">선호도 그룹을 구성하려면 을 참조하십시오<block ref="f5b5be16184c5362a1ca218025e91581" category="inline-link-rx"></block>.</block>
  <block id="ed3ecd4254cc054c70ddee702d7ed519" category="section-title">OpenShift 배포에 사용자 지정 설치 파일을 사용합니다</block>
  <block id="5e059b05dcf86db414d6b8cdd66bcf0f" category="paragraph">IPI를 사용하면 이 문서 앞부분에서 설명한 대화형 마법사를 통해 OpenShift 클러스터를 쉽게 배포할 수 있습니다. 그러나 클러스터 배포의 일부로 일부 기본값을 변경해야 할 수도 있습니다.</block>
  <block id="47a822101acb11c74a4877a3d0b77093" category="inline-link">Red Hat OpenShift 사용자 지정을 통해 OpenStack에 클러스터 설치</block>
  <block id="42bb5e38e5b1c611bdce679410b24d67" category="paragraph">이 경우 클러스터를 즉시 배포하지 않고 wizardarder를 실행하고 작업을 수행할 수 있습니다. 대신 나중에 클러스터를 배포할 수 있는 구성 파일이 생성됩니다. IPI 기본값을 변경해야 하거나 다중 테넌시와 같은 다른 용도로 환경에 여러 동일한 클러스터를 배포하려는 경우 매우 유용합니다. OpenShift에 대한 사용자 지정 설치 구성을 만드는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="05810b34cd92ddfe8fd049160cb24f72" category="inline-link-rx"></block>.</block>
  <block id="f5b3b6b5d5a71b2934abd61ddb561ce2" category="inline-link-macro">다음은 NetApp 스토리지 개요입니다.</block>
  <block id="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="paragraph"><block ref="dd2c34a46e688e4fd1c53e1a8d8af1d0" category="inline-link-macro-rx"></block></block>
  <block id="43288d8129021b1fe8b4bc6784e65b32" category="doc">기능: NetApp OpenShift에서 Kubernetes용 고급 클러스터 관리</block>
  <block id="de59be6e44d20d9dd12412571b745c5f" category="section-title">애플리케이션 라이프사이클 관리</block>
  <block id="fa19c463235a810b3a93333d6ee51d6c" category="paragraph">애플리케이션을 생성하고 클러스터 세트 전반에서 관리하려면,</block>
  <block id="920db239cf01c8ded4b7f364194ab540" category="list-text">측면 표시줄에서 애플리케이션 관리 로 이동하고 애플리케이션 생성 을 클릭합니다. 만들려는 응용 프로그램의 세부 정보를 입력하고 저장 을 클릭합니다.</block>
  <block id="6b41f909eb299f214abfb15580583456" category="image-alt">응용 프로그램을 만듭니다</block>
  <block id="bcb3e5b76f189a87ea350550f86de83f" category="list-text">응용 프로그램 구성 요소가 설치되면 응용 프로그램이 목록에 나타납니다.</block>
  <block id="d70fc022d09a33f4044c81cd670a71b6" category="image-alt">응용 프로그램 목록</block>
  <block id="672d326704c3be4bebf6c816a48495e7" category="list-text">이제 콘솔에서 애플리케이션을 모니터링 및 관리할 수 있습니다.</block>
  <block id="0787d747a308cc786b50363313ccf714" category="inline-link-macro">다음: 기능 - 거버넌스 및 위험.</block>
  <block id="f4c7ffc89dab76d5a6dccad54114c204" category="paragraph"><block ref="f4c7ffc89dab76d5a6dccad54114c204" category="inline-link-macro-rx"></block></block>
  <block id="1630dbfdd4887ce201ea82c71cde3d11" category="doc">Kubernetes용 고급 클러스터 관리 구축</block>
  <block id="39d08ecbb9add7bd87659df206457a73" category="list-text">허브 클러스터용 Red Hat OpenShift 클러스터(버전 4.5 이상</block>
  <block id="f41043c73a62a435944d8abfb45094cb" category="list-text">관리되는 클러스터를 위한 Red Hat OpenShift 클러스터(버전 4.4.3보다 큼</block>
  <block id="d60c66eb778a488709534045787b6a26" category="list-text">Red Hat OpenShift 클러스터에 대한 클러스터 관리자 액세스</block>
  <block id="374185e020d06ceed3f020af518a1c14" category="list-text">Kubernetes용 Advanced Cluster Management에 대한 Red Hat 서브스크립션</block>
  <block id="9afcd045ce0197d71ba631e3fbe43095" category="paragraph">Advanced Cluster Management는 OpenShift 클러스터를 위한 추가 기능으로, 허브 및 관리 클러스터에서 사용되는 기능을 기반으로 하드웨어 리소스에 대한 특정 요구 사항과 제한이 있습니다. 클러스터를 사이징할 때는 이러한 문제를 고려해야 합니다. 설명서를 참조하십시오<block ref="a5d2b81b971715f092f7296621743e22" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="65a62318377ddbc5fe3f73548dc3d677" category="paragraph">선택적으로 허브 클러스터에 인프라 구성 요소를 호스팅하는 전용 노드가 있고 해당 노드에만 고급 클러스터 관리 리소스를 설치하려면 해당 노드에 내약성과 선택기를 추가해야 합니다. 자세한 내용은 설명서를 참조하십시오<block ref="df4d7b25534e8f26e8ab3acc1c646101" category="inline-link-rx"></block>.</block>
  <block id="3f71071db67a1d6b5b63e2d9cc6b0e93" category="inline-link-macro">다음: 설치.</block>
  <block id="2a9cc50366c16ec40c1a5132f8fe5533" category="paragraph"><block ref="2a9cc50366c16ec40c1a5132f8fe5533" category="inline-link-macro-rx"></block></block>
  <block id="ad3a2e9007d848afd0c15ffc402781bb" category="doc">워크플로우: NetApp ONTAP 기반의 Red Hat OpenShift 가상화</block>
  <block id="4b6826f4f20a8e7e7a3b42ccb81d514f" category="section-title">VM 클로닝</block>
  <block id="4a56de086437c8a56c22bccd4e7ed9ba" category="paragraph">OpenShift에서 기존 VM의 복제는 Astra Trident의 Volume CSI 클로닝 기능을 통해 이루어집니다. CSI 볼륨 클로닝은 기존 PVC를 PV를 복제하여 데이터 소스로 사용하여 새로운 PVC를 생성할 수 있습니다. 새 PVC가 생성된 후, 별도의 요소로 작동하며 원본 PVC에 대한 링크 또는 종속성 없이 작동합니다.</block>
  <block id="0ea820e58acf3d0c3acac3f64518c517" category="image-alt">VM 클로닝 아키텍처</block>
  <block id="a1dbf280b3b5da141010127710d68ba7" category="paragraph">CSI 볼륨 클로닝에는 다음과 같은 몇 가지 제한 사항이 있습니다.</block>
  <block id="7f8cb9ac957166d3d134bf9df8861f5b" category="list-text">원본 PVC와 대상 PVC는 동일한 프로젝트에 있어야 합니다.</block>
  <block id="058d8141e417cb514573ba1a70e2e0cd" category="list-text">클론 복제는 동일한 스토리지 클래스 내에서 지원됩니다.</block>
  <block id="611b1b227968093cc5c73e69f7ac0fda" category="list-text">클론 복제는 소스 볼륨과 타겟 볼륨이 동일한 볼륨 모드 설정을 사용하는 경우에만 수행할 수 있습니다. 예를 들어 블록 볼륨은 다른 블록 볼륨에만 클론을 생성할 수 있습니다.</block>
  <block id="557d036c1a69ab0889c0820deb1e88de" category="paragraph">OpenShift 클러스터의 VM은 두 가지 방법으로 클론을 생성할 수 있습니다.</block>
  <block id="e1230e5b1f51d793ea14fb31df500399" category="list-text">소스 VM을 종료합니다</block>
  <block id="29ec5d7b455e19c4f8141df877a9af0a" category="list-text">소스 VM을 활성 상태로 유지합니다</block>
  <block id="84d19f7437a8329c49099517eccd37dc" category="section-title">소스 VM을 종료합니다</block>
  <block id="9057e692817874e4c563dec1fa8c1700" category="paragraph">VM을 종료하여 기존 VM을 복제하는 것은 Astra Trident의 지원을 통해 구현되는 네이티브 OpenShift 기능입니다. VM을 클론 복제하려면 다음 단계를 완료하십시오.</block>
  <block id="ea1abad541ee7994705555d53c0281c3" category="list-text">워크로드 &gt; 가상화 &gt; 가상 머신 으로 이동하고 복제할 가상 머신 옆에 있는 줄임표를 클릭합니다.</block>
  <block id="375000776ee4694734b1d066c46e7096" category="list-text">Clone Virtual Machine을 클릭하고 새 VM에 대한 세부 정보를 제공합니다.</block>
  <block id="b22c43b0906ef8ba78f3fbb7d5b1ff20" category="image-alt">VM을 복제합니다</block>
  <block id="cf702a835a3fd4b019603d29ec402106" category="list-text">Clone Virtual Machine을 클릭합니다. 그러면 소스 VM이 종료되고 클론 VM이 생성됩니다.</block>
  <block id="82cfb538b52ee01d4a9901d4d2cfad4d" category="list-text">이 단계가 완료된 후 복제된 VM의 컨텐츠를 액세스하고 확인할 수 있습니다.</block>
  <block id="3c7aa222cd4c9ee079b31567a347c05f" category="paragraph">기존 VM은 소스 VM의 기존 PVC를 클로닝한 다음 복제된 PVC를 사용하여 새 VM을 생성하여 복제할 수도 있습니다. 이 방법을 사용하면 소스 VM을 종료할 필요가 없습니다. 다음 단계를 완료하여 VM을 종료하지 않고 클론을 생성합니다.</block>
  <block id="81ab8abf2317781c0eb6f4deeaeea5a5" category="list-text">Storage &gt; PersistentVolumeClaims 로 이동하고 소스 VM에 연결된 PVC 옆에 있는 줄임표를 클릭합니다.</block>
  <block id="545ce69617c1c157be6073dcc63bfbae" category="list-text">Clone PVC(PVC 복제) 를 클릭하고 새 PVC에 대한 세부 정보를 제공합니다.</block>
  <block id="e659422cf737778a2fb1cdd50cc8003e" category="image-alt">PVC 복제</block>
  <block id="07c24ffdbaf9583216cca9f030058c11" category="list-text">그런 다음 클론 을 클릭합니다. 그러면 새 VM에 대한 PVC가 생성됩니다.</block>
  <block id="5ba8ff3c009683ee423b0884c25360d0" category="list-text">워크로드 &gt; 가상화 &gt; 가상 시스템으로 이동하고 생성 &gt; YAML을 클릭합니다.</block>
  <block id="cd32f6b0aebb29494cbc9cc21a10c926" category="list-text">SPEC&gt;template&gt;SPEC&gt;volumes 섹션에서 컨테이너 디스크 대신 복제된 PVC를 연결합니다. 요구 사항에 따라 새 VM에 대한 기타 모든 세부 정보를 제공합니다.</block>
  <block id="75b0d3500d81c7799a5b84eca57d6d04" category="list-text">생성 을 클릭하여 새 VM을 생성합니다.</block>
  <block id="19e005e0709674157e554800d5ea7ef9" category="list-text">VM이 성공적으로 생성된 후 새 VM이 소스 VM의 클론인지 액세스하고 확인합니다.</block>
  <block id="fdbfc131399a8776fecd30fa821de4d0" category="inline-link-macro">다음: 워크플로우: 스냅샷으로부터 VM을 생성하십시오.</block>
  <block id="c5c4205f35e83d4dc33cfa7821ceb5a7" category="paragraph"><block ref="c5c4205f35e83d4dc33cfa7821ceb5a7" category="inline-link-macro-rx"></block></block>
  <block id="c12328be87e4d79e79b3db80bd6ff03f" category="list-text">NetApp ONTAP 문서 센터</block>
  <block id="1b214ce6b630c9ad822fc984e20f3675" category="inline-link"><block ref="1b214ce6b630c9ad822fc984e20f3675" category="inline-link-rx"></block></block>
  <block id="91fe04078e98f81bd39430c985bba713" category="paragraph"><block ref="91fe04078e98f81bd39430c985bba713" category="inline-link-rx"></block></block>
  <block id="0b98c026ddf9e406d439373d2dab724b" category="inline-link"><block ref="0b98c026ddf9e406d439373d2dab724b" category="inline-link-rx"></block></block>
  <block id="63d46b0efa85a58196faf13e5aa20d7d" category="paragraph"><block ref="63d46b0efa85a58196faf13e5aa20d7d" category="inline-link-rx"></block></block>
  <block id="3c572f7c92d4b91543f94621d03cf993" category="list-text">Google Cloud의 Anthos</block>
  <block id="712cab3570d004ba67a47d7ff8df208b" category="inline-link"><block ref="712cab3570d004ba67a47d7ff8df208b" category="inline-link-rx"></block></block>
  <block id="a5526c10a9a8b42f6aab833b33a57eaf" category="paragraph"><block ref="a5526c10a9a8b42f6aab833b33a57eaf" category="inline-link-rx"></block></block>
  <block id="aa69ca65720dd2e4eef99ebfb7816268" category="list-text">Anthos의 Bare Metal</block>
  <block id="a3df86c144842761b9bcb0b540edbefe" category="inline-link"><block ref="a3df86c144842761b9bcb0b540edbefe" category="inline-link-rx"></block></block>
  <block id="8d3014f959efddffaea116898b063218" category="paragraph"><block ref="8d3014f959efddffaea116898b063218" category="inline-link-rx"></block></block>
  <block id="8921c6e9843ba7487c77f4dce1467111" category="summary">NetApp Element 소프트웨어는 모듈식의 확장 가능한 성능을 제공하며, 각 스토리지 노드는 환경에 보장된 용량과 처리량을 제공합니다. NetApp Element 시스템은 단일 클러스터에서 4개 노드에서 100개 노드로 확장할 수 있으며 다양한 고급 스토리지 관리 기능을 제공합니다.</block>
  <block id="5d77fe4a6bb4c5e88c5c18510b3c4749" category="doc">NetApp Element: NetApp의 Red Hat OpenShift</block>
  <block id="53c583e55a36ad49234df678a2dbcf45" category="paragraph">NetApp Element 소프트웨어는 모듈식의 확장 가능한 성능을 제공하며, 각 스토리지 노드는 환경에 보장된 용량과 처리량을 제공합니다. NetApp Element 시스템은 단일 클러스터에서 4개 노드에서 100개 노드로 확장할 수 있으며 다양한 고급 스토리지 관리 기능을 제공합니다.</block>
  <block id="22f48c519a73ce4759edffb196331422" category="paragraph"><block ref="22f48c519a73ce4759edffb196331422" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27765508a97a89684590658c3465fb70" category="inline-link">NetApp SolidFire 웹 사이트</block>
  <block id="d37eaafbb6dfb29673d63ff988ff4f41" category="paragraph">NetApp Element 스토리지 시스템에 대한 자세한 내용은 를 참조하십시오<block ref="0d1d77e6774527457304fa15f73899a1" category="inline-link-rx"></block>.</block>
  <block id="bd4ffcaabbe4a4f83fbfaaa2e34dc8a3" category="section-title">iSCSI 로그인 리디렉션 및 자동 복구 기능</block>
  <block id="dbafa7c074ef7efc3c778b69c0ad31b5" category="paragraph">NetApp Element 소프트웨어는 기존 TCP/IP 네트워크에서 SCSI 명령을 캡슐화하는 표준 방법인 iSCSI 스토리지 프로토콜을 활용합니다. SCSI 표준이 바뀌거나 이더넷 네트워크의 성능이 향상되면 iSCSI 스토리지 프로토콜이 아무런 변경 없이 이점을 제공합니다.</block>
  <block id="23e6b910b28346537f5696478fffe779" category="paragraph">모든 스토리지 노드에 관리 IP와 스토리지 IP가 있지만 NetApp Element 소프트웨어는 클러스터의 모든 스토리지 트래픽에 단일 스토리지 가상 IP 주소(SVIP 주소)를 알립니다. iSCSI 로그인 프로세스의 일환으로, 스토리지는 타겟 볼륨이 다른 주소로 이동되었다는 응답을 할 수 있으므로 협상 프로세스를 진행할 수 없습니다. 그런 다음 호스트는 호스트 측 재구성이 필요 없는 프로세스에서 새 주소로 로그인 요청을 다시 실행합니다. 이 프로세스를 iSCSI 로그인 리디렉션이라고 합니다.</block>
  <block id="b8603f3d585261d0005c7c5e51108d19" category="paragraph">iSCSI 로그인 리디렉션은 NetApp Element 소프트웨어 클러스터의 핵심 부분입니다. 호스트 로그인 요청이 수신되면 노드는 IOPS 및 볼륨의 용량 요구 사항에 따라 트래픽을 처리할 클러스터 구성원을 결정합니다. 볼륨은 NetApp Element 소프트웨어 클러스터에 분산되며, 단일 노드에서 해당 볼륨에 대해 너무 많은 트래픽을 처리하고 있거나 새 노드를 추가한 경우 재배포됩니다. 지정된 볼륨의 여러 복사본이 스토리지 전체에 할당됩니다.</block>
  <block id="772db62cf9ecb837ed4f0a91a5963492" category="paragraph">이러한 방식으로 노드 장애 후 볼륨 재배포가 수행되면 로그아웃 이후에 호스트 연결에 영향을 주지 않고 새 위치로 리디렉션하여 로그인할 수 있습니다. iSCSI 로그인 리디렉션을 사용하는 NetApp Element 소프트웨어 클러스터는 무중단 업그레이드 및 운영이 가능한 자동 복구, 스케일아웃 아키텍처입니다.</block>
  <block id="5c8e89de2b8e6e2f103d858b59e5aca0" category="section-title">NetApp Element 소프트웨어 클러스터 QoS</block>
  <block id="16600c3602f9acbaa2286f34135f6bb8" category="paragraph">NetApp Element 소프트웨어 클러스터를 사용하면 볼륨별로 QoS를 동적으로 구성할 수 있습니다. 볼륨당 QoS 설정을 사용하면 정의한 SLA에 따라 스토리지 성능을 제어할 수 있습니다. 다음과 같이 구성 가능한 세 가지 매개 변수는 QoS를 정의합니다.</block>
  <block id="d91a826908d0c27cf5d21d2152292ab0" category="list-text">* 최소 IOPS. * NetApp Element 소프트웨어 클러스터가 볼륨에 제공하는 최소 유지 IOPS 수입니다. 볼륨에 대해 구성된 최소 IOPS는 볼륨의 보장된 성능 수준입니다. 볼륨당 성능이 이 수준 아래로 떨어지지 않습니다.</block>
  <block id="f8cd3dfe225577e230dc2699ebbbfe34" category="list-text">* 최대 IOPS. * NetApp Element 소프트웨어 클러스터가 특정 볼륨에 제공하는 최대 지속 IOPS 수입니다.</block>
  <block id="827b5871d6ce8f2203a567ef3024f072" category="list-text">* 버스트 IOPS. * 짧은 버스트 시나리오에서 허용되는 최대 IOPS 수입니다. 버스트 지속 시간 설정은 기본 1분으로 구성할 수 있습니다. 볼륨이 최대 IOPS 레벨 미만으로 실행 중인 경우 버스트 크레딧이 누적됩니다. 성능 수준이 매우 높고 푸시되면 볼륨에서 최대 IOPS를 초과하는 짧은 IOPS 버스트가 허용됩니다.</block>
  <block id="e95bb6f1e85d1ffe0eb983fd5e0fbde8" category="section-title">멀티 테넌시</block>
  <block id="086d1eacd91102f734387f0266326344" category="paragraph">보안 멀티 테넌시는 다음과 같은 기능을 통해 구현됩니다.</block>
  <block id="97bee3e8d0db89b2cd19eba861763e7a" category="list-text">* 보안 인증. * CHAP(Challenge-Handshake Authentication Protocol)는 보안 볼륨 액세스에 사용됩니다. LDAP(Lightweight Directory Access Protocol)는 관리 및 보고를 위해 클러스터에 안전하게 액세스하는 데 사용됩니다.</block>
  <block id="3918507b16aa3cc38274c29da446d90f" category="list-text">* 볼륨 액세스 그룹(VAG). * 선택적으로 VAG를 인증 대신 사용하여 iSCSI 이니시에이터 관련 IQN(iSCSI 정규화된 이름)을 하나 이상의 볼륨에 매핑할 수 있습니다. vag의 볼륨에 액세스하려면 볼륨 그룹에 대해 이니시에이터 IQN이 허용된 IQN 목록에 있어야 합니다.</block>
  <block id="28328e0db9c18c9ada207997f806124f" category="list-text">* VLAN(Tenant Virtual LAN). * 네트워크 수준에서 VLAN을 사용하면 iSCSI 초기자와 NetApp Element 소프트웨어 클러스터 간의 엔드 투 엔드 네트워크 보안을 쉽게 유지할 수 있습니다. 워크로드 또는 테넌트를 격리하기 위해 생성된 모든 VLAN에 대해 NetApp Element 소프트웨어는 특정 VLAN을 통해서만 액세스할 수 있는 별도의 iSCSI 대상 SVIP 주소를 생성합니다.</block>
  <block id="5fec85270e969240cc769f429b9c8cdc" category="list-text">* VRF 지원 VLAN. * 데이터 센터의 보안 및 확장성을 더욱 지원하기 위해 NetApp Element 소프트웨어를 사용하면 VRF와 유사한 기능에 대한 테넌트 VLAN을 활성화할 수 있습니다. 이 기능은 다음과 같은 두 가지 주요 기능을 추가합니다.</block>
  <block id="fca8436836d48525b8d98babbfd68518" category="list-text">* 테넌트 SVIP 주소로 L3 라우팅 * 이 기능을 사용하면 NetApp Element 소프트웨어 클러스터의 VLAN 또는 별도의 네트워크에서 iSCSI 초기자를 설정할 수 있습니다.</block>
  <block id="eaea554ececf5b64515f0833c56b3de4" category="list-text">중복 또는 중복 IP 서브넷.* 이 기능을 사용하면 테넌트 환경에 템플릿을 추가할 수 있으므로 각 테넌트 VLAN에 동일한 IP 서브넷의 IP 주소를 할당할 수 있습니다. 이 기능은 IPspace의 규모 및 보존이 중요한 서비스 공급자 환경에 유용할 수 있습니다.</block>
  <block id="c08531651ee4977d5020da1b84003631" category="section-title">엔터프라이즈 스토리지 효율성</block>
  <block id="78712bd6b2d8e5531e122b5e849fb842" category="paragraph">NetApp Element 소프트웨어 클러스터는 전반적인 스토리지 효율성과 성능을 높여줍니다. 다음 기능은 인라인으로 수행되며 항상 켜져 있으며 사용자가 수동으로 구성할 필요가 없습니다.</block>
  <block id="6893566c26b28e197cebdefdcc6af3ae" category="list-text">* 데이터 중복 제거. * 이 시스템은 고유한 4K 블록만 저장합니다. 중복된 4K 블록이 이미 저장된 데이터 버전에 자동으로 연결됩니다. 데이터는 블록 드라이브에 있으며 NetApp Element 소프트웨어 Helix 데이터 보호를 사용하여 미러링됩니다. 이 시스템을 사용하면 시스템 내에서 용량 소비 및 쓰기 작업이 크게 줄어듭니다.</block>
  <block id="2e5dd3a69ccb3f04d7814fc742318204" category="list-text">* 압축. * 압축은 데이터를 NVRAM에 쓰기 전에 인라인으로 수행됩니다. 데이터가 압축되어 4K 블록으로 저장되고 시스템에서 압축된 상태로 유지됩니다. 이 압축을 통해 클러스터 전체의 용량 소비, 쓰기 작업 및 대역폭 사용량이 크게 줄어듭니다.</block>
  <block id="215de8162cb5ac909005881f92812fb0" category="list-text">* 씬 프로비저닝. * 이 기능은 필요한 시간에 적절한 양의 스토리지를 제공하여 오버프로비저닝된 볼륨 또는 충분히 활용되지 않는 볼륨으로 인한 용량 소비를 제거합니다.</block>
  <block id="95f1b89c8e9c330fcfdc8ec84633bfe6" category="list-text">* Helix. * 개별 볼륨의 메타데이터는 메타데이터 드라이브에 저장되며 이중화를 위해 보조 메타데이터 드라이브로 복제됩니다.</block>
  <block id="da9c9b2b4164632e569069fe1e7c53ee" category="admonition">요소는 자동화를 위해 설계되었습니다. 모든 스토리지 기능은 API를 통해 사용할 수 있습니다. 이러한 API는 UI에서 시스템을 제어하는 데 사용하는 유일한 방법입니다.</block>
  <block id="28bbba0205a8bfd9f8f2da8b73522dc7" category="inline-link-macro">다음으로, NetApp 스토리지 통합 개요를 살펴보겠습니다.</block>
  <block id="d61c98dcb4bec6f3e1213776ebb1e6c3" category="paragraph"><block ref="d61c98dcb4bec6f3e1213776ebb1e6c3" category="inline-link-macro-rx"></block></block>
  <block id="aa9095c5ba77e3549672e5c4fae1fedc" category="doc">베어 메탈 기반 OpenShift</block>
  <block id="a62e902f0d244d960eddf2f14d3afa6f" category="paragraph">베어 메탈 기반 OpenShift는 상용 서버에 OpenShift Container Platform을 자동으로 배포하는 기능을 제공합니다.</block>
  <block id="0e05c6235b67ae8e5b743c9ca77358fa" category="paragraph">베어 메탈 기반 OpenShift는 OpenShift의 가상 배포와 유사하며 컨테이너화 준비가 되지 않은 애플리케이션에 대해 가상화된 워크로드를 지원하는 동시에 OpenShift 클러스터의 간편한 배포, 신속한 프로비저닝 및 확장을 제공합니다. 베어 메탈에 배포하면 OpenShift 환경 외에도 호스트 하이퍼바이저 환경을 관리하는 데 필요한 추가 오버헤드가 필요하지 않습니다. 베어 메탈 서버에 직접 배포하면 호스트와 OpenShift 환경 간에 리소스를 공유하는 데 따른 물리적 오버헤드 제한도 줄일 수 있습니다.</block>
  <block id="67a3852a946bc539243cc1e5f8982d03" category="section-title">Bare Metal의 OpenShift는 다음과 같은 기능을 제공합니다.</block>
  <block id="9a3c3034787ddbd4af974d73f795c75a" category="list-text">IPI 또는 보조 설치 프로그램 배포.* 설치 관리자 프로비저닝 인프라(IPI)에 의해 배포된 OpenShift 클러스터를 베어메탈 서버에 배포하면 고객은 하이퍼바이저 계층을 관리할 필요 없이 다재다능하고 쉽게 확장 가능한 OpenShift 환경을 상용 서버에 직접 배포할 수 있습니다.</block>
  <block id="bf995f5252e568d22b265ec62c16914c" category="list-text">* 컴팩트 클러스터 설계. * 하드웨어 요구 사항을 최소화하기 위해 베어 메탈의 OpenShift를 사용하면 OpenShift 컨트롤 플레인 노드가 작업자 노드 및 호스트 컨테이너 역할을 할 수 있도록 하여 단 3개의 노드로 구성된 클러스터를 배포할 수 있습니다.</block>
  <block id="13442dfd439ae0a377b0a2d2d9df1709" category="list-text">OpenShift 가상화 * OpenShift는 OpenShift 가상화를 사용하여 컨테이너 내에서 가상 머신을 실행할 수 있습니다. 이 컨테이너 네이티브 가상화는 컨테이너 내부의 KVM 하이퍼바이저를 실행하며 VM 스토리지용 영구 볼륨을 연결합니다.</block>
  <block id="6e6a5272d3c6f8eceb96e3c19f0faaf6" category="list-text">* AI/ML 최적화 인프라 * GPU 기반 작업자 노드를 OpenShift 환경에 통합하고 OpenShift Advanced Scheduling을 활용하여 머신 러닝 애플리케이션을 위한 Kubeflow와 같은 애플리케이션을 배포합니다.</block>
  <block id="6bc136fcf409560a1029f6f323619bbf" category="paragraph">NetApp 기반 Red Hat OpenShift 솔루션은 2개의 데이터 스위치를 사용하여 25Gbps의 기본 데이터 연결을 제공합니다. 또한 스토리지 노드의 대역 내 관리를 위해 1Gbps의 접속 기능을 제공하는 관리 스위치 2개와 IPMI 기능의 대역 외 관리를 사용합니다.</block>
  <block id="17fea9675576fc9c72deb9501a5fd16a" category="paragraph">OpenShift Bare-Metal IPI 배포의 경우 별도의 네트워크에 네트워크 인터페이스가 연결되어 있어야 하는 Red Hat Enterprise Linux 8 시스템인 공급자 노드를 만들어야 합니다.</block>
  <block id="2f42f99315e0171a6e5c61957ae4689c" category="list-text">* 프로비저닝 네트워크. * 이 네트워크는 베어 메탈 노드를 부팅하고 OpenShift 클러스터를 배포하는 데 필요한 이미지와 패키지를 설치하는 데 사용됩니다.</block>
  <block id="aba727a2dc3dd836a33a2022bb2a9c3f" category="list-text">* 베어 메탈 네트워크. * 이 네트워크는 구축된 클러스터의 공용 통신에 사용됩니다.</block>
  <block id="7633522f66aaba6bc4bb2c25d299d287" category="paragraph">고객은 공급자 노드를 설정하기 위해 배포 목적으로 프로비저닝되는 부트스트랩 VM과 노드 자체에서 트래픽을 제대로 라우팅할 수 있도록 브리지 인터페이스를 생성합니다. 클러스터를 구축한 후에는 API 및 수신 VIP 주소가 부트스트랩 노드에서 새로 구축된 클러스터로 마이그레이션됩니다.</block>
  <block id="963d7d04e1f1692a7fc49ae899123dbd" category="paragraph">다음 이미지는 IPI 배포 중 및 배포 완료 후 환경을 보여줍니다.</block>
  <block id="096e71732ebcd1f43544a7159596cb17" category="paragraph"><block ref="096e71732ebcd1f43544a7159596cb17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bb18861dc375756df1a31b7ed3c03f38" category="paragraph"><block ref="bb18861dc375756df1a31b7ed3c03f38" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5a0639a1bbc3695e0ebaf4c3affe363" category="paragraph">NetApp OpenShift의 경우 가상 LAN(VLAN)을 사용하여 네트워크 트래픽을 논리적으로 다른 용도로 분리할 수 있도록 설계되었습니다.</block>
  <block id="3d9073c9e531118eb3aff0f20647c86f" category="cell">베어 메탈 노드 및 IPMI에 대한 관리</block>
  <block id="f53272342c85041784b2d5136e6eaa7d" category="cell">베어 메탈 네트워크</block>
  <block id="44a94f76baabd05ab407f76c946326c8" category="cell">클러스터를 사용할 수 있게 되면 OpenShift 서비스를 위한 네트워크가 형성됩니다</block>
  <block id="fc221309746013ac554571fbd180e1c8" category="cell">181</block>
  <block id="11405696f0e53417a3847f430a7b8ed0" category="cell">네트워크 프로비저닝</block>
  <block id="846325c36d78e7582d8bfcab277ca67a" category="cell">IPI를 통한 PXE 부팅 및 베어 메탈 노드 설치를 위한 네트워크</block>
  <block id="eb5f501445f81cb1f7f4cf290565f9c8" category="admonition">이러한 각 네트워크는 VLAN에 의해 가상으로 분리되지만 PXE 부팅 시퀀스 중에 VLAN 태그를 전달할 방법이 없으므로 각 물리적 포트는 기본 VLAN이 할당된 액세스 모드에서 설정해야 합니다.</block>
  <block id="3ab0ae61b5256f874297403903fd5afc" category="paragraph">OpenShift 컨테이너 플랫폼을 배포하기 전에 다음 인프라를 구축해야 합니다.</block>
  <block id="06a9d12a76441fd395abeba7bf0d7b91" category="list-text">대역내 관리 네트워크 및 VM 네트워크에서 액세스할 수 있는 전체 호스트 이름 확인을 제공하는 DNS 서버가 하나 이상 있어야 합니다.</block>
  <block id="905a394004d9055ec4708e53880cac66" category="list-text">대역내 관리 네트워크 및 VM 네트워크에서 액세스할 수 있는 NTP 서버가 하나 이상 있어야 합니다.</block>
  <block id="447cb4a01965e3df01476db3576e0399" category="list-text">(선택 사항) 대역내 관리 네트워크와 VM 네트워크 모두에 대한 아웃바운드 인터넷 연결.</block>
  <block id="b611590ed189a9cbc27648402168f00a" category="inline-link-macro">다음은 NetApp 스토리지 개요입니다.</block>
  <block id="2be0276ec05c9b03a47573ad9795095a" category="paragraph"><block ref="2be0276ec05c9b03a47573ad9795095a" category="inline-link-macro-rx"></block></block>
  <block id="25d77826c061b84a0c036f43e02aa129" category="doc">OpenShift Virtualization 설치: NetApp과 함께 Red Hat OpenShift의 설치</block>
  <block id="60423d24e49c8db4836be0abd09fb78d" category="doc">NetApp ONTAP iSCSI 구성</block>
  <block id="8e0bd613649f232fe1f718134898ea21" category="paragraph">NetApp ONTAP 스토리지 시스템과의 Trident 통합을 활성화하려면 스토리지 시스템과의 통신을 지원하는 백엔드를 생성해야 합니다.</block>
  <block id="3ca99f0e09d3b1ea097a113dd72c9317" category="list-text">다운로드한 설치 아카이브에서 사용할 수 있는 예제 백엔드 파일이 'ample-input' 폴더 계층에 있습니다. iSCSI를 지원하는 NetApp ONTAP 시스템의 경우 'backend-ontap-san.json' 파일을 작업 디렉토리에 복사하고 파일을 편집합니다.</block>
  <block id="fa346018b8222fdc195d0b73016cf5a0" category="list-text">이 파일에서 관리 LIF, dataLIF, svm, 사용자 이름 및 암호 값을 편집합니다.</block>
  <block id="38ace6c607c7db13cd4cc319f9b0225b" category="list-text">이 백엔드 파일을 배치하고 다음 명령을 실행하여 첫 번째 백엔드를 생성합니다.</block>
  <block id="d8f188eff4c16fa87dd87f51db847f73" category="list-text">백엔드가 생성되면 다음 번에 스토리지 클래스를 생성해야 합니다. 백엔드와 마찬가지로 샘플 입력 폴더에서 사용 가능한 환경에 대해 편집할 수 있는 샘플 스토리지 클래스 파일이 있습니다. 작업 디렉토리에 복사하고 생성된 백엔드를 반영하기 위해 필요한 편집을 수행합니다.</block>
  <block id="eb22c0d536e50f388da6dfd91ba4c0b6" category="list-text">이 파일에 대해 편집해야 하는 유일한 방법은 새로 생성된 백엔드에서 스토리지 드라이버의 이름으로 'backendType' 값을 정의하는 것입니다. 또한 이름 필드 값을 기록해 둡니다. 이 값은 나중에 참조해야 합니다.</block>
  <block id="3ae96676432caea17595a22525bd9660" category="admonition">이 파일에 정의된 fschType이라는 선택적 필드가 있습니다. iSCSI 백엔드에서 이 값은 특정 Linux 파일 시스템 유형(XFS, ext4 등)으로 설정하거나, OpenShift가 사용할 파일 시스템을 결정할 수 있도록 삭제할 수 있습니다.</block>
  <block id="7183f006fd74d941c838f003380f3f46" category="list-text">"OC" 명령을 실행하여 스토리지 클래스를 생성합니다.</block>
  <block id="71cb54ab06aa16af27a0ec2157972648" category="list-text">스토리지 클래스를 생성한 후 첫 번째 영구 볼륨 클레임(PVC)을 생성해야 합니다. 샘플 입력에도 이 작업을 수행하는 데 사용할 수 있는 PVC-BASIC.YAML 파일이 있습니다.</block>
  <block id="afc499f2f95809cedce5c8922067065f" category="list-text">이 파일에 대해 편집해야 하는 유일한 내용은 'torageClassName' 필드가 방금 만든 필드와 일치한다는 것입니다. PVC 정의는 프로비저닝할 작업 부하에 따라 필요에 따라 추가로 사용자 정의할 수 있습니다.</block>
  <block id="02eb9c3824b0b8eae9723daa7a2912d1" category="list-text">OC 명령을 실행하여 PVC를 생성한다. 생성 중인 백업 볼륨의 크기에 따라 생성 시간이 다소 걸릴 수 있으므로 완료 시 프로세스를 확인할 수 있습니다.</block>
  <block id="90dc29cb8c225faef816aefeaad3027d" category="inline-link-macro">다음으로 솔루션 검증/사용 사례를 살펴보겠습니다.</block>
  <block id="99632a9c8a0d8380e77d9d11f96edfdc" category="paragraph"><block ref="99632a9c8a0d8380e77d9d11f96edfdc" category="inline-link-macro-rx"></block></block>
  <block id="8b14fb34f5313442bf2fdc4d80edc389" category="summary">이 섹션에서는 NetApp 배포를 통해 Red Hat OpenShift를 사용자 지정하려는 사용자를 위한 로드 밸런싱 장치 옵션을 탐구하는 데 사용됩니다.</block>
  <block id="87beaa6eff6159cd7270b2a4e71c10a4" category="doc">로드 밸런싱 장치 옵션 알아보기: NetApp의 Red Hat OpenShift</block>
  <block id="a802e9436bb9bcbfa2b88bb549e28503" category="paragraph">대부분의 경우 Red Hat OpenShift는 경로를 통해 외부 세계에 애플리케이션을 제공합니다. 외부에서 연결할 수 있는 호스트 이름을 제공하여 서비스가 노출됩니다. 정의된 라우트와 서비스로 식별되는 엔드포인트는 OpenShift 라우터에서 외부 클라이언트에 명명된 연결을 제공하기 위해 사용될 수 있습니다.</block>
  <block id="0aa971b4d33bdc82c500a35166e588c8" category="paragraph">그러나 경우에 따라 적절한 서비스를 제공하기 위해 응용 프로그램에서 사용자 지정 로드 밸런싱 장치를 구축하고 구성해야 하는 경우도 있습니다. 한 가지 예로는 NetApp Astra Control Center가 있습니다. 이러한 요구 사항을 충족하기 위해 다양한 사용자 지정 로드 밸런서 옵션을 평가했습니다. 설치 및 구성에 대한 자세한 내용은 이 섹션을 참조하십시오.</block>
  <block id="6914d9014ff3e2cb99cabff26b55a0bc" category="paragraph">다음 페이지에서는 NetApp OpenShift에서 검증된 로드 밸런서 옵션에 대한 추가 정보를 제공합니다.</block>
  <block id="2b545f7c547a71eaeda9dcb451aea0c5" category="inline-link-macro">메탈리스</block>
  <block id="eaefba36e93c0d0177c3de1143bd08dd" category="list-text"><block ref="eaefba36e93c0d0177c3de1143bd08dd" category="inline-link-macro-rx"></block></block>
  <block id="10a93051f49f4080568cecc5ec30cd99" category="inline-link-macro">F5 BIG-IP</block>
  <block id="886218e92c071e06819887a13189b4e6" category="list-text"><block ref="886218e92c071e06819887a13189b4e6" category="inline-link-macro-rx"></block></block>
  <block id="0f07e63979900ab2abf6d2d578850a47" category="inline-link-macro">다음으로: 솔루션 검증/사용 사례: NetApp 및 Red Hat OpenShift</block>
  <block id="3a29a96f08f4066b544db012326464ed" category="paragraph"><block ref="3a29a96f08f4066b544db012326464ed" category="inline-link-macro-rx"></block></block>
  <block id="3605e05aa598ff405b5edffc1bf474f1" category="summary">NetApp과 함께 Red Hat OpenShift에서 멀티 테넌시 구성</block>
  <block id="13148717f8faa9037f37d28971dfc219" category="doc">검증</block>
  <block id="286c0d2f200233e63709210881b700c4" category="paragraph">이전 단계에서 구성한 멀티테넌트 아키텍처를 확인하려면 다음 단계를 수행하십시오.</block>
  <block id="627fd2c5e0310dc7409ea377e5d13045" category="section-title">할당된 프로젝트에서 PVC 또는 POD를 생성하기 위한 액세스를 검증합니다</block>
  <block id="f4da6475fc7e97756adf2751840e077d" category="list-text">PROJECT-1의 개발자인 OCP-PROJECT-1-USER로 로그인합니다.</block>
  <block id="2d7fbbcee3114769610fea6ef6f4cdf0" category="list-text">새 프로젝트를 만들려면 액세스 권한을 확인하십시오.</block>
  <block id="12cdc5f68c3a0ca10544c0a57e866249" category="list-text">PROJECT-1에 할당된 storageclass를 사용하여 PROJECT-1에서 PVC를 생성한다.</block>
  <block id="145d2249af633a497182f76e714d1f2e" category="list-text">PVC와 관련된 PV를 확인한다.</block>
  <block id="d424ec829e7a6f56de4d74835b97103a" category="list-text">PV 및 해당 볼륨이 NetApp ONTAP의 PROJECT-1 전용 SVM에서 생성되었는지 확인합니다.</block>
  <block id="a345b6be662b316a3b3e3cfbc7566b31" category="list-text">PROJECT-1에서 POD를 생성하고 이전 단계에서 만든 PVC를 마운트합니다.</block>
  <block id="7b929f9e235c85c6b73ed2ee867c5514" category="list-text">POD가 실행 중이고 볼륨이 마운트되어 있는지 확인합니다.</block>
  <block id="8c9885c86a67cc4c47a30d7e8d14badb" category="section-title">다른 프로젝트에서 PVC 또는 POD를 생성하거나 다른 프로젝트 전용 리소스를 사용하도록 액세스를 검증합니다</block>
  <block id="8e27501b578972bd7b65468deaa482ca" category="list-text">PROJECT-2에 할당된 storageclass를 사용하여 PROJECT-1에서 PVC를 생성한다.</block>
  <block id="71bc5a6f1f0141981e0034b388233917" category="list-text">PROJECT-2에서 PVC를 작성합니다.</block>
  <block id="1149bf04288dfa82d0e3b713a6e66aa1" category="list-text">PVC의 TEST-PVC-PROJECT-1-SC-2, TEST-PVC-PROJECT-2-SC-1이 생성되지 않았는지 확인한다.</block>
  <block id="0d843e91c3b8f62457e19b2d32ecace3" category="list-text">PROJECT-2에서 POD를 작성합니다.</block>
  <block id="83aa0a39007c30e71adde6fbf8180d9f" category="section-title">프로젝트, 리소스 할당량 및 StorageClasses를 보고 편집하려면 액세스 권한을 확인합니다</block>
  <block id="43700888cdcd166f379f95bd1751ae63" category="list-text">새 프로젝트를 만들려면 액세스 권한을 선택합니다.</block>
  <block id="32579947c29f341292c3ce775140178b" category="list-text">프로젝트 보기에 대한 액세스 권한 확인</block>
  <block id="9e97a1398bb4a0499bb69bf1c9e67d6a" category="list-text">사용자가 PROJECT-1에서 ResourceQuotas를 보거나 편집할 수 있는지 확인합니다.</block>
  <block id="17a658c4329ed475a82d2e02c0406118" category="list-text">사용자가 스토리지 시스템을 볼 수 있는 액세스 권한이 있는지 확인합니다.</block>
  <block id="aa177e49bfc4cc0182f57218ce6bdd4d" category="list-text">스토리지 풀 설명을 위한 액세스를 확인하십시오.</block>
  <block id="997cef2cfb8ccc12d8739c63e69794f3" category="list-text">스토리지 풀 편집을 위한 사용자 액세스 권한 검증</block>
  <block id="9eb6f7c0e27dd8274a30b43a4aee8d53" category="inline-link-macro">다음: 확장.</block>
  <block id="acd8a990c476bd6cb45a9044361ba723" category="paragraph"><block ref="acd8a990c476bd6cb45a9044361ba723" category="inline-link-macro-rx"></block></block>
  <block id="e690fa655ec589e6d0abb58164d5ccfd" category="doc">추가 정보: NetApp의 Red Hat OpenShift</block>
  <block id="1be465260df7c846768e06c988594a6a" category="paragraph">이 문서에 설명된 정보에 대한 자세한 내용은 다음 웹 사이트를 참조하십시오.</block>
  <block id="6f4e4d9fbe846fd8bf7decf7dcffbd63" category="list-text">NetApp 문서</block>
  <block id="1497398039e94eb756be9a3cff5649c7" category="inline-link"><block ref="1497398039e94eb756be9a3cff5649c7" category="inline-link-rx"></block></block>
  <block id="f2d3084aa0f70da5e15757ee3292cda7" category="paragraph"><block ref="f2d3084aa0f70da5e15757ee3292cda7" category="inline-link-rx"></block></block>
  <block id="824bd84e05db30b27e73f839dae3b8e5" category="list-text">Astra Trident 문서</block>
  <block id="fe549ebd8a3f0fea1803cbaa947ef198" category="list-text">NetApp Astra Control Center 문서</block>
  <block id="ad837604b59ea6a89754d8e75f595c7b" category="inline-link"><block ref="ad837604b59ea6a89754d8e75f595c7b" category="inline-link-rx"></block></block>
  <block id="4af69e66dd3d513168080d177919dd21" category="paragraph"><block ref="4af69e66dd3d513168080d177919dd21" category="inline-link-rx"></block></block>
  <block id="21b11dbf6ab3c6d36a76f280fe8ec75d" category="list-text">Red Hat OpenShift 설명서</block>
  <block id="74201863479cf5c9b89330c920283301" category="inline-link"><block ref="74201863479cf5c9b89330c920283301" category="inline-link-rx"></block></block>
  <block id="3e10ed3875c45f9dc9064324660fc2b1" category="paragraph"><block ref="3e10ed3875c45f9dc9064324660fc2b1" category="inline-link-rx"></block></block>
  <block id="06fd33ae9f869a89e860634ec94b9793" category="list-text">Red Hat OpenStack 플랫폼 문서</block>
  <block id="647d438a62673b6a6c9830682f6bc128" category="inline-link"><block ref="647d438a62673b6a6c9830682f6bc128" category="inline-link-rx"></block></block>
  <block id="705a39bc1a12c50103a847633c3f7493" category="paragraph"><block ref="705a39bc1a12c50103a847633c3f7493" category="inline-link-rx"></block></block>
  <block id="8d79e9650a1f62f89d77743225e203c0" category="list-text">Red Hat 가상화 문서</block>
  <block id="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link"><block ref="a1bcc86cb4d53b458f0fdad36c20a0c0" category="inline-link-rx"></block></block>
  <block id="6d6038842b529e3d97aa9a8a9d81d866" category="paragraph"><block ref="6d6038842b529e3d97aa9a8a9d81d866" category="inline-link-rx"></block></block>
  <block id="4666fc2f640685636f115f8b2b6b8ce0" category="list-text">VMware vSphere 설명서</block>
  <block id="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link"><block ref="9c2eeeb25388391ff52a45ac0567fa73" category="inline-link-rx"></block></block>
  <block id="71aa41fc980571d5a324adedae614f9c" category="paragraph"><block ref="71aa41fc980571d5a324adedae614f9c" category="inline-link-rx"></block></block>
  <block id="e38be1dc20a2b358b917b60fe2677b39" category="doc">NetApp Element iSCSI 구성</block>
  <block id="dc5fa659e0452a77d6006f5b72f8b334" category="paragraph">NetApp Element 스토리지 시스템과의 Trident 통합을 활성화하려면 iSCSI 프로토콜을 사용하여 스토리지 시스템과의 통신을 지원하는 백엔드를 생성해야 합니다.</block>
  <block id="05ca7295321cb9b417a251e75557c6c5" category="list-text">다운로드한 설치 아카이브에서 사용할 수 있는 예제 백엔드 파일이 'ample-input' 폴더 계층에 있습니다. iSCSI를 지원하는 NetApp Element 시스템의 경우 'backend-solidfire.json' 파일을 작업 디렉토리로 복사하고 파일을 편집합니다.</block>
  <block id="27ef1192cd037c8978195be045fa054e" category="list-text">끝점 줄에서 사용자, 암호, MVIP 값을 편집합니다.</block>
  <block id="d1b7418d19df7144a98dfde725db068c" category="list-text">VIP 값을 편집합니다.</block>
  <block id="dd7f72325e6f60ea7163b071e4d5e2cc" category="list-text">이 백엔드 파일을 배치하고 다음 명령을 실행하여 첫 번째 백엔드를 생성합니다.</block>
  <block id="b73d05719d0ea2964c963f6f83a34d3d" category="admonition">이 파일에 정의된 fschType이라는 선택적 필드가 있습니다. iSCSI 백엔드에서 이 값은 특정 Linux 파일 시스템 유형(XFS, ext4 등)으로 설정하거나 OpenShift가 사용할 파일 시스템을 결정할 수 있도록 삭제할 수 있습니다.</block>
  <block id="fb12e7f50899cc1254f9a6f1e0341423" category="summary">Astra Control Center를 사용하여 사후 분석 애플리케이션을 복제하고 CI/CD 파이프라인에서 애플리케이션을 복원합니다</block>
  <block id="bc42bbaf219349a2ba37dfd4709b2003" category="doc">NetApp Astra Control을 활용하여 사후 분석 및 애플리케이션 복원을 수행합니다</block>
  <block id="4e42a1e911325b5048e50f7b5ea73d1f" category="section-title">VM 실시간 마이그레이션</block>
  <block id="7df52e0f8b2cb2af1e107fde51d06945" category="paragraph">실시간 마이그레이션은 다운타임 없이 OpenShift 클러스터에서 한 노드에서 다른 노드로 VM 인스턴스를 마이그레이션하는 프로세스입니다. OpenShift 클러스터에서 라이브 마이그레이션을 사용하려면 공유 ReadWriteMany 액세스 모드를 사용하여 VM을 PVC에 바인딩해야 합니다. NFS 프로토콜에 사용하도록 설정된 NetApp ONTAP 클러스터의 SVM으로 구성된 Astra Trident 백엔드는 PVC에 대한 공유 ReadWriteMany 액세스를 지원합니다. 따라서 Trident가 NFS 지원 SVM에서 프로비저닝한 StorageClasses에서 PVC가 있는 VM을 다운타임 없이 마이그레이션할 수 있습니다.</block>
  <block id="09e113cd46b4487f140ee07899ea3359" category="image-alt">VM 실시간 마이그레이션 아키텍처</block>
  <block id="660b7fa756d01df7c4338afb9050abb1" category="paragraph">공유된 ReadWriteMany 액세스를 사용하여 PVC에 바인딩된 VM을 생성하려면 다음을 수행합니다.</block>
  <block id="842f7d4793f116332f5b12b648dfd539" category="list-text">워크로드 &gt; 가상화 &gt; 가상 시스템 으로 이동하고 생성 &gt; 마법사 사용 을 클릭합니다.</block>
  <block id="416d6e9d0df33a74dd38603be60453c1" category="list-text">원하는 운영 체제를 선택하고 Next(다음) 를 클릭합니다. 선택한 OS에 이미 부팅 소스가 구성되어 있다고 가정하겠습니다.</block>
  <block id="e1b595d3037639bdea165dde4b1f3906" category="list-text">검토 및 생성 창에서 VM을 생성할 프로젝트를 선택하고 VM 세부 정보를 제공합니다. 선택한 OS에 적합한 PVC를 지정하여 부트 소스를 클론으로 선택하고 CD-ROM에서 부팅하십시오.</block>
  <block id="998a8df469c318f9cd606b44664cea5d" category="list-text">가상 시스템 사용자 지정 을 클릭한 다음 저장소 를 클릭합니다.</block>
  <block id="ae024d48dbfaaf4badad7bf9c812a98f" category="list-text">rootdisk 옆에 있는 줄임표를 클릭하고 Trident를 사용하여 프로비저닝된 스토리지 클래스를 선택합니다. 고급 을 확장하고 액세스 모드로 공유 액세스(rwx) 를 선택합니다. 저장을 클릭합니다.</block>
  <block id="ef44ba6bf4a3e677b41b361628554b88" category="image-alt">디스크 rwx에 액세스할 수 있도록 합니다</block>
  <block id="2ae6b586f76075c7d71faff7ba9d2a41" category="list-text">검토 및 확인 을 클릭한 다음 가상 시스템 생성 을 클릭합니다.</block>
  <block id="18c830e61a7a92c60804118ef362933c" category="paragraph">OpenShift 클러스터의 다른 노드로 VM을 수동으로 마이그레이션하려면 다음 단계를 완료하십시오.</block>
  <block id="289f346dbeb0185de2648a24955ca887" category="list-text">워크로드 &gt; 가상화 &gt; 가상 시스템으로 이동합니다.</block>
  <block id="cc58a226305ad2362de0317c1fd8261b" category="list-text">마이그레이션할 VM의 경우 줄임표를 클릭한 다음 가상 시스템 마이그레이션 을 클릭합니다.</block>
  <block id="b5839595a4132807edfc858d9f6d90ad" category="list-text">메시지가 나타나면 마이그레이션 을 클릭하여 확인합니다.</block>
  <block id="d0f501bd9588700bc91fe10b7d3f761a" category="admonition">devictionStrategy 가 LiveMigrate 로 설정된 경우 원래 노드를 유지 관리 모드로 전환하면 OpenShift 클러스터의 VM 인스턴스가 다른 노드로 자동 마이그레이션됩니다.</block>
  <block id="ca77161ad6ca11bca347f347b181c25f" category="inline-link-macro">다음으로, 워크플로우: VM 클로닝</block>
  <block id="294f8e986041208286bb2300b191a2ff" category="paragraph"><block ref="294f8e986041208286bb2300b191a2ff" category="inline-link-macro-rx"></block></block>
  <block id="c48db988cd283c11f89d4dd85803ec0a" category="doc">NetApp과 함께 Red Hat OpenShift에서 멀티 테넌시를 구성합니다</block>
  <block id="6d72da55d82cdd434045ba5df1a959b6" category="paragraph">컨테이너에서 여러 애플리케이션 또는 워크로드를 실행하는 많은 조직에서는 애플리케이션 또는 작업 부하당 하나의 Red Hat OpenShift 클러스터를 배포하는 경향이 있습니다. 이를 통해 애플리케이션 또는 워크로드에 대한 엄격한 격리를 구현하고 성능을 최적화하며 보안 취약점을 줄일 수 있습니다. 그러나 각 애플리케이션에 대해 별도의 Red Hat OpenShift 클러스터를 배포하면 자체 문제가 발생합니다. 또한 각 클러스터를 단독으로 모니터링 및 관리해야 하는 운영 오버헤드가 늘어나고, 다양한 애플리케이션을 위한 전용 리소스로 비용이 증가하며, 효율적인 확장성을 저해합니다.</block>
  <block id="332dcd535fa9ce865f462efb80829a35" category="paragraph">이러한 문제를 해결하기 위해 단일 Red Hat OpenShift 클러스터에서 모든 애플리케이션 또는 워크로드를 실행하는 것을 고려할 수 있습니다. 그러나 이러한 아키텍처에서 리소스 격리 및 애플리케이션 보안 취약점은 주요 과제 중 하나입니다. 한 워크로드의 보안 취약점이 다른 작업 부하로 자연스럽게 유출되어 영향 영역이 증가할 수 있습니다. 또한 한 응용 프로그램에서 갑자기 제어되지 않는 리소스 사용률은 기본적으로 리소스 할당 정책이 없기 때문에 다른 응용 프로그램의 성능에 영향을 줄 수 있습니다.</block>
  <block id="14a9bacc4b197037f54eb0c4c7e1970c" category="paragraph">따라서 조직에서는 단일 클러스터에서 모든 워크로드를 실행하면서 각 워크로드별로 전용 클러스터의 이점을 제공하는 동시에 두 환경 모두에서 최상의 솔루션을 찾는 것이 좋습니다.</block>
  <block id="73c1b26ace2fc5fca6e6e78c00a61837" category="paragraph">이러한 효과적인 솔루션 중 하나는 Red Hat OpenShift에서 멀티 테넌시를 구성하는 것입니다. 멀티 테넌시는 리소스, 보안 등을 적절하게 격리하여 동일한 클러스터에서 여러 테넌트를 함께 사용할 수 있는 아키텍처입니다. 이 컨텍스트에서 테넌트는 특정 사용자 그룹이 단독으로 사용하도록 구성된 클러스터 리소스의 하위 집합으로 볼 수 있습니다. Red Hat OpenShift 클러스터에서 멀티 테넌시를 구성하면 다음과 같은 이점이 있습니다.</block>
  <block id="cde9f9f8fcae0cdc6624895868803d60" category="list-text">클러스터 리소스를 공유하여 CapEx 및 OpEx 절감</block>
  <block id="943a49720e6c85fa9692af2a5ebd8829" category="list-text">운영 및 관리 오버헤드 감소</block>
  <block id="f51a58b3ab19c778652fcff9dd39ca55" category="list-text">보안 침해의 교차 오염으로부터 워크로드를 보호합니다</block>
  <block id="181cfddfdb055879df4d55323a14c473" category="list-text">리소스 경합으로 인해 예기치 않은 성능 저하로부터 워크로드 보호</block>
  <block id="f3ff3f5b3c67fb47bb8ec0f2f688b97d" category="paragraph">완전히 실현된 멀티테넌트 OpenShift 클러스터의 경우 컴퓨팅, 스토리지, 네트워킹, 보안 등과 같은 다양한 리소스 버킷에 속하는 클러스터 리소스에 대해 할당량 및 제한을 구성해야 합니다. 이 솔루션에서 모든 리소스 버킷의 특정 측면을 다루지만, NetApp은 NetApp ONTAP가 지원하는 Astra Trident에 의해 동적으로 할당된 스토리지 리소스에서 멀티테넌시를 구성하여 동일한 Red Hat OpenShift 클러스터에서 여러 워크로드에서 제공 또는 소비되는 데이터를 격리하고 보호하는 모범 사례에 초점을 맞춥니다.</block>
  <block id="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="paragraph"><block ref="4fbbd2f5b2a8e82447aa1b841b2a70d0" category="inline-link-macro-rx"></block></block>
  <block id="254f642527b45bc260048e30704edb39" category="doc">구성</block>
  <block id="44b1200b793638d4a3aebd1bee591e12" category="paragraph">모든 멀티테넌트 솔루션의 경우 사용자는 필요한 것보다 더 많은 클러스터 리소스에 액세스할 수 없습니다. 따라서 다중 테넌시 구성의 일부로 구성할 전체 리소스 세트는 클러스터 관리자, 스토리지 관리자 및 각 프로젝트를 작업하는 개발자가 구성합니다.</block>
  <block id="1ceba10f8902735a18e8c3bb3e8a3052" category="paragraph">다음 표에는 여러 사용자가 수행해야 하는 여러 작업이 정리되어 있습니다.</block>
  <block id="064dceba374668ef0734be5f9e182682" category="cell">* 클러스터 관리자 *</block>
  <block id="445b72f2cbecd97022bb6636eda3cbc7" category="cell">다양한 애플리케이션 또는 워크로드를 위한 프로젝트를 생성합니다</block>
  <block id="e033ab3bea3b8a20afb5852070df0203" category="cell">storage-admin에 대한 ClusterRoles 및 RoleBindings를 생성합니다</block>
  <block id="293d08622718634a8518b6fcc6376617" category="cell">특정 프로젝트에 대한 액세스를 할당하는 개발자를 위한 역할 및 RoleBindings를 만듭니다</block>
  <block id="3e97e469255cd3686174c371f50961f9" category="cell">[선택 사항] 특정 노드에서 Pod를 예약하도록 프로젝트를 구성합니다</block>
  <block id="93ffd2b1215bc47cc78b020f89e922ef" category="cell">* 스토리지 - 관리자 *</block>
  <block id="043ab42cdcbdacc4691c26ee52ed8ccd" category="cell">NetApp ONTAP에서 SVM을 생성합니다</block>
  <block id="be09a24f118a66330a40633e9d5ebfca" category="cell">Trident 백엔드를 생성합니다</block>
  <block id="55995e8c220e05b3e75252cccf5752be" category="cell">StorageClasses를 생성합니다</block>
  <block id="2a5eb41b2d7fd04d01836f89ab790852" category="cell">스토리지 리소스 할당량을 생성합니다</block>
  <block id="4e00898ecc4e6640083ccff8d85fbe87" category="cell">개발자 *</block>
  <block id="bfc5fb8ef5464441bc8b3ca7eda2892d" category="cell">할당된 프로젝트에서 PVC 또는 POD를 생성하거나 패치하기 위한 액세스를 검증합니다</block>
  <block id="9e95c94350b2b7b51176ad958deb1388" category="cell">다른 프로젝트에서 PVC 또는 POD를 생성하거나 패치하기 위한 액세스를 검증합니다</block>
  <block id="8c0b7954d326b4bcf2f42a57ef00eead" category="cell">프로젝트, 리소스 할당량 및 StorageClasses를 보거나 편집하려면 액세스 유효성을 검사합니다</block>
  <block id="4edd9914739183e9cb724a222261a01f" category="inline-link-macro">다음: 필수 구성 요소.</block>
  <block id="8013a47a037d25fa6d9671120cfc1ee5" category="paragraph"><block ref="8013a47a037d25fa6d9671120cfc1ee5" category="inline-link-macro-rx"></block></block>
  <block id="482f4dddd14a12f4ece48aef54de313c" category="summary">Red Hat OpenShift Container Platform은 온프레미스 인프라와 하이브리드 클라우드 인프라 전반에서 개발 및 IT 운영을 단일 플랫폼에서 통합하여 애플리케이션을 일관되게 개발, 배포 및 관리합니다. Red Hat OpenShift는 컨테이너 기반 워크로드를 위해 설계된 세계 최고의 엔터프라이즈 Linux 배포판인 Kubernetes 및 Red Hat Enterprise Linux CoreOS를 비롯한 오픈 소스 혁신과 업계 표준을 기반으로 구축되었습니다.</block>
  <block id="f122078c68f20c36897fec8a7c4a23e8" category="doc">OpenShift 개요</block>
  <block id="e68e90b5707502c9f2fc1361ac071b3d" category="paragraph">Red Hat OpenShift Container Platform은 온프레미스 인프라와 하이브리드 클라우드 인프라 전반에서 개발 및 IT 운영을 단일 플랫폼에서 통합하여 애플리케이션을 일관되게 개발, 배포 및 관리합니다. Red Hat OpenShift는 컨테이너 기반 워크로드를 위해 설계된 세계 최고의 엔터프라이즈 Linux 배포판인 Kubernetes 및 Red Hat Enterprise Linux CoreOS를 비롯한 오픈 소스 혁신과 업계 표준을 기반으로 구축되었습니다. OpenShift는 CNCF(Cloud Native Computing Foundation) 인증 Kubernetes 프로그램의 일부로, 컨테이너 워크로드의 이동성과 상호 운용성을 제공합니다.</block>
  <block id="b2b7104a419a54dcb2763bddc6a0a47c" category="section-title">Red Hat OpenShift는 다음과 같은 기능을 제공합니다.</block>
  <block id="d383250f88949df87bac7768b697ccb6" category="list-text">* 셀프 서비스 프로비저닝. * 개발자는 가장 많이 사용하는 툴을 사용하여 필요에 따라 애플리케이션을 쉽고 빠르게 만들 수 있으며, 운영 환경은 전체 환경을 완벽하게 제어할 수 있습니다.</block>
  <block id="df45d857ed72e8e5ed370c6fdfd1e305" category="list-text">* 영구 스토리지. * OpenShift Container Platform은 영구 스토리지를 지원하므로 상태 저장 애플리케이션과 클라우드 네이티브 상태 비저장 애플리케이션을 모두 실행할 수 있습니다.</block>
  <block id="29ee9790b817110f2303080d5b295946" category="list-text">* CI/CD(Continuous Integration and Continuous Development). * 이 소스 코드 플랫폼은 규모에 따라 빌드 및 배포 이미지를 관리합니다.</block>
  <block id="a0f0997dded25d9aa9c767f29c17c249" category="list-text">* 오픈 소스 표준. * 이러한 표준은 컨테이너 오케스트레이션을 위한 오픈 컨테이너 이니셔티브(OCI)와 Kubernetes를 기타 오픈 소스 기술과 통합합니다. 귀사는 특정 공급업체의 기술 로드맵 또는 비즈니스 로드맵에 제한되지 않습니다.</block>
  <block id="7dc3d12ecda66373091607ba18ef4434" category="list-text">CI/CD 파이프라인 * OpenShift는 CI/CD 파이프라인에 대한 기본 지원을 제공하므로 개발 팀이 애플리케이션 제공 프로세스의 모든 단계를 자동화하고 애플리케이션의 코드 또는 구성에 대한 모든 변경 사항을 실행할 수 있습니다.</block>
  <block id="95e4c6a8e27cc92068d97ef795477714" category="list-text">* 역할 기반 액세스 제어(RBAC). * 이 기능은 대규모 개발자 그룹을 구성하는 데 도움이 되는 팀 및 사용자 추적 기능을 제공합니다.</block>
  <block id="d565eddf8e07af916519ec07f8712204" category="list-text">* 자동 구축 및 배포. * OpenShift는 개발자가 컨테이너화된 애플리케이션을 구축하거나 애플리케이션 소스 코드 또는 바이너리에서 컨테이너를 구축할 수 있는 플랫폼을 제공합니다. 그런 다음, 이 플랫폼은 애플리케이션에 대해 정의된 특성을 기반으로 인프라 전반에서 이러한 애플리케이션을 자동으로 구축합니다. 예를 들어, 할당되어야 하는 리소스의 양과 타사 라이센스를 준수하기 위해 구축해야 하는 인프라스트럭처의 위치 등을 예로 들 수 있습니다.</block>
  <block id="4fe0bdfd5a2ae34ba1a93860fd91d2fd" category="list-text">* 일관된 환경 * OpenShift는 개발자와 애플리케이션 라이프사이클 전반에 걸쳐 운영 체제, 라이브러리, 런타임 버전(예: Java 런타임), 또한 일관성 없는 환경에서 발생한 위험을 제거하기 위해 사용 중인 응용 프로그램 런타임(예: tomcat)도 마찬가지입니다.</block>
  <block id="64f8957eb1a3bb6a1e9ebd391e76925a" category="list-text">* 구성 관리. * 구성 및 중요 데이터 관리는 플랫폼에 내장되어 있어 응용 프로그램을 빌드하는 데 사용되는 기술이나 배포된 환경에 관계 없이 일관성 있고 환경 제한이 없는 응용 프로그램 구성이 응용 프로그램에 제공되도록 합니다.</block>
  <block id="5efb308bdb8052c1aa3fe8333f459fe5" category="list-text">* 응용 프로그램 로그 및 메트릭 * 신속한 피드백은 응용 프로그램 개발의 중요한 요소입니다. OpenShift의 통합 모니터링 및 로그 관리 기능을 통해 개발자에게 즉각적인 메트릭을 제공하여 애플리케이션이 변경 내용 전반에 걸쳐 어떻게 동작하는지 연구하고 애플리케이션 수명 주기 동안 가능한 한 빨리 문제를 해결할 수 있도록 합니다.</block>
  <block id="8c2b388bd42b0b6bae19890633c98a8d" category="list-text">* 보안 및 컨테이너 카탈로그. * OpenShift는 멀티 테넌시를 제공하고 SELinux(Security-Enhanced Linux), CGroup, seccomp(Secure Computing Mode)와 함께 보안 설정을 사용하여 컨테이너를 격리 및 보호함으로써 유해한 코드 실행으로부터 사용자를 보호합니다. 또한 다양한 하위 시스템에 대한 TLS 인증서를 통한 암호화 및 Red Hat 인증 컨테이너(access.redhat.com/containers 액세스할 수 있습니다. 이 컨테이너는 보안 강화, 신뢰 및 보안 애플리케이션 컨테이너를 최종 사용자에게 제공하기 위해 스캔 및 등급이 정해졌습니다.</block>
  <block id="16c321ec2744799f0acef92ce84d06ca" category="paragraph"><block ref="16c321ec2744799f0acef92ce84d06ca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fe8c2f8039053e077a0ca678496b72aa" category="section-title">Red Hat OpenShift의 배포 방법</block>
  <block id="9c2dd02f13d452b4422ac6c864933f01" category="paragraph">Red Hat OpenShift 4부터 OpenShift를 위한 배포 방법에는 고도의 맞춤형 배포를 위한 UPI(User Provisioned Infrastructure)를 사용한 수동 배포 또는 IPI(Installer Provisioned Infrastructure)를 사용한 완전 자동화된 배포가 포함됩니다.</block>
  <block id="68dc46cb39cdfc93e4593bbdd5c218cf" category="paragraph">IPI 설치 방법은 대부분의 경우 개발, 테스트 및 생산 환경에 OCP 클러스터를 신속하게 배포할 수 있기 때문에 선호되는 방법입니다.</block>
  <block id="ec55e5ffb2376dada4b2eb066c1fd9fd" category="section-title">Red Hat OpenShift의 IPI 설치</block>
  <block id="a91a379e59fea6610134af1efa3dfe87" category="paragraph">OpenShift의 설치 관리자 프로비저닝 인프라(IPI) 배포에는 다음과 같은 고급 단계가 포함됩니다.</block>
  <block id="d1befa03c79ca0b84ecc488dea96bc68" category="inline-link">웹 사이트</block>
  <block id="a07879007b1202a533ff3ef18bc0d197" category="list-text">Red Hat OpenShift를 방문하십시오<block ref="36af4d1b80928d398e137421c95a1013" category="inline-link-rx"></block> SSO 자격 증명을 사용하여 로그인합니다.</block>
  <block id="66f8ff89bd2c9146cb3273d416c60fd2" category="list-text">Red Hat OpenShift를 배포할 환경을 선택하십시오.</block>
  <block id="cc66c30273a9be504b88d3239e65516b" category="paragraph"><block ref="cc66c30273a9be504b88d3239e65516b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f5806bcee67fc8f13f0255068a186e42" category="list-text">다음 화면에서 설치 관리자, 고유한 풀 암호 및 관리용 CLI 툴을 다운로드합니다.</block>
  <block id="86b43786316d35748685c4f7abc4145b" category="paragraph"><block ref="86b43786316d35748685c4f7abc4145b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9a2aa5906b4dad4a982c3a9c51d31f3" category="list-text">를 따릅니다<block ref="04512308a1627dc41acfeed51ef16ba3" category="inline-link-rx"></block> Red Hat이 선택한 환경에 배포할 수 있도록 제공합니다.</block>
  <block id="220887aee59c37fa79fc366cba7dad4e" category="section-title">NetApp은 OpenShift 구축을 검증했습니다</block>
  <block id="d711fd24836980dd490f3c01dd3ee8de" category="paragraph">NetApp은 다음과 같은 각 데이터 센터 환경에서 IPI(Installer provisioned Infrastructure) 배포 방법을 사용하여 랩에서 Red Hat OpenShift의 배포를 테스트하고 검증했습니다.</block>
  <block id="fecab6277bc7322982f127ce83dee308" category="list-text"><block ref="fecab6277bc7322982f127ce83dee308" category="inline-link-macro-rx"></block></block>
  <block id="ff3de63c4917b45d20525986d5b29962" category="list-text"><block ref="ff3de63c4917b45d20525986d5b29962" category="inline-link-macro-rx"></block></block>
  <block id="f88eb30a75027b557910958c7306cb4e" category="inline-link-macro">Red Hat Virtualization의 OpenShift</block>
  <block id="92fb5c16a9f212d49c0c5fb48ebc9144" category="list-text"><block ref="92fb5c16a9f212d49c0c5fb48ebc9144" category="inline-link-macro-rx"></block></block>
  <block id="2772c11e552b243e60a34490c4174ff9" category="inline-link-macro">VMware vSphere의 OpenShift입니다</block>
  <block id="83fc4dbe543f82a9e50bc1bd4c74fb70" category="list-text"><block ref="83fc4dbe543f82a9e50bc1bd4c74fb70" category="inline-link-macro-rx"></block></block>
  <block id="d10b633b8bd8d022c66a52d93e0ed6ce" category="section-title">클러스터 라이프사이클 관리</block>
  <block id="8b9449bdfc859a900fc4da7c79420145" category="paragraph">다양한 OpenShift 클러스터를 관리하기 위해 클러스터를 생성하거나 Advanced Cluster Management로 가져올 수 있습니다.</block>
  <block id="0ef06ef8df800cf71fb95c66e0e08f1a" category="list-text">먼저 인프라 &gt; 클러스터를 자동화하십시오.</block>
  <block id="0becde0fcfda03aec9c722d042326324" category="list-text">새 OpenShift 클러스터를 생성하려면 다음 단계를 완료하십시오.</block>
  <block id="e056bb6efa17796fc810edad8410280d" category="list-text">공급자 연결 만들기: 공급자 연결로 이동하여 연결 추가 를 클릭하고 선택한 공급자 형식에 해당하는 모든 세부 정보를 제공한 다음 추가 를 클릭합니다.</block>
  <block id="50dfc508091b37338da8357e63e6a405" category="image-alt">공급자 연결을 추가합니다</block>
  <block id="401b252566122602a82ff66bc7ed3e6c" category="list-text">새 클러스터를 생성하려면 클러스터 로 이동하고 클러스터 추가 &gt; 클러스터 생성 을 클릭합니다. 클러스터 및 해당 공급자에 대한 세부 정보를 제공하고 Create를 클릭합니다.</block>
  <block id="2984cab36bd51d5446963e671e808f5d" category="image-alt">클러스터 추가</block>
  <block id="2da6eeb34cf16de43ab8fa2f939d81c7" category="list-text">클러스터가 생성되면 클러스터 목록에 Ready 상태로 표시됩니다.</block>
  <block id="e6d9a6b38dd36fd9870260249ba5fc1f" category="list-text">기존 클러스터를 가져오려면 다음 단계를 수행하십시오.</block>
  <block id="f52ae06380cfd00cae7839562f550e87" category="list-text">클러스터 로 이동하고 클러스터 추가 &gt; 기존 클러스터 가져오기 를 클릭합니다.</block>
  <block id="63b7276dd1b569babc28304e786e2041" category="list-text">클러스터의 이름을 입력하고 가져오기 저장 및 코드 생성 을 클릭합니다. 기존 클러스터를 추가하는 명령이 표시됩니다.</block>
  <block id="be87809a27ab2944f89ccaebd89b7596" category="list-text">Copy Command 를 클릭하고 허브 클러스터에 추가할 클러스터에서 명령을 실행합니다. 그러면 클러스터에 필요한 에이전트 설치가 시작되고, 이 프로세스가 완료되면 클러스터가 준비 상태로 클러스터 목록에 나타납니다.</block>
  <block id="9a618414b83afe67c19abcf935be6dbd" category="image-alt">기존 클러스터 가져오기</block>
  <block id="c812d1382d834648706b3bf1e6848135" category="list-text">여러 클러스터를 생성하고 가져온 후에는 단일 콘솔에서 클러스터를 모니터링하고 관리할 수 있습니다.</block>
  <block id="068e5ec1cc0eaa7c2596be7eb1b40194" category="inline-link-macro">다음: 기능 - 응용 프로그램 수명 주기 관리</block>
  <block id="0405bd6ea905b8d563fd501d933a3e51" category="paragraph"><block ref="0405bd6ea905b8d563fd501d933a3e51" category="inline-link-macro-rx"></block></block>
  <block id="d008c60ddb28c0bbad1dfabdd77327fc" category="doc">구성: 스토리지 관리 작업</block>
  <block id="6c0ed744c737f30af364d229639c8288" category="paragraph">스토리지 관리자가 다음 리소스를 구성해야 합니다.</block>
  <block id="64244866ddff81ded5e6aaa49055c6aa" category="list-text">NetApp ONTAP 클러스터에 admin으로 로그인합니다.</block>
  <block id="85ca996063b5ec233e56a20ba93c5f44" category="list-text">Storage &gt; Storage VMs 로 이동하고 Add 를 클릭합니다. 필요한 세부 정보를 제공하여 프로젝트-1과 프로젝트-2에 각각 필요한 SVM 2개를 생성합니다. SVM 및 리소스를 관리하는 vsadmin 계정도 생성합니다.</block>
  <block id="3f8bc17bf8dd138aa2915235f0a9c0d3" category="image-alt">ONTAP에서 SVM 생성</block>
  <block id="b436e7799d01413277e05983e509574a" category="list-text">스토리지 관리자로 Red Hat OpenShift 클러스터에 로그인합니다.</block>
  <block id="c9bd46366e9fb78552566f1e7a13633a" category="list-text">프로젝트-1의 백엔드를 생성하여 프로젝트 전용 SVM에 매핑합니다. ONTAP 클러스터 관리자를 사용하는 대신 SVM의 vsadmin 계정을 사용하여 백엔드를 SVM에 연결하는 것이 좋습니다.</block>
  <block id="f934b433773b966e5ebe0c7172decda4" category="admonition">이 예에서는 ONTAP-NAS 드라이버를 사용하고 있습니다. 사용 사례에 따라 백엔드를 생성할 때 적절한 드라이버를 사용하십시오.</block>
  <block id="8628ed29313534f54f01e0da36e66ab7" category="admonition">트리덴트 프로젝트에 Trident가 설치되어 있다고 가정합니다.</block>
  <block id="4a6c648106c1ff38316705bf986de601" category="list-text">마찬가지로, project-2를 위한 Trident 백엔드를 생성한 다음 project-2 전용 SVM에 매핑합니다.</block>
  <block id="9a45d41277a2e8ce29709826a31fb482" category="list-text">그런 다음 스토리지 클래스를 생성합니다. storagePools 매개 변수를 설정하여 project-1용 스토리지 클래스를 생성하고 backend 전용 스토리지 풀을 project-1에 사용하도록 구성합니다.</block>
  <block id="4350d40426f8c94f6ca046609969adb2" category="list-text">마찬가지로, project-2에 대한 스토리지 클래스를 생성하고 백엔드에서 project-2에 대한 스토리지 풀을 사용하도록 구성합니다.</block>
  <block id="2ee847ebe129ae778860d6dd2da21cf6" category="list-text">ResourceQuota를 생성하여 다른 프로젝트 전용 스토리지로부터 스토리지를 요청하는 Project-1의 리소스를 제한합니다.</block>
  <block id="c689ae18a0f5e47541dcec4afb6e187a" category="list-text">마찬가지로, ResourceQuota를 생성하여 다른 프로젝트 전용 스토리지로부터 스토리지를 요청하는 Project-2의 리소스를 제한합니다.</block>
  <block id="7f9ddc8224f28e1481299160807c876d" category="inline-link-macro">다음: 검증.</block>
  <block id="93a1440c4dcba82f234a9305a9445144" category="paragraph"><block ref="93a1440c4dcba82f234a9305a9445144" category="inline-link-macro-rx"></block></block>
  <block id="501195b19cb60bfec4c2e4899a2a460c" category="summary">Red Hat OpenShift 클러스터를 등록하면 Astra Control Center를 통해 배포 및 관리하는 애플리케이션을 검색할 수 있습니다.</block>
  <block id="d19de154f02438c6d6918a4e016c7c62" category="doc">보호할 애플리케이션을 선택하십시오</block>
  <block id="a022d74e2b8b62dd9f1caa37a51aa3f3" category="section-title">애플리케이션 관리</block>
  <block id="d8c780951f3271e7d72b116e5f41d46b" category="list-text">OpenShift 클러스터와 ONTAP 백엔드가 Astra Control Center에 등록된 후, 컨트롤 센터는 지정된 ONTAP 백엔드로 구성된 스토리지 클래스 스토리지를 사용하는 모든 네임스페이스에서 애플리케이션을 자동으로 검색하기 시작합니다.</block>
  <block id="3b5963749d054f288f27dfb2f20d0370" category="inline-image-macro">Astra Control Center 애플리케이션이 검색되었습니다</block>
  <block id="a78e618a70881e5c5dda311aaa61c250" category="paragraph"><block ref="a78e618a70881e5c5dda311aaa61c250" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c46442de8c982973aeee99a9441b746" category="list-text">앱 &gt; 검색됨 으로 이동한 후 Astra를 사용하여 관리하려는 애플리케이션 옆에 있는 드롭다운 메뉴를 클릭합니다. 관리 를 클릭합니다.</block>
  <block id="22d84cdf10d4c1059d68b1ab7da5b375" category="inline-image-macro">Astra Control Center에서 애플리케이션을 관리합니다</block>
  <block id="4afca1ab36db499d54b08ff38dff8a5c" category="paragraph"><block ref="4afca1ab36db499d54b08ff38dff8a5c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d694cfe5907a4790ea939388a8cfd25" category="list-text">응용 프로그램이 사용 가능 상태로 전환되고 앱 섹션의 관리 탭에서 볼 수 있습니다.</block>
  <block id="dc496d6799e0c6ab3bdfdbdc6a086b48" category="inline-image-macro">Astra Control Center 애플리케이션을 사용할 수 있습니다</block>
  <block id="872adedc4ac847cec0aa8fb9299d32e5" category="paragraph"><block ref="872adedc4ac847cec0aa8fb9299d32e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2c2a82496277a88b32b0e8d27249d3d" category="inline-link-macro">다음: 응용 프로그램을 보호합니다.</block>
  <block id="d5be948b8a7fea6618eb171c64927be2" category="paragraph"><block ref="d5be948b8a7fea6618eb171c64927be2" category="inline-link-macro-rx"></block></block>
  <block id="4d4480c77d84881f85763c51fb0a0ebb" category="doc">비디오 및 데모: NetApp의 Red Hat OpenShift</block>
  <block id="f64f81d4393ab1fc9545c35c8eb9f74d" category="paragraph">다음 비디오에서는 이 문서에 설명되어 있는 몇 가지 기능을 설명합니다.</block>
  <block id="051525dd6e814133d477a1812a4164c2" category="inline-link-macro">비디오: Red Hat 가상화 배포 기반의 Red Hat OpenShift용 NetApp HCI</block>
  <block id="817cc3ec794caf508075034f1fa54315" category="list-text"><block ref="817cc3ec794caf508075034f1fa54315" category="inline-link-macro-rx"></block></block>
  <block id="5e217c79c499978721e658f868053d3f" category="inline-link-macro">다음: 추가 정보: NetApp의 Red Hat OpenShift</block>
  <block id="d2fb587a433995783f0688b22359272d" category="paragraph"><block ref="d2fb587a433995783f0688b22359272d" category="inline-link-macro-rx"></block></block>
  <block id="114856cfc010d937269afe29138175fc" category="doc">OpenShift Virtualization을 통한 가상 시스템 배포: NetApp과 Red Hat OpenShift</block>
  <block id="b2f35a84b813ef160b585d350d2fcd58" category="summary">베어 메탈 기반 Anthos의 하드웨어 독립적 기능을 사용하면 사용 사례에 최적화된 컴퓨팅 플랫폼을 선택할 수 있습니다. 따라서 는 기존 인프라를 일치시키고 자본 지출을 줄일 수 있습니다.</block>
  <block id="5f95fbda20eeb9ce0859afe2ac6f42fa" category="doc">솔루션 요구 사항</block>
  <block id="7d4009b9254a61f6afd71a2656a3a78f" category="section-title">컴퓨팅: 자체 서버를 사용합니다</block>
  <block id="dee41946d9d6ca32131352cb4374f12b" category="paragraph">다음 표에는 이 솔루션을 구현하는 데 필요한 최소 컴퓨팅 하드웨어 구성 요소의 수가 나와 있습니다. 단, 사용되는 하드웨어 모델은 고객 요구 사항에 따라 다를 수 있습니다.</block>
  <block id="c64518704ce0c0d5501a45763f464276" category="cell">사용</block>
  <block id="602f72fff77475a16eff159759656261" category="cell">하드웨어 및 모델</block>
  <block id="06e9950a2c1bb489cf54d03d4547e913" category="cell">관리 노드</block>
  <block id="b349dcffed4594674c8ce6c91e72e42f" category="cell">Cisco UCS B200</block>
  <block id="fcb81a84511da525a1581c4ccc00d0fb" category="cell">작업자 노드</block>
  <block id="4867cc2ab4385d91c3a36d6ace67a984" category="cell">HP ProLiant DL360</block>
  <block id="2c0b20f0fbc047d58ca10a50c6a32bc7" category="section-title">스토리지: NetApp ONTAP</block>
  <block id="8bf5bd6530ea430a8edac8a795165179" category="cell">NetApp AFF를 참조하십시오</block>
  <block id="eb8440af98c502b8095408e970297e6b" category="cell">NetApp AFF A300</block>
  <block id="e8d610d6c2d243856beaade33b5aa123" category="cell">2개(HA 쌍 1개)</block>
  <block id="b6ce11f078022a4ab598b8016db52a13" category="paragraph">다음 표에 명시된 소프트웨어 버전은 NetApp과 파트너가 NetApp 솔루션을 검증하는 데 사용되었으며 소프트웨어 구성 요소는 고객 요구 사항에 따라 다를 수 있습니다.</block>
  <block id="128b9c7509f09d8ff4b08e87def0ac74" category="cell">3명의 관리자가 있는 OS</block>
  <block id="7cd95c816f8a04ff858a857e3e5a484d" category="cell">20.04</block>
  <block id="836a05a21ac6df3b6bcf9838895b017e" category="cell">Worker4의 OS</block>
  <block id="bbd243e896202aa0eb00ce19d8a7fea8" category="cell">Worker3의 OS</block>
  <block id="aa1fc3398e84bda331b47203c1e53ad5" category="cell">CentOS</block>
  <block id="aaad0494526f271ca02ebd06a79e7382" category="cell">Worker2의 OS</block>
  <block id="2a568439f8e6ff92daa9925ce8a03adf" category="cell">8.2</block>
  <block id="c73bbd3786350b0a8d3577d82afdf489" category="cell">Red Hat Enterprise Linux</block>
  <block id="7ac53708026d8515ce15cc154e95f46b" category="cell">Worker1의 OS</block>
  <block id="d6422a625045167156b3c0d85ca23ebf" category="cell">8.1</block>
  <block id="7cf4fea896dee61293d729d9985621d7" category="cell">컨테이너 오케스트레이션</block>
  <block id="ca9f0d77f73d954e88e6ab43539ac7cb" category="cell">1.6.0</block>
  <block id="ea704238343d48baa3a08f039015185f" category="cell">스토리지 OS</block>
  <block id="f33749dd101d316dcf2e6953732629f9" category="cell">9.7P8</block>
  <block id="8fe1ffd8f7dcf339dd4f34aabb6e1c99" category="cell">컨테이너 스토리지 관리</block>
  <block id="a84024ce06ef98519b3b51300b2c8fbf" category="cell">20.10</block>
  <block id="d94e09dc1956d9513e690f8d24852f05" category="inline-link">Anthos의 Bare Metal 문서</block>
  <block id="dea0bcd20b41ad5a5b5830e0facf5d5d" category="paragraph">베어 메탈 하드웨어 및 소프트웨어 요구 사항에 대한 Anthos는 를 참조하십시오<block ref="39597b4f74e08019db4cace51500cfd6" category="inline-link-rx"></block> 페이지.</block>
  <block id="71196ec10a92c76a666a93f55523b96e" category="inline-link-macro">다음: 배포 요약.</block>
  <block id="1b8d67e147d4d9c532832778cca5fee8" category="paragraph"><block ref="1b8d67e147d4d9c532832778cca5fee8" category="inline-link-macro-rx"></block></block>
  <block id="58c0d00b6ee4c263f1fbe431b41eebf4" category="summary">Astra Control Center에서 애플리케이션 워크로드를 관리하고 나면 해당 워크로드에 대한 보호 설정을 구성할 수 있습니다.</block>
  <block id="16dcf1808fc3c9a6f8342f97305d2ad6" category="doc">애플리케이션 보호</block>
  <block id="59af79c7ab060b4cca322301a4729f0c" category="section-title">애플리케이션 스냅샷 생성</block>
  <block id="c0cf3c0162d106c6ee24b7afa9b79575" category="paragraph">애플리케이션의 스냅샷은 해당 스냅샷 복사본을 기반으로 애플리케이션을 특정 시점으로 복원하거나 클론 복제하는 데 사용할 수 있는 ONTAP 스냅샷 복사본을 생성합니다.</block>
  <block id="9101281f33d55e682b1a47a44251fa0e" category="list-text">응용 프로그램의 스냅샷을 만들려면 앱 &gt; 관리 탭으로 이동하여 스냅샷 복사본을 만들 응용 프로그램을 클릭합니다. 응용 프로그램 이름 옆의 드롭다운 메뉴를 클릭하고 스냅샷 을 클릭합니다.</block>
  <block id="c01290a8a623e36f9bcae85b910a3410" category="inline-image-macro">Astra Control Center 스냅샷 버튼</block>
  <block id="f40e241f10f15eb6887acbc81fec81b0" category="inline-image-macro">Astra Control Center에서 스냅샷을 생성합니다</block>
  <block id="1853746a915bea325b8b576237c24427" category="section-title">애플리케이션 백업 생성</block>
  <block id="91796648d42dbd448c6cbb2044cb92ba" category="paragraph">애플리케이션 백업에서는 애플리케이션의 활성 상태와 애플리케이션 리소스의 구성을 캡처하여 파일로 저장한 다음 원격 오브젝트 스토리지 버킷에 저장합니다.</block>
  <block id="72e328bb06195897c7a644970c61d3a2" category="paragraph">Astra Control Center에서 관리 대상 애플리케이션을 백업 및 복구하려면 백업 ONTAP 시스템에 대한 고급 사용자 설정을 사전 요구 사항으로 구성해야 합니다. 이렇게 하려면 다음 명령을 입력합니다.</block>
  <block id="6db82a24b17137378420e9fc7961d961" category="list-text">Astra Control Center에서 관리 대상 응용 프로그램의 백업을 생성하려면 Apps &gt; Managed 탭으로 이동하여 백업할 응용 프로그램을 클릭합니다. 응용 프로그램 이름 옆의 드롭다운 메뉴를 클릭하고 백업을 클릭합니다.</block>
  <block id="bc230776554b8a63af328cf9f01124e1" category="inline-image-macro">Astra Control Center 백업 버튼</block>
  <block id="e10781941ccd98298d2856b437b3fb4b" category="inline-image-macro">Astra Control Center에서 백업을 생성합니다</block>
  <block id="92955527b375720b2a586155a776c0ac" category="inline-image-macro">Astra Control Center 클론 버튼</block>
  <block id="c4293ef1955d52694e7d2288b637df1a" category="inline-image-macro">Astra Control Center 복구</block>
  <block id="c501040965cb5ca97cc675347e9ebfdf" category="list-text">새 애플리케이션은 검색 상태로 전환되지만, Astra Control Center는 선택한 클러스터에 애플리케이션을 생성합니다. 응용 프로그램의 모든 리소스가 Astra에 의해 설치 및 감지되면 응용 프로그램은 사용 가능 상태로 전환됩니다.</block>
  <block id="9ff3c5458e4a8facc6e7c25656a3baf7" category="inline-image-macro">Astra Control Center에서 새로운 앱이 검색되었습니다</block>
  <block id="abd6754aa5a185ca83b3f00c5da68534" category="inline-link-macro">다음으로 솔루션 검증/사용 사례를 살펴보겠습니다.</block>
  <block id="8bfe62be82a77570753936203ee020ca" category="paragraph"><block ref="8bfe62be82a77570753936203ee020ca" category="inline-link-macro-rx"></block></block>
  <block id="7c613b296892d4712b9041d3081282f8" category="summary">NetApp OpenShift를 사용한 Kubernetes용 고급 클러스터 관리</block>
  <block id="78e1aefe2bbb2518f1156636e761e479" category="paragraph">OpenShift 클러스터에 Kubernetes용 Advanced Cluster Management를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="b17056cdbd9ec695d4348e1ad799ace4" category="list-text">허브 클러스터로 OpenShift 클러스터를 선택하고 클러스터 관리자 권한으로 로그인합니다.</block>
  <block id="bc2ab7a7550cebeb52a08cf830b5ecf6" category="list-text">Operators &gt; Operators Hub로 이동하여 Kubernetes용 Advanced Cluster Management를 검색합니다.</block>
  <block id="2e5d3941e033e96d5317cc2bbd1da914" category="image-alt">ACM 타일</block>
  <block id="c4ab802b80978ba1c5de3922d546bdb7" category="list-text">Kubernetes용 고급 클러스터 관리 를 선택하고 설치 를 클릭합니다.</block>
  <block id="cc5a9dd5971b8369354db684e5dbfe2b" category="image-alt">ACM 타일 세부 정보</block>
  <block id="c972585d6241c4f2ed2604bcc8706358" category="list-text">Install Operator(사용자 설치) 화면에서 필요한 세부 정보를 제공하고(NetApp은 기본 매개 변수를 유지할 것을 권장) Install(설치)을 클릭합니다.</block>
  <block id="72b342ddabad6a9ec11df82389c40b88" category="image-alt">ACM 작업자 타일을 장착하십시오</block>
  <block id="11458c333e4903e54ca46f822ba6a3b6" category="list-text">작업자 설치가 완료될 때까지 기다립니다.</block>
  <block id="64524f91c2fdfcd54b4bbcab35392908" category="image-alt">ACM 사용자 설치 진행 중</block>
  <block id="7bf3d0678c48be5730f20005e6f88aa1" category="list-text">연산자가 설치된 후 Create MultiClusterHub 를 클릭합니다.</block>
  <block id="e0d84ec6a5b8f92909a7a3bef11455c1" category="image-alt">ACM 운영자 Multiclusterhub</block>
  <block id="95f29f27e373a9759cf065e1fde23e28" category="list-text">Create MultiClusterHub 화면에서 세부 정보를 입력하고 Create를 클릭합니다. 그러면 다중 클러스터 허브의 설치가 시작됩니다.</block>
  <block id="344f0cb43d1b2e7a719bea808fe7c5bf" category="image-alt">다중 클러스터 허브 생성 화면</block>
  <block id="a50aa5e8249109d6f4902945e968ad7d" category="list-text">모든 Pod가 개방형 클러스터 관리 네임스페이스에서 실행 상태로 이동하고 운영자가 Succeeded 상태로 이동하면 Kubernetes용 Advanced Cluster Management가 설치됩니다.</block>
  <block id="851548d1ad843a23609f325e8b54e72d" category="image-alt">ACM 작업자가 장착됨</block>
  <block id="391dd52c88201d377f1572062e22c43e" category="list-text">허브 설치를 완료하는 데 약간의 시간이 걸리며, 작업이 완료되면 MultiCluster 허브가 실행 상태로 이동합니다.</block>
  <block id="c7aa79f0c31ac15d728ee47c7e6eaee2" category="image-alt">멀티클러스터 허브가 준비되었습니다</block>
  <block id="eef36825efd5d2d40e4f833635cd19da" category="list-text">또한 오픈 클러스터 관리 네임스페이스에 경로를 생성합니다. 경로의 URL에 연결하여 고급 클러스터 관리 콘솔에 액세스합니다.</block>
  <block id="f761fad3f1c25e94d5f46ebd9e23a901" category="image-alt">ACM 콘솔 경로</block>
  <block id="4488e277b96ae08def5eb77c2d8c6e74" category="inline-link-macro">다음: 기능 - 클러스터 수명 주기 관리</block>
  <block id="8a4d50965d8a3c708bdb16a716d64246" category="paragraph"><block ref="8a4d50965d8a3c708bdb16a716d64246" category="inline-link-macro-rx"></block></block>
  <block id="4e92dab2ab2bbe684f09a2aca58c9e44" category="list-text">NetApp ONTAP 클러스터</block>
  <block id="b645e117fe786bf56128cde2dec3971a" category="list-text">Red Hat OpenShift 클러스터</block>
  <block id="f675b3d5e1e137870f481a742a3ec0af" category="list-text">클러스터에 설치된 Trident</block>
  <block id="1db1a9d97c708824712706fc4267ec25" category="list-text">tridentctl 및 OC 도구가 설치되고 $PATH에 추가된 관리 워크스테이션</block>
  <block id="7cf4175762acfbabf9178d34f2504b28" category="list-text">ONTAP에 대한 관리자 액세스</block>
  <block id="10a540d0ed57154e8676c5725af53935" category="list-text">OpenShift 클러스터에 대한 클러스터 관리자 액세스</block>
  <block id="6340f6ab1111f349228595ebceb8f6db" category="list-text">클러스터가 ID 공급자와 통합됩니다</block>
  <block id="9e110c19bb79322a0b76199795550dea" category="list-text">ID 공급자는 서로 다른 팀의 사용자를 효율적으로 구분하도록 구성되어 있습니다</block>
  <block id="b917a2bfe0dd0160c3ad88751f355f5d" category="inline-link-macro">다음: 클러스터 관리자 작업.</block>
  <block id="7a9f102fda0e3438bff54da4acdbccbb" category="paragraph"><block ref="7a9f102fda0e3438bff54da4acdbccbb" category="inline-link-macro-rx"></block></block>
  <block id="810a039d1a8524388b75a0fe8d837afc" category="summary">Astra Control Center에서 워크로드를 관리할 수 있도록 하려면 먼저 Red Hat OpenShift 클러스터를 등록해야 합니다.</block>
  <block id="3557f7a93216446476c40d54e0426c40" category="doc">Astra Control Center에 Red Hat OpenShift 클러스터를 등록합니다</block>
  <block id="349c99fe6f384da92e5b8289b828791c" category="section-title">Red Hat OpenShift 클러스터를 등록합니다</block>
  <block id="c179429ab818c9d0cca3d1db55f788bf" category="list-text">첫 번째 단계는 OpenShift 클러스터를 Astra Control Center에 추가하고 관리하는 것입니다. 클러스터 로 이동하고 클러스터 추가 를 클릭하고 OpenShift 클러스터에 대한 kubecon무화과 파일을 업로드한 다음 저장소 선택 을 클릭합니다.</block>
  <block id="8dfc7d6b819f8c17b51391e3b3159add" category="inline-image-macro">Astra Control Center 클러스터 생성</block>
  <block id="7470624615914e8e3d5fdf4ea1aa31de" category="paragraph"><block ref="7470624615914e8e3d5fdf4ea1aa31de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7d9a690231a2d896f69e9b45c9ff4a1" category="admonition">kubecon무화과 파일은 사용자 이름 및 암호 또는 토큰으로 인증하기 위해 생성할 수 있습니다. 토큰은 제한된 시간 후에 만료되며 등록된 클러스터에 연결할 수 없는 상태로 유지될 수 있습니다. NetApp은 OpenShift 클러스터를 Astra Control Center에 등록하려면 사용자 이름과 암호를 사용하여 kubeconfig 파일을 사용하는 것이 좋습니다.</block>
  <block id="2fb91f8695d5dc9db4bf5a7ef710ec73" category="list-text">Astra Control Center가 적합한 스토리지 클래스를 감지합니다. 이제 NetApp ONTAP에서 SVM이 지원하는 Trident를 사용하여 스토리지 글라스의 볼륨 프로비저닝 방법을 선택하고 검토를 클릭합니다. 다음 창에서 세부 정보를 확인하고 Add Cluster를 클릭합니다.</block>
  <block id="cab7d2cb072914c0a5a89baab41d38e8" category="inline-image-macro">Astra Control Center 클러스터 선택 스토리지를 생성합니다</block>
  <block id="68ac91074dd3b4e5514e5f56a6c9c756" category="paragraph"><block ref="68ac91074dd3b4e5514e5f56a6c9c756" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3edb3c83eb1bede6778cc1960a651973" category="list-text">1단계에서 설명한 대로 두 OpenShift 클러스터를 모두 등록합니다. 추가된 클러스터는 검색 상태로 이동하고 Astra Control Center는 이를 검사하고 필요한 에이전트를 설치합니다. 성공적으로 등록되면 클러스터 상태가 실행 중으로 변경됩니다.</block>
  <block id="420b9c40f78cc4825914319af51801b9" category="inline-image-macro">Astra Control Center 클러스터를 사용할 수 있습니다</block>
  <block id="1b017a62213661e1ed3c5c581fcf74a2" category="paragraph"><block ref="1b017a62213661e1ed3c5c581fcf74a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ed5c1a60b8165b8bc691cbdf1b0d122c" category="admonition">Astra Control Center에서 관리하는 모든 Red Hat OpenShift 클러스터는 관리되는 클러스터에 설치된 에이전트가 해당 레지스트리에서 이미지를 가져올 때 설치에 사용된 이미지 레지스트리에 액세스할 수 있어야 합니다.</block>
  <block id="8d01de34ef9b9b934d18009a1e3273a9" category="list-text">Astra Control Center에서 백엔드를 관리할 스토리지 리소스로 ONTAP 클러스터를 가져옵니다. OpenShift 클러스터를 Astra에 추가하고 storageclass를 구성하면 ONTAP 클러스터를 자동으로 검색하고 검사하여 스토리지 클래스를 백업하지만 관리 대상 Astra Control Center로 가져오지 않습니다.</block>
  <block id="781ffd1df517a65b302412f53de974da" category="inline-image-macro">Astra Control Center 백엔드 검색</block>
  <block id="1fcc7977dffdc8fd8fc53582c67da895" category="paragraph"><block ref="1fcc7977dffdc8fd8fc53582c67da895" category="inline-image-macro-rx" type="image"></block></block>
  <block id="feab1371530d1ef069d928e811bcb08b" category="list-text">ONTAP 클러스터를 가져오려면 백엔드에서 드롭다운을 클릭하고 관리할 ONTAP 클러스터 옆에 있는 관리를 선택합니다. ONTAP 클러스터 자격 증명을 입력하고 정보 검토 를 클릭한 다음 스토리지 백엔드 가져오기 를 클릭합니다.</block>
  <block id="4da0c23c38cf0da34e1e6660ff74542b" category="inline-image-macro">Astra Control Center에서 백엔드를 생성합니다</block>
  <block id="69dbaffc2661024ee0b5095bc3674f60" category="paragraph"><block ref="69dbaffc2661024ee0b5095bc3674f60" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edb4425c04926a17b6ff9a4a2ecdc669" category="list-text">백엔드가 추가되면 상태가 사용 가능으로 변경됩니다. 이러한 백엔드는 이제 OpenShift 클러스터의 영구 볼륨과 ONTAP 시스템의 해당 볼륨에 대한 정보를 갖게 됩니다.</block>
  <block id="92c130f9be24925c7dee36f7580ea347" category="inline-image-macro">Astra Control Center 백엔드를 사용할 수 있습니다</block>
  <block id="e9f487b0aad6779edbf50c6092477bd5" category="paragraph"><block ref="e9f487b0aad6779edbf50c6092477bd5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f2d10d92dc9d83e3cf3514e8e883e5cb" category="list-text">Astra Control Center를 사용하여 OpenShift 클러스터 전체에서 백업 및 복원을 수행하려면 S3 프로토콜을 지원하는 오브젝트 스토리지 버킷을 프로비저닝해야 합니다. 현재 지원되는 옵션은 ONTAP S3, StorageGRID 및 AWS S3입니다. 이 설치를 위해 AWS S3 버킷을 구성하려고 합니다. Bucket 으로 이동하여 Bucket 추가 를 클릭하고 Generic S3 를 선택합니다. S3 버킷에 대한 세부 정보와 액세스할 자격 증명을 입력하고 "이 버킷을 클라우드의 기본 버킷으로 설정" 확인란을 클릭한 다음 추가를 클릭합니다.</block>
  <block id="6910cb9051734be0129cb1e7dd84ce5c" category="inline-image-macro">Astra Control Center는 버킷을 만듭니다</block>
  <block id="2786d0b632389f7cbd6c4e67fba0061f" category="paragraph"><block ref="2786d0b632389f7cbd6c4e67fba0061f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5a9f831c51dc05a9b40eae2850329fc" category="inline-link-macro">다음: 보호할 응용 프로그램을 선택합니다.</block>
  <block id="74dd157086250792afa856d5a6c32777" category="paragraph"><block ref="74dd157086250792afa856d5a6c32777" category="inline-link-macro-rx"></block></block>
  <block id="06fdae3f02fee5cbe172f1574564c925" category="doc">Kubernetes용 고급 클러스터 관리: NetApp의 Red Hat OpenShift</block>
  <block id="30c15b5a84f4fb26cd25b38dc787b22d" category="paragraph">개발 환경에서 운영 환경으로 컨테이너화된 애플리케이션으로 전환함에 따라 많은 조직에서는 해당 애플리케이션의 테스트 및 배포를 지원하기 위해 여러 Red Hat OpenShift 클러스터가 필요합니다. 이와 함께 조직은 일반적으로 OpenShift 클러스터에서 여러 애플리케이션 또는 워크로드를 호스팅합니다. 따라서 각 조직은 클러스터 세트를 관리해야 하며, OpenShift 관리자는 사내 데이터 센터와 퍼블릭 클라우드가 혼합된 다양한 환경에서 여러 클러스터를 관리하고 유지 관리해야 하는 추가적인 과제를 해결해야 합니다. 이러한 과제를 해결하기 위해 Red Hat은 Kubernetes용 Advanced Cluster Management를 도입했습니다.</block>
  <block id="1cf7b9db4d7fe091bd1bbb685e5beea8" category="paragraph">Kubernetes용 Red Hat Advanced Cluster Management를 사용하면 다음 작업을 수행할 수 있습니다.</block>
  <block id="808c579683377aa7bd89b8e4d76ba220" category="list-text">데이터 센터와 퍼블릭 클라우드 전반에서 여러 클러스터를 생성, 임포트, 관리합니다</block>
  <block id="7fe0555145a586e3fb769f86902ccc72" category="list-text">단일 콘솔에서 여러 클러스터의 애플리케이션 또는 워크로드를 구축하고 관리합니다</block>
  <block id="416434625b0f2158d99a4af37f233805" category="list-text">여러 클러스터 리소스의 상태 및 상태 모니터링 및 분석</block>
  <block id="fed6fdd49a1e6adda0ea12a93e74ea2d" category="list-text">여러 클러스터에서 보안 규정 준수 모니터링 및 적용</block>
  <block id="a7516c278242a08b85090e24cbf67218" category="paragraph">Kubernetes용 Red Hat Advanced Cluster Management는 Red Hat OpenShift 클러스터에 대한 애드온으로 설치되며, 모든 작업을 위한 중앙 컨트롤러로 이 클러스터를 사용합니다. 이 클러스터를 허브 클러스터라고 하며, 사용자가 고급 클러스터 관리에 연결할 수 있는 관리 영역을 노출합니다. Advanced Cluster Management 콘솔을 통해 가져오거나 생성되는 다른 모든 OpenShift 클러스터는 허브 클러스터에서 관리되며 관리되는 클러스터라고 합니다. 관리 대상 클러스터에 Klusterlet이라는 에이전트를 설치하여 허브 클러스터에 연결하고 클러스터 라이프사이클 관리, 애플리케이션 라이프사이클 관리, 관찰 가능성 및 보안 준수와 관련된 다양한 활동에 대한 요청을 처리합니다.</block>
  <block id="b1000f23e43dfac19b53c74d7ebe66c8" category="image-alt">ACM 아키텍처</block>
  <block id="a376445fd812a7fa27714e6b11bc6163" category="paragraph">자세한 내용은 설명서를 참조하십시오<block ref="50c0dc50e188cf3a7847d9a813fd829e" category="inline-link-rx"></block>.</block>
  <block id="a99137a02f570225903b02b175e289a4" category="paragraph"><block ref="a99137a02f570225903b02b175e289a4" category="inline-link-macro-rx"></block></block>
  <block id="86c2cc4630e619e2c08c32f54e844297" category="section-title">여러 클러스터에 리소스를 생성합니다</block>
  <block id="bc2397695676d1a63e489d4c80c8cd91" category="paragraph">Kubernetes의 고급 클러스터 관리를 사용하면 콘솔에서 하나 이상의 관리되는 클러스터에 리소스를 동시에 생성할 수 있습니다. 예를 들어, 서로 다른 NetApp ONTAP 클러스터로 백업된 여러 사이트에 OpenShift 클러스터를 사용하고 두 사이트에서 PVC를 프로비저닝하고 싶은 경우 상단 표시줄에서 (+) 기호를 클릭할 수 있습니다. 그런 다음 PVC를 생성할 클러스터를 선택하고 YAML 리소스를 붙여 넣은 다음 생성 을 클릭합니다.</block>
  <block id="24800112d59462f8ea9ff03f5dd456a7" category="image-alt">리소스를 생성합니다</block>
  <block id="ec22e01e7cd5087ef746b3db5852da6e" category="doc">확장: 더 많은 프로젝트 추가</block>
  <block id="0e4136a9f4ad3204c07db26d3c28a546" category="paragraph">멀티 테넌트 구성에서는 스토리지 리소스로 새 프로젝트를 추가하려면 멀티 테넌시가 위반되지 않도록 추가적인 구성이 필요합니다. 멀티 테넌트 클러스터에 프로젝트를 더 추가하려면 다음 단계를 완료하십시오.</block>
  <block id="c8acb1fa89b1ec9d78799a2dd4aa8b59" category="list-text">NetApp ONTAP 클러스터에 스토리지 관리자로 로그인합니다.</block>
  <block id="d0ed0d7b81278233c852e4a0d8aa123b" category="list-text">스토리지 -&gt; 스토리지 VM으로 이동한 후 추가 를 클릭합니다. PROJECT-3 전용 SVM을 새로 생성합니다. SVM 및 리소스를 관리하는 vsadmin 계정도 생성합니다.</block>
  <block id="5790e2b8b367726e78500054d959d6f7" category="image-alt">확장을 위한 SVM 생성</block>
  <block id="b0c67e9a89c7ece3169ab5849bb0e411" category="list-text">Red Hat OpenShift 클러스터에 클러스터 관리자로 로그인합니다.</block>
  <block id="c9e86337c7483c8d45e5e535829d2163" category="list-text">새 프로젝트를 만듭니다.</block>
  <block id="1c01b62cc887329b006a88e9f959b5d4" category="list-text">PROJECT-3의 사용자 그룹이 IDP에서 생성되고 OpenShift 클러스터와 동기화되었는지 확인합니다.</block>
  <block id="46c82384780a492254c43d461363d9ac" category="list-text">PROJECT-3의 개발자 역할을 만듭니다.</block>
  <block id="21ac9e9bbb2cfc707143311f4601af1c" category="admonition">이 섹션에 제공된 역할 정의는 예일 뿐입니다. 개발자 역할은 최종 사용자 요구 사항에 따라 정의되어야 합니다.</block>
  <block id="8efa8222e644f71e636f98917439566d" category="list-text">개발자를 위한 RoleBinding 만들기 project-3에서 developer-project-3 역할을 프로젝트-3의 해당 그룹(OCP-PROJECT-3)에 바인딩합니다.</block>
  <block id="e1f01c3341da15c9079bf5996c059811" category="list-text">Red Hat OpenShift 클러스터에 스토리지 관리자로 로그인합니다</block>
  <block id="2ca2d57f42208b6e7e9026b491595f41" category="list-text">Trident 백엔드를 생성하여 PROJECT-3 전용 SVM에 매핑합니다. ONTAP 클러스터 관리자를 사용하는 대신 SVM의 vsadmin 계정을 사용하여 백엔드를 SVM에 연결하는 것이 좋습니다.</block>
  <block id="c4dcda95616fac9215b5dac3cde37220" category="admonition">이 예에서는 ONTAP-NAS 드라이버를 사용하고 있습니다. 사용 사례에 따라 백엔드를 생성하는 데 적합한 드라이버를 사용하십시오.</block>
  <block id="55da75937cfedfe97c220c1e9d556d84" category="list-text">PROJECT-3의 스토리지 클래스를 생성하고 PROJECT-3 전용 백엔드에서 스토리지 풀을 사용하도록 구성합니다.</block>
  <block id="6efdcf6ed405066371d23375541816a1" category="list-text">ResourceQuota를 생성하여 다른 프로젝트 전용 스토리지로부터 스토리지를 요청하는 Project-3의 리소스를 제한합니다.</block>
  <block id="1dea1d57247580b530335ec2d484f8a5" category="list-text">다른 프로젝트의 ResourceQuotas를 패치하여 해당 프로젝트의 리소스가 project-3 전용 스토리지 클래스에서 스토리지에 액세스하는 것을 제한합니다.</block>
  <block id="3a724344bfc1b086a678d66814f20dd7" category="summary">이 섹션에서는 Jenkins와 지속적인 통합 및 지속적인 제공 또는 배포 파이프라인을 구축하여 솔루션 운영을 검증하는 단계를 제공합니다.</block>
  <block id="b830a759b7bbee23da50f11979fb8f27" category="doc">영구 스토리지로 Jenkins CI/CD 파이프라인 구축: NetApp과의 Red Hat OpenShift</block>
  <block id="ff587ce314d6f90660779e9d75cafe53" category="paragraph">이 섹션에서는 Jenkins와 지속적인 통합/지속적인 공급 또는 배포(CI/CD) 파이프라인을 구축하여 솔루션 운영을 검증하는 단계를 제공합니다.</block>
  <block id="9eb8af4dd2c3557a24b914601b6ae465" category="section-title">Jenkins 배포에 필요한 리소스를 생성합니다</block>
  <block id="93b3852e5c67975dd33b1769b24a4a85" category="paragraph">Jenkins 응용 프로그램 배포에 필요한 리소스를 생성하려면 다음 단계를 수행하십시오.</block>
  <block id="9fd493573e73cb0e5e55e97306249596" category="list-text">Jenkins라는 새 프로젝트를 만듭니다.</block>
  <block id="5690195262fb589b6021733b4a5a4432" category="paragraph"><block ref="5690195262fb589b6021733b4a5a4432" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d256abce3dbdfed83e337956e42f60f" category="list-text">이 예에서는 영구 스토리지에 Jenkins를 구축했습니다. Jenkins 빌드를 지원하려면 PVC를 만듭니다. 저장소 &gt; 영구 볼륨 클레임 으로 이동하고 영구 볼륨 클레임 생성 을 클릭합니다. 생성된 스토리지 클래스를 선택하고 영구 볼륨 클레임 이름이 Jenkins 인지 확인하고 적절한 크기 및 액세스 모드를 선택한 다음 만들기 를 클릭합니다.</block>
  <block id="f9db9f308c8ed7f5d0ed0851d8d605cb" category="paragraph"><block ref="f9db9f308c8ed7f5d0ed0851d8d605cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9272f40a21ca3dad814c4e3886b40776" category="section-title">영구 스토리지로 Jenkins를 배포합니다</block>
  <block id="939a7b51bfb262627185af768c3c1024" category="paragraph">영구 스토리지로 Jenkins를 배포하려면 다음 단계를 수행하십시오.</block>
  <block id="d31d340fd6b135cac2cfac7b04a34c10" category="list-text">왼쪽 위 모서리에서 역할을 관리자 에서 개발자 로 변경합니다. Add(추가) 를 클릭하고 Catalog(카탈로그) 에서 선택합니다. 키워드별 필터 표시줄에서 Jenkins를 검색합니다. 영구 저장소를 사용하는 Jenkins Service 를 선택합니다.</block>
  <block id="bc5512ef7a17a0cfb58cb1ede30a6137" category="paragraph"><block ref="bc5512ef7a17a0cfb58cb1ede30a6137" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6baa4bd25992de2d17278ade0d3090ad" category="list-text">"인스턴스화 템플릿"을 클릭합니다.</block>
  <block id="949381804bf1e16ca04ba9ac5fabc6a4" category="paragraph"><block ref="949381804bf1e16ca04ba9ac5fabc6a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7b4a6da6ab2733552de61d67b38a39e" category="list-text">기본적으로 Jenkins 응용 프로그램의 세부 정보가 채워집니다. 요구 사항에 따라 매개 변수를 수정하고 생성 을 클릭합니다. 이 프로세스는 OpenShift에서 Jenkins를 지원하는 데 필요한 모든 리소스를 생성합니다.</block>
  <block id="cc9a211dac876290bd6ed039cf1afdcf" category="paragraph"><block ref="cc9a211dac876290bd6ed039cf1afdcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb86f2dea9912af1bb1677c9cf33e619" category="list-text">Jenkins Pod는 Ready 상태로 들어가려면 약 10~12분이 걸립니다.</block>
  <block id="274c247b7612630006e3d87d5ed5d46f" category="paragraph"><block ref="274c247b7612630006e3d87d5ed5d46f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da33835bff86a0b0c8be6c67dcf677bb" category="list-text">포드가 인스턴스화된 후 네트워킹 &gt; 라우트로 이동합니다. Jenkins 웹 페이지를 열려면 Jenkins 루트에 제공된 URL을 클릭합니다.</block>
  <block id="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="paragraph"><block ref="2ebe03c4d2a2f4464e9ec333d6fd7c17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d59d1324dea050a2c0ffc376de411aa0" category="list-text">Jenkins 앱을 만드는 동안 OpenShift OAuth가 사용되었기 때문에 OpenShift로 로그인 을 클릭합니다.</block>
  <block id="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="paragraph"><block ref="8dd2ba6f6eb648ee9a5d6e1b6aa96114" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70a742210f3e3599821b3a11b682144c" category="list-text">Jenkins 서비스 계정을 인증하여 OpenShift 사용자에게 액세스합니다.</block>
  <block id="9359288fc248319fa9acef62e4686d1c" category="paragraph"><block ref="9359288fc248319fa9acef62e4686d1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b07934b6023389a7e3e183b45e3b7448" category="list-text">Jenkins 시작 페이지가 표시됩니다. Maven 빌드를 사용하기 때문에 Maven 설치를 먼저 완료하십시오. Manage Jenkins &gt; Global Tool Configuration 으로 이동한 다음 Maven 하위 헤드에서 Add Maven 을 클릭합니다. 선택한 이름을 입력하고 자동 설치 옵션이 선택되어 있는지 확인합니다. 저장 을 클릭합니다.</block>
  <block id="00713894c16827219fd5ab50c5fc3794" category="paragraph"><block ref="00713894c16827219fd5ab50c5fc3794" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8fd32305bf380bf893ef2407eae75f5d" category="list-text">이제 CI/CD 워크플로우를 시연하기 위한 파이프라인을 생성할 수 있습니다. 홈 페이지의 왼쪽 메뉴에서 새 작업 만들기 또는 새 항목 만들기를 클릭합니다.</block>
  <block id="24f99be3c7033ab08c3baec1cdf32702" category="paragraph"><block ref="24f99be3c7033ab08c3baec1cdf32702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b6fc174a3fad5c396413febe1d4ba50" category="list-text">항목 만들기 페이지에서 선택한 이름을 입력하고 파이프라인을 선택한 다음 확인을 클릭합니다.</block>
  <block id="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="paragraph"><block ref="b8c544e8c9e5bd5fa17dce065fd5dcc9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd55d787cacfb25983e0a24b58ba6d48" category="list-text">Pipeline 탭을 선택합니다. 샘플 파이프라인 시험 사용 드롭다운 메뉴에서 GitHub + Maven 을 선택합니다. 코드가 자동으로 채워집니다. 저장 을 클릭합니다.</block>
  <block id="dedbf53849830e8b275b69e9b98159ce" category="paragraph"><block ref="dedbf53849830e8b275b69e9b98159ce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0191ad3b841f8db403ec4749d571eb4b" category="list-text">지금 구축을 클릭하여 준비, 빌드 및 테스트 단계를 통해 개발을 시작합니다. 전체 빌드 프로세스를 완료하고 빌드 결과를 표시하는 데 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="1d11f84feef51515ab9fdaafb3f02f3a" category="paragraph"><block ref="1d11f84feef51515ab9fdaafb3f02f3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b04b355d9fc6a2e23965649ebdd0aa31" category="list-text">코드 변경 사항이 있을 때마다 파이프라인을 재구축하여 새로운 소프트웨어 버전을 패치할 수 있으므로 지속적인 통합 및 지속적인 제공이 가능합니다. 최근 변경 내용 을 클릭하여 이전 버전의 변경 내용을 추적합니다.</block>
  <block id="43d9a2fc4d89e82c869a466778811ab3" category="paragraph"><block ref="43d9a2fc4d89e82c869a466778811ab3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0b41ceffa053ec5210732b1f8d0f0c5d" category="inline-link-macro">다음: 비디오 및 데모.</block>
  <block id="232b127190e97018e70ee81d28e36117" category="paragraph"><block ref="232b127190e97018e70ee81d28e36117" category="inline-link-macro-rx"></block></block>
  <block id="55c7e45b50d0b012faf4bce31b6ad05d" category="section-title">스냅샷으로부터 VM을 생성하십시오</block>
  <block id="9e5a59ca9aef030e74a725dab3fb6dcf" category="paragraph">Astra Trident와 Red Hat OpenShift를 사용하면 IT에서 프로비저닝한 스토리지 클래스에서 영구 볼륨의 스냅샷을 생성할 수 있습니다. 이 기능을 사용하면 사용자는 볼륨의 시점 복사본을 만들어 새 볼륨을 생성하거나 동일한 볼륨을 이전 상태로 복원할 수 있습니다. 이를 통해 롤백에서 클론, 데이터 복원에 이르기까지 다양한 활용 사례를 지원하거나 지원할 수 있습니다.</block>
  <block id="f991e1a54e399d272c7d968dcdfdb690" category="paragraph">OpenShift의 스냅샷 작업의 경우 VolumeSnapshotClass, VolumeSnapshot 및 VolumeSnapshotContent 리소스를 정의해야 합니다.</block>
  <block id="0e2d1628ef03c4400cd293c3143cabb3" category="list-text">VolumeSnapshotContent는 클러스터의 볼륨에서 생성된 실제 스냅샷입니다. 이 리소스는 스토리지용 PersistentVolume과 유사한 클러스터 차원의 리소스입니다.</block>
  <block id="8ca4876558d3675f7a3e2c452c62a215" category="list-text">VolumeSnapshot은 볼륨의 스냅샷을 생성하기 위한 요청입니다. PersistentVolumeClaim과 유사합니다.</block>
  <block id="7f9fbed02a61699d31f7d9a0eb11bc81" category="list-text">VolumeSnapshotClass를 사용하면 관리자가 VolumeSnapshot에 대해 서로 다른 속성을 지정할 수 있습니다. 동일한 볼륨에서 생성된 서로 다른 스냅샷에 대해 서로 다른 속성을 가질 수 있습니다.</block>
  <block id="7f7858938c48bb9f08341c0e41c9162d" category="image-alt">VM을 생성할 수 있습니다</block>
  <block id="99bf6e1ad41f7875d5b7ec9f857c4f0f" category="paragraph">VM의 스냅샷을 생성하려면 다음 단계를 완료합니다.</block>
  <block id="5dc14d36063086387d2eb7cf012544aa" category="list-text">VolumeSnapshot을 생성하는 데 사용할 수 있는 VolumeSnapshotClass를 생성합니다. Storage &gt; VolumeSnapshotClasses 로 이동하고 Create VolumeSnapshotClass 를 클릭합니다.</block>
  <block id="52f0977d1e65469f01e2f290e637a8f1" category="list-text">스냅샷 클래스의 이름을 입력하고 드라이버에 csi.trident.netapp.io 를 입력한 다음 생성 을 클릭합니다.</block>
  <block id="508073b07367d898823f1841627451d4" category="image-alt">스냅샷 클래스를 생성합니다</block>
  <block id="2bde7e02152796551174ea391bda0b60" category="list-text">소스 VM에 연결된 PVC를 확인한 다음 해당 PVC의 스냅샷을 생성합니다. 'Storage &gt; VolumeSnapshots'로 이동하여 Create VolumeSnapshots을 클릭합니다.</block>
  <block id="b9513caba1fba7b4291a9e22bc512de5" category="list-text">스냅샷을 생성할 PVC를 선택하고 스냅샷 이름을 입력하거나 기본값을 적용한 다음 적절한 VolumeSnapshotClass를 선택합니다. 그런 다음 만들기 를 클릭합니다.</block>
  <block id="a7a384e6f13cae2ef877b4dd78fd48ad" category="image-alt">스냅샷 생성</block>
  <block id="d8ae3e40f0f0dba0b7c7ba5b8eea845a" category="list-text">그러면 해당 시점에 PVC의 스냅샷이 생성됩니다.</block>
  <block id="e9b3b34ca8f917d1968a106e682f1a97" category="section-title">스냅샷으로부터 새 VM을 생성합니다</block>
  <block id="3ffbaa72c8e63f0ec3ced08d8ebf9f72" category="list-text">먼저 스냅샷을 새 PVC로 복구합니다. Storage &gt; VolumeSnapshots로 이동하고 복원하려는 스냅샷 옆에 있는 줄임표를 클릭한 다음 Restore as new PVC(새 PVC로 복원) 를 클릭합니다.</block>
  <block id="5160cd070df38f982551c5fea6f1c844" category="list-text">새 PVC의 세부 정보를 입력하고 Restore(복원) 를 클릭합니다. 이렇게 하면 새 PVC가 생성됩니다.</block>
  <block id="0d695454ca10516a832452b6123c5bb5" category="image-alt">스냅샷을 새 PVC로 복원합니다</block>
  <block id="8a4d1acf8df9931b5c42b3253f943d79" category="list-text">다음으로 이 PVC에서 새 VM을 생성합니다. 워크로드 &gt; 가상화 &gt; 가상 시스템으로 이동하고 생성 &gt; YAML을 클릭합니다.</block>
  <block id="91b9a57ab88a6942f692f9f393549f6e" category="list-text">spec &gt; template &gt; spec &gt; volumes 섹션에서 컨테이너 디스크 대신 스냅샷에서 생성된 새 PVC를 지정합니다. 요구 사항에 따라 새 VM에 대한 기타 모든 세부 정보를 제공합니다.</block>
  <block id="57dc3c96f32e4895e89eab4a248088f5" category="list-text">VM이 성공적으로 생성된 후 스냅샷이 생성된 시점에 스냅샷을 생성하는 데 PVC를 사용한 VM의 상태와 새 VM의 상태가 동일한지 액세스 및 확인합니다.</block>
  <block id="50465c19760e2a5476479f1f4a464119" category="summary">NetApp의 Bare Metal Anthos는 배포된 인프라의 사용자 지정을 가능하게 하여 컨테이너 기반 워크로드를 효율적으로 실행할 수 있는 강력한 플랫폼을 제공합니다.</block>
  <block id="3ae752a47170fdc4f7ff5ed3204c1fb5" category="paragraph"><block ref="3ae752a47170fdc4f7ff5ed3204c1fb5" category="inline-link-macro-rx"></block></block>
  <block id="31fd0c2c8d388a4cd2c6459234743476" category="section-title">관찰 가능성</block>
  <block id="e98511d60f9850de86f096614f447322" category="paragraph">Kubernetes용 고급 클러스터 관리를 사용하면 모든 클러스터에서 노드, 포드, 애플리케이션 및 워크로드를 모니터링할 수 있습니다.</block>
  <block id="36aff44ed429ca86d182dc7ee3dfdbb1" category="list-text">환경 관찰 &gt; 개요 로 이동합니다.</block>
  <block id="7a6ccefec75a946583cffdd0a8a47e09" category="image-alt">관찰 가능성 홈 페이지</block>
  <block id="c9904a9276a489fc238c999d2ddd633f" category="list-text">모든 클러스터에 있는 모든 Pod 및 워크로드는 다양한 필터를 기준으로 모니터링 및 정렬됩니다. 해당 데이터를 보려면 Pod를 클릭합니다.</block>
  <block id="4a973ae1a908770e354f949d3c0592f8" category="image-alt">포드 관찰</block>
  <block id="7cd1c61051d3647bc47d839e0efee222" category="list-text">다양한 데이터 요소를 기반으로 클러스터 전체의 모든 노드를 모니터링하고 분석합니다. 노드를 클릭하여 해당 세부 정보를 자세히 확인합니다.</block>
  <block id="8a373f777de729c082b5be2d80b7eca6" category="image-alt">노드를 관찰합니다</block>
  <block id="4e7f54a0ebc5cd69209a17181d477e4c" category="list-text">모든 클러스터는 다양한 클러스터 리소스 및 매개 변수를 기반으로 모니터링 및 구성됩니다. 클러스터 세부 정보를 보려면 클러스터 를 클릭합니다.</block>
  <block id="2ececa2c251a851a85e976daae558c81" category="image-alt">클러스터 관찰</block>
  <block id="a883982d5f8961021329c238318d4e2b" category="inline-link-macro">다음: 기능 - 리소스 생성</block>
  <block id="5ca146f2101c14a961df161060f86cb9" category="paragraph"><block ref="5ca146f2101c14a961df161060f86cb9" category="inline-link-macro-rx"></block></block>
  <block id="a0c55f3c40b8bb2d3e26f8d11ca73cbc" category="summary">이 참조 문서는 NetApp에서 검증한 바와 같이 여러 데이터 센터 환경에서 IPI(Installer provisioned Infrastructure)를 통해 배포된 Red Hat OpenShift 솔루션의 배포 검증을 제공합니다. 또한, 영구 스토리지 관리를 위한 Astra Trident 스토리지 오케스트레이터를 사용하여 NetApp 스토리지 시스템과의 스토리지 통합에 대해서도 자세히 설명합니다. 마지막으로, 다양한 솔루션 검증 및 실제 사용 사례를 살펴보고 문서화합니다.</block>
  <block id="a0e01d06503f271c1de7acc0acd01733" category="doc">NVA-1160: NetApp 기반의 Red Hat OpenShift</block>
  <block id="3f4b17e041e63192875c654812122484" category="paragraph">NetApp의 Alan Cowles와 Nikhil M Kulkarni입니다</block>
  <block id="4711a0fd2fa3c3625080f399e5261ecd" category="paragraph">NetApp OpenShift with NetApp 솔루션은 다음과 같은 사용 사례를 통해 고객에게 뛰어난 가치를 제공하도록 설계되었습니다.</block>
  <block id="44815e873492015d6a8ab6362de8da6c" category="list-text">베어 메탈, Red Hat OpenStack Platform, Red Hat Virtualization 및 VMware vSphere에 IPI(Installer Provisioned Infrastructure)를 사용하여 배포된 Red Hat OpenShift를 쉽게 배포 및 관리할 수 있습니다.</block>
  <block id="03bb323d052d033ea0b5b2cab17f1219" category="list-text">OSP, RHV, vSphere 또는 OpenShift Virtualization을 통해 가상 배포된 Red Hat OpenShift를 사용하여 엔터프라이즈 컨테이너 및 가상화된 워크로드의 성능을 합친 것입니다.</block>
  <block id="a2ac5b8f3de7c17418af38c828121a15" category="list-text">NetApp 스토리지와 Kubernetes용 오픈 소스 스토리지 오케스트레이터인 Astra Trident의 Red Hat OpenShift의 기능을 설명하는 실제 구성 및 사용 사례</block>
  <block id="f08561bbd831bfa1923e6acf045ef13a" category="section-title">비즈니스 가치</block>
  <block id="932ba7da1da9b241bfc5ddbb10e49da2" category="paragraph">기업은 새로운 제품을 만들고, 릴리즈 주기를 단축하며, 새로운 기능을 빠르게 추가하기 위해 DevOps 사례를 점점 더 채택하고 있습니다. 컨테이너 및 마이크로서비스는 타고난 애자일 특성상 DevOps 사례를 지원하는 데 중요한 역할을 합니다. 그러나 엔터프라이즈 환경에서 운영 환경에서 DevOps를 수행하는 것은 그 자체로 문제가 되며 다음과 같은 기본 인프라에서 특정 요구사항을 부과합니다.</block>
  <block id="43ee156205e7f74e32a02d556537fe90" category="list-text">스택의 모든 계층에서 고가용성 보장</block>
  <block id="b59807af538b77fee1fb3d1d3c81f9a8" category="list-text">간편한 구축 절차</block>
  <block id="2748d7182409b378e23f62724be778fd" category="list-text">무중단 운영 및 업그레이드</block>
  <block id="1a4af279491c72d7c36b4c9767ae712f" category="list-text">마이크로서비스 민첩성을 유지하기 위한 API 기반 및 프로그래밍 가능한 인프라</block>
  <block id="0cdff7d38ef496f6b5510c5034fedf15" category="list-text">성능 보장이 포함된 멀티 테넌시</block>
  <block id="8ca11bfd783c730b04c0c77fc7574406" category="list-text">가상화 워크로드 및 컨테이너화된 워크로드를 동시에 실행할 수 있습니다</block>
  <block id="0111977afdb7fa380f806edbe8438163" category="list-text">워크로드 요구사항에 따라 인프라를 독립적으로 확장할 수 있는 능력</block>
  <block id="42c487483a8feee3cc0365881a4cc265" category="paragraph">NetApp의 Red Hat OpenShift는 이러한 문제를 인식하고 고객이 선택한 데이터 센터 환경에 RedHat OpenShift IPI를 완전히 자동으로 배포하여 각 문제를 해결하는 솔루션을 제시합니다.</block>
  <block id="d3d8eb53a347d6ffc9fb157d9ac8398b" category="paragraph">NetApp OpenShift의 경우 NetApp 솔루션은 다음과 같은 주요 구성요소로 이루어져 있습니다.</block>
  <block id="fd89bb4228981d3b22187eb451421cd6" category="section-title">Red Hat OpenShift Container Platform</block>
  <block id="2b8932b35916e8cecb6216546111322e" category="paragraph">Red Hat OpenShift Container Platform은 완전히 지원되는 엔터프라이즈 Kubernetes 플랫폼입니다. Red Hat은 컨테이너화된 애플리케이션을 구축, 배포 및 관리하기 위해 모든 구성 요소가 완벽하게 통합된 애플리케이션 플랫폼을 제공하기 위해 오픈 소스 Kubernetes를 몇 가지 개선하였습니다.</block>
  <block id="70240bc0debcb080aa08dbd9e7b9a525" category="paragraph">자세한 내용은 OpenShift 웹 사이트를 참조하십시오<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="81f74b2a02db97d708bd7cbf08d2463a" category="section-title">NetApp 스토리지 시스템을 나타냅니다</block>
  <block id="660d073f0987fac312dc40bd5dc868bd" category="paragraph">NetApp은 엔터프라이즈 데이터 센터 및 하이브리드 클라우드 구축에 적합한 여러 스토리지 시스템을 보유하고 있습니다. NetApp 포트폴리오에는 NetApp ONTAP, NetApp Element, NetApp E-Series 스토리지 시스템이 포함되어 있으며, 컨테이너식 애플리케이션을 위한 영구 스토리지를 제공할 수 있습니다.</block>
  <block id="aa4193984de53d2a6d8fcc2d77c09bda" category="paragraph">자세한 내용은 NetApp 웹 사이트를 참조하십시오<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="069b087e8e1e69cc928f18a85f683523" category="section-title">NetApp 스토리지 통합</block>
  <block id="b4186621511a622be24ad982b0a8ec32" category="paragraph">NetApp Astra Control Center는 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공하며, 온프레미스 환경에 구축되어 신뢰할 수 있는 NetApp 데이터 보호 기술을 기반으로 합니다.</block>
  <block id="947496ade2e4a2c8e929d9aa9f00be04" category="paragraph">자세한 내용은 NetApp Astra 웹 사이트를 참조하십시오<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="05cd0cf0962d29806df78d956f772deb" category="paragraph">Astra Trident는 Red Hat OpenShift를 포함한 컨테이너 및 Kubernetes 배포를 위한 오픈 소스 및 완전 지원 스토리지 오케스트레이터입니다.</block>
  <block id="0bc570c518e7c4f356ebceb14fa8372f" category="section-title">고급 구성 옵션</block>
  <block id="aa44798f04a58b33c3699abd02a59c57" category="paragraph">이 섹션에서는 전용 개인 이미지 레지스트리를 만들거나 사용자 지정 로드 밸런서 인스턴스를 배포하는 등 실제 사용자가 이 솔루션을 운영 환경에 배포할 때 수행해야 할 사용자 지정 작업에 대해 설명합니다.</block>
  <block id="382742bb5fff6a719c144a0a01cd17e3" category="section-title">검증된 릴리즈에 대한 최신 지원 매트릭스</block>
  <block id="e7e767d7c0e58b16e57d3ab16150db80" category="cell">제공합니다</block>
  <block id="40ddf58fef213ff0d6433ef322edfe2e" category="cell">소프트웨어 버전</block>
  <block id="bd4a2d19c5168aa8c2b89b4affba2402" category="cell">9.8, 9.9.1</block>
  <block id="fcda5b98e8c212807dc088477e802757" category="cell">NetApp Element</block>
  <block id="601712ded7a71b0842984ad41b6aad39" category="cell">12.3</block>
  <block id="12c17259bf3f3b36e970c9e3abbc6b43" category="cell">NetApp Astra Control Center를 참조하십시오</block>
  <block id="8d96276332b02a2ef892828c1d4fbab4" category="cell">애플리케이션 인식 데이터 관리</block>
  <block id="8de59ec369b10820d0dd336b9765c79b" category="cell">NetApp Astra Trident</block>
  <block id="765bb3744268ca0de607208bfdc8a37a" category="cell">스토리지 오케스트레이션</block>
  <block id="b175d08ac03101cd40f077848d436e1f" category="cell">Red Hat OpenShift</block>
  <block id="d7ac58512991ed45f3abecbfbb9cddf1" category="cell">컨테이너 오케스트레이션</block>
  <block id="2454407b9991c6c5f417a2feb8ea7970" category="cell">4.6 EUS, 4.7</block>
  <block id="9c4e78a1b7e7b4981aced1e10d037c6d" category="cell">Red Hat OpenStack 플랫폼</block>
  <block id="de45aa336111dfa1825c54726464307c" category="cell">프라이빗 클라우드 인프라</block>
  <block id="3c5825a0d4bdb85c67182ef89bc9c7eb" category="cell">16.1</block>
  <block id="80e910f35b12e9c61335fa88de36edd0" category="cell">Red Hat 가상화</block>
  <block id="e3024b13494086daa1b9813a799ba41a" category="cell">데이터 센터 가상화</block>
  <block id="f9a97ed4e88eeab44f2693afa0eb2089" category="cell">4.4</block>
  <block id="8887a9a417a1629326acdb917d224337" category="cell">VMware vSphere를 참조하십시오</block>
  <block id="9c295b8302ac546bb93a346b68089f50" category="cell">6.7U3</block>
  <block id="aacc79f269e716528198eabb064b216b" category="inline-link-macro">다음은 Red Hat OpenShift 개요입니다.</block>
  <block id="62857c2aca7eeae2c1f44104c3fc7dde" category="paragraph"><block ref="62857c2aca7eeae2c1f44104c3fc7dde" category="inline-link-macro-rx"></block></block>
  <block id="472d13eb415cd6107aeef3a1ae6cd705" category="summary">NetApp은 Red Hat OpenShift와 같은 컨테이너 기반 환경에서 지속적인 데이터를 오케스트레이션하고 관리할 수 있도록 고객을 지원하는 다양한 제품을 제공합니다.</block>
  <block id="2515fbef39d57544723402c683215c64" category="doc">NetApp 스토리지 통합 개요</block>
  <block id="689ca76b61ed9331405d36eb5ded709d" category="paragraph">NetApp은 Red Hat OpenShift와 같은 컨테이너 기반 환경에서 영구 데이터를 오케스트레이션하고 관리하는 데 도움이 되는 다양한 제품을 제공합니다.</block>
  <block id="ebfc0e639726a366f8eb5ac86bb7cc43" category="paragraph"><block ref="ebfc0e639726a366f8eb5ac86bb7cc43" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0c3fd18fbca2ec11aa1ef250cf79f2e5" category="paragraph">NetApp Astra Control은 NetApp 데이터 보호 기술을 기반으로 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공합니다. Astra Control Service는 클라우드 네이티브 Kubernetes 구축에서 상태 저장 워크로드를 지원할 수 있습니다. Astra Control Center는 Red Hat OpenShift와 같은 온프레미스 배포에서 상태 저장 워크로드를 지원할 수 있습니다. 자세한 내용은 NetApp Astra Control 웹 사이트를 참조하십시오<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="cd351007d4a671a321b6881f730d0dc3" category="paragraph">다음 페이지는 NetApp OpenShift with NetApp 솔루션에서 애플리케이션 및 영구 스토리지 관리를 위해 검증된 NetApp 제품에 대한 추가 정보를 제공합니다.</block>
  <block id="afa49872fb8ae001174e4c8f2cc47208" category="inline-link-macro">다음은 NetApp Astra Control Center의 개요입니다</block>
  <block id="22fd530ae76b4bbe50669b9a4d5b72d7" category="paragraph"><block ref="22fd530ae76b4bbe50669b9a4d5b72d7" category="inline-link-macro-rx"></block></block>
  <block id="f79c612e785ac74789a25e8dda9e8731" category="doc">Astra Trident 개요</block>
  <block id="78c43863df60a7808264e8659cfa6b54" category="paragraph">Astra Trident는 Red Hat OpenShift를 포함하여 컨테이너 및 Kubernetes 배포를 위한 오픈 소스 및 완전 지원되는 스토리지 오케스트레이터입니다. Trident는 NetApp ONTAP 및 Element 스토리지 시스템을 포함한 전체 NetApp 스토리지 포트폴리오와 연동되며 NFS 및 iSCSI 연결도 지원합니다. Trident는 최종 사용자가 스토리지 관리자의 개입 없이 NetApp 스토리지 시스템에서 스토리지를 프로비저닝 및 관리할 수 있도록 하여 DevOps 워크플로우를 가속합니다.</block>
  <block id="a4957cf974ce20219897bbbf5b131cb8" category="paragraph">관리자는 특정 수준의 성능을 보장하는 압축, 특정 디스크 유형 또는 QoS 수준을 비롯한 고급 스토리지 기능을 지원하는 스토리지 시스템 모델과 프로젝트 요구사항에 따라 여러 스토리지 백엔드를 구성할 수 있습니다. 이러한 백엔드를 정의한 후, 개발자는 프로젝트의 이러한 백엔드를 사용하여 지속적인 PVC(Volume Claim)를 생성하고 필요에 따라 컨테이너에 영구 저장소를 연결할 수 있습니다.</block>
  <block id="ecfb2402c181e98da49a5d763378b116" category="paragraph"><block ref="ecfb2402c181e98da49a5d763378b116" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0626021388a8dcc9b1e26b1209550b8d" category="paragraph">Astra Trident는 빠른 개발 주기를 제공하며, Kubernetes와 마찬가지로 1년에 4회 릴리즈됩니다.</block>
  <block id="b62bb4786ef52ad76706950add6991dd" category="paragraph">20.04 릴리즈부터 Trident 운영자가 Trident 설정을 수행합니다. 운영자는 대규모 구축을 용이하게 하고 Trident 설치의 일부로 배포된 Pod에 대한 자동 복구를 포함한 추가 지원을 제공합니다.</block>
  <block id="4a85fdd5a26454abc330a5ec2a46a326" category="paragraph">21.01 릴리즈를 통해 Trident Operator의 설치를 용이하게 하는 제어 차트를 사용할 수 있게 되었습니다.</block>
  <block id="4281e618126caa3d322e78eafddba1b2" category="section-title">Astra Trident를 다운로드하십시오</block>
  <block id="f95d0437e813349fa018b7f0e68e9a7d" category="paragraph">구축된 사용자 클러스터에 Trident를 설치하고 영구 볼륨을 프로비저닝하려면 다음 단계를 완료하십시오.</block>
  <block id="422269f9bb560b76869cbd586b8370d5" category="list-text">다운로드한 번들에서 Trident 설치를 추출합니다.</block>
  <block id="52d012c119e8e080d08f6a1592f8f9ec" category="section-title">Hrom을 사용하여 Trident 연산자를 설치합니다</block>
  <block id="68602d0447fae81afa9d0528ef0c6420" category="list-text">먼저 사용자 클러스터의 "kubecononfig" 파일 위치를 환경 변수로 설정하여 Trident에 이 파일을 전달할 수 있는 옵션이 없으므로 참조할 필요가 없습니다.</block>
  <block id="449774824d889f1d6ebc0bbcc4920493" category="list-text">Helm 명령을 실행하여 사용자 클러스터에 삼중덴트 네임스페이스를 생성하는 동안 Helm 디렉토리의 tarball에서 Trident 연산자를 설치합니다.</block>
  <block id="64e437a845e5de3c8e50925ebdfce295" category="list-text">네임스페이스에서 실행 중인 포드를 확인하거나 tridentctl 바이너리를 사용하여 설치된 버전을 확인하여 Trident가 성공적으로 설치되었는지 확인할 수 있습니다.</block>
  <block id="3ce67d5de6974f67e0048e6fdbf89498" category="admonition">경우에 따라 고객 환경에 Trident 구축의 사용자 지정이 필요할 수 있습니다. 이러한 경우 Trident 연산자를 수동으로 설치하고 포함된 매니페스트를 업데이트하여 배포를 사용자 지정할 수도 있습니다.</block>
  <block id="8bd534d3b6bc8d2541df052e053ed65d" category="section-title">Trident 연산자를 수동으로 설치합니다</block>
  <block id="1315b42a551dafb715ab654d8eb5af40" category="list-text">먼저, Trident에 이 파일을 전달할 수 있는 옵션이 없기 때문에 사용자 클러스터의 "kubecononfig" 파일을 참조할 필요가 없도록 환경 변수로 설정합니다.</block>
  <block id="5d710ec7d521df428edd75c1885ee89b" category="list-text">트리덴트 설치 프로그램 디렉토리에는 필요한 모든 리소스를 정의하기 위한 매니페스트가 들어 있습니다. 적절한 매니페스트를 사용하여 '트리엔오케스트레이터' 사용자 지정 리소스 정의를 만듭니다.</block>
  <block id="0ac11186fb38b2e9d4acd38d03f61b5c" category="list-text">Trident 네임스페이스가 없으면 제공된 매니페스트를 사용하여 클러스터에 Trident 네임스페이스를 만듭니다.</block>
  <block id="004c51fe71b5c654f88a31270ec6c8e9" category="list-text">연산자에 대한 'erviceAccount', 'clusterRole', 'ClusterRoleBinding', 'erviceAccount', 'PodSecurityPolicy', 또는 연산자 자체에 대한 'erviceAccount' 등 Trident 운용자 구축에 필요한 리소스를 생성한다.</block>
  <block id="f7b9c678b684e969a3ee5ac971514f48" category="list-text">다음 명령을 사용하여 운영자 배포 후 상태를 확인할 수 있습니다.</block>
  <block id="b34dd67c198ad4cf0088bd29c7ef4658" category="list-text">운영자가 구축되었으므로 이제 Trident를 설치할 수 있습니다. 이를 위해서는 '트리엔오케스트레이터'를 만들어야 합니다.</block>
  <block id="e32d70a13ba1767d9a373fe9a0535531" category="section-title">스토리지에 대한 작업자 노드 준비</block>
  <block id="4b4d60be85b0c53c72ae4b8a05deacef" category="paragraph">대부분의 Kubernetes 배포판에는 Red Hat OpenShift를 포함하여 기본적으로 설치된 NFS 백엔드를 마운트하는 패키지와 유틸리티가 함께 제공됩니다.</block>
  <block id="693642fbb464db49c22715a536e99c3f" category="paragraph">iSCSI 프로토콜을 통해 블록 스토리지 볼륨을 매핑할 수 있도록 작업자 노드를 준비하려면 해당 기능을 지원하는 데 필요한 패키지를 설치해야 합니다.</block>
  <block id="cccb85b5e6a9a19187087f71254d1fb2" category="paragraph">Red Hat OpenShift에서는 MCO(Machine Config Operator)를 배포된 후 클러스터에 적용하여 처리됩니다.</block>
  <block id="7b8e6ef8272a81ebcc108ee3fcf4eac8" category="list-text">OCP 웹 콘솔에 로그인하여 Compute(컴퓨팅) &gt; Machine Configs(장비 구성) 로 이동합니다. Create Machine Config 를 클릭합니다. YAML 파일을 복사하여 붙여넣은 다음 생성 을 클릭합니다.</block>
  <block id="c25282bfd8c140d1f79c25362637f744" category="paragraph">다중 경로를 사용하지 않는 경우:</block>
  <block id="541c76e8762c84e3e0488f91c8062e08" category="paragraph">다중 경로 사용 시:</block>
  <block id="d9f036d3b9f84b626f8a777480066cab" category="list-text">구성을 생성한 후 작업자 노드에 구성을 적용하고 다시 로드하는 데 약 20~30분이 걸립니다. 'OC Get MCP'를 사용하여 기계 설정이 적용되었는지 확인하고 작업자에 대한 기계 구성 풀이 업데이트되었는지 확인합니다. 작업자 노드에 로그인하여 iscsid 서비스가 실행 중인지 확인할 수도 있습니다(다중 경로를 사용하는 경우 multipathd 서비스가 실행 중인지 확인).</block>
  <block id="6e16409ed6038c106c7fa1dfbfb9da0f" category="admonition">또한 MachineConfig가 성공적으로 적용되고 서비스가 예상대로 시작되었는지 확인할 수 있는 것은 적절한 플래그를 사용하여 OC debug 명령을 실행하는 것입니다.</block>
  <block id="b09d268106fd9cbfffd1dc848382a150" category="section-title">스토리지 시스템 백엔드를 생성합니다</block>
  <block id="f71051465199267cbb540658a51e2957" category="paragraph">Astra Trident Operator 설치를 완료한 후에는 사용 중인 특정 NetApp 스토리지 플랫폼에 대한 백엔드를 구성해야 합니다. Astra Trident의 설정 및 구성을 계속하려면 아래 링크를 따라가십시오.</block>
  <block id="615767b52353571ac174e22f1a984aa3" category="inline-link-macro">NetApp ONTAP NFS 를 참조하십시오</block>
  <block id="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="list-text"><block ref="fa0fe4c03e1ba99a2cac1c4c208b7fbd" category="inline-link-macro-rx"></block></block>
  <block id="c93e7ef2934826b1393251e9f7d9e331" category="inline-link-macro">NetApp ONTAP iSCSI를 참조하십시오</block>
  <block id="d7b539d4bc16fbdf1477adddfda6c802" category="list-text"><block ref="d7b539d4bc16fbdf1477adddfda6c802" category="inline-link-macro-rx"></block></block>
  <block id="d0e0904111acb167badbf5f196ad1205" category="inline-link-macro">NetApp Element iSCSI 를 참조하십시오</block>
  <block id="2e5d36490241211379006b7f6934bf06" category="list-text"><block ref="2e5d36490241211379006b7f6934bf06" category="inline-link-macro-rx"></block></block>
  <block id="122aacda8785e42ca8fd7bd6ebce84f8" category="summary">VMware vSphere는 ESXi 하이퍼바이저에서 실행되는 다수의 가상 서버 및 네트워크를 중앙에서 관리하기 위한 가상화 플랫폼입니다.</block>
  <block id="68bc8529d7c57946fe13e6b3399ee287" category="inline-link">VMware vSphere 웹 사이트</block>
  <block id="80888e73d00a224bebfc22e8e4539b6d" category="paragraph">VMware vSphere에 대한 자세한 내용은 를 참조하십시오<block ref="8e822bbeb5824c0a05189bf9ff98da5c" category="inline-link-rx"></block>.</block>
  <block id="cb4d59b9004b7c584811a3d656f78bc5" category="paragraph">VMware vSphere는 다음과 같은 기능을 제공합니다.</block>
  <block id="a542faac65568ba146d392d835d7fb33" category="list-text">* VMware vCenter Server. * VMware vCenter Server는 단일 콘솔에서 모든 호스트와 VM에 대한 통합 관리를 제공하고 클러스터, 호스트 및 VM의 성능 모니터링을 집계합니다.</block>
  <block id="413563ec6c2672beb7df15f465cb4a48" category="list-text">* VMware vSphere vMotion * VMware vCenter를 사용하면 요청 시 중단 없이 클러스터 내의 노드 간에 VM을 핫 마이그레이션할 수 있습니다.</block>
  <block id="e6583703b8777be27f8db85d741711b4" category="list-text">* vSphere High Availability. * 호스트 장애 시 운영 중단을 방지하기 위해 VMware vSphere를 사용하면 호스트를 클러스터링하고 고가용성을 구성할 수 있습니다. 호스트 장애로 인해 중단된 VM은 클러스터의 다른 호스트에서 곧 재부팅되어 서비스가 복구됩니다.</block>
  <block id="46b35ead34118cb2c50327c71e4aa640" category="list-text">* DRS(Distributed Resource Scheduler). * VMware vSphere 클러스터는 호스팅 중인 VM의 리소스 요구 사항을 로드 밸런싱하도록 구성할 수 있습니다. 리소스 경합 상태의 VM은 클러스터의 다른 노드로 핫 마이그레이션할 수 있으므로 충분한 리소스를 사용할 수 있습니다.</block>
  <block id="cfb123c76f1c7a506310e1162d7ae235" category="paragraph"><block ref="cfb123c76f1c7a506310e1162d7ae235" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c6371faa8d72dee8337811921707a4b" category="paragraph">NetApp 기반 Red Hat OpenShift 솔루션은 2개의 데이터 스위치를 사용하여 25Gbps의 기본 데이터 연결을 제공합니다. 또한 스토리지 노드의 대역 내 관리를 위해 1Gbps에서 연결을 제공하는 두 개의 추가 관리 스위치와 IPMI 기능의 대역 외 관리를 사용합니다. OCP는 VMware vSphere에서 클러스터 관리를 위해 VM 논리 네트워크를 사용합니다. 이 섹션에서는 솔루션에 사용되는 각 가상 네트워크 세그먼트의 배열 및 용도에 대해 설명하고 솔루션 구축을 위한 사전 요구 사항을 설명합니다.</block>
  <block id="e75b582a8823d532f6022b43ac209538" category="paragraph">VMware vSphere의 Red Hat OpenShift는 VLAN(Virtual Local Area Network)을 사용하여 서로 다른 목적으로 네트워크 트래픽을 논리적으로 분리하도록 설계되었습니다. 이 구성은 고객의 요구에 맞게 확장하거나 특정 네트워크 서비스에 대한 추가 격리를 제공할 수 있습니다. 다음 표에는 NetApp 솔루션의 유효성을 검사하는 동안 솔루션을 구현하는 데 필요한 VLAN이 나와 있습니다.</block>
  <block id="3c8c5d8387f173924ffeb2bf88084dba" category="cell">물리적 노드 및 IPMI에 대한 관리</block>
  <block id="c61d980d5248923d65a5dfe7f8818011" category="cell">VM 네트워크</block>
  <block id="f33bd5bca507f2b59fc0a43383ade71b" category="cell">가상 게스트 네트워크 액세스</block>
  <block id="cd3718e8610b820344c9a0284fe84f90" category="cell">스토리지 네트워크</block>
  <block id="c846a1f843522d592b784a66368abed3" category="cell">ONTAP NFS용 스토리지 네트워크</block>
  <block id="6cdd60ea0045eb7a6ec44c54d29ed402" category="cell">184</block>
  <block id="5e6094f6f2176409f469ee445fcf3f50" category="cell">ONTAP iSCSI용 스토리지 네트워크</block>
  <block id="eecca5b6365d9607ee5a9d336962c534" category="cell">185</block>
  <block id="45cf0331a91fdc3679a78fdd8f7c60a7" category="cell">ESXi 노드, vCenter Server, ONTAP Select에 대한 관리</block>
  <block id="e8e0dd181e4ee545195120626098bfba" category="cell">3480</block>
  <block id="11967d5f57969ea4713204eace8fbf4e" category="cell">NetApp Element iSCSI용 스토리지 네트워크</block>
  <block id="3fb04953d95a94367bb133f862402bce" category="cell">3481</block>
  <block id="3de18ffc25309bd0755d8543a30ded78" category="cell">마이그레이션 네트워크</block>
  <block id="c87f7de78a1912f53050e58df90e1445" category="cell">가상 게스트 마이그레이션을 위한 네트워크</block>
  <block id="b7fede84c2be02ccb9c77107956560eb" category="cell">3482</block>
  <block id="9335616a8b7dc0e6f94fd0c6aa720efe" category="list-text">대역 내 관리 네트워크 및 VM 네트워크에서 액세스할 수 있는 전체 호스트 이름 확인을 제공하는 DNS 서버가 하나 이상 있어야 합니다.</block>
  <block id="bd690c49b77b8274786240fa94d9d880" category="section-title">최소 3개의 노드로 구성된 ESXi 클러스터에 OpenShift를 배포합니다</block>
  <block id="3500f2194985ef1b586c649fbe519d8d" category="paragraph">이 문서에 설명된 검증된 아키텍처는 2개의 ESXi 하이퍼바이저 노드를 구축하고 VMware vSphere HA 및 VMware vMotion을 활성화하여 내결함성 구성을 보장하여 HA 작업에 적합한 최소 하드웨어 구축을 제공합니다. 이 구성을 사용하면 배포된 VM이 두 하이퍼바이저 간에 마이그레이션되고 하나의 호스트를 사용할 수 없게 될 경우 재부팅됩니다.</block>
  <block id="e79fa01ec6b411cfda4f8baad9f95cb0" category="paragraph">Red Hat OpenShift는 처음에 3개의 마스터 노드와 함께 배포되기 때문에 일부 환경에서는 2노드 구성의 최소 2개의 마스터가 동일한 노드를 차지할 수 있으며, 이로 인해 특정 노드를 사용할 수 없게 될 경우 OpenShift에 장애가 발생할 수 있습니다. 따라서 OpenShift 마스터를 균등하게 배포하여 내결함성을 한층 더 높일 수 있도록 ESXi 하이퍼바이저 노드를 3개 이상 구축해야 하는 것이 Red Hat의 모범 사례입니다.</block>
  <block id="9dc31e1598f94b9476a025632cee3e19" category="section-title">가상 머신 및 호스트 선호도를 구성합니다</block>
  <block id="f5428382aa8b44d7ef6ca71195afc8ca" category="paragraph">VM 및 호스트 친화성을 활성화하여 여러 하이퍼바이저 노드에 OpenShift 마스터를 배포할 수 있습니다.</block>
  <block id="c23c2371397ad3490af42526283948a4" category="paragraph">유사성 또는 반유사성은 VM 및/또는 호스트 세트에 대한 규칙을 정의하는 방법으로, VM이 그룹의 동일한 호스트 또는 호스트에서 함께 실행되는지 아니면 다른 호스트에서 실행되는지를 결정합니다. VM 및/또는 동일한 매개 변수와 조건 집합을 가진 호스트로 구성된 선호도 그룹을 생성하여 VM에 적용됩니다. 선호도 그룹의 VM이 그룹의 동일한 호스트에서 실행되는지, 아니면 다른 호스트에서 개별적으로 실행되는지에 따라 선호도 그룹의 매개 변수는 양의 선호도 또는 음의 선호도를 정의할 수 있습니다.</block>
  <block id="9934283c0bf98610b4be1803b9ad3430" category="inline-link">vSphere 6.7 설명서: DRS 선호도 규칙 사용</block>
  <block id="291f24f63dc31f9f921b09c567fc963f" category="paragraph">선호도 그룹을 구성하려면 을 참조하십시오<block ref="4b14049244eae7b3d11ef8e44785dd4e" category="inline-link-rx"></block>.</block>
  <block id="7b65abec68958867d7dd5f43b3b06e08" category="inline-link">Red Hat OpenShift 사용자 지정과 함께 vSphere에 클러스터 설치</block>
  <block id="6e7315bf45cda77f0a1477ed6f712eb6" category="paragraph">이 경우 즉시 클러스터를 배포하지 않고도 마법사를 실행하고 작업을 수행할 수 있지만 마법사는 나중에 클러스터를 배포할 수 있는 구성 파일을 만듭니다. IPI 기본값을 변경해야 하거나 다중 테넌시와 같은 다른 용도로 환경에 여러 동일한 클러스터를 배포하려는 경우 매우 유용합니다. OpenShift에 대한 사용자 지정 설치 구성을 만드는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="fc4239653f75b84dd3ca03fe8b28dd64" category="inline-link-rx"></block>.</block>
  <block id="4d7f7f28f54da25e8386b6cfbcbda861" category="summary">이 솔루션의 현재 배포는 Google Cloud 팀이 제공하는 도구를 사용하여 두 가지 엄격한 검증 프로세스를 거쳤습니다.</block>
  <block id="9fc7e91d0cfa196bee652e5b3ab8991b" category="doc">솔루션 검증</block>
  <block id="1bee22d71e0dda5649b05ac8074a7994" category="paragraph">이 솔루션의 현재 배포는 Google Cloud 팀이 제공하는 도구를 사용하여 두 가지 엄격한 검증 프로세스를 거쳤습니다. 이러한 검증에는 다음 테스트의 하위 집합이 포함됩니다.</block>
  <block id="9ce4b6121b9169f9a57e370bc063e43a" category="list-text">Anthos 지원 플랫폼에 대한 파트너 검증:</block>
  <block id="b490ae83108f0a60d2d464f37aed5b33" category="list-text">베어 메탈 플랫폼 서비스의 모든 Anthos가 설치 및 실행 중인지 확인합니다.</block>
  <block id="132b0b7921ef1247c2db8a06ebb68fa0" category="list-text">베어 메탈 클러스터의 물리적 Anthos를 4개의 작업자 노드에서 3개로 확장하고 4개로 다시 확장합니다.</block>
  <block id="5d80842c7c4c549fffd35b71989523c6" category="list-text">사용자 지정 네임스페이스를 만들고 삭제합니다.</block>
  <block id="bd4534ff45d2d6e71d15c4133153f039" category="list-text">Nginx 웹 서버 배포를 생성하여 복제 수를 늘려 배포를 확장합니다.</block>
  <block id="afdfab7c351a97a8f8e386c8c07eead0" category="list-text">Nginx 응용 프로그램에 대한 침투를 생성하고 index.html을 말하여 연결을 확인합니다.</block>
  <block id="e093cbb18731dc9a857dff2a5a9c5b0d" category="list-text">모든 테스트 제품군 작업을 성공적으로 정리하고 클러스터를 사전 테스트 상태로 되돌립니다.</block>
  <block id="6c91e0c5fc919c3ee9adc7909c3331b7" category="list-text">Anthos 지원 스토리지에 대한 파트너 검증:</block>
  <block id="5aacb1c1d8ec3130c7bfc91d7678968c" category="list-text">영구 볼륨 클레임을 사용하여 구축을 생성합니다.</block>
  <block id="7c14d31217a85dc93c1505315501ef24" category="list-text">오프라인 볼륨 크기 조정 작업을 확인합니다.</block>
  <block id="b6ab6f9d0bc58a79facf618d65db092c" category="list-text">영구 볼륨이 클러스터 확장 작업을 수행하는지 확인합니다.</block>
  <block id="fa789d11a4863ab2ab7271940566105a" category="paragraph"><block ref="fa789d11a4863ab2ab7271940566105a" category="inline-link-macro-rx"></block></block>
  <block id="fe70522102670f75ed2fff361701d056" category="paragraph">이 참조 문서는 NetApp에서 검증한 바와 같이 여러 데이터 센터 환경에서 IPI(Installer provisioned Infrastructure)를 통해 배포된 Red Hat OpenShift 솔루션의 배포 검증을 제공합니다. 또한 영구 스토리지 관리를 위한 Astra Trident 스토리지 오케스트레이터와 상태 저장 애플리케이션의 관리 및 보호를 위한 NetApp Astra Control Center를 사용하여 NetApp 스토리지 시스템과의 스토리지 통합에 대해 자세히 설명합니다. 마지막으로, 다양한 솔루션 검증 및 실제 사용 사례를 살펴보고 문서화합니다.</block>
  <block id="2c65eb4e4300c763b9d8ffcdc45660fc" category="paragraph">OpenShift 가상화를 설치하려면 다음 단계를 완료하십시오.</block>
  <block id="bb761e1ed8ef4412cddb399e81488f83" category="list-text">클러스터 관리자 권한으로 Red Hat OpenShift 베어 메탈 클러스터에 로그인합니다.</block>
  <block id="3f4b86cf3e8a535371d3937bd126d789" category="list-text">원근 표시 드롭다운에서 관리자 를 선택합니다.</block>
  <block id="bbb49986c10d9b599ce8b72ea09d5261" category="list-text">Operators &gt; OperatorHub로 이동하여 OpenShift Virtualization을 검색합니다.</block>
  <block id="78146e6a44100deebbe276c19e6c437a" category="image-alt">OpenShift Operator Hub를 참조하십시오</block>
  <block id="016a229c1180d24870be44f7391c5678" category="list-text">OpenShift Virtualization 타일을 선택하고 Install을 클릭합니다.</block>
  <block id="fe87c9ebb6d1db5af643c2101dd83c2d" category="image-alt">OpenShift Virtualization Operator Tile</block>
  <block id="d2770f20a312c7d906cf3d8a97d335a2" category="list-text">Install Operator(사용자 설치) 화면에서 모든 기본 매개변수를 그대로 두고 Install(설치) 을 클릭합니다.</block>
  <block id="66b5ae84d6c0a470bb131b7aeb63f734" category="image-alt">OpenShift 가상화 운영자 세부 정보</block>
  <block id="5f27d84a5a158e75ab7ac4543ca7c1be" category="image-alt">OpenShift Virtualization Operator 설치</block>
  <block id="49598c5badb95e31a9894d5dc277f301" category="list-text">운영자가 설치되면 HyperConverged 생성 을 클릭합니다.</block>
  <block id="f63ea68253a91a92e8afb2e42bf0fb36" category="image-alt">OpenShift Virtualization Operator - Hyperconverged를 만듭니다</block>
  <block id="0e4308133099865567bc6a19f0abcb88" category="list-text">Create HyperConverged(HyperConverged 생성) 화면에서 Create(생성) 를 클릭하여 모든 기본 매개 변수를 수락합니다. 이 단계에서는 OpenShift Virtualization 설치를 시작합니다.</block>
  <block id="c57b56755457ec355801b1e17915fc47" category="image-alt">OpenShift Virtualization Operator - 하이퍼컨버지드 세부 정보</block>
  <block id="ee0ffac6ee8f4e224a044d95e68aa30d" category="list-text">모든 Pod가 OpenShift-CNV 네임스페이스에서 실행 상태로 이동하고 OpenShift Virtualization 연산자가 SUCEEDED 상태가 되면 운영자를 사용할 준비가 된 것입니다. 이제 OpenShift 클러스터에서 VM을 생성할 수 있습니다.</block>
  <block id="423e88e20ace3dbca3f9d5bd3b109cef" category="image-alt">OpenShift Virtualization Operator 설치가 완료되었습니다</block>
  <block id="46af5002087f682df1feb9b3339d1f68" category="inline-link-macro">다음: 워크플로우: VM을 생성합니다.</block>
  <block id="066b9e10038ca1d47643166f151f910c" category="paragraph"><block ref="066b9e10038ca1d47643166f151f910c" category="inline-link-macro-rx"></block></block>
  <block id="1d45b25ba986072287aaf72b6cf94130" category="paragraph">NetApp ONTAP에서 지원하는 Red Hat OpenShift 및 Astra Trident는 기본적으로 워크로드 간 격리를 제공하지 않지만 멀티 테넌시를 구성하는 데 사용할 수 있는 다양한 기능을 제공합니다. NetApp ONTAP가 지원하는 Astra Trident가 있는 Red Hat OpenShift 클러스터에서 멀티테넌트 솔루션을 설계하는 방법을 잘 이해하기 위해 일련의 요구 사항이 있는 예제를 고려하고 이 솔루션에 대한 구성을 개략적으로 설명합니다.</block>
  <block id="385df0e95c28430fb792ec836529f371" category="paragraph">한 조직이 Red Hat OpenShift 클러스터에서 두 개의 다른 팀이 진행 중인 두 프로젝트의 일부로 두 개의 워크로드를 실행하는 것으로 가정해 보겠습니다. 이러한 워크로드의 데이터는 NetApp ONTAP NAS 백엔드의 Astra Trident가 동적으로 프로비저닝한 PVC에 있습니다. 조직은 이러한 두 워크로드를 위한 멀티테넌트 솔루션을 설계하고 이러한 프로젝트에 사용되는 리소스를 격리하여 보안 및 성능이 유지되도록 해야 합니다. 이러한 애플리케이션은 주로 해당 애플리케이션을 지원하는 데이터에 초점을 맞춥니다.</block>
  <block id="9c965c0beb472bc9265925ebbc55507e" category="paragraph">다음 그림은 NetApp ONTAP가 지원하는 Astra Trident가 있는 Red Hat OpenShift 클러스터의 멀티 테넌트 솔루션을 보여줍니다.</block>
  <block id="2ed5156911e542a4d3d64a6e160f6446" category="image-alt">NetApp ONTAP에서 지원하는 Astra Trident와 Red Hat OpenShift 클러스터의 멀티 테넌시</block>
  <block id="3c438be737391744e2fed6f73c418638" category="section-title">기술 요구 사항</block>
  <block id="ff94444190436ee7694d15be2dde0f29" category="list-text">NetApp ONTAP 스토리지 클러스터</block>
  <block id="086e6c16e3fe8e13c336612ef636aa02" category="list-text">아스트라 트리덴트</block>
  <block id="0d46ef98dfe52c8d01c0c5ace93d8165" category="section-title">Red Hat OpenShift – 클러스터 리소스</block>
  <block id="72710b926f57dad99b29203c63f4e3fd" category="paragraph">Red Hat OpenShift 클러스터의 관점에서 볼 때 가장 먼저 해야 할 리소스는 프로젝트입니다. OpenShift 프로젝트는 전체 OpenShift 클러스터를 여러 가상 클러스터로 분할하는 클러스터 리소스로 볼 수 있습니다. 따라서 프로젝트 수준에서 격리하면 다중 임차를 구성할 수 있는 기반이 제공됩니다.</block>
  <block id="20e1834bb9396599a6dcf7d743aa1b36" category="paragraph">다음으로, 클러스터에서 RBAC를 구성합니다. 가장 좋은 방법은 모든 개발자가 IDP(Identity Provider)에서 단일 프로젝트 또는 작업 부하를 단일 사용자 그룹으로 구성하도록 하는 것입니다. Red Hat OpenShift는 IDP 통합 및 사용자 그룹 동기화를 지원하므로 IDP의 사용자 및 그룹을 클러스터로 가져올 수 있습니다. 이렇게 하면 클러스터 관리자가 프로젝트 전용 클러스터 리소스의 액세스를 해당 프로젝트에서 작업하는 사용자 그룹 또는 그룹으로 분리하여 모든 클러스터 리소스에 대한 무단 액세스를 제한할 수 있습니다. Red Hat OpenShift와의 IDP 통합에 대한 자세한 내용은 설명서를 참조하십시오<block ref="213cff8958909b80a9514e0c8321d8ef" category="inline-link-rx"></block>.</block>
  <block id="6d4e96186b1f4267def393ec42bf2d9e" category="paragraph">각 프로젝트에 대해 스토리지에서 생성된 볼륨이 별도의 스토리지에 생성된 것처럼 호스트에 나타나도록 하기 위해 Red Hat OpenShift 클러스터의 영구 스토리지 공급자 역할을 하는 공유 스토리지를 격리하는 것이 중요합니다. 이를 위해 프로젝트나 작업 부하가 있는 것처럼 NetApp ONTAP에 SVM(스토리지 가상 시스템)을 최대한 많이 생성하고 각 SVM을 작업 부하에 전용으로 사용합니다.</block>
  <block id="c4ff2177ae2f8ed9c3e5353068cf2195" category="section-title">Red Hat OpenShift – 스토리지 리소스</block>
  <block id="76245f392269db8492c3610e325b1963" category="paragraph">스토리지 클래스는 이름이 같은 리소스가 아니므로 다른 네임스페이스나 프로젝트의 Pod를 통해 한 프로젝트의 스토리지 클래스에 대한 스토리지 클레임이 거부되도록 하려면 어떻게 해야 합니까? 리소스 할당량을 사용하면 됩니다. ResourceQuotas 는 프로젝트당 리소스의 총 사용량을 제어하는 개체입니다. 프로젝트의 개체에서 사용할 수 있는 총 리소스 양뿐만 아니라 수를 제한할 수 있습니다. 리소스 할당량을 사용하면 프로젝트의 거의 모든 리소스를 제한할 수 있으며, 이러한 리소스를 효율적으로 사용하면 리소스 오버 프로비저닝 또는 과소비로 인한 비용 및 운영 중단을 줄일 수 있습니다. 설명서를 참조하십시오<block ref="9b2bb9683c8f6144876bed616f252527" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="5402bb91006fe391aea122e11c3607db" category="paragraph">이 활용 사례에서는 특정 프로젝트의 포드를 해당 프로젝트 전용이 아닌 스토리지 클래스에서 스토리지를 청구하는 것을 제한해야 합니다. 이렇게 하려면 "&lt;storage-class-name&gt;.storageclass.storage.k8s.io/persistentvolumeclaims"를 0으로 설정하여 다른 스토리지 클래스에 대한 영구 볼륨 클레임을 제한해야 합니다. 또한 클러스터 관리자는 프로젝트의 개발자가 리소스 할당량을 수정할 수 있는 액세스 권한이 없어야 합니다.</block>
  <block id="6c7eefdca8e3859011afa00995879a32" category="inline-link-macro">다음: 구성.</block>
  <block id="0c86c0f2c0ad5b82864ef1b20a904132" category="paragraph"><block ref="0c86c0f2c0ad5b82864ef1b20a904132" category="inline-link-macro-rx"></block></block>
  <block id="a38830c0aa781c889eeb5910f47be6ea" category="summary">Astra Control Center를 통해 CI/CD 파이프라인에서 데이터 보호를 활성화합니다</block>
  <block id="dc0365ad4c92bc3f8973ff5616cd6830" category="doc">Astra Control Center를 통한 CI/CD 파이프라인의 데이터 보호</block>
  <block id="5568d55567785f154c987872c1684bfa" category="doc">워크로드 마이그레이션: NetApp의 Red Hat OpenShift</block>
  <block id="9f9077091d74fb2c701c8c8c4a837c16" category="summary">이 솔루션의 초기 검증을 위해 NetApp은 WWT(World Wide Technology)와 협력하여 WWT의 ATC(Advanced Technology Center)에서 환경을 구축했습니다. Anthos는 Google Cloud에서 제공하는 bmctl 도구를 사용하여 베어 메탈 인프라에 배포되었습니다. 다음 섹션에서는 유효성 검사를 위해 사용되는 배포에 대해 자세히 설명합니다.</block>
  <block id="06dc93ff20817f0d5fb8a07f8e43d6cb" category="doc">구축 요약</block>
  <block id="195d9c1693fc10788ad8da5d4d9d2402" category="paragraph">NetApp 솔루션을 사용한 베어 메탈 기반 Anthos는 3개의 Anthos 제어 플레인 노드와 4개의 Anthos 작업자 노드로 구성된 고가용성 하이브리드 클러스터로 구축되었습니다.</block>
  <block id="d0236eb3bd180706e0eaca7d726c66e6" category="paragraph">사용되는 제어 플레인 노드는 Cisco UCS B200M3 블레이드 서버로서 섀시에서 호스팅되며 각 서버에 vNIC(단일 가상 네트워크 인터페이스 카드)가 구성되어 있어 내결함성을 위해 Cisco UCS 플랫폼 레벨에서 A/B 페일오버를 허용합니다. Cisco UCS 섀시는 패브릭 A와 패브릭 B를 따라 트래픽을 분리할 수 있는 서로 다른 경로를 제공하는 Cisco UCS 6248 패브릭 상호 연결 쌍에 업스트림을 연결합니다 WWT의 핵심 네트워크에 다시 연결되는 Cisco Nexus 5548 데이터 센터 스위치 쌍으로 업스트림에 연결된 패브릭 상호 연결망을 통해 연결됩니다.</block>
  <block id="3753f99ef321c354828532bad11422ec" category="paragraph">작업자 노드는 HP ProLiant DL360 노드로서, 각각 Red Hat Enterprise Linux 8.2, CentOS 8.2, Ubuntu 20.04 LTS 또는 Ubuntu 18.04 LTS의 Anthos에 대해 지원되는 Linux 배포판 중 하나를 실행합니다. Red Hat Enterprise Linux 8 및 CentOS 8 노드는 LACP 모드에서 실행되는 NIC 팀으로 구성되어 있으며 내결함성을 위해 2개의 Nexus 9k C93180YC-FX 스위치에 케이블로 연결되어 있었습니다. Ubuntu 서버는 LACP 모드에서 네트워크 연결을 위해 구성되었으며 내결함성을 위해 동일한 쌍의 Nexus 9k 스위치에 케이블로 연결되었습니다.</block>
  <block id="e5b1fecda3d68cda9e216e0e73b26dec" category="paragraph">다음 그림은 랙 데이터 센터 스위치 상단에 대한 솔루션의 물리적 케이블 연결 다이어그램을 보여 줍니다.</block>
  <block id="aa5914d8b6d8a27fd4df86fef0c0395a" category="paragraph"><block ref="aa5914d8b6d8a27fd4df86fef0c0395a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7a105940efa6ed6c71004ff40b8347" category="paragraph">다음 그림은 NetApp 파트너 WWT의 연구실에서 하드웨어에 구축 및 검증된 솔루션을 논리적으로 나타낸 것입니다.</block>
  <block id="ff8f4395cfa334d6d144e3a2426e7b96" category="paragraph"><block ref="ff8f4395cfa334d6d144e3a2426e7b96" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8d3f61f51562ad245b65242dc92c0da" category="inline-link-macro">다음: 솔루션 검증.</block>
  <block id="b1d15269d6e9cabdf17337c73e6a5f07" category="paragraph"><block ref="b1d15269d6e9cabdf17337c73e6a5f07" category="inline-link-macro-rx"></block></block>
  <block id="cb8e8e87ec9c630a0a27910fe29abceb" category="summary">RHV는 RHEL(Red Hat Enterprise Linux)에서 실행되고 KVM 하이퍼바이저를 사용하는 엔터프라이즈 가상 데이터 센터 플랫폼입니다.</block>
  <block id="932e95da8a59703292a426466e703c7a" category="paragraph">Red Hat Virtualization(RHV)은 RHEL(Red Hat Enterprise Linux)에서 실행되고 KVM 하이퍼바이저를 사용하는 엔터프라이즈 가상 데이터 센터 플랫폼입니다.</block>
  <block id="603bc85f6f6f4d9e5095745d9252f1d3" category="inline-link">Red Hat 가상화 웹 사이트</block>
  <block id="8a961382f0c47dc86706f0aa8bb93fb4" category="paragraph">RHV에 대한 자세한 내용은 를 참조하십시오<block ref="ac07861257bcab0c21d310fa00cb324b" category="inline-link-rx"></block>.</block>
  <block id="7adf04762320f012179ffe68fb0aeb9f" category="paragraph">RHV는 다음과 같은 기능을 제공합니다.</block>
  <block id="0178ef6806a57586f6c66dde7e0e86d2" category="list-text">* VM 및 호스트의 중앙 집중식 관리 * RHV Manager는 배포 시 물리적 또는 가상 머신(VM)으로 실행되며 중앙 인터페이스에서 솔루션 관리를 위한 웹 기반 GUI를 제공합니다.</block>
  <block id="c29d3f9be705e3dcf947c6d2464cb090" category="list-text">* 자체 호스팅된 엔진. * RHV를 사용하면 하드웨어 요구 사항을 최소화하기 위해 게스트 VM을 실행하는 동일한 호스트에 RHV Manager(RHV-M)를 VM으로 배포할 수 있습니다.</block>
  <block id="e2545c34b3a35dbcd93423b539eae91a" category="list-text">* 고가용성. * 호스트 장애 시 중단을 방지하기 위해 RHV를 사용하면 VM을 고가용성을 구성할 수 있습니다. 고가용성 VM은 복구 정책을 사용하여 클러스터 레벨에서 제어됩니다.</block>
  <block id="8f91b3a5c6d176cad584bb5f06c53684" category="list-text">* 높은 확장성 * RHV 클러스터 하나에는 최대 200개의 하이퍼바이저 호스트가 있어 대규모 VM의 요구 사항을 지원하여 리소스 탐욕스러운 엔터프라이즈급 워크로드를 호스팅할 수 있습니다.</block>
  <block id="a175fea9b8830c0cdbe1b268cb114738" category="list-text">* 보안 강화. * RHV, 보안 가상화(sVirt) 및 보안 강화 Linux(SELinux) 기술은 호스트 및 VM에 대한 보안 강화 및 보안 강화를 위해 RHV에 사용됩니다. 이러한 기능을 통해 얻을 수 있는 주요 이점은 VM과 관련 리소스의 논리적 격리가 있다는 것입니다.</block>
  <block id="01b0ee840ef208c283c3f4e959aa9427" category="paragraph"><block ref="01b0ee840ef208c283c3f4e959aa9427" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd4c83df745cf56330120fb3ac308da2" category="paragraph">NetApp 기반 Red Hat OpenShift 솔루션은 2개의 데이터 스위치를 사용하여 25Gbps의 기본 데이터 연결을 제공합니다. 또한 스토리지 노드의 대역 내 관리를 위해 1Gbps에서 연결을 제공하는 두 개의 추가 관리 스위치와 IPMI 기능을 위한 대역 외 관리를 사용합니다. OCP는 클러스터 관리를 위해 RHV의 가상 머신 논리 네트워크를 사용합니다. 이 섹션에서는 솔루션에 사용되는 각 가상 네트워크 세그먼트의 배열 및 용도에 대해 설명하고 솔루션 구축을 위한 사전 요구 사항을 설명합니다.</block>
  <block id="2d7e48e226974692ed3f522a2baef6db" category="paragraph">RHV 기반 Red Hat OpenShift는 VLAN(Virtual Local Area Network)을 사용하여 네트워크 트래픽을 논리적으로 서로 다른 목적으로 분리할 수 있도록 설계되었습니다. 이 구성은 고객의 요구에 맞게 확장하거나 특정 네트워크 서비스에 대한 추가 격리를 제공할 수 있습니다. 다음 표에는 NetApp 솔루션의 유효성을 검사하는 동안 솔루션을 구현하는 데 필요한 VLAN이 나와 있습니다.</block>
  <block id="36a1694bce9815b7e38a9dad05ad42e0" category="cell">1172</block>
  <block id="c347686b0750301dfca053b321126bcc" category="cell">RHV-H 노드, RHV-Manager 및 ovirmgmt 네트워크를 위한 관리</block>
  <block id="21c5bba1dd6aed9ab48c2b34c1a0adde" category="cell">3343</block>
  <block id="3083202a936b7d0ef8b680d7ae73fa1a" category="cell">3344</block>
  <block id="38a77aa456fc813af07bb428f2363c8d" category="cell">3345</block>
  <block id="7e4be32047fe5b09a23fd956cd4e82f0" category="section-title">3개 이상의 노드가 포함된 RHV 클러스터에 OpenShift를 배포합니다</block>
  <block id="de4e964e7be880b328384cfedd5873d9" category="paragraph">이 문서에 설명된 검증된 아키텍처는 2개의 RHV-H 하이퍼바이저 노드를 배포하고 두 호스트가 호스팅된 엔진과 구축된 VM을 관리할 수 있는 내결함성 구성을 보장하여 HA 운영에 적합한 최소 하드웨어 구축을 제공합니다.</block>
  <block id="4a3fe6077a529bcbe033bbb7d13027d6" category="paragraph">Red Hat OpenShift는 처음에 3개의 마스터 노드와 함께 배포되기 때문에 2노드 구성에서 최소한 2개의 마스터가 동일한 노드를 차지하게 되므로 특정 노드를 사용할 수 없게 되면 OpenShift의 운영 중단을 초래할 수 있습니다. 따라서 Red Hat 모범 사례는 OpenShift 마스터를 균등하게 배포하고 솔루션에서 추가적인 내결함성을 얻을 수 있도록 솔루션의 일부로 RHV-H 하이퍼바이저 노드를 3개 이상 배포하는 것입니다.</block>
  <block id="b98f17dd49fc6d1c2a9b58922fae2686" category="paragraph">VM/호스트 선호도를 활성화하여 여러 하이퍼바이저 노드에 OpenShift 마스터를 배포할 수 있습니다.</block>
  <block id="df1b58247681ba5f974a572d530dbdf9" category="paragraph">유사성은 VM 및/또는 호스트 세트에 대한 규칙을 정의하는 방법으로, VM이 그룹의 동일한 호스트 또는 호스트에서 함께 실행되는지 아니면 다른 호스트에서 실행되는지를 결정합니다. VM 및/또는 동일한 매개 변수와 조건 집합을 가진 호스트로 구성된 선호도 그룹을 생성하여 VM에 적용됩니다. 선호도 그룹의 VM이 그룹의 동일한 호스트에서 실행되는지, 아니면 다른 호스트에서 개별적으로 실행되는지에 따라 선호도 그룹의 매개 변수는 양의 선호도 또는 음의 선호도를 정의할 수 있습니다.</block>
  <block id="02d7502b2b132a675665088322fde9b0" category="paragraph">매개 변수에 대해 정의된 조건은 강제 적용이나 소프트 적용일 수 있습니다. 강제 적용은 선호도 그룹의 VM이 항상 외부 조건과 상관 없이 긍정 또는 부정적인 선호도를 따르도록 합니다. 소프트 적용은 선호도 그룹의 VM에 대해 더 높은 선호도를 설정하여 가능한 경우 긍정 또는 부정적 선호도를 따르도록 합니다. 이 문서에 설명된 2개 또는 3개의 하이퍼바이저 구성에서 소프트 선호도 설정이 권장됩니다. 대규모 클러스터에서는 하드 친화성이 OpenShift 노드를 올바르게 배포할 수 있습니다.</block>
  <block id="5c00bc5cb1bdae240d18551e77806abd" category="inline-link">Red Hat 6.11. Affinity Group 설명서</block>
  <block id="f38d8cd9caeb9a037c470b7d061392a0" category="paragraph">선호도 그룹을 구성하려면 을 참조하십시오<block ref="eb1587f3cb611d53dba5bde41d49122a" category="inline-link-rx"></block>.</block>
  <block id="2b083bcbbb2d2208e64c13cb183af44f" category="paragraph">IPI를 사용하면 이 문서 앞부분에서 설명한 대화형 마법사를 통해 OpenShift 클러스터를 쉽게 배포할 수 있습니다. 그러나 클러스터 배포의 일부로 변경해야 할 수 있는 몇 가지 기본값이 있을 수 있습니다.</block>
  <block id="1050f3dc9e3ee559789e3b25f2e4f77e" category="inline-link">Red Hat OpenShift Customizations를 사용하여 RHV에 클러스터 설치</block>
  <block id="a5867d73fa54e5b850ff2642c45ade52" category="paragraph">이 경우 클러스터를 즉시 배포하지 않고도 마법사를 실행하고 작업을 수행할 수 있습니다. 대신 나중에 클러스터를 구축할 수 있는 구성 파일이 생성됩니다. IPI 기본값을 변경하거나 멀티 테넌시와 같은 다른 용도로 환경에 여러 개의 동일한 클러스터를 배포하려는 경우 매우 유용합니다. OpenShift에 대한 사용자 지정 설치 구성을 만드는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="15427a9f842d7a49b872cf64115f33bc" category="inline-link-rx"></block>.</block>
  <block id="9d312703c40c2d87b835076063682d59" category="summary">NetApp ONTAP는 직관적인 GUI, 자동화 통합을 지원하는 REST API, AI 정보에 기반한 예측 분석 및 수정 조치, 무중단 하드웨어 업그레이드, 교차 스토리지 가져오기 등의 기능을 갖춘 강력한 스토리지 소프트웨어 툴입니다.</block>
  <block id="48235fec2427a785c4a09d7150fc11fc" category="inline-link">NetApp ONTAP 웹 사이트</block>
  <block id="e65027864c84a42fc0799d878ffa0005" category="paragraph">NetApp ONTAP 스토리지 시스템에 대한 자세한 내용은 를 참조하십시오<block ref="be9464a7a83e639a645a801fff2791d9" category="inline-link-rx"></block>.</block>
  <block id="3716516b242be48f15f8cbce6557a296" category="paragraph">ONTAP는 다음과 같은 기능을 제공합니다.</block>
  <block id="3e23168685787e9deffccb3bdb29d98a" category="list-text">NFS, CIFS, iSCSI, FC, FCoE 및 iSCSI의 동시 데이터 액세스 및 관리를 지원하는 유니파이드 스토리지 시스템 NVMe 프로토콜을 지원합니다.</block>
  <block id="11927aa24f71bc959d85115c8dd8c3a9" category="list-text">다양한 구축 모델에는 All-Flash 기반 온프레미스, 하이브리드, All-HDD 하드웨어 구성, ONTAP Select와 같은 지원되는 하이퍼바이저 기반 VM 기반 스토리지 플랫폼, Cloud Volumes ONTAP와 같은 클라우드 등이 있습니다.</block>
  <block id="65c42edcb28a34e276f92dd9b2172613" category="list-text">자동 데이터 계층화, 인라인 데이터 압축, 중복제거, 컴팩션을 지원하여 ONTAP 시스템의 데이터 스토리지 효율성을 높입니다.</block>
  <block id="f0a8a62c8d7ea4d12a7f1c95b40d3cb3" category="list-text">워크로드 기반, QoS 제어 스토리지</block>
  <block id="1e16ebc829d46d68a51d55ac22293b1e" category="list-text">퍼블릭 클라우드와 원활하게 통합하여 데이터를 계층화 및 보호합니다. ONTAP는 또한 어떤 환경에서든 강력한 데이터 보호 기능을 제공합니다.</block>
  <block id="613db5a747bd15eeccbcbedce5bd8888" category="list-text">* NetApp Snapshot 복사본 * 추가 성능 오버헤드 없이 최소한의 디스크 공간을 사용하여 데이터를 신속하게 시점 백업해 줍니다.</block>
  <block id="8f666d296151faf9c472110831227243" category="list-text">* NetApp SnapMirror. * 스토리지 시스템 간에 데이터의 스냅샷 복사본을 미러링합니다. ONTAP는 다른 물리적 플랫폼과 클라우드 네이티브 서비스에 대한 데이터 미러링을 지원합니다.</block>
  <block id="5685b3f13393b751231ff096f77e6747" category="list-text">NetApp SnapLock. * 지정된 기간 동안 덮어쓰거나 지울 수 없는 특수 볼륨에 데이터를 기록하여 재기록할 수 없는 데이터를 효율적으로 관리</block>
  <block id="dff1063d1e007396b7fb75f266dd48b7" category="list-text">* NetApp SnapVault. * 여러 스토리지 시스템의 데이터를 중앙 스냅샷 복사본으로 백업하여 지정된 모든 시스템에 대한 백업 기능을 제공합니다.</block>
  <block id="779cb4084f09228e9562ca3bedc5555c" category="list-text">NetApp SyncMirror. * 는 동일한 컨트롤러에 물리적으로 연결된 두 개의 서로 다른 플렉스에 데이터를 실시간 RAID 레벨 미러링 기능을 제공합니다.</block>
  <block id="929a0581ca4b2982313e21e51effbc10" category="list-text">* NetApp SnapRestore. * Snapshot 복사본에서 백업된 데이터를 필요에 따라 신속하게 복원합니다.</block>
  <block id="4e3f9a03501932f914205c4ad0e682ea" category="list-text">* NetApp FlexClone. * 은 Snapshot 복사본을 기반으로 NetApp 볼륨의 읽기 가능하고 쓰기 가능한 복사본을 즉각적으로 프로비저닝합니다.</block>
  <block id="96f474208f638efbbd85fac3a46a2ed4" category="paragraph">ONTAP에 대한 자세한 내용은 를 참조하십시오<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="c389369b80a8ce8ead607b4c7088682e" category="admonition">NetApp ONTAP는 사내, 가상화 또는 클라우드에서 사용할 수 있습니다.</block>
  <block id="81bf516f5b38ea41d503a2670a9dc144" category="paragraph"><block ref="81bf516f5b38ea41d503a2670a9dc144" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e80842c9211bc376ee42d583c70ae408" category="section-title">NetApp 플랫폼</block>
  <block id="5a69e0f8303b40f9f4d56038d3d260c9" category="section-title">NetApp AFF/FAS</block>
  <block id="f4fc33973424c12639f93790b1c6f370" category="paragraph">NetApp은 짧은 지연 시간, 통합 데이터 보호, 멀티 프로토콜 지원으로 강력한 AFF(All-Flash) 및 FAS(스케일아웃 하이브리드) 스토리지 플랫폼을 제공합니다.</block>
  <block id="d4c312c600a949fb72436c2d10568a90" category="paragraph">두 시스템 모두 NetApp ONTAP 데이터 관리 소프트웨어를 기반으로 합니다. 이 소프트웨어는 고가용성, 클라우드 통합, 간소화된 스토리지 관리를 위한 업계 최고의 데이터 관리 소프트웨어로 Data Fabric에 필요한 엔터프라이즈급 속도, 효율성 및 보안을 제공합니다.</block>
  <block id="992c24be8f66e4259b38ce763c115251" category="paragraph">NetApp AFF/FAS 플랫폼에 대한 자세한 내용을 보려면 클릭하십시오<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="3a3a5cd068731551120f43f37950768b" category="section-title">ONTAP Select</block>
  <block id="b008e805d13d953ddb5cbb220d8ef9b6" category="paragraph">ONTAP Select는 NetApp ONTAP의 소프트웨어 정의 배포로, 사용자 환경의 하이퍼바이저에 구축할 수 있습니다. VMware vSphere 또는 KVM에 설치할 수 있으며 하드웨어 기반 ONTAP 시스템의 모든 기능과 환경을 제공합니다.</block>
  <block id="3f0bbee5abf3eed060d4147cb0d060b9" category="paragraph">ONTAP Select에 대한 자세한 내용을 보려면 을 클릭합니다<block ref="7c1424ed7be035c303f12b0763e38ece" category="inline-link-rx"></block>.</block>
  <block id="f0f4b6de2040d7dc57e7f4f6baee7ec3" category="paragraph">NetApp Cloud Volumes ONTAP는 클라우드 구축 버전의 NetApp ONTAP로, Amazon AWS, Microsoft Azure, Google Cloud를 비롯한 다양한 퍼블릭 클라우드에 구축할 수 있습니다.</block>
  <block id="c7fa0d52c3955385f084d0e67c59f963" category="paragraph">Cloud Volumes ONTAP에 대한 자세한 내용을 보려면 을 클릭합니다<block ref="75c9b0075008bbe40ac851ad7f6dda6a" category="inline-link-rx"></block>.</block>
  <block id="a5369d9ec76321542413da21642ecc74" category="inline-link-macro">다음으로, NetApp 스토리지 통합 개요를 살펴보겠습니다</block>
  <block id="1a9b0bf11ebe49684776b9ffad6b4022" category="paragraph"><block ref="1a9b0bf11ebe49684776b9ffad6b4022" category="inline-link-macro-rx"></block></block>
  <block id="3fc5f6755312b7edeef9542bd55ef639" category="section-title">기대치를 설정합니다</block>
  <block id="9d7264067197bc9ff368288f98750fd6" category="paragraph">이 기능을 사용하면 여러 클러스터에 대한 규정 준수 정책을 정의하고 클러스터가 규정을 준수하도록 할 수 있습니다. 규칙 위반 또는 위반 사항을 알리거나 수정하기 위해 정책을 구성할 수 있습니다.</block>
  <block id="87f4e127e0ecf99187b35830ca7e78aa" category="list-text">측면 표시줄에서 거버넌스 및 위험 으로 이동합니다.</block>
  <block id="0ecc505d3375f8bb3bd959aaaf7e710a" category="list-text">규정 준수 정책을 생성하려면 정책 생성 을 클릭하고 정책 표준의 세부 정보를 입력한 다음 이 정책을 준수할 클러스터를 선택합니다. 이 정책의 위반 사항을 자동으로 해결하려는 경우 적용 확인란을 선택하고 생성 을 클릭합니다.</block>
  <block id="f6262e5369e2b989638aaa9d4f333d91" category="image-alt">규정 준수 정책을 수립합니다</block>
  <block id="0a1575621f2b12d5216e6d1c95eed2e6" category="list-text">필요한 모든 정책을 구성한 후 고급 클러스터 관리에서 정책 또는 클러스터 위반을 모니터링하고 해결할 수 있습니다.</block>
  <block id="38c080ff2128a92954fb61942ea497c0" category="image-alt">정책 모니터링</block>
  <block id="465d1c9d2d9ea711e43e2e20077e10f9" category="inline-link-macro">다음: 기능 - 관찰 가능성.</block>
  <block id="056789fad8ccaddf0ac3b4ef0a68b61a" category="paragraph"><block ref="056789fad8ccaddf0ac3b4ef0a68b61a" category="inline-link-macro-rx"></block></block>
  <block id="6de80120fa9469d052fc37775d89d5ca" category="doc">WP-7337: 베어 메탈(Bare Metal)의 Anthos</block>
  <block id="8310f10ba877c17b561c1119aa03a750" category="paragraph">이러한 결합을 통해 서버, 스토리지 및 네트워킹의 모든 잠재력을 Google Cloud가 제공하는 지원, 서비스 수준, 월별 청구 및 온디맨드 유연성과 결합하여 실현할 수 있습니다. 자체 하드웨어, 네트워크 및 스토리지를 사용하고 있기 때문에 애플리케이션 규모, 보안 및 네트워크 지연 시간을 직접 제어할 수 있을 뿐 아니라 베어 메탈에서 Anthos와 함께 관리 및 컨테이너화된 애플리케이션의 이점을 누릴 수 있습니다.</block>
  <block id="5cb451e1c66a533348d9c913d8c630e3" category="inline-link-macro">다음: 솔루션 개요</block>
  <block id="7133ec6c94c3cb3dd5d77dce10f8fd70" category="paragraph"><block ref="7133ec6c94c3cb3dd5d77dce10f8fd70" category="inline-link-macro-rx"></block></block>
  <block id="943dbb8750d636d9918af903ac016c0e" category="summary">NetApp은 Trident Storage Orchestrator를 사용하여 Red Hat OpenShift에 구축된 애플리케이션용 스토리지를 프로비저닝할 수 있는 여러 스토리지 플랫폼을 제공합니다.</block>
  <block id="77caa49b32b4fc8ce3276158f57f9229" category="doc">NetApp 스토리지 개요</block>
  <block id="3dbb1adfd571e8b44af1259f287d723f" category="paragraph">NetApp은 Astra Trident Storage Orchestrator를 사용하여 Red Hat OpenShift에 구축된 애플리케이션용 스토리지를 프로비저닝할 수 있는 여러 스토리지 플랫폼을 보유하고 있습니다.</block>
  <block id="0186ffea1bd2c7ff6458a3a619d01ea2" category="paragraph"><block ref="0186ffea1bd2c7ff6458a3a619d01ea2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bc4bb14f0d89a22c593112574d0fb3" category="list-text">AFF 및 FAS 시스템에서 NetApp ONTAP를 실행하고 파일 기반(NFS) 및 블록 기반(iSCSI) 사용 사례에 대한 스토리지를 제공합니다.</block>
  <block id="bf3bfadca5040d5a50a8703c7dbb7ef1" category="list-text">Cloud Volumes ONTAP와 ONTAP Select는 각각 클라우드 및 가상 공간에서도 동일한 이점을 제공합니다.</block>
  <block id="3cc957c67b836ddc993931d8d2253032" category="list-text">NetApp Cloud Volumes Service(AWS/GCP) 및 Azure NetApp Files는 클라우드에서 파일 기반 스토리지를 제공합니다.</block>
  <block id="faad8e024544c328d584c28118fb4102" category="list-text">NetApp Element 스토리지 시스템은 확장성이 뛰어난 환경에서 블록 기반(iSCSI) 사용 사례를 제공합니다.</block>
  <block id="cb050b8fb8c2102a0ab337119eb19f0f" category="admonition">NetApp 포트폴리오의 각 스토리지 시스템은 온프레미스 사이트와 클라우드 간에 데이터 관리와 이동을 모두 쉽게 하여 데이터가 애플리케이션의 위치에 있도록 보장합니다.</block>
  <block id="85a240011ba49404bf70606e37c41c96" category="paragraph">다음 페이지는 NetApp OpenShift에서 검증된 NetApp 스토리지 시스템에 대한 추가 정보를 제공합니다.</block>
  <block id="3a374bfcdd912b5071f863e2b9f0eefa" category="list-text"><block ref="3a374bfcdd912b5071f863e2b9f0eefa" category="inline-link-macro-rx"></block></block>
  <block id="70b44fe3d3567f3f2a5ccd67ff8ac852" category="list-text"><block ref="70b44fe3d3567f3f2a5ccd67ff8ac852" category="inline-link-macro-rx"></block></block>
  <block id="93e14ba37d069eff22130cf694c451c1" category="summary">NetApp AFF는 짧은 지연 시간, 통합 데이터 보호, 멀티 프로토콜 지원 및 무중단 운영을 제공하는 강력한 All-Flash 스토리지 플랫폼입니다. NetApp ONTAP 데이터 관리 소프트웨어를 기반으로 하는 NetApp AFF는 유지보수, 업그레이드, 스토리지 시스템의 전체 교체에 이르기까지 무중단 운영을 보장합니다.</block>
  <block id="9ecccbf5710194af15cca545b567957a" category="section-title">NetApp AFF/FAS 기반 NetApp ONTAP</block>
  <block id="13a74472f5a5018f40319d30a728d03e" category="paragraph">NetApp ONTAP는 직관적인 GUI, 자동화 통합을 지원하는 REST API, AI 정보에 기반한 예측 분석 및 수정 조치, 무중단 하드웨어 업그레이드, 교차 스토리지 가져오기 등의 기능을 갖춘 강력한 스토리지 소프트웨어 툴입니다.</block>
  <block id="fce4095b40c80c8632028b9837563736" category="list-text">* NetApp FlexClone. * 은 Snapshot 복사본을 기반으로 NetApp 볼륨의 읽기 가능하고 쓰기 가능한 복사본을 즉각적으로 프로비저닝합니다. ONTAP에 대한 자세한 내용은 를 참조하십시오<block ref="eb1214e3900207403ada8715d3d4c764" category="inline-link-rx"></block>.</block>
  <block id="75714c8168a0c2a2594249ece5acf44c" category="paragraph"><block ref="75714c8168a0c2a2594249ece5acf44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dad787ba7494eee7d6dbd3cef7e5900e" category="paragraph">영구 볼륨(PVS)은 Kubernetes 환경에 정의된 스토리지 클래스를 기반으로 프로비저닝됩니다. 스토리지 관리자가 생성한 스토리지 백엔드(프로젝트 요구에 따라 사용자 지정 가능)와 스토리지 시스템 모델을 사용하여 압축, 특정 디스크 유형 또는 성능을 보장하는 QoS 수준과 같은 다양한 고급 스토리지 기능을 사용할 수 있습니다.</block>
  <block id="3068002de1b5d66a6a163ddc9883ad94" category="paragraph">Trident는 NetApp 포트폴리오에서 각 시스템 및 서비스에서 스토리지를 조정합니다.</block>
  <block id="6d906f4c160e6416d4f0c02a0fb9696c" category="paragraph"><block ref="6d906f4c160e6416d4f0c02a0fb9696c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="885a32398324f13cbf847894ab05bb41" category="paragraph">Google Cloud의 Anthos는 조직이 최신 하이브리드 클라우드 인프라를 구축 및 관리하는 동시에 애플리케이션 개발에 중점을 둔 민첩한 워크플로우를 채택할 수 있는 클라우드 기반 Kubernetes 데이터 센터 솔루션입니다. 베어 메탈 기반의 Anthos는 Anthos의 기능을 확장하여 하이퍼바이저 계층 없이 물리적 서버에서 직접 온프레미스(on-premise)을 실행하고 Google Cloud의 Anthos GKE 클러스터와 상호 운용합니다.</block>
  <block id="581adec598400d9d02114736724b28d3" category="paragraph">컨테이너, 서비스 메시 및 기타 혁신적인 기술을 채택하는 조직은 로컬 및 클라우드 기반 환경에서 일관된 애플리케이션 개발 사이클과 운영 지원 워크로드를 경험할 수 있습니다.</block>
  <block id="ea2625d89edeb5ba9cb41ca58df54e93" category="paragraph">Anthos는 다음과 같은 기능을 제공합니다.</block>
  <block id="c10e0a21a04a29dfca9609b3ec4bab76" category="list-text">* Anthos 구성 관리. * 하이브리드 Kubernetes 배포의 정책 및 보안을 자동화합니다.</block>
  <block id="e8c4d5cbaf3932ffa3fa7a097bff923e" category="list-text">* Anthos Service Mesh. * Istio 기반 서비스 메쉬로 애플리케이션 가시성, 보안 및 제어를 개선합니다.</block>
  <block id="b7fd1509ff5472f08e8216f563c9c8af" category="list-text">* Kubernetes 애플리케이션용 Google Cloud Marketplace * 손쉬운 구축을 위해 선별된 컨테이너 애플리케이션의 카탈로그</block>
  <block id="5204c290ae3b1ebca311a7ca7d447791" category="list-text">* Migrate for Anthos. * 물리적 서비스 및 VM을 사내에서 클라우드로 자동 마이그레이션. 그림 3은 Anthos 솔루션과 사내 데이터 센터 내의 배포가 클라우드의 인프라와 상호 연결하는 방법을 보여 줍니다.</block>
  <block id="608fd0ec5cdb56ad3d3e6d9595ec6f19" category="inline-link">Anthos 웹 사이트</block>
  <block id="1192e096cd21e1aa81d806fe9e5d2213" category="paragraph">Anthos에 대한 자세한 내용은 를 참조하십시오<block ref="717e02fd176ae4981315950f42bdf0a6" category="inline-link-rx"></block>.</block>
  <block id="70f64e61deea67473fb9951b8f5888b3" category="paragraph">다음 그림은 Google Cloud의 Anthos 아키텍처를 보여줍니다.</block>
  <block id="99d1b69697dd97e963c0a8145277719d" category="paragraph"><block ref="99d1b69697dd97e963c0a8145277719d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="761fffea4910d62111da90337e75abb5" category="paragraph">Anthos on Bare Metal은 고객의 사설 데이터 센터에 배포되는 GKE의 확장입니다. 조직은 사내 Anthos 클러스터의 Google Cloud에서 컨테이너에서 실행되도록 설계된 동일한 애플리케이션을 배포할 수 있습니다. 베어 메탈(Bare Metal)의 Anthos는 사용자가 선택한 기본 Linux 운영 체제를 사용하여 물리적 서버에서 직접 실행되며 데이터 센터의 코어 또는 에지에서 실행할 수 있는 기능을 갖춘 완전한 하이브리드 클라우드 환경을 고객에게 제공합니다.</block>
  <block id="9eb2eb227133ada575ae959b570e545c" category="paragraph">베어 메탈(Bare Metal)의 Anthos는 다음과 같은 이점을 제공합니다.</block>
  <block id="d966dba0352f5bc4bd7cec115bb0f6f4" category="list-text">*하드웨어에 구애 받지 않습니다.* 고객은 기존 데이터 센터에서 최적화된 하드웨어 플랫폼을 선택한 Anthos를 실행할 수 있습니다.</block>
  <block id="69dd75c781331ee9a4c6b2b30d065262" category="list-text">* 비용 절감. * Google Cloud 환경에서 리소스를 프로비저닝하지 않고 애플리케이션 배포에 자체 물리적 리소스를 사용하여 상당한 비용 절감을 실현할 수 있습니다.</block>
  <block id="22c97b10f741190427f7bf14aaa217c3" category="list-text">* 개발 후 게시 * 응용 프로그램이 개발 중인 동안 온프레미스 배포를 사용할 수 있습니다. 이를 통해 로컬 데이터 센터의 개인 정보 보호 환경에서 응용 프로그램을 테스트한 후 클라우드에서 공개적으로 사용할 수 있습니다.</block>
  <block id="0f9f68e8f2e2599804f40d8fc0861b6d" category="list-text">* 더 나은 성능. * 짧은 지연 시간과 최고 수준의 성능을 필요로 하는 집약적인 애플리케이션을 하드웨어에 더 가깝게 실행할 수 있습니다.</block>
  <block id="844236b21d302f8c93eda00636abfff8" category="list-text">* 보안 요구 사항 * 보안 문제가 발생하거나 퍼블릭 클라우드에 저장할 수 없는 민감한 데이터 세트가 있는 고객은 자체 데이터 센터의 보안으로부터 애플리케이션을 실행하여 조직의 요구 사항을 충족할 수 있습니다.</block>
  <block id="895cc29ffb809aaf615d5db487a23c7c" category="list-text">* 관리 및 운영. * 베어 메탈 기반 Anthos는 내장 네트워킹, 수명 주기 관리, 진단, 상태 점검, 로깅, 모니터링 기능을 제공합니다.</block>
  <block id="04b942b754be5e16fc9d5b114dd70bb7" category="inline-link-macro">다음은 솔루션 요구 사항입니다.</block>
  <block id="dea54f5c884510a9da9977e2655c0a5a" category="paragraph"><block ref="dea54f5c884510a9da9977e2655c0a5a" category="inline-link-macro-rx"></block></block>
  <block id="a003986254b5a6c136733113505348da" category="doc">F5 BIG-IP 로드 밸런서 설치</block>
  <block id="048600e045fd4c5afe58ec9d65aa4b19" category="paragraph">F5 BIG-IP는 광범위한 고급 프로덕션 등급 트래픽 관리 및 L4-L7 로드 밸런싱, SSL/TLS 오프로드, DNS, 방화벽 등의 보안 서비스를 제공하는 ADC(Application Delivery Controller)입니다. 이러한 서비스는 애플리케이션의 가용성, 보안 및 성능을 크게 향상시킵니다.</block>
  <block id="5c47e8322efb7f77c0aa515fec29477e" category="paragraph">F5 BIG-IP는 전용 하드웨어, 클라우드 또는 온프레미스 가상 어플라이언스로 다양한 방식으로 구축 및 사용할 수 있습니다. 요구 사항에 따라 F5 BIG-IP를 탐색 및 배포하려면 여기 설명서를 참조하십시오.</block>
  <block id="16a275a8b38f9c5211732c331edb7135" category="paragraph">F5 BIG-IP 서비스와 Red Hat OpenShift의 효율적인 통합을 위해 F5는 BIG-IP Container Ingress Service(CIS)를 제공합니다. CI는 특정 CRD(Custom Resource Definitions)에 대한 OpenShift API를 감시하고 F5 BIG-IP 시스템 구성을 관리하는 컨트롤러 포드로 설치됩니다. F5 BIG-IP CIS는 OpenShift에서 서비스 유형 로드 밸런서 및 경로를 제어하도록 구성할 수 있습니다.</block>
  <block id="e3ce824a7aff01576faaac58df9e0b18" category="paragraph">또한 로드 밸런서를 서비스하기 위한 자동 IP 주소 할당의 경우 F5 IPAM 컨트롤러를 사용할 수 있습니다. F5 IPAM 컨트롤러는 사전 구성된 풀에서 IP 주소를 할당하는 ipamLabel 주석이 있는 loadbalancer 서비스용 OpenShift API를 감시하는 컨트롤러 포드로 설치됩니다.</block>
  <block id="3b08b142099d42d5280d7b493288bf63" category="paragraph">이 페이지에는 F5 BIG-IP CIS 및 IPAM 컨트롤러에 대한 설치 및 구성 지침이 나와 있습니다. 사전 요구 사항으로 F5 BIG-IP 시스템을 배포하고 라이센스를 받아야 합니다. 또한 빅-IP VE 기본 라이센스와 함께 기본적으로 포함되는 SDN 서비스에 대한 라이센스가 필요합니다.</block>
  <block id="5fb7b483d0c9fa099945579d826691b8" category="admonition">F5 BIG-IP는 독립 실행형 또는 클러스터 모드로 구축할 수 있습니다. 이러한 검증을 위해 F5 BIG-IP는 독립 실행형 모드로 구축되었지만, 생산 목적상 단일 장애 지점을 방지하기 위해 대규모 IP 클러스터를 사용하는 것이 좋습니다.</block>
  <block id="0d3e8be481c0c23fd0a68da9a9340ef7" category="admonition">F5 BIG-IP 시스템은 전용 하드웨어, 클라우드 또는 12.x 이상의 버전이 있는 가상 어플라이언스로 구축할 수 있으며 F5 CIS와 통합할 수 있습니다. 이 문서의 목적에 따라 F5 BIG-IP 시스템은 예를 들어 BIG-IP VE 버전을 사용하는 가상 어플라이언스로 검증되었습니다.</block>
  <block id="39bc153685f2a0c6d56db4227295a3b0" category="section-title">검증된 릴리즈</block>
  <block id="00d0a06cc7c922b3bc62b22524723ff8" category="cell">F5 BIG-IP VE 버전</block>
  <block id="5bd03f916d1e7b0410d0d3b2d12c6366" category="cell">16.1.0</block>
  <block id="c6f7874f49f685ffdf1b5a8aad8875c4" category="cell">F5 컨테이너 침투 서비스</block>
  <block id="21f47a5b35d016c2f0f8f57704079407" category="cell">2.5.1</block>
  <block id="9635118f932e26e24f0ca315d3843379" category="cell">F5 IPAM 컨트롤러</block>
  <block id="5256eb2d6e3cf80e003a290e63843800" category="cell">0.1.4</block>
  <block id="088afeececf092d5a406e0f5022a9638" category="cell">F5 AS3</block>
  <block id="425b0ca2d1d9d5c75555116fcd1614bf" category="cell">3.30.0</block>
  <block id="7cd8fb6e31cc946c078d2740c76a9899" category="section-title">설치</block>
  <block id="b9a4064fa117596b59fb18df84df74df" category="inline-link">F5 AS3 GitHub 리포지토리</block>
  <block id="6463cf716c052865ec9f4716ff0b5d3f" category="list-text">필수 명령 대신 BIG-IP 시스템이 JSON의 구성을 수락할 수 있도록 F5 Application Services 3 확장을 설치합니다. 로 이동합니다<block ref="0d4e47593b830323684cdec40cb60c71" category="inline-link-rx"></block>최신 RPM 파일을 다운로드합니다.</block>
  <block id="4c0802ebd79a8c6e5ea4aed829f023c9" category="list-text">F5 BIG-IP 시스템에 로그인하고 iApps &gt; 패키지 관리 LX 로 이동한 다음 가져오기 를 클릭합니다.</block>
  <block id="3536ed517a711f49cfe64071db031cf5" category="list-text">파일 선택 을 클릭하고 다운로드한 AS3 RPM 파일을 선택한 다음 확인 을 클릭하고 업로드 를 클릭합니다.</block>
  <block id="2a90f793207a5a0c028d8ccc45e943fd" category="inline-image-macro">iApps 업로드</block>
  <block id="7a3eaac0605c201c339e116a475c0bf6" category="paragraph"><block ref="7a3eaac0605c201c339e116a475c0bf6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="caedd771b59d267eda8f88d329e8784f" category="list-text">AS3 확장 프로그램이 성공적으로 설치되었는지 확인합니다.</block>
  <block id="c434efeb83b6dc500ea7893f1ad4236b" category="inline-image-macro">AS3 설치 검증</block>
  <block id="eb52ccb2be126d28d17e4383ae6ea6cf" category="paragraph"><block ref="eb52ccb2be126d28d17e4383ae6ea6cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97e9e05bfde432cfa7291b1e55a52ba7" category="list-text">그런 다음 OpenShift와 BIG-IP 시스템 간의 통신에 필요한 리소스를 구성합니다. 먼저 OpenShift SDN용 BIG-IP 시스템에서 VXLAN 터널 인터페이스를 생성하여 OpenShift와 BIG-IP 서버 간에 터널을 생성합니다. 네트워크 &gt; 터널 &gt; 프로필 로 이동하고 생성 을 클릭한 다음 부모 프로필을 VXLAN 으로 설정하고 플러딩 유형 을 멀티캐스트 로 설정합니다. 프로파일 이름을 입력하고 마침 을 클릭합니다.</block>
  <block id="faaca798da0468a250bf3c3bffc26681" category="inline-image-macro">VXLAN 프로필을 생성합니다</block>
  <block id="bddf6bed69a1a2234f15cefc27853c50" category="paragraph"><block ref="bddf6bed69a1a2234f15cefc27853c50" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45ae0c96657fdc5a20e83839c2386c1e" category="list-text">네트워크 &gt; 터널 &gt; 터널 목록 으로 이동하고 생성 을 클릭한 다음 터널의 이름과 로컬 IP 주소를 입력합니다. 이전 단계에서 만든 터널 프로필을 선택하고 마침 을 클릭합니다.</block>
  <block id="1497a4f92d416d6c80392ec3467ff140" category="inline-image-macro">VXLAN 터널을 생성합니다</block>
  <block id="53ce9cdf8cf7f6cb09991e817df94959" category="paragraph"><block ref="53ce9cdf8cf7f6cb09991e817df94959" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc5e5bc480b39177b8cb8c9c3a2266ae" category="list-text">클러스터 관리자 권한으로 Red Hat OpenShift 클러스터에 로그인합니다.</block>
  <block id="986e63a308b4bebd3f531e38fa5a06c7" category="list-text">OpenShift에서 F5 BIG-IP 서버용 hostsubnet을 생성합니다. 그러면 서브넷이 OpenShift 클러스터에서 F5 BIG-IP 서버로 확장됩니다. 호스트 서브넷 YAML 정의를 다운로드합니다.</block>
  <block id="fd4475e12938f5f51ba3f312b42cdd39" category="list-text">호스트 서브넷 파일을 편집하고 OpenShift SDN용 BIG-IP VTEP(VXLAN 터널) IP를 추가합니다.</block>
  <block id="2e6d8a8db3c4d4a2227ffa0571be2a86" category="admonition">사용자 환경에 맞게 호스트 팁 및 기타 세부 정보를 변경합니다.</block>
  <block id="7f9916ee1bc520d892dfbbb1e06e2732" category="list-text">HostSubnet 리소스를 생성합니다.</block>
  <block id="7a46b2d02d466dda0cc67b215cb80bff" category="list-text">F5 BIG-IP 서버에 대해 생성된 호스트 서브넷의 클러스터 IP 서브넷 범위를 가져옵니다.</block>
  <block id="4f6c1fea3654c07f1606c0c76509d0b0" category="list-text">F5 BIG-IP 서버에 해당하는 OpenShift의 호스트 서브넷 범위에서 IP를 사용하여 OpenShift VXLAN에서 셀프 IP를 생성합니다. F5 BIG-IP 시스템에 로그인하고 네트워크 &gt; Self IP 로 이동한 다음 생성 을 클릭합니다. F5 BIG-IP 호스트 서브넷용으로 생성된 클러스터 IP 서브넷의 IP를 입력하고 VXLAN 터널을 선택한 다음 다른 세부 정보를 입력합니다. 그런 다음 마침 을 클릭합니다.</block>
  <block id="5c241806c0dd5ebb7030904151cb78ef" category="inline-image-macro">VXLAN에 대한 셀프 IP를 생성합니다</block>
  <block id="ffad9e123d8b7013e7d4553570644879" category="paragraph"><block ref="ffad9e123d8b7013e7d4553570644879" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4d094b7d82871afb601d2f30d416ba8d" category="list-text">CIS에서 구성 및 사용할 F5 BIG-IP 시스템에 파티션을 생성합니다. 시스템 &gt; 사용자 &gt; 파티션 목록 으로 이동하고 생성 을 클릭한 다음 세부 정보를 입력합니다. 그런 다음 마침 을 클릭합니다.</block>
  <block id="4d81871723233ec21ed69ab80e638779" category="inline-image-macro">BIG-IP 파티션을 생성합니다</block>
  <block id="b83428617c6ed29213f89e68f142bd18" category="paragraph"><block ref="b83428617c6ed29213f89e68f142bd18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37397397fa66431e2fa681b97126c399" category="admonition">F5는 CIS에서 관리하는 파티션에서 수동 구성을 수행하지 않을 것을 권장합니다.</block>
  <block id="81e4a49e9dbe0b55256fe5abf1b94fa4" category="list-text">OperatorHub의 연산자를 사용하여 F5 BIG-IP CIS를 설치합니다. 클러스터 관리자 권한으로 Red Hat OpenShift 클러스터에 로그인하고 F5 BIG-IP 시스템 로그인 자격 증명을 사용하여 암호를 생성합니다. 이는 운영자의 필수 조건입니다.</block>
  <block id="5de4ac005898cabf55523098c40c549b" category="list-text">F5 CIS CRD를 설치합니다.</block>
  <block id="0eddace1b16ed738fe1be181481c71b6" category="list-text">Operators &gt; OperatorHub 로 이동하고 키워드 F5 를 검색한 다음 F5 Container Ingress Service 타일을 클릭합니다.</block>
  <block id="07543409cb05595e273df71050b9a9c0" category="inline-image-macro">OperatorHub의 F5 CIS</block>
  <block id="334a7bbf4711d93b48b93c2b81d84a71" category="paragraph"><block ref="334a7bbf4711d93b48b93c2b81d84a71" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c25b2a3d320d6d02584fde4190d05d91" category="list-text">운영자 정보를 읽고 설치를 클릭하십시오.</block>
  <block id="60d3353ed1910ad5c7bd352d0c1bea85" category="inline-image-macro">OperatorHub의 F5 CIS 정보 타일</block>
  <block id="1aa79507d413f19135716c8006afa423" category="paragraph"><block ref="1aa79507d413f19135716c8006afa423" category="inline-image-macro-rx" type="image"></block></block>
  <block id="637a1bc658defc200d903b27828aa8fb" category="list-text">Install operator(설치 작업자) 화면에서 모든 기본 매개변수를 그대로 두고 Install(설치) 을 클릭합니다.</block>
  <block id="ccf254d7c8b666c9c127ec12fe14804b" category="inline-image-macro">F5 CIS 연산자를 설치합니다</block>
  <block id="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="paragraph"><block ref="56e9cc6f2f7ece6c23fa6faa7f320d5d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="636d8318702bc67a1613ceadf7ce9d00" category="list-text">운전자를 설치하는 데 시간이 걸립니다.</block>
  <block id="dffa3077bcff43536afd75bd61b11c0c" category="inline-image-macro">F5 CIS 작동자 설치 진행</block>
  <block id="b1be0ed9469d2ced1f6283b49735f5c1" category="paragraph"><block ref="b1be0ed9469d2ced1f6283b49735f5c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="197a0a4cc4a45ec9a62fe2b7335d8dfc" category="list-text">운용자 설치 후 Installation Successful 메시지가 출력된다.</block>
  <block id="5bf83e99bfa132430d0b690181334933" category="list-text">Operators &gt; Installed Operators 로 이동하고 F5 Container Ingress Service 를 클릭한 다음 F5BigIpCtlr 타일에서 Create instance 를 클릭합니다.</block>
  <block id="a5f584f06c59c2cf4a4a4e8b42d495a2" category="inline-image-macro">F5BigIpCtlr을 생성합니다</block>
  <block id="a2574a02e64888de32a5a277ed05f668" category="paragraph"><block ref="a2574a02e64888de32a5a277ed05f668" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5ce9a4ef68c16a3ab5d0dd555305872" category="list-text">YAML View(YAML 보기) 를 클릭하고 필요한 매개변수를 업데이트한 후 다음 내용을 붙여 넣습니다.</block>
  <block id="2e2beb899f89156ed06287fe6f78e6cf" category="admonition">콘텐츠를 복사하기 전에 설정 값을 반영하도록 아래의 매개 변수 'bigip_partition', 'openshift_sdn_name', 'bigip_url' 및 'bigip_login_secret'을 업데이트합니다.</block>
  <block id="50a17348dc3f981a95001edcc80a428f" category="list-text">이 콘텐츠를 붙여 넣은 후 만들기 를 클릭합니다. 그러면 kubbe-system 네임스페이스에 CIS 포드가 설치됩니다.</block>
  <block id="72003ce6faa67d172e943ddd74fab63b" category="inline-image-macro">F5 CIS Pod를 확인합니다</block>
  <block id="ef76b6b9f85ff0ec00e48f565e13eff9" category="paragraph"><block ref="ef76b6b9f85ff0ec00e48f565e13eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc8632c05e82ccafb395157ccae4f5c3" category="admonition">기본적으로 Red Hat OpenShift는 L7 로드 밸런싱을 위해 경로를 통해 서비스를 노출하는 방법을 제공합니다. 내장된 OpenShift 라우터는 이러한 경로의 트래픽을 광고 및 처리하는 역할을 합니다. 그러나 F5 CIS를 구성하여 외부 F5 BIG-IP 시스템을 통한 라우트를 지원할 수도 있습니다. 이 시스템은 보조 라우터로 실행하거나 자체 호스팅된 OpenShift 라우터에 대한 대체 라우터로 실행할 수 있습니다. CI는 OpenShift 라우트의 라우터 역할을 하는 BIG-IP 시스템에 가상 서버를 생성하고 BIG-IP는 광고 및 트래픽 라우팅을 처리합니다. 이 기능을 활성화하는 매개변수에 대한 자세한 내용은 여기 에서 설명서를 참조하십시오. 이러한 매개 변수는 APPS/v1 API의 OpenShift 배포 리소스에 대해 정의됩니다. 따라서 F5BigIpCtlr 리소스 cis.f5.com/v1 API와 함께 사용할 경우 매개변수 이름에 대한 하이픈(-)을 밑줄(_)으로 바꿉니다.</block>
  <block id="a6e55fc1fe932b26a294a0f2880478aa" category="list-text">CIS 자원 생성에 전달되는 인자는 IPAM:TRUE, CUSTOM_RESOURCE_MODE:TRUE입니다. 이러한 매개변수는 IPAM 컨트롤러와 CIS 통합을 활성화하는 데 필요합니다. F5 IPAM 리소스를 생성하여 CIS가 IPAM 통합을 활성화했는지 확인합니다.</block>
  <block id="84ac0b78989fa6595723d5541b8ec470" category="list-text">F5 IPAM 컨트롤러에 필요한 서비스 계정, 역할 및 rolebinding을 만듭니다. YAML 파일을 생성하고 다음 내용을 붙여 넣습니다.</block>
  <block id="670c1074ae74616731a63f6b9462b94e" category="list-text">리소스를 생성합니다.</block>
  <block id="b7802bea6dc04d06b63232b6301621bb" category="list-text">YAML 파일을 생성하고 아래에 제공된 F5 IPAM 배포 정의를 붙여 넣습니다.</block>
  <block id="6a1491ddca525bea3293eca6ea8019d0" category="admonition">아래 SPEC.template.spec.containers[0].args의 IP 범위 매개 변수를 업데이트하여 설정에 해당하는 ipamLabels 및 IP 주소 범위를 반영합니다.</block>
  <block id="642252b62fe47e95caa77e3b06a7dbaf" category="admonition">IPAM 컨트롤러가 정의된 범위에서 IP 주소를 검색하고 할당하기 위해서는 ipamlabels ["range1" 및 "range2"(아래 예의 경우)에 부하 분산 장치 유형의 서비스에 대한 주석을 달아야 합니다.</block>
  <block id="8f253132259909c28624117b3476a672" category="list-text">F5 IPAM 컨트롤러 배포를 생성합니다.</block>
  <block id="43946dccec13f46420eb559911e4c526" category="list-text">F5 IPAM 컨트롤러 포드가 실행 중인지 확인합니다.</block>
  <block id="1362b3e7985b4f24d6c2ef4438ee1f0e" category="list-text">F5 IPAM 스키마를 만듭니다.</block>
  <block id="52b8ffce119fe77b28034f2fdd35eb5f" category="section-title">검증</block>
  <block id="32172ccfad6e7060b8f5e091e296f09c" category="list-text">loadbalancer 형식의 서비스를 생성합니다</block>
  <block id="0847be44e618094bc81c848c7d131399" category="list-text">IPAM Controller가 외부 IP를 할당하는지 확인한다.</block>
  <block id="0e51a0606ba7833099aa57bd61c62ba6" category="list-text">배포를 생성하고 생성된 로드 밸런서 서비스를 사용합니다.</block>
  <block id="5f905cb56a4d1b364cab7fc57f4de4e5" category="list-text">Pod가 실행 중인지 확인합니다.</block>
  <block id="51b4d723f0434284233dab97982b185d" category="list-text">OpenShift에서 loadbalancer 유형의 서비스를 위해 BIG-IP 시스템에 해당 가상 서버가 생성되었는지 확인한다. Local Traffic &gt; Virtual Servers &gt; Virtual Server List로 이동합니다.</block>
  <block id="91193cea3335c4666b7dc31ca767030c" category="inline-image-macro">해당 서비스 유형 로드 밸런싱 장치에 대한 BIG-IP 가상 서버 생성을 확인합니다</block>
  <block id="879dfaa1de924ed5e9ccb98da9ac95cd" category="paragraph"><block ref="879dfaa1de924ed5e9ccb98da9ac95cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad8905a47eb465223ebe7acf569732b1" category="doc">구성: 클러스터 관리 작업</block>
  <block id="552eab1d1ea09d0d1733b97dee6609a1" category="paragraph">Red Hat OpenShift cluster-admin은 다음과 같은 작업을 수행합니다.</block>
  <block id="8a4ffd494b5e8af3ac1be2cd9ab254fb" category="list-text">Red Hat OpenShift 클러스터에 cluster-admin으로 로그인합니다.</block>
  <block id="7ccd4d72e4addf5c27c53bafaeb3fdbd" category="list-text">서로 다른 프로젝트에 해당하는 두 개의 프로젝트를 작성합니다.</block>
  <block id="6c98bfb16f2e9bbebd943c1f8592306d" category="list-text">PROJECT-1의 개발자 역할을 만듭니다.</block>
  <block id="14bd8c5f1032dd20f94d4434365c6530" category="admonition">이 섹션에 제공된 역할 정의는 예일 뿐입니다. 개발자 역할은 최종 사용자 요구 사항에 따라 정의되어야 합니다.</block>
  <block id="3c73122271c9219b54ca745b732adc28" category="list-text">마찬가지로 project-2에 대한 개발자 역할을 만듭니다.</block>
  <block id="7428df2e0e503f4cabb43a4667bc1983" category="list-text">모든 OpenShift 및 NetApp 스토리지 리소스는 일반적으로 스토리지 관리자가 관리합니다. 스토리지 관리자를 위한 액세스는 Trident가 설치될 때 생성되는 덴트 운영자 역할에 의해 제어됩니다. 또한 스토리지 관리자는 리소스 할당량에 대한 액세스 권한이 있어야 스토리지 소비 방식을 제어할 수 있습니다.</block>
  <block id="cf17c458ea3abaad557d7cfc69886dbe" category="list-text">클러스터의 모든 프로젝트에서 리소스 할당량을 관리하는 역할을 생성하여 스토리지 관리자에게 연결합니다.</block>
  <block id="db99ab183aa8f56c951cf20e25e7465c" category="list-text">클러스터가 조직의 ID 공급자와 통합되었으며 사용자 그룹이 클러스터 그룹과 동기화되었는지 확인합니다. 다음 예제에서는 ID 공급자가 클러스터와 통합되고 사용자 그룹과 동기화되었음을 보여 줍니다.</block>
  <block id="36e36b60ddb8f46fe0b9b4e8f4dce56f" category="list-text">스토리지 관리자용 ClusterRoleBindings를 구성합니다.</block>
  <block id="38f22acd9ae9c74099644738d613baaa" category="admonition">스토리지 관리자의 경우 세 가지 역할, 즉 세 가지 운영자 및 리소스 할당량이 바인딩되어야 합니다.</block>
  <block id="ced38b1f1c19446862c601754b82b94c" category="list-text">Developer-project-1 역할을 project-1의 해당 그룹(OCP-project-1)에 바인딩하는 개발자를 위한 RoleBindings를 만듭니다.</block>
  <block id="2aa292f2ff8b13fe141ca55c27bc29c2" category="list-text">마찬가지로 개발자 역할을 프로젝트 2의 해당 사용자 그룹에 바인딩하는 개발자를 위한 RoleBindings 를 만듭니다.</block>
  <block id="7d03daab3e74958fc08ebc0c90e0a6a2" category="inline-link-macro">다음: 스토리지 관리자 작업.</block>
  <block id="f3d9bb76442ab5c11e6af4dd328b2559" category="paragraph"><block ref="f3d9bb76442ab5c11e6af4dd328b2559" category="inline-link-macro-rx"></block></block>
  <block id="7eba670f1ea5a6e2fba9cff6b6399064" category="summary">이 페이지에서는 MetalLB 로드 밸런서에 대한 설치 및 구성 지침을 자세히 설명합니다.</block>
  <block id="79a2d2fa50d2b47d02c0e9dbdfadc07f" category="doc">MetalLB 로드 밸런서 설치: NetApp과 Red Hat OpenShift</block>
  <block id="0b2da9b5fe81e13e88c9a05981a95a9e" category="paragraph">이 페이지에는 MetalLB 로드 밸런서에 대한 설치 및 구성 지침이 나와 있습니다.</block>
  <block id="d719c733d0cd8753c048c8c3a025fd51" category="paragraph">MetalLB는 OpenShift 클러스터에 설치되는 자체 호스팅 네트워크 로드 밸런서로서, 클라우드 공급자에서 실행되지 않는 클러스터에서 유형 로드 밸런서의 OpenShift 서비스를 생성할 수 있습니다. 로드 밸런서 서비스를 지원하기 위해 함께 작동하는 MetalLB의 두 가지 주요 기능은 주소 할당과 외부 안내입니다.</block>
  <block id="28a4ce0a0514d0f6a6596fc7a9c5e725" category="section-title">MetalLB 구성 옵션</block>
  <block id="04c22d763ca95631f9c8789eb2c6e68f" category="paragraph">MetalLB가 OpenShift 클러스터 외부의 로드 밸런서 서비스에 할당된 IP 주소를 알려 주면 두 가지 모드로 작동합니다.</block>
  <block id="92f98c10e5e0c86bcae2e9cb58b700e3" category="list-text">* Layer 2 모드 * 이 모드에서는 OpenShift 클러스터의 한 노드가 서비스 소유권을 가져와 해당 IP에 대한 ARP 요청에 응답하여 OpenShift 클러스터 외부에서 해당 IP에 연결할 수 있도록 합니다. 노드만 IP를 광고하기 때문에 대역폭 병목 현상 및 느린 페일오버 제한이 있습니다. 자세한 내용은 설명서를 참조하십시오 <block ref="4a1d14cac7ed68a2326a050e0f1fed80" category="inline-link-macro-rx"></block>.</block>
  <block id="13f78a1c753a58b3786e5664e7b01344" category="list-text">* BGP mode. * 이 모드에서 OpenShift 클러스터의 모든 노드는 라우터와 BGP 피어링 세션을 설정하고 트래픽을 서비스 IP로 전달하기 위한 경로를 광고합니다. 이를 위해서는 MetalLB를 해당 네트워크의 라우터에 통합해야 합니다. BGP의 해싱 메커니즘으로 인해 서비스에 대한 IP-노드 매핑이 변경될 때 특정 제한이 있습니다. 자세한 내용은 설명서를 참조하십시오 <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="5fe238de20fea7c5ec86dde0a98c5841" category="admonition">이 문서에서는 MetalLB를 Layer-2 모드로 구성합니다.</block>
  <block id="32333b5f74abf17bffedb6e7abeb7b5f" category="section-title">MetalLB 로드 밸런서 설치</block>
  <block id="70bd399edc6825961c98dc29c2a49299" category="list-text">MetalLB 리소스를 다운로드합니다.</block>
  <block id="d95ae9e4bae10f240e5577110ccbd7e6" category="list-text">파일 Metallb.YAML을 편집하고 컨트롤러 배포 및 스피커 DemonSet에서 pec.template.spec.securityContext` 파일을 제거합니다.</block>
  <block id="39bb715a16a6f4c1ab16bc3ad3654f0b" category="paragraph">삭제할 줄: *</block>
  <block id="803519c541b237245faa09039c50dcaa" category="list-text">'metallb-system' 네임스페이스를 만듭니다.</block>
  <block id="980aff973ca30f65ec180530f40def06" category="list-text">MetalLB CR을 만듭니다.</block>
  <block id="f87be5542b64a7f94a807699fd549479" category="list-text">MetalLB 스피커를 구성하기 전에, 로드 밸런서가 작동하는 데 필요한 네트워킹 구성을 수행할 수 있도록 스피커 DemonSet Elevated 권한을 부여합니다.</block>
  <block id="53747915d8e79873876b08edb1ce3671" category="list-text">MetalLB는 metallb-system 네임스페이스에서 ConfigMap을 만들어 구성합니다.</block>
  <block id="2b1e829362de1a86eeb131cdc4619908" category="list-text">이제 로드 밸런서 서비스가 생성되면 MetalLB는 서비스에 외부 IP를 할당하고 ARP 요청에 응답하여 IP 주소를 알립니다.</block>
  <block id="234ce2b9b198f2acf2193cbd06120ff2" category="admonition">BGP 모드에서 MetalLB를 구성하려면 위의 6단계를 건너뛰고 MetalLB 설명서의 절차를 따르십시오 <block ref="fed7545a9b4a70bb7835cc8b07492cba" category="inline-link-macro-rx"></block>.</block>
  <block id="eeaa3ef2816f113fd1978b036eefc4a4" category="doc">솔루션 검증 및 사용 사례: NetApp 기반 Red Hat OpenShift</block>
  <block id="9e766e668731b912ea84be747f0d6b4b" category="paragraph">이 페이지에서 제공되는 예는 NetApp 기반의 Red Hat OpenShift에 대한 솔루션 검증 및 사용 사례입니다.</block>
  <block id="6f60a8e202d6d4f297230695ffa9c1a6" category="inline-link-macro">영구 스토리지로 Jenkins CI/CD 파이프라인을 구축합니다</block>
  <block id="20b131c747c2ab8c4c617107b04dfe76" category="list-text"><block ref="20b131c747c2ab8c4c617107b04dfe76" category="inline-link-macro-rx"></block></block>
  <block id="e85b6a5686bf01c916e1c3b442e8db44" category="inline-link-macro">NetApp과 함께 Red Hat OpenShift에서 멀티 테넌시를 구성합니다</block>
  <block id="29a3155f4e27ac61f0e6d1e00866c981" category="list-text"><block ref="29a3155f4e27ac61f0e6d1e00866c981" category="inline-link-macro-rx"></block></block>
  <block id="781cf19a6329e508987456098cde8c79" category="list-text"><block ref="781cf19a6329e508987456098cde8c79" category="inline-link-macro-rx"></block></block>
  <block id="ddb9608f0f25d56d00a539a63333efa0" category="list-text"><block ref="ddb9608f0f25d56d00a539a63333efa0" category="inline-link-macro-rx"></block></block>
  <block id="0d1d64b47559f0c28c883e7e790b8363" category="summary">이 섹션에서는 실제 사용자가 전용 이미지 레지스트리 만들기 또는 사용자 지정 로드 밸런서 인스턴스 배포와 같이 이 솔루션을 운영 환경에 배포할 때 수행해야 할 사용자 지정 작업에 대해 설명합니다.</block>
  <block id="b432301f7ba469598e6ea2eb86e4859a" category="paragraph">일반적으로 가장 쉽게 배포할 수 있는 솔루션이 가장 좋지만, 경우에 따라 특정 애플리케이션 또는 솔루션이 배포되는 환경의 요구 사항 또는 사양을 충족하기 위해 고급 사용자 지정이 필요합니다. 이를 위해 NetApp 기반의 Red Hat OpenShift 솔루션은 이러한 요구사항을 충족하기 위해 다음과 같은 사용자 정의를 지원합니다.</block>
  <block id="2642cf401e87de575eae139953f87134" category="admonition">이 섹션에서는 타사 로드 밸런서 사용 또는 맞춤형 컨테이너 이미지 호스팅을 위한 프라이빗 레지스트리 생성 등 NetApp Astra Control Center 설치를 위한 사전 요구 사항과 같은 몇 가지 고급 구성 옵션을 문서화했습니다.</block>
  <block id="02b655f637212514780af2795fd74fc4" category="paragraph">다음 페이지에서는 NetApp OpenShift에서 검증된 고급 구성 옵션에 대한 자세한 정보를 제공합니다.</block>
  <block id="becc5334b7f3d2f4f57fc42cd287fd54" category="inline-link-macro">로드 밸런서 옵션 탐색</block>
  <block id="22651dd64b4cd4c6d2742d1f8b126ae6" category="list-text"><block ref="22651dd64b4cd4c6d2742d1f8b126ae6" category="inline-link-macro-rx"></block></block>
  <block id="261bdcc1d2c24d15c43c5947e69ea9e6" category="inline-link-macro">개인 이미지 레지스트리 구성</block>
  <block id="c8db11b008075455562a8b598b31753c" category="list-text"><block ref="c8db11b008075455562a8b598b31753c" category="inline-link-macro-rx"></block></block>
  <block id="f913f3c8b073438c23eb36c9cf8237ac" category="section-title">VM을 생성합니다</block>
  <block id="71dd19ec5a595517b0b57750ad1a6568" category="paragraph">VM은 운영 체제 및 데이터를 호스트하기 위해 볼륨이 필요한 상태 저장 배포입니다. CNV에서는 VM이 Pod로 실행되므로 Trident를 통해 NetApp ONTAP에서 호스팅되는 PVS를 통해 VM을 지원합니다. 이러한 볼륨은 디스크로 연결되며 VM의 부팅 소스를 비롯한 전체 파일 시스템을 저장합니다.</block>
  <block id="e01cb9126428f7417091e42362dcb6cb" category="image-alt">VM 아키텍처를 생성합니다</block>
  <block id="51f24796fdd958a7a4ab9fb9a1086c9a" category="paragraph">OpenShift 클러스터에서 가상 머신을 생성하려면 다음 단계를 수행하십시오.</block>
  <block id="eaeef52618dbbd29ca52633c93abcbb4" category="list-text">원하는 운영 체제를 선택하고 Next(다음) 를 클릭합니다.</block>
  <block id="6befc3ce0d5cbd575434f0d5e1ec1125" category="list-text">선택한 운영 체제에 구성된 부팅 소스가 없는 경우 해당 소스를 구성해야 합니다. 부트 소스의 경우, URL에서 또는 레지스트리에서 OS 이미지를 가져올 것인지 선택하고 해당 세부 정보를 제공합니다. Advanced 를 확장하고 Trident-backed StorageClass 를 선택합니다. 다음 을 클릭합니다.</block>
  <block id="9b992d4161d9af3e77a9c4e35f9d7652" category="image-alt">VM의 부팅 소스를 생성합니다</block>
  <block id="fe46fcd3bb2eadd55896f6a4e9af5b05" category="list-text">선택한 운영 체제에 이미 구성된 부팅 소스가 있는 경우 이전 단계를 건너뛸 수 있습니다.</block>
  <block id="c119644bb97e69cc47555d48ff5ead07" category="list-text">가상 머신을 사용자 지정하려면 가상 머신 사용자 지정 을 클릭하고 필요한 매개 변수를 수정합니다.</block>
  <block id="8b2c60e63de0927cca5bd9401cdd4647" category="list-text">가상 머신 생성을 클릭하여 가상 머신을 생성합니다. 그러면 백그라운드에서 해당 포드가 회전합니다.</block>
  <block id="ba7734e1db4ae3c0a25330f01ced054d" category="paragraph">URL이나 레지스트리에서 템플릿이나 운영 체제에 대해 부트 소스를 구성하면 OpenShift-virtualization-OS-images' 프로젝트에서 PVC를 생성하고 KVM 게스트 이미지를 PVC로 다운로드합니다. 템플릿 PVC에 해당 OS에 대한 KVM 게스트 이미지를 수용할 수 있는 충분한 공간이 있는지 확인해야 합니다. 그런 다음 이러한 PVC는 프로젝트의 각 템플릿을 사용하여 생성될 때 가상 머신에 루트디스크로 복제되고 첨부됩니다.</block>
  <block id="2188a3011c4ccaa5490bcaca14a05579" category="inline-link-macro">다음: 워크플로: VM 실시간 마이그레이션.</block>
  <block id="a997d50e238a53b066824f32046c10ab" category="paragraph"><block ref="a997d50e238a53b066824f32046c10ab" category="inline-link-macro-rx"></block></block>
  <block id="92637d8d513510f7c1f5bfac6e1cce9b" category="summary">NetApp ONTAP 스토리지 시스템과의 Trident 통합을 활성화하려면 스토리지 시스템과의 통신을 지원하는 백엔드를 생성해야 합니다.</block>
  <block id="cbaa3aa588b8aa5c85dca443c15a0195" category="doc">NetApp ONTAP NFS 구성</block>
  <block id="89441fb0b16307f49090afa2b479b9fa" category="list-text">다운로드한 설치 아카이브에서 사용할 수 있는 예제 백엔드 파일이 'ample-input' 폴더 계층에 있습니다. NFS를 지원하는 NetApp ONTAP 시스템의 경우 'backend-ontap-nas.json' 파일을 작업 디렉토리에 복사하고 파일을 편집하십시오.</block>
  <block id="87f6ff6bf74013e1dfe6df49a1cf1986" category="list-text">backendName, managedLIF, dataLIF, svm, 사용자 이름, 및 암호 값을 입력합니다.</block>
  <block id="f897eefba2c59919d6493db4825e2db2" category="admonition">사용자 지정 backendName 값을 storageDriverName 과 NFS를 함께 사용하여 쉽게 식별할 수 있도록 하는 데이터 LIF를 함께 정의하는 것이 좋습니다.</block>
  <block id="00d6947fd6a153943286b857dcd0f339" category="admonition">이 파일에 정의된 fschType이라는 선택적 필드가 있습니다. 이 라인은 NFS 백엔드에서 삭제할 수 있습니다.</block>
  <block id="9d9b3c1914053d9ff102d01b77ab40a9" category="summary">이 사용 사례는 클라우드 기반 분석 데이터를 사내 데이터 센터에 백업해야 하는 브로드캐스트 고객을 기반으로 합니다.</block>
  <block id="0abf694ae9fa8ac43b805ba39a10d143" category="doc">사용 사례 2: 클라우드에서 사내로 백업 및 재해 복구</block>
  <block id="d05b5b5452aa966fcd3c8947a172f44a" category="inline-link-macro">이전: 활용 사례 1 - Hadoop 데이터 백업</block>
  <block id="d6b3b64a2054103914910c4432cc9e18" category="paragraph"><block ref="d6b3b64a2054103914910c4432cc9e18" category="inline-link-macro-rx"></block></block>
  <block id="733d8d14fe9ffb98d02b33079e3d3db2" category="paragraph">이 사용 사례는 아래 그림과 같이 클라우드 기반 분석 데이터를 사내 데이터 센터에 백업해야 하는 브로드캐스트 고객을 기반으로 합니다.</block>
  <block id="063e138ba69a95a99bd2f908b540e210" category="paragraph"><block ref="063e138ba69a95a99bd2f908b540e210" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54861efdd06fc309e1c9a420feff98eb" category="section-title">시나리오</block>
  <block id="26fea23389e404e4cb8cf9be2c100cbd" category="paragraph">이 시나리오에서는 IoT 센서 데이터가 클라우드로 수집되고 AWS 내의 오픈 소스 Apache Spark 클러스터를 사용하여 분석됩니다. 따라서 클라우드에서 처리된 데이터를 사내로 백업해야 합니다.</block>
  <block id="5f5e12d29ffccf33e8cb5a30f4d2fe8c" category="section-title">요구사항 및 당면 과제</block>
  <block id="c04f16bb8233216a472d30b6c509b230" category="paragraph">이 사용 사례의 주요 요구사항과 과제는 다음과 같습니다.</block>
  <block id="bb446485afc21a80bc5f26a9131de160" category="list-text">데이터 보호를 사용하도록 설정하면 클라우드의 운영 Spark/Hadoop 클러스터에 성능 영향이 미치지 않습니다.</block>
  <block id="dbb6231aec34eed7c53cff2d4a2d43ef" category="list-text">클라우드 센서 데이터를 효율적이고 안전한 방식으로 이동하고 사내로 보호해야 합니다.</block>
  <block id="848b66ad8aca524142404de79ce64c73" category="list-text">온디맨드, 즉각적인, 낮은 클러스터 로드 시간 등 다양한 조건에서 데이터를 클라우드로 유연하게 전송할 수 있습니다.</block>
  <block id="49b21ad0d38942f635877e7bbc5d7a1e" category="section-title">해결 방법</block>
  <block id="4d8011e28e4ef4359ca7c169e7797091" category="paragraph">이 고객은 Spark 클러스터 HDFS 스토리지에 AWS EBS(Elastic Block Store)를 사용하여 Kafka를 통해 원격 센서에서 데이터를 수신 및 수집했습니다. 따라서 HDFS 스토리지는 백업 데이터의 소스 역할을 합니다.</block>
  <block id="e55d60f6f17896ce9b53a0ef23e23413" category="paragraph">이러한 요구사항을 충족하기 위해 NetApp ONTAP Cloud를 AWS에 구축하고 NFS 공유를 생성하여 Spark/Hadoop 클러스터의 백업 타겟 역할을 수행합니다.</block>
  <block id="c260f0b6bfdb6eff1473aafbf5bd075a" category="paragraph">NFS 공유가 생성된 후 데이터 이동 없는 분석 모듈을 활용하여 HDFS EBS 스토리지에서 ONTAP NFS 공유로 데이터를 복제합니다. ONTAP 클라우드의 NFS에 데이터가 상주한 후에는 SnapMirror 기술을 사용하여 필요에 따라 클라우드에서 사내 스토리지로 데이터를 안전하고 효율적으로 미러링할 수 있습니다.</block>
  <block id="aecad7c5bdfba92aa6cd945a9045c37f" category="paragraph">이 이미지는 클라우드에서 사내 솔루션으로 백업 및 재해 복구를 보여줍니다.</block>
  <block id="94c7a6b63152038de5e8b2763cdef06c" category="paragraph"><block ref="94c7a6b63152038de5e8b2763cdef06c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bbd6a10b63926b84e9a28da6d4214925" category="inline-link-macro">다음: 사용 사례 3 - 기존 Hadoop 데이터에 대해 DevTest를 설정합니다.</block>
  <block id="e0f915fb1893e398d54abc6f9d00ca57" category="paragraph"><block ref="e0f915fb1893e398d54abc6f9d00ca57" category="inline-link-macro-rx"></block></block>
  <block id="7e936a7640e03dad09e0b76d68277d56" category="summary">NetApp은 NetApp StorageGRID 설정을 통해 생산 및 소비자 워크로드를 위한 3~4개의 노드로 계층형 스토리지 테스트를 수행했습니다.</block>
  <block id="3c2fe55c24192bbec6d6d3aede570213" category="doc">확장성을 갖춘 성능 테스트</block>
  <block id="ef1ee9d1f1e9874aca751251bbce31bf" category="inline-link-macro">이전: Confluent verification.</block>
  <block id="6d08115c54837de983d3ddc9dcd8f038" category="paragraph"><block ref="6d08115c54837de983d3ddc9dcd8f038" category="inline-link-macro-rx"></block></block>
  <block id="7d962aad50ee059cfbd23de23ab5a916" category="paragraph">NetApp StorageGRID 설정을 통해 생산자 및 소비자 워크로드를 위한 3~4개의 노드로 계층형 스토리지 테스트를 수행했습니다. 이 테스트에 따르면 완료 시간과 성능 결과는 StorageGRID 노드 수에 정비례합니다. StorageGRID를 설치하려면 최소 3개의 노드가 필요합니다.</block>
  <block id="4e6097966a711c7acf606365a2925b64" category="list-text">스토리지 노드의 수가 증가했을 때 생산 및 소비자 작업을 완료하는 데 걸리는 시간이 선형적으로 감소했습니다.</block>
  <block id="544baf869b5baa766e8839cd33697872" category="paragraph"><block ref="544baf869b5baa766e8839cd33697872" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d098e780afaaad433dd6982bbc5af988" category="list-text">S3 검색 작업의 성능은 StorageGRID 노드 수에 따라 선형으로 증가합니다. StorageGRID는 최대 200개의 StorgeGRID 노드를 지원합니다.</block>
  <block id="2cd319a657a7fccb8f747dab6f102dcc" category="paragraph"><block ref="2cd319a657a7fccb8f747dab6f102dcc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c8105fbc386e60a03fe0cf5390eb0ce" category="inline-link-macro">다음: Confluent S3 커넥터.</block>
  <block id="40acd085e3c223b35d81906b1c904f46" category="paragraph"><block ref="40acd085e3c223b35d81906b1c904f46" category="inline-link-macro-rx"></block></block>
  <block id="55473d705d75e19b6040dbe34242319c" category="summary">이 섹션에서는 이 솔루션에 사용된 기술에 대해 설명합니다.</block>
  <block id="d7023badac36eeb28bf29785a97c493c" category="inline-link-macro">이전: 솔루션 아키텍처 세부 정보.</block>
  <block id="258ee3f437d6a20985ccf4e13065a097" category="paragraph"><block ref="258ee3f437d6a20985ccf4e13065a097" category="inline-link-macro-rx"></block></block>
  <block id="d82d42ad0a2161d02e1d8ce74ffcf0ab" category="paragraph">NetApp StorageGRID는 비용 효율적인 고성능 오브젝트 스토리지 플랫폼입니다. 계층형 스토리지를 사용하면 중개인의 로컬 스토리지 또는 SAN 스토리지에 저장된 Confluent Kafka의 데이터 대부분이 원격 오브젝트 저장소로 오프로드됩니다. 이 구성은 클러스터 재조정, 확장 또는 축소 또는 실패한 브로커 교체에 드는 시간과 비용을 줄여 운영 효율성을 크게 개선합니다. 오브젝트 스토리지는 오브젝트 저장소 계층에 있는 데이터를 관리하는 데 중요한 역할을 합니다. 따라서 적합한 오브젝트 스토리지를 선택하는 것이 중요합니다.</block>
  <block id="3fa5e29e13fc3b3448ca388750ef38f0" category="paragraph">StorageGRID는 분산된 노드 기반 그리드 아키텍처를 사용하여 정책 중심의 지능형 글로벌 데이터 관리를 제공합니다. 정교한 데이터 관리 기능과 결합된 유비쿼터스 글로벌 오브젝트 네임스페이스를 통해 페타바이트 단위의 비정형 데이터와 수십억 개의 오브젝트 관리를 간소화합니다. 단일 호출 개체 액세스는 사이트 간에 확장되고 고가용성 아키텍처를 단순화하는 동시에 사이트 또는 인프라 중단과 관계없이 지속적인 개체 액세스를 보장합니다.</block>
  <block id="30f28784f61df7a2f8e7069cefea91eb" category="paragraph">멀티 테넌시를 사용하면 동일한 그리드 내에서 여러 비정형 클라우드 및 엔터프라이즈 데이터 애플리케이션을 안전하게 서비스할 수 있으므로 NetApp StorageGRID의 ROI 및 사용 사례가 증가합니다. 여러 지역에서 내구성, 보호, 성능, 인접성을 최적화하여 메타데이터 기반 오브젝트 라이프사이클 정책을 통해 여러 서비스 레벨을 생성할 수 있습니다. 사용자는 데이터 관리 정책을 조정하고 트래픽 제한을 모니터링 및 적용하여 끊임없이 변화하는 IT 환경에서 요구 사항이 변경됨에 따라 데이터 환경을 중단 없이 다시 조정할 수 있습니다.</block>
  <block id="dc10add739549f11a9f3d6ac44bf7fcc" category="section-title">Grid Manager를 통한 간편한 관리</block>
  <block id="494ed2651e6b5b87a49cfe7ab40d5253" category="paragraph">StorageGRID 그리드 관리자는 브라우저 기반의 그래픽 인터페이스로, 단일 창에서 전세계에 분산된 위치에 걸쳐 StorageGRID 시스템을 구성, 관리 및 모니터링할 수 있습니다.</block>
  <block id="a96dbd2aff4998074bc0ca48dc4817d5" category="paragraph"><block ref="a96dbd2aff4998074bc0ca48dc4817d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3784ac64ff307aaceedbc4045a0d047c" category="paragraph">StorageGRID 그리드 관리자 인터페이스를 사용하여 다음 작업을 수행할 수 있습니다.</block>
  <block id="57d56613e28a4b5b4e9f351d17e228f7" category="list-text">이미지, 비디오, 레코드 등 전 세계에 분산된 페타바이트 규모의 오브젝트 저장소를 관리합니다.</block>
  <block id="5865c6ada208cf4e21f121f0d367b25a" category="list-text">그리드 노드 및 서비스를 모니터링하여 개체 가용성을 보장합니다.</block>
  <block id="52134209a1824af49cd06b67ca3aedc7" category="list-text">ILM(정보 수명 주기 관리) 규칙을 사용하여 시간이 지남에 따라 오브젝트 데이터의 배치를 관리합니다. 이러한 규칙은 수집된 개체의 데이터, 데이터가 손실되지 않도록 보호하는 방법, 오브젝트 데이터가 저장되는 위치 및 기간에 대해 적용됩니다.</block>
  <block id="5c578eee23496659cea7dda27021c318" category="list-text">시스템 내의 트랜잭션, 성능 및 운영을 모니터링합니다.</block>
  <block id="c91fcac1d7192250f9c73d72ad06e051" category="section-title">정보 수명 주기 관리 정책</block>
  <block id="a1d8b1b1990901cd5a97dd0f3dee2da9" category="inline-link-macro">ILM 정책</block>
  <block id="37e0a993cc0a3c5aacb623e412befc5b" category="inline-link-macro">ILM 규칙</block>
  <block id="0beeefc6ac257658ea119788351ad268" category="paragraph">StorageGRID는 오브젝트의 복제본 보존 및 특정 성능 및 데이터 보호 요구사항에 따라 오브젝트를 저장할 수 있도록 2+1 및 4+2(특히 다른)와 같은 EC(삭제 코딩) 스키마를 사용하는 등의 유연한 데이터 관리 정책을 제공합니다. 시간에 따라 워크로드와 요구사항이 달라지날수록 ILM 정책도 시간에 따라 바뀌어야 합니다. ILM 정책을 수정하는 것은 핵심 기능이므로 StorageGRID 고객은 끊임없이 변화하는 환경에 빠르고 쉽게 적응할 수 있습니다. 를 확인하십시오 <block ref="b2ddd4069e5288685e27e7989fb1a613" category="inline-link-macro-rx"></block> 및 <block ref="7593bc4c70a5537fc14593339f7e6540" category="inline-link-macro-rx"></block> StorageGRID에서 설정.</block>
  <block id="356760a65d5411f2c9f8647f90e50978" category="inline-link-macro">SG5712, SG5760, SG6060 또는 SGF6024</block>
  <block id="2ec930774314e7709987603c82825f4b" category="paragraph">StorageGRID는 VM, 베어 메탈 또는 특수 제작된 어플라이언스 등 스토리지 노드를 추가하여 성능을 확장합니다 <block ref="585d6d5337b82c3c73a6c04b53fcdd23" category="inline-link-macro-rx"></block>. 이 테스트에서는 SGF6024 어플라이언스를 사용하는 최소 크기의 3노드 그리드로 Apache Kafka의 주요 성능 요구사항을 초과했습니다. 고객이 추가 브로커로 Kafka 클러스터를 확장함에 따라 스토리지 노드를 추가하여 성능과 용량을 확장할 수 있습니다.</block>
  <block id="3eee81ca69cbbee2bec24db63e4dea0d" category="section-title">부하 분산 장치 및 엔드포인트 구성</block>
  <block id="5b42fd120a40ecd7cc8ac5cdedde8ceb" category="paragraph">StorageGRID의 관리 노드는 StorageGRID 시스템을 보고, 구성하고, 관리할 수 있는 그리드 관리자 UI(사용자 인터페이스) 및 REST API 엔드포인트와 시스템 작업을 추적할 수 있는 감사 로그를 제공합니다. Confluent Kafka 계층형 스토리지에 가용성이 높은 S3 엔드포인트를 제공하기 위해 관리 노드와 게이트웨이 노드에서 서비스로 실행되는 StorageGRID 로드 밸런서를 구현했습니다. 또한 로드 밸런서는 로컬 트래픽을 관리하고 GSLB(Global Server Load Balancing)에 연결하여 재해 복구를 지원합니다.</block>
  <block id="dca5165744ce2dbf5825f022349ee941" category="section-title">StorageGRID의 트래픽 분류</block>
  <block id="588db6e460515c5268204303c93a770b" category="paragraph">StorageGRID에는 QoS 기능이 내장되어 있습니다. 트래픽 분류 정책은 클라이언트 애플리케이션에서 들어오는 다양한 유형의 S3 트래픽을 모니터링하는 데 도움이 될 수 있습니다. 그런 다음 정책을 생성하여 적용하여 In/Out 대역폭, 읽기/쓰기 동시 요청 수 또는 읽기/쓰기 요청 속도에 따라 이 트래픽에 제한을 적용할 수 있습니다.</block>
  <block id="bb2bd99338b18762ef6953ad2cbfafc7" category="section-title">아파치 카프카</block>
  <block id="611f69baa46f691eeeb33645e83f0fcb" category="paragraph">Apache Kafka는 Java 및 Scala로 작성된 스트림 처리를 사용하는 소프트웨어 버스의 프레임워크입니다. 이 제품은 실시간 데이터 피드 처리를 위한 높은 처리량의 짧은 대기 시간을 갖춘 통합 플랫폼을 제공하기 위해 마련되었습니다. Kafka는 데이터 내보내기 및 가져오기를 위해 Kafka Connect를 통해 외부 시스템에 연결할 수 있으며 Java 스트림 처리 라이브러리인 Kafka 스트림을 제공합니다. Kafka는 효율성을 위해 최적화된 바이너리 TCP 기반 프로토콜을 사용하며, 네트워크를 통한 왕복 작업의 오버헤드를 줄이기 위해 자연스럽게 메시지를 그룹화하는 "메시지 세트" 추상화에 의존합니다. 이렇게 하면 순차 디스크 작업, 더 큰 네트워크 패킷 및 연속 메모리 블록이 증가하므로 Kafka는 랜덤 메시지 쓰기의 폭주 스트림을 선형 쓰기로 전환할 수 있습니다. 다음 그림은 Apache Kafka의 기본 데이터 흐름을 보여 줍니다.</block>
  <block id="d1675da945892e06b2f84c42c32b7074" category="paragraph"><block ref="d1675da945892e06b2f84c42c32b7074" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c50889322e9d7d913a4218be06b94d9d" category="paragraph">Kafka는 생산자라는 임의의 수의 프로세스에서 가져온 키 값 메시지를 저장합니다. 데이터는 여러 주제 내의 서로 다른 파티션으로 분할될 수 있습니다. 파티션 내에서 메시지는 해당 오프셋(파티션 내의 메시지 위치)에 의해 엄격하게 정렬되고 타임 스탬프와 함께 인덱싱되고 저장됩니다. 소비자라고 하는 다른 프로세스는 파티션에서 메시지를 읽을 수 있습니다. 스트림 처리를 위해 Kafka는 Kafka의 데이터를 사용하는 Java 애플리케이션을 작성하고 결과를 Kafka에 다시 쓸 수 있는 스트림 API를 제공합니다. Apache Kafka는 Apache Apex, Apache Flink, Apache Spark, Apache Storm, Apache nifi 등의 외부 스트림 처리 시스템과도 작동합니다.</block>
  <block id="0f13dfad626acfc5a84f5c6d8127cb93" category="paragraph">Kafka는 하나 이상의 서버(브로커)로 구성된 클러스터에서 실행되며 모든 항목의 파티션이 클러스터 노드에 분산됩니다. 또한 파티션이 여러 브로커에 복제됩니다. 이 아키텍처를 통해 Kafka는 내결함성이 있는 방식으로 대규모 메시지 스트림을 전달할 수 있으며 JMS(Java Message Service), AMQP(Advanced Message Queuing Protocol) 등의 기존 메시징 시스템을 대체할 수 있습니다. Kafka는 0.11.0.0 릴리스 이후 트랜잭션 쓰기를 제공하여 스트림 API를 사용하여 정확히 한 번의 스트림 처리를 제공합니다.</block>
  <block id="a05ab89a0e70d8932f92ff5626b80205" category="paragraph">Kafka는 일반과 컴팩션이라는 두 가지 유형의 주제를 지원합니다. 정규 주제는 보존 시간 또는 공간 바인딩으로 구성할 수 있습니다. 지정된 보존 시간보다 오래된 레코드가 있거나 파티션에 대해 바인딩된 공간이 초과된 경우 Kafka는 사용 가능한 저장소 공간을 확보하기 위해 이전 데이터를 삭제할 수 있습니다. 기본적으로 항목은 보존 기간이 7일로 구성되지만 데이터를 무기한 저장할 수도 있습니다. 압축된 항목의 경우 시간 또는 공간 범위에 따라 레코드가 만료되지 않습니다. 대신 Kafka는 나중에 받은 메시지를 동일한 키를 사용하는 이전 메시지의 업데이트로 취급하며 키당 최신 메시지를 삭제하지 않도록 보장합니다. 사용자는 특정 키에 대해 null 값을 갖는 소위 tombstone 메시지를 작성하여 메시지를 완전히 삭제할 수 있습니다.</block>
  <block id="67510baee28b6897f23f317ea0eec6cd" category="paragraph">Kafka에는 다음과 같은 5가지 주요 API가 있습니다.</block>
  <block id="43437be1fd3e6788160e377194164ab4" category="list-text">* Producer API. * 응용 프로그램에서 레코드 스트림을 게시할 수 있도록 허용합니다.</block>
  <block id="d4814db3c767fa7cb8ef858faeb32012" category="list-text">* 소비자 API. * 응용 프로그램에서 항목 및 레코드 스트림 프로세스를 구독할 수 있도록 허용합니다.</block>
  <block id="8e4e76f717f8e282710dbe0549551bbc" category="list-text">* Connector API. * 항목을 기존 응용 프로그램에 연결할 수 있는 재사용 가능한 프로듀서 및 소비자 API를 실행합니다.</block>
  <block id="32a74767220f0fd870d75199524522d5" category="list-text">* Streams API. * 이 API는 입력 스트림을 출력으로 변환하고 결과를 생성합니다.</block>
  <block id="4bb47a81bc800e1fb57bdde2d0945599" category="list-text">* Admin API. * Kafka 주제, 브로커 및 기타 Kafka 객체를 관리하는 데 사용됩니다.</block>
  <block id="610121f784783393f66b6624cf93dafb" category="paragraph">소비자 및 생산자 API는 Kafka 메시징 프로토콜을 기반으로 하며 Java의 Kafka 소비자 및 생산자 클라이언트에 대한 참조 구현을 제공합니다. 기본 메시징 프로토콜은 개발자가 프로그래밍 언어로 소비자 또는 생산자 클라이언트를 작성하는 데 사용할 수 있는 이진 프로토콜입니다. 이렇게 하면 JVM(Java Virtual Machine) 에코시스템에서 Kafka가 잠금 해제됩니다. 사용 가능한 비 Java 클라이언트 목록은 Apache Kafka wiki에서 유지 관리됩니다.</block>
  <block id="3b85a5b4b78ed5de8ac5389862ce3d3f" category="section-title">Apache Kafka 사용 사례</block>
  <block id="21f595a264810e4537696c1280efad57" category="paragraph">Apache Kafka는 메시징, 웹 사이트 활동 추적, 메트릭, 로그 집계, 스트림 처리, 이벤트 소싱 및 로깅 커밋</block>
  <block id="60f50b920903b4049f776062aa5e6cdc" category="list-text">Kafka는 향상된 처리량, 내장 파티셔닝, 복제 및 내결함성 기능을 제공하므로 대규모 메시지 처리 애플리케이션에 적합한 솔루션입니다.</block>
  <block id="0ae69072c472e595412163a07084932c" category="list-text">Kafka는 실시간 게시 구독 피드 집합으로 추적 파이프라인에서 사용자의 활동(페이지 보기, 검색)을 재구축할 수 있습니다.</block>
  <block id="6d9673a2fe148c529c3b2051cfe93896" category="list-text">Kafka는 운영 모니터링 데이터에 자주 사용됩니다. 이를 위해서는 분산된 애플리케이션에서 통계를 집계하여 운영 데이터의 중앙 집중식 피드를 생성하는 작업이 필요합니다.</block>
  <block id="8b8951c427cfdc3f095bb9d556dce00e" category="list-text">많은 사람들이 Kafka를 로그 집계 솔루션의 대안으로 사용합니다. 로그 집계는 일반적으로 서버에서 물리적 로그 파일을 수집하여 처리를 위해 중앙 위치(예: 파일 서버 또는 HDFS)에 배치합니다. Kafka는 파일 세부 정보를 추상화하고 로그 또는 이벤트 데이터를 메시지 스트림으로 추상화합니다. 따라서 대기 시간이 짧아지며 여러 데이터 소스 및 분산된 데이터 사용을 더욱 쉽게 지원할 수 있습니다.</block>
  <block id="e9b95314420c3704f19bfa0e922f51d1" category="list-text">Kafka의 많은 사용자는 여러 스테이지로 구성된 처리 파이프라인에서 원시 입력 데이터가 Kafka 주제에서 소비된 후 추가 소비 또는 후속 처리를 위해 새로운 주제로 집계, 강화 또는 기타 방식으로 변환되는 데이터를 처리합니다. 예를 들어 뉴스 기사를 추천하기 위한 처리 파이프라인은 RSS 피드에서 기사 콘텐츠를 크롤링하여 "기사" 항목에 게시할 수 있습니다. 추가 처리에서는 이 콘텐츠를 정규화하거나 중복 제거하고 정리된 문서 콘텐츠를 새 주제에 게시하며 최종 처리 단계에서 사용자에게 이 콘텐츠를 추천하려고 할 수 있습니다. 이러한 처리 파이프라인은 개별 주제를 기반으로 실시간 데이터 플로우의 그래프를 작성합니다.</block>
  <block id="f2bf506d0e67708783f1bc5c0b518527" category="list-text">이벤트 수그리기는 상태 변경이 시간 순서 기록 시퀀스로 기록되는 응용 프로그램 디자인의 스타일입니다. Kafka는 매우 큰 저장 로그 데이터를 지원하므로 이 스타일로 구축된 애플리케이션에 대한 탁월한 백엔드로 활용할 수 있습니다.</block>
  <block id="6a4fef92874e37e1418ff91ed4fda9cd" category="list-text">Kafka는 분산 시스템에 대한 일종의 외부 커밋 로그 역할을 할 수 있습니다. 이 로그는 노드 간 데이터를 복제하고 장애가 발생한 노드가 데이터를 복원할 수 있도록 재동기화 메커니즘 역할을 합니다. Kafka의 로그 컴팩션 기능은 이 활용 사례를 지원하는 데 도움이 됩니다.</block>
  <block id="a03d0d99a3287875dda3d19daa736d0c" category="section-title">유창하게</block>
  <block id="ca010f92402f8d9066224231329f1128" category="paragraph">Confluent Platform은 Kafka를 완성하는 엔터프라이즈급 플랫폼으로, 애플리케이션 개발 및 연결 속도를 높이고, 스트림 처리를 통해 혁신을 지원하고, 규모에 따라 엔터프라이즈 운영을 간소화하고, 엄격한 아키텍처 요구 사항을 충족하도록 설계된 고급 기능을 제공합니다. Apache Kafka를 처음 개발한 Confluent는 Kafka 관리 또는 모니터링의 부담을 덜면서 엔터프라이즈급 기능을 통해 Kafka의 이점을 확장해 줍니다. 현재 Fortune 100대 기업 중 80% 이상이 데이터 스트리밍 기술을 사용하고 있으며 대부분 Confluent를 사용하고 있습니다.</block>
  <block id="3bcbf4072ba1e23a48434530e19a485d" category="section-title">왜 Confluent인가?</block>
  <block id="0fcb60f8560b74a641f556dbf96faf91" category="paragraph">Confluorent는 기록 데이터와 실시간 데이터를 단일 중앙 데이터 소스에 통합하여 완전히 새로운 범주의 최신 이벤트 기반 애플리케이션을 쉽게 구축하고, 범용 데이터 파이프라인을 구축하며, 완전한 확장성, 성능, 안정성으로 강력한 새 사용 사례를 활용할 수 있도록 지원합니다.</block>
  <block id="f781b7a8a0d145997db9cf8449512bb8" category="section-title">Contfluent는 어떤 용도로 사용됩니까?</block>
  <block id="6b41836f6be8bfff401751859b6f5561" category="paragraph">Confluent Platform을 사용하면 데이터가 다른 시스템 간에 어떻게 전송 또는 통합되는지 등의 기본 메커니즘을 걱정하지 않고 데이터에서 비즈니스 가치를 창출하는 방법에 집중할 수 있습니다. 특히 Confluent Platform은 데이터 소스를 Kafka에 연결하고 스트리밍 애플리케이션을 구축하며 Kafka 인프라의 보안, 모니터링 및 관리를 간소화합니다. 현재 Confluent Platform은 금융 서비스, 옴니채널 소매, 자율 자동차, 사기 탐지 등 다양한 산업 전반의 다양한 사용 사례에 사용됩니다. 마이크로서비스, IoT</block>
  <block id="774f9746d58ac38abf733a92e4720365" category="paragraph">다음 그림에서는 Confluent Kafka 플랫폼 구성 요소를 보여 줍니다.</block>
  <block id="a4eaf48584aaa7df975a9275a8b4ee24" category="paragraph"><block ref="a4eaf48584aaa7df975a9275a8b4ee24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0693822e07a3206c53912f33e3d67758" category="section-title">Confluent의 이벤트 스트리밍 기술 개요</block>
  <block id="f6d3df755e538ab85e1dffe4e2ef9966" category="paragraph">Confluent Platform의 핵심은 입니다<block ref="67718c59f00d7d04e4868dff5b37db2b" category="inline-link-rx"></block>가장 널리 사용되는 오픈 소스 분산 스트리밍 플랫폼입니다. Kafka의 주요 기능은 다음과 같습니다.</block>
  <block id="f630f472aeeab8697846e0f1f2f730aa" category="list-text">레코드 스트림을 게시하고 구독합니다.</block>
  <block id="176fc2b349b906f6eb7a8f49c7ce9780" category="list-text">내결함성이 있는 방식으로 레코드 스트림을 저장합니다.</block>
  <block id="6026e29e86fd0ddcb6cba3908f85691f" category="list-text">레코드 스트림을 처리합니다.</block>
  <block id="f7ec60663c6d3ee6fd5abe343b34f2b4" category="paragraph">즉시 사용할 수 있는 Confluorent Platform에는 스키마 레지스트리, REST 프록시, 총 100개 이상의 사전 구축된 Kafka 커넥터 및 ksqlDB도 포함되어 있습니다.</block>
  <block id="55be5d4d3f7143137050de9374d03f6f" category="section-title">Confluent 플랫폼의 엔터프라이즈 기능 개요</block>
  <block id="c7d070206c9b11b02bee9b591736971c" category="list-text">* Confluent Control Center. * Kafka 관리 및 모니터링을 위한 GUI 기반 시스템. Kafka Connect를 쉽게 관리하고 다른 시스템에 대한 연결을 생성, 편집 및 관리할 수 있습니다.</block>
  <block id="da2f1a857a79ec960671ee4c735cc96e" category="list-text">Kubernetes를 위한 * Contfluent. * Kubernetes를 위한 Confluent는 Kubernetes 운영자입니다. Kubernetes 운영자는 특정 플랫폼 애플리케이션에 대한 고유한 기능과 요구 사항을 제공하여 Kubernetes의 오케스트레이션 기능을 확장합니다. Confluent Platform의 경우, Kubernetes에서 Kafka의 구축 프로세스를 크게 간소화하고 일반적인 인프라 라이프사이클 작업을 자동화할 수 있습니다.</block>
  <block id="5488a6660d4f7d32995b983624c2e915" category="list-text">* Kafka * 커넥터에 대한 Confluent 커넥터 Kafka Connect API를 사용하여 Kafka를 데이터베이스, 키 값 저장소, 검색 인덱스 및 파일 시스템과 같은 다른 시스템에 연결합니다. Confluorent Hub에는 가장 널리 사용되는 데이터 소스 및 싱크에 대한 다운로드 가능한 커넥터가 있습니다. 여기에는 Confluorent Platform이 포함된 이러한 커넥터의 전체 테스트 및 지원 버전이 포함됩니다. 자세한 내용은 을 참조하십시오<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="b47dc18271c0f29d64ce1f45f12a053c" category="list-text">* 자체 밸런싱 클러스터 * 는 자동화된 로드 밸런싱, 장애 감지 및 자동 복구를 제공합니다. 필요에 따라 브로커를 추가하거나 해체할 수 있도록 지원하며 수동 튜닝이 필요하지 않습니다.</block>
  <block id="776a13408286748f8c985c409604e8b6" category="list-text">* 연결 클러스터. * 직접 클러스터를 연결하고 링크 브리지를 통해 클러스터 간에 주제를 미러링합니다. 클러스터 링크를 사용하면 멀티 데이터 센터, 멀티 클러스터, 하이브리드 클라우드 구축을 간편하게 설정할 수 있습니다.</block>
  <block id="1e5c2c1a7b1c3f9809e2b97438773325" category="list-text">* Confluorent auto data balancer. * 브로커 수, 파티션 크기, 파티션 수 및 클러스터 내의 리더 수에 대한 클러스터를 모니터링합니다. 균형 조정을 통해 트래픽을 재조정함으로써 운영 워크로드에 미치는 영향을 최소화하면서 클러스터 전체에서 짝수 워크로드를 생성할 수 있습니다.</block>
  <block id="0f97179e1bb10c15685ca78b035b4956" category="list-text">* Confluent Replicator. * 여러 데이터 센터에서 여러 Kafka 클러스터를 훨씬 쉽게 유지 관리할 수 있습니다.</block>
  <block id="a409602cf12dbcb436352a95146b6407" category="list-text">* 계층형 스토리지. * 즐겨 사용하는 클라우드 공급자를 사용하여 대량의 Kafka 데이터를 저장할 수 있는 옵션을 제공하므로 운영 부담과 비용이 줄어듭니다. 계층형 스토리지를 사용하면 비용 효율적인 오브젝트 스토리지에 데이터를 보관하고 더 많은 컴퓨팅 리소스가 필요할 때만 브로커를 확장할 수 있습니다.</block>
  <block id="ce61411f1780c30f58dd5aed90a77ad3" category="list-text">* Confluent JMS 클라이언트. * Confluent Platform에는 Kafka용 JMS 호환 클라이언트가 포함되어 있습니다. 이 Kafka 클라이언트는 Kafka 브로커를 백엔드로 사용하여 JMS 1.1 표준 API를 구현합니다. JMS를 사용하는 레거시 애플리케이션이 있고 기존 JMS 메시지 브로커를 Kafka로 교체하려는 경우 유용합니다.</block>
  <block id="b38f5ff9be3975e499ba273a01035420" category="list-text">* Confluent MQTT proxy. * 중간에 MQTT 브로커가 없어도 MQTT 장치 및 게이트웨이에서 Kafka에 직접 데이터를 게시할 수 있는 방법을 제공합니다.</block>
  <block id="ab05a802c02076dd0f0b419529e71ccd" category="list-text">* Confluent 보안 플러그인 * Confluent 보안 플러그인은 다양한 Confluent 플랫폼 도구 및 제품에 보안 기능을 추가하는 데 사용됩니다. 현재 Confluent REST 프록시에 사용할 수 있는 플러그인이 있어 수신 요청을 인증하고 인증된 보안 주체를 Kafka에 요청에 전파할 수 있습니다. 이렇게 하면 Confluent REST 프록시 클라이언트가 Kafka 브로커의 멀티테넌트 보안 기능을 활용할 수 있습니다.</block>
  <block id="4f9143a5adb8a0385a1c660d201ef274" category="inline-link-macro">다음: Confluent verification</block>
  <block id="d566a24bfcb09090b96a073132a83173" category="paragraph"><block ref="d566a24bfcb09090b96a073132a83173" category="inline-link-macro-rx"></block></block>
  <block id="69fc1008ccb741113af5042f04fcbc8b" category="summary">이 문서에서는 NetApp 스토리지 컨트롤러에서 Kafka를 사용하기 위한 모범 사례 지침을 설명합니다.</block>
  <block id="22f51db51c9641d5358726fa5e03f67b" category="doc">TR-4912: NetApp을 통해 Confluent Kafka 계층형 스토리지를 위한 모범 사례 지침</block>
  <block id="a29b982ab81cd1d74045ee43e3378135" category="paragraph">Karthkeyan Nagalingam, Joseph Kandatillarambil, NetApp Rankesh Kumar, Confluent</block>
  <block id="37281d123cc59a7c05b3ce30b5ea435e" category="paragraph">Apache Kafka는 매일 수조 건의 이벤트를 처리할 수 있는 커뮤니티 분산 이벤트 스트리밍 플랫폼입니다. 처음에 메시징 큐로 구상된 Kafka는 분산 커밋 로그의 추상화를 기반으로 합니다. Kafka는 2011년 LinkedIn에서 제작 및 오픈 소스를 통해 메시지 큐에서 완전한 이벤트 스트리밍 플랫폼으로 발전했습니다. Confluent는 Apache Kafka를 Confluent Platform과 함께 배포할 수 있도록 합니다. Confluent Platform은 Kafka를 보완하는 추가적인 커뮤니티 및 상용 기능을 제공하여 대규모 생산 환경에서 운영자와 개발자 모두의 스트리밍 경험을 개선하도록 설계되었습니다.</block>
  <block id="e1c012d650a6912ddb72ab0ee914d169" category="paragraph">이 문서에서는 다음 내용을 제공하여 NetApp의 오브젝트 스토리지 제품에서 Confluent Tiered Storage를 사용하기 위한 모범 사례 지침을 설명합니다.</block>
  <block id="2717b4b699259a5e59279aac92d526a2" category="list-text">NetApp 오브젝트 스토리지를 위한 Confluent 검증 – NetApp StorageGRID</block>
  <block id="0939eec6a072b9deba2d6aa39249110d" category="list-text">계층형 스토리지 성능 테스트</block>
  <block id="7607a859995debe77df0676d09d8270b" category="list-text">NetApp 스토리지 시스템에 대한 Confluent의 모범 사례 지침</block>
  <block id="59cb8890508bcaf057fd0360eb8ff783" category="section-title">ContFluent Tiered Storage를 선택해야 하는 이유</block>
  <block id="7a3966946c615eb57ae930f6948a1c65" category="inline-link-macro">이 기사는 Confluent에 의해 작성되었습니다</block>
  <block id="eced8e0ff3a0cd0f66b3a8845f1e08be" category="paragraph">Confluent는 많은 애플리케이션, 특히 빅데이터, 분석 및 스트리밍 워크로드를 위한 기본 실시간 스트리밍 플랫폼이 되었습니다. 계층적 스토리지를 사용하면 사용자가 Confluent 플랫폼의 스토리지에서 컴퓨팅을 분리할 수 있습니다. Data Fabric을 활용하면 데이터를 보다 경제적으로 저장하고, 사실상 무한대의 데이터를 저장하고, 필요 시 워크로드를 스케일업(또는 스케일다운) 할 수 있으며, 데이터 및 테넌트 재조정과 같은 관리 작업을 더 쉽게 수행할 수 있습니다. S3 호환 스토리지 시스템은 이러한 모든 기능을 활용하여 모든 이벤트의 데이터를 한 곳에서 대중화할 수 있으며, 복잡한 데이터 엔지니어링이 필요하지 않습니다. Kafka에 계층형 스토리지를 사용해야 하는 이유에 대한 자세한 내용은 을 참조하십시오 <block ref="3c87b0bff8160b787f5bf29d10131d5e" category="inline-link-macro-rx"></block>.</block>
  <block id="911086e7904dbc449b09545eba850304" category="section-title">NetApp StorageGRID를 계층형 스토리지로 선택해야 하는 이유</block>
  <block id="ee6c2a9cd0205695027987ec8da32dfe" category="paragraph">StorageGRID은 NetApp에서 제공하는 업계 최고의 오브젝트 스토리지 플랫폼입니다. StorageGRID은 Amazon S3(Simple Storage Service) API를 비롯한 업계 표준 오브젝트 API를 지원하는 소프트웨어 정의 오브젝트 기반 스토리지 솔루션입니다. StorageGRID는 비정형 데이터를 대규모로 저장 및 관리하여 안전하고 내구성 있는 오브젝트 스토리지를 제공합니다. 콘텐츠가 적절한 위치, 적합한 시간 및 적합한 스토리지 계층에 배치되어 전 세계적으로 분산된 다양한 미디어의 워크플로우를 최적화하고 비용을 줄입니다.</block>
  <block id="5e5ef53b540f19d6746e6645de37cbb4" category="paragraph">StorageGRID의 가장 큰 차별화 요소는 정책 기반 데이터 라이프사이클 관리를 지원하는 ILM(정보 라이프사이클 관리) 정책 엔진입니다. 정책 엔진은 메타데이터를 사용해 수명 주기 동안 데이터가 저장되는 방식을 관리하여 처음에 성능을 최적화하고 데이터 사용 기간에 따라 비용 및 내구성을 자동으로 최적화할 수 있습니다.</block>
  <block id="a7f9d3e4bde145f56bcbec81a6dc2ef3" category="section-title">ContFluent Tiered Storage 활성화</block>
  <block id="a5cb83c3eb7e8757a8f985f8d935e700" category="paragraph">계층형 스토리지의 기본 개념은 데이터 스토리지와 데이터 처리 작업을 분리하는 것입니다. 이와 같은 분리 덕분에 데이터 스토리지 계층과 데이터 처리 계층이 독립적으로 확장하는 것이 훨씬 쉬워졌습니다.</block>
  <block id="e963c7bc15c18e21f60a9969d876e3e8" category="paragraph">Confluent를 위한 계층형 스토리지 솔루션은 두 가지 요소를 고려해야 합니다. 먼저, 목록 작업의 일관성 오류, 간헐적인 개체 가용성 손실 등과 같은 일반적인 개체 저장소의 일관성 및 가용성 속성을 문제를 해결 또는 방지해야 합니다. 두 번째로, 이 제품은 계층형 스토리지와 Kafka의 복제 및 내결함성 모델 간의 상호 작용을 올바르게 처리해야 하며, 이러한 상호 작용에는 좀비 리더가 계속해서 오프셋 범위를 계층화할 수 있는 가능성이 포함됩니다. NetApp 오브젝트 스토리지는 일관된 오브젝트 가용성과 HA 모델을 모두 제공하므로 피로한 스토리지를 계층 오프셋 범위에 사용할 수 있습니다. NetApp 오브젝트 스토리지는 일관된 오브젝트 가용성과 HA 모델을 제공하여 지친 스토리지를 계층 오프셋 범위에 사용할 수 있도록 합니다.</block>
  <block id="104f1daa661d4c74d5bfd4e54946a4f4" category="paragraph">계층형 스토리지를 사용하면 스트리밍 데이터의 지연 시간이 짧은 읽기 및 쓰기 작업에 고성능 플랫폼을 사용할 수 있으며, 처리량이 높은 내역 읽기를 위해 NetApp StorageGRID와 같은 경제적이고 확장 가능한 오브젝트 저장소를 사용할 수도 있습니다. NetApp은 Spark with NetApp 스토리지 컨트롤러 및 세부 정보를 위한 기술 솔루션도 갖추고 있습니다. 다음 그림은 Kafka가 실시간 분석 파이프라인에 어떻게 부합하는지를 보여줍니다.</block>
  <block id="c7e421673ed217d2262c482dc24d0995" category="paragraph"><block ref="c7e421673ed217d2262c482dc24d0995" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66b784e6401c98dcf152747d22976bf7" category="paragraph">다음 그림은 NetApp StorageGRID가 Confluent Kafka의 오브젝트 스토리지 계층으로 적합한 방식을 보여줍니다.</block>
  <block id="f4e981d58b1468737da82402b3cce7f1" category="paragraph"><block ref="f4e981d58b1468737da82402b3cce7f1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c3dbe3ccb3831e313d1d072656fa861" category="inline-link-macro">다음은 솔루션 아키텍처 세부 정보입니다.</block>
  <block id="adcb27f49e58936cf868bc3cc2726dd7" category="paragraph"><block ref="adcb27f49e58936cf868bc3cc2726dd7" category="inline-link-macro-rx"></block></block>
  <block id="663d826f2d39c93c218bb619244537b3" category="summary">NetApp StorageGRID의 계층형 스토리지를 위해 Kafka와 Confluent Platform으로 인증을 수행했습니다.</block>
  <block id="5436c2a5438619c1dbe68551a8297494" category="doc">Confluent 검증</block>
  <block id="0a569fd987814c0464300156b2e26414" category="paragraph"><block ref="0a569fd987814c0464300156b2e26414" category="inline-link-macro-rx"></block></block>
  <block id="0c112d1616223eaa5f0484a9499d587f" category="paragraph">NetApp StorageGRID에서 Confluent Platform 6.2 계층형 스토리지를 사용하여 검증을 수행했습니다. NetApp과 Confluent 팀은 이 검증을 함께 수행하여 검증에 필요한 테스트 사례를 실행했습니다.</block>
  <block id="ba5b5ff137c16b8859e6ac90b55d071c" category="section-title">Confluent 플랫폼 설정</block>
  <block id="d8802fa9749bdc5ddc844a1f86c9461d" category="paragraph">검증을 위해 다음 설정을 사용했습니다.</block>
  <block id="7b5948d7f6534813c3989b6697841566" category="paragraph">검증을 위해 3대의 zookeers, 5개의 브로커, 5개의 테스트 스크립트 실행 서버, 256GB RAM이 장착된 명명된 도구 서버, 16개의 CPU를 사용했습니다. NetApp 스토리지의 경우 SGF6024s 4개로 SG1000 로드 밸런서와 함께 StorageGRID를 사용했습니다. 스토리지와 브로커는 100GbE 연결을 통해 연결되었습니다.</block>
  <block id="e9f968cb8cc147519310d7290c28f99d" category="paragraph">다음 그림은 Confluent 확인에 사용되는 구성의 네트워크 토폴로지를 보여줍니다.</block>
  <block id="82dc8b1c8f1a6f08261f17b764e74bf4" category="paragraph"><block ref="82dc8b1c8f1a6f08261f17b764e74bf4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8a85abadadde0e32bd269b5667b6226" category="paragraph">도구 서버는 Confluent 노드에 요청을 보내는 애플리케이션 클라이언트의 역할을 합니다.</block>
  <block id="a0b3c1e592076debe73b163734ed8e2b" category="section-title">Confluent 계층형 스토리지 구성</block>
  <block id="81082f7982ae1144f7662efde7446f1f" category="paragraph">계층화된 스토리지 구성에는 Kafka에서 다음 매개 변수가 필요합니다.</block>
  <block id="c78850251892556ff1c48a03b16cf1bf" category="paragraph">검증을 위해 StorageGRID를 HTTP 프로토콜과 함께 사용했지만 HTTPS도 작동합니다. 액세스 키와 비밀 키는 confluent.tier.s3.cred.file.path 매개 변수에 제공된 파일 이름에 저장됩니다.</block>
  <block id="4e19f24a6f1bb774911253be7f9d487f" category="section-title">NetApp 오브젝트 스토리지 - StorageGRID</block>
  <block id="2d5dff5c754356b277b47604fee26e79" category="paragraph">StorageGRID에서 정화를 위해 단일 사이트 구성을 구성했습니다.</block>
  <block id="1ba0fc45020f864c62328d58df2351ef" category="paragraph"><block ref="1ba0fc45020f864c62328d58df2351ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829026ce89cdb29d9f59599cb2244752" category="section-title">검증 테스트</block>
  <block id="f97246b7185276a5fe91aba0dd7311ae" category="paragraph">검증을 위해 다음 5가지 테스트 사례를 완료했습니다. 이러한 검사는 Trogor 프레임워크에서 실행됩니다. 첫 번째 두 테스트는 기능 테스트이고 나머지 세 가지는 성능 테스트입니다.</block>
  <block id="4c5791ce7d906a384ff35dab9f635d41" category="section-title">객체 저장소 정확도 테스트</block>
  <block id="a0a36b11d315565a64a50eb2a0ed8c35" category="paragraph">이 테스트에서는 오브젝트 저장소 API의 모든 기본 작업(예: get/put/delete)이 계층적 스토리지의 요구에 따라 잘 작동하는지 여부를 확인합니다. 모든 오브젝트 저장소 서비스가 다음 테스트보다 먼저 통과해야 하는 기본 테스트입니다. 통과 또는 실패한 단정적인 테스트입니다.</block>
  <block id="7cf5be835d50b9e5b598a4363e5a1310" category="section-title">계층화 기능 정확도 테스트</block>
  <block id="afca9446d059f239c7c73699ec215b35" category="paragraph">이 테스트에서는 종단 간 계층형 스토리지 기능이 통과 또는 실패한 적극적 테스트와 잘 작동하는지 여부를 확인합니다. 이 테스트에서는 기본적으로 계층화를 사용하도록 구성되고 핫 세트 크기가 크게 줄어든 테스트 항목을 생성합니다. 새로 만든 테스트 항목으로 이벤트 스트림을 생성하고 브로커가 세그먼트를 개체 저장소에 아카이빙할 때까지 대기한 다음 이벤트 스트림을 사용하여 소비된 스트림이 생성된 스트림과 일치하는지 확인합니다. 이벤트 스트림에 생성되는 메시지 수를 구성할 수 있으므로 테스트 요구에 따라 충분한 크기의 워크로드를 생성할 수 있습니다. 줄어든 핫세트 크기는 소비자가 활성 세그먼트 밖에 있는 페치를 개체 저장소에서만 제공되도록 합니다. 이렇게 하면 읽기에 대한 개체 저장소의 정확성을 테스트하는 데 도움이 됩니다. 객체 저장소 결함 주입 여부와 관계없이 이 테스트를 수행했습니다. StorageGRID의 노드 중 하나에서 서비스 관리자 서비스를 중지하고 엔드 투 엔드 기능이 오브젝트 스토리지에서 작동하는지 확인하여 노드 장애를 시뮬레이션했습니다.</block>
  <block id="88960bc44aa73a667c97d6168a27332a" category="section-title">계층 가져오기 벤치마크</block>
  <block id="777c3235446f781652127bde532a7d6e" category="paragraph">이 테스트에서는 계층형 오브젝트 스토리지의 읽기 성능을 검증하고 벤치마크에 의해 생성된 세그먼트에서 과부하된 읽기 요청 범위를 검사했습니다. 이 벤치마크에서 Confluent는 계층 가져오기 요청을 처리하기 위해 사용자 지정 클라이언트를 개발했습니다.</block>
  <block id="07b15abc12bd3f43d57ebd95fce23917" category="section-title">생산 - 워크로드 벤치마크 소비</block>
  <block id="82ac7c284d524e3dba7699721633a674" category="paragraph">이 테스트에서는 세그먼트 아카이브를 통해 오브젝트 저장소에서 쓰기 워크로드를 간접적으로 생성했습니다. 소비자 그룹이 세그먼트를 가져올 때 객체 스토리지에서 읽기 워크로드(세그먼트 읽기)가 생성되었습니다. 이 워크로드는 테스트 스크립트에 의해 생성되었습니다. 이 테스트에서는 오브젝트 저장소에서 병렬 스레드의 읽기 및 쓰기 성능을 확인했습니다. 계층화 기능 정확도 테스트에서 보았듯이, 객체 저장소 결함 주입을 사용하여 테스트했으며 포함하지 않았습니다.</block>
  <block id="fc8cd6782366e38a4c0191fff79825b0" category="section-title">보존 워크로드 벤치마크</block>
  <block id="c51c74edfaecd19ad2258d1dd18ba5d5" category="paragraph">이 테스트에서는 무거운 주제 보존 워크로드 하에서 오브젝트 저장소의 삭제 성능을 검사했습니다. 보존 워크로드는 테스트 주제와 동시에 많은 메시지를 생성하는 테스트 스크립트를 사용하여 생성되었습니다. 테스트 주제는 공격적인 크기 기반 및 시간 기반 보존 설정으로 구성되었으며, 이로 인해 이벤트 스트림이 개체 저장소에서 지속적으로 제거됩니다. 그런 다음 세그먼트가 아카이브되었습니다. 이로 인해 오브젝트 저장소 삭제 작업의 수행 중개 및 컬렉션에 의해 오브젝트 저장소에서 많은 삭제가 수행되었습니다.</block>
  <block id="b2ce010f52b23eb40ba6b51b92837acb" category="inline-link-macro">다음: 확장성의 성능 테스트.</block>
  <block id="4a94c930da0f9f0974ad6d4f2d17726b" category="paragraph"><block ref="4a94c930da0f9f0974ad6d4f2d17726b" category="inline-link-macro-rx"></block></block>
  <block id="cedd54d52b90b58fb9615e956db81629" category="summary">본 문서는 NetApp AFF 및 FAS 스토리지 시스템, NetApp Cloud Volumes ONTAP, NetApp 연결형 스토리지, Spark 및 Hadoop용 NetApp FlexClone 기술을 사용하는 하이브리드 클라우드 데이터 솔루션에 대해 설명합니다. 이러한 솔루션 아키텍처를 통해 고객은 자신의 환경에 적합한 데이터 보호 솔루션을 선택할 수 있습니다. NetApp은 고객과의 상호 작용 및 비즈니스 사용 사례를 기반으로 이러한 솔루션을 설계했습니다.</block>
  <block id="6a604a825549ac87ecf8a00412ee6365" category="doc">TR-4657: NetApp 하이브리드 클라우드 데이터 솔루션 - 고객 사용 사례를 기반으로 Spark 및 Hadoop</block>
  <block id="71932d00608c3a9fe13a866ab35227f6" category="paragraph">NetApp의 Karthikeyan Nagalingam 및 Sathish Thyagarajan</block>
  <block id="8b6b60ca3f35331d22d686d9c4e12871" category="paragraph">본 문서는 NetApp AFF 및 FAS 스토리지 시스템, NetApp Cloud Volumes ONTAP, NetApp 연결형 스토리지, Spark 및 Hadoop용 NetApp FlexClone 기술을 사용하는 하이브리드 클라우드 데이터 솔루션에 대해 설명합니다. 이러한 솔루션 아키텍처를 통해 고객은 자신의 환경에 적합한 데이터 보호 솔루션을 선택할 수 있습니다. NetApp은 고객과의 상호 작용 및 비즈니스 사용 사례를 기반으로 이러한 솔루션을 설계했습니다. 이 문서에서는 다음과 같은 자세한 정보를 제공합니다.</block>
  <block id="d928ac205302ed3d60386e2a4759c6d6" category="list-text">Spark 및 Hadoop 환경 및 고객의 당면 과제를 해결하기 위해 데이터 보호가 필요한 이유</block>
  <block id="4444991e618ed955b12fdbcf746ad762" category="list-text">NetApp 비전 및 구성 요소와 서비스를 기반으로 하는 Data Fabric</block>
  <block id="018b3e5bb8ca92450618b4f5ff9719f7" category="list-text">이러한 구성 요소를 사용하여 유연한 데이터 보호 워크플로우를 구축하는 방법</block>
  <block id="30b68051de2b69f7d6ab186bed865f7c" category="list-text">실제 고객 사용 사례를 기반으로 한 여러 아키텍처의 장단점을 설명합니다. 각 활용 사례는 다음과 같은 구성 요소를 제공합니다.</block>
  <block id="acf055fa7efae33ce06471f448ae1267" category="list-text">고객 시나리오</block>
  <block id="2a9dbfa4b74c53d7304fc8b79a1874d3" category="list-text">해결하세요</block>
  <block id="cb9825c3c7619f7000c8452d9005aa5b" category="list-text">솔루션 요약</block>
  <block id="40300466f60ef41f731d7fd45a1024e2" category="section-title">Hadoop 데이터 보호를 선택해야 하는 이유</block>
  <block id="d54234515a0cb2905eb88ccb03d85491" category="paragraph">Hadoop 및 Spark 환경에서는 다음과 같은 문제를 해결해야 합니다.</block>
  <block id="9ed257b8e8a9504946fcf430ea2e12e3" category="list-text">* 소프트웨어 또는 사용자 오류. * Hadoop 데이터 작업을 수행하는 동안 소프트웨어 업데이트에 사람의 실수가 발생할 수 있으며, 이로 인해 작업에 예상치 못한 결과가 발생할 수 있습니다. 이 경우 오류나 부당한 결과를 방지하려면 데이터를 보호해야 합니다. 예를 들어, 소프트웨어 업데이트가 제대로 실행되지 않아 트래픽 신호 데이터를 일반 텍스트 형식으로 제대로 분석하지 못하는 새로운 기능이 추가되었습니다. 이 소프트웨어는 JSON 및 기타 비 텍스트 파일 형식을 분석하여 실시간 트래픽 제어 분석 시스템을 통해 데이터 포인트가 누락된 예측 결과를 생성합니다. 이 상황은 출력 결함을 초래하여 교통 신호에서 사고를 일으킬 수 있습니다. 데이터 보호는 이전 작업 중인 응용 프로그램 버전으로 빠르게 롤백할 수 있는 기능을 제공하여 이 문제를 해결할 수 있습니다.</block>
  <block id="38b145294d087c4d733df994e6a7b6c1" category="list-text">* 규모와 확장성 * 데이터 소스와 볼륨의 수가 계속 증가함에 따라 분석 데이터의 크기가 매일 증가하고 있습니다. 소셜 미디어, 모바일 앱, 데이터 분석 및 클라우드 컴퓨팅 플랫폼은 현재 빅데이터 시장의 주요 데이터 소스로서 빠르게 증가하고 있으며, 따라서 정확한 데이터 운영을 위해 데이터를 보호해야 합니다.</block>
  <block id="80908b4b31d37977701d3694fbc636ac" category="list-text">* Hadoop의 기본 데이터 보호. * Hadoop에는 데이터를 보호하는 기본 명령이 있지만 이 명령은 백업 중에 데이터의 일관성을 제공하지 않습니다. 디렉토리 레벨 백업만 지원합니다. Hadoop에서 생성된 스냅샷은 읽기 전용이며 백업 데이터를 직접 재사용하는 데 사용할 수 없습니다.</block>
  <block id="e664ca405ed3e90fecf2e085985fe24c" category="section-title">Hadoop 및 Spark 고객의 데이터 보호 당면 과제</block>
  <block id="c2d49a2ee903d6d86976c3618079a61d" category="paragraph">Hadoop 및 Spark 고객의 일반적인 과제는 데이터 보호 중에 운영 클러스터의 성능에 부정적인 영향을 주지 않고 백업 시간을 단축하고 백업 안정성을 높이는 것입니다.</block>
  <block id="8d54bea5cb89e665d1a703529f703765" category="paragraph">또한 고객은 RPO(복구 시점 목표) 및 RTO(복구 시간 목표) 다운타임을 최소화하고 사내 및 클라우드 기반 재해 복구 사이트를 제어하여 비즈니스 연속성을 최적화해야 합니다. 이 제어 기능은 일반적으로 엔터프라이즈급 관리 툴을 사용하는 데서 비롯됩니다.</block>
  <block id="042be4d2813fd31d6b49e6eeaa1a42c3" category="paragraph">Hadoop과 Spark 환경은 데이터 볼륨이 엄청나며 증가하기 때문에 복잡합니다. 하지만 데이터가 도착하는 속도는 점점 증가하고 있습니다. 이 시나리오를 통해 소스 데이터에서 효율적인 최신 DevTest 및 QA 환경을 빠르게 생성하기가 어렵습니다. NetApp은 이러한 과제를 인식하고 이 백서에 제공된 솔루션을 제공합니다.</block>
  <block id="1f60e9ce60971dc2129b30c8820ff343" category="inline-link-macro">다음 단계로: NetApp에서 제공하는 빅데이터 아키텍처 관련 Data Fabric</block>
  <block id="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="paragraph"><block ref="b8d3f7ee1ffc74c6a96c88a193dc6f1e" category="inline-link-macro-rx"></block></block>
  <block id="69efde21ccf40f1dda4d665f81bacefe" category="summary">이 시나리오에서는 NetApp NFS 스토리지 솔루션을 사용하여 대형 금융 서비스 및 투자 은행의 분석 플랫폼을 현대화함으로써 자산 관리 및 정량적 사업부의 투자 위험 및 파생물 분석에 상당한 개선을 이루었습니다.</block>
  <block id="0158648474e8dffab94ca58af2257b92" category="doc">사용 사례 5: 분석 워크로드 가속화</block>
  <block id="c8ea1eda8e0ac121148ac86dee9649a7" category="inline-link-macro">이전: 사용 사례 4 - 데이터 보호 및 멀티 클라우드 연결</block>
  <block id="87fb2a1eb3f12014af6e5dd36ba66e5e" category="paragraph"><block ref="87fb2a1eb3f12014af6e5dd36ba66e5e" category="inline-link-macro-rx"></block></block>
  <block id="24b0e878b8196875cd088397ac8312a9" category="paragraph">고객의 기존 환경에서 분석 플랫폼에 사용되는 Hadoop 인프라는 Hadoop 서버의 내부 스토리지를 활용했습니다. JBOD 환경의 독점 특성으로 인해 조직 내의 많은 내부 고객은 실시간 데이터의 반복 샘플에 의존하는 시뮬레이션인 Monte Carlo 정량 모델을 활용할 수 없었습니다. 시장 이동이 불확실성의 영향을 이해하는 데 있어 최적화되지 않은 능력은 정량적 자산 관리 사업부에 비호의적으로 작용했습니다.</block>
  <block id="788ab145281501314f18747a0ab1eaea" category="paragraph">이 은행의 정량적 사업부는 정확하고 시기 적절한 예측을 얻기 위한 효율적인 예측 방법을 원했습니다. 이를 위해 IT 팀에서는 인프라를 현대화하고, 기존 I/O 대기 시간을 줄이며, Hadoop, Spark와 같은 분석 애플리케이션의 성능을 개선하여 투자 모델을 효율적으로 시뮬레이션하고, 잠재적인 이익을 측정하고, 위험을 분석해야 한다는 사실을 깨달았습니다.</block>
  <block id="5ff37557b096819452a25d129a312360" category="paragraph">고객은 기존 Spark 솔루션에 대한 JBOD를 가지고 있었습니다. 그런 다음 NetApp ONTAP, NetApp StorageGRID 및 MinIO Gateway to NFS를 활용하여 잠재적인 이익과 위험을 평가하는 투자 모델에 대한 시뮬레이션 및 분석을 실행하는 금융 그룹의 정량적 대기 시간을 줄였습니다. 이 이미지는 NetApp 스토리지의 Spark 솔루션을 보여줍니다.</block>
  <block id="095ba715431845442ef6bf2f4283ad1c" category="paragraph"><block ref="095ba715431845442ef6bf2f4283ad1c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3a052314babbb25c995c7b6b2b18d04" category="paragraph">위 그림과 같이 StorageGRID A800, A700 시스템 및 AFF는 Spark가 있는 6노드 Hadoop 클러스터 및 데이터 분석 작업을 위한 YARN 및 Hive 메타데이터 서비스의 NFS 및 S3 프로토콜을 통해 쪽모이 세공 파일에 액세스하기 위해 구축되었습니다.</block>
  <block id="bc12facb8aa0a34db56b00fdbc21c351" category="paragraph">고객의 기존 환경에서 DAS(직접 연결 스토리지) 솔루션을 사용할 경우 컴퓨팅과 스토리지를 독립적으로 확장한다는 단점이 있었습니다. Spark용 NetApp ONTAP 솔루션을 통해 은행의 재무 분석 사업부에서 스토리지를 컴퓨팅에서 분리하여 필요에 따라 인프라 리소스를 보다 효율적으로 제공할 수 있게 되었습니다.</block>
  <block id="582c4aa65d1bd005ddc785db8b807fca" category="paragraph">NFS와 함께 ONTAP를 사용함으로써 컴퓨팅 서버 CPU는 Spark SQL 작업에 거의 전적으로 활용되었고 I/O 대기 시간이 약 70% 감소되어 스파크 워크로드에 더 나은 컴퓨팅 성능과 성능 향상을 제공했습니다. 또한 CPU 활용률을 높임으로써 고객이 GPUDirect와 같은 GPU를 활용하여 플랫폼을 더욱 현대화할 수 있도록 했습니다. 또한 StorageGRID는 스파크 워크로드를 위한 저렴한 스토리지 옵션을 제공하며 MinIO 게이트웨이는 S3 프로토콜을 통해 NFS 데이터에 대한 안전한 액세스를 제공합니다. 클라우드의 데이터에 대해 NetApp은 Cloud Volumes ONTAP, Azure NetApp Files 및 NetApp Cloud Volumes Service를 권장합니다.</block>
  <block id="6e362ed6e741056d737b93021ab2f3f9" category="paragraph"><block ref="6e362ed6e741056d737b93021ab2f3f9" category="inline-link-macro-rx"></block></block>
  <block id="7747c0c1913888384e25d3a99b247187" category="summary">이 문서에서는 Confluent Kafka 인증 테스트, 성능 결과, 조정, Kafka 커넥터 및 자체 재조정 기능을 포함하여 NetApp 스토리지에서 Kafka를 사용하는 모범 사례 지침을 제공합니다.</block>
  <block id="0c7a4422707cf3f11c73c66ea0d5d215" category="inline-link-macro">이전: 사이징.</block>
  <block id="f902aefc255b4eb6b31c283ad42816de" category="paragraph"><block ref="f902aefc255b4eb6b31c283ad42816de" category="inline-link-macro-rx"></block></block>
  <block id="d17096a4e247d84eba8c623e8df7bb38" category="paragraph">이 문서에서는 검증 테스트, 계층형 스토리지 성능 결과, 튜닝, Confluent S3 커넥터 및 셀프 밸런싱 기능을 포함하여 NetApp 스토리지와 함께 Contuent Tiered Storage를 사용하기 위한 모범 사례 지침을 제공합니다. ILM 정책, 검증을 위한 다양한 성능 테스트 및 산업 표준 S3 API를 통한 유창한 성능을 고려할 때 NetApp StorageGRID 오브젝트 스토리지는 유창한 계층형 스토리지를 위한 최적의 선택입니다.</block>
  <block id="06bf7cdac46014ea728ea73ea94f29ed" category="list-text">아파치 카프카란</block>
  <block id="9411b66537bb375699af4bbf90c682d3" category="inline-link"><block ref="9411b66537bb375699af4bbf90c682d3" category="inline-link-rx"></block></block>
  <block id="a2b6e6fe4a206b71df85cc00f128ef0c" category="paragraph"><block ref="a2b6e6fe4a206b71df85cc00f128ef0c" category="inline-link-rx"></block></block>
  <block id="8f74869149421fffb3c139e146a83d10" category="list-text">S3 싱크 매개 변수 세부 정보</block>
  <block id="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link"><block ref="015ac233ccf3051a25abbbd7f56a39e9" category="inline-link-rx"></block></block>
  <block id="26f8d9a8c1177c17a089f9a5c18628f4" category="paragraph"><block ref="26f8d9a8c1177c17a089f9a5c18628f4" category="inline-link-rx"></block></block>
  <block id="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link"><block ref="14bdc4a7a7b448924b5fe68d2a843973" category="inline-link-rx"></block></block>
  <block id="c001bbfb62e45f662fe697182fa82240" category="paragraph"><block ref="c001bbfb62e45f662fe697182fa82240" category="inline-link-rx"></block></block>
  <block id="4f6236b021284cc85e87f1145d34e74b" category="list-text">Confluent 플랫폼의 무한 스토리지</block>
  <block id="43a9697f317e04e185bacb99ee76b7fb" category="inline-link"><block ref="43a9697f317e04e185bacb99ee76b7fb" category="inline-link-rx"></block></block>
  <block id="a156036c426dcb5d87fc97e5eacdc183" category="paragraph"><block ref="a156036c426dcb5d87fc97e5eacdc183" category="inline-link-rx"></block></block>
  <block id="a53b0667612f6e25b1d426569d860cac" category="list-text">ContFluent Tiered Storage - 모범 사례 및 사이징</block>
  <block id="a2e63818a36c6308885f4c0109e99b56" category="inline-link"><block ref="a2e63818a36c6308885f4c0109e99b56" category="inline-link-rx"></block></block>
  <block id="0c2ea24bb29ad03d1f43efe9a08c7da0" category="paragraph"><block ref="0c2ea24bb29ad03d1f43efe9a08c7da0" category="inline-link-rx"></block></block>
  <block id="ee764f7614a20c6500a54f1abc769567" category="list-text">Confluent 플랫폼용 Amazon S3 싱크 커넥터</block>
  <block id="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link"><block ref="e1ca3ac3d812689b98c4cf79bf597e4b" category="inline-link-rx"></block></block>
  <block id="ca80d8d3004f0fce6bc195b6b43ccaeb" category="paragraph"><block ref="ca80d8d3004f0fce6bc195b6b43ccaeb" category="inline-link-rx"></block></block>
  <block id="5cbad2383ea03d52c73feba910ccb4a9" category="list-text">Kafka 사이징</block>
  <block id="7a8c563c1b96991ca597759bb447eb65" category="inline-link"><block ref="7a8c563c1b96991ca597759bb447eb65" category="inline-link-rx"></block></block>
  <block id="a2d2c0cad325abb54e33c688d54ce125" category="paragraph"><block ref="a2d2c0cad325abb54e33c688d54ce125" category="inline-link-rx"></block></block>
  <block id="989772944133ad8cd766bbdfe91cb365" category="list-text">StorageGRID 사이징</block>
  <block id="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link"><block ref="a81a58c7d51f312f40511a68d8e0d40c" category="inline-link-rx"></block></block>
  <block id="1e9dcc0360cfc46d71d6e0c3effa6379" category="paragraph"><block ref="1e9dcc0360cfc46d71d6e0c3effa6379" category="inline-link-rx"></block></block>
  <block id="5f750332aea13a67a316c81c03a35752" category="list-text">Kafka 활용 사례</block>
  <block id="c97a8ddb222f78361f59ac027aa08c70" category="inline-link"><block ref="c97a8ddb222f78361f59ac027aa08c70" category="inline-link-rx"></block></block>
  <block id="58f7c8dd51e4199a8f2caf79409bada1" category="paragraph"><block ref="58f7c8dd51e4199a8f2caf79409bada1" category="inline-link-rx"></block></block>
  <block id="f51439b4d8807e7a73cb24b6f11e16e2" category="list-text">confluent platform 6.0의 자체 균형 조정 Kafka 클러스터</block>
  <block id="866d1bcab8bac705e171a01e8fe2e717" category="inline-link"><block ref="866d1bcab8bac705e171a01e8fe2e717" category="inline-link-rx"></block></block>
  <block id="b6251e175649ca2d0108725f99fc225f" category="paragraph"><block ref="b6251e175649ca2d0108725f99fc225f" category="inline-link-rx"></block></block>
  <block id="aa3c3c6442ddbda62fd0694691e34122" category="inline-link"><block ref="aa3c3c6442ddbda62fd0694691e34122" category="inline-link-rx"></block></block>
  <block id="f7365ec0514100387d644210374998c1" category="paragraph"><block ref="f7365ec0514100387d644210374998c1" category="inline-link-rx"></block></block>
  <block id="a5091aedd97daf7c5a5297fa5d73a469" category="cell">2021년 12월</block>
  <block id="2c755351ada495582a6d9015943de077" category="summary">이 사용 사례에서 고객은 DevTest와 보고 목적으로 동일한 데이터 센터와 원격 위치에서 대량의 분석 데이터를 포함하는 기존 Hadoop 클러스터를 기반으로 새로운 Hadoop/Spark 클러스터를 신속하고 효율적으로 구축해야 합니다.</block>
  <block id="acb2dd720b2161405c8cb1ca6035618b" category="doc">사용 사례 3: 기존 Hadoop 데이터에 대해 DevTest 활성화</block>
  <block id="aeab228f25b5fbe0b00f83117579246e" category="inline-link-macro">이전: 사용 사례 2 - 클라우드에서 사내로 백업 및 재해 복구</block>
  <block id="cf44ed74ea7e07a8e4478e43d9537e07" category="paragraph"><block ref="cf44ed74ea7e07a8e4478e43d9537e07" category="inline-link-macro-rx"></block></block>
  <block id="4e19c1aafa6d3711ae619f7e1621a61e" category="paragraph">이 시나리오에서는 사내 및 재해 복구 위치에 대규모 Hadoop 데이터 레이크를 구축하고 Spark/Hadoop 클러스터를 여러 개 구축했습니다.</block>
  <block id="5768edca640abf2b08dd5ba0e593dcc7" category="list-text">DevTest, QA 또는 동일한 운영 데이터에 액세스해야 하는 기타 목적으로 여러 Hadoop 클러스터를 생성합니다. 여기서 문제는 매우 큰 Hadoop 클러스터를 공간 효율적인 방식으로 여러 번 즉시 클론 복제해야 한다는 것입니다.</block>
  <block id="529c78f9988d342b33707ecaae7d2576" category="list-text">운영 효율성을 위해 Hadoop 데이터를 DevTest 및 보고 팀에 동기화합니다.</block>
  <block id="07178cfd87815398d5079e55c257f96c" category="list-text">운영 클러스터와 새 클러스터 간에 동일한 자격 증명을 사용하여 Hadoop 데이터를 배포합니다.</block>
  <block id="b26eaa756d7ec14dcec5c25d7d9ad6b6" category="list-text">예약된 정책을 사용하여 운영 클러스터에 영향을 주지 않고 QA 클러스터를 효율적으로 생성합니다.</block>
  <block id="6442ec446d11bbd47497299e0ffceed5" category="paragraph">FlexClone 기술은 방금 설명한 요구 사항에 응답하는 데 사용됩니다. FlexClone 기술은 스냅샷 복사본의 읽기/쓰기 복사본입니다. 이 기능은 상위 스냅샷 복사본 데이터에서 데이터를 읽고 새 블록/수정된 블록에 대해 추가 공간만 사용합니다. 빠르고 공간 효율적입니다.</block>
  <block id="51a22383ed7ac5a70a455d81a9bad789" category="paragraph">먼저, NetApp 일관성 그룹을 사용하여 기존 클러스터의 스냅샷 복사본을 생성했습니다.</block>
  <block id="4b481b20e942087b64c5bb7b07d9dca9" category="paragraph">NetApp System Manager 또는 스토리지 관리 프롬프트 내의 Snapshot 복사본 일관성 그룹 스냅샷 복사본은 애플리케이션 정합성이 보장된 그룹 스냅샷 복사본이며, FlexClone 볼륨은 일관성 그룹 스냅샷 복사본을 기반으로 생성됩니다. FlexClone 볼륨이 상위 볼륨의 NFS 엑스포트 정책을 상속한다는 점을 언급하는 것이 좋습니다. 스냅샷 복사본이 생성된 후에는 아래 그림과 같이 DevTest 및 보고를 위해 새 Hadoop 클러스터를 설치해야 합니다. In-Place Analytics Module은 NFS 데이터에 대한 In-Place Analytics Module 사용자 및 그룹 인증을 통해 새 Hadoop 클러스터에서 클론 생성된 NFS 볼륨에 액세스합니다.</block>
  <block id="4c490dfedbcc5a021b8a4c823e337d41" category="paragraph">적절한 액세스 권한을 가지려면 새 클러스터에 현재 위치 분석 모듈 사용자 및 그룹 구성에서 구성된 사용자에 대해 동일한 UID와 GUID가 있어야 합니다.</block>
  <block id="6ee7e035a9c46bb26ee76c40aa671148" category="paragraph">이 이미지는 DevTest용 Hadoop 클러스터를 보여 줍니다.</block>
  <block id="4157075925c8c1518cc71d1d0abab403" category="paragraph"><block ref="4157075925c8c1518cc71d1d0abab403" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e10ad11fd299ee6f161f17d772a78a48" category="inline-link-macro">다음: 사용 사례 4 - 데이터 보호 및 멀티 클라우드 연결</block>
  <block id="8109e574f349ced8f667b9389c9189a4" category="paragraph"><block ref="8109e574f349ced8f667b9389c9189a4" category="inline-link-macro-rx"></block></block>
  <block id="43f0735f931622d61f6837a0eb61f87e" category="summary">이 테스트는 클러스터 토폴로지 변경 또는 불균등한 로드를 기반으로 재조정을 자동화하는 셀프 밸런싱 클러스터 기능을 기반으로 합니다.</block>
  <block id="565b2f1bfcd6857afba2efa000b83759" category="doc">Confluent Self-Balancing 클러스터</block>
  <block id="6dec1258fbcccbfaa7098758abb00055" category="inline-link-macro">이전: Kafka S3 커넥터.</block>
  <block id="6e3bea5fe8473b6e884edafaf7fcf1d4" category="paragraph"><block ref="6e3bea5fe8473b6e884edafaf7fcf1d4" category="inline-link-macro-rx"></block></block>
  <block id="d3975bd93d0a2c24b382774d34b5a963" category="paragraph">이전에 Kafka 클러스터를 관리했다면 수동으로 파티션을 다른 브로커에 재할당하여 클러스터 전체에서 워크로드가 균형 있게 조정되도록 하는 데 따르는 문제에 익숙할 것입니다. Kafka가 대규모로 구축된 조직의 경우 대량의 데이터를 개각하는 일은 까다롭고 번거로우며 위험할 수 있습니다. 특히 클러스터 위에 미션 크리티컬 애플리케이션을 구축하는 경우에는 더욱 그렇습니다. 그러나 가장 작은 Kafka 사용 사례에서도 이 프로세스는 시간이 많이 걸리며 오류가 발생하기 쉽습니다.</block>
  <block id="3c404a9102e2cb3ac7b75fa7ff7a2cb2" category="paragraph">이 실습에서는 Confluent Self-Balancing 클러스터 기능을 테스트하여 클러스터 토폴로지 변경 또는 불균등한 로드를 기반으로 재조정을 자동화했습니다. Confluent rebalance 테스트는 노드 장애 또는 확장 노드에서 브로커 간의 데이터 재조정이 필요한 경우 새 브로커를 추가하는 시간을 측정하는 데 도움이 됩니다. 기존 Kafka 구성에서는 클러스터의 증가에 따라 재조정할 데이터의 양이 증가하지만 계층형 스토리지에서는 소량의 데이터로 제한됩니다. NetApp의 검증을 바탕으로, 계층화된 스토리지에서 재조정은 기존 Kafka 아키텍처에서 몇 초 또는 몇 분 만에 이루어지게 되며, 클러스터의 확장에 따라 선형으로 증가합니다.</block>
  <block id="c9e4cfc44588cc591252c88cad0a3a09" category="paragraph">자체 밸런싱 클러스터에서는 파티션 재조정이 완전히 자동화되어 Kafka의 처리량을 최적화하고 브로커 확장을 가속화하며 대규모 클러스터를 실행하는 데 따른 운영 부담을 줄일 수 있습니다. 안정적인 상태에서 자체 균형 조정 클러스터는 브로커 전체의 데이터 불균형을 모니터링하고 지속적으로 파티션을 재할당하여 클러스터 성능을 최적화합니다. 플랫폼을 확장하거나 축소할 때 자체 균형 조정 클러스터는 새로운 브로커의 존재 또는 이전 브로커의 제거를 자동으로 인식하고 후속 파티션 재할당을 트리거합니다. 이를 통해 브로커를 쉽게 추가하고 해체할 수 있으므로 Kafka 클러스터의 유연성이 근본적으로 높아집니다. 이러한 이점은 수동 개입, 복잡한 수학 또는 재할당을 분할하는 데 수반되는 인적 오류의 위험 없이 제공됩니다. 따라서 데이터 재조정이 훨씬 더 빠르게 완료되고, 클러스터를 지속적으로 감독해야 하는 대신 더 가치 있는 이벤트 스트리밍 프로젝트에 집중할 수 있습니다.</block>
  <block id="cc87abc70119e2ad833c42a865a33659" category="inline-link-macro">다음은 모범 사례 지침입니다.</block>
  <block id="caf8da5a9482899a1495e1e052a4b287" category="paragraph"><block ref="caf8da5a9482899a1495e1e052a4b287" category="inline-link-macro-rx"></block></block>
  <block id="df343d31543826a7505d157cf243c96a" category="summary">Hadoop DistCp는 대규모 클러스터 간 및 클러스터 간 복제에 사용되는 기본 툴입니다. Hadoop DistCp 기본 프로세스는 MapReduce와 같은 Hadoop 네이티브 툴을 사용하여 Hadoop 데이터를 HDFS 소스에서 해당 타겟으로 복제하는 일반적인 백업 워크플로우입니다.</block>
  <block id="2a377dc939cca8cab65101c1869d628d" category="doc">Hadoop 데이터 보호 및 NetApp</block>
  <block id="9445444fbd9e863564ea85ad226c0e80" category="inline-link-macro">이전: NetApp의 빅데이터 아키텍처 기반 Data Fabric</block>
  <block id="e30c587da81860e05b3f8ecfb5b9965b" category="paragraph"><block ref="e30c587da81860e05b3f8ecfb5b9965b" category="inline-link-macro-rx"></block></block>
  <block id="5f45c95989226891db648114a547a6bd" category="paragraph">Hadoop DistCp는 대규모 클러스터 간 및 클러스터 간 복제에 사용되는 기본 툴입니다. 아래 그림에 표시된 Hadoop DistCp 기본 프로세스는 MapReduce와 같은 Hadoop 기본 툴을 사용하여 HDFS 소스에서 해당 타겟으로 Hadoop 데이터를 복제하는 일반적인 백업 워크플로우입니다. NetApp NFS 직접 액세스를 통해 고객은 NFS를 Hadoop DistCp 툴의 타겟 타겟으로 설정하여 MapReduce를 통해 HDFS 소스에서 NFS 공유로 데이터를 복사할 수 있습니다. NetApp NFS 직접 액세스는 DistCp 툴을 위한 NFS 드라이버 역할을 합니다.</block>
  <block id="6369c8cb38b142174d2f84d12d2f0420" category="paragraph"><block ref="6369c8cb38b142174d2f84d12d2f0420" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4849340a20db94ed712aca71c30b915" category="inline-link-macro">다음: Hadoop 데이터 보호 활용 사례 개요</block>
  <block id="817c6593a9a8efc031ec597b5d11d605" category="paragraph"><block ref="817c6593a9a8efc031ec597b5d11d605" category="inline-link-macro-rx"></block></block>
  <block id="35f99fa939062899487754f637210a25" category="summary">이 섹션에서는 Confluent 인증에 사용되는 하드웨어 및 소프트웨어에 대해 다룹니다. 이 정보는 NetApp 스토리지를 사용하는 Kafka 구축에 적용할 수 있습니다.</block>
  <block id="92672a7a2b909945fbfa9f44f057c7a1" category="doc">사이징</block>
  <block id="5ffdfbbb428796f516e072e038d107b0" category="inline-link-macro">이전: 모범 사례 지침.</block>
  <block id="49575973ec85e64724d2a45d401f32b3" category="paragraph"><block ref="49575973ec85e64724d2a45d401f32b3" category="inline-link-macro-rx"></block></block>
  <block id="faa5cf9412df3e7266db15b6f1a5070d" category="paragraph">Kafka 사이징은 단순, 세분화, 역방향 및 파티션의 4가지 구성 모드로 수행할 수 있습니다.</block>
  <block id="1fbb1e3943c2c6c560247ac8f9289780" category="section-title">단순함</block>
  <block id="580c6adb23970405f45409b06eb3ba39" category="paragraph">단순 모드는 최초 Apache Kafka 사용자 또는 초기 상태 사용 사례에 적합합니다. 이 모드에서는 처리량 MBps, 읽기 팬아웃, 보존 및 리소스 사용률(기본값 60%)과 같은 요구 사항을 제공합니다. 또한 온프레미스(베어 메탈, VMware, Kubernetes 또는 OpenStack) 또는 클라우드와 같은 환경에 진입할 수 있습니다. 이 정보를 바탕으로 Kafka 클러스터의 크기를 조정하면 브로커, zookeeper, Apache Kafka 연결 작업자, 스키마 레지스트리, REST 프록시, ksqlDB 및 Confluorent 제어 센터에 필요한 서버 수가 제공됩니다.</block>
  <block id="ae20e37661048a8d6cd37c4dbacac985" category="paragraph">계층형 스토리지의 경우 Kafka 클러스터의 크기를 조정할 수 있는 세분화된 구성 모드를 고려해 보십시오. 세밀한 모드는 숙련된 Apache Kafka 사용자나 잘 정의된 사용 사례에 적합합니다. 이 섹션에서는 생산자, 스트림 프로세서 및 소비자를 위한 크기를 조정하는 방법에 대해 설명합니다.</block>
  <block id="40d2d6f5a1dfde1a3b5ba2a70377fa0f" category="section-title">프로듀서</block>
  <block id="05318fa579b7e76a65531afd94250ed3" category="paragraph">Apache Kafka의 생산자(예: 네이티브 클라이언트, REST 프록시 또는 Kafka 커넥터)를 설명하기 위해 다음 정보를 제공합니다.</block>
  <block id="91be21e4458c6c8f0d6f61c307faf194" category="list-text">* 이름. * Spark.</block>
  <block id="0ae6d6b48753e01bf1ae73bb86ee6276" category="list-text">* Producer type. * 응용 프로그램 또는 서비스, 프록시(RDBMS, MQTT, 기타) 및 기존 데이터베이스(RDBMS, NoSQL, 기타). "모름"을 선택할 수도 있습니다.</block>
  <block id="3fd4bc385cb0a0f62ae4183f316ff707" category="list-text">* 초당 이벤트 수 평균 처리량 * (예: 1,000,000).</block>
  <block id="14ec4c2c8c9edf10c6aeefaf27f1f713" category="list-text">* 최대 처리량 * 초당 이벤트 수(예: 4,000,000).</block>
  <block id="b4672ddde5cb9c30e0e682084a411123" category="list-text">* 평균 메시지 크기. * (바이트), 압축되지 않음(예: 최대 1MB, 1000).</block>
  <block id="dd6d45bc2ad71619bde2260f1776e9b2" category="list-text">* 메시지 형식. * 옵션은 Avro, JSON, 프로토콜 버퍼, 바이너리, 텍스트, “잘 모르겠군요.” 및 기타.</block>
  <block id="b26274df5f3f47d18e40ee961fa8c5b5" category="list-text">* 복제 계수. * 옵션은 1, 2, 3(Confluent recommendation), 4, 5, 또는 6.</block>
  <block id="6320400b940be83033b0ce5ea91a3799" category="list-text">* 보존 시간. * 1일(예:) 데이터를 Apache Kafka에 얼마나 오랫동안 저장하기를 원하십니까? 무한 시간 동안 임의의 단위로 -1을 입력합니다. 이 계산기는 보존 기간이 10년으로 무한 경우를 가정합니다.</block>
  <block id="eb46bfc819d70448200241a8f1efec72" category="list-text">"Enable Tiered Storage to Decrease Broker Count and Allow for Infinite Storage?" 확인란을 선택합니다.</block>
  <block id="d66063041931961a7565ee71f7a7dd67" category="list-text">계층형 스토리지를 사용하는 경우 보존 필드는 브로커에 로컬로 저장된 데이터의 핫 세트를 제어합니다. 아카이브 보존 필드는 아카이브 오브젝트 스토리지에 데이터가 저장되는 기간을 제어합니다.</block>
  <block id="13bc2bec2c4039bad2d63b4ccf9611d4" category="list-text">* 아카이브 스토리지 보존. * 1년(예:) 아카이브 스토리지에 데이터를 얼마나 오랫동안 저장하려는 경우 무한 기간 동안 임의의 단위로 -1을 입력합니다. 이 계산기는 무한 보존을 위해 10년을 유지하는 것으로 가정합니다.</block>
  <block id="841d5d94c8cc645b8a35f0b58d3d5c6d" category="list-text">* Growth Multiplier. * 1(예:) 이 매개 변수의 값이 현재 처리량을 기반으로 하는 경우 1로 설정합니다. 추가 성장에 따라 크기를 조정하려면 이 매개 변수를 성장 배수로 설정합니다.</block>
  <block id="5f044353fac0e72b8b68a9608cdfea2d" category="list-text">* 생산자 인스턴스 수. * 10(예:) 얼마나 많은 프로듀서 인스턴스가 실행됩니까? 이 입력은 CPU 부하를 사이징 계산에 통합하기 위해 필요합니다. 빈 값은 CPU 로드가 계산에 포함되지 않았음을 나타냅니다.</block>
  <block id="585e13820ff765aec3c094fbb66fb358" category="paragraph">이 예제 입력에 따라 크기를 조정하면 생산자에 다음과 같은 영향을 줍니다.</block>
  <block id="5504abde59477d70ee34b7c970af3ed2" category="list-text">압축되지 않은 바이트의 평균 처리량: 1Gbps. 압축되지 않은 바이트 단위의 최대 처리량: 4Gbps. 압축된 바이트의 평균 처리량: 400Mbps 압축된 바이트 단위의 최대 처리량: 1.6GBps. 이 값은 기본 60% 압축률을 기반으로 합니다(이 값은 변경할 수 있음).</block>
  <block id="fe685c6164262035f3c0407347a3d38d" category="inline-link-macro"><block ref="fe685c6164262035f3c0407347a3d38d" category="inline-link-rx"></block></block>
  <block id="d6730cec7284a7856088b8a49563caef" category="list-text">필요한 총 온브로커 핫 세트 스토리지 수: 31,104TB(복제 포함), 압축. 총 비브로커 아카이브 스토리지 필요: 378,432TB, 압축. 사용 <block ref="e132e1b42fc350f637835189d38d8bdf" category="inline-link-macro-rx"></block> StorageGRID 사이징:</block>
  <block id="65541f1c1daa682e605090dda4f5581b" category="paragraph">스트림 프로세서는 아파치 Kafka로부터 데이터를 소비하고 아파치 Kafka로 다시 생산하는 애플리케이션 또는 서비스를 설명해야 합니다. 대부분의 경우 ksqlDB 또는 Kafka 스트림에 빌드됩니다.</block>
  <block id="47bf3a39e68a8e88ad9fff34b58afc0a" category="list-text">* 이름. * Spark streamer.</block>
  <block id="23f4b8037342e7943a6f549d7868281e" category="list-text">* 처리 시간. * 이 프로세서는 단일 메시지를 처리하는 데 얼마나 걸립니까?</block>
  <block id="0d4a13e2166384d926575e139fe3c68c" category="list-text">1ms(단순한 상태 비저장 변환) [예], 10ms(Stateful 인메모리 작업).</block>
  <block id="a1d2bac0d8ed78c0ce6bb941328bc680" category="list-text">100ms(stateful 네트워크 또는 디스크 작동), 1000ms(타사 REST 호출)</block>
  <block id="8b74c5757b588cdfea993715c0ce3b58" category="list-text">이 매개 변수를 벤치마킹하고 시간이 얼마나 걸리는지 정확히 알고 있습니다.</block>
  <block id="df8cd4e4488e4a8198132e46fc2beec9" category="list-text">* 출력 보존. * 1일(예) 스트림 프로세서는 Apache Kafka로 출력을 다시 생성합니다. 이 출력 데이터를 Apache Kafka에 얼마나 오랫동안 저장하기를 원하십니까? 무한 기간 동안 임의의 단위로 -1을 입력합니다.</block>
  <block id="108b072da5b6fab64d55b4f1d69690d4" category="list-text">"계층 스토리지를 사용하여 브로커 수를 줄이고 무한 확장 스토리지를 허용하시겠습니까?" 확인란을 선택합니다.</block>
  <block id="c4462b25651379530a9eea9b2b478755" category="list-text">* 아카이브 스토리지 보존. * 1년(예:) 아카이브 스토리지에 데이터를 얼마나 오랫동안 저장하려는 경우 무한 기간 동안 임의의 단위로 -1을 입력합니다. 이 계산기는 무한 보존을 위해 10년을 유지하는 것으로 가정합니다.</block>
  <block id="6507507d73f33bc3d1077b4454d9d3dd" category="list-text">* 출력 통과 백분율. * 100(예:) 스트림 프로세서는 Apache Kafka로 출력을 다시 생성합니다. Apache Kafka로 다시 출력되는 인바운드 처리량의 비율은 얼마입니까? 예를 들어, 인바운드 처리량이 20Mbps이고 이 값이 10이면 출력 처리량은 2Mbps입니다.</block>
  <block id="d1a6a4732f959b58cd8c77edcf10b31b" category="list-text">어떤 응용 프로그램에서 이 정보를 읽습니까? 프로듀서 유형 기반 사이징에 사용되는 이름인 “Spark”를 선택합니다. 위의 입력을 기반으로 스트림 프로세스 인스턴스 및 주제 파티션 예상에 대한 사이징의 영향을 예상할 수 있습니다.</block>
  <block id="bbc0ea8f6decb55572d395615cd02a3b" category="list-text">이 스트림 프로세서 응용 프로그램에는 다음과 같은 수의 인스턴스가 필요합니다. 들어오는 항목에는 이러한 많은 파티션이 필요할 수 있습니다. 이 매개 변수를 확인하려면 Confluent에 문의하십시오.</block>
  <block id="0a206846c82be8eef261c4c686599582" category="list-text">성장 승수가 없는 평균 처리량에 대해 1,000개</block>
  <block id="b032c5d1deed2d1b75c4f8019b5155e3" category="list-text">최대 처리량에 대해 4,000(성장 승수 없음)</block>
  <block id="5cbe73cfdf68ec8b04b4506b237d8af9" category="list-text">성장 승수가 포함된 평균 처리량의 경우 1,000개</block>
  <block id="f51843d6cdec756114fb7f153ab79f46" category="list-text">최대 처리량에 대해 4,000(성장 승수 포함)</block>
  <block id="1ebe06b1421d14bafea4a4d9a545d956" category="section-title">소비자</block>
  <block id="4d2351cfaa069bdffc56cd73486deacb" category="paragraph">Apache Kafka의 데이터를 사용하고 Apache Kafka로 다시 생성하지 않는 애플리케이션 또는 서비스(예: 네이티브 클라이언트 또는 Kafka Connector)에 대해 설명하십시오.</block>
  <block id="21af20352468dedb23eb4b6fa7362e32" category="list-text">* 이름. * Spark 소비자.</block>
  <block id="9e3b25cc5e8806da459be0a41ecfce10" category="list-text">* 처리 시간. * 이 소비자는 단일 메시지를 처리하는 데 얼마나 걸립니까?</block>
  <block id="39ad97382609f7463897aa49624f20d4" category="list-text">1ms(예: 로깅 같은 간단하고 상태 비저장 작업)</block>
  <block id="3d74518bdd6cfa27a42a16145872cc59" category="list-text">10ms(데이터 저장소에 대한 빠른 쓰기)</block>
  <block id="9f44c2afdbd671220f00e45494646aa6" category="list-text">100ms(데이터 저장소에 대한 느린 쓰기)</block>
  <block id="1284667da9611e925a39eee76e44e565" category="list-text">1000ms(타사 휴면 통화)</block>
  <block id="fff6a4b96ed9fb45c7eab95aeb8eb684" category="list-text">알려진 기간의 다른 벤치마크 프로세스</block>
  <block id="6490501e3342b6bea241de7194a60bba" category="list-text">* 소비자 유형. * 기존 데이터 저장소(RDBMS, NoSQL, 기타)에 대한 애플리케이션, 프록시 또는 싱크</block>
  <block id="23a444b3f78a63619b03bea8301f4edb" category="list-text">어떤 응용 프로그램에서 이 정보를 읽습니까? 이 매개 변수를 이전에 결정된 생산자 및 스트림 사이징에 연결합니다.</block>
  <block id="2feb2ea8e1991424930eda0c7cdeb393" category="paragraph">위의 입력 내용에 따라 소비자 인스턴스 및 주제 파티션 추정치에 대한 사이징을 결정해야 합니다. 소비자 응용 프로그램에는 다음과 같은 수의 인스턴스가 필요합니다.</block>
  <block id="90e1e02e655ca52c281e9b5ac01ca245" category="list-text">평균 처리량에 대해 2,000개, 성장 승수 없음</block>
  <block id="228e2cc32e2eedd0cfaf646cb26ad562" category="list-text">최대 처리량에 대해 8,000개, 성장 승수 없음</block>
  <block id="622c202fad5851b4699d8679ec9d3ce4" category="list-text">성장 승수를 포함한 평균 처리량에 대해 2,000개</block>
  <block id="da18372dd9e384fd5a4fd97fa6bdb872" category="list-text">성장 승수를 포함한 최대 처리량에 대해 8,000개</block>
  <block id="5992882fb5e2f68b36cbf47d5ffc182a" category="paragraph">들어오는 주제에는 이 수의 파티션도 필요할 것입니다. 확인하려면 Confluent에 문의하십시오.</block>
  <block id="152f9b32fca1ce5e9a3fc34e8c9e69c0" category="paragraph">생산자, 스트림 프로세서 및 소비자에 대한 요구 사항 외에도 다음과 같은 추가 요구 사항을 제공해야 합니다.</block>
  <block id="aea71dcdb94c855eb0655cb615bdcfe2" category="list-text">* 재생성 시간. * 예: 4시간. Apache Kafka 브로커 호스트에 장애가 발생하고 데이터가 손실되며 장애가 발생한 호스트를 대체하기 위해 새 호스트를 프로비저닝하는 경우 이 새 호스트 재구축 속도는 얼마나 빨라야 합니까? 값을 알 수 없는 경우 이 매개 변수를 비워 둡니다.</block>
  <block id="3bc49d2594090d023892da5211f6f7a4" category="list-text">* 리소스 활용률 목표(백분율) * 예: 60. 평균 처리량 중에 호스트를 얼마나 활용하기를 원하십니까? Confluent는 Confluent 셀프 밸런싱 클러스터를 사용하고 있지 않는 한 60%의 사용률을 권장합니다. 이 경우 활용률이 더 높을 수 있습니다.</block>
  <block id="9fa691f61c91ce32c6fb2dcc53a9d09c" category="section-title">환경에 대해 설명하십시오</block>
  <block id="7e431f8959ae4a79bcfc6e55728ead5a" category="list-text">* 클러스터가 어떤 환경에서 실행됩니까? * Amazon Web Services, Microsoft Azure, Google 클라우드 플랫폼, 베어 메탈 온프레미스, VMware 온프레미스, 사내에 OpenStack 또는 온프레미스에 Kubernates가 있습니까?</block>
  <block id="34946a533795a145eb4c6d66ee12e56b" category="list-text">* 호스트 세부 정보. * 코어 수: 48(예:), 네트워크 카드 유형(10GbE, 40GbE, 16GbE, 1GbE 또는 다른 유형).</block>
  <block id="a50ad1bade1c614aa4ceaa766944b0e1" category="list-text">* 스토리지 볼륨. * 호스트: 12(예:) 호스트당 지원되는 하드 드라이브 또는 SSD 수는 몇 개입니까? Confluent는 호스트당 12개의 하드 드라이브를 권장합니다.</block>
  <block id="bf903fced4e4e598ede3fb2a9dd5427a" category="list-text">* 스토리지 용량/볼륨(GB). * 1000(예:) 단일 볼륨에서 몇 기가바이트의 스토리지를 저장할 수 있습니까? Confluent에서는 1TB 디스크를 권장합니다.</block>
  <block id="85a140efdb29007799d7d5e7c16691d5" category="list-text">* 스토리지 구성. * 스토리지 볼륨은 어떻게 구성됩니까? Confluent는 Raid10에서 모든 Confluent 기능을 이용할 것을 권장합니다. JBOD, SAN, RAID 1, RAID 0, RAID 5, 및 기타 유형도 지원됩니다.</block>
  <block id="237d14e07eccd0d6535cf69ee4507805" category="list-text">* 단일 볼륨 처리량(Mbps). * 125(예:) 단일 스토리지 볼륨이 초당 메가바이트 단위로 읽거나 쓸 수 있는 속도는 얼마나 됩니까? Confluent는 일반적으로 125MBps 처리량의 표준 하드 드라이브를 권장합니다.</block>
  <block id="57499d42a69c4ed9f1e7994a0bad7e9f" category="list-text">* 메모리 용량(GB). * 64(예:)</block>
  <block id="9db0153ae987c66e360fc7027c7819c8" category="paragraph">환경 변수를 결정한 후 클러스터 크기를 선택합니다. 위에 표시된 예시 매개 변수를 토대로 Confluent Kafka에 대한 다음 사이징을 결정했습니다.</block>
  <block id="fc644e6661f2118a6b0733f85424f3fa" category="list-text">* 아파치 Kafka. * 브로커 수: 22. 클러스터가 스토리지에 바인딩되어 있습니다. 호스트 수를 줄이고 무한 스토리지를 허용하도록 계층형 스토리지를 설정하는 것이 좋습니다.</block>
  <block id="689921f4781dfd392aedc0eac4116284" category="list-text">* Apache ZooKeeper. * Count:5; Apache Kafka Connect 작업자: Count:2; Schema Registry: Count:2; REST Proxy: Count:2; ksqlDB:Count:2; Confluorent Control Center: Count:1.</block>
  <block id="df1673ed6a212d182bedbf3a4bdc79a7" category="paragraph">사용 사례를 염두에 두고 플랫폼 팀에 리버스 모드를 사용합니다. 파티션 모드를 사용하여 단일 항목에 필요한 파티션 수를 계산합니다. 을 참조하십시오<block ref="d971ea0f6ada2eeb1a618f5145544e00" category="inline-link-rx"></block> 역 및 파티션 모드에 따른 크기 조정.</block>
  <block id="4127d3e6d7b548701a1cf83ef1d7a922" category="paragraph"><block ref="4127d3e6d7b548701a1cf83ef1d7a922" category="inline-link-macro-rx"></block></block>
  <block id="139709c8a32ed1bcce233da863c5efda" category="summary">이 섹션에서는 이 인증에서 얻은 교훈을 설명합니다.</block>
  <block id="eab9ac0f00ca7c338d71f9acf8885092" category="doc">모범 사례 지침</block>
  <block id="524a5aa4f422c84af378b5418bb1539b" category="inline-link-macro">이전: Confluent 자체 재조정 클러스터</block>
  <block id="ae7f441436d5c9a5dc4278e4ea2b87e8" category="paragraph"><block ref="ae7f441436d5c9a5dc4278e4ea2b87e8" category="inline-link-macro-rx"></block></block>
  <block id="1bd6648fc95556a0a0fde4774f780085" category="list-text">NetApp의 검증을 기반으로 S3 오브젝트 스토리지는 데이터를 유창하게 유지하는 데 가장 적합합니다.</block>
  <block id="18f3dd1f96633e1c3f4b4473c8f63239" category="list-text">처리량이 높은 SAN(특히 FC)을 사용하여 브로커의 핫 데이터 또는 로컬 디스크를 유지할 수 있습니다. 왜냐하면, ContFluent 계층형 스토리지 구성에서 브로커 데이터 디렉토리에 있는 데이터의 크기는 데이터가 오브젝트 스토리지로 이동되는 세그먼트 크기 및 보존 시간을 기준으로 합니다.</block>
  <block id="992e82f9c5ce28bbe0068e8ff7ea8a09" category="list-text">오브젝트 저장소는 세그먼트일 때 더 나은 성능을 제공합니다. 바이트 수는 더 높고 512MB를 테스트했습니다.</block>
  <block id="f165ec9e9849281afaf2162f6396907c" category="list-text">Kafka에서는 해당 주제에 대해 생성된 각 레코드에 대한 키 또는 값(바이트)의 길이가 length.key.value 매개 변수에 의해 제어됩니다. StorageGRID의 경우 S3 오브젝트 수집 및 검색 성능이 더 높은 값으로 향상되었습니다. 예를 들어, 512바이트는 5.8GBps 검색, 1024바이트는 7.5GBps S3 검색, 2048바이트는 10Gbps 가까이 제공</block>
  <block id="92a9c9d4753636cd8ef8008380f5de9b" category="paragraph">다음 그림은 length.key.value를 기준으로 S3 오브젝트 수집 및 조회 결과를 나타낸 것이다.</block>
  <block id="b50ee24368ac624f2816b9e550167cb9" category="paragraph"><block ref="b50ee24368ac624f2816b9e550167cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9432e98ec213778ab349305141050c42" category="list-text">* Kafka 튜닝. * 계층형 스토리지의 성능을 향상시키려면 TierFetcherNumThreads 및 TierArchivernumThreads를 늘릴 수 있습니다. 일반적으로 TierFetchernumThreads를 물리적 CPU 코어 수와 일치하도록 늘리고 TierArchivernumThreads를 CPU 코어 수의 절반으로 늘리고자 합니다. 예를 들어, 서버 속성에서 8개의 물리적 코어가 있는 컴퓨터를 사용하는 경우 confluent.tier.fetcher.num.threads=8 및 confluent.tier.Archiver.num.threads=4를 설정합니다.</block>
  <block id="ed3ecb8a7183dd06de652f3dc38b1037" category="list-text">* 항목 삭제에 대한 시간 간격 * 주제가 삭제되면 객체 저장소에서 로그 세그먼트 파일 삭제가 즉시 시작되지 않습니다. 대신 이 파일을 삭제하기 전에 기본값이 3시간인 시간 간격이 있습니다. confluent.tier.topic.delete.check.interval.ms 구성을 수정하여 이 간격의 값을 변경할 수 있습니다. 주제 또는 클러스터를 삭제하는 경우 해당 버킷의 오브젝트도 수동으로 삭제할 수 있습니다.</block>
  <block id="3833b7b3d2c8a15e32f72248bab1add9" category="list-text">* 계층형 스토리지 내부 항목에 대한 ACL. * 온-프레미스 배포의 권장 모범 사례는 계층형 스토리지에 사용되는 내부 항목에 대해 ACL 허가자를 활성화하는 것입니다. 이 데이터에 대한 액세스를 브로커 사용자에게만 제한하려면 ACL 규칙을 설정합니다. 이렇게 하면 내부 항목이 안전하게 보호되며 계층형 스토리지 데이터 및 메타데이터에 대한 무단 액세스가 방지됩니다.</block>
  <block id="ebcb583d4445a2a39076c7fa4627f79a" category="admonition">사용자 '&lt;Kafka&gt;'를 배포의 실제 브로커 교장으로 바꿉니다.</block>
  <block id="0ca954cd7923be900c49b3b807caf2b6" category="paragraph">예를 들어, "confluent-tier-state" 명령은 계층형 스토리지의 내부 항목에 대한 ACL을 설정합니다. 현재 계층형 스토리지와 관련된 내부 주제는 하나뿐입니다. 이 예제에서는 내부 항목의 모든 작업에 대해 Kafka의 주요 권한을 제공하는 ACL을 만듭니다.</block>
  <block id="c7aa1f1ea2c8ad1712056dd97321d808" category="inline-link-macro">다음: 사이징.</block>
  <block id="de8a38c4c90ce81d8c4b82c44500e504" category="paragraph"><block ref="de8a38c4c90ce81d8c4b82c44500e504" category="inline-link-macro-rx"></block></block>
  <block id="5e524f38cae9a99f3ebbaf012df2894e" category="summary">NetApp이 제공하는 Data Fabric은 클라우드 및 사내 환경에서 데이터 관리를 단순화하고 통합하여 디지털 전환을 가속합니다. NetApp이 제공하는 Data Fabric은 데이터 가시성 및 통찰력, 데이터 액세스 및 제어, 데이터 보호 및 보안을 위해 일관되고 통합된 데이터 관리 서비스 및 애플리케이션(구성 요소)을 제공합니다.</block>
  <block id="3c2db15f0fee10b08496ec1701f104d8" category="doc">NetApp에서 제공하는 빅데이터 아키텍처 관련 Data Fabric</block>
  <block id="32e0d2b797e6706a73e8146d103572c7" category="inline-link-macro">이전: 솔루션 개요</block>
  <block id="45af7a946606481f9e2b5f0434aa0484" category="paragraph"><block ref="45af7a946606481f9e2b5f0434aa0484" category="inline-link-macro-rx"></block></block>
  <block id="981d357acc471e35d8d150f861ff1828" category="paragraph">NetApp이 제공하는 Data Fabric은 클라우드 및 사내 환경에서 데이터 관리를 단순화하고 통합하여 디지털 전환을 가속합니다.</block>
  <block id="d5a64464c1e1f9d8be4cafc8b2325fa6" category="paragraph">NetApp이 제공하는 Data Fabric은 데이터 가시성과 통찰력, 데이터 액세스 및 제어, 데이터 보호 및 보안을 위한 일관성 있는 통합 데이터 관리 서비스 및 애플리케이션(구성 요소)을 제공합니다(아래 그림 참조).</block>
  <block id="22313f8779f9135c9b421ac0d4b320fb" category="paragraph"><block ref="22313f8779f9135c9b421ac0d4b320fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5083bdadc0fe82e6398670e5dcc6bff9" category="section-title">검증된 Data Fabric 고객 사용 사례</block>
  <block id="3c1223e53bc7b972a018d3e2597e0bfd" category="paragraph">NetApp이 제공하는 Data Fabric은 고객에게 다음과 같은 9가지 검증된 사용 사례를 제공합니다.</block>
  <block id="a6800f5cacde75e6f1cfb931a6f2dba6" category="list-text">분석 워크로드 가속화</block>
  <block id="5b0fa9517345824f19ceddd9d0cd39de" category="list-text">DevOps 혁신 가속</block>
  <block id="90ed50a34505fc6883bd65c36ed8b810" category="list-text">클라우드 호스팅 인프라 구축</block>
  <block id="f3933541659deec9d28aa584238f0468" category="list-text">클라우드 데이터 서비스 통합</block>
  <block id="d70909396aef5247a5a1b17dd15cf43d" category="list-text">데이터 보호 및 보안</block>
  <block id="7af5a6e7f241b8d284656f20880db36f" category="list-text">비정형데이터의 최적화</block>
  <block id="2c63452d476328fa43a39c00bef366f1" category="list-text">데이터 센터의 효율성 확보</block>
  <block id="0f72ba4c2b371e4f9f47e7d8c61468a5" category="list-text">데이터 통찰력 및 제어 제공</block>
  <block id="0da79db0a9974fc0002f744165467752" category="list-text">단순화 및 자동화</block>
  <block id="5d5b69e7e19270db49a42eb4e96be2ee" category="paragraph">본 문서는 9가지 사용 사례 중 2가지(솔루션 포함)를 다룹니다.</block>
  <block id="7adb8b5c573e74594feeb2f74e1ffc96" category="section-title">NetApp NFS 직접 액세스</block>
  <block id="233060aa11b5715000c000e94576cca9" category="paragraph">아래 그림에 표시된 NetApp NFS 직접 액세스(이전의 NetApp In-Place Analytics Module)를 사용하면 데이터를 이동하거나 복사하지 않고도 기존 또는 새로운 NFSv3 또는 NFSv4 데이터에 대해 빅데이터 분석 작업을 실행할 수 있습니다. 여러 데이터 복제본을 방지하고 소스와 데이터를 동기화할 필요가 없습니다. 예를 들어 금융 부문에서 데이터를 한 위치에서 다른 위치로 이동하는 것은 쉬운 일이 아닌 법적 의무를 준수해야 합니다. 이 시나리오에서는 NetApp NFS 직접 액세스가 원래의 위치에서 재무 데이터를 분석합니다. 또 다른 주요 이점은 NetApp NFS 직접 액세스를 사용하여 기본 Hadoop 명령을 사용하여 Hadoop 데이터를 간편하게 보호하고 NetApp의 강력한 데이터 관리 포트폴리오를 활용하여 데이터 보호 워크플로우를 활성화할 수 있다는 것입니다.</block>
  <block id="96e1e6bac181280c42ba5de56a8ef4c2" category="paragraph"><block ref="96e1e6bac181280c42ba5de56a8ef4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa47c768dc0f007b4606d394be4330c3" category="paragraph">NetApp NFS 직접 액세스에서는 Hadoop/Spark 클러스터에 다음과 같은 두 가지 유형의 구축 옵션을 제공합니다.</block>
  <block id="cc7514a5b2b35641026a81211ae7fe9a" category="list-text">기본적으로 Hadoop/Spark 클러스터는 데이터 스토리지와 기본 파일 시스템에 HDFS(Hadoop Distributed File System)를 사용합니다. NetApp NFS 직접 액세스는 기본 HDFS를 NFS 스토리지로 대체하여 NFS 데이터에 대한 직접 분석 작업을 지원합니다.</block>
  <block id="5a5dace50e75999dec9323da42fe5410" category="list-text">다른 구축 옵션에서 NetApp NFS 직접 액세스는 NFS를 단일 Hadoop/Spark 클러스터의 HDFS와 함께 추가 스토리지로 구성할 수 있도록 지원합니다. 이 경우 고객은 NFS 내보내기를 통해 데이터를 공유하고 HDFS 데이터와 함께 동일한 클러스터에서 데이터를 액세스할 수 있습니다.</block>
  <block id="933871f01596456078e75585ab9480ae" category="paragraph">NetApp NFS 직접 액세스를 사용할 때의 주요 이점은 다음과 같습니다.</block>
  <block id="bc3221e251e23e5ee9782e37b0337c38" category="list-text">현재 위치의 데이터를 분석하여 분석 데이터를 HDFS와 같은 Hadoop 인프라스트럭처로 이동하는 데 시간과 성능이 많이 소모되는 작업을 방지합니다.</block>
  <block id="fe5efea0cd6733d158bfb04016f055f0" category="list-text">복제본 수를 3개부터 1개로 줄입니다.</block>
  <block id="21b00f92397ca3c72f6407dd3a873e23" category="list-text">사용자가 컴퓨팅 및 스토리지를 분리하여 독립적으로 확장할 수 있습니다.</block>
  <block id="be7e2eb6e940a1e798db3abedc75b7a8" category="list-text">ONTAP의 강력한 데이터 관리 기능을 활용하여 엔터프라이즈 데이터 보호 기능을 제공합니다.</block>
  <block id="acc50ec5f7ffe1b08ee357afcb502a0f" category="list-text">Hortonworks 데이터 플랫폼에서 인증되었습니다.</block>
  <block id="be5acbdc2ea462a8345ea92d4c42511c" category="list-text">하이브리드 데이터 분석을 구축할 수 있습니다.</block>
  <block id="227afbdb4ab9214131d6ca5ca3df3cd6" category="list-text">동적 다중 스레드 기능을 활용하여 백업 시간을 단축합니다.</block>
  <block id="787364630dc10cfc2657bc82f289a9fb" category="section-title">빅 데이터를 위한 구성 요소</block>
  <block id="7698deb733ad601844c58f0102d0470c" category="paragraph">NetApp 기반의 Data Fabric은 아래 그림과 같이 데이터 액세스, 제어, 보호 및 보안을 위한 데이터 관리 서비스와 애플리케이션(구성 요소)을 통합합니다.</block>
  <block id="f0a67f0f8f389fb239ce107f693a7e68" category="paragraph"><block ref="f0a67f0f8f389fb239ce107f693a7e68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="162f2b2249f4b8bda40b0c01043779b3" category="paragraph">위 그림의 구성 요소는 다음과 같습니다.</block>
  <block id="e64f250539a531b81423d6f3f4729665" category="list-text">* NetApp NFS 직접 액세스 * 는 추가 소프트웨어 또는 드라이버 요구사항 없이 최신 Hadoop 및 Spark 클러스터를 NetApp NFS 볼륨에 직접 액세스할 수 있도록 지원합니다.</block>
  <block id="2867a490011894512662b9423698d0e0" category="list-text">* NetApp Cloud Volumes ONTAP 및 클라우드 볼륨 서비스. * Microsoft Azure 클라우드 서비스의 AWS(Amazon Web Services) 또는 ANF(Azure NetApp Files)에서 실행되는 ONTAP를 기반으로 하는 소프트웨어 정의 연결형 스토리지.</block>
  <block id="5d382bdcedb0a9c7aa214b09e129e5e7" category="list-text">NetApp SnapMirror 기술 *. 사내 및 ONTAP 클라우드 또는 NPS 인스턴스 간에 데이터 보호 기능을 제공합니다.</block>
  <block id="e2d911047fad9851fae1d7c4e71b2fab" category="list-text">* 클라우드 서비스 공급자 * 이러한 공급자에는 AWS, Microsoft Azure, Google Cloud 및 IBM Cloud가 포함됩니다.</block>
  <block id="486add91df5cb94a1fee5fccffe4f39b" category="list-text">* PaaS. * AWS의 EMR(Amazon Elastic MapReduce) 및 Databricks와 같은 클라우드 기반 분석 서비스와 Microsoft Azure HDInsight 및 Azure Databricks</block>
  <block id="35848dde21e4a5f344385ead6dec9a43" category="inline-link-macro">이제 Hadoop 데이터 보호와 NetApp이 모두 필요합니다.</block>
  <block id="149584f581a09d835c88f233c514412e" category="paragraph"><block ref="149584f581a09d835c88f233c514412e" category="inline-link-macro-rx"></block></block>
  <block id="16d17bd11d09e7ab044f85f158c4ee5c" category="doc">솔루션 아키텍처 세부 정보</block>
  <block id="40328f8a932f8ae1964c73c1f2eca76b" category="paragraph"><block ref="40328f8a932f8ae1964c73c1f2eca76b" category="inline-link-macro-rx"></block></block>
  <block id="096d10f0062b97cca959118975fa506a" category="paragraph">이 섹션에서는 Confluent 검증에 사용된 하드웨어 및 소프트웨어에 대해 다룹니다. 이 정보는 NetApp 스토리지를 사용하는 Confluent Platform 구축에 적용할 수 있습니다. 다음 표에서는 테스트를 거친 솔루션 아키텍처 및 기본 구성 요소에 대해 설명합니다.</block>
  <block id="cd6b218ceb186591718799f941a99fd0" category="cell">Confluent Kafka 버전 6.2</block>
  <block id="8a1732b4cde6f106471a0e6dbb186bed" category="list-text">세 명의 주키퍼입니다</block>
  <block id="fde5b2c6fa48108e02c6a3587ce451b4" category="list-text">브로커 서버 5대</block>
  <block id="cd2e7d4aa00a79a9a92980e984ec50d7" category="list-text">5개의 도구 서버</block>
  <block id="e9617e461b2b6597095fc0d3c26666c5" category="list-text">하나의 Grafana</block>
  <block id="5d96f98a638cf23ac2f3dfe513198e9a" category="list-text">제어 센터 1개</block>
  <block id="a2a44121136232f1f2dcfb5e5ce5cf22" category="cell">Linux(Ubuntu 18.04)</block>
  <block id="a0681d05c825936a4afc9d89f305934c" category="cell">모든 서버</block>
  <block id="cc3bec1f9974aef63e75985fed9c343e" category="cell">계층형 스토리지를 위한 NetApp StorageGRID</block>
  <block id="2d4f4568ad652ff08727bc044f1373cc" category="list-text">StorageGRID 소프트웨어</block>
  <block id="4ebcee22d98fbad50cf1c7e108dd9541" category="list-text">SG1000(로드 밸런서) 1개</block>
  <block id="a51cb0f5fd275943954c8d687912e458" category="list-text">SGF6024 4개</block>
  <block id="83cc5cf13ad44caf6aa94887d189cd3a" category="list-text">24 x 800 SSD 4개</block>
  <block id="7ccdc7c1d04d9b48b4b016417504685b" category="list-text">S3 프로토콜</block>
  <block id="e185a6ccd16ce2c64c7e948bbc46f45a" category="list-text">4 x 100GbE(브로커와 StorageGRID 인스턴스 간 네트워크 연결)</block>
  <block id="5ecafb7b42f662438e20bd643feb79c9" category="cell">15 Fujitsu Primergy RX2540 서버</block>
  <block id="cdb0680ecb0e0ed91d8293e41334b379" category="cell">각 장착 사양: * CPU 2개, 물리적 코어 16개 * Intel Xeon * 256GB 물리적 메모리 * 100GbE 듀얼 포트</block>
  <block id="c88aa001e26103d0ebe4894b3c9ab9f5" category="paragraph"><block ref="c88aa001e26103d0ebe4894b3c9ab9f5" category="inline-link-macro-rx"></block></block>
  <block id="fa7dcae8e4f7d8ecc191c3ce8547a53a" category="summary">이 사용 사례는 고객의 빅데이터 분석 데이터를 위한 멀티 클라우드 연결을 제공하는 클라우드 서비스 파트너와 관련이 있습니다.</block>
  <block id="2268700ee8bd2216d594273e566b0cc9" category="doc">사용 사례 4: 데이터 보호 및 멀티 클라우드 연결</block>
  <block id="2c8eccdfa6390b1d09b2527f7d7d2cc5" category="inline-link-macro">이전: 사용 사례 3 - 기존 Hadoop 데이터에 대해 DevTest 설정</block>
  <block id="fda5cc5b496f5f7aa6de18740227bc15" category="paragraph"><block ref="fda5cc5b496f5f7aa6de18740227bc15" category="inline-link-macro-rx"></block></block>
  <block id="3cec8f6cf1ce867e7f73dd5132b7fbf3" category="paragraph">이 시나리오에서는 여러 소스에서 AWS로 수신된 IoT 데이터가 NPS의 중앙 위치에 저장됩니다. NPS 스토리지는 AWS 및 Azure에 위치한 Spark/Hadoop 클러스터에 연결되므로, 여러 클라우드에서 실행되는 빅데이터 분석 애플리케이션이 동일한 데이터에 액세스할 수 있습니다.</block>
  <block id="bed6436414550585ccb4ac4c67a449a3" category="list-text">고객은 여러 클라우드를 사용하여 동일한 데이터에 대한 분석 작업을 실행하려고 합니다.</block>
  <block id="6af3e1f448b2a56e9bd0fbbd43b31bc8" category="list-text">다양한 센서와 허브를 통해 사내, 클라우드와 같은 다양한 소스로부터 데이터를 받아야 합니다.</block>
  <block id="e3c7f1ced05166adfc90c26337389e3e" category="list-text">솔루션은 효율적이고 비용 효율적이어야 합니다.</block>
  <block id="b320f1b1ab6d0a21e40ee3d444669645" category="list-text">주요 과제는 사내 및 다른 클라우드 간에 하이브리드 분석 서비스를 제공하는 비용 효율적이고 효율적인 솔루션을 구축하는 것입니다.</block>
  <block id="0d4b3cfa555ff36cd92fb4e36fb69fbf" category="paragraph">이 이미지는 데이터 보호 및 멀티 클라우드 연결 솔루션을 보여줍니다.</block>
  <block id="faaf8e6278dc7a68fd1dd98dfe7f525a" category="paragraph"><block ref="faaf8e6278dc7a68fd1dd98dfe7f525a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14c23633f1ab374f4c801386847ba2f8" category="paragraph">위 그림과 같이 센서의 데이터가 스트리밍되어 Kafka를 통해 AWS Spark 클러스터로 수집됩니다. 이 데이터는 Equinix 데이터 센터 내의 클라우드 공급자 외부에 있는 NPS에 있는 NFS 공유에 저장됩니다. NetApp NPS는 Direct Connect와 Express Route 연결을 통해 Amazon AWS 및 Microsoft Azure에 연결되므로, 고객은 데이터 이동 없는 분석 모듈을 활용하여 Amazon 및 AWS 분석 클러스터 모두에서 데이터에 액세스할 수 있습니다. 이 접근 방식은 여러 하이퍼 스케일러의 클라우드 분석 문제를 해결합니다.</block>
  <block id="4089db0b43263b1f59a9c2db909edf6e" category="paragraph">따라서 사내 스토리지와 NPS 스토리지 모두 ONTAP 소프트웨어를 실행하므로 SnapMirror는 사내 클러스터에 NPS 데이터를 미러링하여 사내 및 여러 클라우드에 하이브리드 클라우드 분석을 제공할 수 있습니다.</block>
  <block id="d446808fb03b5fae4f2e518cbc7d767f" category="paragraph">최적의 성능을 위해 일반적으로 여러 네트워크 인터페이스 및 직접 연결/빠른 경로를 사용하여 클라우드 인스턴스에서 데이터에 액세스할 것을 권장합니다.</block>
  <block id="1ef541fe0fa79d247c0f1751629bb504" category="inline-link-macro">다음: 사용 사례 5 - 분석 워크로드 가속화</block>
  <block id="7dfabd0b120fe0403ff107668db4094a" category="paragraph"><block ref="7dfabd0b120fe0403ff107668db4094a" category="inline-link-macro-rx"></block></block>
  <block id="1dca3067f5c6c2fa6b32ef683fcab56f" category="summary">이 시나리오에서는 고객이 대규모 사내 Hadoop 저장소를 보유하고 있으며 재해 복구를 위해 백업하려고 합니다. 그러나 고객의 현재 백업 솔루션은 비용이 많이 들고 24시간 이상의 긴 백업 윈도우에 어려움을 겪고 있습니다.</block>
  <block id="817ac2975197bd6c376a7918a798981f" category="doc">사용 사례 1: Hadoop 데이터 백업</block>
  <block id="8efec9e11b7742f59dbe1af079e1c1d0" category="inline-link-macro">이전: Hadoop 데이터 보호 활용 사례 개요</block>
  <block id="259b434ecfae95df231c879645a98918" category="paragraph"><block ref="259b434ecfae95df231c879645a98918" category="inline-link-macro-rx"></block></block>
  <block id="7ffe71c29f8ea391bbd80c1e8441af9a" category="list-text">소프트웨어 하위 호환성:</block>
  <block id="d96828d85e8cc053407a391bee52257f" category="list-text">제안된 대체 백업 솔루션은 운영 Hadoop 클러스터에 사용되는 현재 실행 중인 소프트웨어 버전과 호환되어야 합니다.</block>
  <block id="dd5bb530e532c011487ffc3a69e56f57" category="list-text">확정된 SLA를 충족하기 위해 제안된 대체 솔루션은 매우 낮은 RPO 및 RTO를 달성해야 합니다.</block>
  <block id="4783ab1f0401dc9c24cc9afa6dc5823e" category="list-text">NetApp 백업 솔루션을 통해 생성된 백업은 데이터 센터에서 로컬로 구축된 Hadoop 클러스터뿐만 아니라 원격 사이트의 재해 복구 위치에서 실행되는 Hadoop 클러스터에서도 사용할 수 있습니다.</block>
  <block id="1dbc869d2df036d4d6e732e9c680ab6b" category="list-text">제안된 솔루션은 비용 효율적이어야 합니다.</block>
  <block id="7405e6ba4b630f11b88a7976325a95e4" category="list-text">제안 솔루션은 백업 시간 동안 현재 실행 중인 운영 중인 분석 작업의 성능 영향을 줄여야 합니다.</block>
  <block id="e3d4f6860e578b28733c41c2c852f821" category="section-title">고객의 기존 백업 솔루션</block>
  <block id="f350f804f84a5bf788cd78cd4aae7eab" category="paragraph">아래 그림은 원래 Hadoop 네이티브 백업 솔루션을 보여 줍니다.</block>
  <block id="2975218bd3c71a4ac4eac95d3529a9cb" category="paragraph"><block ref="2975218bd3c71a4ac4eac95d3529a9cb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="76b8e496c38192b97fdfa6cae2ba2bb4" category="paragraph">운영 데이터는 중간 백업 클러스터를 통해 테이프로 보호됩니다.</block>
  <block id="d07ca391addc59b7408fb88541552b43" category="list-text">HDFS1 데이터는 'Hadoop distcp-update&lt;hdfs1&gt;&lt;hdfs2&gt;' 명령을 실행하여 HDFS2에 복사됩니다.</block>
  <block id="2c4cadbb7f122d1d0cd988a11681248a" category="list-text">백업 클러스터는 NFS 게이트웨이 역할을 하며 테이프 라이브러리를 통해 Linux 'CP' 명령을 통해 테이프에 데이터를 수동으로 복사합니다.</block>
  <block id="b73035943c8623cbdb7bd67992201012" category="paragraph">원래 Hadoop 네이티브 백업 솔루션의 이점은 다음과 같습니다.</block>
  <block id="5bdb90a1352ca42ab8dde5b9ab7ffac3" category="list-text">이 솔루션은 Hadoop 기본 명령을 기반으로 하므로 사용자가 새로운 절차를 배울 필요가 없습니다.</block>
  <block id="f581d1b5f93adda1865bad95e215a7b9" category="list-text">이 솔루션은 업계 표준 아키텍처와 하드웨어를 활용합니다.</block>
  <block id="ddd131647a4d5e1b5bcb983ec8872ff9" category="paragraph">원래 Hadoop 네이티브 백업 솔루션의 단점은 다음과 같습니다.</block>
  <block id="2cd5e9eae715f3bb0475ed032bf56190" category="list-text">긴 백업 시간이 24시간을 초과하므로 운영 데이터가 취약해집니다.</block>
  <block id="b22d500a5624a2c57ec5bda86aa57011" category="list-text">백업 시간 동안 클러스터 성능이 크게 저하되었습니다.</block>
  <block id="69bfe7f4231b0c1d65247d0abfc89cb3" category="list-text">테이프에 복사하는 것은 수동 프로세스입니다.</block>
  <block id="6ef8e4ec49425ac5ded9c6cc599c17d2" category="list-text">백업 솔루션은 필요한 하드웨어 및 수동 프로세스에 필요한 인력 시간의 측면에서 비용이 많이 듭니다.</block>
  <block id="1b4d2bf420e7f05ecb82ecf2197ab810" category="section-title">백업 솔루션</block>
  <block id="6d977e36854ae6439cbc4fe8e0c1b227" category="paragraph">이러한 당면 과제와 요구 사항을 바탕으로 기존 백업 시스템을 고려하여 세 가지 가능한 백업 솔루션을 제안하였습니다. 다음 하위 섹션에서는 이러한 세 가지 백업 솔루션 각각에 대해 설명합니다. 솔루션 A에서 솔루션 C까지의 레이블이 지정되어 있습니다</block>
  <block id="c5a6c012dc14dc7f9d2fa0df0ccb0cdf" category="section-title">솔루션 A</block>
  <block id="8ee7b0fbb95cf5b1c98578a7ef03b9eb" category="paragraph">솔루션 A는 아래 그림과 같이 데이터 이동 없는 분석 모듈을 백업 Hadoop 클러스터에 추가하여 NetApp NFS 스토리지 시스템에 대한 보조 백업을 허용함으로써 테이프 요구 사항을 제거합니다.</block>
  <block id="411ee6c684ee720eff303771433e41d6" category="paragraph"><block ref="411ee6c684ee720eff303771433e41d6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2813f022c034c63ad3d6efeeb503eb70" category="paragraph">솔루션 A에 대한 자세한 작업은 다음과 같습니다.</block>
  <block id="0406c5ca05cfb5f7a0c02971c3962460" category="list-text">운영 Hadoop 클러스터에는 보호가 필요한 HDFS에 고객의 분석 데이터가 있습니다.</block>
  <block id="feb7749ff700168c127dfbd8376b35f7" category="list-text">HDFS가 포함된 백업 Hadoop 클러스터는 데이터의 중간 위치로 작동합니다. JBOD(Just a Bunch of Disks)는 운영 및 백업 Hadoop 클러스터 모두에서 HDFS용 스토리지를 제공합니다.</block>
  <block id="b3f54540429c806b8cf0080fd78b34bc" category="list-text">Hadoop distcp –update –diff &lt;hdfs1&gt;&lt;hdfs2&gt;' 명령을 실행하여 운영 클러스터 HDFS에서 백업 클러스터 HDFS로 Hadoop 운영 데이터를 보호합니다.</block>
  <block id="2de4833848a0b94bd672bdf9bc60d4aa" category="admonition">Hadoop 스냅샷은 운영 환경에서 백업 Hadoop 클러스터로 데이터를 보호하는 데 사용됩니다.</block>
  <block id="79ef8fc2c565c69b33f5918c3a0bdd9a" category="list-text">NetApp ONTAP 스토리지 컨트롤러는 NFS로 내보낸 볼륨을 제공하며 백업 Hadoop 클러스터에 프로비저닝됩니다.</block>
  <block id="b0e42779d51b21a745cae08f938ec60a" category="list-text">MapReduce와 여러 개의 mapper를 활용하는 "Hadoop distcp" 명령을 실행하면 데이터 이동 없는 분석 모듈을 사용하여 분석 데이터가 백업 Hadoop 클러스터에서 NFS로 보호됩니다.</block>
  <block id="738997de22c6371f563f69e1bb57b6e5" category="paragraph">NetApp 스토리지 시스템의 NFS에 데이터가 저장된 후 NetApp Snapshot, SnapRestore 및 FlexClone 기술을 사용하여 필요에 따라 Hadoop 데이터를 백업, 복원, 복제할 수 있습니다.</block>
  <block id="0bd252182290e872b264ad65d369637f" category="admonition">SnapMirror 기술을 사용하여 Hadoop 데이터를 클라우드뿐 아니라 재해 복구 위치에도 보호할 수 있습니다.</block>
  <block id="4a1b9aaeaa6487c6df7072326cf3798e" category="paragraph">솔루션 A의 이점은 다음과 같습니다.</block>
  <block id="0843e6a882cae98851adbefb52d05827" category="list-text">Hadoop 운영 데이터는 백업 클러스터로부터 보호됩니다.</block>
  <block id="522d0cf303cbf1b16ea5cc33480ce02f" category="list-text">HDFS 데이터는 NFS를 통해 보호되므로 클라우드 및 재해 복구 위치에 대한 보호가 가능합니다.</block>
  <block id="298d20d1ae9110668e52c07776f62948" category="list-text">백업 작업을 백업 클러스터로 오프로드하여 성능을 향상시킵니다.</block>
  <block id="4c10451e9e5bf987bc3ab16a9fce3966" category="list-text">수동 테이프 작업이 필요 없습니다</block>
  <block id="0ff20f264e79e773549ded37f50f4b3b" category="list-text">NetApp 툴을 통해 엔터프라이즈 관리 기능을 지원합니다.</block>
  <block id="4c84f95e2dad9b5385151a736e89f0c3" category="list-text">기존 환경을 최소한으로 변경해야 합니다.</block>
  <block id="66f3b3a8c99e03a363a88a58fabe03cc" category="list-text">비용 효율적인 솔루션입니다.</block>
  <block id="4e941dea7920913a2c3a6d2a11a0936f" category="paragraph">이 솔루션의 단점은 성능을 향상시키기 위해 백업 클러스터와 추가 매퍼가 필요하다는 것입니다.</block>
  <block id="0628ac302dce6afb9d95a6b8ebd0d013" category="paragraph">이 고객은 단순성, 비용, 전반적인 성능 때문에 최근에 솔루션 A를 배포했습니다.</block>
  <block id="7a3ba8b554aec9832f399bff2ba17c74" category="paragraph">이 솔루션에서는 JBOD 대신 ONTAP의 SAN 디스크를 사용할 수 있습니다. 이 옵션은 백업 클러스터 스토리지 로드를 ONTAP로 오프로드하지만, 단점은 SAN 패브릭 스위치가 필요하다는 점입니다.</block>
  <block id="501a1b4ce382e8e2da0089aded30d11e" category="section-title">해결 방법 B</block>
  <block id="304af2b0b47890c7db8f6097978fdede" category="paragraph">솔루션 B는 운영 Hadoop 클러스터에 데이터 이동 없는 분석 모듈을 추가하여 아래 그림과 같이 백업 Hadoop 클러스터가 필요하지 않습니다.</block>
  <block id="303388aba87d7dcff207a6cd098b0cfe" category="paragraph"><block ref="303388aba87d7dcff207a6cd098b0cfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ca30c628556726e2038c5df9689fd91" category="paragraph">솔루션 B에 대한 자세한 작업은 다음과 같습니다.</block>
  <block id="e493f6dc701d2253466d5705af2e5bb1" category="list-text">NetApp ONTAP 스토리지 컨트롤러는 운영 Hadoop 클러스터에 NFS 내보내기를 프로비저닝합니다.</block>
  <block id="3c321f811c173c1f133bdcc77fc81a33" category="paragraph">Hadoop 네이티브 'Hadoop distcp' 명령은 Hadoop 데이터를 데이터 이동 없는 분석 모듈을 통해 운영 클러스터 HDFS에서 NFS로 보호합니다.</block>
  <block id="665cfb3949b836c368d9be47d34bcbba" category="list-text">NetApp 스토리지 시스템의 NFS에 데이터가 저장된 후에는 Snapshot, SnapRestore 및 FlexClone 기술을 사용하여 필요에 따라 Hadoop 데이터를 백업, 복원, 복제할 수 있습니다.</block>
  <block id="4f1aeb2a94e89562b7bef27c368ed9cc" category="paragraph">솔루션 B의 이점은 다음과 같습니다.</block>
  <block id="748dc25f775dc78e1da24328f753d1e1" category="list-text">운영 클러스터는 백업 솔루션에 맞게 약간 수정되어 구축이 간소화되고 추가 인프라스트럭처 비용이 절감됩니다.</block>
  <block id="a565a40a6656693466a7da18be6d44ca" category="list-text">백업 작업을 위한 백업 클러스터는 필요하지 않습니다.</block>
  <block id="fa6ae9dfac02b933ef93450603114fce" category="list-text">HDFS 운영 데이터는 NFS 데이터 변환 시 보호됩니다.</block>
  <block id="cf7952142a1253af6b9394a3f01408b3" category="list-text">이 솔루션을 사용하면 NetApp 툴을 통해 엔터프라이즈 관리 기능을 수행할 수 있습니다.</block>
  <block id="02946730aaff0e3d8abfa986a2fe949d" category="paragraph">이 솔루션의 단점은 프로덕션 클러스터에 구현되어 운영 클러스터에 추가 관리자 작업을 추가할 수 있다는 것입니다.</block>
  <block id="0a3b8c5fab2a32545423ade2927b1185" category="section-title">솔루션 C</block>
  <block id="6c176725a15c1c609d24387ddf6600da" category="paragraph">솔루션 C에서는 아래 그림과 같이 NetApp SAN 볼륨을 HDFS 스토리지용 Hadoop 운영 클러스터에 직접 프로비저닝합니다.</block>
  <block id="dc460b3501caf17186202576855a6d3c" category="paragraph"><block ref="dc460b3501caf17186202576855a6d3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0d09b63c2b939de22a3b5d0f4cb3c87" category="paragraph">솔루션 C에 대한 자세한 단계는 다음과 같습니다.</block>
  <block id="35edf0b5a2042b4561d4d499298010e6" category="list-text">NetApp ONTAP SAN 스토리지는 HDFS 데이터 스토리지를 위한 운영 Hadoop 클러스터에서 프로비저닝됩니다.</block>
  <block id="3b694951a08990d1243da1dd36e6cd07" category="list-text">NetApp Snapshot 및 SnapMirror 기술은 운영 Hadoop 클러스터의 HDFS 데이터를 백업하는 데 사용됩니다.</block>
  <block id="c32b4eb407751e515d7d037629b66dfb" category="list-text">백업이 스토리지 계층에 있기 때문에 스냅샷 복사본 백업 프로세스 중에 Hadoop/Spark 클러스터의 운영에 미치는 성능 영향은 없습니다.</block>
  <block id="ef54974b65426daa87a86290447ed9a6" category="admonition">스냅샷 기술은 데이터 크기에 관계없이 몇 초 내에 백업을 완료합니다.</block>
  <block id="f499d7fd731eb2bb1efe6c4069efcb47" category="paragraph">솔루션 C의 이점은 다음과 같습니다.</block>
  <block id="abe0be0b8deb695793caa75a1dcfc4b3" category="list-text">스냅샷 기술을 사용하여 공간 효율적인 백업을 생성할 수 있습니다.</block>
  <block id="5788267ffe4023e91b333de591766cca" category="inline-link-macro">다음: 사용 사례 2 - 클라우드에서 사내로 백업 및 재해 복구</block>
  <block id="1619284091911820ebd1407554fb6da7" category="paragraph"><block ref="1619284091911820ebd1407554fb6da7" category="inline-link-macro-rx"></block></block>
  <block id="f9fe6a27dc7f13d26e9416153b950597" category="summary">이 섹션에서는 이 백서의 초점을 구성하는 데이터 보호 활용 사례에 대해 자세히 설명합니다. 나머지 섹션에서는 고객 문제(시나리오), 요구 사항 및 당면 과제, 솔루션 등 각 사용 사례에 대한 자세한 정보를 제공합니다.</block>
  <block id="6a15e1dac7cc5c330a1da84c32b3ff2e" category="doc">Hadoop 데이터 보호 활용 사례 개요</block>
  <block id="d161097dc6596d3807b21a5635856d71" category="inline-link-macro">이전: Hadoop 데이터 보호 및 NetApp</block>
  <block id="1a5df0b83f496dc00b4a331caac0d5cd" category="paragraph"><block ref="1a5df0b83f496dc00b4a331caac0d5cd" category="inline-link-macro-rx"></block></block>
  <block id="385dae214dc9bab52698dc7cd42632ad" category="paragraph">이 활용 사례에서 In-Place Analytics Module은 대형 금융 기관에서 긴 백업 시간을 24시간 이상으로 단축하면서 몇 시간 미만으로 단축하도록 지원했습니다.</block>
  <block id="06b83cb579d9aaf1f26d8c4284a5a42e" category="paragraph">NetApp에서 제공하는 Data Fabric을 구성 요소로 사용함으로써 대규모 브로드캐스트 회사는 주문형, 즉각적인 데이터 전송 같은 다양한 데이터 전송 모드에 따라 클라우드 데이터를 사내 데이터 센터에 백업하는 요구사항을 충족시킬 수 있었습니다. 또는 Hadoop/Spark 클러스터 로드를 기반으로 합니다.</block>
  <block id="da17b6db6e3e50f66b5bcaee1d74f8b1" category="paragraph">NetApp 솔루션을 통해 온라인 음악 유통업체는 다양한 지점에서 공간 효율적인 다중 Hadoop 클러스터를 신속하게 구축하여 보고서를 생성하고 예약된 정책을 사용하여 일일 DevTest 작업을 실행할 수 있었습니다.</block>
  <block id="90fc62f886a8c33032d4db8b79ec5814" category="paragraph">한 대형 서비스 공급자는 NetApp이 제공하는 Data Fabric을 사용하여 다양한 클라우드 인스턴스에서 고객에게 멀티 클라우드 분석을 제공합니다.</block>
  <block id="67f07a55567ecfc26b3c7b54823a43ee" category="paragraph">가장 큰 금융 서비스 및 투자 은행 중 하나는 NetApp 네트워크 연결 스토리지 솔루션을 사용하여 I/O 대기 시간을 줄이고 정량 재무 분석 플랫폼을 가속화했습니다.</block>
  <block id="2afe208a471bf6c54f0ccc97f4c6508d" category="inline-link-macro">다음: 활용 사례 1 - Hadoop 데이터 백업</block>
  <block id="aac250a096aacf9aed26ebbd137818da" category="paragraph"><block ref="aac250a096aacf9aed26ebbd137818da" category="inline-link-macro-rx"></block></block>
  <block id="a64b3943d4911d301243b8ac8779ba53" category="summary">이 섹션에서는 다양한 Hadoop 데이터 보호 요구사항을 충족하기 위해 NetApp에서 제공하는 사용 사례 및 솔루션을 요약합니다.</block>
  <block id="23496143e5ca83c13eb4d953786abdcd" category="inline-link-macro">이전: 사용 사례 5 - 분석 워크로드 가속화</block>
  <block id="09b7371b2ae3168a3c54b30e4966e86e" category="paragraph"><block ref="09b7371b2ae3168a3c54b30e4966e86e" category="inline-link-macro-rx"></block></block>
  <block id="ac81718eacd21c51db78a7185a5c0a96" category="paragraph">이 섹션에서는 다양한 Hadoop 데이터 보호 요구사항을 충족하기 위해 NetApp에서 제공하는 사용 사례 및 솔루션을 요약합니다. 고객은 NetApp이 제공하는 Data Fabric을 사용하여 다음을 수행할 수 있습니다.</block>
  <block id="ce0bf05854efb234905c751e40774ab5" category="list-text">NetApp의 풍부한 데이터 관리 기능과 Hadoop 기본 워크플로우와의 통합을 활용하여 적합한 데이터 보호 솔루션을 유연하게 선택할 수 있습니다.</block>
  <block id="925b1719b2db8532854b1de76f928f31" category="list-text">Hadoop 클러스터의 백업 윈도우 시간을 약 70% 단축</block>
  <block id="7de96884f777b768ef12e40582f4d816" category="list-text">Hadoop 클러스터 백업으로 인한 성능 영향을 없앱니다.</block>
  <block id="d5235d7ce8947322a12272f0c6dc7e24" category="list-text">여러 클라우드 공급자로부터 데이터 보호 및 데이터 액세스를 동시에 단일 분석 데이터 소스에 제공</block>
  <block id="61e7eb3536cca4c51ae700159e1d247a" category="list-text">FlexClone ® 기술을 사용하여 빠르고 공간 효율적인 Hadoop 클러스터 복사본을 생성합니다.</block>
  <block id="64bb4a6337ad7b2efa8dc5d43d492edf" category="paragraph">이 문서에 설명된 정보에 대한 자세한 내용은 다음 문서 및/또는 웹 사이트를 참조하십시오.</block>
  <block id="253914d41704f0f326f6595e14005170" category="list-text">NetApp 빅데이터 분석 솔루션</block>
  <block id="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link"><block ref="85eb07da2e4fd15718f8d05d269a4e30" category="inline-link-rx"></block></block>
  <block id="f87d78d98a2357057eba948402e285f0" category="paragraph"><block ref="f87d78d98a2357057eba948402e285f0" category="inline-link-rx"></block></block>
  <block id="b2eb92b872fe536c4a859e695eaf280d" category="list-text">NetApp 스토리지를 사용하는 Apache Spark 워크로드</block>
  <block id="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link"><block ref="a904c9f7327a2cbf0c9411dd8b7551fa" category="inline-link-rx"></block></block>
  <block id="3db0ab5f6c6b92b8d32d80cb1a83e214" category="paragraph"><block ref="3db0ab5f6c6b92b8d32d80cb1a83e214" category="inline-link-rx"></block></block>
  <block id="1bff250c7118efa9007019415bb2730d" category="list-text">Apache Spark용 NetApp 스토리지 솔루션</block>
  <block id="83d445161ea1f91a19d552f783018ea5" category="inline-link"><block ref="83d445161ea1f91a19d552f783018ea5" category="inline-link-rx"></block></block>
  <block id="142c737f7563ed12b8b08b6fc8779b8c" category="paragraph"><block ref="142c737f7563ed12b8b08b6fc8779b8c" category="inline-link-rx"></block></block>
  <block id="df245018c012fa9deefc0e1d65196e46" category="list-text">NetApp에서 지원하는 Data Fabric 기반 Apache Hadoop</block>
  <block id="143ece864a38e1c8267bd8318d458955" category="inline-link"><block ref="143ece864a38e1c8267bd8318d458955" category="inline-link-rx"></block></block>
  <block id="b890b67174812331efb42656a186fa42" category="paragraph"><block ref="b890b67174812331efb42656a186fa42" category="inline-link-rx"></block></block>
  <block id="49d7c87b66a2b688ec65b1a4fe9b5ddc" category="list-text">NetApp 데이터 이동 없는 분석 모듈</block>
  <block id="1d669c79bffe95dd384dffb8309a0d40" category="inline-link"><block ref="1d669c79bffe95dd384dffb8309a0d40" category="inline-link-rx"></block></block>
  <block id="fde1cd76fa73f8065aeb8a97c77b40ec" category="paragraph"><block ref="fde1cd76fa73f8065aeb8a97c77b40ec" category="inline-link-rx"></block></block>
  <block id="0407c27180c9b019e644e8ad4c6a9324" category="section-title">감사의 말</block>
  <block id="c4f052e8512b2541f8154dd256a529d6" category="list-text">Paul Burland, 영업 담당자, ANZ Victoria District Sales, NetApp</block>
  <block id="5d14432aa90b3b3ebfa87b98a1844edb" category="list-text">Hoseb Dermanilian, NetApp 비즈니스 개발 매니저</block>
  <block id="929bdc02c2d9943ae8cb52786476e6c6" category="list-text">Lee Dorrier, NetApp MPSG 이사</block>
  <block id="a3ed56594a87e322fbcf5a6e705a4134" category="list-text">David Thiessen, 시스템 엔지니어, ANZ Victoria District SE, NetApp</block>
  <block id="effdc6a5d743a9db1cd347a2ac8d6b80" category="cell">2018년 1월</block>
  <block id="81d2cd2b484f8c425c2146303b9f1c55" category="cell">사용 사례 5로 업데이트: 분석 워크로드 가속화</block>
  <block id="bc15ae13f16a39532174d0aec78a6432" category="summary">이 설정에서는 Kafka S3 싱크 커넥터를 사용하여 바로 Kafka에서 오브젝트 스토리지의 항목을 읽고 쓰는 방법을 보여 줍니다. 이 테스트에서는 독립 실행형 Confluent 클러스터를 사용했지만 이 설정은 분산 클러스터에 적용됩니다.</block>
  <block id="8b7e627b574df4c4813de77ed2896ad8" category="doc">Confluent S3 커넥터</block>
  <block id="9b154eb37aabb62c75c78bd31457468f" category="inline-link-macro">이전: 확장성의 성능 테스트.</block>
  <block id="aa4f22f43748e77c4fb71f8cb5333c25" category="paragraph"><block ref="aa4f22f43748e77c4fb71f8cb5333c25" category="inline-link-macro-rx"></block></block>
  <block id="524b95dc71b518ce734757656cf9594c" category="paragraph">Amazon S3 싱크 커넥터는 Apache Kafka 항목의 데이터를 Avro, JSON 또는 바이트 형식의 S3 오브젝트로 내보냅니다. Amazon S3 싱크 커넥터는 주기적으로 Kafka의 데이터를 폴링하여 S3로 업로드합니다. 분할자는 모든 Kafka 파티션의 데이터를 청크로 분할하는 데 사용됩니다. 각 데이터 청크는 S3 오브젝트로 표시됩니다. 키 이름은 주제, Kafka 파티션 및 이 데이터 청크의 시작 오프셋을 인코딩합니다.</block>
  <block id="b5829317a86f448ffca89934abe420d3" category="list-text">Confluent 웹 사이트에서 Confluent Kafka를 다운로드하십시오.</block>
  <block id="99eec7bbd3416776cb76d9d8f52bfddc" category="list-text">패키지를 서버의 폴더에 압축을 풉니다.</block>
  <block id="2d025d1c11796b49f323ce393e802635" category="list-text">두 변수를 내보냅니다.</block>
  <block id="e238a3352503bcd61be91778a307f02e" category="list-text">독립 실행형 Confluorent Kafka 설정의 경우 클러스터는 "/tmp"에 임시 루트 폴더를 생성합니다. 또한 ZooKeeper, Kafka, 스키마 레지스트리, 연결, ksql-server를 생성합니다. 제어 센터 폴더를 만들고 해당 구성 파일을 '$CONFLUENT_HOME'에서 복사합니다. 다음 예를 참조하십시오.</block>
  <block id="fc1644d2d2819b87443b810d963409fa" category="list-text">ZooKeeper를 구성합니다. 기본 매개 변수를 사용하는 경우 아무것도 변경할 필요가 없습니다.</block>
  <block id="ad2d4e5ed593359b5d1fe13997541e6f" category="paragraph">위 구성에서 서버를 업데이트했습니다. XXX'재산. 기본적으로 Kafka 리더 선택을 위해서는 Zookeepers가 세 개 필요합니다.</block>
  <block id="b7eb15647b54e1bfd5b79f04012f19ce" category="list-text">고유한 ID로 '/tmp/confluent.406980/zookeeper/data'에 myid 파일을 만들었습니다.</block>
  <block id="78f7f3d70d7fc386cde6a61b7d08bc07" category="paragraph">myid 파일에 대한 마지막 IP 주소 수를 사용했습니다. Kafka, CONNECT, CONTROL-CENTER, Kafka, Kafka-Rest, ksql-server 및 schema-registry 구성.</block>
  <block id="5ad6084775d1229b3edcbda0f353315c" category="list-text">Kafka 서비스를 시작합니다.</block>
  <block id="67228b3b71aba311ab74c0946efe35e8" category="paragraph">각 구성에 대한 로그 폴더가 있어 문제를 해결하는 데 도움이 됩니다. 경우에 따라 서비스를 시작하는 데 더 많은 시간이 걸릴 수 있습니다. 모든 서비스가 실행 중인지 확인합니다.</block>
  <block id="65272a6acb72513d0bfa2bdd8b0c6d1b" category="list-text">'confluent-hub'을 이용하여 Kafka CONNECT를 설치한다.</block>
  <block id="4bdaf464a75dbea14d9240c6722a822a" category="paragraph">confluent-hub install confluentinc/Kafka-connect-S3:10.0.3'을 사용하여 특정 버전을 설치할 수도 있습니다.</block>
  <block id="004220cf4b170d47a455040fde149eaf" category="list-text">기본적으로 '/data/confluent/confluent-6.2.0/share/confluent-hub-components/confluentententinc-kafka-connect-s3'에 confluentinc-kafka-connect-s3이 설치됩니다.</block>
  <block id="fe4b44765b8ad323e0d6a2e6b7325246" category="list-text">새로운 'confluentinc-kafka-connect-s3'으로 플러그인 경로를 업데이트합니다.</block>
  <block id="331885900730ee061e0f6b4f55e62ece" category="list-text">Confluent 서비스를 중지하고 다시 시작합니다.</block>
  <block id="7fe69cf1bb033725fdeb56839e70fe4e" category="list-text">'/root/.aws/credentials' 파일에서 액세스 ID와 비밀 키를 설정한다.</block>
  <block id="fac7d16b475df7919931f2de707a4a45" category="list-text">버킷에 도달할 수 있는지 확인합니다.</block>
  <block id="369f5700a42f83495e179b9e947587fb" category="list-text">S3 및 버킷 구성에 대해 S3-싱크 속성 파일을 구성합니다.</block>
  <block id="3d3c898205223806be88ccecb8f0598c" category="list-text">S3 버킷으로 몇 개의 레코드를 가져옵니다.</block>
  <block id="50b781543cad31f75eed99b8efb20e79" category="list-text">S3 싱크 커넥터를 로드합니다.</block>
  <block id="6e773b2ab9703d3433d0ebfb5a45a3a1" category="list-text">S3 싱크 상태를 확인합니다.</block>
  <block id="b533fadf7b5ac18085d65eb6814528cf" category="list-text">로그를 확인하여 S3 싱크가 항목을 수락할 준비가 되었는지 확인합니다.</block>
  <block id="613093505fc60a58e7893af8aee3b7b8" category="list-text">Kafka의 주제를 확인하십시오.</block>
  <block id="38f7472ee233ba1cc1a7d724a0ca6542" category="list-text">S3 버킷의 오브젝트를 확인합니다.</block>
  <block id="09fa6729fb808be555e2da157c07e47e" category="list-text">내용을 확인하려면 다음 명령을 실행하여 각 파일을 S3에서 로컬 파일 시스템으로 복사합니다.</block>
  <block id="e8eeb400cc1af7c80b7561572c879a12" category="inline-link">아파치 아카이브</block>
  <block id="7d059565bbab6abb5da76e3abcfe6f90" category="list-text">레코드를 인쇄하려면 avro-tools-1.11.0.1.jar (에서 사용 가능)를 사용합니다<block ref="55ee52f435d2dbbc99b651e203ff837e" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="e621a272d292cd32516db52fc07b5855" category="inline-link-macro">다음: ConfFluent 자체 재조정 클러스터.</block>
  <block id="56b9b2115a3169192950ec86c26f6add" category="paragraph"><block ref="56b9b2115a3169192950ec86c26f6add" category="inline-link-macro-rx"></block></block>
  <block id="bf647454e36069fd16f1a7a35cf6a865" category="sidebar">시작하기</block>
  <block id="624e816c7f229d54827ad7bc018eb8da" category="sidebar">지원되는 스토리지 옵션</block>
  <block id="40d267fad784266cb59c36d76573e7c6" category="sidebar">AWS 기반 NetApp(VMC)</block>
  <block id="e7060d0555f178d672a4197df38e1d39" category="sidebar">가상화 환경을 구성합니다</block>
  <block id="2408eed8aca98d53134097e8990c8225" category="sidebar">게스트 연결 스토리지 옵션</block>
  <block id="a64cd881ec955d17faa5e396a891e1e6" category="sidebar">Azure 기반 NetApp(AVS)</block>
  <block id="d1b0ccc0fc426266cf228929d5424ce4" category="sidebar">Google Cloud Platform의 NetApp(GCVE)</block>
  <block id="b84034a4ed4e546b39d5bd268ff06eaa" category="sidebar">시작/모범 사례</block>
  <block id="b0f878715a3d12827d6fb02b0df1f23c" category="sidebar">NetApp 및 VMware: 시작하기</block>
  <block id="690359e9e894d87f3144da561090e3f0" category="sidebar">VMware vSphere 관리자를 위한 NetApp ONTAP의 이점</block>
  <block id="c0bf5949fe87e1e5caf42e4746cd0080" category="sidebar">ONTAP를 사용하는 VMware vSphere 모범 사례</block>
  <block id="584132370dee3f2fccd2ca59888bee18" category="sidebar">퍼블릭 클라우드의 VMware</block>
  <block id="631ed8aac33a641d62d751c3abd77c57" category="sidebar">AWS용 NetApp VMC</block>
  <block id="9f5fbecd7c791f090de17716e147c3a5" category="sidebar">NetApp for Azure AVS</block>
  <block id="b2ab132403a71f074bc776eb29725292" category="sidebar">NetApp for Google Cloud Platform GCVE</block>
  <block id="07a2344d318341cbbdb1983d22dc80f0" category="sidebar">보안 데이터 보호</block>
  <block id="10e5369e04057873bcce3de87e2c6187" category="sidebar">NetApp ONTAP 9를 사용하는 VMware 사이트 복구 관리자(SRM</block>
  <block id="9f4b95975f14f6481a322f453e05049c" category="sidebar">VMware vSphere용 ONTAP 툴 - 제품 보안</block>
  <block id="c4f0254bef611d7217287539f6e00feb" category="sidebar">VMware vSphere 자동화</block>
  <block id="ce006038ddc2a04747fe5a2c9c43b8f5" category="sidebar">데모 및 자습서</block>
  <block id="eccb6fc5c04122d7aef60d899a77089e" category="sidebar">추가 리소스</block>
  <block id="5e4af7ed70d1a211f16d528dcdfc6474" category="sidebar">가상 데스크톱 솔루션</block>
  <block id="cf04feec36847ba9c9671b28661cd1fc" category="sidebar">NetApp 솔루션 설명서</block>
  <block id="38d9ffc674675d65fbb8aabd7e47acd3" category="sidebar">FlexPod 솔루션</block>
  <block id="6f4bb0fa6fee4cf4ae1b8b1fc16e17cb" category="sidebar">레거시 NetApp HCI 솔루션</block>
  <block id="3523ec156cfc8217bb64d1273e5663fa" category="sidebar">NetApp 솔루션 정보</block>
  <block id="d648f2a68a54fd1b3329efc3cf24d29c" category="sidebar">법적 고지</block>
  <block id="91770f038cd944a1d3b9b347edeb2b10" category="sidebar">새로운 기능</block>
  <block id="17c3771ed0b6c1ae15740eff715e9922" category="sidebar">비디오 및 데모</block>
  <block id="e673b6ab6c5649a4df8e874aaa9017b9" category="sidebar">지원되는 구성</block>
  <block id="0333ddced253ee1c6929eda5612dea92" category="sidebar">자동화 요청</block>
  <block id="bdca592f24222e5064192bb9e2f9af6e" category="sidebar">FlexPod - NetApp Cisco 솔루션</block>
  <block id="0da8a1ebf94a3a1e650dbfbd01c69dd9" category="sidebar">FlexPod 솔루션 기술 콘텐츠</block>
  <block id="32591d046a055939af0d128133dc8606" category="sidebar">FlexPod 영업 페이지</block>
  <block id="9e2c62f406d88ad1ee253efd74f593df" category="sidebar">새 솔루션 제안</block>
  <block id="7fd861566be88364067d817b54a44688" category="sidebar">솔루션 피드백을 제공합니다</block>
  <block id="9a9891facf2fa1c878c0fc18c6638005" category="sidebar">AI 통합 인프라</block>
  <block id="12797522e94d75727dd0a05a4ed9f5ff" category="sidebar">NVIDIA와 함께 ONTAP AI</block>
  <block id="687350c847aefbf978e16be26609d101" category="sidebar">NVIDIA DGX A100 시스템 설계 가이드를 지원하는 ONTAP AI</block>
  <block id="4c7a8c5b878fcdf733694f638b393b6b" category="sidebar">NVIDIA DGX A100 시스템 탑재 ONTAP AI 구축 가이드</block>
  <block id="74c684b866e5fcffcc9c5165a491d5b2" category="sidebar">NVIDIA DGX A100 시스템과 Mellanox Spectrum 이더넷 스위치 설계 가이드를 지원하는 ONTAP AI</block>
  <block id="f8363659ae3ab117a0afa4163ca69fc7" category="sidebar">NVIDIA DGX A100 Systems 및 Mellanox Spectrum 이더넷 스위치 포함 ONTAP AI 구축 가이드 를 참조하십시오</block>
  <block id="0c3efd7c1aae12456ab9935ae5fd15e0" category="sidebar">NVIDIA DGX A100 Systems 및 BeeGFS 지원 EF-Series AI</block>
  <block id="c70e778edabe427cd2db90132a56e456" category="sidebar">NVIDIA DGX A100 Systems 및 BeeGFS 설계를 지원하는 EF-Series AI</block>
  <block id="06aa576b3e3e95c5df800228d146af65" category="sidebar">NVIDIA DGX A100 Systems 및 BeeGFS 구축이 포함된 EF-Series AI</block>
  <block id="2967ab4748573d0cb6f2c4084c4fd70f" category="sidebar">BeeGFS 및 NetApp E-Series 참조 아키텍처</block>
  <block id="1db760587a86f5c1b9ab39aa8cf8cf3d" category="sidebar">NetApp E-Series 스토리지로 IBM Spectrum Scale 구축</block>
  <block id="08479c0355c887a02e772206b0d5d7f5" category="sidebar">AI 및 ML 모델 교육 워크로드용 NetApp ONTAP 및 Lenovo ThinkSystem SR670</block>
  <block id="e648dd2d4df65a903e9c1204d81abaed" category="sidebar">AI 및 ML 모델 교육 워크로드용 NetApp AFF A800 및 Fujitsu Server PRIMERGY GX2570 M5</block>
  <block id="6a571fb799acb43b64f874729f838e2a" category="sidebar">데이터 파이프라인, 데이터 레이크 및 관리</block>
  <block id="c79bd5ac7ebc0eae5588b9ad529a380f" category="sidebar">자율 주행 워크로드를 위한 NetApp StorageGRID 데이터 레이크</block>
  <block id="fad62e8b886e655813cc4ce635152f62" category="sidebar">Trident 구축</block>
  <block id="8ad188089680179dea816084001d7bf0" category="sidebar">AI 및 분석 워크플로우를 위한 E-Series 및 BeeGFS로 데이터 이동</block>
  <block id="ae270ffdc87820776fadfe121aa13143" category="sidebar">NetApp AI를 통한 감정 분석</block>
  <block id="f74720767a0bf20cfdb6bba5f215d795" category="sidebar">지원 센터 정서 분석 배포</block>
  <block id="1863627f5be51826024a24014fce26ff" category="sidebar">Azure-Click-Through Rate Prediction의 분산 교육</block>
  <block id="7f39827ac712fa5b76b27ff0b267373c" category="sidebar">NetApp DataOps 툴킷을 사용하여 데이터 세트 및 모델 버전 관리</block>
  <block id="458df51beb3b33cfa61bdc8725403f5b" category="sidebar">참고용 Jupyter 노트북</block>
  <block id="70be05b3500f28affc2d048f81c4f7ab" category="sidebar">분산된 Azure 교육 - 차선 감지</block>
  <block id="7767872606b9c99eb656c9568c1fdd83" category="sidebar">차선 감지 – AI를 통한 분산된 교육</block>
  <block id="ce3b746194cb1fb7d96dfe14187115e0" category="sidebar">데이터 캐싱을 지원하는 하이브리드 클라우드 AI 운영 체제</block>
  <block id="549d044fec039c71abf82f76a0d7969c" category="sidebar">빅 데이터 환경에서 AI 환경으로 데이터 이동</block>
  <block id="18e04180e0442e18a559941bb8de310c" category="sidebar">Edge-NetApp에서 Lenovo ThinkSystem을 사용한 AI 추론 - 솔루션 설계</block>
  <block id="f1e7c981dec3bcee348bda96c55363c4" category="sidebar">NVIDIA를 통한 대화형 AI</block>
  <block id="d5c1931461d1e204a84a486796df2cca" category="sidebar">실행 시 NetApp 오케스트레이션 솔루션: AI</block>
  <block id="c0a0f5bbb431dea70000d73b29e50249" category="sidebar">AI 실행을 통한 최적의 클러스터 및 GPU 활용률</block>
  <block id="09c995632f33d1ee4a581eb951793f35" category="sidebar">AI 설치 실행</block>
  <block id="5c9e37e6d7e6f5e3a76854d8343d626b" category="sidebar">AI 대시보드 및 뷰 실행</block>
  <block id="29ebede332931243e314d8a3f333c1a7" category="sidebar">AI CLI 실행 에서 작업 제출</block>
  <block id="2943702718c42a5063e0c70598cebdc6" category="sidebar">자율 주행 워크로드를 위한 NetApp ONTAP AI 솔루션 설계</block>
  <block id="d11813566a7c636e892d384601baf2c3" category="sidebar">의료 서비스를 위한 NetApp ONTAP AI 참조 아키텍처: 진단 이미징</block>
  <block id="ab8526a90cc9cc979ddd23c87fff57bd" category="sidebar">금융 서비스 워크로드를 위한 NetApp ONTAP AI 참조 아키텍처</block>
  <block id="6efd886c994d37b6577e22359be2310e" category="sidebar">NetApp E-Series 및 BeeGFS를 통해 AI 배포</block>
  <block id="3863e8a73e226ce0c0a6ad02b90ee75b" category="sidebar">NetApp E-Series 시스템을 사용한 Quantum StorNext 설계 가이드 를 참조하십시오</block>
  <block id="7891972f4586e6ee183ea541991ebe9f" category="sidebar">NetApp E-Series 시스템을 사용하는 Quantum StorNext 구축 가이드 를 참조하십시오</block>
  <block id="54d2cdd3035ca1cdff5803c30f2ed2e1" category="sidebar">Oracle Database 구축</block>
  <block id="c880b35e02dbb5854452c86028138e2a" category="sidebar">NetApp ONTAP에 Oracle 데이터베이스 구축</block>
  <block id="699700175d80778f1738d906ee9540d5" category="sidebar">시작하기 및 요구 사항</block>
  <block id="210fdbe41d80b2e8690a970de86a7ffb" category="sidebar">Oracle 19c AWX/Tower 구축 자동화</block>
  <block id="13cf6478a61a7904a3062d587248fb75" category="sidebar">자동화된 Oracle 19c CLI 구축</block>
  <block id="12367669ba6a0b6e059b69b5a95f2902" category="sidebar">Oracle 데이터베이스 데이터 보호</block>
  <block id="3e9d3644ee18a66c51ddd16b668eaa5a" category="sidebar">자동화된 Oracle 데이터 보호</block>
  <block id="82be90bcfc8fd03855e030edaa25583a" category="sidebar">AWX/Tower를 위한 자동화된 Oracle 데이터 보호</block>
  <block id="bc113eb23aa0579a5e1d93e97ca13635" category="sidebar">Oracle Databases on NetApp EF-Series 를 참조하십시오</block>
  <block id="78898e52fcbdc5337204a384f2456d4f" category="sidebar">Microsoft SQL Server를 참조하십시오</block>
  <block id="61def2ac347af2f10fd60cd67052a311" category="sidebar">참조 디자인(실시간 고급 디자인)</block>
  <block id="89447eb7454239e11376250fa04a88f7" category="sidebar">Clustered Data ONTAP을 사용하는 Windows 기반 Microsoft SQL Server와 SAP</block>
  <block id="7c02456b91ace7501ea6f18d1657dcf7" category="sidebar">Microsoft SQL Server 현대화</block>
  <block id="5c008a8422e884d74da1d4b50a7ada55" category="sidebar">Microsoft SQL Server with NetApp EF-Series 모범 사례 가이드 를 참조하십시오</block>
  <block id="30b22b544972f5adb280ca2975099846" category="sidebar">SnapCenter을 사용한 하이브리드 클라우드 데이터베이스 솔루션</block>
  <block id="59f8ae0d5c4ba13dee4828e2727c8859" category="sidebar">온-프레미스로 시작 중입니다</block>
  <block id="ef55a9d1028eac237813e753d20134df" category="sidebar">VMware - 퍼블릭 클라우드</block>
  <block id="27c378e12a7c59dc5aa13b13cc6cecff" category="sidebar">하이퍼스케일러 클라우드의 VMware Cloud</block>
  <block id="452b0b090c1c37a0d467a8df764fd81f" category="sidebar">하이퍼스케일러 클라우드의 NetApp 스토리지</block>
  <block id="2190ab0d2f6281b2f3a73e0fc8e1f560" category="sidebar">요약 및 결론</block>
  <block id="75fcfea0185575f935a7f5f149efd8ca" category="sidebar">VMware 하이브리드 클라우드 사용 사례</block>
  <block id="e251010eb0cac5793d760ab2e5f51473" category="sidebar">사용 사례 개요</block>
  <block id="5d7b876a73a9025080fbf6dd921d1fdd" category="sidebar">데이터 마이그레이션 및 데이터 보호</block>
  <block id="68dfe5056c735db544868f482f9f1d6f" category="sidebar">NetApp XCP의 모범 사례 지침</block>
  <block id="c5071cdf8081474104ef1eee5ec6d784" category="sidebar">소스 스토리지 상자에서 ONTAP로 ACL을 사용한 CIFS 데이터 마이그레이션</block>
  <block id="712d83d9ce8f26363e9bfd1cba104b88" category="sidebar">NetApp E-Series 및 Commvault 데이터 플랫폼 V11</block>
  <block id="aa8156dc9f7aa240e4f412f2f5fedaf5" category="sidebar">Veeam Backup Replication 9.5의 E-Series 및 EF-Series 레퍼런스 아키텍처 및 스토리지 모범 사례</block>
  <block id="74e4bedcc2ff5b37a8770caa0ef72975" category="sidebar">NetApp E-Series 스토리지를 사용한 Veritas NetBackup 구축</block>
  <block id="029f60716c50acd9acf9ce4a9394c91a" category="sidebar">NIST Multitenant Infrastructure용 HyTrust를 사용한 FISMA 보안 제어</block>
  <block id="2a643eb4634917213492cef085506d45" category="sidebar">NetApp 및 VMware 시작하기</block>
  <block id="6c30682e8603121e14abe8bab7bd88f3" category="sidebar">ONTAP용 VMware 가상화</block>
  <block id="cadc483b04d069f993431e3ac64341bf" category="sidebar">가상 볼륨 및 스토리지 정책 기반 관리</block>
  <block id="1918f1bc0ea91d0e5d8e37878d5ab562" category="sidebar">NetApp ONTAP 9가 포함된 VMware 사이트 복구 관리자</block>
  <block id="86fbb5b9292be9b680987addfa410586" category="sidebar">기존 블록 스토리지 용량 할당</block>
  <block id="805a0828a65bce146a58e3556113b017" category="sidebar">VMFS - Fibre Channel</block>
  <block id="26e113624e0cc32cbe2a26e1cde1da24" category="sidebar">VMFS - Fibre Channel over Ethernet</block>
  <block id="8237af9088e8905784b1cb373e3a080d" category="sidebar">VMFS-iSCSI</block>
  <block id="94cab344ef7124917167bd5415b137cf" category="sidebar">VMFS-NVMe over Fabric을 참조하십시오</block>
  <block id="348ee034e8868e5211a6501c09d4b0f0" category="sidebar">기존 파일 스토리지 용량 할당</block>
  <block id="614b997c0fb5abcd68fda0ab9ca05d69" category="sidebar">NFS-v3</block>
  <block id="912655e9dd57ab01b86691021957e61e" category="sidebar">NFS-v4.1</block>
  <block id="a87e5ca19422686ef96f1e6799e9111d" category="sidebar">VDS(가상 데스크톱 서비스)</block>
  <block id="b89c617ff394cc85df3935994baa194b" category="sidebar">Login VSI를 사용한 단일 서버 로드 테스트</block>
  <block id="6abbceca4793ffe4b329045f63b4d219" category="sidebar">운영 관리</block>
  <block id="1b31ca8ddb749644af37aa10b42e6930" category="sidebar">GPU 고려 사항</block>
  <block id="a1da2a2d050a6b61256020afd015a056" category="sidebar">솔루션을 제공합니다</block>
  <block id="739169d2451850e6df7246db70c28cc7" category="sidebar">ESG 기술 검증: NetApp 가상 데스크톱 서비스를 통해 엔터프라이즈 규모의 VDI</block>
  <block id="4725a75839c620bb95363c5f7f2ee9bc" category="sidebar">VMware Horizon을 참조하십시오</block>
  <block id="e2a1b52ebd707739003f77464bbcaa80" category="sidebar">FlexPod 데스크톱 가상화 솔루션</block>
  <block id="9d0be07780aeb437025d4b3420d12540" category="sidebar">NetApp XCP 데이터 마이그레이션</block>
  <block id="645198fb2e03205a7f761aeaff8ef26f" category="sidebar">NetApp 솔루션 자동화 및 Ansible 시작하기</block>
  <block id="22d04ecae9fae88d0b8d4548a46a545b" category="sidebar">요청 자동화</block>
  <block id="cdc53c90644739ab9cb455ad8b663d7b" category="sidebar">Red Hat OpenShift 개요</block>
  <block id="82ebdc178ed6bd9adb7b66c2edfb70d0" category="sidebar">NetApp 스토리지 시스템 개요</block>
  <block id="aef2d8db139dd41c9ae6c878ab92ae75" category="sidebar">NetApp 스토리지 통합 개요</block>
  <block id="5f6fc3deb668cb75e9e6c8932620df6a" category="sidebar">NetApp Astra Control Center 개요</block>
  <block id="846665f4ec19bffa9d9a8c3937c2f9fd" category="sidebar">Red Hat OpenShift 클러스터를 등록합니다</block>
  <block id="b1dbcb80c89b000949ef64c6d6d6c42b" category="sidebar">보호할 응용 프로그램을 선택합니다</block>
  <block id="2913361a2ab3fddb4242f1761d4a6e38" category="sidebar">애플리케이션 보호</block>
  <block id="b066abadb76f5e6776aa1e7cfdf56b38" category="sidebar">NetApp Astra Trident 개요</block>
  <block id="938033783443233af5517c828deb6d1e" category="sidebar">OpenShift를 위한 고급 구성 옵션</block>
  <block id="d48e549b4fdcc889e0243c53bbb4dda0" category="sidebar">솔루션 검증 및 사용 사례</block>
  <block id="f99e4eb05e28c150680cb72ca8410d93" category="sidebar">NetApp ONTAP를 사용하여 Red Hat OpenShift에서 멀티 테넌시를 구성합니다</block>
  <block id="51a25aff8c490f11d9be543c7af23a0d" category="sidebar">클러스터 관리자 작업</block>
  <block id="244e9cd91466ef1240c125511568880a" category="sidebar">스토리지 관리자 작업</block>
  <block id="bc967dc2d57e6eff184a821bf7577a80" category="sidebar">확장</block>
  <block id="d6bf2b10101446c7afd28ff94926fc44" category="sidebar">운영자를 통해 구축</block>
  <block id="e6b088db24ebe67ed0e9567d309387ec" category="sidebar">워크플로우</block>
  <block id="88c506562ebadd679bb16d76a4558619" category="sidebar">VM 클로닝</block>
  <block id="d313887d8fa4b2493a50d1e00bad440e" category="sidebar">응용 프로그램 수명 주기 관리</block>
  <block id="03cae7751c31cc76a90cf5e94e86eb3a" category="sidebar">거버넌스 및 위험</block>
  <block id="f55899cffbf639043209795d5a1af970" category="sidebar">자원 작성</block>
  <block id="7f8513139888dda0c0ecb82a93548af9" category="sidebar">Confluent Kafka 모범 사례</block>
  <block id="497da8ae75854ffd62dc59e332c15252" category="sidebar">Confluent 자체 재조정 클러스터</block>
  <block id="c9f0818cde41901681a02b50763ec342" category="sidebar">NetApp 하이브리드 클라우드 데이터 솔루션 - 고객 사용 사례를 기반으로 Spark 및 Hadoop</block>
  <block id="924f605d39858bdb10692c8d8f810464" category="sidebar">활용 사례 1 - Hadoop 데이터 백업</block>
  <block id="c028df954696d2e4011963e651237b7c" category="sidebar">사용 사례 2 - 클라우드에서 사내까지 백업 및 재해 복구</block>
  <block id="f1ab9c16fee4088d930b2a43e3d48f64" category="sidebar">사용 사례 3 - 기존 Hadoop 데이터에 대해 DevTest 설정</block>
  <block id="4e7c79467b7b25f0415a3a4538d3e2f5" category="sidebar">사용 사례 4 - 데이터 보호 및 멀티 클라우드 연결</block>
  <block id="f38bc790ec57f948f20cbd270b996cc6" category="sidebar">사용 사례 5 - 분석 워크로드 가속화</block>
  <block id="df6654a22cda1b94cf0f51d6ae94bb69" category="sidebar">다양한 분석 전략을 위한 다양한 솔루션 솔루션 솔루션 개요</block>
  <block id="8e2406d586d4192dc66b85722da1c3b9" category="sidebar">Splunk SmartStore가 포함된 NetApp StorageGRID</block>
  <block id="5e3dc34b61f6a21ffd6549ee40d4631b" category="sidebar">NetApp E-Series E5700 및 Splunk Enterprise</block>
  <block id="427d072a2c1690c6d9ece23bef05477b" category="sidebar">NetApp 스토리지 솔루션을 이용한 Apache Spark 워크로드(구축 가이드)</block>
  <block id="c4c3630750312520bc4b93c16056bfd7" category="doc">NVIDIA 기반 NetApp EF-Series AI</block>
  <block id="e6ee072aeeb0647d8c0cfe75e4cde51d" category="paragraph">NetApp과 NVIDIA의 EF-Series AI 통합 인프라 솔루션 개요</block>
  <block id="f512fcc18626023378bfe28dce07116d" category="list-text"><block ref="f512fcc18626023378bfe28dce07116d" category="inline-link-macro-rx"></block></block>
  <block id="ae02a3224f15623423f197426c44a26d" category="list-text"><block ref="ae02a3224f15623423f197426c44a26d" category="inline-link-macro-rx"></block></block>
  <block id="8ce1a272bf4c47418ea6d69083f2df4f" category="inline-link-macro">BeeGFS 구축 가이드</block>
  <block id="7991adac41b3f0e292dee61e87c39052" category="list-text"><block ref="7991adac41b3f0e292dee61e87c39052" category="inline-link-macro-rx"></block></block>
  <block id="9d2ca817bb7dd69d6f7dc09932a53524" category="summary">NetApp 인공 지능 솔루션은 AI/ML 영역 전반에서 NetApp 스토리지의 기능을 보여주는 전략적 기술 솔루션 세트입니다.</block>
  <block id="b54a1e289898cf21f63715dfe64025b7" category="doc">NetApp 인공 지능 솔루션</block>
  <block id="2bbac71d034e7a7a1fca44c7500e187b" category="doc">NVIDIA를 통한 NetApp ONTAP AI</block>
  <block id="4618b9225719de309c0b0f5aa4718c7b" category="paragraph">NetApp과 NVIDIA의 ONTAP AI 통합 인프라 솔루션 개요</block>
  <block id="ab9d770eb05e7725141740f508566fce" category="section-title">NVIDIA DGX A100 시스템을 지원하는 NetApp ONTAP AI</block>
  <block id="7c962be0dc8fdf28c1c4279fe5256a22" category="section-title">NVIDIA DGX A100 시스템과 Mellanox Spectrum 이더넷 스위치가 포함된 NetApp ONTAP AI</block>
  <block id="78463a384a5aa4fad5fa73e2f506ecfc" category="inline-link-macro">영어</block>
  <block id="37ce0afb395b0346118a74c4f05f20a7" category="list-text"><block ref="3b277c3e8740f32e48fe9dd888ed34aa" category="inline-link-macro-rx"></block>&amp;f:@facet_soultion_mktg=[AI, 분석, 인공 지능]++[NetApp.com AI 블로그]</block>
  <block id="191ea533aa1478d35c965840430fbfe6" category="summary">NetApp의 최신 데이터 분석 솔루션은 AI 부문에서 NetApp 스토리지의 기능을 입증하는 일련의 전략적 기술 역량을 갖추고 있습니다.</block>
  <block id="3f7d09efe0b4d4a65add41ac272194fd" category="doc">NetApp의 최신 데이터 분석 솔루션</block>
  <block id="22169240c9a4c0ab61a4ed13c981c5ef" category="sidebar">AI 워크로드를 위한 통합 인프라</block>
  <block id="8508ab1994a5679882beb6400778e8ba" category="sidebar">NVIDIA를 통한 EF-Series AI</block>
  <block id="ec820f861118408d42b077dbf109f374" category="sidebar">NetApp E-Series 스토리지를 통한 IBM Spectrum Scale</block>
  <block id="b63ada7ec650c01320cddeda05deb779" category="sidebar">Edge-NetApp에서 Lenovo ThinkSystem을 사용한 AI 추론</block>
  <block id="7e9b2db694c8b0a87a271e7085251d0e" category="sidebar">AI용 NetApp ONTAP 및 Lenovo ThinkSystem SR670</block>
  <block id="e5c3eeefe82172631e21562a8d3672a5" category="sidebar">AI용 NetApp AFF A800 및 Fujitsu Server PRIMERGY GX2570 M5</block>
  <block id="2fa3e2a0ff5682666455eed0a7b1b569" category="sidebar">데이터 레이크 및 데이터 파이프라인</block>
  <block id="6ac39037a7efa2708d15c0e0e20fb188" category="sidebar">자율 주행 워크로드를 위한 StorageGRID 데이터 레이크</block>
  <block id="eeb4980c2a89f07abf1a0b927066b23c" category="sidebar">E-Series 및 BeeGFS for AI로 데이터 이동</block>
  <block id="13f985aafb32ac9e387186e5a437f96e" category="sidebar">데이터 캐싱을 지원하는 하이브리드 클라우드 AI</block>
  <block id="ac82c7a9ef13f3b604553ccfe1a5bd76" category="sidebar">마름 및 관리</block>
  <block id="3cd04d0e6cf45786c9e94148f213b537" category="sidebar">AI 파이프라인 및 밤공간 관리를 위한 NetApp AI 컨트롤 플레인</block>
  <block id="447e8e0102d91009c125adb678cd7fb5" category="sidebar">Iguazio를 사용한 MLRun 파이프라인</block>
  <block id="71e6eb0dc5951ca93effe179d000f534" category="sidebar">감정 분석</block>
  <block id="cfff43e76ea0e95d290a279bdb279a2e" category="sidebar">클릭률 예측 - Azure에서 제공되는 분산 교육</block>
  <block id="29931fafbbc65eabe1029aee9a3a5a85" category="sidebar">차선 감지 - Azure에서 분산된 교육</block>
  <block id="7656ac1f9ee1e1763f07a285578d922a" category="sidebar">NVIDIA Jarvis를 사용하는 대화형 AI</block>
  <block id="8f0148532a5b5382ec4f005c8a96a4fa" category="sidebar">자율 주행</block>
  <block id="f869ce5572b45e50fe014954c4248d60" category="sidebar">의료 - 진단 이미징</block>
  <block id="951b9c6690c2a4c1228ada2a9980d5a8" category="sidebar">신용 카드 사기 감지</block>
  <block id="f0b83f1f7d211bfb4e278dafd2d6b4fa" category="sidebar">NetApp 스토리지 솔루션을 사용한 Apache Spark 워크로드</block>
  <block id="6bf79bc16e8a34cf5698aabd27cecef1" category="sidebar">최신 데이터 분석 솔루션 개요</block>
  <block id="cd47dd01745339787e4c7300389401f2" category="sidebar">모범 사례</block>
  <block id="1bd369d8fc8172d625ac41a1815aa09d" category="sidebar">Confluent Kafka 모범 사례</block>
  <block id="3ed3645b4e41749082a0692a758a3132" category="sidebar">하이브리드 클라우드 솔루션 - Spark 및 Hadoop 사용 사례</block>
  <block id="0795007b8521bf374f9ddd4eb68a4a2b" category="sidebar">블로그: Data Lake 및 HPC에서 ONTAP NFS로 XCP for Data Migration을 사용합니다</block>
  <block id="9cb9fe27a24f987a1889d5fc1d5d139e" category="sidebar">BeeGFS 및 NetApp E-Series 구축 가이드</block>
  <block id="d064ecad73d9352507092f40af924057" category="cell">2022년 2월 2일</block>
  <block id="c0598da0ea2338576f8d67854c56e3f6" category="cell">AI 및 최신 데이터 분석을 위한 콘텐츠를 더 효과적으로 구성하기 위한 랜딩 페이지를 생성했습니다</block>
  <block id="84c45df200c907852c1e92875618b432" category="cell">2022년 1월 22일</block>
  <block id="b385810d0a927b9d15a69218e3fb38c4" category="cell">AI 및 분석 워크플로우를 위해 E-Series 및 BeeGFS로 데이터 이동 추가</block>
  <block id="89d5e6802ef5a3ae4296f49d4d6bc447" category="sidebar">추가 리소스</block>
  <block id="8598954d073301b356199d49f5c02a69" category="sidebar">블로그:Apache Spark는 NetApp 데이터 분석 운동장에서 실행됩니다</block>
  <block id="c254d48fc85fff80674335af647fc2d3" category="sidebar">NetApp TV: 빅데이터 분석 재생 목록</block>
  <block id="0a2866cc3e2ba203c7e2e3ebeca395be" category="sidebar">UNIX 기반의 Oracle과 SAP, NetApp Clustered Data ONTAP 기반의 NFS</block>
  <block id="4e36e97d23b00520e4b573859ee4cb26" category="list-text"><block ref="4e36e97d23b00520e4b573859ee4cb26" category="inline-link-macro-rx"></block></block>
  <block id="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link"><block ref="ccc4b678df8ad6453b7f71661f118ae1" category="inline-link-rx"></block></block>
  <block id="b17e2a7e5f42c90b40de5971850339ae" category="list-text">TR-4597: ONTAP용 VMware vSphere<block ref="5938ff9651f6c5e53544676ba8504afc" category="inline-link-rx"></block></block>
  <block id="ae1992b408fce873deb0f11eb017ea19" category="summary">이 검증에서 4대의 서버를 NSD(Network Shared Disk) 서버로 사용하여 GPFS에 물리적 디스크를 제공했습니다. GPFS는 NSD 디스크 위에 생성되어 NFS 내보내기로 내보내므로 NFS 클라이언트가 아래 그림과 같이 액세스할 수 있습니다. XCP를 사용하여 GPFS로 내보낸 NFS의 데이터를 NetApp NFS 볼륨으로 복사했습니다.</block>
  <block id="bc64aad447f072e96947f5d02f7e8134" category="doc">GPFS를 NetApp ONTAP NFS로</block>
  <block id="823313a32a4a1131e0469fac26acbdac" category="inline-link-macro">이전: AI용 Data Mover 솔루션</block>
  <block id="c4e4b7ebe157b09b7d1a0db25078dc45" category="paragraph"><block ref="c4e4b7ebe157b09b7d1a0db25078dc45" category="inline-link-macro-rx"></block></block>
  <block id="9a1bdf4376c8448278cf38263e4da8c7" category="paragraph"><block ref="9a1bdf4376c8448278cf38263e4da8c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="86339fb1bc11f77d6e48efc42d910f0f" category="section-title">GPFS 기본</block>
  <block id="d859f99e3b66fbd7305cfd50ba2d4566" category="paragraph">GPFS에 사용되는 노드 유형은 다음과 같습니다.</block>
  <block id="4ac5c1b5474a4920e2433b8f1610729f" category="list-text">* Admin node. * 관리 명령에서 노드 간 통신에 사용하는 노드 이름을 포함하는 선택적 필드를 지정합니다. 예를 들어, 관리자 노드 mastr-51.netapp.com` 가 클러스터의 다른 모든 노드에 네트워크 검사를 전달할 수 있습니다.</block>
  <block id="6659be8d3c5ae97ae05588383a9efb5a" category="list-text">* 쿼럼 노드. * 쿼럼이 파생되는 노드 풀에 노드가 포함되어 있는지 여부를 확인합니다. 쿼럼 노드로 적어도 하나의 노드가 필요합니다.</block>
  <block id="504f43a7f6382dae9e638f1c396a1779" category="list-text">* Manager Node. * 노드가 파일 시스템 관리자 및 토큰 관리자를 선택할 수 있는 노드 풀의 일부인지 여부를 나타냅니다. 둘 이상의 노드를 관리자 노드로 정의하는 것이 좋습니다. 관리자로 지정하는 노드 수는 워크로드와 GPFS 서버 라이센스 수에 따라 다릅니다. 대규모 병렬 작업을 실행 중인 경우 웹 애플리케이션을 지원하는 4노드 클러스터보다 더 많은 관리자 노드가 필요할 수 있습니다.</block>
  <block id="48b637b1e31141b7e6faae1b7c6d8be2" category="list-text">* NSD 서버. * GPFS와 함께 사용할 각 물리적 디스크를 준비하는 서버입니다.</block>
  <block id="8cd64755dc629d6061cef8f3bdddfe8f" category="list-text">* 프로토콜 노드. * NFS를 통해 모든 SSH(Secure Shell) 프로토콜을 통해 GPFS 데이터를 직접 공유하는 노드입니다. 이 노드에는 GPFS 서버 라이센스가 필요합니다.</block>
  <block id="d1a65ffa2a3768b3a494baba34855023" category="section-title">GPFS, NFS 및 XCP의 운영 목록입니다</block>
  <block id="089009e49dc3cafdc4329d07f11c5250" category="paragraph">이 섹션은 GPFS를 만들고 GPFS를 NFS 내보내기로 내보낸 후 XCP를 사용하여 데이터를 전송하는 작업 목록을 제공합니다.</block>
  <block id="1d9da206467eb5273c4b522820cfddb2" category="section-title">GPFS 생성</block>
  <block id="454f38a55393f7773c6e59f13eb6fef5" category="paragraph">GPFS를 만들려면 다음 단계를 완료하십시오.</block>
  <block id="a69093440b15d387cf13aadb026e36a9" category="list-text">서버 중 하나에서 Linux 버전에 대한 스펙트럼 스케일 데이터 액세스를 다운로드하고 설치합니다.</block>
  <block id="8a3d13c75e4dd8c8cffdf92d8e9dd956" category="list-text">모든 노드에 필수 구성 요소 패키지(예: Chef)를 설치하고 모든 노드에서 SELinux(Security-Enhanced Linux)를 비활성화합니다.</block>
  <block id="9356dbe859ed4334d7e27c641d7dd594" category="list-text">설치 노드를 설정하고 클러스터 정의 파일에 관리 노드 및 GPFS 노드를 추가합니다.</block>
  <block id="1bdc86658a65033989c8064812818633" category="list-text">관리자 노드, 쿼럼 노드, NSD 서버 및 GPFS 노드를 추가합니다.</block>
  <block id="d55b679ec8a82b729ae03c882f27b80e" category="list-text">GUI, 관리 및 GPFS 노드를 추가하고, 필요한 경우 추가 GUI 서버를 추가합니다.</block>
  <block id="f4e47c4647a3dafebf21a5f40cfa7f9c" category="list-text">다른 GPFS 노드를 추가하고 모든 노드 목록을 확인하십시오.</block>
  <block id="303364b5437159140dc70a76a77e8aa8" category="list-text">클러스터 정의 파일의 모든 GPFS 노드에 설정할 클러스터 이름, 프로필, 원격 셸 바이너리, 원격 파일 복사본 바이너리 및 포트 범위를 지정합니다.</block>
  <block id="30d14bbe638530772662c104a30d53d3" category="list-text">GPFS 구성 설정을 보고 추가 관리 노드를 추가합니다.</block>
  <block id="d6daa755d449b0cec4c1c23153b9a0be" category="list-text">데이터 수집을 비활성화하고 데이터 패키지를 IBM 지원 센터에 업로드합니다.</block>
  <block id="765ad728fb1bb9eb3c981693321a01ef" category="list-text">NTP를 활성화하고 설치 전에 구성을 미리 확인합니다.</block>
  <block id="1deb66562b5d0f8ce755a102f2731d8d" category="list-text">NSD 디스크를 구성, 생성 및 확인합니다.</block>
  <block id="f54668a02541c80dd54234689ef58ad4" category="list-text">GPFS를 생성합니다.</block>
  <block id="048c1f8a018373ca436ef1a91fe6be57" category="list-text">GPFS를 마운트합니다.</block>
  <block id="18a8260437fd56c8bdc1f994d860e490" category="list-text">GPFS에 필요한 권한을 확인하고 제공하십시오.</block>
  <block id="a150a1930bbf429fc0204993b66d46cb" category="list-text">ddd 명령을 실행하여 GPFS 읽기 및 쓰기를 확인합니다.</block>
  <block id="83cd36fb568894200fe5f9cf7f7e1193" category="section-title">GPFS를 NFS로 내보냅니다</block>
  <block id="e2fc86fc4827b925f5cccecdcd51d6b1" category="paragraph">GPFS를 NFS로 내보내려면 다음 단계를 완료하십시오.</block>
  <block id="af125b713cb0d82420980798e0276ea7" category="list-text">'/etc/exports' 파일을 통해 GPFS를 NFS로 내보냅니다.</block>
  <block id="c953ca93794388b6266ed8529319d420" category="list-text">필요한 NFS 서버 패키지를 설치합니다.</block>
  <block id="c0d11d4c7c65daa849ff313e229d632c" category="list-text">NFS 서비스를 시작합니다.</block>
  <block id="873ad6aeda101f4e6c3a2cb8a46e84ad" category="list-text">GPFS에 파일을 나열하여 NFS 클라이언트를 검증합니다.</block>
  <block id="f9b2649730ae4997f650bc4a2f8c1773" category="section-title">NFS 클라이언트를 구성합니다</block>
  <block id="25be8238edbbbd8936c0385098957520" category="paragraph">NFS 클라이언트를 구성하려면 다음 단계를 수행하십시오.</block>
  <block id="d11e3a3b633c68e9cc37f13adcdfd95a" category="list-text">'/etc/exports' 파일을 통해 GPFS를 NFS로 내보냅니다.</block>
  <block id="64aef4f16c4a9f913379e9668323ed4f" category="list-text">NFS 클라이언트 서비스를 시작합니다.</block>
  <block id="b7eb10685995437ddaa0df5b09b22fb8" category="list-text">NFS 클라이언트의 NFS 프로토콜을 통해 GPFS를 마운트합니다.</block>
  <block id="bb8a91cbc28d52ebb4edab31956c7f58" category="list-text">NFS 마운트 폴더에서 GPFS 파일 목록을 검증합니다.</block>
  <block id="690b19ed08f992a8a2d6e3e872641b2e" category="list-text">XCP를 사용하여 GPFS에서 내보낸 NFS에서 NetApp NFS로 데이터를 이동하십시오.</block>
  <block id="f919d4d761d618912a13cac0895236af" category="list-text">NFS 클라이언트에서 GPFS 파일을 검증합니다.</block>
  <block id="ae2b7fcf15ee142a2de2b3ba9573b414" category="inline-link-macro">다음: HDFS 및 MapR-FS에서 ONTAP NFS로.</block>
  <block id="545d9ad8cb56e65641eb4e8083301a39" category="paragraph"><block ref="545d9ad8cb56e65641eb4e8083301a39" category="inline-link-macro-rx"></block></block>
  <block id="0e0fdc9fc616f1d8648561d150679a8c" category="summary">이 섹션은 GPFS를 구성하고 NetApp XCP를 사용하여 NFS로 데이터를 이동하는 데 필요한 세부 단계를 제공합니다.</block>
  <block id="2cf43976b964350d85af88e8c7c56bfc" category="doc">GPFS에서 NFS로 - 자세한 단계</block>
  <block id="b523cc107fd56956277d38d32b34c938" category="inline-link-macro">이전: 비즈니스 혜택.</block>
  <block id="c415260b3bf5ed05c37515a8e4e526f3" category="paragraph"><block ref="c415260b3bf5ed05c37515a8e4e526f3" category="inline-link-macro-rx"></block></block>
  <block id="7f1260d8686ace0468fd1c74b243b7a1" category="section-title">GPFS 구성</block>
  <block id="de00400b12b028274700d1385b53c26d" category="list-text">서버 중 하나에서 Linux용 Spectrum Scale 데이터 액세스를 다운로드하고 설치합니다.</block>
  <block id="61a030f51cd790deb6f1374ae7e4d88f" category="list-text">모든 노드에 필수 구성 요소 패키지(셰프 및 커널 헤더 포함)를 설치합니다.</block>
  <block id="cea532f5e6d51ac7b08d9f6d71886efe" category="list-text">모든 노드에서 SELinux를 해제합니다.</block>
  <block id="e116db66dcd3a8a38d53716cdd97c179" category="list-text">설치 노드를 설정합니다.</block>
  <block id="6021211d885ba9ec28a1dfcdb72b0542" category="list-text">클러스터 정의 파일에 관리 노드 및 GPFS 노드를 추가합니다.</block>
  <block id="8b361b52f2d7d8ddca7c364e1826015d" category="list-text">관리자 노드 및 GPFS 노드를 추가합니다.</block>
  <block id="d98e392ead2711bea231821e3cafe06e" category="list-text">쿼럼 노드와 GPFS 노드를 추가합니다.</block>
  <block id="549101fb45a9a42ca05a3b680ea6dcdc" category="list-text">NSD 서버 및 GPFS 노드를 추가합니다.</block>
  <block id="0150b7ec1d76a294c8fce802481a2e2d" category="list-text">GUI, 관리 및 GPFS 노드를 추가합니다.</block>
  <block id="5076e582b15cea2e7319261b9eb2dc4e" category="list-text">다른 GUI 서버를 추가합니다.</block>
  <block id="65d8f0643532859908a7e9616439572a" category="list-text">다른 GPFS 노드를 추가합니다.</block>
  <block id="8c6e090e52befa2e95e6d658661749dc" category="list-text">모든 노드를 확인하고 나열합니다.</block>
  <block id="6a21679cbbcb8a64de6016e8efb6b2ea" category="list-text">클러스터 정의 파일에 클러스터 이름을 지정합니다.</block>
  <block id="0e890aabbc215ad4497b26965a0435ad" category="list-text">프로파일을 지정합니다.</block>
  <block id="3296b6b95878e4a01015b9d97691cd23" category="list-text">GPFS에서 사용할 원격 셸 바이너리를 지정하고 '-r 인수'를 사용합니다.</block>
  <block id="6b1edec7f7c05cc2bc9fb41ef76dc8c9" category="list-text">GPFS에서 사용할 원격 파일 복사 바이너리를 지정하고 '-rc 인수'를 사용하십시오.</block>
  <block id="f35c3f5ce8fa5fca13e0eb96082b73fe" category="list-text">모든 GPFS 노드에 설정할 포트 범위를 지정하고, '-e argument'를 사용한다.</block>
  <block id="84807c9c164a1fd83db3680e7b5a6587" category="list-text">GPFS 구성 설정을 봅니다.</block>
  <block id="0addd886868e88c985dddc68658e5767" category="list-text">관리 노드를 추가합니다.</block>
  <block id="d2e4082ff74b3d592d15b584ec3e64a9" category="list-text">NTP를 활성화합니다.</block>
  <block id="bc5f73d061ad4090dd4180838b34fc5a" category="list-text">설치하기 전에 구성을 미리 확인합니다.</block>
  <block id="7f2019dce6ead5054cb5c0d5ccac9d68" category="list-text">NSD 디스크를 구성합니다.</block>
  <block id="bd625aeaf0eb9674912c4c51a421cdb6" category="list-text">NSD 디스크를 생성합니다.</block>
  <block id="bfc7a92fefcdbb8be49ae2f09a04c609" category="list-text">NSD 디스크 상태를 확인합니다.</block>
  <block id="abe092e554a73bb99bd2fd85086ffdce" category="list-text">GPFS에 필요한 권한을 확인하고 제공하십시오.</block>
  <block id="737cdea6c4302200061636f408685896" category="list-text">ddd 명령을 실행하여 GPFS 읽기 및 쓰기를 확인합니다.</block>
  <block id="978d4e591d532e5741bf55bbe09b8672" category="paragraph">GPFS를 NFS로 내보내려면 다음 단계를 완료하십시오.</block>
  <block id="67ae9e67c637e0c39f8d92303b0a9c01" category="list-text">GPFS에 파일을 나열하여 NFS 클라이언트를 검증합니다.</block>
  <block id="e90c8e55eda7dc2ebdbef5659a22a517" category="section-title">NFS 클라이언트를 구성합니다</block>
  <block id="bc2bba568f2fe74e5616fa8f5953b1bf" category="list-text">NFS 클라이언트에 패키지를 설치합니다.</block>
  <block id="7e4215ed068d7218ec28fe900e8feb16" category="list-text">NFS 마운트 폴더에서 GPFS 파일 목록을 검증합니다.</block>
  <block id="77086f36ad335fd9c2cc6a63c1d21d84" category="list-text">XCP를 사용하여 GPFS로 내보낸 NFS에서 NetApp NFS로 데이터를 이동하십시오.</block>
  <block id="96a4b9abe25ad94a1d4ab8e0d2237ef6" category="inline-link-macro">다음: MapR-FS에서 ONTAP NFS로</block>
  <block id="742eb558b5f30d090f7c3ae58b2a554e" category="paragraph"><block ref="742eb558b5f30d090f7c3ae58b2a554e" category="inline-link-macro-rx"></block></block>
  <block id="e0a1057b7f63b9621d22a28a118e4a79" category="summary">이 섹션에서는 이 솔루션의 비즈니스 이점에 대해 설명합니다.</block>
  <block id="7f0cbc7391fd4e971628295e6bff035a" category="doc">비즈니스 이점</block>
  <block id="aaff67cd4222a3be5071cf651cab3d48" category="inline-link-macro">이전: HDFS 및 MapR-FS에서 ONTAP NFS로.</block>
  <block id="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="paragraph"><block ref="4e24fd6dd4cc9fa99c4dddfa8f40ee3e" category="inline-link-macro-rx"></block></block>
  <block id="239f77225835899839f2d1318d1cc1c4" category="paragraph">데이터를 빅데이터 분석에서 AI로 이동하면 다음과 같은 이점이 있습니다.</block>
  <block id="c07548816e2d37db2db301172209009e" category="list-text">서로 다른 Hadoop 파일 시스템과 GPFS에서 데이터를 유니파이드 NFS 스토리지 시스템으로 추출하는 기능</block>
  <block id="17480f22ec6a36806354b84f9824ff80" category="list-text">데이터 전송을 위한 Hadoop 통합 및 자동화 방식</block>
  <block id="626dfcaeea53c1bdef78276b0f594dbf" category="list-text">Hadoop 파일 시스템에서 데이터를 이동하는 데 필요한 라이브러리 개발 비용 절감</block>
  <block id="8576c8e67d6540e2f677340d38ec60e9" category="list-text">NIPAM을 사용하여 단일 데이터 소스에서 여러 네트워크 인터페이스의 총 처리량을 통해 최대 성능을 발휘합니다</block>
  <block id="28338c61f9a9de656b504b14a75bb824" category="list-text">데이터 전송을 위한 예약 방식 및 온디맨드 방식</block>
  <block id="3c70d03dd35337605475e972b74654c8" category="list-text">ONTAP 데이터 관리 소프트웨어를 사용하여 유니파이드 NFS 데이터에 대한 스토리지 효율성 및 엔터프라이즈 관리 기능을 제공합니다</block>
  <block id="2b602714583b0c6daac65349c0e00e16" category="list-text">데이터 전송을 위한 Hadoop 방식을 사용하면 데이터 이동 비용이 전혀 들지 않습니다</block>
  <block id="a3b97091403bff3b38419087acb1c19e" category="inline-link-macro">다음: GPFS에서 NFS로 - 세부 단계.</block>
  <block id="5e982872ec65785f5d685290b9c40026" category="paragraph"><block ref="5e982872ec65785f5d685290b9c40026" category="inline-link-macro-rx"></block></block>
  <block id="600c9e3e31c7cdf2c69044801b9ea998" category="summary">이 섹션에서는 NetApp XCP를 사용하여 MapR-FS 데이터를 ONTAP NFS로 이동하는 데 필요한 자세한 단계를 제공합니다.</block>
  <block id="6a848946dc9169e87668bb9f057c56c2" category="doc">MapR-FS에서 ONTAP NFS로</block>
  <block id="59b0eb4059face89ab060ea59984c8a7" category="inline-link-macro">이전: GPFS에서 NFS로 - 세부 단계.</block>
  <block id="13f1dc977877024b0f36272f1af2b238" category="paragraph"><block ref="13f1dc977877024b0f36272f1af2b238" category="inline-link-macro-rx"></block></block>
  <block id="3362be4f8dc0d043bec6bb8bf22a565b" category="list-text">각 MapR 노드에 대해 LUN 3개를 프로비저닝하고 모든 MapR 노드에 대한 LUN 소유권을 제공합니다.</block>
  <block id="a74eeec8d29cc5a609b980af2aee2fb3" category="list-text">설치 중에 MapR-FS에 사용되는 MapR 클러스터 디스크에 새로 추가된 LUN을 선택합니다.</block>
  <block id="f7dc1a091cd04b392f9a99c5390b9ce2" category="inline-link">MapR 6.1 문서</block>
  <block id="24cb5309ea8c5a7c3244adf133110ecf" category="list-text">에 따라 MapR 클러스터를 설치합니다<block ref="a38d60fa0425a18b5925139ceca806ea" category="inline-link-rx"></block>.</block>
  <block id="7549eec0595c1177d1a3b1a8c556ea8e" category="list-text">Hadoop Jar xxx와 같은 MapReduce 명령을 사용하여 기본 Hadoop 작업을 확인합니다.</block>
  <block id="455177bd981566b3ae1e0084e3381b11" category="list-text">고객 데이터를 MapR-FS에 유지 예를 들어, Teragen을 사용하여 MapR-FS에서 약 테라바이트의 샘플 데이터를 생성했습니다.</block>
  <block id="570bd2111387f5da50ad7d54e23e5fb2" category="list-text">MapR-FS를 NFS 내보내기로 구성합니다.</block>
  <block id="4fe9587feb0e4de26dff3d33bbaf046e" category="list-text">모든 MapR 노드에서 nlockmgr 서비스를 사용하지 않도록 설정합니다.</block>
  <block id="8c5d6c82648b5d5b2a4c82d33569b1c4" category="list-text">'/opt/mMapR/conf/exports' 파일의 모든 MapR 노드에 MapR-FS에서 특정 폴더를 내보냅니다. 하위 폴더를 내보낼 때 다른 권한이 있는 상위 폴더를 내보내지 마십시오.</block>
  <block id="e78b84d9c1ff3b973293510503e86b95" category="list-text">MapR-FS NFS 서비스를 새로 고칩니다.</block>
  <block id="341009af7864703863b08f0bd1df43b5" category="list-text">MapR 클러스터의 특정 서버 또는 서버 세트에 가상 IP 범위를 할당합니다. 그런 다음 MapR 클러스터는 NFS 데이터 액세스를 위해 특정 서버에 IP를 할당합니다. IP를 통해 고가용성을 구현할 수 있습니다. 즉, 특정 IP를 사용하는 서버 또는 네트워크에 장애가 발생할 경우 IP 범위의 다음 IP를 NFS 액세스에 사용할 수 있습니다.</block>
  <block id="5165f49b44f610d03a79da336b53e8f2" category="admonition">모든 MapR 노드에서 NFS 액세스를 제공하려면 각 서버에 가상 IP 세트를 할당하고 NFS 데이터 액세스를 위해 각 MapR 노드의 리소스를 사용할 수 있습니다.</block>
  <block id="fa6899b17d5e71a360316c355d34c8b3" category="paragraph"><block ref="fa6899b17d5e71a360316c355d34c8b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8cb6de965ede92bf8bb036bb8fea6eba" category="paragraph"><block ref="8cb6de965ede92bf8bb036bb8fea6eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="031b138609c608ed553a74b2a1c439e1" category="paragraph"><block ref="031b138609c608ed553a74b2a1c439e1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97532f358124e4f3087e522bb35f2cb8" category="list-text">각 MapR 노드에 할당된 가상 IP를 확인하고 이를 NFS 데이터 액세스에 사용하십시오.</block>
  <block id="d1ed36990409b90ebe749d4e8ddab8b7" category="list-text">NFS 작업을 확인하기 위해 할당된 가상 IP를 사용하여 NFS 내보내기 MapR-FS를 마운트합니다. 하지만 NetApp XCP를 사용하여 데이터를 전송하는 경우 이 단계가 필요하지 않습니다.</block>
  <block id="6288e9b84b4573721ff701d3bdc55fed" category="list-text">MapR-FS NFS 게이트웨이에서 ONTAP NFS로 데이터를 전송하도록 NetApp XCP를 구성합니다.</block>
  <block id="47bcc9815ee0b47ea9de7729c9c727f7" category="list-text">xCP에 대한 카탈로그 위치를 구성합니다.</block>
  <block id="e125588061821db7957020ded3b976f0" category="list-text">라이센스 파일을 '/opt/netapp/xFiles/xCP/'에 복사합니다.</block>
  <block id="76725a579a117275c078f16fdbe1fd04" category="list-text">xCP activate 명령을 사용하여 xCP를 활성화합니다.</block>
  <block id="07f3313db35fd32ada5426648ae5817d" category="list-text">NFS 내보내기에 대한 소스를 확인합니다.</block>
  <block id="7eefcefaba7483a2c7d6c71e934d0f28" category="list-text">여러 소스 IP 및 여러 대상 IP(ONTAP LIF)에서 여러 MapR 노드에서 XCP를 사용하여 데이터를 전송합니다.</block>
  <block id="c2cb3a97c34a702522aba4d19b7a1d39" category="list-text">스토리지 컨트롤러의 로드 분산을 확인합니다.</block>
  <block id="93a2605b6bf89fdb9970a6dbc77dee03" category="paragraph"><block ref="93a2605b6bf89fdb9970a6dbc77dee03" category="inline-link-macro-rx"></block></block>
  <block id="b446e9930ab89aa25e7b422c4c23d83f" category="inline-link-macro">이전: MapR-FS에서 ONTAP NFS로</block>
  <block id="185bcaf9470b338d9a2b58870d7bd2bd" category="paragraph"><block ref="185bcaf9470b338d9a2b58870d7bd2bd" category="inline-link-macro-rx"></block></block>
  <block id="ca79886b03835c933143f8eb102ac932" category="list-text">NetApp 데이터 이동 없는 분석 모듈 모범 사례</block>
  <block id="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link"><block ref="007fcd4e7f754577cf07e39ab5c8dc1d" category="inline-link-rx"></block></block>
  <block id="026671d583a546d6b62291e018f78bf7" category="paragraph"><block ref="026671d583a546d6b62291e018f78bf7" category="inline-link-rx"></block></block>
  <block id="f5ac1e3c252855373c7f660dbd89699d" category="list-text">NetApp FlexGroup 볼륨 모범 사례 및 구현 가이드 를 참조하십시오</block>
  <block id="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link"><block ref="baf8e9fa2301f45f9abf0b6e9dba3e17" category="inline-link-rx"></block></block>
  <block id="f473bc55fb079f0338493530316efc6f" category="paragraph"><block ref="f473bc55fb079f0338493530316efc6f" category="inline-link-rx"></block></block>
  <block id="c9617ae303d0bce89d13bebecca2ea1b" category="paragraph"><block ref="c9617ae303d0bce89d13bebecca2ea1b" category="inline-link-rx"></block></block>
  <block id="46b9839969e4bc429da9cc245c756450" category="cell">버전 3.0</block>
  <block id="b9365bb9132d1eb8770275a763fc5d69" category="cell">2022년 1월</block>
  <block id="e4005842db89b4abb778385f9a8a758f" category="cell">NetApp XCP를 사용하여 HDFS 및 MapR-FS에서 NFS로 데이터를 직접 이동합니다.</block>
  <block id="d835981d77534f5f20446d4648ad7e5b" category="cell">2020년 1월</block>
  <block id="637f51ce71f8f8cadc4b75dfda96d45c" category="cell">xCP가 기본 Data Mover로 포함되어 있습니다. NFS 및 GPFS에 MapR-FS를 NFS 데이터 전송에 추가.</block>
  <block id="a10ba827ae758dee0e50d44366fd3d6d" category="cell">2018년 11월</block>
  <block id="4b3608ccf8a7154699127b487cc49627" category="paragraph">이 문서에서는 인공 지능(AI) 워크플로우에 사용할 수 있도록 빅데이터 분석 및 고성능 컴퓨팅(HPC) 시스템에서 데이터를 이동하는 방법에 대해 설명합니다. AI는 일반적으로 NFS 내보내기를 통해 NFS 데이터를 처리합니다. 하지만 AI 데이터를 빅데이터 분석 및 고성능 컴퓨팅(HPC) 플랫폼에 저장할 수 있습니다. HDFS(Hadoop Distributed File System), Blob(Binary Large Object), S3 스토리지 또는 IBM GPFS(General Parallel File System)가 여기에 해당합니다. 이 문서에서는 Hadoop 네이티브 명령, NetApp In-Place Analytics Module(NIPAM), NetApp XCP를 사용하여 빅데이터 분석 플랫폼과 GPFS에서 NFS로 데이터를 이동하는 방법에 대해 설명합니다. 또한 이 문서에서는 빅데이터 및 HPC에서 AI로 데이터를 이동할 때의 비즈니스 이점에 대해 설명합니다.</block>
  <block id="eea7b9fa88f883b7983320cb8dd802ac" category="summary">이 페이지에서는 AI 운영을 위한 빅데이터 분석의 데이터에 액세스하려고 할 때 고객이 직면할 수 있는 과제에 대해 설명합니다.</block>
  <block id="d4612e7dc1347f1ccbfd5e470dda2295" category="doc">고객의 당면 과제</block>
  <block id="14fd125cf7cc7e6f58e0a07d30ecda87" category="paragraph"><block ref="14fd125cf7cc7e6f58e0a07d30ecda87" category="inline-link-macro-rx"></block></block>
  <block id="b794cc731a2a9499d064b08a32552e78" category="paragraph">AI 운영을 위한 빅데이터 분석에서 데이터에 액세스하려고 할 때 고객이 다음과 같은 과제에 직면할 수 있습니다.</block>
  <block id="593806557377bd8506b6705484962785" category="list-text">고객 데이터가 데이터 레이크 저장소에 있습니다. 데이터 레이크는 정형, 비정형, 반정형, 로그, 머신 간 데이터 등 다양한 유형의 데이터를 포함할 수 있습니다. 이러한 모든 데이터 유형은 AI 시스템에서 처리해야 합니다.</block>
  <block id="43d7d5ce8487763157eabcf01d1cf6ef" category="list-text">AI는 Hadoop 파일 시스템과 호환되지 않습니다. 일반적인 AI 아키텍처는 HDFS 및 HCFS 데이터에 직접 액세스할 수 없으며, 이 데이터는 AI에 대해 이해할 수 있는 파일 시스템(NFS)으로 이동되어야 합니다.</block>
  <block id="e032c722c87677b6dfba13af108c61b8" category="list-text">데이터 레이크 데이터를 AI로 이동하는 작업에는 일반적으로 특수 프로세스가 필요합니다. 데이터 레이크의 데이터 양은 매우 클 수 있습니다. 고객은 AI 시스템으로 데이터를 이동할 수 있는 효율적이고 높은 처리량과 비용 효율적인 방법을 가지고 있어야 합니다.</block>
  <block id="30bd7dc66c05e60d2ea66d09e568cb06" category="list-text">데이터를 동기화하는 중입니다. 고객이 빅데이터 플랫폼과 AI 간의 데이터를 동기화하려는 경우 AI를 통해 처리된 데이터를 분석 처리에 빅데이터와 함께 사용할 수 있습니다.</block>
  <block id="02c553e123c56e4cba5728b7e83bb80b" category="inline-link-macro">다음: Data Mover 솔루션.</block>
  <block id="205e8a4d3382497ff57947382c577faa" category="paragraph"><block ref="205e8a4d3382497ff57947382c577faa" category="inline-link-macro-rx"></block></block>
  <block id="2ea9ecb649c5974bc03036a15d95f5bf" category="summary">AI용 Data Mover 솔루션은 AI 작업에서 Hadoop 데이터를 처리해야 하는 고객의 요구사항을 기반으로 합니다. NetApp은 NIPAM을 사용하여 HDFS에서 NFS로 데이터를 이동합니다. 한 사용 사례에서 고객은 사내 NFS로 데이터를 이동해야 했고, 또 다른 고객은 클라우드의 GPU 클라우드 인스턴스에서 데이터를 처리하기 위해 Windows Azure Storage Blob에서 Cloud Volumes Service로 데이터를 이동해야 했습니다.</block>
  <block id="7f10e017358079527e7045a68782eb14" category="doc">AI용 Data Mover 솔루션</block>
  <block id="2337521acd1f46c410245430b841caa8" category="inline-link-macro">이전: Data Mover 솔루션</block>
  <block id="ee202fa3d5706f12ab6d57e9cb4b4cba" category="paragraph"><block ref="ee202fa3d5706f12ab6d57e9cb4b4cba" category="inline-link-macro-rx"></block></block>
  <block id="b6392eaf0ddf0463d633e69aaeeef3ce" category="paragraph">다음 다이어그램에서는 Data Mover 솔루션 세부 정보를 보여 줍니다.</block>
  <block id="27f83ed51cc554467134084d77b0e050" category="paragraph"><block ref="27f83ed51cc554467134084d77b0e050" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e01b73324e59213b14e79f9d912546bc" category="paragraph">Data Mover 솔루션을 구축하려면 다음 단계가 필요합니다.</block>
  <block id="03337d241355e58cdaa3df5a4bb980ef" category="list-text">ONTAP SAN은 HDFS를 제공하고, NAS는 NIPAM을 통해 NFS 볼륨을 운영 데이터 레이크 클러스터에 제공합니다.</block>
  <block id="0fad6dd0225bf5a5e9c668c30ea5d38a" category="list-text">고객의 데이터는 HDFS 및 NFS에 있습니다. NFS 데이터는 빅데이터 분석 및 AI 운영에 사용되는 다른 애플리케이션의 운영 데이터일 수 있습니다.</block>
  <block id="32477fa182341c04b6e8076232250f76" category="list-text">NetApp FlexClone 기술은 운영 NFS 볼륨의 클론을 생성하여 사내 AI 클러스터에 프로비저닝합니다.</block>
  <block id="4e7e9a946510d25d1b28cc93a3723e69" category="list-text">HDFS SAN LUN의 데이터는 NIPAM 및 "Hadoop distcp" 명령을 사용하여 NFS 볼륨으로 복제됩니다. NIPAM은 여러 네트워크 인터페이스의 대역폭을 사용하여 데이터를 전송합니다. 이 프로세스는 더 많은 데이터를 전송할 수 있도록 데이터 복사 시간을 줄입니다.</block>
  <block id="b0dd56fceeaba1e1db258d1b06d2572d" category="list-text">두 NFS 볼륨 모두 AI 운영을 위해 AI 클러스터에 프로비저닝됩니다.</block>
  <block id="344c1652d7730f66d822b6ed5d07ff77" category="list-text">클라우드의 GPU로 사내 NFS 데이터를 처리하기 위해 NFS 볼륨은 NetApp SnapMirror 기술을 사용해 NPS(NetApp Private Storage)로 미러링되고 GPU를 위한 클라우드 서비스 공급자에 마운트됩니다.</block>
  <block id="c590e653cde69438d43731b18edd533c" category="list-text">고객은 클라우드 서비스 공급자의 GPU에서 EC2/EMR, HDInsight 또는 DataProc 서비스의 데이터를 처리하려고 합니다. Hadoop Data Mover는 데이터를 Hadoop 서비스에서 NIPAM 및 'Hadoop distcp' 명령을 사용하여 Cloud Volumes Services로 이동합니다.</block>
  <block id="8cae7d7989a25f83bf9df9952b16ed2b" category="list-text">Cloud Volumes Service 데이터는 NFS 프로토콜을 통해 AI에 프로비저닝됩니다.AI를 통해 처리되는 데이터는 NIPAM, SnapMirror 및 NPS를 통해 NVIDIA 클러스터와 함께 사내 위치에서 빅데이터 분석을 위한 데이터가 전송될 수 있습니다.</block>
  <block id="980894bd0921c687decdf218e89107e2" category="paragraph">이 시나리오에서는 고객이 사내의 NetApp 스토리지 컨트롤러에서 AI 처리를 위해 필요한 원격 위치의 NAS 시스템에 대용량 파일 개수 데이터가 있습니다. 이 시나리오에서는 XCP 마이그레이션 도구를 사용하여 데이터를 더 빠른 속도로 마이그레이션하는 것이 좋습니다.</block>
  <block id="002cfe6c68deff9c2fcb4fbb3820a5ff" category="paragraph">하이브리드 사용 사례 고객은 Cloud Sync를 사용하여 NFS, CIFS, S3 데이터의 사내 데이터를 클라우드로 마이그레이션할 수 있고, 그 반대로도 NVIDIA 클러스터의 GPU를 사용하여 AI를 처리할 수 있습니다. Cloud Sync와 XCP 마이그레이션 툴은 모두 NFS 데이터를 NetApp ONTAP NFS로 마이그레이션하는 데 사용됩니다.</block>
  <block id="22033f5439b399254e73f6f3588b9b9e" category="inline-link-macro">다음: GPFS에서 NetApp ONTAP NFS로.</block>
  <block id="f56cb05715de107bd001dd11a41b0cf6" category="paragraph"><block ref="f56cb05715de107bd001dd11a41b0cf6" category="inline-link-macro-rx"></block></block>
  <block id="c877e65bbe37324c3309ace4aa7745d1" category="summary">빅데이터 클러스터에서 데이터는 MapR-FS, Windows Azure Storage Blob, S3 또는 Google 파일 시스템과 같은 HDFS 또는 HCFS에 저장됩니다. 우리는 소스에서 Hadoop distcp 명령을 사용하여 NIPAM의 도움을 받아 HDFS, MapR-FS 및 S3를 NetApp ONTAP NFS로 데이터를 복사하는 소스로 사용하여 테스트를 수행했습니다.</block>
  <block id="6d1963202b436934d6b74acc8232dc94" category="inline-link-macro">이전: 고객의 당면 과제.</block>
  <block id="501ee0e125dd4449de2b29015fab6f3e" category="paragraph"><block ref="501ee0e125dd4449de2b29015fab6f3e" category="inline-link-macro-rx"></block></block>
  <block id="013c5604f73da0e909c46aa5d3a670f3" category="paragraph">빅데이터 클러스터에서 데이터는 MapR-FS, Windows Azure Storage Blob, S3 또는 Google 파일 시스템과 같은 HDFS 또는 HCFS에 저장됩니다. 우리는 소스에서 'Hadoop distcp' 명령을 사용하여 NIPAM의 도움을 받아 HDFS, MapR-FS 및 S3를 NetApp ONTAP NFS로 데이터를 복사하는 소스로 사용하여 테스트를 수행했습니다.</block>
  <block id="9fabfa5fcba2e539b6d2c5eff5bb2116" category="paragraph">다음 다이어그램에서는 HDFS 스토리지를 사용하여 실행되는 Spark 클러스터에서 NetApp ONTAP NFS 볼륨으로 이동하는 일반적인 데이터 이동을 보여 줍니다. 이렇게 하면 NVIDIA에서 AI 작업을 처리할 수 있습니다.</block>
  <block id="d824b1bb9493b5a6c5a2e74871468633" category="paragraph"><block ref="d824b1bb9493b5a6c5a2e74871468633" category="inline-image-macro-rx" type="image"></block></block>
  <block id="da6616575a7b32d3eb2fa505007a9a4a" category="paragraph">Hadoop distcp 명령은 MapReduce 프로그램을 사용하여 데이터를 복사합니다. NIPAM은 데이터를 복사할 때 MapReduce와 함께 Hadoop 클러스터의 드라이버 역할을 합니다. NIPAM은 단일 내보내기를 위해 여러 네트워크 인터페이스에 로드를 분산할 수 있습니다. 이 프로세스는 HDFS 또는 HCFS에서 NFS로 데이터를 복사할 때 여러 네트워크 인터페이스에 데이터를 분산하여 네트워크 처리량을 극대화합니다.</block>
  <block id="c2cad9f038dfeecd75697cb4bebe4c68" category="admonition">NIPAM은 MapR에서 지원 또는 인증되지 않았습니다.</block>
  <block id="e68fb74f51fcafb391476c585b1e434d" category="inline-link-macro">다음은 AI용 Data Mover 솔루션입니다.</block>
  <block id="1f4c259e626baca3c7947e6f3db323d4" category="paragraph"><block ref="1f4c259e626baca3c7947e6f3db323d4" category="inline-link-macro-rx"></block></block>
  <block id="5e1ee998c60aed58b6080afc9d8903a3" category="summary">이 문서에서는 NetApp XCP 및 NIPAM을 사용하여 빅데이터 분석 데이터와 HPC 데이터를 AI로 이동하는 방법에 대해 설명합니다. 또한 빅데이터 및 HPC에서 AI로 데이터를 이동하면 얻을 수 있는 비즈니스 이점에 대해서도 설명합니다.</block>
  <block id="82a406843faa25e62de32fd044584709" category="doc">TR-4732: 인공 지능에 대한 빅 데이터 분석 데이터</block>
  <block id="bdd40c24689e02e4043333640734a44e" category="paragraph">이 문서에서는 빅데이터 분석 데이터와 HPC 데이터를 AI로 이동하는 방법에 대해 설명합니다. AI는 NFS 엑스포트를 통해 NFS 데이터를 처리하는 한편, 고객은 HDFS, Blob 또는 S3 스토리지와 같은 빅데이터 분석 플랫폼과 GPFS와 같은 HPC 플랫폼에 AI 데이터를 저장할 수 있습니다. 이 문서에서는 NetApp XCP 및 NIPAM을 사용하여 빅데이터 분석 데이터와 HPC 데이터를 AI로 이동하는 방법에 대해 설명합니다. 또한 빅데이터 및 HPC에서 AI로 데이터를 이동하면 얻을 수 있는 비즈니스 이점에 대해서도 설명합니다.</block>
  <block id="9895310afc8a3755fef2e679c38f32f8" category="section-title">개념 및 구성 요소</block>
  <block id="8ba5fcae463371ff85de74be48ced059" category="section-title">빅데이터 분석 스토리지</block>
  <block id="b5b25f8714075ee7aa7cae37cabc6e77" category="paragraph">빅데이터 분석은 HDFS를 위한 주요 스토리지 제공업체입니다. 고객은 종종 Windows Azure Blob Storage, MapR-FS(MapR-FS) 및 S3 오브젝트 스토리지와 같은 HCFS(Hadoop 호환 파일 시스템)를 사용합니다.</block>
  <block id="201dde15c75147909c8154fe3e727aed" category="section-title">일반 병렬 파일 시스템입니다</block>
  <block id="432f31a1b9dc5a8ef1f048ea3f4f98c8" category="paragraph">IBM의 GPFS는 HDFS에 대한 대안을 제공하는 엔터프라이즈 파일 시스템입니다. GPFS는 애플리케이션에 블록 크기 및 복제 레이아웃을 결정할 수 있는 유연성을 제공하여 우수한 성능과 효율성을 제공합니다.</block>
  <block id="2aff401779cc49866458a642f15c0181" category="inline-link">TR-4382: NetApp 데이터 이동 없는 분석 모듈.</block>
  <block id="ae1165a7ed0006d2dae65ea849898810" category="paragraph">NetApp NIPAM(In-Place Analytics Module)은 NFS 데이터에 액세스하기 위한 Hadoop 클러스터의 역할을 합니다. 이 스트림에는 연결 풀, NFS InputStream, 파일 핸들 캐시 및 NFS OutputStream의 네 가지 구성 요소가 있습니다. 자세한 내용은 을 참조하십시오<block ref="aedae5b2590b798973be1ab298f44ab7" category="inline-link-rx"></block></block>
  <block id="0be6a753178a606f6e24a10fde5ec644" category="section-title">Hadoop 분산 복제본</block>
  <block id="3cc73009b533164939781f9f6a4a1aa0" category="paragraph">Hadoop Distributed Copy(DistCp)는 대규모 클러스터 간 및 클러스터 내 대처 작업에 사용되는 분산 복사 툴입니다. 이 툴은 데이터 배포, 오류 처리 및 보고를 위해 MapReduce를 사용합니다. 파일 및 디렉토리 목록을 확장하고 소스 목록에서 데이터를 복사하기 위한 작업을 매핑하기 위해 파일 및 디렉토리 입력을 수행합니다. 아래 이미지는 HDFS 및 비 HDFS의 DistCp 작업을 보여 줍니다.</block>
  <block id="1a76b3e0f1199267d461c961d30d07a5" category="paragraph"><block ref="1a76b3e0f1199267d461c961d30d07a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8f54af1bdcb54a020503d81bc3b2114" category="paragraph">Hadoop DistCp는 추가 드라이버를 사용하지 않고 두 HDFS 시스템 간에 데이터를 이동합니다. NetApp은 비 HDFS 시스템용 드라이버를 제공합니다. NFS 대상의 경우 NIPAM은 데이터를 복사할 때 Hadoop DistCp가 NFS 대상과 통신하는 데 사용하는 데이터를 복사하는 드라이버를 제공합니다.</block>
  <block id="05fc55cae9e8b2a7fb40e978e4971707" category="paragraph">NetApp Cloud Volumes Service는 최고의 성능을 제공하는 클라우드 네이티브 파일 서비스입니다. 고객은 이 서비스를 통해 신속하게 리소스를 가동하고 속도를 낮추며 NetApp 기능을 사용하여 생산성을 높이고 직원 다운타임을 줄임으로써 출시 기간을 단축할 수 있습니다. Cloud Volumes Service는 전체 데이터 센터 설치 공간을 줄이고 기본 퍼블릭 클라우드 스토리지를 덜 사용하기 때문에 재해 복구 및 클라우드 백업을 위한 최적의 대안이 됩니다.</block>
  <block id="a12ce47d330a9ea070b4fd322ca5f890" category="paragraph">NetApp XCP는 NetApp 제품 간 및 NetApp 간 데이터 마이그레이션을 빠르고 안정적으로 수행할 수 있는 클라이언트 소프트웨어입니다. 이 툴은 대량의 비정형 NAS 데이터를 NAS 시스템에서 NetApp 스토리지 컨트롤러로 복사하도록 설계되었습니다. xCP 마이그레이션 툴은 데이터 마이그레이션, 파일 또는 디렉토리 목록, 공간 보고 등 여러 요청을 병렬로 처리할 수 있는 멀티코어 다중 채널 I/O 스트리밍 엔진을 사용합니다. 기본 NetApp 데이터 마이그레이션 툴입니다. XCP를 사용하여 Hadoop 클러스터 및 HPC에서 NetApp NFS 스토리지로 데이터를 복사할 수 있습니다. 아래 다이어그램에서는 XCP를 사용하여 Hadoop 및 HPC 클러스터에서 NetApp NFS 볼륨으로 데이터를 전송하는 방법을 보여 줍니다.</block>
  <block id="cd7e68aa30250a331c260fee49ff230e" category="paragraph"><block ref="cd7e68aa30250a331c260fee49ff230e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1bce96270b79327e5daf4c0745d66023" category="paragraph">NetApp Cloud Sync는 사내 스토리지와 클라우드 스토리지 간에 NFS, S3 및 CIFS 데이터를 원활하고 안전하게 전송 및 동기화하는 하이브리드 데이터 복제 서비스형 소프트웨어입니다. 이 소프트웨어는 데이터 마이그레이션, 아카이빙, 협업, 분석 등에 사용됩니다. 데이터가 전송된 후 Cloud Sync는 소스와 대상 간의 데이터를 지속적으로 동기화합니다. 그런 다음 델타를 전송합니다. 또한 자체 네트워크, 클라우드 또는 사내 내의 데이터를 보호합니다. 이 소프트웨어는 비용 효율적인 솔루션을 제공하고 데이터 전송을 위한 모니터링 및 보고 기능을 제공하는 용량제 모델을 기반으로 합니다.</block>
  <block id="cbba30a09e75669ecb5b3b2d83a25284" category="inline-link-macro">다음은 고객의 당면 과제입니다.</block>
  <block id="63aa417c654afafebdbdfcaf7a13c8b6" category="paragraph"><block ref="63aa417c654afafebdbdfcaf7a13c8b6" category="inline-link-macro-rx"></block></block>
  <block id="29fb90c4a1468e178582858240052f4c" category="summary">이 솔루션을 위해 NetApp은 데이터 레이크(HDFS) 및 MapR 클러스터 데이터에서 ONTAP NFS로 데이터 마이그레이션을 검증했습니다. MapR-FS 및 HDFS에 데이터가 상주했습니다. NetApp XCP는 HDFS 및 MapR-FS와 같은 분산 파일 시스템에서 ONTAP NFS로 데이터를 직접 마이그레이션하는 새로운 기능을 소개했습니다.</block>
  <block id="d233c10a88f93c454d0e84cd34840512" category="doc">HDFS 및 MapR-FS를 ONTAP NFS로 설정합니다</block>
  <block id="9577f33e5dfe124ba394a5c90a123928" category="inline-link-macro">이전: GPFS에서 NetApp ONTAP NFS로,</block>
  <block id="a503c5d00affd8b681837e8b44490492" category="paragraph"><block ref="a503c5d00affd8b681837e8b44490492" category="inline-link-macro-rx"></block></block>
  <block id="9c02792070008c1748647d8bdbe24432" category="paragraph">이 솔루션을 위해 NetApp은 데이터 레이크(HDFS) 및 MapR 클러스터 데이터에서 ONTAP NFS로 데이터 마이그레이션을 검증했습니다. MapR-FS 및 HDFS에 데이터가 상주했습니다. NetApp XCP는 HDFS 및 MapR-FS와 같은 분산 파일 시스템에서 ONTAP NFS로 데이터를 직접 마이그레이션하는 새로운 기능을 소개했습니다. xCP는 비동기 스레드 및 HDFS C API 호출을 사용하여 MapR-FS 및 HDFS에서 데이터를 통신 및 전송합니다. 아래 그림은 데이터 레이크(HDFS) 및 MapR-FS에서 ONTAP NFS로 데이터 마이그레이션을 보여 줍니다. 이 새로운 기능을 사용하면 소스를 NFS 공유로 내보낼 필요가 없습니다.</block>
  <block id="4581f9b32af32647aa31b2f9d57f6f1f" category="paragraph"><block ref="4581f9b32af32647aa31b2f9d57f6f1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c11c71088d0987243547dd8fc322c2ad" category="section-title">고객이 HDFS 및 MapR-FS에서 NFS로 이동하는 이유는 무엇입니까?</block>
  <block id="b075c8e6a9009d582333c59e237e3646" category="paragraph">Cloudera 및 Hortonworks와 같은 Hadoop 배포 대부분은 HDFS 및 MapR 배포판과 같은 자체 파일 시스템 MapR-FS를 사용하여 데이터를 저장합니다. HDFS 및 MapR-FS 데이터는 머신 러닝(ML) 및 딥 러닝(DL)에 활용할 수 있는 데이터 과학자에게 중요한 통찰력을 제공합니다. HDFS 및 MapR-FS의 데이터는 공유되지 않으며 다른 애플리케이션에서 사용할 수 없습니다. 고객은 공유 데이터, 특히 고객의 중요한 데이터가 여러 애플리케이션에서 사용되는 은행 부문에서 데이터를 찾고 있습니다. 최신 버전의 Hadoop(3.x 이상)은 NFS 데이터 소스를 지원하며, 타사 소프트웨어를 추가하지 않고도 이 소스에 액세스할 수 있습니다. 새로운 NetApp XCP 기능을 사용하면 데이터를 HDFS 및 MapR-FS에서 NetApp NFS로 직접 이동하여 여러 애플리케이션에 액세스할 수 있습니다</block>
  <block id="fa2772759fe171754d3e04460b417464" category="paragraph">12개의 MapR 노드 및 4개의 NFS 서버를 통해 초기 성능 테스트를 위해 AWS(Amazon Web Services)에서 MapR-FS의 데이터를 NFS로 전송하기 위한 테스트가 완료되었습니다.</block>
  <block id="6f6cb72d544962fa333e2e34ce64f719" category="cell">크기</block>
  <block id="5d56dbd20d9ee1ab8a722ff12e331953" category="cell">vCPU</block>
  <block id="4789f23283b3a61f858b641a1bef19a3" category="cell">메모리</block>
  <block id="eec89088ee408b80387155272b113256" category="cell">네트워크</block>
  <block id="e83e5674ab295a6613b60f5e12d1bfe3" category="cell">NFS 서버</block>
  <block id="6215b1525ff41917096b1eb923fe894f" category="cell">i3en.24xLarge</block>
  <block id="26657d5ff9020d2abefe558796b99584" category="cell">96</block>
  <block id="c45b008ff7fe72f83bb47cba575960c7" category="cell">488GiB</block>
  <block id="9f8ce2ff912e3931e4fc14876f3097f2" category="cell">8x 7500 NVMe SSD</block>
  <block id="f899139df5e1059396431415e770c6dd" category="cell">100</block>
  <block id="899f7b8a7c3e28d3161a77da8f1c8e33" category="cell">MapR 노드</block>
  <block id="6ac0fbf236c6d341a7f2c6c92933f744" category="cell">I3en.12xLarge</block>
  <block id="642e92efb79421734881b53e1e1b18b6" category="cell">48</block>
  <block id="1aa80378346dacbf8ce58aaadcefc35e" category="cell">384GiB</block>
  <block id="3ce58620106227953b9e12e2e0633095" category="cell">4x 7500 NVMe SSD</block>
  <block id="c0c7c76d30bd3dcaefc96f40275bdc0a" category="cell">50</block>
  <block id="03e4c674f628169124f81fb7b98f9c92" category="paragraph">초기 테스트에 따르면 20Gbps의 처리량을 확보했으며 일일 2PB의 데이터를 전송할 수 있었습니다.</block>
  <block id="fce5332d471cfbe0baf7fa83eb2d427d" category="inline-link">TR-4863: NetApp XCP-Data Mover, 파일 마이그레이션 및 분석에 대한 모범 사례 지침 - 4863</block>
  <block id="6371d61614d0beaedb75e85d2c297d8f" category="paragraph">HDFS를 NFS로 내보내지 않고 HDFS 데이터 마이그레이션에 대한 자세한 내용은 의 "배포 단계 - NAS" 섹션을 참조하십시오<block ref="6a602f6a965c96a94215a45f0077e771" category="inline-link-rx"></block>.</block>
  <block id="aa722a0d50c9e3bfe81a7128f0e649d7" category="inline-link-macro">다음: 비즈니스 혜택.</block>
  <block id="4e39bc17db35d21d84b6fb1e9786fdb5" category="paragraph"><block ref="4e39bc17db35d21d84b6fb1e9786fdb5" category="inline-link-macro-rx"></block></block>
  <block id="4f25c5c9b33cc2f12b098bd8cc026222" category="sidebar">인공 지능에 빅 데이터 분석 데이터 활용</block>
  <block id="713522228cb3164cc6e71ff6d49c3b13" category="sidebar">GPFS에서 NFS로 - 자세한 단계</block>
  <block id="75afdb5cd8c025ed0681bdb302fcdcda" category="cell">NVA-1160: OperatorHub 및 Ansible을 통해 Astra Control Center 설치 에 새 섹션 추가</block>
  <block id="593fdc7a2167cd2ada3e71219ceb0ecb" category="paragraph">자세한 내용은 Astra Trident 웹 사이트를 참조하십시오<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="3d930ae98e9d9fc9a418d6b8e5e5639f" category="cell">21.12.60</block>
  <block id="8e232cd005846e0f66f39f19aa03103c" category="cell">22.01.0</block>
  <block id="2bb7e89d50aed884078c4b7857f5bb39" category="cell">4.6 EUS, 4.7, 4.8</block>
  <block id="1e90637438eb06672159d2998d220e86" category="open-title">OperatorHub 사용</block>
  <block id="bff0144772c74d96da07b6ccefb79f96" category="list-text">NetApp Support 사이트에 로그인하여 NetApp Astra Control Center의 최신 버전을 다운로드하십시오. 그렇게 하려면 NetApp 계정에 연결된 라이센스가 필요합니다. tarball을 다운로드한 후 관리자 워크스테이션으로 전송합니다.</block>
  <block id="baac643870c95006b4243d078606a15d" category="list-text">설치를 시작하기 전에 Astra Control Center 이미지를 이미지 레지스트리로 밀어 넣으십시오. 이 단계에서는 Docker 또는 Podman을 선택하여 이러한 작업을 수행할 수 있습니다. 두 가지 모두에 대한 지침이 제공됩니다.</block>
  <block id="455cbd59356abfa16dcf7666d4ae6c2b" category="list-title">팟맨</block>
  <block id="ee9b41d8a22021826def077c661525f4" category="list-text">공개적으로 신뢰할 수 없는 개인 이미지 레지스트리를 사용하는 경우 이미지 레지스트리 TLS 인증서를 OpenShift 노드에 업로드합니다. 이렇게 하려면 TLS 인증서를 사용하여 OpenShift-config 네임스페이스에 configmap을 만들고 이를 클러스터 이미지 구성에 패치하여 인증서를 신뢰할 수 있도록 합니다.</block>
  <block id="9c656c969a87783fcf4b94b721f34bc9" category="list-text">Astra Control Center의 "NetApp-acc-operator" 네임스페이스를 생성합니다.</block>
  <block id="788e8355bdd3a21f3a9017a0610940f4" category="list-text">클러스터 관리자 권한으로 Red Hat OpenShift GUI 콘솔에 로그인합니다.</block>
  <block id="3d68b5654b778f026ac691bc6ed70cc5" category="list-text">Operators &gt; OperatorHub 로 이동하여 Astra 를 검색합니다.</block>
  <block id="dc7add750562c445f72d8d016a79ae29" category="list-text">'NetApp-acc-operator' 타일을 선택하고 '설치'를 클릭합니다.</block>
  <block id="c80be3093b470ca8092538e58a261952" category="image-alt">ACC 운전자 타일</block>
  <block id="c65c283737dc37cea2358a91588ff272" category="list-text">Install Operator(사용자 설치) 화면에서 모든 기본 매개변수를 그대로 적용하고 Install(설치)을 클릭합니다.</block>
  <block id="3677d31e24a1853c961f3f1a9a39a1d6" category="image-alt">ACC 운전자 세부 정보</block>
  <block id="ba14525c4ccc9b2f692d062104885b19" category="image-alt">ACC 작업자가 설치를 기다립니다</block>
  <block id="fea3120ff933c367a5882d58dbbe8a08" category="list-text">운용자 설치가 성공하면 View Operator를 클릭합니다.</block>
  <block id="a573acc0621ea72a06ce987a341768bf" category="image-alt">ACC 운전자 설치가 완료되었습니다</block>
  <block id="f99196bf6b988223fab800f28cf0323c" category="list-text">그런 다음 운용자의 Astra Control Center 타일에서 Create Instance를 클릭한다.</block>
  <block id="11f7c569d04eecd142ba5989efcc2da3" category="image-alt">ACC 인스턴스 생성</block>
  <block id="02780e148f03f25db76204c23985d753" category="list-text">Create AstraControlCenter 양식 필드에 내용을 입력하고 Create를 클릭합니다.</block>
  <block id="e31f3b85c5179d88bcf0629842c5342f" category="list-text">필요한 경우 Astra Control Center 인스턴스 이름을 편집합니다.</block>
  <block id="3336a2124154da151aecfe1809d7c821" category="list-text">선택적으로 자동 지원을 활성화하거나 비활성화합니다. 자동 지원 기능을 유지하는 것이 좋습니다.</block>
  <block id="14ddbb7fd85c2907073b06492b95191b" category="list-text">Astra Control Center의 FQDN을 입력합니다.</block>
  <block id="fbcd656fecc902b1994e346dc0627266" category="list-text">Astra Control Center 버전을 입력합니다. 최신 버전이 기본적으로 표시됩니다.</block>
  <block id="311a20c50b8e2d72cf9b31eb6339bff4" category="list-text">Astra Control Center의 계정 이름과 이름, 성, 이메일 주소 등의 관리자 세부 정보를 입력합니다.</block>
  <block id="163e6534daeb1cbd7c56b20a9477802f" category="list-text">볼륨 재확보 정책을 입력합니다. 기본값은 유지입니다.</block>
  <block id="5863d7f52b409374d0d80b1bcbba68fd" category="list-text">이미지 레지스트리에서 이미지를 레지스트리로 푸시하는 동안 레지스트리 FQDN과 조직 이름을 입력합니다(이 예에서는 "astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra`).</block>
  <block id="95279718d2829cd5ed7772d6f0a77ca9" category="list-text">인증이 필요한 레지스트리를 사용하는 경우 이미지 레지스트리 섹션에 암호 이름을 입력합니다.</block>
  <block id="b8f9ae819a2d6559f55aed837fdc2a47" category="list-text">Astra Control Center 리소스 제한에 대한 확장 옵션을 구성합니다.</block>
  <block id="3b489b9fd690a8cdf710454d0ccb5288" category="list-text">기본이 아닌 저장 클래스에 PVC를 배치하려면 보관 클래스 이름을 입력합니다.</block>
  <block id="6b9265a82fa5bd326052ec55e040a54a" category="list-text">CRD 처리 기본 설정을 정의합니다.</block>
  <block id="90aa5928482975bc6ff56f0eaf052451" category="open-title">자동화 [Ansible]</block>
  <block id="b8571b33af3335fed61ab0d7985d007f" category="list-text">Ansible 콘텐츠를 호스팅하는 GitHub 저장소의 클론을 생성합니다.</block>
  <block id="5ed95667cae604c0ddee2dbf04f423fe" category="list-text">NetApp Support 사이트에 로그인하여 NetApp Astra Control Center의 최신 버전을 다운로드하십시오. 그렇게 하려면 NetApp 계정에 연결된 라이센스가 필요합니다. 타볼을 다운로드한 후 워크스테이션으로 전송합니다.</block>
  <block id="6238d4091e12ffa6643c0dc68d72ceab" category="list-text">Astra Control Center가 설치될 OpenShift 클러스터에 대한 관리자 액세스 권한이 있는 kubecononfig 파일을 만들거나 얻습니다.</block>
  <block id="b736c713f352ab43e7543fda4589e96f" category="list-text">디렉토리를 na_Astra_control_suite로 변경합니다.</block>
  <block id="4f31682e7040024757006eed6ba0344a" category="list-text">VAR/VAR.yml 파일을 편집하고 변수를 필수 정보로 채웁니다.</block>
  <block id="8d1e5f9175948d3e6f932794744cde16" category="section-title">설치 후 단계</block>
  <block id="8b70487815961b708f216595f5817311" category="paragraph">Astra Trident의 최신 버전은 2022년 1월 22.01입니다. Kubernetes 배포를 찾을 수 있는 Trident의 버전에 대한 지원 매트릭스입니다<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="b5d9e69ac9444a6a1cfd78cf106c057e" category="list-text">설치 아카이브를 관리 워크스테이션에 다운로드하고 압축을 풉니다. Trident의 현재 버전은 22.01이며 다운로드할 수 있습니다<block ref="defadeb91446b93776c7f5696677985c" category="inline-link-rx"></block>.</block>
  <block id="89c771069f269704306d4ca7b118cc7d" category="paragraph">그러나 NFSv3의 경우 클라이언트와 서버 간에 동시성을 협상하는 메커니즘이 없습니다. 따라서 서버에서 지원되는 값을 사용하여 수동으로 클라이언트 측 sunrpc 슬롯 테이블 항목의 최대 수를 동기화해야 서버의 창 크기를 줄일 필요 없이 NFS 연결에 대한 최상의 성능을 보장할 수 있습니다.</block>
  <block id="9c2d7353683234845149cb6710dc11f8" category="paragraph">ONTAP의 경우 지원되는 최대 sunrpc 슬롯 테이블 항목 수는 128개입니다. 즉, ONTAP는 한 번에 128개의 동시 NFS 요청을 지원할 수 있습니다. 그러나 기본적으로 Red Hat CoreOS/Red Hat Enterprise Linux는 연결당 최대 65,536개의 sunrpc 슬롯 테이블 항목을 갖습니다. 이 값은 128로 설정해야 하며, OpenShift에서 Machine Config Operator(MCO)를 사용하여 설정할 수 있습니다.</block>
  <block id="88cd6afaae477b942c9ab5d396e43cfb" category="paragraph">OpenShift 작업자 노드에서 최대 sunrpc 슬롯 테이블 항목을 수정하려면 다음 단계를 완료하십시오.</block>
  <block id="e7a7478f209d8b5dcaf38a593ce749b3" category="list-text">MCO를 생성한 후에는 모든 작업자 노드에 구성을 적용하고 하나씩 재부팅해야 합니다. 전체 과정은 약 20-30분 정도 소요됩니다. 'OC Get MCP'를 사용하여 기계 설정이 적용되었는지 확인하고 작업자에 대한 기계 구성 풀이 업데이트되었는지 확인합니다.</block>
  <block id="068d2023b916134a0573aaad841124e4" category="paragraph">작업자 노드가 iSCSI 서비스를 실행하도록 구성하려면 다음 단계를 수행하십시오.</block>
  <block id="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link"><block ref="b74877ef96b7f6ef3d913a0c3ebca5e8" category="inline-link-rx"></block></block>
  <block id="086fce5f74cc93b0516aadec33636e09" category="paragraph"><block ref="086fce5f74cc93b0516aadec33636e09" category="inline-link-rx"></block></block>
  <block id="0611f127a7e1e7ef5bbd782030c2e34a" category="paragraph">NetApp ONTAP에서 생성된 다양한 프로젝트에 대해 서로 다른 SVM을 생성한 후 각 SVM을 다른 Trident 백엔드에 매핑해야 합니다. Trident의 백엔드 구성은 OpenShift 클러스터 리소스에 영구 스토리지를 할당하는 역할을 하므로 SVM에 매핑할 세부 정보가 필요합니다. 이 드라이버는 최소한 백엔드의 프로토콜 드라이버여야 합니다. 선택적으로, 볼륨에 스토리지의 용량을 할당하는 방법을 정의하고 볼륨 크기 또는 애그리게이트 사용량 등에 대한 제한을 설정할 수 있습니다. Trident 백엔드의 정의와 관련된 세부 정보를 찾을 수 있습니다<block ref="47a77763732c6cebe093a4a4d61aaa5b" category="inline-link-rx"></block>.</block>
  <block id="891c9b8b0ce367c5e377a1ec23199619" category="paragraph">Trident 백엔드를 구성한 후 다음 단계는 StorageClasses를 구성하는 것입니다. 백엔드가 있는 만큼 스토리지 클래스를 구성하여 각 스토리지 클래스 액세스 권한을 통해 백엔드에서 볼륨을 한 개만 스핀업할 수 있습니다. 스토리지 클래스를 정의하는 동안 storagePools 매개 변수를 사용하여 StorageClass를 특정 Trident 백엔드에 매핑할 수 있습니다. 스토리지 클래스를 정의하는 세부 정보를 찾을 수 있습니다<block ref="1266deb20a7d7c4814b1225e5e572606" category="inline-link-rx"></block>. 따라서 StorageClass에서 Trident 백엔드로 일대일로 매핑하여 하나의 SVM을 가리키도록 합니다. 이렇게 하면 해당 프로젝트에 할당된 StorageClass를 통해 모든 스토리지 청구가 해당 프로젝트 전용 SVM에서 서비스됩니다.</block>
  <block id="b09383080793dfb527084933760af6ed" category="paragraph"><block ref="b09383080793dfb527084933760af6ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f372cf1de9e60f6875a0b24a5c28b07" category="list-text">스냅샷 세부 정보를 입력하고 다음 을 클릭한 다음 스냅샷 을 클릭합니다. 스냅샷을 생성하는 데 약 1분이 소요되며 스냅샷이 성공적으로 생성된 후 상태를 사용할 수 있습니다.</block>
  <block id="42dd75b4fbc849903d5d179a8e68d570" category="paragraph"><block ref="42dd75b4fbc849903d5d179a8e68d570" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0929177ba68c50d4dd73a2a3311ac885" category="paragraph"><block ref="0929177ba68c50d4dd73a2a3311ac885" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f789c3d3aacfbd2d2f99ba395ddb8bc5" category="list-text">백업 세부 정보를 입력하고 백업 파일을 보관할 객체 스토리지 버킷을 선택한 후 다음 을 클릭하고 세부 정보를 검토한 후 백업 을 클릭합니다. 애플리케이션 및 데이터의 크기에 따라 백업이 몇 분 정도 걸릴 수 있으며 백업이 성공적으로 완료된 후 백업 상태를 사용할 수 있게 됩니다.</block>
  <block id="4ba6af660a8dd39dc1d12fb6ee80ba81" category="paragraph"><block ref="4ba6af660a8dd39dc1d12fb6ee80ba81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b1fda3b0f36b6fd708a9871e1c19c50" category="section-title">응용 프로그램을 복원하는 중입니다</block>
  <block id="344aed2ab37311beed01bbd40d93caed" category="paragraph">버튼을 한 번만 누르면 애플리케이션을 동일한 클러스터의 원래 네임스페이스 또는 애플리케이션 보호 및 재해 복구를 위해 원격 클러스터로 복원할 수 있습니다.</block>
  <block id="8ac352fe46a0c45e744688191b7df581" category="list-text">응용 프로그램을 복원하려면 앱 &gt; 관리 탭으로 이동하여 해당 앱을 클릭합니다. 응용 프로그램 이름 옆의 드롭다운 메뉴를 클릭하고 Restore를 클릭합니다.</block>
  <block id="84eb14028ce6ae6f2bf17b71ebe50c69" category="paragraph"><block ref="84eb14028ce6ae6f2bf17b71ebe50c69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b33d7fda666bdb32a2be1f3783106a3c" category="list-text">복원 네임스페이스의 이름을 입력하고 복원할 클러스터를 선택한 다음 기존 스냅샷이나 응용 프로그램 백업에서 복원할지 여부를 선택합니다. 다음 을 클릭합니다.</block>
  <block id="7bbb08271e6b60bc55d6817c7e100528" category="paragraph"><block ref="7bbb08271e6b60bc55d6817c7e100528" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9242e3e5428d2ddbd81dece3073767a" category="list-text">검토 창에서 Restore를 입력하고 세부 정보를 검토한 후 Restore를 클릭합니다.</block>
  <block id="7d6d73878ae09dbfd1e5ee7a0ecab66c" category="inline-image-macro">Astra Control Center 복원 검토</block>
  <block id="b862f033546ae8bdc1bb091ad8b57023" category="paragraph"><block ref="b862f033546ae8bdc1bb091ad8b57023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1b86c631d7b3beb0163beee546245df6" category="list-text">새 애플리케이션은 Restoring 상태로, Astra Control Center는 선택한 클러스터의 애플리케이션을 복구합니다. 응용 프로그램의 모든 리소스가 Astra에 의해 설치 및 감지되면 응용 프로그램은 사용 가능 상태로 전환됩니다.</block>
  <block id="81d066be6d2211bf186bc1960361d8e3" category="paragraph"><block ref="81d066be6d2211bf186bc1960361d8e3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e4600d44abb914105737c3d4a802b87c" category="section-title">애플리케이션 클론 생성</block>
  <block id="5394f3451a07ae7dbe101ceb0725a004" category="paragraph">개발/테스트 또는 애플리케이션 보호 및 재해 복구를 위해 애플리케이션을 원래 클러스터 또는 원격 클러스터에 복제할 수 있습니다. 동일한 스토리지 백엔드에서 동일한 클러스터 내에 애플리케이션을 클론 복제하면 NetApp FlexClone 기술이 사용되므로 PVC를 즉시 클로닝하고 스토리지 공간을 절약할 수 있습니다.</block>
  <block id="04783413cee5e3c613efc7939cea3560" category="list-text">응용 프로그램을 복제하려면 앱 &gt; 관리 탭으로 이동하고 해당 앱을 클릭합니다. 애플리케이션 이름 옆의 드롭다운 메뉴를 클릭하고 클론 을 클릭합니다.</block>
  <block id="1cfafd65804d582aac709fefcd3e60cd" category="paragraph"><block ref="1cfafd65804d582aac709fefcd3e60cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="654c7a62842024ed8e405ed0ac9c4377" category="list-text">새 네임스페이스의 세부 정보를 입력하고 복제할 클러스터를 선택한 다음 기존 스냅샷 또는 백업 또는 애플리케이션의 현재 상태에서 클론을 생성할지 여부를 선택합니다. 그런 다음 세부 정보를 검토한 후 Next(다음) 를 클릭하고 Clone on review(검토 시 복제) 창을 클릭합니다.</block>
  <block id="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="paragraph"><block ref="c0dca29020d3b19fa0a8f6b7acb1ab7e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="60bae26bb7c1e8711f1e39a45fc7b6c7" category="paragraph"><block ref="60bae26bb7c1e8711f1e39a45fc7b6c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d656f81a685df3697a812158d0bd2f21" category="paragraph">NetApp Astra Trident는 Red Hat OpenShift를 포함한 컨테이너 및 Kubernetes 배포를 위한 오픈 소스 및 완전 지원 스토리지 오케스트레이터입니다. 자세한 내용은 Astra Trident 웹 사이트를 참조하십시오<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="list-text"><block ref="fcdf7b66cf4e59ce81d1400e4ca73b4b" category="inline-link-macro-rx"></block></block>
  <block id="ea1c9e7b76d8b7cc203b9f6a9633e241" category="list-text"><block ref="ea1c9e7b76d8b7cc203b9f6a9633e241" category="inline-link-macro-rx"></block></block>
  <block id="4105298f144b4b0e636460eede523df0" category="inline-link-macro">Ansible을 통해 Astra Control Center의 자동 설치</block>
  <block id="64295ddd382f7876d307bac08ad539fe" category="cell"><block ref="64295ddd382f7876d307bac08ad539fe" category="inline-link-macro-rx"></block></block>
  <block id="bd6059cd679908cdb2d015167d51a3fe" category="cell"><block ref="bd6059cd679908cdb2d015167d51a3fe" category="inline-link-macro-rx"></block></block>
  <block id="6dc07ae6ad84b77b5d06f9d3fff5b819" category="cell"><block ref="6dc07ae6ad84b77b5d06f9d3fff5b819" category="inline-link-macro-rx"></block></block>
  <block id="e32276e1eed6ff0e76971afd985cea2d" category="cell"><block ref="e32276e1eed6ff0e76971afd985cea2d" category="inline-link-macro-rx"></block></block>
  <block id="77697d49d0c6b79e2642435a36c8c1e0" category="cell"><block ref="77697d49d0c6b79e2642435a36c8c1e0" category="inline-link-macro-rx"></block></block>
  <block id="60f031c992a9c99aa5413bddb0ecc644" category="cell"><block ref="60f031c992a9c99aa5413bddb0ecc644" category="inline-link-macro-rx"></block></block>
  <block id="13a82ffd84cedcd28833f58d716b4c3c" category="cell"><block ref="13a82ffd84cedcd28833f58d716b4c3c" category="inline-link-macro-rx"></block></block>
  <block id="74d542ee52cd8400c9b9307ed9a99c12" category="list-text">Astra DevOps 사용 사례:</block>
  <block id="3da7df001d5e1f907d2527f52c6ccc00" category="inline-link-macro">NetApp Astra Control을 통해 Kubernetes CI/CD 파이프라인에 보호를 쉽게 통합합니다</block>
  <block id="3f1cbb7eb907b7cb7f46877360d4a588" category="list-text"><block ref="3f1cbb7eb907b7cb7f46877360d4a588" category="inline-link-macro-rx"></block></block>
  <block id="fa4bd1682f261cdd55edf3e8e7dbfef6" category="inline-link-macro">NetApp의 DevOps: Astra Control을 사용하여 사후 분석을 수행하고 애플리케이션을 복원합니다</block>
  <block id="1188d1aaa4a5f54ec1dab3da3576377a" category="list-text"><block ref="1188d1aaa4a5f54ec1dab3da3576377a" category="inline-link-macro-rx"></block></block>
  <block id="ce932b248d7f57bcada97c64dd7429a7" category="inline-link-macro">NetApp Astra Control Center: 어플리케이션 데이터 관리를 위한 간편한 버튼</block>
  <block id="0d47bfb381dd96470ac538b5a112db04" category="list-text"><block ref="0d47bfb381dd96470ac538b5a112db04" category="inline-link-macro-rx"></block></block>
  <block id="6546814199e52492fa0efe5fbff08d5a" category="paragraph">이 솔루션은 현재 SnapCenter에서 지원하는 모든 데이터베이스를 지원하지만 Oracle 및 SQL Server 데이터베이스만 여기에 나와 있습니다. 이 솔루션은 베어 메탈 워크로드도 지원되지만 가상화된 데이터베이스 워크로드에서 검증을 받았습니다.</block>
  <block id="f2a59783d2b5c7be84fec0d6de7a5ae9" category="cell">2022년 3월 8일</block>
  <block id="eab6f1cc9736be0f5d62999f998bf36a" category="cell">새로운 비디오 데모 추가: Astra Control 및 NetApp FlexClone 기술을 사용하여 소프트웨어 개발을 가속화하십시오</block>
  <block id="5df42c63d444f6e9e40d96be8f17ac6f" category="cell">2022-03/01/05</block>
  <block id="9fe0dbff6457627765d03955bd1659be" category="inline-link-macro">비디오: Astra Control 및 NetApp FlexClone 기술로 소프트웨어 개발을 가속화하십시오</block>
  <block id="a0eaa75e3e2b8c6220db02697d4acf1f" category="cell"><block ref="a0eaa75e3e2b8c6220db02697d4acf1f" category="inline-link-macro-rx"></block></block>
  <block id="d5ca81c242aff843ea151d778578cbfc" category="admonition">레지스트리에 신뢰할 수 없는 인증서를 사용하는 경우 셸 스크립트를 편집하고 podman 푸시 명령 "podman push $registry/$(echo$astraImage|SED's/^\////')--tls-verify=false"를 사용하십시오.</block>
  <block id="ec72a928f8eedfaa788b44b6935b50fe" category="doc">NetApp과 Red Hat OpenShift의 Astra Control 및 NetApp FlexClone 기술을 사용하여 소프트웨어 개발 속도 향상</block>
  <block id="b4360d9dcce9e932e3b5b09fdc524745" category="list-text"><block ref="b4360d9dcce9e932e3b5b09fdc524745" category="inline-link-macro-rx"></block></block>
  <block id="fdab91853bf925f2256c6d39ec3f5351" category="section-title">GCP에서 GCVE 구성</block>
  <block id="9e98cd6f2c1243193cfc50a29bbe3bd4" category="list-text"><block ref="9e98cd6f2c1243193cfc50a29bbe3bd4" category="inline-link-macro-rx"></block></block>
  <block id="553bafb094b811158ae732981f2dbb4e" category="list-text"><block ref="553bafb094b811158ae732981f2dbb4e" category="inline-link-macro-rx"></block></block>
  <block id="202373c4c91793dc8fb54647ff8a2241" category="list-text"><block ref="202373c4c91793dc8fb54647ff8a2241" category="inline-link-macro-rx"></block></block>
  <block id="9597c351929448a6eea4162c4f4a80db" category="list-text"><block ref="9597c351929448a6eea4162c4f4a80db" category="inline-link-macro-rx"></block></block>
  <block id="e8318a9e631a084c73ef782e37caec2d" category="list-text"><block ref="e8318a9e631a084c73ef782e37caec2d" category="inline-link-macro-rx"></block></block>
  <block id="169210ceac9b94f0632cd1182961e949" category="open-title">CVO 단일 노드 구축</block>
  <block id="610db6bf34b03f7873afe01d4eec8e58" category="paragraph">이 섹션에는 AWS(Amazon Web Services)에서 단일 노드 NetApp CVO(Cloud Volumes ONTAP)를 구축/구성하기 위한 다양한 Terraform 구성 파일이 포함되어 있습니다.</block>
  <block id="4a537f87e89ac00b1276af84fa6f2da9" category="paragraph">Terraform 문서:<block ref="e2ea72ce6afb985e72624e098135e8e1" category="inline-link-rx"></block></block>
  <block id="c69eb42cd732c6d937af674afc73ba24" category="paragraph">템플릿을 실행하려면:</block>
  <block id="0b2fc5bb85de930f6b1d839951f8df6d" category="list-text">리포지토리를 복제합니다.</block>
  <block id="6f5cc42a3e67b7edb3a2d4b86ebfae01" category="list-text">원하는 폴더로 이동합니다</block>
  <block id="71046100fbc383dd8cd1cdd6160f6d6d" category="list-text">CLI에서 AWS 자격 증명을 구성합니다.</block>
  <block id="4a4f9b0378c89fa21da9e5528c8a7f47" category="list-text">AWS 액세스 키 ID [없음]: AccessKey</block>
  <block id="6bbb2ea6e07d16e69748545bf2ee6a6d" category="list-text">AWS 비밀 액세스 키 [없음]: secretkey</block>
  <block id="7a31be9d48b53cd82a7160af0cd58fbe" category="list-text">기본 지역 이름 [없음]: us-west-2</block>
  <block id="276bf14207394167e2ed4e3eed448680" category="list-text">기본 출력 형식 [None]: json</block>
  <block id="dd08960caafad89635926c55a0efd3a4" category="list-text">VAR/AWS_cvo_single_node_deployment.tfvar의 변수 값을 업데이트합니다</block>
  <block id="e962d97debd0a377828855d79b5ccf66" category="admonition">변수 "AWS_CONNECTOR_DEPLOY_BOOL"을 TRUE/FALSE로 설정하여 커넥터를 배포할 수 있습니다.</block>
  <block id="88cefa0997a2272107223ee543b114db" category="list-text">Terraform 리포지토리를 초기화하여 모든 필수 구성 요소를 설치하고 배포를 준비합니다.</block>
  <block id="046372e4315eccae02c5be2caaac1ac5" category="list-text">Terraform validate 명령을 사용하여 Terraform 파일을 확인합니다.</block>
  <block id="144930ffd88cabf8795c7d4a6698e4ac" category="list-text">구축 과정에서 예상되는 모든 변경 사항을 미리 보려면 구성을 건식 실행하십시오.</block>
  <block id="50a325adfbe874e5e14b044244efa49e" category="list-text">배포를 실행합니다</block>
  <block id="3125f7b5833c80fbd03966accb540bf8" category="paragraph">를 눌러 배포를 삭제합니다</block>
  <block id="58c9aaf9cf3d4d0215afe012b77aa1bc" category="paragraph">커넥터</block>
  <block id="251861170f071d1ebe67b948f5026905" category="paragraph">CVO 구축의 NetApp AWS 커넥터 인스턴스에 대한 Terraform 변수</block>
  <block id="496ee322ba138fdbc777e5ab2e30145e" category="cell">* 이름 *</block>
  <block id="7464a7978b1ad9e7f36e5f0181e97eb5" category="cell">* 유형 *</block>
  <block id="22d8f94f4a088cb8d7c83ec5f44a03af" category="cell">* AWS_CONNECTOR_DEPLOY_BOOL *</block>
  <block id="c26f15e86e3de4c398a8273272aba034" category="cell">불입니다</block>
  <block id="95ab4e4a16c4f585ede4d3c63167c1ee" category="cell">(필수) 커넥터 배포를 확인합니다.</block>
  <block id="e15fa495ec49ba53e0ba45d555c24027" category="cell">* AWS_connector_name *</block>
  <block id="27118326006d3829667a400ad23d5d98" category="cell">문자열</block>
  <block id="5548283861d04af602b7193306751df7" category="cell">(필수) Cloud Manager Connector의 이름입니다.</block>
  <block id="8c3a0cf46a98725e12d666e2e13dc06d" category="cell">* AWS_CONNETOR_REGION *</block>
  <block id="efb4f51f6b08f54633b02a06b94210f2" category="cell">(필수) Cloud Manager Connector가 생성되는 지역</block>
  <block id="358040941579fe064f522f5b1eac2a33" category="cell">* AWS_connector_key_name *</block>
  <block id="5c2f4db5972ecd2062c5f449f09c661f" category="cell">(필수) Connector 인스턴스에 사용할 키 쌍의 이름입니다.</block>
  <block id="0e46676177a5b007dfeefb6ada2b65af" category="cell">* AWS_CONNETOR_COMPANY *</block>
  <block id="a7f1f5d73f372170ea283996e464af43" category="cell">(필수) 사용자의 회사 이름입니다.</block>
  <block id="9b9081642589bb52bb20161632edc5a6" category="cell">* AWS_connector_instance_type *</block>
  <block id="ddd1c9b22f94863b3de9a1b551188553" category="cell">(필수) 인스턴스 유형(예: T3.xLarge). 최소 4개의 CPU와 16GB의 메모리가 필요합니다.</block>
  <block id="f8a700002db36fadde1ab9526f2cf8c3" category="cell">* AWS_connector_subnet_id *</block>
  <block id="76788966b37b9b0df0b8ed78ad67eea9" category="cell">(필수) 인스턴스에 대한 서브넷의 ID입니다.</block>
  <block id="fafb089eb14a5fe730cfadfd7bed4b4f" category="cell">* AWS_CONNETOR_SECURITY_GROUP_ID *</block>
  <block id="52df26383575ad500acf38cc3df88e36" category="cell">* AWS_CONNETOR_IAM_INSTANCE_PROFILE_NAME *</block>
  <block id="59409115b42184ffa519bd9aa24b6816" category="cell">(필수) Connector의 인스턴스 프로파일 이름입니다.</block>
  <block id="8953ca5d18d5f2c4a85fdfe10d30a002" category="cell">* AWS_CONNETOR_ACCOUNT_ID *</block>
  <block id="bba7484e58b18e8edafdbe619961f73f" category="cell">(선택 사항) Connector가 연결될 NetApp 계정 ID 제공되지 않은 경우 Cloud Manager는 첫 번째 계정을 사용합니다. 계정이 없는 경우 Cloud Manager에서 새 계정을 만듭니다. Cloud Manager의 어카운트 탭에서 어카운트 ID를 확인할 수 있습니다<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>.</block>
  <block id="1918f44c178eed586b6fa7d6739af317" category="cell">* AWS_connector_public_IP_bool *</block>
  <block id="a4472307f162bdf147f02784bf81ab9d" category="cell">(선택 사항) 공용 IP 주소를 인스턴스에 연결할지 여부를 나타냅니다. 제공되지 않으면 서브넷의 구성에 따라 연결이 수행됩니다.</block>
  <block id="9fb01bbff06d549bce01928fa2f7784c" category="paragraph">'단일 노드 인스턴스'</block>
  <block id="d166b6e004666a5a8daa6db1c3cf1a13" category="paragraph">단일 NetApp CVO 인스턴스에 대한 Terraform 변수</block>
  <block id="19afa3a1ac092d450f21236f1973c705" category="cell">* cvo_name *</block>
  <block id="59935a520838700b451a3757f31fd4ac" category="cell">(필수) Cloud Volumes ONTAP 작업 환경의 이름입니다.</block>
  <block id="ff855355eebbbfbd54d2734a61c43fd4" category="cell">* cvo_region *</block>
  <block id="b50ada32f992aba9f7055658a79132f2" category="cell">(필수) 작업 환경을 생성할 영역입니다.</block>
  <block id="0e9b90f836062c3007935370ef18245f" category="cell">* cvo_subnet_id *</block>
  <block id="6c7cb9b4623284c101253ed002625e53" category="cell">(필수) 작업 환경을 생성할 서브넷 ID입니다.</block>
  <block id="a99ec45accc4987a7eb2eff5219f96b3" category="cell">* cvo_vpc_id *</block>
  <block id="a179f6c6854fc89c6f118f4d8c201cad" category="cell">(선택 사항) 작업 환경을 생성할 VPC ID입니다. 이 인수를 제공하지 않으면 제공된 서브넷 ID를 사용하여 VPC를 계산합니다.</block>
  <block id="26ff13994e5fbad1e11fc231bc73a5b6" category="cell">cvo_svm_password *</block>
  <block id="c82a889260bdc28c6136ddc6639a4f2e" category="cell">(필수) Cloud Volumes ONTAP의 admin 암호입니다.</block>
  <block id="3815749b59fbccfa0077df4f90c8aa1e" category="cell">* cvo_writing_speed_state *</block>
  <block id="e382698236dcb1567d375a4be3b12c2f" category="cell">(선택 사항) Cloud Volumes ONTAP에 대한 쓰기 속도 설정: ['정상','높음']. 기본값은 '정상'입니다.</block>
  <block id="197b0ef64aabdc02a240f3f472eb4da2" category="open-title">CVO HA 구축</block>
  <block id="a082a9d97b4465f73e12cde3444a5296" category="paragraph">이 섹션에서는 AWS(Amazon Web Services)의 고가용성 쌍에 NetApp CVO(Cloud Volumes ONTAP)를 구축/구성하는 다양한 Terraform 구성 파일을 다룹니다.</block>
  <block id="b31736be0fe5e59cc4905aa080c9ab16" category="list-text">VAR/AWS_cvo_ha_deployment.tfvars의 변수 값을 업데이트합니다.</block>
  <block id="ff8f4d628633e3ceb42dcca91ef2948e" category="paragraph">하쌍</block>
  <block id="f7fbe4e66ae4cece99ae14a24f1c44ef" category="paragraph">HA 쌍의 NetApp CVO 인스턴스에 대한 Terraform 변수</block>
  <block id="018a56af12514193b08f44d59f92fe83" category="cell">* cvo_is_ha *</block>
  <block id="93d83a3a243548e55fb126d283923435" category="cell">(선택 사항) 작업 환경이 HA 쌍인지 여부를 나타냅니다[true, false]. 기본값은 false 입니다.</block>
  <block id="cea330e4ead03fcfec439b1f44be7c07" category="cell">* cvo_node1_subnet_id *</block>
  <block id="3a0cbf54e2a847cd873a45840f9965f5" category="cell">(필수) 첫 번째 노드가 생성될 서브넷 ID입니다.</block>
  <block id="d5d3a5e1275b1995e05472c7bfbcb53f" category="cell">* cvo_node2_subnet_id *</block>
  <block id="5691678a4c059b3a4ebad0f4c6bf6bb5" category="cell">(필수) 두 번째 노드가 생성될 서브넷 ID입니다.</block>
  <block id="4377aa272f4cf89d4bbd39432ffb3b0e" category="cell">* cvo_failover_mode *</block>
  <block id="9d76030e2a28826bff45ea1dff4d6920" category="cell">(선택 사항) HA의 경우 HA 쌍의 페일오버 모드 ['PrivateIP', 'FloatingIP']. 'PrivateIP'는 단일 가용성 구역이고 'FloatingIP'는 여러 가용성 영역을 위한 것입니다.</block>
  <block id="80c8a57adaed641642cd870951a1d4ed" category="cell">* cvo_중재자_subnet_id *</block>
  <block id="49ef0197555436f78dd87f582e510523" category="cell">(선택 사항) 중개자의 서브넷 ID인 HA의 경우.</block>
  <block id="3efb524d034b1e223cb9d31a64f9bbc4" category="cell">* cvo_중재자_key_pair_name *</block>
  <block id="224733036290c1421bed8ad8de688956" category="cell">(선택 사항) HA의 경우 중재자 인스턴스의 키 쌍 이름입니다.</block>
  <block id="069dcc590a2acf756e6ca7f92d7d8355" category="cell">* cvo_cluster_floating_ip *</block>
  <block id="6325a8aefd56c67fab1d0d83b4cb8a2e" category="cell">(선택 사항) HA FloatingIP의 경우 클러스터 관리 부동 IP 주소입니다.</block>
  <block id="618070e07e603612f24fa88a7ab583a8" category="cell">* cvo_data_floating_ip *</block>
  <block id="d8abdbcf87e3308c6a8e731ef574625c" category="cell">(선택 사항) HA FloatingIP의 경우 데이터 부동 IP 주소입니다.</block>
  <block id="f115ec8cf476ea0198405ca27346e423" category="cell">* cvo_data_floating_IP2 *</block>
  <block id="754296c6c8a8cf70377730f6f126f24a" category="cell">* cvo_svm_floating_ip *</block>
  <block id="797d132b963a11de245eae1725911bfe" category="cell">(선택 사항) HA FloatingIP의 경우 SVM 관리 부동 IP 주소입니다.</block>
  <block id="418ba9c064c1fb64b11195c729d6a8b1" category="cell">cvo_route_table_ids *</block>
  <block id="4ee29ca12c7d126654bd0e5275de6135" category="cell">목록</block>
  <block id="671a800e3791f7531a319e8b81e97c44" category="cell">(선택 사항) HA FloatingIP의 경우 부동 IP로 업데이트될 라우트 테이블 ID 목록입니다.</block>
  <block id="5d4a46c0a4567f819ba5935256b18297" category="open-title">FSX 배포</block>
  <block id="d43e39ffb05b35b72664b10dd8b8eb09" category="paragraph">이 섹션에서는 AWS(Amazon Web Services)에서 NetApp ONTAP FSx를 구축/구성하기 위한 다양한 Terraform 구성 파일을 다룹니다.</block>
  <block id="171cc8e4954beec5176905189f71a708" category="list-text">기본 출력 형식 [None](없음):</block>
  <block id="cbc2cee2851524f322f8d71e55d32a64" category="list-text">VAR/AWS_FSX_deployment.tfvars의 변수 값을 업데이트합니다</block>
  <block id="05bf1719b762d4d80bcb0e545b3db1d2" category="paragraph">NetApp AWS 커넥터 인스턴스에 대한 Terraform 변수</block>
  <block id="618716470abe9536903f3c6781c4ac81" category="paragraph">FSx 인스턴스</block>
  <block id="5869d95322d3c435fd999596f0cf2303" category="paragraph">NetApp ONTAP FSx 인스턴스에 대한 Terraform 변수</block>
  <block id="c64f672849455d583204c525f5ea39ad" category="cell">* FSX_NAME *</block>
  <block id="af87bb54b839634f865f7bd7e2be203a" category="cell">* FSX_지역 *</block>
  <block id="02a52209be6996bc01fd629ac6a5b472" category="cell">* FSX_PRIMARY_SUBNET_ID *</block>
  <block id="5dcd0d05819e117f52d439bebd6d2b42" category="cell">(필수) 작업 환경을 생성할 기본 서브넷 ID입니다.</block>
  <block id="0531247f461759a809214a03ea2f5f74" category="cell">* FSX_secondary_subnet_id *</block>
  <block id="b2184e9a131868dbc2332805652a0f02" category="cell">(필수) 작업 환경을 생성할 보조 서브넷 ID입니다.</block>
  <block id="a333cc205644905efae2cf71519da619" category="cell">* FSX_ACCOUNT_ID *</block>
  <block id="323c4fdc16ad2dd9e846afbcd4b69b10" category="cell">(필수) FSx 인스턴스가 연결될 NetApp 계정 ID입니다. 제공되지 않은 경우 Cloud Manager는 첫 번째 계정을 사용합니다. 계정이 없는 경우 Cloud Manager에서 새 계정을 만듭니다. Cloud Manager의 어카운트 탭에서 어카운트 ID를 확인할 수 있습니다<block ref="06d3516203a7f4d79163d93dd508b8c0" category="inline-link-rx"></block>.</block>
  <block id="7355bef79bff8e33a86af33fe4dcca8e" category="cell">* FSX_workspace_id *</block>
  <block id="97377fef3f33f9c8d1fb21c0d81cdf92" category="cell">(필수) 작업 환경의 Cloud Manager 작업 공간의 ID입니다.</block>
  <block id="ab77fdca353b13807c947d554712d8eb" category="cell">* FSX_ADMIN_PASSWORD *</block>
  <block id="c4bd49cb0034d697fd71cae233c3966c" category="cell">* FSX_Throughput_Capacity *</block>
  <block id="e1ae53e33bf94a13f7d73cf885059ea6" category="cell">(선택 사항) 처리량의 용량입니다.</block>
  <block id="011dda542c81d29bda593f0cf6fafdfa" category="cell">* FSX_STORAGE_capacity_size *</block>
  <block id="16b74c686b794890297f7ff7a9c98c9f" category="cell">(선택 사항) 첫 번째 데이터 애그리게이트의 EBS 볼륨 크기입니다. GB의 경우 단위는 [100 또는 500]입니다. TB의 경우 장치는 [1,2,4,8,16]일 수 있습니다. 기본값은 '1'입니다.</block>
  <block id="da7d44d0ad606f586a3b1f567c8502d6" category="cell">* FSX_STORAGE_capacity_size_unit *</block>
  <block id="5ec54d3d7d1db9fbf915daed12667b29" category="cell">(선택 사항) ['GB' 또는 'TB']. 기본값은 'TB'입니다.</block>
  <block id="07cc738168b47a86b740bc01e210b442" category="cell">* FSX_cloudmanager_AWS_credential_name *</block>
  <block id="48dbb4d925fe4a46f28c0a8466a2f628" category="cell">(필수) AWS 자격 증명 계정 이름의 이름입니다.</block>
  <block id="2fbb88fe90f9183c7eab541bc808795f" category="summary">이 페이지에서는 Terraform을 사용하여 클라우드 공급자(AWS, Azure, GCP)에 NetApp 볼륨을 자동으로 구축하는 방법을 설명합니다.</block>
  <block id="8eece2f5500ed61d5d5d24d6b8cc6da5" category="doc">Terraform을 통한 Cloud Volumes Automation</block>
  <block id="e11da9afe91d381489a365c86cc614ab" category="section-title">필수 구성 요소</block>
  <block id="95332f844502bac70e3783f2d906688c" category="list-text">Terraform&gt;=0.13</block>
  <block id="82410a61f302c6bdce619218d5036674" category="list-text">Cloud Manager 계정</block>
  <block id="77913a2ff2c55b56fd6d981e7d7d2303" category="list-text">클라우드 공급자 계정 – AWS, Azure</block>
  <block id="8fdcd620b2871b4f496213f43c8ee21f" category="list-text">호스트 시스템(Terraform에서 지원하는 모든 OS)</block>
  <block id="e5da768f23935e9c380799d86e27d695" category="section-title">공급자 문서</block>
  <block id="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-macro"><block ref="8443f23dd52e13e75f6a652a7e100fb6" category="inline-link-rx"></block></block>
  <block id="b78f34c8bc7d03e88e2a6d7d8907ef93" category="paragraph">Cloud Manager에 대한 Terraform 공급자 문서는 다음 사이트에서 확인할 수 있습니다. <block ref="05e9b3cbe087530696c6230448ff6b71" category="inline-link-macro-rx"></block></block>
  <block id="ef335030cde4c62e318574aa31ee49f7" category="section-title">공급자 버전 제어</block>
  <block id="cc6d892dc2fbac39a7a00c3d822275b8" category="paragraph">공급자 버전을 제어할 수도 있습니다. 이는 Terraform 구성의 필수 _providers 블록에 의해 제어됩니다.</block>
  <block id="bf4e80680b83752f1f57ca7d4e99d09b" category="paragraph">구문은 다음과 같습니다.</block>
  <block id="c26cc3bad4e19f3604486c6e2d4dee15" category="paragraph">공급자 버전 제어에 대해 자세히 알아보십시오.</block>
  <block id="c335a311e2b771c143fbe09512d98021" category="section-title">특정 모듈 실행</block>
  <block id="0d6f6c74055e04156e36ddb127070a54" category="open-title">ANF</block>
  <block id="3f5bad999be275e4e9cf0728a13bf09c" category="paragraph">이 섹션에서는 Azure에서 ANF(Azure NetApp Files) 볼륨을 배포/구성하기 위한 다양한 Terraform 구성 파일을 다룹니다.</block>
  <block id="61d66a29b98e4203b3fc2ea2884a6c5f" category="paragraph">Terraform 문서:<block ref="745f55dd9f8ecc62d59e6b03ca9efbb7" category="inline-link-rx"></block></block>
  <block id="369baedac810ebc745ed2edf7754972b" category="list-text">Azure CLI에 로그인합니다(Azure CLI가 설치되어 있어야 함).</block>
  <block id="443ff7602b19f9692863937e763e1ad2" category="list-text">VAR/Azure_anf.tfvars의 변수 값을 업데이트합니다.</block>
  <block id="95f6ca118177fad8a1dd7e7abb74ce56" category="admonition">"VNET_creation_bool" 및 "subnet_creation_bool" 값을 false로 설정하고 "subnet_id_for_anf_vol"을 제공하여 기존 VNET 및 서브넷을 사용하여 ANF 볼륨을 배포하도록 선택할 수 있습니다. 또한 이 값을 true로 설정하고 새 VNET 및 서브넷을 생성할 수 있습니다. 이 경우 서브넷 ID는 새로 생성된 서브넷에서 자동으로 가져옵니다.</block>
  <block id="cb01f53471a55574a36eafb375d9493a" category="paragraph">단일 NetApp ANF 볼륨에 대한 Terraform 변수</block>
  <block id="98bcef9bf5f44342e688bc29fb3fcbca" category="cell">* az_location *</block>
  <block id="4b05afb76d83065313c3740cd392a5ca" category="cell">(필수) 리소스가 있는 지원되는 Azure 위치를 지정합니다. 이 설정을 변경하면 새 리소스가 생성됩니다.</block>
  <block id="861c040d5ed0212e4bc2aa4f92a2b861" category="cell">az_prefix *</block>
  <block id="e6f149d38df85bed35faeca44370c01c" category="cell">(필수) NetApp Volume을 생성해야 하는 리소스 그룹의 이름입니다. 이 설정을 변경하면 새 리소스가 생성됩니다.</block>
  <block id="7aa7ec2fc803d9041e6dfd5e142dcd23" category="cell">* az_VNET_address_space *</block>
  <block id="c8b090fd446e4181ed79e8e50bed7b91" category="cell">(필수) ANF 볼륨 구축을 위해 새로 생성된 VNET에서 사용할 주소 공간입니다.</block>
  <block id="c5b9420927a71e0bcd6f4c621c66910f" category="cell">az_subnet_address_prefix *</block>
  <block id="94c126b468fd9c408abdff2cccd827a4" category="cell">(필수) ANF 볼륨 구축을 위해 새로 생성된 VNET에서 사용할 서브넷 주소 접두사입니다.</block>
  <block id="3c3133cb45a10a4ec442a4589636bfe1" category="cell">az_volume_path *</block>
  <block id="c8fb8ccec1ede566cac7b410b7623186" category="cell">(필수) 볼륨의 고유한 파일 경로입니다. 마운트 타겟을 생성할 때 사용됩니다. 이 설정을 변경하면 새 리소스가 생성됩니다.</block>
  <block id="5e51835c1dd28fa3cab3636a6beb8016" category="cell">az_capacity_pool_size *</block>
  <block id="a0faef0851b4294c06f2b94bb1cb2044" category="cell">정수</block>
  <block id="32c4a6ca695ae0fd3f41efe5ab8d3ffc" category="cell">* az_VNET_creation_bool *</block>
  <block id="27226c864bac7454a8504f8edb15d95b" category="cell">부울</block>
  <block id="55a1cc8d235c0ca9bd0cf384e2db1fb2" category="cell">(필수) 새 VNET를 만들려면 이 부울을 "true"로 설정합니다. 기존 VNET를 사용하려면 false로 설정합니다.</block>
  <block id="be85fde9f0fcdf86be8ede4b5939a9bf" category="cell">az_subnet_creation_bool *</block>
  <block id="4b079d5e017c7403047fbbd37df93368" category="cell">(필수) 이 부울을 "true"로 설정하면 새 서브넷이 생성됩니다. 기존 서브넷을 사용하려면 false로 설정합니다.</block>
  <block id="bb74e9c4e24089c59a6af0a7a016b586" category="cell">_anf_vol * 용 * az_subnet_id_입니다</block>
  <block id="52c0fe6a129fdcf33be82680a15b2d37" category="cell">(필수) 'subnet_creation_bool'을 TRUE로 설정하여 기존 서브넷을 사용하려는 경우 서브넷 ID를 언급합니다. false로 설정된 경우 기본값으로 둡니다.</block>
  <block id="8376cf4b94c63b51d5e0113c299a75a0" category="cell">* az_netapp_pool_service_level *</block>
  <block id="061fce6317efb41fcda88b5333cb0cc2" category="cell">(필수) 파일 시스템의 타겟 성능 유효한 값으로는 프리미엄, 슈탄다드, 울트라 등이 있습니다.</block>
  <block id="cd145efde532a4a27c5b6687f4b5f1c0" category="cell">* az_NetApp_vol_service_level *</block>
  <block id="d655c67b837d5b3363d556955802b670" category="cell">* az_NetApp_vol_protocol *</block>
  <block id="9e2a44ac250e0b60bce77fba70ebfd70" category="cell">(선택 사항) 목록으로 표시된 대상 볼륨 프로토콜입니다. 지원되는 단일 값으로는 CIFS, NFSv3, NFSv4.1 등이 있습니다. 인수가 정의되지 않으면 기본적으로 NFSv3으로 설정됩니다. 이렇게 변경하면 새 리소스가 생성되고 데이터가 손실됩니다.</block>
  <block id="cac15590a2775bfeaf5f70c36186a840" category="cell">* az_NetApp_vol_security_style *</block>
  <block id="80f43a817b6716a1a82af5fe18f178cd" category="cell">(선택 사항) 볼륨 보안 스타일이며 허용되는 값은 Unix 또는 NTFS입니다. 제공되지 않을 경우 단일 프로토콜 볼륨이 기본 설정인 Unix로 기본 설정됩니다. 즉, "NFSv3" 또는 "NFSv4.1" 볼륨인 경우에는 기본 설정인 "NTFS"가 됩니다. 이중 프로토콜 볼륨에서 제공하지 않으면 그 값은 NTFS가 됩니다.</block>
  <block id="b095a46d015fe5581a97472eedb3e645" category="cell">* az_NetApp_vol_storage_quota *</block>
  <block id="aaff31e02103a31c6f08943798a84789" category="cell">(필수) 파일 시스템에 허용되는 최대 스토리지 할당량(GB)입니다.</block>
  <block id="7bc40f4d4f846e8c7177d752ac52b775" category="open-title">ANF 데이터 보호</block>
  <block id="56978261632f1f36ad5f3f3ea6d2cb4b" category="paragraph">이 섹션에서는 Azure에서 데이터 보호를 사용하여 ANF(Azure NetApp Files) 볼륨을 배포/구성하기 위한 다양한 Terraform 구성 파일을 다룹니다.</block>
  <block id="9b3e184737a0a337479622611ba072b7" category="list-text">VAR/Azure_anf_data_protection.tfvars의 변수 값을 업데이트합니다.</block>
  <block id="bf052e3d77cd2cde5fa905542df51c46" category="paragraph">'ANF 데이터 보호'</block>
  <block id="17745d8782266e5f08c77485447c8727" category="cell">az_alt_location *</block>
  <block id="3bfeadf4c47a658ca94a6066aee32aaa" category="cell">(필수) 보조 볼륨을 생성할 Azure 위치입니다</block>
  <block id="2558355ccfd79f11c2c7771d473c28a9" category="cell">* az_VNET_PRIMARY_ADDRESS_SPACE *</block>
  <block id="cc551875f8711aaffc6141f504677c0b" category="cell">(필수) ANF 1차 볼륨 구축을 위해 새로 생성된 VNET에서 사용할 주소 공간입니다.</block>
  <block id="ea5f0cd471c631d7531bb7fd3b5bac8a" category="cell">* az_VNET_secondary_address_space *</block>
  <block id="fffcb59495331e54049ce33d3dcdf943" category="cell">(필수) ANF 2차 볼륨 구축을 위해 새로 생성된 VNET에서 사용할 주소 공간입니다.</block>
  <block id="88220764f0745e8a07a6578ee5a34962" category="cell">az_subnet_primary_address_prefix *</block>
  <block id="02b00c599f6c249474a4fa82513b5ae3" category="cell">(필수) ANF 운영 볼륨 구축을 위해 새로 생성된 VNET에서 사용할 서브넷 주소 접두사입니다.</block>
  <block id="1bef049d5f330664e35cad0a064c3b9c" category="cell">az_subnet_secondary_address_prefix *</block>
  <block id="1b60506e52e47ecc443e5be52dca93d7" category="cell">(필수) ANF 2차 볼륨 구축을 위해 새로 생성된 VNET에서 사용할 서브넷 주소 접두사입니다.</block>
  <block id="897362b63a34b0eb8e1453709c1f8403" category="cell">az_volume_path_primary *</block>
  <block id="1240d8345e0d2e3e79133040103d900c" category="cell">(필수) 운영 볼륨의 고유한 파일 경로입니다. 마운트 타겟을 생성할 때 사용됩니다. 이 설정을 변경하면 새 리소스가 생성됩니다.</block>
  <block id="b9dd6d654f6dd5777451c38ccbb3a90f" category="cell">az_volume_path_secondary *</block>
  <block id="2d48913a4e9f87154afa26a5629292ac" category="cell">(필수) 보조 볼륨의 고유한 파일 경로입니다. 마운트 타겟을 생성할 때 사용됩니다. 이 설정을 변경하면 새 리소스가 생성됩니다.</block>
  <block id="06c1e84417c5bf369b90b26dd5249917" category="cell">az_capacity_pool_size_primary *</block>
  <block id="3d618d26614058ac7e5a064cbe202b90" category="cell">az_capacity_pool_size_secondary *</block>
  <block id="900391b8f681698a00a1d7681c809eae" category="cell">* az_VNET_primary_creation_bool *</block>
  <block id="ee71ed057be46b5303595075681242b3" category="cell">(필수) 운영 볼륨에 대해 새 VNET를 생성하려면 이 부울을 "true"로 설정합니다. 기존 VNET를 사용하려면 false로 설정합니다.</block>
  <block id="1f3233bfcd515798625102d02489c9c2" category="cell">* az_VNET_secondary_creation_bool *</block>
  <block id="8a5a92fb6843cb45a9752dac34d8056a" category="cell">(필수) 보조 볼륨에 대한 새 VNET를 생성하려면 이 부울을 "true"로 설정합니다. 기존 VNET를 사용하려면 false로 설정합니다.</block>
  <block id="0276da5ab0cbfd3afccac3236ff88906" category="cell">az_subnet_primary_creation_bool *</block>
  <block id="ba2f66ccca4d07fb389900a4c72596a7" category="cell">(필수) 운영 볼륨에 대한 새 서브넷을 생성하려면 이 부울을 "true"로 설정합니다. 기존 서브넷을 사용하려면 false로 설정합니다.</block>
  <block id="78a2830c902a8a1eb6bbedc95b8e859d" category="cell">az_subnet_secondary_creation_bool *</block>
  <block id="1b869ff43f405cb5056d067f1ce0ea2c" category="cell">(필수) 이 부울을 "true"로 설정하면 보조 볼륨에 대한 새 서브넷이 생성됩니다. 기존 서브넷을 사용하려면 false로 설정합니다.</block>
  <block id="004f2f461ceadcb0d344b03f2f00c53d" category="cell">_anf_vol * 용 * az_primary_subnet_id_입니다</block>
  <block id="387a4516572f71aa24490f3bbfc695ef" category="cell">(필수) 'subnet_primary_creation_bool'을 TRUE로 설정하여 기존 서브넷을 사용하려는 경우 서브넷 ID를 언급합니다. false로 설정된 경우 기본값으로 둡니다.</block>
  <block id="2e9685846dda27855273fdf064f9e6ab" category="cell">_anf_vol * 용 * az_secondary_subnet_id_입니다</block>
  <block id="bf5c8bfc6d7cc2d5fe6e7931244a30eb" category="cell">(필수) 'subnet_secondary_creation_bool'을 TRUE로 설정하여 기존 서브넷을 사용하려는 경우 서브넷 ID를 언급합니다. false로 설정된 경우 기본값으로 둡니다.</block>
  <block id="ac839f935b4bbb6bed9bda28a8e642c6" category="cell">* az_netapp_pool_service_level_primary *</block>
  <block id="8cb34f1d64a5bf358b0d3a349ca5bc2f" category="cell">* az_netapp_pool_service_level_secondary *</block>
  <block id="7ad9306273877be4925eef5c298c8082" category="cell">* az_NetApp_vol_service_level_primary *</block>
  <block id="5614656fa00c06faf1c3484531a679a9" category="cell">* az_NetApp_vol_service_level_secondary *</block>
  <block id="4f517398039e7c48806d41487b9419bc" category="cell">* az_NetApp_vol_protocol_primary *</block>
  <block id="82b777cb90770b16388fa42e12e046ab" category="cell">* az_NetApp_vol_protocol_secondary *</block>
  <block id="59783d86d863461df5e6d03ac2bb42df" category="cell">* az_NetApp_vol_storage_quota_primary *</block>
  <block id="de8fa216337d1b3497efb08ceeb2ba75" category="cell">* az_NetApp_vol_storage_quota_secondary *</block>
  <block id="0b11ea56e0e5211214ff431c4e076717" category="cell">* az_DP_replication_frequency *</block>
  <block id="79ce3fc5fe45b145bb343376fe5351b9" category="cell">(필수) 복제 빈도 지원되는 값은 10분, 시간별, 일일 값이며 대/소문자를 구분합니다.</block>
  <block id="c623b4e11f7cb20ff0b7c24a72d3f0ef" category="open-title">ANF 듀얼 프로토콜</block>
  <block id="d25220d03f7afcb6f5edcbc46e369d45" category="paragraph">이 섹션에서는 Azure에서 이중 프로토콜이 활성화된 ANF(Azure NetApp Files) 볼륨을 배포/구성하기 위한 다양한 Terraform 구성 파일을 다룹니다.</block>
  <block id="9568461c901e88398bed16e11ad813d3" category="list-text">VAR/Azure_anf_dual_protocol.tfvars의 변수 값을 업데이트합니다.</block>
  <block id="d263b475ab751de671d08455b33997c1" category="paragraph">이중 프로토콜이 활성화된 단일 ANF 볼륨에 대한 Terraform 변수.</block>
  <block id="b183512797a1d9ea69a8dab9e27df52c" category="cell">az_NetApp_vol_protocol1 *</block>
  <block id="20fd02f6a193c7aeaee651654a332933" category="cell">(필수) 목록으로 표시된 대상 볼륨 프로토콜입니다. 지원되는 단일 값으로는 CIFS, NFSv3, NFSv4.1 등이 있습니다. 인수가 정의되지 않으면 기본적으로 NFSv3으로 설정됩니다. 이렇게 변경하면 새 리소스가 생성되고 데이터가 손실됩니다.</block>
  <block id="cc032be5baf5b9484eb2d659f4e314c6" category="cell">az_NetApp_vol_protocol2 *</block>
  <block id="910944ff76e7b2acfc482a34501df6f5" category="cell">* az_smb_server_username *</block>
  <block id="152372e48ac8f85f2e4908c5a1489a78" category="cell">(필수) ActiveDirectory 객체를 생성하는 사용자 이름입니다.</block>
  <block id="239e5edf090c4c70025b340f651694cc" category="cell">az_smb_server_password *</block>
  <block id="7b05e834084d190fe540481374f4fe0d" category="cell">(필수) ActiveDirectory 객체를 생성하는 사용자 암호.</block>
  <block id="4e2be381ec92158458ceef11bdf41ef7" category="cell">az_smb_server_name *</block>
  <block id="533dd582bfe3528b9b6ae4ff1889bd8f" category="cell">(필수) 서버 이름 을 클릭하여 ActiveDirectory 개체를 생성합니다.</block>
  <block id="f17c01535ba9f04720700d5e0d17172a" category="cell">* az_smb_dns_servers *</block>
  <block id="e70256203c6e23fcee3efa8d56fcfa85" category="cell">(필수) DNS 서버 IP를 사용하여 ActiveDirectory 개체를 생성합니다.</block>
  <block id="bdf618611712c6caa6fd0340470ee9f2" category="open-title">스냅샷의 ANF 볼륨</block>
  <block id="174e6e8f24023c93c7c470267f4c2376" category="paragraph">이 섹션에서는 Azure의 스냅샷에서 ANF(Azure NetApp Files) 볼륨을 배포/구성하기 위한 다양한 Terraform 구성 파일을 다룹니다.</block>
  <block id="215d5ed09cbe3ca5b10c6d616024053a" category="list-text">'VAR/Azure_anf_volume_from_snapshot.tfvars'의 변수 값을 업데이트합니다.</block>
  <block id="a753ff452c91c6e4de63b907e8253e05" category="paragraph">스냅샷을 사용하는 단일 ANF 볼륨에 대한 Terraform 변수.</block>
  <block id="57bd49c8f9a43967f48ec8f1f3ca2846" category="cell">az_snapshot_id *</block>
  <block id="ff461cb79e6adda28ae488782f0da97f" category="cell">(필수) 생성할 새 ANF 볼륨을 사용하는 스냅샷 ID입니다.</block>
  <block id="04107ff6b0460381c55ff620a1021254" category="list-text">VAR\Azure_cvo_single_node_deployment.tfvars의 변수를 업데이트합니다.</block>
  <block id="73b95097cc4819b49af28734c8da85f9" category="paragraph">단일 노드 CVO(Cloud Volumes ONTAP)에 대한 Terraform 변수</block>
  <block id="3226e634f46cb19ab313171144dd34bd" category="cell">* refresh_token *</block>
  <block id="d687ff26916f17fd879c87b138961b29" category="cell">(필수) NetApp Cloud Manager의 업데이트 토큰 이 문제는 NetApp Cloud Central에서 생성될 수 있습니다.</block>
  <block id="2c64afa8a46290b632eba256c644932c" category="cell">az_connector_name *</block>
  <block id="3eb8706ea09733709f78eddf34865fc5" category="cell">az_connector_location *</block>
  <block id="758699b195f5916d500521462cf30da9" category="cell">(필수) Cloud Manager Connector를 생성할 위치입니다.</block>
  <block id="1fab22f54c2298a6c193e9dbf02a5f40" category="cell">az_connector_subscription_id *</block>
  <block id="3eaa20b60039584fbaada041b1e9c27b" category="cell">(필수) Azure 구독의 ID입니다.</block>
  <block id="15a22866556f3e50073015243ddd7953" category="cell">az_connector_company *</block>
  <block id="d6da30a455e4a736b78aebafd5a574ec" category="cell">az_connector_resource_group *</block>
  <block id="7869ff24b2017b68dfcffe9346969d04" category="cell">(필수) 리소스가 생성될 Azure의 리소스 그룹입니다.</block>
  <block id="9ddf31c7bd196ef12b5afc14819332ae" category="cell">az_connector_subnet_id *</block>
  <block id="a41a332f5c3dda90835d004d4471e0a8" category="cell">(필수) 가상 머신에 대한 서브넷의 이름입니다.</block>
  <block id="dabe6b258248c0eefb5e7f8ef812c828" category="cell">* az_connector_VNET_id *</block>
  <block id="5209c2acb9f23446cfa41482e2ff8ee2" category="cell">(필수) 가상 네트워크의 이름입니다.</block>
  <block id="d00bbff7436422db546132791ca30dd2" category="cell">az_connector_network_security_group_name *</block>
  <block id="b5033b19e9c2388be995930fb1c49365" category="cell">(필수) 인스턴스에 대한 보안 그룹의 이름입니다.</block>
  <block id="54dee4dedf4b10ae9a250e887c349324" category="cell">az_connector_associate_public_ip_address *</block>
  <block id="c954a4a98e68d0734dcd6d7ad00db3f5" category="cell">(필수) 공용 IP 주소를 가상 머신에 연결할지 여부를 나타냅니다.</block>
  <block id="d363651cb914dfbc47f512db8ce8a9c0" category="cell">az_connector_account_id *</block>
  <block id="53b73bbe0bca0a3d51fbda15ecc058db" category="cell">(필수) Connector가 연결될 NetApp 계정 ID 제공되지 않은 경우 Cloud Manager는 첫 번째 계정을 사용합니다. 계정이 없는 경우 Cloud Manager에서 새 계정을 만듭니다. Cloud Manager의 어카운트 탭에서 어카운트 ID를 확인할 수 있습니다<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="b851f892237fb399ca9999caee142ccf" category="cell">az_connector_admin_password *</block>
  <block id="aa98915ce83ffe89562020e5b4d9a376" category="cell">(필수) 커넥터 암호.</block>
  <block id="1b9c1e319401f16966d7280c81cdc8dc" category="cell">* az_connector_admin_username *</block>
  <block id="e0f32faffed9caaca61e86caae050f17" category="cell">(필수) Connector의 사용자 이름입니다.</block>
  <block id="425624e10c5de04d471a55e4a8b35e31" category="cell">az_cvo_name *</block>
  <block id="52ebf6980a494c352ee150c2b801af6e" category="cell">* az_cvo_location *</block>
  <block id="8da06548b40415fd473a86a6dba80f82" category="cell">az_cvo_subnet_id *</block>
  <block id="f71ced0388b772479b4e5fba15c83077" category="cell">* az_cvo_VNET_id *</block>
  <block id="7d2219b61301dda6352db570bb7c5034" category="cell">* az_cvo_vNET_resource_group *</block>
  <block id="fecf56abdc6b5472c8da399cad7791b3" category="cell">(필수) 가상 네트워크에 연결된 Azure의 리소스 그룹입니다.</block>
  <block id="c63d2e90acb0448db277b1b5b8a8d1fa" category="cell">* az_cvo_data_encryption_type *</block>
  <block id="e472a1445850887a7f62ae832b27693a" category="cell">(필수) 작업 환경에 사용할 암호화 유형: ['Azure', 'None']. 기본값은 Azure입니다.</block>
  <block id="a09db82d06138c721102bb24bf44745c" category="cell">* az_cvo_storage_type *</block>
  <block id="0f0f84813d06e378040fbcf33a733c2c" category="cell">(필수) 첫 번째 데이터 집계의 스토리지 유형: ['PREMIUM_LRS', 'standard_LRS', 'standardSSD_LRS']. 기본값은 Premium_LRS입니다</block>
  <block id="2dc6453586c69ea950eec68d5ac9658c" category="cell">az_cvo_svm_password *</block>
  <block id="404c8599d393a19d0cd6354f8b6ae58c" category="cell">az_cvo_workspace_id *</block>
  <block id="ec0d845babe316d32a485960e8788bd0" category="cell">(필수) Cloud Volumes ONTAP를 구축할 Cloud Manager 작업 공간의 ID입니다. 제공되지 않은 경우 Cloud Manager는 첫 번째 작업 공간을 사용합니다. 의 작업 공간 탭에서 ID를 찾을 수 있습니다<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="868f934d26dc5bf64ab570c48f38be79" category="cell">az_cvo_capacity_tier *</block>
  <block id="e8dcbe7d10f08e94b9057a584009a175" category="cell">(필수) 첫 번째 데이터 애그리게이트에 대해 데이터 계층화를 사용할 것인지 여부: ['Blob', 'none'] 기본값은 BLOB입니다.</block>
  <block id="25390bc170c676096ec93edd61a5dca6" category="cell">* az_cvo_writing_speed_state *</block>
  <block id="b632952868dfa1143652e0c226514318" category="cell">(필수) Cloud Volumes ONTAP에 대한 쓰기 속도 설정: ['정상', '높음']. 기본값은 '정상'입니다. 이 인수는 HA 쌍과 관련이 없습니다.</block>
  <block id="52742ffdac7415fc1d35c1a6d0d9fb7a" category="cell">az_cvo_ONTAP_version *</block>
  <block id="90e696b73ff714675fc926a955cc68e1" category="cell">(필수) 필요한 ONTAP 버전입니다. 'use_latest_version'이 TRUE로 설정되어 있으면 무시됩니다. 기본값은 최신 버전을 사용하는 것입니다.</block>
  <block id="39a41303384652e186a359e5d96e8014" category="cell">az_cvo_instance_type *</block>
  <block id="fb03bbd04a925d04740ba3d3eae2e8b6" category="cell">(필수) 선택한 라이센스 유형에 따라 사용할 인스턴스 유형: Explore: ['standard_DS3_v2'], Standard: ['standard_DS4_v2, Standard_DS13_v2, Standard_L8s_v2'], Premium: ['standard_DS5_v2','standard_d14_v2.v2.v2의 모든 인스턴스: 지원되는 인스턴스 유형에 대한 자세한 내용은 Cloud Volumes ONTAP 릴리즈 노트를 참조하십시오. 기본값은 'standard_ds4_v2'입니다.</block>
  <block id="c0abbc4097de55ad558bd265d5e19b2e" category="cell">az_cvo_license_type *</block>
  <block id="337fb3a0d6e4f27fa4187c6e10b9d41b" category="cell">(필수) 사용할 라이센스 유형입니다. 싱글 노드: ['Azure-COT-INVURE-PAYGO', Azure-COT-STANDARD-PAGO', Azure-COT-Premium-BYOL', capacity-paygo'] HA: ['Azure-ha-cot-standard-paygo', 'Azure-ha-cot-premium-paygo', 'Azure-ha-cot-premium-BYOL', 'ha-capacity-paygo'] 기본값은 Azure-COT-STANDARD-PAGO입니다. HA는 Capacity-Paygo 또는 ha-capacity-paygo를 사용하여 Bring Your Own License Type Capacity-Based 또는 Freemium을 선택합니다. HA에서 BYOL(Bring Your Own License Type Node-Based)을 선택하려면 Azure-COT-Premium-BYOL(Azure-COT-Premium-BYOL) 또는 Azure-ha-COT-Premium-BYOL(Azure-Hot-Premium-BYOL)을 사용하십시오.</block>
  <block id="5e952a0432dfc8995121e15b76aa554a" category="cell">* az_cvo_NSS_ACCOUNT *</block>
  <block id="c3ae78309504c231f8afd5bc3790d119" category="cell">(필수) 이 Cloud Volumes ONTAP 시스템에서 사용할 NetApp Support 사이트 계정 ID입니다. 라이센스 유형이 BYOL 이고 NSS 계정이 제공되지 않은 경우 Cloud Manager는 기존의 첫 번째 NSS 계정을 사용하려고 합니다.</block>
  <block id="e7e63db47174977525dadf7a52fc6b39" category="cell">az_tenant_id *</block>
  <block id="66093475775d81b74da52f4377ff5ce5" category="cell">(필수) Azure에 등록된 애플리케이션/서비스 주체의 테넌트 ID입니다.</block>
  <block id="7934d010494793aec0f365d710cdf720" category="cell">* az_application_id *</block>
  <block id="587bfaa720a64e832c9eef635797e8d8" category="cell">(필수) Azure에 등록된 응용 프로그램/서비스 보안 주체의 응용 프로그램 ID입니다.</block>
  <block id="67830019a9948cfd51759684b5f8a262" category="cell">* az_application_key *</block>
  <block id="56d6515673e3c08156696c47a943c020" category="cell">(필수) Azure에 등록된 응용 프로그램/서비스 보안 주체의 응용 프로그램 키</block>
  <block id="522a4529185faee9fa34a9398ab7263f" category="list-text">VAR\Azure_cvo_ha_deployment.tfvars의 변수를 업데이트합니다.</block>
  <block id="e2da3e968f76091801635ce624569dcb" category="paragraph">'HA 쌍 인스턴스'</block>
  <block id="86ed32721429fbcc7b5e123836e3ebcd" category="paragraph">HA 쌍 Cloud Volumes ONTAP(CVO)에 대한 Terraform 변수</block>
  <block id="72170ff3a9ca936d7855297f0bbd1eeb" category="cell">(필수) 선택한 라이센스 유형에 따라 사용할 인스턴스 유형: Explore: ['standard_DS3_v2'], Standard: ['standard_DS4_v2, Standard_DS13_v2, Standard_L8s_v2'], Premium: ['standard_DS5_v2', 'Standard_DS14_v2'], BYOL: PayGo에 정의된 모든 인스턴스 유형 지원되는 인스턴스 유형에 대한 자세한 내용은 Cloud Volumes ONTAP 릴리즈 노트를 참조하십시오. 기본값은 'standard_ds4_v2'입니다.</block>
  <block id="b515d8e49b6ef626aa91dbd970708132" category="cell">(필수) 사용할 라이센스 유형입니다. 단일 노드: ['Azure-COT-INVURE-PAYGO, Azure-COT-STANDARD-PAGO, Azure-COT-Premium-BYOL, capacity-paygo'] HA:['Azure-ha-cot-standard-paygo, Azure-ha-cot-premium-paygo, Azure-ha-cot-premium-BYOL, ha-capacity-paygo'] 기본값은 Azure-COT-STANDARD-PAGO입니다. HA는 Capacity-Paygo 또는 ha-capacity-paygo를 사용하여 Bring Your Own License Type Capacity-Based 또는 Freemium을 선택합니다. HA에서 BYOL(Bring Your Own License Type Node-Based)을 선택하려면 Azure-COT-Premium-BYOL(Azure-COT-Premium-BYOL) 또는 Azure-ha-COT-Premium-BYOL(Azure-Hot-Premium-BYOL)을 사용하십시오.</block>
  <block id="728aafab2377ad85ce4ae3f6a4b3dd33" category="cell">(필수) 인스턴스에 대한 보안 그룹의 ID를 ','로 구분하여 여러 보안 그룹을 제공할 수 있습니다.</block>
  <block id="fbd9a83d6df239351ac0498cbaa58065" category="paragraph">이 솔루션에서는 Terraform 모듈을 사용하여 AWS(CVO Single Node, CVO HA, FSX ONTAP) 및 Azure(CVO Single Node, CVO HA, ANF)에 Cloud Volumes를 자동으로 구축합니다. 코드는 에서 찾을 수 있습니다<block ref="d07ec9f91b2ccc52b0d628a1b144c1d8" category="inline-link-rx"></block></block>
  <block id="0db20ddc31a427cc02802395aa53db7f" category="cell">(필수) 용량 풀 크기가 TB 단위로 언급됩니다.</block>
  <block id="c47acd947f63c78f7729c5c176778d53" category="paragraph">데이터 보호가 활성화된 단일 ANF 볼륨에 대한 Terraform 변수.</block>
  <block id="ca7ce11916c29a2c94b4fd33dc0b6313" category="paragraph">이 섹션에서는 Azure에서 Cloud Volumes ONTAP(단일 노드 CVO)를 구축/구성하기 위한 다양한 Terraform 구성 파일을 다룹니다.</block>
  <block id="7bd8d7a58d3957cf7697ceb3467bffae" category="cell">(필수) 작업 환경을 생성할 위치입니다.</block>
  <block id="a5ab436e757f5af2106d5ed5e5dd9df0" category="cell">(필수) Cloud Volumes ONTAP 시스템의 서브넷 이름입니다.</block>
  <block id="353190ef77d18ad13aeb6b4f0f3ddd66" category="paragraph">이 섹션에서는 Azure에서 CVO(Cloud Volumes ONTAP) HA(고가용성)를 구축/구성하기 위한 다양한 Terraform 구성 파일을 다룹니다.</block>
  <block id="3adefdd7d79d9a7c848b2dd81fd4feff" category="paragraph">이 섹션에는 GCP(Google Cloud Platform)에서 단일 노드 NetApp CVO(Cloud Volumes ONTAP)를 구축/구성하기 위한 다양한 Terraform 구성 파일이 포함되어 있습니다.</block>
  <block id="b05dddcb6f00ee8dba8395d241b9d24d" category="list-text">GCP 인증 키 JSON 파일을 디렉토리에 저장합니다.</block>
  <block id="44b4381353a1686f5b81f73f018d336c" category="list-text">VAR/GCP_cvo_single_node_deployment.tfvar의 변수 값을 업데이트합니다</block>
  <block id="2ac544064187c52d64d3eec81700dd42" category="admonition">변수 "GCP_connector_deploy_bool"을 true/false 로 설정하여 커넥터를 배포할 수 있습니다.</block>
  <block id="283162995c6eba560352663fa7cafbb3" category="paragraph">CVO 배포용 NetApp GCP 커넥터 인스턴스에 대한 Terraform 변수.</block>
  <block id="c0b4a62bb4903159c66ef5fd828dbb35" category="cell">* GCP_CONNETOR_DEPLOY_BOOL *</block>
  <block id="3448a02a5105e0eeb2a6243836814f36" category="cell">* GCP_connector_name *</block>
  <block id="982137a628765a4ede6a620653ab8bf6" category="cell">* GCP_CONNETOR_PROJECT_ID *</block>
  <block id="816194da363b92545a1114d46c4943f1" category="cell">(필수) 커넥터를 생성할 GCP project_id입니다.</block>
  <block id="49a94de7b7e8762f961e471d657496eb" category="cell">* GCP_CONNETOR_ZONE *</block>
  <block id="ff9633a62f1e60af63fc951afd6966bc" category="cell">(필수) Connector를 생성할 GCP 영역입니다.</block>
  <block id="c667eb31817317b5455e6a8883f4664a" category="cell">* GCP_connector_company *</block>
  <block id="9d1203849926481ebb6be1fb1d6ec3de" category="cell">* GCP_CONNETOR_SERVICE_ACCOUNT_EMAIL *</block>
  <block id="d4a302e18b412231fe06e54e038aed80" category="cell">(필수) 커넥터 인스턴스에 대한 SERVICE_ACCOUNT의 전자 메일입니다. 이 서비스 계정은 커넥터가 Cloud Volume ONTAP를 생성할 수 있도록 하는 데 사용됩니다.</block>
  <block id="0e3852268e0e5a3a486b8fcf6e3ae1c1" category="cell">* GCP_CONNETOR_SERVICE_ACCOUNT_PATH *</block>
  <block id="f863e677d176e63d3642e53ae6b336b5" category="cell">(필수) GCP 인증 목적을 위한 service_account JSON 파일의 로컬 경로입니다. 이 서비스 계정은 GCP에서 Connector를 생성하는 데 사용됩니다.</block>
  <block id="cfd7e4961aa34c5626712429d469ed18" category="cell">* GCP_CONNETOR_ACCOUNT_ID *</block>
  <block id="231d57c65fc42941f6a520976dc80ec3" category="cell">(선택 사항) Connector가 연결될 NetApp 계정 ID 제공되지 않은 경우 Cloud Manager는 첫 번째 계정을 사용합니다. 계정이 없는 경우 Cloud Manager에서 새 계정을 만듭니다. Cloud Manager의 어카운트 탭에서 어카운트 ID를 확인할 수 있습니다<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="9ea10c86ddbbfa93db9af98d0a38e7d7" category="paragraph">GCP의 단일 NetApp CVO 인스턴스에 대한 Terraform 변수</block>
  <block id="9d8a021dcdac02b1cffc5ee14bc79241" category="cell">* GCP_cvo_name *</block>
  <block id="bc023aad2be985e1a3252a959cb2c43b" category="cell">* GCP_cvo_project_id *</block>
  <block id="c7a61709c9cf6aa90f854f8e30110412" category="cell">(필수) GCP 프로젝트의 ID입니다.</block>
  <block id="6f74a6834cfd9c72b6694ae9ecb7f332" category="cell">* GCP_cvo_zone *</block>
  <block id="dea2d3525e8ec98bbd9a7931a8ed9921" category="cell">(필수) 작업 환경을 생성할 영역의 영역입니다.</block>
  <block id="2c09e34e29e9c5f65d5d8ac921fd8105" category="cell">* GCP_cvo_GCP_service_account *</block>
  <block id="77853ddcc7178537c8d9c0301b71c991" category="cell">(필수) Google Cloud 스토리지로 콜드 데이터를 계층화할 수 있도록 GCP_SERVICE_ACCOUNT 이메일을 보냅니다.</block>
  <block id="ffb5588c947a413a01016a81af9ddbc7" category="cell">* GCP_cvo_svm_password *</block>
  <block id="9507c3b760db1c7e6c8d1674933449e4" category="cell">* GCP_cvo_workspace_id *</block>
  <block id="4efb152d95f2b6b19ca1387a26e8f750" category="cell">(선택 사항) Cloud Volumes ONTAP를 구축할 Cloud Manager 작업 공간의 ID입니다. 제공되지 않은 경우 Cloud Manager는 첫 번째 작업 공간을 사용합니다. 의 작업 공간 탭에서 ID를 찾을 수 있습니다<block ref="ed21e31bd71ab546f26978ff562b5c5d" category="inline-link-rx"></block>.</block>
  <block id="7cbf1746ddada50a540811a75b633bfa" category="cell">* GCP_cvo_license_type *</block>
  <block id="108ccbda23ae580baf5fb86c14613837" category="cell">(선택 사항) 사용할 라이센스 유형입니다. 단일 노드의 경우: ['capacity-paygo', 'GCP-cot-score-paygo', 'GCP-cot-standard-paygo', 'GCP-cot-premium-paygo', 'GCP-cot-premium-BYOL'], HA:['ha-capacity-paygo', 'GCP-ha-cot-cot-Explore-paygo', 'GCP-ha-cot-standard-paygo', 'GCP-ha-cot-premium-BYOL'] 기본값은 단일 노드의 경우 'capacity-paygo'이고 HA의 경우 'ha-capacity-pago'입니다.</block>
  <block id="ec6c16de8b82f3fc6c55f03f1d9a0848" category="cell">* GCP_cvo_capacity_package_name *</block>
  <block id="564565c1364213fe3ffcef055b61947b" category="cell">(선택 사항) 용량 패키지 이름: ['Essential', 'Professional', 'Freemium']. 기본값은 '필수'입니다.</block>
  <block id="ac245610a2b7e434b78946f9ab069afe" category="paragraph">이 섹션에서는 GCP(Google Cloud Platform)의 고가용성 쌍에 NetApp CVO(Cloud Volumes ONTAP)를 구축/구성하는 다양한 Terraform 구성 파일을 다룹니다.</block>
  <block id="00c7a940cc525046dc63cee112a8ef2d" category="list-text">VAR/GCP_cvo_ha_deployment.tfvars의 변수 값을 업데이트합니다.</block>
  <block id="657426021b9624d6c24fae901c9998c1" category="paragraph">GCP의 HA 쌍에 있는 NetApp CVO 인스턴스에 대한 Terraform 변수.</block>
  <block id="2a20062f50c253ff821e16ab60e9bd71" category="cell">* GCP_cvo_is_ha *</block>
  <block id="c7d1d567eb3eec5faac1c3efbf5c63d6" category="cell">* GCP_cvo_node1_zone *</block>
  <block id="2cb70db8c1982b17ac705ceace5b64ae" category="cell">(선택 사항) 노드 1의 영역</block>
  <block id="b231cdca0a533a8afcbf95810dcdd937" category="cell">* GCP_cvo_node2_zone *</block>
  <block id="2aad8f424dde09a3fb42570367a156de" category="cell">(선택 사항) 노드 2의 영역</block>
  <block id="7dd3bb55d8d71efcb06fc86bbb29993a" category="cell">* GCP_cvo_중재자_존 *</block>
  <block id="767c5594dfa391fbb74bd9360557a0a8" category="cell">(선택 사항) 중재자를 위한 영역.</block>
  <block id="4ecd0da4e352bb336bd4c5925e627fbb" category="cell">* GCP_cvo_vPC_id *</block>
  <block id="0a49d29112682612dc74e881a68deed0" category="cell">(선택 사항) VPC의 이름입니다.</block>
  <block id="eedae790807f6f5998c1d5b2eccfcf91" category="cell">* GCP_cvo_subnet_id *</block>
  <block id="dbb13624053bb884443eb3a8a891a35e" category="cell">(선택 사항) Cloud Volumes ONTAP에 대한 서브넷의 이름입니다. 기본값은 'default'입니다.</block>
  <block id="5fbbd2383d042b5ab01878b936e467ff" category="cell">* GCP_cvo_vpc0_node_and_data_connectivity *</block>
  <block id="24239aec58a00d53d32147d2e71cca4d" category="cell">(선택 사항) 노드 및 데이터 연결에 필요한 NIC1용 VPC 경로입니다. 공유 VPC를 사용하는 경우 netwrok_project_id를 제공해야 합니다.</block>
  <block id="b1dd5e2b134fc3db50406e05c7ae6c38" category="cell">* GCP_cvo_vpc1_cluster_connectivity *</block>
  <block id="714e5d0cdfde4cbf4df83df266c672e7" category="cell">(선택 사항) 클러스터 연결에 필요한 NIC2용 VPC 경로입니다.</block>
  <block id="f8d315b03e4b926495b923dfe4b49b23" category="cell">* GCP_cvo_vpc2_ha_connectivity *</block>
  <block id="5c144c2c76f5d988024f4d7398060d71" category="cell">(선택 사항) NIC3용 VPC 경로, HA 연결에 필요</block>
  <block id="1366961106ddc181e83c467cf5559a14" category="cell">* GCP_cvo_vpc3_data_replication *</block>
  <block id="b4be5ce15bf4e51acd3167c47e79955f" category="cell">(선택 사항) 데이터 복제에 필요한 NIC4용 VPC 경로입니다.</block>
  <block id="065308400ba1fac48f2ca62781d79dff" category="cell">* GCP_cvo_subnet0_node_and_data_connectivity *</block>
  <block id="2a33bb449fd47fa1f379b60f3e1473ca" category="cell">(선택 사항) 노드 및 데이터 연결에 필요한 NIC1의 서브넷 경로입니다. 공유 VPC를 사용하는 경우 netwrok_project_id를 제공해야 합니다.</block>
  <block id="da8a35439720c0bc705f001b954bd61e" category="cell">* GCP_cvo_subnet1_cluster_connectivity *</block>
  <block id="01b515c3b8d74ae94df6572b47a3f06d" category="cell">(선택 사항) 클러스터 연결에 필요한 NIC2의 서브넷 경로입니다.</block>
  <block id="7ea43f4ca8d2a868f20df11b9e0b39b2" category="cell">* GCP_cvo_subnet2_ha_connectivity *</block>
  <block id="a35bd275122015b3834d13c0dc72b87f" category="cell">(선택 사항) HA 연결에 필요한 NIC3의 서브넷 경로입니다.</block>
  <block id="16c5273854a933d221200af8f06d106a" category="cell">* GCP_cvo_subnet3_data_replication *</block>
  <block id="b36fab455a4e11803791a090935906af" category="cell">(선택 사항) 데이터 복제에 필요한 NIC4의 서브넷 경로입니다.</block>
  <block id="e69179170f564daf56d8694c1c5d35fe" category="cell">* GCP_cvo_GCP_volume_size *</block>
  <block id="eb01714b284e762b9c44adfa5575690c" category="cell">(선택 사항) 첫 번째 데이터 애그리게이트의 GCP 볼륨 크기입니다. GB의 경우 단위는 [100 또는 500]입니다. TB의 경우 장치는 [1,2,4,8]일 수 있습니다. 기본값은 '1'입니다.</block>
  <block id="4c767d9b6ddddf4abeaece5590c0b101" category="cell">* GCP_cvo_GCP_volume_size_unit *</block>
  <block id="944ce323a5a1ffb09543fd409911cc88" category="open-title">CVS 볼륨</block>
  <block id="ffcc65b297748299934a184d39035ae4" category="paragraph">이 섹션에는 GCP(Google Cloud Platform)에서 NetApp CVS(Cloud Volumes Services) 볼륨을 구축/구성하기 위한 다양한 Terraform 구성 파일이 포함되어 있습니다.</block>
  <block id="732c3eabba1449281a4fddb59dbddcac" category="paragraph">Terraform 문서:<block ref="35b7d5c9a11899e5d5e07079551e8cef" category="inline-link-rx"></block></block>
  <block id="d203294ba4c28418657d90a7f8a7510d" category="list-text">VAR/GCP_CVs_volume.tfvars의 변수 값을 업데이트합니다.</block>
  <block id="40686c9084c59387baf48000dd09e6ab" category="paragraph">CVS 볼륨</block>
  <block id="3efdf9b0e7f4af483444f271367d6361" category="paragraph">NetApp GCP CVS 볼륨에 대한 Terraform 변수</block>
  <block id="0ffdc0b2b4889601b216ab5087650d46" category="cell">* GCP_cvs_name *</block>
  <block id="8ff48dd93ed73eb9adc26090e58ed80b" category="cell">(필수) NetApp CVS 볼륨의 이름입니다.</block>
  <block id="b6759cef3cfc5890deb6a790f73c8b79" category="cell">* GCP_CV_PROJECT_ID *</block>
  <block id="b0257576709acc899b5376a171c3cd98" category="cell">(필수) CVS 볼륨을 생성할 GCP 프로젝트_ID입니다.</block>
  <block id="447b0e81ae249b907128b7ea83e045c5" category="cell">* GCP_CV_GCP_SERVICE_ACCOUNT_PATH *</block>
  <block id="820ecb1b7a653c1e2dece0176d15eaed" category="cell">(필수) GCP 인증 목적을 위한 service_account JSON 파일의 로컬 경로입니다. 이 서비스 계정은 GCP에서 CVS 볼륨을 생성하는 데 사용됩니다.</block>
  <block id="6cb8bdefdf91cd2d80f6d9849de25fb8" category="cell">* GCP_cvs_region *</block>
  <block id="ec9461de174e3ad866c58b577c94034b" category="cell">(필수) CVS 볼륨을 생성할 GCP 영역</block>
  <block id="fc944aa114b94de895d84f5375000c0b" category="cell">* GCP_cvs_network *</block>
  <block id="23a1cb77eeeabfd36bbab18e5de9f0dc" category="cell">(필수) 볼륨의 네트워크 VPC</block>
  <block id="31681a1878caf611cea11e159a4fc1aa" category="cell">* GCP_cvs_size *</block>
  <block id="6f84d4d0c83121512056657a2dc0e808" category="cell">(필수) 볼륨 크기는 102400에서 102400까지입니다(GiB).</block>
  <block id="5c1eb3efe4738cb21efadc992aeeef81" category="cell">* GCP_cvs_volume_path *</block>
  <block id="bacdc6093d23e2f886b0cb0609418030" category="cell">(선택 사항) 볼륨의 볼륨 경로 이름입니다.</block>
  <block id="0467ee670bdb8fff57da77368d6d5385" category="cell">* GCP_CV_PROTOCOL_TYPE *</block>
  <block id="b91db1bd1a57ea4c9953036d82a63e95" category="cell">(필수) 볼륨의 PROTOCOL_TYPE. NFS의 경우 'NFSv3' 또는 'NFSv4'를 사용하고 SMB의 경우 'CIFS' 또는 'MB'를 사용합니다.</block>
  <block id="8065bff4940ae8d7161f926b0df47ac4" category="inline-link">NetApp 상호 운용성 매트릭스 툴</block>
  <block id="1479ddf58c038ab7d220ff734c74deaf" category="list-text">의 NFS v4.1 상호 운용성 표 노트를 참조하십시오<block ref="8813559f5b95abb5411182be29200aff" category="inline-link-rx"></block> 지원을 위해 필요한 특정 ESXi 패치 수준</block>
  <block id="fe01ac95967cd8cb5f5b5669b685277a" category="cell">HTTPS 연결 - https 연결을 통한 SOAP에 사용되는 VP 및 SRA입니다</block>
  <block id="e4b8a8d8761aab7733e317b585d5d606" category="cell">ONTAP 클러스터에 연결하는 데 사용됩니다</block>
  <block id="6f3666cf392f9aa79924b94f433b64ed" category="doc">VMware vSphere용 NetApp SnapCenter 플러그인 - VMware 기반 구축</block>
  <block id="a1dd31a3dca44eb1fe27b895521130ae" category="inline-link-macro">다음: 추가 정보 - VMware vSphere용 SnapCenter 플러그인 - 솔루션 전제 조건</block>
  <block id="874d68c7d23e9e2e452ff6efaf757dee" category="paragraph"><block ref="874d68c7d23e9e2e452ff6efaf757dee" category="inline-link-macro-rx"></block></block>
  <block id="7dcf4233280fcc0e80d2c5b8ce82af91" category="paragraph">NetApp SnapCenter 소프트웨어는 애플리케이션, 데이터베이스 및 파일 시스템 전반에서 데이터 보호를 안전하게 조율하고 관리하는 사용하기 쉬운 엔터프라이즈 플랫폼입니다.</block>
  <block id="7dc8c97b0d6d3055290baa0eb36dbfa5" category="paragraph">VMware vSphere용 SnapCenter 플러그인을 사용하면 VM에 대한 백업, 복구 및 연결 작업과 VMware vCenter에서 직접 SnapCenter에 등록된 데이터 저장소에 대한 백업 및 마운트 작업을 수행할 수 있습니다.</block>
  <block id="00389b40803806e30e1877e1a0469e22" category="inline-link">VMware vSphere용 NetApp SnapCenter 플러그인 개요</block>
  <block id="10408567d24e2dd65731b1e2f0508a5d" category="doc">VMware vSphere용 NetApp SnapCenter 플러그인 - 솔루션 전제 조건</block>
  <block id="0a70bb0111bccb302f68cc327b0527f8" category="inline-link-macro">이전: 추가 정보 - VMware vSphere용 SnapCenter 플러그인 - 구축</block>
  <block id="dc69c4899210bca949880d9753e92b35" category="paragraph"><block ref="dc69c4899210bca949880d9753e92b35" category="inline-link-macro-rx"></block></block>
  <block id="8eaab69b7b060fb16ac9ba9484edb36e" category="inline-link-macro">다음: 추가 정보 - VMware vSphere용 SnapCenter 플러그인 - 백업 워크플로우</block>
  <block id="4602e4aeb078cfce115f5bcaf3d65ba7" category="paragraph"><block ref="4602e4aeb078cfce115f5bcaf3d65ba7" category="inline-link-macro-rx"></block></block>
  <block id="d3b0a496a8cf35e38aa2e2195dec2f94" category="doc">VMware vSphere용 NetApp SnapCenter 플러그인 - 복원 워크플로우</block>
  <block id="e7f47d4d003703cc37a3f472bf362522" category="doc">VMware vSphere용 NetApp SnapCenter 플러그인 - 백업 워크플로우</block>
  <block id="b80c59ad5be93a14a5e884c9617272bd" category="inline-link-macro">이전: 추가 정보 - VMware vSphere용 SnapCenter 플러그인 - 솔루션 전제 조건</block>
  <block id="b8c179b73c48ccf857c179c753fc7866" category="paragraph"><block ref="b8c179b73c48ccf857c179c753fc7866" category="inline-link-macro-rx"></block></block>
  <block id="7889fbe4fe01425f9ecdef9442f812b8" category="inline-link-macro">다음: 추가 정보 - VMware vSphere용 SnapCenter 플러그인 - 복구 워크플로우.</block>
  <block id="907647e9678147c153e1b1f855122048" category="paragraph"><block ref="907647e9678147c153e1b1f855122048" category="inline-link-macro-rx"></block></block>
  <block id="3e23a542d0c1cb3dc87ca41f7ec8dc9c" category="doc">VMware vSphere용 NetApp SnapCenter 플러그인 - SQL Server 복원 워크플로우</block>
  <block id="d16efdedacbd64c8b85d50f0b58e4c60" category="inline-link-macro">이전: 추가 정보: VMware vSphere용 SnapCenter 플러그인 - 복구 워크플로우.</block>
  <block id="553f0bde4f032f393b8659c8440bae26" category="paragraph"><block ref="553f0bde4f032f393b8659c8440bae26" category="inline-link-macro-rx"></block></block>
  <block id="eee0a010c96cd5f8a48024b64979138a" category="inline-link-macro">이전: 추가 정보 - VMware vSphere용 SnapCenter 플러그인 - 백업 워크플로우.</block>
  <block id="db5a03b9e1de0d20dc54468940b207eb" category="paragraph"><block ref="db5a03b9e1de0d20dc54468940b207eb" category="inline-link-macro-rx"></block></block>
  <block id="5f01983db70d04ee21145e7d21902fb2" category="inline-link-macro">다음: 추가 정보 - VMware vSphere용 SnapCenter 플러그인 - SQL 복구 워크플로우</block>
  <block id="724a2f2542f99df4a44d9ad7cfb15363" category="paragraph"><block ref="724a2f2542f99df4a44d9ad7cfb15363" category="inline-link-macro-rx"></block></block>
  <block id="02674a4ef33e11c879283629996c8ff8" category="cell">방향</block>
  <block id="0c95054981de037de06e544a52eb3613" category="cell">8143</block>
  <block id="a8e6fe5b9e68f30a146cefebaa7edcc3" category="cell">인바운드</block>
  <block id="5bd529d5b07b647a8863cf71e98d651a" category="cell">8043</block>
  <block id="cb4b69eb9bd10da82c15dca2f86a1385" category="cell">9060</block>
  <block id="b6d767d2f8ed5d21a44b0e5886680cb9" category="cell">22</block>
  <block id="d82d678e9583c1f5f283ec56fbf1abb7" category="cell">9080</block>
  <block id="a44ba9086b2b83ccf2baf7c678723449" category="cell">9083</block>
  <block id="abea47ba24142ed16b7d8fbf2c740e0d" category="cell">1162</block>
  <block id="5cce8dede893813f879b873962fb669f" category="cell">1527)을 참조하십시오</block>
  <block id="91c15b8eb529bf2100c10383d1010a1e" category="cell">내부 전용</block>
  <block id="13f3cf8c531952d72e5847c4183e6910" category="cell">443</block>
  <block id="1ef2b5426b0824e93e33753fa87ddbf5" category="cell">양방향</block>
  <block id="d56302f459af314c7996db681d5b4696" category="cell">2022년 3월 29일</block>
  <block id="ee0b2b1b7d5e8eb309b29d0051f84d0c" category="cell">NetApp Astra를 통해 새로운 TR:DevOps를 추가했습니다</block>
  <block id="a32ca451a300bb4e3c6b19cb1592126a" category="inline-link-macro">NetApp Astra와 DevOps</block>
  <block id="cb6bb56e7a1df42aff4aeae660a2df10" category="cell"><block ref="cb6bb56e7a1df42aff4aeae660a2df10" category="inline-link-macro-rx"></block></block>
  <block id="73677e8d319e77c91f647e668e868ecb" category="paragraph">자세한 내용은 OpenShift 웹 사이트를 참조하십시오<block ref="35d5a627a33ce17e4bd125258d59fbc4" category="inline-link-rx"></block>.</block>
  <block id="f582083d849d313b57029bcb7e14f0b5" category="paragraph">자세한 내용은 NetApp 웹 사이트를 참조하십시오<block ref="95da63d781dead5af723667a3f69096a" category="inline-link-rx"></block>.</block>
  <block id="8fe0ec287a8d48a38a4f1454d62282f5" category="paragraph">NetApp Astra Control Center는 신뢰할 수 있는 NetApp 데이터 보호 기술을 기반으로 사내 환경에 구축된 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공합니다.</block>
  <block id="54fe0fc00087535e613994102131f164" category="paragraph">Astra Trident는 컨테이너 및 Kubernetes 배포용 {k8s_distribution_name}의 오픈 소스 및 완전 지원 스토리지 오케스트레이터입니다.</block>
  <block id="8f98c507505a202b216bb930f143954d" category="paragraph">NetApp은 컨테이너화된 애플리케이션을 위해 데이터를 프로비저닝, 보호 및 관리할 수 있는 Astra Trident 및 Astra Control과 함께 자격이 있는 여러 스토리지 플랫폼을 제공합니다.</block>
  <block id="1268e1be2d69bcbe60fed1b018c4c7be" category="list-text">NetApp Element 스토리지 시스템은 확장성이 뛰어난 환경에서 블록 기반(iSCSI) 사용 사례를 지원합니다.</block>
  <block id="c64f419c58469b610f6840042d2d188c" category="admonition">NetApp 포트폴리오의 각 스토리지 시스템은 데이터가 애플리케이션의 위치에 있도록 사내 사이트와 클라우드 간에 데이터 관리와 이동을 모두 간소화합니다.</block>
  <block id="8d866fd138999801041cd8ebf044c39f" category="paragraph">다음 페이지에서는 {solution_name} 솔루션에서 검증된 NetApp 스토리지 시스템에 대한 추가 정보를 제공합니다.</block>
  <block id="31190025c7f2a3470ada77c7c360ad75" category="list-text"><block ref="31190025c7f2a3470ada77c7c360ad75" category="inline-link-macro-rx"></block></block>
  <block id="15155104ed4dffb0c6f48a716c490eb6" category="list-text"><block ref="15155104ed4dffb0c6f48a716c490eb6" category="inline-link-macro-rx"></block></block>
  <block id="8bd43c9f55116966ac61fd08aa3cd4bf" category="list-text">퍼블릭 클라우드와 원활하게 통합하여 데이터를 계층화 및 보호합니다. ONTAP는 또한 어떤 환경에서든 강력한 데이터 보호 기능을 제공합니다.</block>
  <block id="d06c8b79097ede1a26446d68bec0ca39" category="paragraph">ONTAP에 대한 자세한 내용은 를 참조하십시오<block ref="b961dc88c1ac3ab8c78f9fff5ef05edb" category="inline-link-rx"></block>.</block>
  <block id="a95908309fdc4765216365a8dc7d2561" category="paragraph">두 시스템 모두 단순화된 고가용성 클라우드 통합형 스토리지 관리를 위한 업계 최고의 데이터 관리 소프트웨어인 NetApp ONTAP 데이터 관리 소프트웨어를 통해 Data Fabric 요구에 맞는 엔터프라이즈급 속도, 효율성 및 보안을 제공합니다.</block>
  <block id="158de41b0c768154e1c26d384097971b" category="paragraph">ONTAP Select는 NetApp ONTAP의 소프트웨어 정의 배포로, 사용자 환경의 하이퍼바이저에 구축할 수 있습니다. VMware vSphere 또는 KVM에 설치할 수 있으며 하드웨어 기반 ONTAP 시스템의 모든 기능과 환경을 제공합니다.</block>
  <block id="87517df6852cb879fffc1e5811e773eb" category="paragraph">NetApp은 상태 저장 컨테이너 애플리케이션 및 데이터를 오케스트레이션, 관리, 보호 및 마이그레이션하는 데 유용한 다양한 제품을 제공합니다.</block>
  <block id="a4d4eca64bc27dfd5dc959bc05745797" category="paragraph"><block ref="a4d4eca64bc27dfd5dc959bc05745797" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c60042e38b748289146bd910731af5f0" category="paragraph">NetApp Astra Control은 NetApp 데이터 보호 기술을 기반으로 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공합니다. Astra Control Service는 클라우드 네이티브 Kubernetes 구축에서 상태 저장 워크로드를 지원할 수 있습니다. Astra Control Center는 {k8s_distribution_name}과 같은 엔터프라이즈 Kubernetes 플랫폼의 온프레미스 구축에서 상태 저장 워크로드를 지원할 수 있습니다. 자세한 내용은 NetApp Astra Control 웹 사이트를 참조하십시오<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="40de36ed0c5ebc385749ac6095c24949" category="paragraph">NetApp Astra Trident는 컨테이너 및 Kubernetes 배포용 {k8s_distribution_name}의 오픈 소스 및 완전 지원 스토리지 오케스트레이터입니다. 자세한 내용은 Astra Trident 웹 사이트를 참조하십시오<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="ccbb3765ebd50818c2e13a7aba362360" category="paragraph">다음 페이지에서는 {solution_name} 솔루션의 애플리케이션 및 영구 스토리지 관리에 대해 검증된 NetApp 제품에 대한 추가 정보를 제공합니다.</block>
  <block id="9dc16d6a3e39a8a9654ccfa622d163cf" category="list-text"><block ref="9dc16d6a3e39a8a9654ccfa622d163cf" category="inline-link-macro-rx"></block></block>
  <block id="65b4726a91c7e38728e01572140c82b3" category="list-text"><block ref="65b4726a91c7e38728e01572140c82b3" category="inline-link-macro-rx"></block></block>
  <block id="61e8a38bc32bac1a07ee434aa2849ff7" category="paragraph">NetApp Astra Control Center는 NetApp ONTAP 스토리지 시스템에 스토리지 클래스 및 스토리지 백엔드를 사용하여 구축 및 구성된 Astra Trident 스토리지 오케스트레이터가 있는 {k8s_distribution_name} 클러스터에 설치할 수 있습니다.</block>
  <block id="ca272f711326de89f484505d0ad670ab" category="paragraph">Astra Trident에 대한 자세한 내용은 을 참조하십시오 <block ref="fdebacf9b174a956e59f11468f6dd03c" category="inline-link-macro-rx"></block>.</block>
  <block id="c46717c86eab6ada72e202311e47bf46" category="paragraph">클라우드 연결 환경에서 Astra Control Center는 Cloud Insights를 사용하여 고급 모니터링 및 원격 측정 기능을 제공합니다. Cloud Insights 연결이 없을 경우 제한된 모니터링 및 원격 측정(7일 메트릭)을 사용할 수 있으며 개방형 메트릭 엔드포인트를 통해 Kubernetes 기본 모니터링 툴(Prometheus 및 Grafana)으로 내보낼 수 있습니다.</block>
  <block id="b5348ca8ff6fec2e5b760e7176813e60" category="paragraph">Astra Control Center의 유료 버전 외에 90일 평가판 라이센스가 제공됩니다. 평가판 버전은 이메일과 Community Slack 채널을 통해 지원됩니다. 고객은 제품 내 지원 대시보드에서 이러한 리소스, 기타 기술 자료 문서 및 문서를 사용할 수 있습니다.</block>
  <block id="8b05a70d35504af755eb73a78fd137f0" category="paragraph">Astra 포트폴리오에 대한 자세한 내용은 를 참조하십시오 <block ref="230f9d60eb4e7cc8be41a0e702c37eff" category="inline-link-macro-rx"></block>.</block>
  <block id="82c67e38528d52fd46de6b6ba7370337" category="paragraph">Astra Trident는 빠른 개발 주기를 제공하며 Kubernetes와 마찬가지로 1년에 4회 릴리즈됩니다.</block>
  <block id="ed42e52f359216f47260ed1d21ef331c" category="paragraph">20.04 릴리즈부터 Trident 운영자가 Trident 설정을 수행합니다. 운영자는 대규모 구축을 용이하게 하고 Trident 설치의 일부로 배포된 Pod의 자동 복구를 포함하여 추가 지원을 제공합니다.</block>
  <block id="ef55276f0238c6b1a3f893bc026b5644" category="summary">NetApp 컨테이너 솔루션은 널리 사용되는 Kubernetes 기반 컨테이너 오케스트레이터와 NetApp 스토리지 관리 시스템 및 소프트웨어와의 통합이 검증되었습니다.</block>
  <block id="d56bc5e4affc2f557b7bb79afe47b1be" category="doc">NetApp 컨테이너 솔루션</block>
  <block id="6fd40b989d7667b2025880aec23fdf21" category="paragraph">이 참조 문서는 NetApp에서 검증한 바와 같이 여러 데이터 센터 환경에서 Google Cloud의 Anthos의 구현 검증을 제공합니다. 또한 영구 스토리지 관리를 위한 Astra Trident 스토리지 오케스트레이터와 상태 저장 애플리케이션의 관리 및 보호를 위한 NetApp Astra Control Center를 사용하여 NetApp 스토리지 시스템과의 스토리지 통합에 대해 자세히 설명합니다. 마지막으로, 다양한 솔루션 검증 및 실제 사용 사례를 살펴보고 문서화합니다.</block>
  <block id="7768400c23564e6141f156e229944614" category="summary">Anthos는 단일 플랫폼에서 개발과 IT 운영을 통합하여 사내 및 하이브리드 클라우드 인프라 전반에서 애플리케이션을 일관되게 구축, 배포 및 관리합니다. Anthos는 GKE Kubernetes 클러스터를 가상 또는 베어 메탈 형식으로 데이터 센터 환경에 직접 통합합니다.</block>
  <block id="346f4310b75e0cc51fdf8a1db6149978" category="doc">Anthos 개요</block>
  <block id="89ef90a5be38c2b656627392eee1a2a9" category="paragraph">NetApp의 Anthos는 온프레미스 GKE(Google Kubernetes Engine) 환경을 안정적이고 신뢰할 수 있는 방법으로 구축하기 위한 검증된 모범 사례 하이브리드 클라우드 아키텍처입니다. 이 NetApp 검증 아키텍처 참조 문서는 베어 메탈 및 가상 환경에 구축된 NetApp 솔루션 Anthos의 설계 가이드 및 구현 검증 역할을 합니다. 이 문서에 설명된 아키텍처는 NetApp 및 Google Cloud의 실무 전문가가 기업 데이터 센터 환경에서 Anthos를 실행할 때의 이점을 제공하도록 검증되었습니다.</block>
  <block id="72efb373513d77a08aa5dd7e375a418f" category="section-title">Anthos</block>
  <block id="5b1a0b45a2d6518143a0c9b299e736b4" category="paragraph">Anthos는 조직이 최신 하이브리드 클라우드 인프라를 구축 및 관리하는 동시에 애플리케이션 개발에 중점을 둔 민첩한 워크플로우를 채택할 수 있는 하이브리드 클라우드 Kubernetes 데이터 센터 솔루션입니다. 오픈 소스 기술을 기반으로 구축된 솔루션인 VMware의 Anthos는 Google Cloud의 Anthos GKE와 연결 및 상호 운용이 가능한 VMware vSphere 기반 인프라에서 온-프레미스로 실행됩니다. 컨테이너, 서비스 메시 및 기타 혁신적인 기술을 채택하는 조직은 로컬 및 클라우드 기반 환경에서 일관된 애플리케이션 개발 사이클과 운영 지원 워크로드를 경험할 수 있습니다. 다음 그림은 Anthos 솔루션과 사내 데이터 센터 내의 배포가 클라우드의 인프라와 상호 연결하는 방법을 보여 줍니다.</block>
  <block id="42fc2dc2813b6a8c6bbca7ebe6d3f51e" category="paragraph">Anthos에 대한 자세한 내용은 Anthos 웹 사이트를 참조하십시오<block ref="bcfc39c80df16a8beb60f78ea034be9d" category="inline-link-rx"></block>.</block>
  <block id="ed4b514e0a9558c7acbec81ecc5fe0e1" category="list-text">* Kubernetes Applications용 Google Cloud Marketplace * 간편한 배포를 위해 선별된 컨테이너 애플리케이션의 카탈로그입니다.</block>
  <block id="b2f70465e1ea6dcdc0843dc8ed3b7f55" category="list-text">* Migrate for Anthos. * 물리적 서비스 및 VM을 사내에서 클라우드로 자동 마이그레이션.</block>
  <block id="52bc26b321a0b4cd1f91f7961a0783c8" category="list-text">* 클라우드 인스턴스의 로깅 및 모니터링을 위해 Google에서 제공하는 Stackdriver. * 관리 서비스입니다.</block>
  <block id="9d1fde4a5ff757f9279ca3b948ce8cb2" category="paragraph"><block ref="9d1fde4a5ff757f9279ca3b948ce8cb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a4777b2291cea091fd5877d9051ff1a3" category="section-title">Anthos의 배포 방법</block>
  <block id="0b7914a951055f790f36ed2e8e90bf01" category="section-title">VMware의 Anthos 클러스터</block>
  <block id="1702288bedca391f972e58fc0561e9ed" category="paragraph">VMware vSphere 환경에 구축된 Anthos 클러스터는 대부분의 최종 사용자 Kubernetes 워크로드에 맞춰 신속하게 구축, 유지 관리 및 확장할 수 있습니다.</block>
  <block id="6f2ed4f8e4ebad80d7a306a0dc285156" category="paragraph">NetApp과 함께 배포된 VMware의 Anthos 클러스터에 대한 자세한 내용은 페이지를 참조하십시오 <block ref="2f8f1280f6424b00276dc85d82fdb14f" category="inline-link-macro-rx"></block>.</block>
  <block id="45a6d5427a773bd692ba6faf09ae9200" category="paragraph">베어 메탈 서버에 배포된 Anthos 클러스터는 하드웨어에 종속되지 않으며 개인 맞춤형 사용 사례에 맞게 최적화된 컴퓨팅 플랫폼을 선택할 수 있습니다.</block>
  <block id="00d32067724b7191cb5b0ffaf99cc3fe" category="list-text">스토리지 클래스를 생성하려면 kubbtl 명령을 실행합니다.</block>
  <block id="36a95a56c85c06906ce9ed37f6c88bbe" category="list-text">kubbectl 명령을 실행하여 PVC를 생성한다. 생성 중인 백업 볼륨의 크기에 따라 생성 시간이 다소 걸릴 수 있으므로 완료 시 프로세스를 확인할 수 있습니다.</block>
  <block id="f9d11737e933d637293dde1af50cc17c" category="inline-link-macro">이 문서를 참조하십시오</block>
  <block id="8e6bdc78726b4f56217f2db215176c4c" category="paragraph">Astra Control Center를 지원하는 Astra Trident의 설치 및 구성은 를 참조하십시오 <block ref="a26f48e8d5c30c46f5b177e7942c3e6b" category="inline-link-macro-rx"></block>.</block>
  <block id="5a45cefd7ffdd292bbc23212059fae63" category="paragraph">클라우드 연결 환경에서 Astra Control Center는 Cloud Insights를 사용하여 고급 모니터링 및 원격 측정 기능을 제공합니다. Cloud Insights 연결이 없을 경우 제한된 모니터링 및 원격 측정(7일 메트릭)을 사용할 수 있으며 개방형 메트릭 엔드포인트를 통해 Kubernetes 기본 모니터링 툴(Prometheus 및 Grafana)으로 내보낼 수 있습니다.</block>
  <block id="f7606168abf643ab18d0fa39eaf87445" category="admonition">단일 사이트에 OpenShift를 설치할 때마다 전용 SVM을 설치하여 영구 스토리지로 사용하는 것이 좋습니다. 다중 사이트 배포에는 추가 스토리지 시스템이 필요합니다.</block>
  <block id="cdcf8f111b01a0c0037e638c481f80b0" category="admonition">Docker 설치에는 20.10 이상의 Docker 버전이 있어야 하며, Podman 설치에는 3.0 이상의 podman 버전이 있어야 합니다.</block>
  <block id="bcd2576f09ac9988bca57ac067028342" category="section-title">설치 후 단계</block>
  <block id="f1712afd3ab64493ad6802bfa9e5be87" category="list-text">설치가 완료되었는지 확인하려면 'acc-operator-controller-manager' 로그를 확인하십시오.</block>
  <block id="da44b5941c7cfd27a6f5686a3168f332" category="list-text">CRD에 제공된 관리자 이메일 주소를 사용하여 처음으로 Astra Control Center GUI에 로그인할 경우 비밀번호를 변경해야 합니다.</block>
  <block id="d46a5e1e10f8a4a33306d0696cef14f5" category="summary">이 참조 문서는 NetApp 및 엔지니어링 파트너가 검증한 바와 같이 여러 데이터 센터 환경에 구축된 Anthos with NetApp 솔루션의 배포 검증을 제공합니다.</block>
  <block id="9d171bf7d3d65afb2e7e56d43b4b9ed5" category="doc">NVA-1165: NetApp의 Anthos</block>
  <block id="e961a4cbc5c7e2be5e3f72a578aeb4da" category="paragraph">NetApp의 Alan Cowles와 Nikhil Kulkarni입니다</block>
  <block id="9b3053daf2ec8e22b4a577982f08f107" category="paragraph">NetApp 솔루션의 Anthos는 다음과 같은 사용 사례를 통해 고객에게 탁월한 가치를 제공하도록 설계되었습니다.</block>
  <block id="cbc828fed325d3834b2bf3b1f2b5e639" category="inline-link">쿠버바이러스</block>
  <block id="341508ebeee3f32bbf4f6fee6cb456a0" category="list-text">엔터프라이즈 컨테이너 및 가상화된 워크로드의 힘을 합쳐 Anthos와 함께 vSphere 또는 베어 메탈에 가상으로 배포<block ref="3149dc0a8051bd1d167afbb1fe9775d9" category="inline-link-rx"></block>.</block>
  <block id="de800fedc3b1bf6c4cf497db01ca193d" category="list-text">Kubernetes용 오픈 소스 스토리지 오케스트레이터인 NetApp 스토리지와 Astra Trident와 함께 Anthos의 기능을 강조하는 실제 구성 및 사용 사례</block>
  <block id="22acab0d08b6253aa6c7d6be2fd3f4d3" category="paragraph">NetApp 솔루션의 Anthos는 다음과 같은 주요 구성 요소로 이루어져 있습니다.</block>
  <block id="c6e52ea38355d1c4527e874a4c673b5b" category="section-title">Anthos의 사내</block>
  <block id="385c65f480dfcbc7cb530a2c6c807ae9" category="paragraph">Premise의 Anthos는 VMware vSphere 하이퍼바이저 또는 선택한 베어 메탈 인프라에 구축할 수 있는 완벽하게 지원되는 엔터프라이즈 Kubernetes 플랫폼입니다.</block>
  <block id="b73ed4ba665437210c3da7d43d6618bf" category="paragraph">Astra Trident는 Anthos를 비롯한 컨테이너 및 Kubernetes 배포를 위한 오픈 소스 및 완벽하게 지원되는 스토리지 오케스트레이터입니다.</block>
  <block id="87f76f310cf20e85a098d49fa77367e5" category="cell">VMware 기반 Anthos 클러스터</block>
  <block id="bdca6efb043178ef172612dd1e173dde" category="cell">1.10</block>
  <block id="eb5d694ff9583283fe6d0190a39d5f7a" category="cell">6.7U3, 7.0U3</block>
  <block id="5b9abd64aa4865a31820ebec932e54f2" category="section-title">Anthos Ready 스토리지 파트너 프로그램.</block>
  <block id="02046ad0e82ff27f6e1774aa588fd853" category="cell">배포 유형</block>
  <block id="1552eec8291d257c4b855dcfa425d802" category="cell">스토리지 시스템</block>
  <block id="6a5025e8000765df098a91023b66544a" category="cell">Astra Trident 버전</block>
  <block id="888a77f5ac0748b6c8001822417df8b6" category="cell">프로토콜</block>
  <block id="56079badd056a19303cc26e6a4fcc7e0" category="cell">VMware</block>
  <block id="955ddf0f7e289ee80cdea4b5324b620d" category="cell">22.01</block>
  <block id="c07ee5debf5f3a3fef16c1ee5e8e4942" category="cell">NAS</block>
  <block id="e5db66c80967b6fa50a1eede0ce50e2f" category="cell">MultiWriter, 볼륨 확장, 스냅샷</block>
  <block id="62a0282d39568be094470486eaf70c4f" category="cell">산</block>
  <block id="4c606f506efd3b3bef3499e3342b5933" category="cell">물리적 블록, 볼륨 확장, 스냅샷</block>
  <block id="231afe47f3f37d3808096b36c28b4ded" category="cell">요소</block>
  <block id="a2da3c930443e5d1421caec9ee18a376" category="cell">베어 메탈</block>
  <block id="ddffa1813009160db4406c9ef143dd1e" category="section-title">NetApp 스토리지 통합</block>
  <block id="de3b8bd79707b5ac064727a07d81d808" category="paragraph">베어 메탈 기반 Anthos의 하드웨어 독립적 기능을 통해 맞춤형 사용 사례에 최적화된 컴퓨팅 플랫폼을 선택할 수 있으며 다양한 추가 이점을 제공할 수 있습니다.</block>
  <block id="b872ec62b57abae84b75461c58e0a0a7" category="list-text">* 자체 서버를 도입하십시오. * 기존 인프라에 맞는 서버를 사용하여 자본 지출 및 관리 비용을 절감할 수 있습니다.</block>
  <block id="2c912ca37607e38556f15eebae425241" category="paragraph">Google Cloud는 Anthos Ready 플랫폼 파트너 프로그램을 통해 Anthos의 새로운 릴리스로 파트너 서버 플랫폼의 업데이트된 검증을 주기적으로 요청합니다. 현재 검증된 서버 플랫폼 목록과 지원되는 Anthos 버전을 확인할 수 있습니다<block ref="3b2369e07f297fb9367d6c18ca70e2ac" category="inline-link-rx"></block>.</block>
  <block id="6a655d9810c4c5ea4ab7a5520d43ca6f" category="paragraph">다음 표에는 베어 메탈 배포에 대한 Anthos의 검증을 위해 NetApp 및 NetApp 파트너 엔지니어가 테스트한 서버 플랫폼이 포함되어 있습니다.</block>
  <block id="c0bd7654d5b278e65f21cf4e9153fdb4" category="cell">제조업체</block>
  <block id="529a05ca6c1263aab080ec4f20754411" category="cell">만듭니다</block>
  <block id="7b1d1185b835814de783483f686e9825" category="cell">Cisco의</block>
  <block id="21f20abdc637c3f2ef02355079dac15d" category="cell">UCS를 참조하십시오</block>
  <block id="8746d13b8a20e92a40041de84ef0df6f" category="cell">B200 M5</block>
  <block id="3cd9b23ed31110b2ebcbcc8c9a1dc8c0" category="cell">HPE</block>
  <block id="dcaa84314614529edc3d258cff7f565a" category="cell">ProLiant</block>
  <block id="76cca00a6b1e58467cea8165c904fe4f" category="cell">DL360</block>
  <block id="c5c8661ff74179fd251af29468f2ee7d" category="paragraph">다음 표에는 NetApp과 파트너가 솔루션을 검증하는 데 사용된 Linux 운영 체제 목록이 나와 있습니다.</block>
  <block id="b8e7b465df7c5979dc731d06e84ce2cf" category="cell">놓습니다</block>
  <block id="97f1ca2cfbf4529686b9719bf26e07c0" category="cell">Anthos 버전</block>
  <block id="6762f053abca7510f6648c71492724a7" category="cell">8.4</block>
  <block id="6a3bfb64d8c5e16ce63f46624e637b30" category="cell">18.04 LTS</block>
  <block id="d4a5ee60a5a19102b6c00749a050feaf" category="cell">20.04 LTS</block>
  <block id="26181b11798a17989dc697461dc3e9d0" category="section-title">추가 하드웨어</block>
  <block id="629f0a0ce45378aa8d3f93d405eb19cc" category="paragraph">완전 검증된 솔루션으로 Anthos on Bare Metal의 구축을 완료하기 위해 NetApp과 파트너 엔지니어는 네트워킹 및 스토리지용 추가 데이터 센터 구성 요소를 테스트했습니다.</block>
  <block id="9e5fa7e53550abb6c768c926e7888df7" category="paragraph">다음 표에는 이러한 추가 인프라 구성 요소에 대한 정보가 나와 있습니다.</block>
  <block id="b763f3ad097c7d9beb9849be170a627a" category="cell">하드웨어 이름</block>
  <block id="8c692721fdfc559bf4689567aa48fb47" category="cell">Nexus</block>
  <block id="5cb4ead83aaa15a241ef0e8c36f0678c" category="cell">C9336C-FX2</block>
  <block id="2f72e4f4112efeb63b9fb0ed1eefd1c9" category="cell">A250</block>
  <block id="8bb152d8bbc90b878b63c05b6b953334" category="section-title">추가 소프트웨어</block>
  <block id="effae9170216f08fb6cb3265a4cae9cc" category="paragraph">다음 표에는 검증 환경에 배포된 추가 소프트웨어 버전의 목록이 나와 있습니다.</block>
  <block id="91c8cbe28b4928f6ea19ea8d1894623a" category="cell">소프트웨어 이름입니다</block>
  <block id="604081aa29d106416ce93ba7c42a41e3" category="cell">NXOS</block>
  <block id="55e62f54b487de5f2a89d645f80d77b4" category="cell">9.3(5)</block>
  <block id="e0f2ed66fa5adfb40b7738ba72a899c9" category="paragraph">NetApp과 WWT(World Wide Technology)의 파트너 팀에서 실시한 Anthos Ready 플랫폼 검증 중에 랩 환경은 다음 다이어그램을 기반으로 구축되었으며, 이를 통해 각 서버 유형, 운영 체제, 네트워크 장치의 기능을 테스트할 수 있었습니다. 및 스토리지 시스템을 구축할 수 있습니다.</block>
  <block id="f8caba75d33af6e6a5a53160c246688e" category="paragraph"><block ref="f8caba75d33af6e6a5a53160c246688e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c7a2b443f8714e7071c1d55a3bd2715f" category="section-title">인프라 지원 리소스</block>
  <block id="f8f0e385abfb7fc517b1b9b4e9e8d19e" category="paragraph">베어 메탈에 Anthos를 배포하기 전에 다음 인프라가 마련되어 있어야 합니다.</block>
  <block id="957478b81604fc0a340d863f3b89a2da" category="summary">NetApp은 Trident Storage Orchestrator를 사용하여 Anthos에 구축된 애플리케이션용 스토리지를 프로비저닝할 수 있는 여러 스토리지 플랫폼을 보유하고 있습니다.</block>
  <block id="f623f7fc1ffb9cfc3afddcf52e2fec23" category="paragraph">NetApp은 Anthos에 구축된 애플리케이션에 스토리지를 프로비저닝할 수 있는 Astra Trident Storage Orchestrator를 통해 검증된 여러 스토리지 플랫폼을 보유하고 있습니다.</block>
  <block id="0c5e049b7be7649501696f84472d6820" category="paragraph"><block ref="0c5e049b7be7649501696f84472d6820" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e2719bf8f96a980f38256b7a4060368" category="list-text">Ansible 플레이북을 사용하여 Astra Control Center를 배포하려면 Ansible이 설치된 Ubuntu/RHEL 시스템이 있어야 합니다. 설명된 절차를 따르십시오<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Ubuntu 및 의 경우<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> RHEL의 경우</block>
  <block id="bf98d9390f43e942cd74d874e3bf6d68" category="list-text">디렉토리를 na_Astra_control_suite로 변경합니다.</block>
  <block id="cfcf9f0f05f9790927b65e14214edc6e" category="list-text">Playbook을 실행하여 Astra Control Center를 구축합니다. 특정 구성에 대한 루트 권한이 Playbook에 필요합니다.</block>
  <block id="3c0e37ba6fc2025cda3b9ec88b955aab" category="paragraph">Playbook을 실행하는 사용자가 root 이거나 암호 없는 sudo가 구성된 경우 다음 명령을 실행하여 플레이북을 실행합니다.</block>
  <block id="6b682acdf6e246de63c54d6f90044faa" category="paragraph">사용자에게 암호 기반 sudo 액세스가 구성된 경우 다음 명령을 실행하여 플레이북을 실행한 다음 sudo 암호를 입력합니다.</block>
  <block id="bbdfa4f0841eb6d317a11ae76992b8b8" category="summary">이 섹션에서는 NetApp 구축의 Anthos를 사용자 지정하려는 사용자를 위한 로드 밸런싱 장치 옵션을 탐구하는 데 사용됩니다.</block>
  <block id="b935e49429349d1edf159cd09a0b8ff5" category="paragraph">다음 페이지에서는 Anthos with NetApp 솔루션에 검증된 로드 밸런서 옵션에 대한 추가 정보를 제공합니다.</block>
  <block id="fbc20d9fb2c2f042edf73e3b39b3278a" category="paragraph"><block ref="fbc20d9fb2c2f042edf73e3b39b3278a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f1bcd982a417f561201a3262b52a84d7" category="list-text">NetApp SnapLock. * 지정된 기간 동안 덮어쓰거나 지울 수 없는 특수 볼륨에 데이터를 기록하여 재기록할 수 없는 데이터를 효율적으로 관리</block>
  <block id="99634a0c579c45d299cfbb8b818c51bb" category="paragraph"><block ref="99634a0c579c45d299cfbb8b818c51bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="678cbe37bb872d145128736b4650ef68" category="paragraph">NetApp은 짧은 지연 시간, 통합 데이터 보호, 멀티 프로토콜 지원으로 강력한 All-Flash(AFF) 및 스케일아웃 하이브리드(FAS) 스토리지 플랫폼을 제공합니다.</block>
  <block id="a150469d40f75f1df1e87a9558f50769" category="paragraph">두 시스템 모두 NetApp ONTAP 데이터 관리 소프트웨어를 기반으로 합니다. 이 소프트웨어는 고가용성, 클라우드 통합, 간소화된 스토리지 관리를 위한 업계 최고의 데이터 관리 소프트웨어로 Data Fabric에 필요한 엔터프라이즈급 속도, 효율성 및 보안을 제공합니다.</block>
  <block id="a9b90f3200d3b94ea47e85db3a435816" category="paragraph">NetApp AFF 및 FAS 플랫폼에 대한 자세한 내용을 보려면 클릭하십시오<block ref="629508ef5a91b5835f70894f34eed424" category="inline-link-rx"></block>.</block>
  <block id="7bfa2a7b059f09c3a772620888e93ef4" category="list-text">백업 세부 정보를 입력하고 백업 파일을 보관할 오브젝트 스토리지 버킷을 선택한 후 다음 을 클릭합니다. 세부 정보를 검토한 후 백업을 클릭합니다. 애플리케이션 및 데이터의 크기에 따라 백업에 몇 분이 걸릴 수 있습니다. 백업이 성공적으로 완료되면 백업 상태를 사용할 수 있게 됩니다.</block>
  <block id="bf6a757407fc5616f49930e56f86f233" category="list-text">응용 프로그램을 복제하려면 앱 &gt; 관리 탭으로 이동하고 해당 앱을 클릭합니다. 애플리케이션 이름 옆의 드롭다운 메뉴를 클릭하고 클론 을 클릭합니다.</block>
  <block id="9b6757a6af2937cac7096646ee8dedb8" category="paragraph">F5 BIG-IP는 ADC(Application Delivery Controller)로서 L4-L7 로드 밸런싱, SSL/TLS 오프로드, DNS, 방화벽 등과 같은 다양한 고급 프로덕션 등급 트래픽 관리 및 보안 서비스를 제공합니다. 이러한 서비스는 애플리케이션의 가용성, 보안 및 성능을 크게 향상시킵니다.</block>
  <block id="402c558f65f9d58557e4d79511d71f01" category="paragraph">F5 BIG-IP는 Anthos의 사내 에서 사용할 수 있는 번들 로드 밸런서 솔루션 중 첫 번째 솔루션이었으며 Anthos와 NetApp 솔루션의 Anthos Ready 파트너 검증을 위해 여러 초기 단계에서 사용되었습니다.</block>
  <block id="b662a8c121a377d9111fe64265c8d819" category="paragraph">이 솔루션은 VMware vSphere에 구축된 가상 어플라이언스를 사용합니다. F5 Big-IP 가상 어플라이언스에 대한 네트워킹은 네트워크 환경에 따라 2개 또는 3개 설정 구성으로 구성할 수 있습니다. 이 문서의 배포는 두 가지 설정 구성을 기반으로 합니다. Anthos에서 사용할 가상 어플라이언스 구성에 대한 자세한 내용은 을 참조하십시오<block ref="f18a28d0c935319437c4d1b1e33e5728" category="inline-link-rx"></block>.</block>
  <block id="a1fa27779242b4902f7ae3bdd5c6d508" category="cell">유형</block>
  <block id="37f438df6a6d5ba4c17ef8ca58562f00" category="cell">F5</block>
  <block id="90524e294c6b7accf9b320977f3f5baa" category="cell">BIG-IP VE</block>
  <block id="bc75f10c94df92e80198364d879456ab" category="cell">15.0.1-0.0.11</block>
  <block id="c2c889e06ea18c0e72996bc4b43c8115" category="cell">16.1.0-0.0.19</block>
  <block id="674751c31a2db2596bf7788e2953b80f" category="paragraph">F5 BIG-IP를 설치하려면 다음 단계를 수행하십시오.</block>
  <block id="ee5cd6f83412e93266bf30ff048db6ff" category="list-text">F5에서 가상 응용 프로그램 OVA(Open Virtual Appliance) 파일을 다운로드합니다<block ref="cafae381bde5e2381c6df42a3aa937c6" category="inline-link-rx"></block>.</block>
  <block id="fff9995f30a825c5d3e5709e7b78117a" category="admonition">어플라이언스를 다운로드하려면 F5 키를 등록해야 합니다. 빅 IP Virtual Edition 로드 밸런서에 대한 30일 데모 라이센스를 제공합니다. 어플라이언스 배포에는 영구적인 10Gbps 라이센스를 사용하는 것이 좋습니다.</block>
  <block id="1a104d04970b6b80d8cf31f554404f4d" category="list-text">Infrastructure Resource Pool을 마우스 오른쪽 버튼으로 클릭하고 Deploy OVF Template을 선택합니다. 1단계에서 방금 다운로드한 OVA 파일을 선택할 수 있는 마법사가 시작됩니다. 다음 을 클릭합니다.</block>
  <block id="fdf7304b13d736c791bc745a330e7309" category="image-alt">Big-IP 어플라이언스 구축</block>
  <block id="fbd07b7802c1a124a9359b27b9f46968" category="list-text">마법사가 제공하는 다음 화면에서는 환경에서 사용할 가상 네트워크를 사용자 지정할 수 있습니다. External 필드에서 VM_Network 를 선택하고 Management 필드에서 Management_Network 를 선택합니다. Internal 및 HA는 F5 Big-IP 어플라이언스의 고급 구성에 사용되며 구성되지 않습니다. 이러한 매개 변수는 단독으로 사용하거나 비인프라 분산 포트 그룹에 연결하도록 구성할 수 있습니다. 다음 을 클릭합니다.</block>
  <block id="93353313944577e80d34c3d9491db6ce" category="list-text">어플라이언스의 요약 화면을 검토하고 모든 정보가 올바르면 마침을 클릭하여 배포를 시작합니다.</block>
  <block id="68b984a73f20c874fb80feeaa4621109" category="list-text">가상 어플라이언스가 구축된 후 마우스 오른쪽 버튼으로 클릭하고 전원을 켭니다. 관리 네트워크에서 DHCP 주소를 수신해야 합니다. 이 어플라이언스는 Linux 기반이며 VMware Tools가 배포되어 있으므로 vSphere Client에서 수신한 DHCP 주소를 볼 수 있습니다.</block>
  <block id="d92e443c00989a23096c72b760af7de8" category="list-text">웹 브라우저를 열고 이전 단계의 IP 주소로 어플라이언스에 연결합니다. 기본 로그인은 admin/admin이고, 처음 로그인하면 어플라이언스는 즉시 admin 암호를 변경하라는 메시지를 표시합니다. 그런 다음 새 자격 증명으로 로그인해야 하는 화면으로 돌아갑니다.</block>
  <block id="dbe135d0d5ae1eb2c137c81f0ce0bdfb" category="image-alt">BIG-IP 구성</block>
  <block id="bdb0e3e1ff63b6d5f08545e207448035" category="list-text">첫 번째 화면에 설치 유틸리티를 완료하라는 메시지가 표시됩니다. 다음 을 클릭하여 유틸리티를 시작합니다.</block>
  <block id="8523c09995ae3cfb4593cd6c4e09029f" category="list-text">다음 화면에 어플라이언스에 대한 라이센스 활성화 메시지가 표시됩니다. 시작하려면 활성화를 클릭하십시오. 다음 페이지에 메시지가 표시되면 다운로드 등록 시 받은 30일 평가판 라이센스 키 또는 어플라이언스 구입 시 구입한 영구 라이센스를 붙여 넣습니다. 다음 을 클릭합니다.</block>
  <block id="38d2bfb14ed98f122ce9d9b9cdb2a127" category="admonition">장치가 활성화를 수행하려면 관리 인터페이스에 정의된 네트워크가 인터넷에 연결될 수 있어야 합니다.</block>
  <block id="6ba845d7cd0e966d0a2a21209623a5b4" category="list-text">다음 화면에 최종 사용자 사용권 계약(EULA)이 표시됩니다. 사용권 계약 내용이 허용되는 경우 Accept(수락) 를 클릭합니다.</block>
  <block id="c14be37e927625fe613c8c559de70df1" category="list-text">다음 화면에서는 지금까지 수행된 구성 변경을 확인할 때 경과 시간을 계산합니다. 초기 구성으로 다시 시작하려면 계속을 클릭합니다.</block>
  <block id="3c3d807fce3ffcb905b00324d2f7e2b9" category="list-text">Configuration Change(구성 변경) 창이 닫히고 Setup Utility(설정 유틸리티)에 Resource Provisioning(리소스 프로비저닝) 메뉴가 표시됩니다. 이 창에는 현재 라이센스가 부여된 기능과 가상 어플라이언스 및 실행 중인 각 서비스에 대한 현재 리소스 할당이 나열됩니다.</block>
  <block id="117c183bcbd703e6b0520f843e971c9b" category="list-text">왼쪽의 플랫폼 메뉴 옵션을 클릭하면 플랫폼을 추가로 수정할 수 있습니다. 수정 사항에는 DHCP로 구성된 관리 IP 주소 설정, 어플라이언스가 설치된 호스트 이름 및 표준 시간대 설정, SSH 액세스 가능성으로부터 어플라이언스 보안 등이 포함됩니다.</block>
  <block id="fad130ca7ff2a3734a8b7547b3ebc404" category="list-text">그런 다음 표준 네트워킹 기능을 구성할 수 있는 네트워크 메뉴를 클릭합니다. 다음 을 클릭하여 표준 네트워크 구성 마법사를 시작합니다.</block>
  <block id="37f1b31abf7679b5f5e495d8796a48a7" category="admonition">셀프 IP 주소, 넷마스크 및 유동 IP 주소에 대한 이 페이지의 공백은 자리 표시자로 사용할 라우팅이 불가능한 IP로 채울 수 있습니다. 또한 3개 설정 구성을 구축할 경우 가상 게스트에 대해 분산 포트 그룹으로 구성된 내부 네트워크를 채울 수 있습니다. 마법사를 계속하려면 작업을 완료해야 합니다.</block>
  <block id="c3966f18c8da763e8d9f315b3e44811e" category="list-text">다음 페이지에서는 환경에 여러 가상 어플라이언스를 구축하는 경우 내부 HA 네트워크를 구성할 수 있습니다. 계속하려면 자체 IP 주소 및 넷마스크 필드를 입력해야 하며, 인터페이스 1.3을 VLAN 인터페이스로 선택해야 합니다. VLAN 인터페이스는 OVF 템플릿 마법사에서 정의한 HA 네트워크에 매핑됩니다.</block>
  <block id="0d469ac29aab926968093104ad6265df" category="list-text">다음 페이지에서는 NTP 서버를 구성할 수 있습니다. 다음 을 클릭하여 DNS 설정을 계속합니다. DNS 서버 및 도메인 검색 목록은 이미 DHCP 서버에 의해 채워져야 합니다. Next(다음) 를 클릭하여 기본값을 적용하고 계속합니다.</block>
  <block id="97a60c27b370d45c17075cff06f473a3" category="list-text">마법사의 나머지 부분에서는 다음을 클릭하여 고급 피어링 설정을 계속 진행합니다. 이 설정은 이 문서의 범위를 벗어납니다. 그런 다음 마침을 클릭하여 마법사를 종료합니다.</block>
  <block id="0953ce81fac634b21f33efe8dee24c28" category="list-text">Anthos 관리 클러스터 및 환경에 배포된 각 사용자 클러스터를 위한 개별 파티션을 생성합니다. 왼쪽 메뉴에서 시스템 을 클릭하고 사용자 로 이동한 다음 파티션 목록 을 클릭합니다.</block>
  <block id="616e4c989df3c842830310568b54cee6" category="section-title">Anthos와의 통합</block>
  <block id="c0018d5f0e0d9decd39a8059cc2bc473" category="paragraph">이 페이지에 제공된 예는 NetApp Anthos의 솔루션 검증 및 사용 사례입니다.</block>
  <block id="fdd1d4ba64f526087e6e49e35a884fbd" category="summary">이 섹션에서는 실제 사용자가 이 솔루션을 운영 환경에 배포할 때 수행해야 할 사용자 지정(예: 사용자 지정 로드 밸런싱 장치 인스턴스 배포)에 대해 설명합니다.</block>
  <block id="90f687894749dad073416489141eb43f" category="list-text">NetApp Astra Trident 문서</block>
  <block id="7cfc9495aac39bbaa5defc76b7f4e8db" category="list-text">VMware 문서의 Anthos 클러스터</block>
  <block id="f5266df5a7db89637cf0d7391221b756" category="inline-link"><block ref="f5266df5a7db89637cf0d7391221b756" category="inline-link-rx"></block></block>
  <block id="1bdc624c553dda22bc7a529bda2dd06b" category="paragraph"><block ref="1bdc624c553dda22bc7a529bda2dd06b" category="inline-link-rx"></block></block>
  <block id="9ee8ef3c59727b8b17070caf87743214" category="list-text">Anthos의 Bare Metal Documentation</block>
  <block id="bc10096da41c680de98ecf3f1def7d17" category="inline-link"><block ref="bc10096da41c680de98ecf3f1def7d17" category="inline-link-rx"></block></block>
  <block id="d642746f7d7a37b7cb340d9a62d751a5" category="paragraph"><block ref="d642746f7d7a37b7cb340d9a62d751a5" category="inline-link-rx"></block></block>
  <block id="10a641cf7647f6970bad748b52bb253b" category="paragraph"><block ref="10a641cf7647f6970bad748b52bb253b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7f640668ae5a8fc28f807fe0d6b9128b" category="paragraph">이러한 방식으로 노드 장애 후 볼륨 재배포가 수행되면 로그아웃 이후에 호스트 연결에 영향을 주지 않고 새 위치로 리디렉션하여 로그인할 수 있습니다. iSCSI 로그인 리디렉션을 사용하는 NetApp Element 소프트웨어 클러스터는 무중단 업그레이드 및 운영이 가능한 자가 복구, 스케일아웃 아키텍처입니다.</block>
  <block id="206188ac4e8ec83453b82a36311f1a25" category="paragraph">VMware의 Anthos 클러스터는 최종 사용자의 프라이빗 데이터 센터에 구축되는 Google Kubernetes Engine의 확장 서비스입니다. 조직은 온프레미스의 Kubernetes 클러스터에서 Google Cloud의 컨테이너에서 실행하도록 설계된 동일한 애플리케이션을 배포할 수 있습니다. VMware의 Anthos 클러스터를 데이터 센터의 기존 VMware vSphere 환경에 구축할 수 있으므로 자본 비용을 절감하고 더욱 신속한 구축 및 확장 작업을 수행할 수 있습니다.</block>
  <block id="b107e7085d2931bbe4118d8c5eed9643" category="paragraph">VMware에 Anthos 클러스터를 구축하는 경우 다음과 같은 구성 요소가 포함됩니다.</block>
  <block id="d17685a3ddd89e969b430984ce944772" category="paragraph"><block ref="d17685a3ddd89e969b430984ce944772" category="inline-image-macro-rx" type="image"></block></block>
  <block id="348ed6380fe1c4753877d1f13d95d39a" category="paragraph">VMware의 Anthos 클러스터는 다음과 같은 이점을 제공합니다.</block>
  <block id="cf97925041bebbd35543bc4fc24fa499" category="list-text">* 고급 멀티 테넌시 * 각 최종 사용자는 자체 개발 환경에 필요한 가상 리소스와 함께 구축된 자체 사용자 클러스터를 할당할 수 있습니다.</block>
  <block id="a6c34625dcf8367e84732b5219f81cb7" category="list-text">* 개발 후 게시 * 응용 프로그램이 개발 중인 동안 온프레미스 배포를 사용할 수 있습니다. 이를 통해 로컬 데이터 센터의 개인 정보 보호 환경에서 응용 프로그램을 테스트한 후 클라우드에서 공개적으로 제공할 수 있습니다.</block>
  <block id="4418ae814387892bd88d45091a182234" category="list-text">* vSphere High Availability. * 호스트 장애 시 운영 중단을 방지하기 위해 VMware vSphere를 사용하면 호스트를 클러스터링하고 고가용성을 구성할 수 있습니다. 호스트 장애로 인해 중단된 VM은 클러스터의 다른 호스트에서 곧 재부팅되어 서비스가 복구됩니다.</block>
  <block id="44da02789c784d2615f858b0e9007c1d" category="inline-link">NetApp FlexPod를 참조하십시오</block>
  <block id="08edd2123939d5309dced149763a50ee" category="inline-link">NetApp HCI</block>
  <block id="58d64ca3570be3edd23e4165a8c0d9ee" category="paragraph">다음 표에는 NetApp 및 NetApp 파트너 엔지니어가 VMware 배포에서 Anthos 클러스터의 검증을 위해 테스트한 서버 플랫폼이 포함되어 있습니다. 여기에는 와 같은 솔루션이 포함됩니다<block ref="5ea2f6a45afb6a8f064f7631dd737389" category="inline-link-rx"></block> Cisco UCS 서버 및 를 사용합니다<block ref="3ff4d1b07fc6ed14e7fcf7636d0ad5aa" category="inline-link-rx"></block> 하이브리드 클라우드 인프라 플랫폼:</block>
  <block id="bcb24d33d2a22de9b0c3e9f38becc496" category="cell">보기</block>
  <block id="9f80c25863c6e1e85d8d5492b437cb64" category="cell">C410</block>
  <block id="696c660ff8d9323e55146a6dbd4e4088" category="section-title">운영 체제</block>
  <block id="69da39b403ff0537d2282cb291d4397c" category="paragraph">VMware의 Anthos 클러스터는 고객이 선택한 대로 vSphere 6 및 7 환경 모두에 배포하여 현재 데이터 센터 인프라를 충족할 수 있습니다.</block>
  <block id="23d300c91b3d48f94c1e7f5953ad3e5e" category="cell">7.0U3</block>
  <block id="89f7e5d7117ac9eb1ece116273f5f012" category="paragraph">NetApp과 NetApp의 파트너 엔지니어는 완벽하게 검증된 솔루션으로 Anthos의 배포를 완료하기 위해 네트워킹 및 스토리지용 추가 데이터 센터 구성 요소를 테스트했습니다.</block>
  <block id="fe02a8fc8838381700e175498b8e1db0" category="cell">Mellanox에서</block>
  <block id="92666505ce75444ee14be2ebc2f10a60" category="cell">SN</block>
  <block id="d7a84628c025d30f7b2c52c958767e76" category="cell">2010년</block>
  <block id="bf07aaec06ff922b8a11ef624141bfdb" category="cell">S410</block>
  <block id="dd4a9a41d8672c9659041812469e1df2" category="paragraph">다음 표에는 검증 환경에 배포된 소프트웨어 버전 목록이 나와 있습니다.</block>
  <block id="da0d53141f6343167596fe8598964773" category="cell">소프트웨어 이름</block>
  <block id="3c537b8d673e06e2107129b600143391" category="cell">4.1(3e)</block>
  <block id="f932bed2d12442d21507b51d22b88dd7" category="cell">1.8</block>
  <block id="c1770c414b5c19c253a48e36fa2da50f" category="paragraph">NetApp에서 실시한 Anthos Ready 플랫폼 검증 중에 연구소 환경은 다음 다이어그램을 기반으로 구축되었으며, 여러 NetApp 스토리지 시스템 및 스토리지 백엔드와 함께 배포된 여러 사용자 클러스터를 테스트할 수 있게 되었습니다.</block>
  <block id="c1c59b2c25178eb5f3956ae189dc384b" category="paragraph"><block ref="c1c59b2c25178eb5f3956ae189dc384b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="13d18f8604b3585f7ab88b87766a8d38" category="paragraph">Anthos를 배포하기 전에 다음과 같은 인프라를 구축해야 합니다.</block>
  <block id="92b7a761f185f74bf3bf9d2229c67a28" category="list-text">클러스터가 동적으로 확장되어야 하는 경우 필요에 따라 네트워크 주소 리스를 제공하는 데 사용할 수 있는 DHCP 서버입니다.</block>
  <block id="8256d4d5c73a64213343972bedd38f45" category="section-title">Anthos를 최소 3개의 노드로 구성된 ESXi 클러스터에 배포합니다</block>
  <block id="150754dbd257c09eef8557a399e5ebc2" category="paragraph">여러 하이퍼바이저 노드에 Anthos 클러스터 노드를 분산하는 것은 VM 및 호스트 친화성을 활성화하여 달성할 수 있습니다.</block>
  <block id="659aed3f7f249a658860ff0d51cdef11" category="paragraph">선호도 그룹을 구성하려면 아래에서 사용 중인 VMware vSphere 버전에 해당하는 링크를 참조하십시오.</block>
  <block id="bfe724d354657c9ac5cef22bd231f66f" category="inline-link">vSphere 7.0 설명서: DRS 선호도 규칙 사용</block>
  <block id="10c2b11d36730909ac14bcf903f9c456" category="paragraph"><block ref="0817a5be4b4f4733045646ef5cffc66c" category="inline-link-rx"></block>.<block ref="211975e132e07e8f3a0d0d18ff3759e5" category="inline-link-rx"></block>.</block>
  <block id="a272bae97494286f198c532bb9579161" category="list-text">그런 다음 이미지 레지스트리 TLS 인증서를 OpenShift 노드에 업로드합니다. 이렇게 하려면 TLS 인증서를 사용하여 OpenShift-config 네임스페이스에서 configmap을 만들고 이를 클러스터 이미지 구성에 패치하여 인증서를 신뢰할 수 있도록 합니다.</block>
  <block id="306235ad6a87783a223e0ba03145dc12" category="doc">개인 이미지 레지스트리 만들기</block>
  <block id="56a0195518edf56f84e2b789302cf485" category="paragraph">이 절차에서는 Astra Trident 및 NetApp ONTAP에서 제공하는 영구 볼륨의 지원을 받는 개인 이미지 레지스트리를 만드는 방법에 대해 설명합니다.</block>
  <block id="13bb7c6596c212587d7a35708de351f2" category="admonition">Astra Control Center에는 Astra 컨테이너에 필요한 이미지를 호스팅하기 위한 레지스트리가 필요합니다. 다음 섹션에서는 Red Hat OpenShift 클러스터에서 사설 레지스트리를 설정하고 Astra Control Center 설치를 지원하는 데 필요한 이미지를 푸시하는 단계를 설명합니다.</block>
  <block id="83806e2d09a78bbe33b3e817a88df12b" category="list-text">수신 운영자 OpenShift 레지스트리 경로에 기본 TLS 인증서를 사용하는 경우 다음 명령을 사용하여 TLS 인증서를 가져올 수 있습니다.</block>
  <block id="6714b6fa43a8d03bcbfeb657bd27788d" category="list-text">OpenShift 내부 레지스트리는 인증에 의해 제어됩니다. 모든 OpenShift 사용자는 OpenShift 레지스트리에 액세스할 수 있지만 로그인한 사용자가 수행할 수 있는 작업은 사용자 권한에 따라 다릅니다.</block>
  <block id="489c81c1a0ec76cf6ab9a12890120550" category="list-text">서비스 계정에 패치하려면 다음 명령을 실행합니다.</block>
  <block id="ec0c98e5e0be835a1df04b40b6c8e96c" category="list-text">OpenShift 노드 이외의 워크스테이션에서 이미지를 푸시 또는 풀려면 다음 단계를 수행하십시오.</block>
  <block id="872c01365a01300e2a8a772cd65e51b1" category="summary">이 페이지에서는 시소 로드 밸런서에 대한 설치 및 구성 지침을 자세히 설명합니다.</block>
  <block id="1ffbf83c6ff924ed568f0f88c922ac88" category="paragraph">이 페이지에는 시소 관리 로드 밸런서에 대한 설치 및 구성 지침이 나와 있습니다.</block>
  <block id="aa2bdb165616b7814c712fd55ecd1ce8" category="paragraph">다음 텍스트는 GKE-Admin 클러스터에 대한 파티션 구성의 샘플입니다. 주석 및 수정이 필요한 값은 아래 굵은 텍스트로 표시됩니다.</block>
  <block id="b7e1a8e2925f8cb0b4f88b8532edd6d7" category="admonition">이 파일은 로드 밸런서가 기본 클러스터에 제공하는 네트워크의 게이트웨이와 넷마스크를 제공하고, 로드 밸런서를 실행하기 위해 구축된 가상 머신의 관리 IP 및 호스트 이름을 제공합니다.</block>
  <block id="5137c3284aa2dc8893ef670919f28a5f" category="list-text">설치를 시작하기 전에 Astra Control Center 이미지를 이미지 레지스트리로 밀어 넣으십시오. Docker 또는 Podman에서 이 작업을 수행할 수 있습니다. 두 가지 모두에 대한 지침은 이 단계에서 제공합니다.</block>
  <block id="123a55fe7e6f2398763a03f409e2c1de" category="admonition">또는 서비스 계정을 만들고, 레지스트리 편집기 및/또는 레지스트리 뷰어 역할(푸시/풀 액세스 필요 여부에 따라)을 할당하고, 서비스 계정의 토큰을 사용하여 레지스트리에 로그인할 수 있습니다.</block>
  <block id="a917b1e998a1fed8ddebd661c3ff12b3" category="list-text">쉘 스크립트 파일을 작성하고 다음 내용을 붙여 넣습니다.</block>
  <block id="f2f27bc59d06be1e1f58b94160cf9949" category="admonition">kubeadmin 사용자를 사용하여 개인 레지스트리에 로그인하는 경우 암호 대신 토큰을 사용합니다. - docker login -u OCP -user -p token astra-registry.apps.ocp-vmw.cie.netapp.com`.</block>
  <block id="61dbdb9822ed0d400254915ff02a4ee9" category="admonition">또는 서비스 계정을 만들고, 레지스트리 편집기 및/또는 레지스트리 뷰어 역할(푸시/풀 액세스 필요 여부에 따라)을 할당하고, 서비스 계정의 토큰을 사용하여 레지스트리에 로그인할 수 있습니다.</block>
  <block id="37a5c97f291196f8c672c75798a29beb" category="admonition">경로를 사용하여 수신 운영자의 기본 TLS 인증서가 있는 OpenShift 내부 레지스트리를 사용하는 경우 이전 단계를 따라 인증서를 경로 호스트 이름에 패치해야 합니다. 수신 운영자로부터 인증서를 추출하기 위해 'OC extract secret/router-ca--keys=tls.crt-n openshift-ingrator' 명령어를 사용할 수 있다.</block>
  <block id="08e6bc541e2517b4105b8ac0ccbfe0f3" category="list-text">"NetApp-acc-operator" 네임스페이스에서 자격 증명을 사용하여 이미지 레지스트리에 로그인하기 위한 암호를 만듭니다.</block>
  <block id="e1e6f0b52690f367570b6c16ddf92d98" category="list-text">'NetApp-acc-operator' 타일을 선택하고 설치 를 클릭합니다.</block>
  <block id="1c17ca035fc060e6a6c77e025e8f27a1" category="list-text">Install Operator(설치 작업자) 화면에서 모든 기본 매개변수를 적용하고 Install(설치)을 클릭합니다.</block>
  <block id="5fa86531d41ab8ca8bee80ba657a599d" category="list-text">작업자 설치가 완료되면 View Operator(작업자 보기) 로 이동합니다.</block>
  <block id="72c52a676e647d2aa400f12fe446f9f1" category="list-text">그런 다음, 운영자의 Astra Control Center 타일에서 인스턴스 생성을 클릭합니다.</block>
  <block id="500c99ec2ed1582312d17f1ea94ab5d0" category="list-text">Create AstraControlCenter 양식 필드에 내용을 입력하고 Create를 클릭합니다.</block>
  <block id="097026a522eed2b2c71f07efd97bcf31" category="list-text">Astra Control Center의 계정 이름과 이름, 성, 이메일 주소와 같은 관리자 세부 정보를 입력합니다.</block>
  <block id="ad2acc92f46f11a5d2a5ace0c933a44c" category="list-text">이미지 레지스트리에서 이미지를 레지스트리로 푸시하는 동안 레지스트리 FQDN과 조직 이름을 입력합니다(이 예에서는 "astra-registry.apps.ocp-vmw.cie.netapp.com/netapp-astra`).</block>
  <block id="3e99f691e1f9756e43f68a0aa28e61e0" category="list-text">인증이 필요한 레지스트리를 사용하는 경우 이미지 레지스트리 섹션에 암호 이름을 입력합니다.</block>
  <block id="f009662483a899fd0d4b99ff5f1912f3" category="list-text">Astra Control Center 리소스 제한에 대한 확장 옵션을 구성합니다.</block>
  <block id="c8a326f53d0d33a113452a303c243987" category="summary">NetApp과 Google Cloud는 수년간 긴밀한 관계를 유지하고 있었으며, NetApp은 Cloud Volumes ONTAP과 Cloud Volumes Service를 통해 Google Cloud에 클라우드 데이터 서비스를 최초로 도입했습니다. 그런 다음 NetApp HCI 플랫폼을 검증하여 VMware vSphere에 구축된 하이퍼바이저 기반 하이브리드 멀티 클라우드 Kubernetes 솔루션인 Google Cloud Anthos On-Premises와 함께 사용할 수 있도록 했습니다. 그런 다음 NetApp은 NetApp Astra Trident, ONTAP 및 NFS 프로토콜을 위한 Anthos Ready 자격을 통과하여 컨테이너에 동적 영구 스토리지를 제공했습니다.</block>
  <block id="f989491ea62ea4778f84ec6b21a68adf" category="paragraph">NetApp과 Google Cloud는 수년간 긴밀한 관계를 유지하고 있었으며, NetApp은 Cloud Volumes ONTAP 및 Cloud Volumes Service를 통해 Google Cloud용 클라우드 데이터 서비스를 최초로 도입했습니다. 그런 다음 NetApp HCI 플랫폼을 검증하여 VMware vSphere에 구축된 하이퍼바이저 기반 하이브리드 멀티 클라우드 Kubernetes 솔루션인 Google Cloud Anthos On-Premises와 함께 사용할 수 있도록 했습니다. 그런 다음 NetApp은 NetApp Astra Trident, ONTAP 및 NFS 프로토콜을 위한 Anthos Ready 자격을 통과하여 컨테이너에 동적 영구 스토리지를 제공했습니다.</block>
  <block id="1349318f8c0f3a02420c7453ca5cda7d" category="paragraph">Anthos는 이제 고객 환경의 베어 메탈 서버에 직접 설치할 수 있으며, 이를 통해 고객은 하이퍼바이저가 없는 로컬 데이터 센터로 Google Cloud를 확장할 수 있는 추가 옵션을 추가할 수 있습니다. 또한 NetApp ONTAP 스토리지 운영 체제 및 NetApp Astra Trident의 기능을 활용하여 컨테이너용 영구 스토리지를 통합하여 플랫폼의 기능을 확장할 수 있습니다.</block>
  <block id="2b9593caebc55ca069d98dcb7a3473c8" category="list-text">NetApp Astra Trident를 사용하여 NetApp ONTAP에서 요청된 영구 볼륨을 프로비저닝하고 첨부하십시오.</block>
  <block id="c0724935c9b9fa3acfd0441317cac5e4" category="list-text">영구 볼륨의 분리 및 다시 연결 기능을 확인합니다.</block>
  <block id="05053a6eeca3d00f1ffdaead4d65118f" category="list-text">노드의 다른 Pod에서 영구 볼륨의 멀티 연결, 읽기 전용 액세스를 검증합니다.</block>
  <block id="d7b2cdc877c7db996d45c651b4e7834a" category="paragraph">이 문서에서는 Kubernetes용 오픈 소스 스토리지 오케스트레이터인 NetApp Astra Trident를 사용하여 베어 메탈 플랫폼에서 Google Cloud의 Anthos를 기반으로 NetApp ONTAP 스토리지 플랫폼의 구성 및 검증을 개략적으로 설명하고 상태 저장 애플리케이션 컨테이너용 영구 스토리지를 배포 및 관리합니다.</block>
  <block id="4ed7e16612fd7090efc8d89c68421b74" category="paragraph">ONTAP 9.7 소프트웨어를 실행하는 NetApp AFF A300 스토리지 시스템은 Anthos 작업자 노드와 동일한 Nexus 9k 스위치 쌍에 물리적으로 설치 및 연결되었습니다. 이러한 네트워크 업링크는 인터페이스 그룹(a0a)에 통합되었으며, 작업자 노드가 스토리지 시스템과 상호 작용할 수 있도록 적절한 데이터 네트워크 VLAN 태그가 지정되었습니다. SVM(Storage Virtual Machine)은 NFS 프로토콜을 지원하는 데이터 LIF와 Trident를 위한 스토리지 운영 전용으로 생성되어, 베어 메탈 클러스터의 Anthos에 구축된 컨테이너에 영구 스토리지를 제공합니다. 이러한 영구 볼륨은 Kubernetes용 NetApp 오픈 소스 스토리지 오케스트레이터의 최신 릴리즈인 NetApp Astra Trident 20.10에서 제공됩니다.</block>
  <block id="6a5e993e443aa30456050e2589b6e1a7" category="paragraph">NetApp Astra Trident는 Google Cloud Anthos를 비롯한 컨테이너 및 Kubernetes 배포를 위한 오픈 소스 및 완벽하게 지원되는 스토리지 오케스트레이터입니다. NetApp ONTAP 소프트웨어를 비롯한 전체 NetApp 스토리지 포트폴리오와 연동됩니다. Trident는 CSI를 완벽히 지원하므로 스토리지 관리자의 개입 없이 NetApp 스토리지 시스템에서 스토리지를 프로비저닝 및 관리할 수 있어 DevOps 워크플로우를 가속화합니다. Trident는 Kubernetes API 엔드포인트와 직접 통신하여 NetApp 스토리지 시스템에서 볼륨을 생성 및 관리하여 컨테이너의 스토리지 요청을 PVC(영구적 볼륨 클레임)의 형태로 제공하는 운영자로 구축됩니다.</block>
  <block id="eb3bc37ad07db70234f55e02bb4fa499" category="paragraph">NetApp Astra Trident에 대한 자세한 내용은 을 참조하십시오<block ref="9f564c4a71f7ad715885fb9db4485dda" category="inline-link-rx"></block> 페이지.</block>
  <block id="3752e68cccc911651920465532b3d6b4" category="paragraph">베어 메탈 기반 Anthos의 하드웨어 독립적 기능을 사용하면 사용 사례에 최적화된 컴퓨팅 플랫폼을 선택할 수 있습니다. 따라서 는 기존 인프라를 일치시키고 자본 지출을 줄일 수 있습니다.</block>
  <block id="fb5205026c598f136a15ad6c49fc1826" category="paragraph">다음 표에는 솔루션을 구현하는 데 필요한 최소 스토리지 하드웨어 구성 요소의 수가 나와 있습니다. 단, 사용되는 하드웨어 모델은 고객 요구 사항에 따라 다를 수 있습니다.</block>
  <block id="0e98dfa85df93b279e4fd456b30409cf" category="admonition">이 멀티 OS 환경은 베어 메탈 솔루션의 Anthos의 지원되는 OS 버전과의 상호 운용성을 보여줍니다. 우리는 고객이 구축을 위해 하나 또는 일부 운영 체제를 표준화할 것으로 예상하고 있습니다.</block>
  <block id="65ffe919dd9568cce4454508d8e543bd" category="paragraph">NetApp의 Bare Metal Anthos는 배포된 인프라의 사용자 지정을 가능하게 하여 컨테이너 기반 워크로드를 효율적으로 실행할 수 있는 강력한 플랫폼을 제공합니다. 고객은 원하는 서버 인프라와 지원되는 운영 체제를 사용하거나 기존 인프라에 솔루션을 배포할 수도 있습니다. 이러한 환경의 기능과 유연성은 NetApp ONTAP 및 NetApp Astra Trident의 통합을 통해 크게 증가하므로 컨테이너용 영구 스토리지를 효율적으로 프로비저닝 및 관리하여 상태 저장 애플리케이션 워크로드를 지원합니다. Google Cloud의 잠재력을 NetApp이 제공하는 데이터 센터로 확장함으로써, 고객은 애플리케이션 워크로드를 개발 및 프로덕션하기 위해 완벽하게 지원되고 가용성이 높고 쉽게 확장 가능하며 완벽하게 관리되는 Kubernetes 솔루션의 이점을 실현할 수 있습니다.</block>
  <block id="96bef5489c133651bd324f8029d14586" category="paragraph"><block ref="96bef5489c133651bd324f8029d14586" category="inline-link-macro-rx"></block></block>
  <block id="8b682694b3e16be71600ae19c5a6e2fe" category="doc">NetApp Astra Control을 활용하여 사후 분석을 수행하고 애플리케이션을 복원합니다</block>
  <block id="7715f0efda43c06909ce1afad9f650b6" category="inline-link-macro">다음: 추가 정보: NetApp Astra를 통한 DevOps</block>
  <block id="5d74a508c84dc62d2e7a448ba2c651fa" category="paragraph"><block ref="5d74a508c84dc62d2e7a448ba2c651fa" category="inline-link-macro-rx"></block></block>
  <block id="97e84aad4ef505e4cda6422dc1c95990" category="doc">추가 정보: NetApp Astra를 통한 DevOps</block>
  <block id="0221d1074d249c254f0679e761454a05" category="inline-link"><block ref="0221d1074d249c254f0679e761454a05" category="inline-link-rx"></block></block>
  <block id="40454fb96e27a719bd7a751c4ec47d16" category="paragraph"><block ref="40454fb96e27a719bd7a751c4ec47d16" category="inline-link-rx"></block></block>
  <block id="5eae6f5974c9d4195ebe0cf8b607647e" category="list-text">Ansible 설명서</block>
  <block id="015674032a5c43c779a74ee9e3dbfc94" category="inline-link"><block ref="015674032a5c43c779a74ee9e3dbfc94" category="inline-link-rx"></block></block>
  <block id="f13ae695d1de0b91201bca0cd4e87c69" category="paragraph"><block ref="f13ae695d1de0b91201bca0cd4e87c69" category="inline-link-rx"></block></block>
  <block id="f89c93af274397315016bac75d215351" category="inline-link"><block ref="f89c93af274397315016bac75d215351" category="inline-link-rx"></block></block>
  <block id="9e4287aba38224954e73e528ce96bb47" category="paragraph"><block ref="9e4287aba38224954e73e528ce96bb47" category="inline-link-rx"></block></block>
  <block id="7a42c46751036b34f81738e60f1b7e97" category="list-text">Rancher 문서</block>
  <block id="6483799d4ba7ad61fe06633600d8824a" category="inline-link"><block ref="6483799d4ba7ad61fe06633600d8824a" category="inline-link-rx"></block></block>
  <block id="b8e7a2183995014079b38a90770a02ea" category="paragraph"><block ref="b8e7a2183995014079b38a90770a02ea" category="inline-link-rx"></block></block>
  <block id="d7c98030ea1f0ace5cb1fc0a5954a87c" category="list-text">Kubernetes 문서</block>
  <block id="1c333560e2edbd1cefb05f127658b17f" category="doc">Astra Control Center를 통해 CI/CD 파이프라인에서 데이터 보호</block>
  <block id="943b2a1ab5485e1a2db3098051987614" category="summary">FlexClone 기술을 사용하여 빠르게 구축합니다</block>
  <block id="065cb44483a670695f374bc25a1f01b4" category="doc">사용 사례 검증: NetApp Astra와 DevOps</block>
  <block id="438d983a4a02b97c1363407ba1bb3dbd" category="paragraph">NetApp Astra를 사용하여 DevOps에서 검증된 사용 사례는 다음과 같습니다.</block>
  <block id="47d55e9f9b259c93da777f74a5e832ee" category="inline-link-macro">NetApp Astra Control을 통해 CI/CD 파이프라인에 보호 기능을 통합합니다</block>
  <block id="86ebb4e5f51da406d6b6170528e02c8c" category="list-text"><block ref="86ebb4e5f51da406d6b6170528e02c8c" category="inline-link-macro-rx"></block></block>
  <block id="a9e51e0a4f30c204f900ee62c24b54e8" category="inline-link-macro">Astra Control을 활용하여 사후 분석 및 애플리케이션 복원을 용이하게 합니다</block>
  <block id="5ea6f0d962656bf6d901dedc10e9da49" category="list-text"><block ref="5ea6f0d962656bf6d901dedc10e9da49" category="inline-link-macro-rx"></block></block>
  <block id="6c9a3a62fc54ba1feccaee9df9c39f88" category="inline-link-macro">NetApp FlexClone으로 소프트웨어 개발 가속화</block>
  <block id="001bc4e878f5da889174d53f10bc3a58" category="list-text"><block ref="001bc4e878f5da889174d53f10bc3a58" category="inline-link-macro-rx"></block></block>
  <block id="69955eeaaa4d02c4d90d3119741235a0" category="inline-link-macro">다음: 비디오 및 데모 - NetApp Astra의 DevOps</block>
  <block id="d2ed0f238fb1fa6e7a14606baf24c2ab" category="paragraph"><block ref="d2ed0f238fb1fa6e7a14606baf24c2ab" category="inline-link-macro-rx"></block></block>
  <block id="d0f564d49f74b4698141e88cbce5ad41" category="summary">NetApp은 컨테이너화된 애플리케이션에 대한 데이터를 프로비저닝, 보호 및 관리할 수 있는 Astra Trident 및 Astra Control과 함께 자격을 갖춘 여러 스토리지 플랫폼을 보유하고 있으므로 DevOps 처리량을 정의하고 극대화하는 데 도움이 됩니다.</block>
  <block id="b43c4021858544ebd3a492d082a7f349" category="doc">NetApp 스토리지 시스템 개요</block>
  <block id="e3775ded02e90946eb22f7f559238e62" category="list-text"><block ref="e3775ded02e90946eb22f7f559238e62" category="inline-link-macro-rx"></block></block>
  <block id="9111d84a5d538f39612bb42cb2a729aa" category="inline-link-macro">다음은 NetApp 스토리지 통합 개요입니다.</block>
  <block id="1139e8039447d6c6f83fa4a35ea79999" category="paragraph"><block ref="1139e8039447d6c6f83fa4a35ea79999" category="inline-link-macro-rx"></block></block>
  <block id="70806b7246c09c2ec58c7947d781ebdf" category="doc">NetApp Astra Control 개요</block>
  <block id="3d4bc8fb320a39f7369e26aa8dd43ff9" category="paragraph">Astra Control Center에 대한 자세한 설치 및 운영 가이드는 설명서를 참조하십시오 <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>.</block>
  <block id="778aa9cc77239e29447d4ec0991d37ed" category="section-title">Astra Control Center 자동화</block>
  <block id="1c3dabdc1df77100ef6e17757091285e" category="paragraph">Astra Control Center에는 프로그래밍 방식의 액세스를 위한 완전한 기능의 REST API가 있습니다. 사용자는 프로그래밍 언어 또는 유틸리티를 사용하여 Astra Control REST API 끝점과 상호 작용할 수 있습니다. 이 API에 대한 자세한 내용은 설명서를 참조하십시오 <block ref="bb2ca4e10b1254bc49d4388c68f9edb7" category="inline-link-macro-rx"></block>.</block>
  <block id="5d9f4b40183d98a25c3ab751a2c22032" category="paragraph">Astra Control REST API와 상호 작용하기 위해 미리 만들어진 소프트웨어 개발 툴킷을 원할 경우, NetApp에서 다운로드할 수 있는 Astra Control Python SDK 툴킷을 제공합니다 <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>.</block>
  <block id="22082fb9e9a42ddec66d9e75b3a3e61f" category="paragraph">프로그래밍이 현재 상황에 고유하지 않고 구성 관리 툴을 사용하려는 경우 NetApp이 게시하는 Ansible 플레이북을 클론 복제 및 실행할 수 있습니다 <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>.</block>
  <block id="d10e08b0a3edeee9dca36ed4d8843516" category="inline-link-macro">다음: 사용 사례 검증: NetApp Astra를 사용한 DevOps</block>
  <block id="05caddd89629dc542b78549ec8132f7e" category="paragraph"><block ref="05caddd89629dc542b78549ec8132f7e" category="inline-link-macro-rx"></block></block>
  <block id="b75bc3343d170f8dd97d55a434b978ed" category="doc">Astra Control을 사용하여 사후 분석을 용이하게 하고 애플리케이션을 복원합니다</block>
  <block id="3bbc946d425216e518cab3d8bcac2d2e" category="inline-link-macro">첫 번째 사용 사례</block>
  <block id="3693bda9c9f6c60fbcfaa68a3c84d1c0" category="paragraph">에 있습니다 <block ref="378d294ca149bdd5226353f2fb623f62" category="inline-link-macro-rx"></block>또한, NetApp Astra Control Center를 사용하여 Kubernetes에서 애플리케이션을 보호하는 방법을 시연했습니다. 이 섹션에서는 NetApp Astra 툴킷에서 Python SDK를 사용하여 Astra Control을 통해 애플리케이션 백업을 개발 워크플로우에 직접 통합하는 방법을 설명합니다. 이 방식을 사용하면 CI/CD(Continuous Integration and Continuous Deployment) 프로세스 중에 주문형 백업을 자동화하여 개발 및 운영 환경을 보호할 수 있습니다. 이 애플리케이션 정합성 보장 데이터 보호 계층이 CI/CD 파이프라인 및 운영 애플리케이션에 추가되면서 프로세스에 문제가 발생하면 개발 프로세스가 안전해 비즈니스 연속성 모범 사례를 촉진합니다.</block>
  <block id="93cf0eac312e112dec7819cf9726e08d" category="paragraph">기존 워크플로우에서 응용 프로그램을 새 버전으로 업그레이드할 때 오류가 발생한 후 개발 팀은 고객이 제공하는 버그 보고서를 기반으로 실시간으로 문제 해결을 시도합니다. 또는 문제가 처음 발생할 때 팀이 병렬 디버깅 환경에 응용 프로그램을 다시 배포하여 해당 프로세스를 오프라인으로 만들 수 있습니다. 이전 버전에서 운영 환경으로 이전 코드 기반을 재배포하여 응용 프로그램을 작업 순서로 복원할 수 있습니다.</block>
  <block id="63cbc205a471137f16d61f24cd16531d" category="image-alt">기존 워크플로우</block>
  <block id="cd78d769508976f182829ab0d59eb537" category="paragraph">이 방식은 효과가 있지만, IT 팀은 문제가 발생했을 때 손상된 운영 앱의 상태가 운영 환경에 표시된 버전과 일치하는지 확인해야 합니다. 또한 리포지토리에서 코드를 가져와 시스템 이미지를 다시 배포하여 응용 프로그램을 양호한 실행 상태로 복원함으로써 정상 작동이 확인된 빌드를 운영 환경으로 승격하는 데 시간을 소비해야 합니다. 또한 이 시나리오에서는 프로덕션 데이터베이스 자체가 결함 있는 코드로 인해 손상되었는지 여부를 고려하지 않았습니다. 데이터베이스 데이터를 위한 별도의 백업 프로세스가 마련되어 있는 것이 이상적이지만 게시된 응용 프로그램의 상태와 일치한다고 가정해야 합니까? 여기서 Stateful 및 애플리케이션 정합성이 보장되는 백업, 복원 및 클론 생성 시 Astra Control이 제공하는 이점은 그 가치를 실제로 보여 줍니다.</block>
  <block id="8b8ad5ef011a096e139bfa3245f80536" category="paragraph">먼저 Astra Control을 사용하여 응용 프로그램의 상태에 대한 사후 분석을 용이하게 할 수 있습니다. 우리는 응용 프로그램 일관성 있는 방식으로 버기 프로덕션 버전을 병렬 테스트 환경에 복제하는 방식으로 이 작업을 수행합니다. 이 환경을 버그에 따라 문제가 발생한 상태로 두고 실시간으로 문제를 해결할 수 있습니다.</block>
  <block id="f94a2c6cdc2965b0f258d8215d1d28e0" category="paragraph">또한 Astra Control은 운영 애플리케이션을 마지막 허용 가능한 백업(해당 코드 버전 이전)으로 복원할 수 있는 데이터 이동 없는 복원 기능을 지원합니다. 복원된 버전은 이전에 할당된 수신 IP를 포함하여 응용 프로그램 일관성 및 상태 저장 방식으로 이전 버기 프로덕션 응용 프로그램의 위치를 가정합니다. 따라서 프런트 엔드에 액세스하는 고객은 백업 버전으로의 전환에 대해 알지 못합니다.</block>
  <block id="1b0d7d8dcdf6d93ab2d330cc2396dfbc" category="image-alt">사후 작업 흐름</block>
  <block id="204890df83c01d375e4f4b6a724cc278" category="section-title">사용 사례 검증을 위한 사전 요구사항</block>
  <block id="93323e0f22b5aab17967ba48325ffbfa" category="paragraph">다음 도구 또는 플랫폼이 전제 조건으로 구축 및 구성되었습니다.</block>
  <block id="f4f24690df38094196eebb86cb8ae057" category="list-text">Red Hat OpenShift Container Platform</block>
  <block id="727324215fe79d6ac06ad699c15bc8b6" category="list-text">NetApp ONTAP 시스템에 백엔드가 구성된 OpenShift에 설치된 NetApp Astra Trident</block>
  <block id="229afb3c2926b78c5616a952d849e68c" category="list-text">NetApp ONTAP 백엔드를 가리키는 기본 스토리지 클래스 구성</block>
  <block id="ba5452097a4c1be15b1efd3a6b26349f" category="list-text">OpenShift 클러스터에 설치된 NetApp Astra Control Center</block>
  <block id="81c0c009a723f32f259a76657c0df955" category="list-text">OpenShift 클러스터가 Astra Control Center에 관리 클러스터로 추가되었습니다.</block>
  <block id="6500a898faeb0dbf12368cd5d4c62b66" category="list-text">Jenkins가 OpenShift 클러스터에 설치되어 있습니다.</block>
  <block id="76046924ab57dbfe48ac94a0d7cd184f" category="list-text">생산 환경에 설치된 Magento 응용 프로그램. 이 활용 사례의 운영 환경은 Red Hat OpenShift 클러스터의 'magento-prod'라는 네임스페이스입니다.</block>
  <block id="7e5531e0bbdbf2a1b4736169f5261238" category="list-text">운영 애플리케이션은 Astra Control Center에서 관리합니다.</block>
  <block id="be3750e953403822ff53f62de7d378c9" category="list-text">Astra Control로 캡처한 운영 애플리케이션의 정상 작동이 확인된 백업입니다.</block>
  <block id="a571d6a950aa43dc09919def5e2f001a" category="section-title">파이프라인 복제 및 복원</block>
  <block id="c04ae281a30f44b5bfe0091b23da26f7" category="paragraph">애플리케이션이 새 버전으로 업그레이드되었다는 점을 고려하면 프로덕션 환경('magento-prod')의 애플리케이션이 업그레이드 후 의도한 대로 작동하지 않습니다. 프런트 엔드 쿼리에서 반환되는 데이터가 요청과 일치하지 않거나 데이터베이스가 실제로 손상되었다고 가정해 보겠습니다. 파이프라인을 클론 복제 및 복원하려면 다음 단계를 완료하십시오.</block>
  <block id="8c2af21e6b34f2b1071040d4d1cfcb1c" category="image-alt">실패한 앱</block>
  <block id="6b1006b72a3e1550c386243b3965f2dc" category="list-text">Jenkins에 로그인하고 새 항목, 파이프라인을 차례로 클릭하여 파이프라인을 생성합니다.</block>
  <block id="42c6ce7c0a0da42cf240660b7916b661" category="list-text">Jenkinsfile에서 파이프라인을 복사합니다<block ref="8676dd4f33dff00c4bf2944921591642" category="inline-link-rx"></block>.</block>
  <block id="64b46adfefce359622cb0f4882c6c1bd" category="list-text">Jenkins 파이프라인 섹션에 파이프라인을 붙여넣은 다음 저장을 클릭합니다.</block>
  <block id="68d9707b516a968ed4c0757cbe9d5a9f" category="list-text">운영 환경의 현재 Magento 응용 프로그램 버전, Astra Control Center FQDN, API 토큰, 운영 및 디버그 환경의 인스턴스 ID 및 응용 프로그램 이름 또는 네임스페이스, 소스 및 대상 클러스터 이름과 같은 각 세부 정보로 Jenkins 파이프라인의 매개 변수를 채웁니다. 이 활용 사례를 위해 운영 환경은 'magento-prod'라는 네임스페이스이며, 디버그 환경은 Red Hat OpenShift 클러스터에 구성된 'magento-debug'라는 네임스페이스입니다.</block>
  <block id="0aada8c0ec6d36d56210caa3cac9e025" category="list-text">지금 구축을 클릭합니다. 파이프라인은 실행을 시작하고 단계를 진행합니다. 응용 프로그램은 먼저 현재 상태에서 디버그 환경으로 복제되고 응용 프로그램은 알려진 작업 백업으로 복원됩니다.</block>
  <block id="4413dc875e85526bf92964b740f23064" category="image-alt">사후 파이프라인</block>
  <block id="4abbf0b75dc539f2afebf5014fbe6ea8" category="list-text">복제된 응용 프로그램이 버그 포함 버전인지 확인합니다.</block>
  <block id="cbcf57aecdb6a6d216d8239a690bc2f6" category="image-alt">클론 생성된 앱에 실패했습니다</block>
  <block id="e73e23a9c5f896c3c98ea35a77116dfe" category="list-text">운영 환경이 작업 중인 백업으로 복원되고 운영 중인 애플리케이션이 예상대로 작동하는지 확인합니다.</block>
  <block id="b24fb6cbfbfd8a2620eab1cb8f9d1563" category="image-alt">Prod 앱을 복원했습니다</block>
  <block id="cbd612409ffde58db700aacbf7ea15ca" category="paragraph">이 두 가지 작업을 함께 수행할 경우 일반 비즈니스 운영으로 더 빠르게 되돌릴 수 있습니다. 이 사용 사례를 실제 작동 중인 경우 비디오를 시청하십시오 <block ref="f5eb99e953852b5d0acfc08abd7c4f00" category="inline-link-macro-rx"></block>.</block>
  <block id="847338f2bbcf0d01da4eec4011f6ad14" category="summary">이 기술 보고서에서는 컨테이너식 애플리케이션을 사용하여 NetApp에서 DevOps 사용 사례를 간편하고 효율적으로 활용하는 방법을 간략하게 설명합니다. 먼저, Astra 포트폴리오를 사용하여 NetApp 스토리지 시스템과 Kubernetes 플랫폼과의 통합에 대해 자세히 설명합니다. 마지막으로, 다양한 솔루션 검증 및 실제 사용 사례를 살펴보고 문서화합니다.</block>
  <block id="322f410c2f08f93c29982d4bf9cabcc0" category="doc">TR-4919: NetApp Astra를 통한 DevOps</block>
  <block id="ede7528f12f050f41a167a0f19204ecb" category="paragraph">NetApp Astra 기반의 DevOps 솔루션은 다음과 같은 사용 사례를 통해 고객에게 뛰어난 가치를 제공하도록 설계되었습니다.</block>
  <block id="2dcb73ff09329212051362094e88c1a7" category="list-text">지원되는 Kubernetes 배포 위에 구축된 애플리케이션 및 개발 환경을 손쉽게 구축 및 관리할 수 있습니다.</block>
  <block id="c267f4560fe6c3f4bee2d0420cdd7977" category="list-text">DevOps 워크플로우의 실제 사용 사례에 대한 논의 및 NetApp이 이러한 방법을 더욱 쉽게 채택 및 사용할 수 있도록 제공하는 툴 및 방법의 예</block>
  <block id="52d3258544cd838f0c52461847e6943b" category="list-text">애플리케이션 정합성이 보장된 스냅샷, 백업 및 클론을 사용하여 DevOps 경험을 향상하는 방법을 알아보십시오.</block>
  <block id="6071498e95e7692ffc4f3f66e80e1fe2" category="list-text">스택의 모든 계층에서 고가용성을 보장하므로 워크플로우가 중단되지 않습니다.</block>
  <block id="0fd2f931dbf65015445450e54266b6dd" category="list-text">최종 사용자를 위한 간편한 배포 및 관리 절차</block>
  <block id="683aa4d78ced60b9236f9cc2f4eaf1eb" category="list-text">마이크로서비스 및 개발자 민첩성을 따라잡을 수 있는 API 기반 프로그래밍 가능 인프라</block>
  <block id="440bd390f196ecee0d5c1bbc242f74c1" category="list-text">워크로드 요구사항에 따라 인프라를 독립적으로 자동 확장할 수 있습니다.</block>
  <block id="e1151e572983d1f8759759f2765ccd80" category="list-text">DevOps 워크플로우에 대한 백업 영구 데이터 세트와 함께 애플리케이션을 보호하면 재구축이나 수동 데이터 복제에 의존하지 않고 시장 출시 기간을 단축할 수 있습니다.</block>
  <block id="556e90029d54aba834e233882cb7bdb5" category="paragraph">이러한 기능과 과제를 인식하는 이 기술 보고서는 다양한 NetApp 제품 포트폴리오를 사용하여 컨테이너화된 애플리케이션의 DevOps 사용 사례를 개선 및 단순화하는 프로세스를 개략적으로 설명합니다.</block>
  <block id="3c4a3a2e21fd3a1caee264afd78ccaa4" category="paragraph">NetApp을 지원하는 DevOps 솔루션에는 다음과 같은 주요 구성 요소가 포함되어 있습니다.</block>
  <block id="26ebb4a3d87e964eeae59f74f1cf7565" category="section-title">DevOps 사례</block>
  <block id="d113ef32a81ded7eb94b33e9a12344d3" category="paragraph">DevOps 사례에서는 최종 사용자가 코드를 개발 중인 환경을 제어할 수 있도록 함으로써 개발 워크플로우를 개선하는 자동화되고 반복 가능하며 쉽게 관리할 수 있는 운영에 초점을 맞춥니다. 이 솔루션은 NetApp 기술이 이러한 운영에 가장 큰 도움이 될 수 있는 몇 가지 예와 사용 사례를 제공합니다.</block>
  <block id="301a5e3f98e4b9ad41275bc224cd61ec" category="paragraph">현재 수많은 컨테이너 오케스트레이션 플랫폼을 사용하고 있습니다. 이러한 플랫폼의 대부분은 Kubernetes를 기반으로 하지만 각각 장단점이 있습니다. 따라서 DevOps 워크플로우에 사용할 컨테이너 오케스트레이션 플랫폼을 선택할 때는 기능 세트와 통합을 이해하는 것이 중요합니다. NetApp Astra 제품군을 사용하여 전체 DevOps 사용 사례에 대해 다음 플랫폼을 지원합니다.</block>
  <block id="6c00bd8314a0e887501377d7e80e84a0" category="list-text"><block ref="41493d18eda2456ccaff840381cd2ba9" category="inline-link-rx"></block> 4.6.8+</block>
  <block id="82033d4b30c6027097326898ed36b593" category="inline-link">목장</block>
  <block id="30fad75d887172c8bd19dcc5febd9364" category="list-text"><block ref="f47c99eede6f9eae831133d1e9b5034b" category="inline-link-rx"></block> 2.5 이상</block>
  <block id="22bd2466d697a7c77e319d9a31c2166f" category="list-text"><block ref="fe8d70118059c4a67994e27a008bb3e0" category="inline-link-rx"></block> 1.20 이상</block>
  <block id="a56837df79ae6671b6b511c330431135" category="inline-link">VMware Tanzu Kubernetes Grid를 참조하십시오</block>
  <block id="b2bc0f20995d2c98d2f854eb51c195c7" category="list-text"><block ref="3f98585591c50cc93953cd157cf0939c" category="inline-link-rx"></block> 1.4 이상</block>
  <block id="a1c1bb4994628000cfe61563bf4ff4f5" category="inline-link">VMware Tanzu Kubernetes Grid Integrated Edition을 참조하십시오</block>
  <block id="a75ee0eed3c5f01371e94695f023b820" category="list-text"><block ref="948fe538658bc79d22a37c7852e43c83" category="inline-link-rx"></block> 1.12.2 이상</block>
  <block id="fba78f40ce7eabf1a8bf79ee5c44bd8e" category="inline-link-macro">다음: DevOps 개요</block>
  <block id="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="paragraph"><block ref="a9d268e4b26cd47b2d7a0aa5a816a1c8" category="inline-link-macro-rx"></block></block>
  <block id="44a18520ed05f9b0b2e06135a4ff7518" category="summary">DevOps 및 이 기술 보고서의 잠재적 사용 사례에 대한 개요</block>
  <block id="74b9fd8d0b2ef1c2b396580a2afd59ae" category="doc">DevOps 개요</block>
  <block id="d5df4eecbaafa5d83d7698ba92c7cecd" category="paragraph">소프트웨어를 구축하는 조직은 지난 몇 년 동안 DevOps의 개념을 수용해 왔습니다. DevOps 사례는 조직의 장애물을 해소하여 개발 및 운영 팀을 더욱 가깝게 만들어줍니다. 또한 DevOps 사례를 통해 IT 팀은 제공 속도를 높이고, 가용성을 높이고, 서비스와 애플리케이션의 안정성을 개선하여 팀의 생산성을 높일 수 있습니다. 또한 자동화 프레임워크의 도입은 대규모 애플리케이션 구축, 테스트, 운영 또는 완전 자동화된 인프라 플랫폼 또는 스택 관리까지 성공의 핵심 요소입니다. DevOps 실무자가 일상 업무에서 접할 수 있는 경험을 향상하기 위해 NetApp 솔루션을 구현할 수 있는 DevOps의 몇 가지 주요 사용 사례에 대해 알아보겠습니다.</block>
  <block id="e7ccc944261680ee4a52d724dd1ca1c5" category="section-title">DevOps 사용 사례</block>
  <block id="e4fd3fc8a04e3e1d2e788cd1b017e1f2" category="paragraph">DevOps는 보편적으로 수락되는 단일한 정의를 가지고 있지 않지만, DevOps 교정기를 위한 솔루션은 일반적으로 규모에 따라 쉽게 구현, 반복 및 관리할 수 있는 유사한 구성이나 이념을 포함합니다. 다음 섹션에서는 NetApp 솔루션이 지원하는 DevOps 워크플로우의 잠재적 사용 사례를 설명합니다.</block>
  <block id="020a9588f0f051f7f9ff59fabaffa365" category="section-title">CI/CD(Continuous Integration, Continuous Delivery, Continuous Deployment)</block>
  <block id="b1a2676c9ceea5e6ef4c514562097e9a" category="paragraph">지속적인 통합, 지속적인 공급 및 CI/CD(Continuous Deployment, Continuous Delivery)는 자동화된 방식으로 코드를 지속적으로 업데이트, 테스트 및 배포할 수 있는 방법을 설정하여 개발자가 코딩 방식을 구현하고 혁신하도록 장려하는 코딩 철학입니다. 대부분의 DevOps 워크플로우에서 CI/CD를 구현하는 가장 일반적인 방법은 CI/CD 파이프라인이며, 이 목표를 달성하는 데 도움이 되는 여러 타사 소프트웨어 애플리케이션이 있습니다.</block>
  <block id="3ff91355eb24188940a49b15da87cb74" category="image-alt">CI/CD 이미지</block>
  <block id="64d92cb8c4c053363095cf796a7b89ba" category="paragraph">CI/CD 유형 워크플로에 도움이 될 수 있는 널리 사용되는 애플리케이션의 예는 다음과 같습니다.</block>
  <block id="418f66e40d28aac0fa315742070e645f" category="inline-link">ArgoCD를 참조하십시오</block>
  <block id="2e54334c0a5ce2e3e5a5845df3ab3ada" category="inline-link">젠킨스</block>
  <block id="e1500a23f27fb897c6cdf5caab04195d" category="inline-link">테크톤</block>
  <block id="4d094d290ed5b2a855427290709addea" category="paragraph"><block ref="ff7d5093e53bbd8006cbcaaeb044f69a" category="inline-link-rx"></block>
<block ref="0d8e72f4ae085bb6c45eba7c3f144090" category="inline-link-rx"></block>
<block ref="313a601d85cff2a8e7d85ce0f552cc73" category="inline-link-rx"></block></block>
  <block id="2c14caaf080b9d4ff53b1e0d7364a348" category="paragraph">이 기술 보고서의 후반부에 포함된 일부 사용 사례는 Jenkins에서 입증되었지만, 조직이 자체 관행으로 구현한 어떤 툴에도 기본 CI/CD 원칙을 적용할 수 있습니다.</block>
  <block id="af41549605744cf23f27cbc14458bf82" category="section-title">코드로서의 인프라</block>
  <block id="3e9f73de1e8a89473ea5df8ed9ad7651" category="paragraph">코드로서의 인프라는 자동화된 명령, API 및 SDK(소프트웨어 개발 키트)를 통해 IT 리소스를 프로비저닝하고 관리하는 데 도움이 됩니다. 이 개념은 개발자가 목표를 달성하는 데 방해가 될 수 있는 물리적 데이터 센터 또는 리소스 한계를 제거하여 DevOps 경험을 크게 개선합니다.</block>
  <block id="9b2cf15c50955773c7604b77322b057e" category="image-alt">인프라 코드 이미지</block>
  <block id="a7f5f35426b927411fc9231b56382173" category="inline-link">파이썬</block>
  <block id="d51d5ee15f404c2f4f7863bebcde1fac" category="inline-link">Ansible</block>
  <block id="14590850b4107a6f92feb1af739b82eb" category="inline-link">인형</block>
  <block id="10feac82bf81358ba2b3681989464290" category="paragraph">최종 사용자는 와 같은 프로그래밍 언어를 사용하는 경우가 많습니다<block ref="11022d613ff738bd6763caad4acd7f7e" category="inline-link-rx"></block> 또는 등의 자동화 툴을 사용할 수 있습니다<block ref="9790ec336069075a6bee003fe52e73bb" category="inline-link-rx"></block> 또는<block ref="82158671408fe4876cefcfa78b9fd777" category="inline-link-rx"></block> 필요할 때 개발자가 호출할 수 있는 자동화되고 반복 가능한 인프라 확장 작업을 생성합니다.</block>
  <block id="25d4b1e166882d63d2b4f8c8919a7513" category="paragraph">NetApp ONTAP 및 Astra Control에는 퍼블릭 API와 Ansible 모듈 또는 소프트웨어 개발 툴킷이 포함되어 있어 운영 자동화를 매우 쉽게 채택하고 DevOps 프로세스에 통합할 수 있습니다.</block>
  <block id="137a72e2db1a693e6a6d286f154ddc67" category="inline-link-macro">다음은 NetApp 스토리지 시스템 개요입니다.</block>
  <block id="436a9385e01c8134ffa76de0039b69e9" category="paragraph"><block ref="436a9385e01c8134ffa76de0039b69e9" category="inline-link-macro-rx"></block></block>
  <block id="72a943bda30daac28d5a7097897df424" category="summary">NetApp은 컨테이너 기반 환경에서 영구 데이터를 오케스트레이션하고 관리하는 데 도움이 되는 다양한 제품을 제공합니다.</block>
  <block id="d9ac8f9dec3643254ee6240ba67244f5" category="list-text"><block ref="d9ac8f9dec3643254ee6240ba67244f5" category="inline-link-macro-rx"></block></block>
  <block id="dd2387c2fbbd7ec35d40da2a116c5349" category="list-text"><block ref="dd2387c2fbbd7ec35d40da2a116c5349" category="inline-link-macro-rx"></block></block>
  <block id="0218e43406cb3e0a01af575972d39479" category="inline-link-macro">다음: 사용 사례 검증: NetApp Astra를 사용한 DevOps</block>
  <block id="138b9ec9c8120fa5dbf98537df5269d4" category="paragraph"><block ref="138b9ec9c8120fa5dbf98537df5269d4" category="inline-link-macro-rx"></block></block>
  <block id="ae5d1fe148e47e375a2109cb3f29045a" category="paragraph">설명서를 참조하십시오 <block ref="a57add0d538360cd0adbee43a89f028d" category="inline-link-macro-rx"></block> Astra Trident를 설치하고 사용하려면 다음을 수행합니다.</block>
  <block id="dc51ad14ee45a258aa1e6606251cf967" category="doc">비디오 및 데모: NetApp Astra를 사용한 DevOps</block>
  <block id="cd70acb1d118792e37e49b5dc15142ad" category="paragraph">다음 비디오에서는 이 문서에 설명된 몇 가지 기능을 설명합니다.</block>
  <block id="47a3fe612643a48831699e345fc50086" category="inline-link-macro">비디오: Astra Control을 통해 CI/CD 파이프라인에서 데이터 보호를 통합합니다</block>
  <block id="b137de00495bfd71913e4fe2ecc2fbb5" category="list-text"><block ref="b137de00495bfd71913e4fe2ecc2fbb5" category="inline-link-macro-rx"></block></block>
  <block id="11a855b91bda336c24ae0014cf0b01aa" category="list-text"><block ref="11a855b91bda336c24ae0014cf0b01aa" category="inline-link-macro-rx"></block></block>
  <block id="760ebcab0161b35f2cbcee21a65a788a" category="list-text"><block ref="760ebcab0161b35f2cbcee21a65a788a" category="inline-link-macro-rx"></block></block>
  <block id="c6b924f851b08c850fe2e53f34ada256" category="doc">NetApp FlexClone 기술을 사용하여 소프트웨어 개발 가속화</block>
  <block id="e071982902994eb194aeef35d4e7d131" category="paragraph">Kubernetes 클러스터에 배포된 애플리케이션을 클론 복제하는 것은 현재 작업 중인 버전에 영향을 주지 않고 환경을 파트너와 공유하거나 개발 환경에서 새 버전의 코드를 테스트하여 워크플로우를 가속화하려는 개발자에게 매우 유용한 툴입니다. Kubernetes 애플리케이션의 상태 저장 및 애플리케이션 정합성이 보장되는 클론 복제는 NetApp Astra Control에 포함된 주요 기능이며, 애플리케이션의 백업 및 복원 기능도 제공합니다. 이와 더불어, 동일한 스토리지 백엔드를 사용하여 동일한 Kubernetes 클러스터 내에 애플리케이션을 클론 복제하면 Astra Control은 기본적으로 NetApp FlexClone 기술을 사용하여 영구 데이터 볼륨을 복제하므로 프로세스의 속도를 크게 높일 수 있습니다. 이 프로세스를 가속화하면 복제된 환경이 프로비저닝되고 몇 분 만에 사용할 수 있으므로 개발자가 테스트 또는 개발 환경을 다시 배포하는 데 비해 잠시 멈춰 작업을 다시 시작할 수 있습니다. 편의를 위해 NetApp Astra Control에서 제공되는 모든 기능을 API로 호출할 수 있으며, 이 API를 통해 Ansible과 같은 자동화 프레임워크와 쉽게 통합할 수 있습니다. 따라서 복제 절차를 시작하기 위해 플레이북이나 역할에서 약간의 변경만 필요하기 때문에 환경을 훨씬 빠르게 스테이징할 수 있습니다.</block>
  <block id="130a289acaa6c63f08a152e232264781" category="section-title">NetApp FlexClone 기술이란 무엇입니까?</block>
  <block id="de7fc3e1378f3d66008013e37abfc654" category="paragraph">NetApp FlexClone 기술은 NetApp FlexVol의 쓰기 가능한 시점 스냅샷 기반 복사본입니다. 이러한 데이터는 거의 즉각적으로 프로비저닝되고 소스 볼륨의 모든 데이터를 포함하며 새 볼륨의 데이터가 소스에서 전환되기 전까지 추가 스토리지 공간을 사용하지 않습니다. 여러 데이터 복사본이 스테이징 목적으로 유용하고 스토리지 시스템에 이러한 볼륨 프로비저닝을 위한 리소스가 제한적인 경우, 이러한 리소스는 개발 또는 템플릿 기반 환경에서 주로 사용됩니다. 데이터를 여러 번 복사해야 하는 기존 스토리지 시스템과 비교하여 상당한 스토리지 공간과 시간을 소모하는 NetApp FlexClone 기술은 스토리지에 따른 작업을 가속화합니다.</block>
  <block id="66b43b8d36a821005edbb505f73e703f" category="image-alt">FlexClone 이미지</block>
  <block id="b9ca5ba97cf75d3dafb51f78e073770a" category="inline-link">NetApp 문서</block>
  <block id="b9c059adc88329f807d19beff36c402c" category="paragraph">NetApp FlexClone 기술에 대한 자세한 내용은 의 페이지를 참조하십시오<block ref="26a4454b15f9e59c91953aae4d5cca61" category="inline-link-rx"></block>.</block>
  <block id="c2bdd689dbc313e32552cbc9e519673e" category="list-text">Red Hat OpenShift 4.6.8+, Rancher 2.5+ 또는 Kubernetes 1.19+와 같은 지원되는 Kubernetes 배포</block>
  <block id="17909bff47021a48534aa137533988cb" category="list-text">NetApp Astra Control Center 21.12 이상</block>
  <block id="f6e864ce20ae64f2d8e8d9788960ddcb" category="list-text">NetApp Astra Trident를 통해 스토리지 백엔드가 구성된 NetApp ONTAP 시스템입니다.</block>
  <block id="02de8f49568cea93a498f8b7b321a4e4" category="list-text">Ansible 2.9 이상</block>
  <block id="0f466e306fc4825f1141ddc130ca599a" category="list-text">NetApp Astra Control에서 관리 대상 애플리케이션으로 클론 복제하려는 환경을 위한 템플릿입니다.</block>
  <block id="3e36385ca501623e48219eaf55547185" category="section-title">사용 사례 소개</block>
  <block id="c7af167d0f4082e772505e76bb547621" category="paragraph">이 사용 사례에서는 다음과 같은 워크플로를 시각화합니다.</block>
  <block id="fc1fa3a113fd483da9a2a706cef62740" category="image-alt">워크플로 이미지</block>
  <block id="3056a7af3144c13993f45fa84e78699e" category="list-text">사용자가 Ansible 플레이북을 실행하여 새로운 스테이징 환경을 구축합니다.</block>
  <block id="c48538a3317fc98bc2fa8cf73553ca0b" category="list-text">Ansible은 URI-API 모듈을 사용하여 Astra Control을 호출하여 클론 생성 작업을 실행합니다.</block>
  <block id="af27beb3ef227700c87619b941ef922d" category="list-text">Astra Control은 미리 프로비저닝된 템플릿 환경에서 클론 생성 작업을 실행하여 새로운 관리 애플리케이션을 생성합니다.</block>
  <block id="afec891492c1e0c4d92776aa8fbb7a37" category="admonition">이 환경은 개발 중인 단일 독립 실행형 애플리케이션이거나 Jenkins CI/CD 파이프라인과 같은 전체 개발 환경일 수 있습니다.</block>
  <block id="b120622a84d96b41ece4bf14a2afc42c" category="list-text">그런 다음 사용자는 Gitea와 같은 온라인 저장소에서 해당 코드의 버전을 복제된 개발 환경으로 가져옵니다.</block>
  <block id="58b9c8dff15389cfc89079bed15b0353" category="list-text">새로운 버전의 애플리케이션은 NetApp Astra Control에서 구축 및 관리합니다.</block>
  <block id="512473ae00b91f234459da9d54a73d63" category="admonition">이 두 프로세스는 모두 자동화할 수 있습니다.</block>
  <block id="45469e0108aa4b426d8e379bf3e01032" category="list-text">사용자는 이 복제 환경에서 새 코드를 개발할 수 있습니다.</block>
  <block id="290324e3d59e2f7053c0f9e9e6e0efa3" category="list-text">사용자가 개발 작업에 만족하면 코드를 호스팅된 저장소로 다시 푸시할 수 있습니다.</block>
  <block id="30d4a5dfd238538be60a29a62c199938" category="paragraph">여기서 제시하는 사용 사례는 복제할 특정 환경 또는 애플리케이션에 대한 골드 템플릿이 있는지 여부에 따라 달라집니다. 저희 환경에서는 Wordpress 배포, Magento 배포, DevTools이라는 제목의 Gitea가 있는 Jenkins CI/CD 환경 등 세 개의 템플릿을 만들었습니다.</block>
  <block id="c30f4e03a21fface6aa43659a4078d71" category="image-alt">템플릿 이미지</block>
  <block id="1107495525479f3871a68bae36a3f17b" category="paragraph">각 환경은 NetApp Astra Control을 통해 관리되며, NetApp Astra Trident가 제공하는 NFS 백엔드와 함께 NetApp ONTAP 스토리지 시스템에 현재 저장된 영구 볼륨이 있습니다.</block>
  <block id="2ba3749d66f6540154024e19b4d99cc9" category="section-title">사용 사례 검증</block>
  <block id="7a73c2eecaec86daa9aee3eff521b699" category="list-text">클론 복제 역할 및 애플리케이션 업데이트 플레이북을 포함하는 NetApp 솔루션 엔지니어링 팀에서 제공하는 Ansible 툴킷을 복제하십시오.</block>
  <block id="6264ab91acf969dcae78c1602bca2059" category="list-text">VAR/CLONE_VAR.Lyml을 편집하여 Astra Control 환경에 맞는 글로벌 가치를 입력합니다.</block>
  <block id="240e34a15ccbba0aea72efc21aaab86d" category="admonition">입력해야 하는 글로벌 환경 값은 API 액세스 메뉴 아래의 NetApp Astra Control의 사용자 프로필 아이콘 아래에서 확인할 수 있습니다.</block>
  <block id="f35821a1d6caaf6d90163620f4ea7458" category="image-alt">API 액세스 이미지</block>
  <block id="25037aa69bc75f53a1077e99016fcb35" category="list-text">글로벌 변수가 완료된 경우 복제할 특정 애플리케이션의 값을 선택할 수 있습니다. devtools 환경을 Alan-devtools라고 하는 개인 환경으로 복제하려면 다음을 수행합니다.</block>
  <block id="3c88bcd7ff9904c39c203d75df0f43aa" category="admonition">클론 복제 프로세스에서 NetApp FlexClone 기술을 활용하려면 'rc-cluster'와 'dest-cluster'가 동일해야 합니다.</block>
  <block id="7701b76fd4e9f02523bba989b59e089f" category="list-text">이제 플레이북을 실행하여 애플리케이션을 복제할 수 있습니다.</block>
  <block id="b843fd904e687b09c9fea5652dd26835" category="admonition">기록된 Playbook은 루트 사용자 또는 sudo 프로세스를 통해 "-K" 인수를 전달하여 에스컬레이션할 수 있는 사람이 실행해야 합니다.</block>
  <block id="47261a281b6d461c0e208fcdd564b6ef" category="list-text">Playbook의 실행이 완료되면 복제된 애플리케이션이 Astra Control Center 콘솔에서 사용 가능한 것으로 표시됩니다.</block>
  <block id="4ebfaaa8ab1aa4f1a8e1f0e4c080a066" category="image-alt">복제된 앱 이미지</block>
  <block id="d7d808da7950a8d4bece269105013664" category="list-text">그런 다음, 사용자가 애플리케이션이 배포된 Kubernetes 환경에 로그인하여 애플리케이션이 새 IP 주소로 표시되는지 확인하고 개발 작업을 시작할 수 있습니다.</block>
  <block id="ba87075b7677acd5c3798c45d5899095" category="paragraph">이 사용 사례 데모와 응용 프로그램 업그레이드 예제는 를 참조하십시오 <block ref="c3446aeb84c085acd211fbde68c1be91" category="inline-link-macro-rx"></block>.</block>
  <block id="a7f77f303480f7b7143a247c228eaebb" category="doc">Astra Control과 NetApp FlexClone 기술을 사용하여 소프트웨어 개발을 가속화하십시오</block>
  <block id="2f1df67ff878abb3db18e3010bcc2920" category="paragraph">DevOps 워크플로우의 가장 일반적인 용도 중 하나는 지속적인 통합 및 CI/CD(Continuous Deployment) 파이프라인으로서, 개발자가 새로운 코드를 커밋할 때 애플리케이션에서 자동화된 테스트 제품군을 구축, 통합 및 실행합니다. DevOps 엔지니어 및 SRE(Site-Reliability Engineer)에는 일반적으로 개발 프로세스에서 새로운 기능 개발, 회귀 테스트, 버그 수정, 품질 엔지니어링 및 기타 기능을 위해 다양한 워크플로우 전용 파이프라인이 있습니다.</block>
  <block id="1413f73ce604910297e839d41a24e9f9" category="paragraph">팀의 자동화 수준이 높아짐에 따라 운영 중인 애플리케이션의 변화 속도가 압도적으로 느껴질 수 있습니다. 따라서 일부 팀은 운영 중인 애플리케이션 또는 서비스를 보호하고자 합니다. 코드 및 컨테이너 이미지를 보호할 뿐 아니라 애플리케이션 상태, 구성 데이터(예: Kubernetes 객체 및 애플리케이션과 관련된 리소스), 애플리케이션의 영구 데이터도 보호하려고 합니다.</block>
  <block id="8322f060ae0335cf0232ac3b55da6556" category="paragraph">이 사용 사례에서는 새로운 버전의 애플리케이션을 배포하는 프로모션-운영 파이프라인을 먼저 스테이징 환경에 구축한 다음 운영 환경에 구축하는 방법을 자세히 살펴보겠습니다. 이 예는 주요 퍼블릭 클라우드 및 온프레미스 환경에도 동일하게 적용됩니다. 앱 버전 중 하나의 배포를 보여주지만 파란색/녹색 또는 카나리아 배포와 같은 다른 전략에서도 파이프라인을 사용할 수 있습니다. CI/CD 파이프라인의 일부로 전체 애플리케이션 백업을 생성하여 애플리케이션을 보호합니다. 운영 중인 애플리케이션과 데이터, 상태, 구성을 애플리케이션 인식형 백업으로 여러 DevOps 워크플로우에 유용하게 사용할 수 있습니다.</block>
  <block id="13c258a59936aa47a4215b1c02921c7d" category="image-alt">NetApp Astra 활용 사례 1 아키텍처를 사용한 DevOps</block>
  <block id="fcd7f001e9274fdefb14bff91c799306" category="inline-link">마멘토</block>
  <block id="0e8625d3981b9d26e0866da357d318c8" category="inline-link">NetApp Astra Control Python SDK</block>
  <block id="e5c0235557a0821c530e70a6ac76e817" category="paragraph">이 사용 사례를 검증하는 데 사용된 애플리케이션은 입니다<block ref="ca8bdc27f15f815590190c112abb55a0" category="inline-link-rx"></block>웹 기반 프런트 엔드를 사용하는 전자 상거래 솔루션, 검색 및 분석 기능을 위한 Elasticsearch 인스턴스, 모든 쇼핑 인벤토리 및 트랜잭션 세부 정보를 추적하는 MariaDB 데이터베이스 이 컨테이너형 애플리케이션은 Red Hat OpenShift 클러스터에 설치되었습니다. 애플리케이션의 모든 Pod에서 영구 볼륨을 사용하여 데이터를 저장했습니다. 영구 볼륨은 NetApp 스토리지 시스템에서 스토리지를 프로비저닝할 수 있는 Kubernetes용 컨테이너 스토리지 인터페이스 호환 스토리지 오케스트레이터인 NetApp Astra Trident에 의해 자동으로 생성되었습니다. 또한 Astra Control Center의 애플리케이션 보호 기능을 활용하기 위해 해당 애플리케이션을 Astra Control에서 관리했으며, 이 애플리케이션을 사용하여 애플리케이션의 상태를 영구 볼륨에 저장된 데이터와 함께 저장하는 애플리케이션 백업을 트리거했습니다. 을 사용했습니다<block ref="d0b4b6e44937c3a38c218d58868f48cf" category="inline-link-rx"></block> 애플리케이션 백업을 트리거하는 프로세스를 자동화하기 위해 CI/CD 파이프라인에 도입되었습니다. 이 파이프라인은 이라는 인기 있는 CI/CD 툴을 사용하여 생성 및 실행되었습니다 <block ref="2362760839a75356cff2ce591e8175c5" category="inline-link-rx"></block>] 응용 프로그램을 빌드, 보호 및 배포하기 위한 흐름을 자동화합니다.</block>
  <block id="be6d35c56a8d9c9eda054648f5aaf778" category="paragraph">CI/CD 파이프라인에 보호를 도입하기 위한 사전 요구 사항과 절차를 살펴보겠습니다.</block>
  <block id="019b3399490601533f0c22df26617506" category="list-text">NetApp ONTAP 시스템에 백엔드가 구성된 OpenShift에 설치된 NetApp Astra Trident</block>
  <block id="32714d2e851023befd52d2dafcb3df12" category="list-text">NetApp ONTAP 백엔드를 가리키는 기본 스토리지 클래스 구성</block>
  <block id="4feccdee8cd5d15c137a63228c1e8035" category="list-text">OpenShift 클러스터에 설치된 NetApp Astra Control Center</block>
  <block id="89a7002b85e3c07334367a744cb41016" category="list-text">OpenShift 클러스터가 Astra Control Center에 관리 클러스터로 추가되었습니다</block>
  <block id="f485827022df06c2991a88b97eeb4e48" category="list-text">Jenkins는 OpenShift 클러스터에 설치되며 Docker 엔진이 설치된 에이전트 노드로 구성됩니다</block>
  <block id="e6b72ced375884adc1f139800a859ef1" category="section-title">응용 프로그램을 설치하는 중입니다</block>
  <block id="cd03481692ef65344c4dd7bf363bc056" category="paragraph">스테이징 및 운영 환경에 애플리케이션을 처음 설치하는 것부터 시작하겠습니다. 이 활용 사례의 경우 이 단계가 선행 조건이므로 수동으로 수행됩니다. CI/CD 파이프라인은 이후 애플리케이션의 새 버전 릴리스에 따라 워크플로우를 구축하고 배포하는 데 사용됩니다.</block>
  <block id="2ee68ca17059fe4d4ab06d0230bed0c3" category="paragraph">이 활용 사례의 생산 환경은 '마젠토-프로드'라는 네임스페이스이며, 해당 스테이징 환경은 Red Hat OpenShift 클러스터에 구성된 '마젠토-스테이징'이라는 네임스페이스입니다. 응용 프로그램을 설치하려면 다음 단계를 수행하십시오.</block>
  <block id="05586ccfd2c7dbe7b3226b21240add7c" category="list-text">프로덕션 환경에 bitnami Helm 차트를 사용하여 Magento 응용 프로그램을 설치합니다. Magento 및 MariaDB Pod용 rwx PVS를 사용합니다.</block>
  <block id="14224ce39d8587f380c4b992c668c24d" category="admonition">Magento bitnami Helm 차트에는 Magento GUI 서비스를 제공하기 위해 로드 밸런서 서비스가 필요합니다. 우리는 중고 <block ref="6beef47e42ff9b3760535f361acb6931" category="inline-link-macro-rx"></block> 이 예에서는 온프레미스 로드 밸런서 서비스를 제공합니다.</block>
  <block id="4750ba228d6f73ce1e9d9e27f0cd2ca5" category="list-text">몇 분 후 모든 Pod 및 서비스가 실행되고 있는지 확인합니다.</block>
  <block id="3a0715e577e143188e1e748efe2fca27" category="list-text">스테이징 환경에 대해서도 동일한 절차를 반복합니다.</block>
  <block id="e684201cc94f2e04edf2353711b58fe5" category="section-title">Astra Control Center에서 Magento 응용 프로그램을 관리합니다</block>
  <block id="e9758d5e82771fcca93395ce3a7c1d40" category="list-text">응용 프로그램 으로 이동하고 검색된 응용 프로그램 탭을 선택합니다.</block>
  <block id="082833c45c4a99b63cbf53365495e0d2" category="list-text">제작 환경('magento-prod')에서 Magento 응용 프로그램에 대한 줄임표를 클릭하고 관리를 클릭합니다.</block>
  <block id="28a12dc4e9b29cb97bfaf36914e9983a" category="list-text">이제 Magento 응용 프로그램은 Astra Control Center에서 관리합니다. Astra Control에서 지원하는 모든 작업은 애플리케이션에서 수행할 수 있습니다. 응용 프로그램 버전도 확인합니다.</block>
  <block id="4ef629c07108e88861fc4036780e9a1f" category="image-alt">업그레이드 전에 Magento 버전 확인</block>
  <block id="c03f75891d5e0356b60d3752df0f0444" category="list-text">스테이징 환경에서 Magento 응용 프로그램을 관리하는 단계를 반복합니다('magento-staging').</block>
  <block id="881e2f21543c210893e098f6383f4199" category="section-title">통합 보호를 갖춘 CI/CD 파이프라인</block>
  <block id="841e01ce1d424839fd87eed89e1ce154" category="paragraph">새로운 버전의 애플리케이션을 사용할 때는 CI/CD 파이프라인을 사용하여 컨테이너 이미지를 구축하고, 스테이징 및 운영 환경의 백업을 수행하고, 새로운 버전의 애플리케이션을 스테이징 환경에 구축하고, 프로덕션으로 승격할 승인을 기다립니다. 그런 다음 운영 환경에 새 버전의 애플리케이션을 배포합니다. CI/CD 파이프라인을 사용하려면 다음 단계를 완료하십시오.</block>
  <block id="88ba71f9d62d24eeb2decfe9cd30cfb1" category="list-text">Jenkins에 로그인하여 필요한 자격 증명을 생성합니다. 하나는 Magento 크레드이고, 하나는 MariaDB 관리자 크레드이고, 다른 하나는 MariaDB 루트 크레드입니다.</block>
  <block id="9743ff34b00bc2d03fdc0b6ee11b0781" category="list-text">Manage Jenkins &gt; Manage Credentials로 이동한 후 해당 도메인을 클릭합니다.</block>
  <block id="5efc31d04501ec1bfbc5b2e785ac7cc2" category="list-text">자격 증명 추가 를 클릭하고 종류를 암호 및 범위가 전역으로 설정된 사용자 이름으로 설정합니다. 자격 증명의 사용자 이름, 암호 및 ID를 입력하고 확인 을 클릭합니다.</block>
  <block id="5ff08be42358b0ed5a5235096ccfa397" category="image-alt">자격 증명을 생성합니다</block>
  <block id="ef7b482a4875dec8ec53a6a7ecea081b" category="list-text">다른 두 자격 증명에도 같은 절차를 반복합니다.</block>
  <block id="955b68bae8db1bc3b2abbf6ada3710be" category="list-text">대시보드로 돌아가서 새 항목을 클릭하여 파이프라인을 생성한 다음 파이프라인을 클릭합니다.</block>
  <block id="027f0bd54326a6b14e6c7daf65d07f5c" category="list-text">Jenkinsfile에서 파이프라인을 복사합니다<block ref="94d69998dfd97a76d20ae02a64c629ae" category="inline-link-rx"></block>.</block>
  <block id="843730ff8981a034040c0f42fdaa48ce" category="list-text">Helm 차트 버전, 업그레이드할 Magento 응용 프로그램 버전, Astra 도구 키트 버전, Astra Control Center FQDN, API 토큰 및 인스턴스 ID를 포함한 각 세부 정보로 Jenkins 파이프라인의 매개 변수를 채웁니다. 운영 및 스테이징 환경 모두의 Docker 레지스트리, 네임스페이스 및 Magento IP를 지정하고 생성된 자격 증명의 자격 증명 ID도 지정합니다.</block>
  <block id="3f52d6cbc878f43533503f2bd5a61952" category="list-text">지금 구축을 클릭합니다. 파이프라인은 실행을 시작하고 단계를 진행합니다. 응용 프로그램 이미지는 먼저 빌드되어 컨테이너 레지스트리에 업로드됩니다.</block>
  <block id="059d6fb9b965d0897c20fb2482659279" category="image-alt">파이프라인 진행 상황</block>
  <block id="ed2c1f4dfcf187d5140cf31e58801b4f" category="list-text">애플리케이션 백업은 Astra Control을 통해 시작됩니다.</block>
  <block id="633d66eb7984b86ee4487b6a10ffc34a" category="image-alt">백업이 시작되었습니다</block>
  <block id="75b0ba1236c133f891fdd36b2e3913f3" category="list-text">백업 단계가 성공적으로 완료된 후 Astra Control Center에서 백업을 확인합니다.</block>
  <block id="2b3a33094c5c31ac6cc6be770417a07c" category="image-alt">백업이 완료되었습니다</block>
  <block id="fec272abe380f3502ef64cbc2cc652bf" category="list-text">그런 다음 새 버전의 응용 프로그램이 스테이징 환경에 배포됩니다.</block>
  <block id="4576032c05f55b22a040f067151cde6f" category="image-alt">스테이징 배포가 시작되었습니다</block>
  <block id="4d4659ee9b2600243399d4aceca7c670" category="list-text">이 단계가 완료된 후 프로그램은 사용자가 프로덕션에 대한 배포를 승인하기를 기다립니다. 이 단계에서는 QA 팀이 일부 수동 테스트를 수행하고 생산을 승인한다고 가정합니다. 그런 다음 Approve(승인) 를 클릭하여 새 버전의 애플리케이션을 프로덕션 환경에 배포할 수 있습니다.</block>
  <block id="e30db45e8514d0d8f662187e28b8b5ec" category="image-alt">프로모션을 기다리는 중입니다</block>
  <block id="3a7b15850615e9fd306b379f77e0e016" category="list-text">운영 애플리케이션도 원하는 버전으로 업그레이드되었는지 확인합니다.</block>
  <block id="f11253856e2b859c46731353f46b732e" category="image-alt">프로덕션 앱이 업그레이드되었습니다</block>
  <block id="70817285f3f68722fd851dde7464feb2" category="paragraph">CI/CD 파이프라인의 일부로, 전체 애플리케이션 인식 백업을 생성하여 애플리케이션을 보호하는 기능을 입증했습니다. 전체 애플리케이션이 프로모션-운영 파이프라인의 일부로 백업되었으므로 고도로 자동화된 애플리케이션 구축에 대해 더욱 확신을 가질 수 있습니다. 애플리케이션의 데이터, 상태 및 구성을 포함하는 이 애플리케이션 인식 백업은 여러 DevOps 워크플로우에 유용할 수 있습니다. 중요한 워크플로 중 하나는 예상치 못한 문제가 발생할 경우 이전 버전의 응용 프로그램으로 롤백하는 것입니다.</block>
  <block id="94ec4ad32f9ba408876eabf1a42f6901" category="paragraph">Jenkins 툴을 사용하여 CI/CD 워크플로우를 시연했지만, 이 개념은 여러 도구와 전략에 대해 쉽고 효율적으로 추론할 수 있습니다. 이 사용 사례를 실제 작동 중인 경우 비디오를 시청하십시오 <block ref="2eda593691b1da530fed5bfcba32a663" category="inline-link-macro-rx"></block>.</block>
  <block id="b36bddb7c9d9a83be2a0353a3a744767" category="paragraph">NetApp은 컨테이너화된 애플리케이션을 위해 데이터를 프로비저닝, 보호 및 관리할 수 있는 Astra Trident 및 Astra Control과 함께 자격이 있는 여러 스토리지 플랫폼을 제공합니다.</block>
  <block id="963b3936c1baa510ebca7a5496ece873" category="paragraph">NetApp은 상태 저장 컨테이너 애플리케이션 및 데이터의 오케스트레이션, 관리, 보호 및 마이그레이션을 지원하는 다양한 제품을 제공합니다.</block>
  <block id="8a52e85b93902c27be7f0b5fa8493e52" category="paragraph">NetApp Astra Control은 NetApp 데이터 보호 기술을 기반으로 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공합니다. Astra Control Service는 클라우드 네이티브 Kubernetes 구축에서 상태 저장 워크로드를 지원할 수 있습니다. Astra Control Center는 {k8s_distribution_name}과 같은 엔터프라이즈 Kubernetes 플랫폼의 온프레미스 구축에서 상태 저장 워크로드를 지원할 수 있습니다. 자세한 내용은 NetApp Astra Control 웹 사이트를 참조하십시오<block ref="508f471fa59796a53754f031c40091c1" category="inline-link-rx"></block>.</block>
  <block id="6026755482efeb14efb7399db02c4e5e" category="paragraph">Astra Trident는 컨테이너 및 Kubernetes 배포용 {k8s_distribution_name}의 오픈 소스 및 완전 지원 스토리지 오케스트레이터입니다. Trident는 NetApp ONTAP 및 Element 스토리지 시스템을 포함한 전체 NetApp 스토리지 포트폴리오와 연동되며 NFS 및 iSCSI 연결도 지원합니다. Trident는 최종 사용자가 스토리지 관리자의 개입 없이 NetApp 스토리지 시스템에서 스토리지를 프로비저닝 및 관리할 수 있도록 하여 DevOps 워크플로우를 가속합니다.</block>
  <block id="0e60ae06a3d7bec5f8950d8ea76b57d4" category="paragraph">Astra Trident의 최신 버전은 2022년 4월 22.04입니다. Kubernetes 배포를 찾을 수 있는 Trident의 버전에 대한 지원 매트릭스입니다<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="b453397e87e54278a4cd32ac644d5934" category="sidebar">파트너 솔루션 정보</block>
  <block id="ff94fd25dea669a1eb9fc9bad5af5e80" category="sidebar">Red Hat OpenShift 웹 사이트</block>
  <block id="8cf2142329e586b4350d53a76071db82" category="sidebar">Anthos 웹 사이트</block>
  <block id="a5860a0f10641c9e31f8301d3f3ae548" category="sidebar">컨테이너를 위한 리소스</block>
  <block id="e2ed9dce9d5bb40e79fc6d3008de22ff" category="sidebar">NetApp의 Anthos</block>
  <block id="500ce409f120039287d7670f42ff1821" category="sidebar">NetApp을 통한 DevOps</block>
  <block id="59b5f97219239806c778ffff9bda8ad0" category="sidebar">사용 사례 검증</block>
  <block id="1a4f47ee7c7d8b59e68be952ac121268" category="sidebar">Anthos를 위한 고급 구성 옵션</block>
  <block id="b0ed101b405f642695988c7ef3313b52" category="sidebar">아카이빙 솔루션</block>
  <block id="9eb662185982de390339607d2ee459a4" category="summary">Google Cloud의 Cloud Volumes Service는 기본적으로 데이터를 보호할 수 있는 다양한 방법을 제공합니다.</block>
  <block id="52aa20c1efa9dfeda78d72f4c056c23f" category="doc">Google Cloud의 Cloud Volumes Service로 데이터를 보호하는 방법</block>
  <block id="c0db72d078098472051229dbdb83118e" category="inline-link-macro">이전: 개요.</block>
  <block id="78dad9c3bba77d55493b24502dbe6a1d" category="paragraph"><block ref="78dad9c3bba77d55493b24502dbe6a1d" category="inline-link-macro-rx"></block></block>
  <block id="9967209a1408f78f781d93dd0cdf88c4" category="section-title">안전한 아키텍처 및 테넌시 모델</block>
  <block id="9ba9e0f1cce71f64d3188bfdc502a43d" category="inline-link-macro">“Cloud Volumes Service 아키텍처”</block>
  <block id="33186704f78f73f32736a9ba7f8ddc85" category="inline-link">프라이빗 서비스 액세스</block>
  <block id="5971da0242ce7b616ff2972978613cef" category="inline-link-macro">"임차 모델"</block>
  <block id="01760cb04e3a4a93404ab2c878b036db" category="inline-link-macro">“공유 VPC”</block>
  <block id="e70da8f06ec706ed45906f411481eda0" category="paragraph">이 아키텍처에서 테넌트는 섹션을 참조하십시오 <block ref="0a088dd892133b6a77304655c2b8b829" category="inline-link-macro-rx"></block>)는 사용자가 명시적으로 연결하지 않는 한 서로 완전히 격리된 Google Cloud 프로젝트로 정의됩니다. 테넌트를 통해 Cloud Volumes Service 볼륨 플랫폼을 사용하는 다른 테넌트에서 데이터 볼륨, 외부 이름 서비스 및 기타 필수 요소를 완벽하게 격리할 수 있습니다. Cloud Volumes Service 플랫폼은 VPC 피어링을 통해 연결되므로 이러한 격리가 적용됩니다. 공유 VPC를 사용하여 여러 프로젝트 간에 Cloud Volumes Service 볼륨을 공유할 수 있습니다(섹션 참조) <block ref="c2426c8c5bcdce9adb82a8906c5a3478" category="inline-link-macro-rx"></block>)를 클릭합니다. SMB 공유 및 NFS 내보내기에 액세스 제어를 적용하여 데이터 세트를 보거나 수정할 수 있는 사용자 또는 항목을 제한할 수 있습니다.</block>
  <block id="35a0e1620a03f33da8739635aaa3b607" category="section-title">컨트롤 플레인을 위한 강력한 ID 관리</block>
  <block id="4504de40d15959838801111af31d224e" category="inline-link">IAM(Identity Access Management)</block>
  <block id="d242c9a4fc4e118d87391841845ef44b" category="paragraph">Cloud Volumes Service 구성이 수행되는 컨트롤 플레인에서 을 사용하여 ID 관리를 관리합니다<block ref="490163f8d94b8a8397824811fb91c5ec" category="inline-link-rx"></block>. IAM은 Google Cloud 프로젝트 인스턴스에 대한 인증(로그인) 및 권한 부여(권한)를 제어할 수 있는 표준 서비스입니다. 모든 구성은 TLS 1.2 암호화를 사용하는 보안 HTTPS 전송을 통해 Cloud Volumes Service API로 수행되며, 보안을 강화하기 위해 JWT 토큰을 사용하여 인증이 수행됩니다. Cloud Volumes Service용 Google 콘솔 UI는 사용자 입력을 Cloud Volumes Service API 호출로 변환합니다.</block>
  <block id="688247a9da881160b1073a4b76442640" category="section-title">보안 강화 - 공격 표면 제한</block>
  <block id="4901056002c8d64da3b67da6a5a2dbbb" category="paragraph">효과적인 보안 기능 중 일부는 서비스에서 사용할 수 있는 공격 표면의 수를 제한하고 있습니다. 공격 표면에는 유휴 데이터, 전송 중 데이터 전송, 로그인 및 데이터 세트 자체를 비롯한 다양한 사항이 포함될 수 있습니다.</block>
  <block id="733e720a346376b07eb9adac497c4063" category="inline-link-macro">“서비스 운영,”</block>
  <block id="aa6187208cb06e0a43851ee1783a370c" category="paragraph">관리되는 서비스는 기본적으로 설계의 일부 공격 표면을 제거합니다. 섹션에 설명된 대로 인프라스트럭처 관리 <block ref="ddbc8ce5f4099ff7254959018f566688" category="inline-link-macro-rx"></block> 전담 팀에 의해 처리되고, 사람이 실제로 구성에 접촉하는 횟수를 줄이기 위해 자동화되어 의도적이거나 의도하지 않은 오류의 수를 줄입니다. 필요한 서비스만 서로 액세스할 수 있도록 네트워킹이 차단되었습니다. 암호화는 데이터 저장소에 저장되며 데이터 플레인에 대해서만 Cloud Volumes Service 관리자의 보안 주의가 필요합니다. API 인터페이스 뒤에 대부분의 관리 기능을 숨기면 공격 표면을 제한하여 보안을 달성할 수 있습니다.</block>
  <block id="d8d81a048343e815b76f916e1c58e636" category="section-title">제로 트러스트 모델</block>
  <block id="d2c4e1022fc22d0780bd913d3f16498e" category="paragraph">역사적으로 IT 보안 철학은 위협을 완화하기 위해 외부 메커니즘(예: 방화벽 및 침입 탐지 시스템)에만 의존하는 것으로 확인되고 검증해야 했습니다. 그러나 피싱, 사회 공학, 내부자 위협 및 네트워크에 침입하고 파괴를 초래할 수 있는 확인 기능을 제공하는 기타 방법을 통해 환경의 확인을 우회하기 위해 공격과 침해가 진화했습니다.</block>
  <block id="853f80d22a64d4fff24c05d305e800a8" category="paragraph">제로 트러스트는 "모든 것을 검증하면서 아무것도 신뢰하지 않는다"라는 현재의 원칙을 바탕으로 보안 측면에서 새로운 방식이 되었습니다. 따라서 기본적으로 액세스가 허용되지 않습니다. 표준 방화벽, 침입 탐지 시스템(IDS)을 비롯한 다양한 방법과 다음과 같은 방법을 바탕으로 이러한 원칙을 적용합니다.</block>
  <block id="d07f4106373448c16aedf0c01749e560" category="list-text">강력한 인증 방법(예: AES 암호화 Kerberos 또는 JWT 토큰)</block>
  <block id="4bbee6cac6b31b494ade66a9fc2f16e7" category="list-text">강력한 단일 ID 소스(예: Windows Active Directory, LDAP(Lightweight Directory Access Protocol) 및 Google IAM)</block>
  <block id="da31693a70531052458cd4eff104672d" category="list-text">네트워크 세분화 및 보안 멀티 테넌시(테넌트만 기본적으로 액세스 허용)</block>
  <block id="a8ce5780cff146b27ae2c2b3fddc0447" category="list-text">최소 권한 액세스 정책을 통한 세분화된 액세스 제어</block>
  <block id="493f70c348ea51d5c7cb8a28593df5a1" category="list-text">디지털 감사 및 종이 추적을 지원하는 신뢰할 수 있는 전담 관리자의 소규모 독점 목록</block>
  <block id="fd5070ec3e2f12398e4de9b77b900cbf" category="paragraph">Google Cloud에서 실행되는 Cloud Volumes Service는 "신뢰, 모든 것을 확인"하는 입장을 구현하여 제로 트러스트 모델을 고수합니다.</block>
  <block id="d7f2615c71a1567cc13cf3a7f7de0aea" category="section-title">암호화</block>
  <block id="83c3a5400dd4f14665a803a22add4a9d" category="inline-link-macro">“저장된 데이터 암호화”</block>
  <block id="a37154afafe65368d5170741a4669261" category="inline-link-macro">"SMB 암호화"</block>
  <block id="e688fd1eb8866f914263d3493c30ccbb" category="inline-link-macro">“지역 간 복제”</block>
  <block id="c05431edaaaefc20b48a7cd96f110e5d" category="inline-link-macro">“전송 중인 데이터 암호화”</block>
  <block id="48aa29a35d8e13e796333876f4ea9f62" category="inline-link-macro">"Google Cloud 네트워크"</block>
  <block id="31d64d3cd8b2a692701b32dd6a611c76" category="paragraph">유휴 데이터 암호화(섹션 참조 <block ref="ce3046d8bb0cfdf8a89295f31068c29b" category="inline-link-macro-rx"></block>) XTS-AES-256 암호를 NetApp Volume Encryption(NVE)과 함께 사용하고 를 사용하여 전송 중입니다 <block ref="9963d74c8d0d381d9818a5c550dd7163" category="inline-link-macro-rx"></block> 또는 NFS Kerberos 5p를 지원합니다. TLS 1.2 암호화로 지역 간 복제 전송이 보호되므로 안심하십시오(섹션 참조) <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>)를 클릭합니다. 또한 Google 네트워킹은 암호화된 통신도 제공합니다(섹션 참조) <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block>)를 사용하여 공격에 대한 보호 계층을 추가합니다. 전송 암호화에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="0e3bb83173de6418179f08aaa25b48dd" category="inline-link-macro-rx"></block>.</block>
  <block id="db57ea7882be0cb73c78bf1ba25a6823" category="section-title">데이터 보호 및 백업</block>
  <block id="48b5832efbf50440742eee7bfd02733b" category="inline-link-macro">Cloud Volumes Service 백업</block>
  <block id="cdb185875636a141b69ddabde6df7040" category="paragraph">보안은 단순한 공격 방지에 관한 것이 아닙니다. 또한 공격이 발생할 경우 또는 발생할 때 공격을 어떻게 복구하는지도 다룹니다. 이 전략에는 데이터 보호 및 백업이 포함됩니다. Cloud Volumes Service는 정전 발생 시 다른 지역으로 복제할 수 있는 방법을 제공합니다(섹션 참조) <block ref="8b1fa1a1fab3125dbb820bfe80ca0428" category="inline-link-macro-rx"></block>) 또는 데이터 세트가 랜섬웨어 공격의 영향을 받는 경우 또한 을 사용하여 Cloud Volumes Service 인스턴스 외부의 위치에 데이터를 비동기식으로 백업할 수도 있습니다 <block ref="92f2015a7a07a74ffc21a27b08fadbb0" category="inline-link-macro-rx"></block>. 정기적인 백업을 사용하면 보안 이벤트를 완화하는데 소요되는 시간을 줄이고 비용을 절감하고 관리자에게 불안감을 줄 수 있습니다.</block>
  <block id="3b0aab94fdc89c539c78fcbbf0190080" category="section-title">업계 최고 수준의 Snapshot 복사본으로 랜섬웨어에 신속하게 대응</block>
  <block id="e7d51c7f9901730a4f176b908516d9f0" category="inline-link-macro">“변경 불가능한 Snapshot 복사본”</block>
  <block id="613542b40dc5d23e9b7129726e6901e9" category="inline-link-macro">“서비스 운영”</block>
  <block id="06646d879e1be0df7191f42262dc1293" category="paragraph">Cloud Volumes Service은 데이터 보호 및 백업 외에도 변경 불가능한 스냅샷 복사본에 대한 지원을 제공합니다(섹션 참조) <block ref="46dfee0c3fc63af00a088b428ebe2c09" category="inline-link-macro-rx"></block>랜섬웨어 공격으로부터 복구할 수 있는 볼륨(섹션 참조 <block ref="f545e9c9b1aa4e21f947ee53ac36de63" category="inline-link-macro-rx"></block>) 문제를 발견하는 후 몇 초 이내에 운영 중단을 최소화하십시오. 복구 시간과 효과는 스냅샷 일정에 따라 다르지만 랜섬웨어 공격의 경우 한 시간 차이만큼 작은 스냅샷 복사본을 생성할 수 있습니다. 스냅샷 복사본은 성능 및 용량 사용에 거의 영향을 주지 않고, 데이터 세트를 보호하는 데 있어 위험이 낮은 하이 보상 접근 방식입니다.</block>
  <block id="f21f1562468eeb7bb67162f8fc79596c" category="inline-link-macro">다음: 보안 고려 사항 및 공격 표면</block>
  <block id="d6cb5b8910b7e61e1d2a16900dff7414" category="paragraph"><block ref="d6cb5b8910b7e61e1d2a16900dff7414" category="inline-link-macro-rx"></block></block>
  <block id="9b6e8c1f1a4d79991136cfd2b3fde77a" category="summary">Cloud Volumes Service를 사용하면 Cloud Volumes Service 인스턴스를 외부 Active Directory 서버에 연결하여 SMB 및 UNIX 사용자 모두의 ID 관리를 수행할 수 있습니다. Cloud Volumes Service에서 SMB를 사용하려면 Active Directory 연결을 생성해야 합니다.</block>
  <block id="d099e6eafff98e1042c1029849e2db1b" category="doc">Active Directory 연결을 생성할 때의 고려 사항</block>
  <block id="1ca3bc7ee6e687110fa43103bcff28e9" category="inline-link-macro">이전: 이중 프로토콜/멀티프로토콜</block>
  <block id="90e9716dfe1097d996980af0b2d435b6" category="paragraph"><block ref="90e9716dfe1097d996980af0b2d435b6" category="inline-link-macro-rx"></block></block>
  <block id="b092138563f7b68473c3bf2a6a23a434" category="inline-link">개인 Google 액세스</block>
  <block id="dd1f65c08f03e8278da92a88b4c609b5" category="inline-link">Google Cloud에서 Active Directory를 사용하는 모범 사례</block>
  <block id="758d9a1746e1f53cf6e7882ed864c1a4" category="paragraph">이 구성은 보안을 고려해야 하는 몇 가지 옵션을 제공합니다. 외부 Active Directory 서버는 온-프레미스 인스턴스 또는 클라우드 네이티브 서버가 될 수 있습니다. 온-프레미스 Active Directory 서버를 사용하는 경우, 도메인을 외부 네트워크(예: DMZ 또는 외부 IP 주소)에 노출하지 마십시오. 대신 을 사용하여 사내 네트워크에 대한 보안 전용 터널 또는 VPN, 단방향 포리스트 트러스트 또는 전용 네트워크 연결을 사용합니다<block ref="76bc9bf9d2d87bee997fb1ade7da1eaa" category="inline-link-rx"></block>. 에 대한 자세한 내용은 Google Cloud 설명서를 참조하십시오<block ref="28831e2b31059cd3ce2ee26e8b5c8fcf" category="inline-link-rx"></block>.</block>
  <block id="22900d9fe4089ff2f29ada31dfd82836" category="admonition">CVS-SW를 사용하려면 Active Directory 서버가 동일한 지역에 있어야 합니다. CVS-SW에서 다른 지역으로 DC 연결을 시도하면 시도가 실패합니다. CVS-SW를 사용할 때는 Active Directory DC를 포함하는 Active Directory 사이트를 생성한 다음 Cloud Volumes Service에서 사이트를 지정하여 교차 지역 DC 연결 시도를 방지해야 합니다.</block>
  <block id="9f69695f33b67147c3fd64e477aa784b" category="section-title">Active Directory 자격 증명</block>
  <block id="2ae640f39e0e652f621ec44b74e57892" category="paragraph">NFS용 SMB 또는 LDAP가 활성화된 경우 Cloud Volumes Service는 Active Directory 컨트롤러와 상호 작용하여 인증에 사용할 컴퓨터 계정 개체를 생성합니다. 이는 Windows SMB 클라이언트가 도메인에 가입하는 방식과 다르지 않으며 Active Directory의 OU(조직 구성 단위)에 동일한 액세스 권한이 필요합니다.</block>
  <block id="d5b16e2c41dd06274f88cd52182d8034" category="paragraph">대부분의 경우 보안 그룹은 Cloud Volumes Service와 같은 외부 서버에서 Windows 관리자 계정 사용을 허용하지 않습니다. 경우에 따라 Windows 관리자 사용자는 보안 모범 사례로 완전히 비활성화됩니다.</block>
  <block id="e33d961644188dff361a3a61603aee23" category="section-title">SMB 시스템 계정을 생성하는 데 필요한 권한입니다</block>
  <block id="7274d74c9decfd509d3c2a9c91098fca" category="inline-link">컴퓨터 계정 객체를 생성 및 수정하는 위임된 권한</block>
  <block id="da90c2a52e7d047f641621a25fcd43c7" category="paragraph">Cloud Volumes Service 컴퓨터 개체를 Active Directory에 추가하려면 도메인에 대한 관리 권한이 있거나 있는 계정입니다<block ref="39a1d8c5f0c0a4ae053b3e24111592ed" category="inline-link-rx"></block> 지정된 OU에 대한 필수 구성 요소입니다. Active Directory의 제어 위임 마법사를 사용하여 다음과 같은 액세스 권한이 있는 컴퓨터 개체를 생성/삭제할 수 있는 사용자 지정 작업을 만들어 이 작업을 수행할 수 있습니다.</block>
  <block id="db3317ceb65be02e43db6f277e0ad94e" category="list-text">읽기/쓰기</block>
  <block id="9da76760248a4997f94bdd63f1c04f01" category="list-text">모든 자식 개체를 생성/삭제합니다</block>
  <block id="858ac25470b9539b8e2bb4d6958fde5b" category="list-text">모든 속성 읽기/쓰기</block>
  <block id="e798906fb7bcd7b0403d97d21044e339" category="list-text">암호 변경/재설정</block>
  <block id="4eb6bcf48028313e542c0964c09b46b9" category="paragraph">이렇게 하면 정의된 사용자에 대한 보안 ACL이 Active Directory의 OU에 자동으로 추가되고 Active Directory 환경에 대한 액세스가 최소화됩니다. 사용자가 위임된 후에는 이 창에서 해당 사용자 이름과 암호를 Active Directory 자격 증명으로 제공할 수 있습니다.</block>
  <block id="66d939bc6b363153976bbd24624850b8" category="admonition">Active Directory 도메인에 전달되는 사용자 이름과 암호는 컴퓨터 계정 개체 쿼리 및 생성 중에 Kerberos 암호화를 사용하여 보안을 강화합니다.</block>
  <block id="8575c9ec9ca166098f9d546c3c12e9b1" category="section-title">Active Directory 연결 세부 정보입니다</block>
  <block id="452740f6c26f32def386962441d5cb2c" category="inline-link">Active Directory 연결 세부 정보</block>
  <block id="af31d4ab1f284e1f94d3522fd1fa36fe" category="paragraph">를 클릭합니다<block ref="9255123c1378b2d08be170075ba389b5" category="inline-link-rx"></block> 다음과 같은 컴퓨터 계정 배치에 대한 특정 Active Directory 스키마 정보를 관리자에게 제공하는 필드를 제공합니다.</block>
  <block id="353000b4dd170de2ebede38bb7420e40" category="list-text">* Active Directory 연결 유형. * Cloud Volumes Service 또는 CVS 성능 서비스 유형의 볼륨에 대해 영역의 Active Directory 연결이 사용되는지 여부를 지정하는 데 사용됩니다. 기존 연결에서 이 설정을 잘못 설정하면 사용하거나 편집할 때 제대로 작동하지 않을 수 있습니다.</block>
  <block id="d5cc4c55027c65e3b8d52c15d308935d" category="list-text">* 도메인. * Active Directory 도메인 이름입니다.</block>
  <block id="c3fab9d188d8e1e4a9e0ba27a52306c6" category="inline-link">고려 사항</block>
  <block id="925e235ec5866cd9c094261d9e20eec4" category="list-text">* 사이트. * 보안 및 성능을 위해 Active Directory 서버를 특정 사이트로 제한합니다<block ref="cae534855afa8eaefaa37d26edea88d5" category="inline-link-rx"></block>. Cloud Volumes Service는 현재 Cloud Volumes Service 인스턴스가 아닌 다른 영역에 있는 Active Directory 서버에 대한 Active Directory 인증 요청을 허용하지 않으므로 여러 Active Directory 서버가 여러 지역에 걸쳐 있는 경우 이 작업이 필요합니다. 예를 들어, Active Directory 도메인 컨트롤러는 CVS-Performance만 지원하는 영역에 있지만 CVS-SW 인스턴스에서 SMB 공유를 원할 수 있습니다.</block>
  <block id="bc3a6531a92e21b83c95f7d7044fd498" category="list-text">DNS 서버 * 이름 조회에 사용할 DNS 서버.</block>
  <block id="44ea07387884d17ba7d18393d327374b" category="inline-link-macro">Active Directory에 Cloud Volumes Service가 표시되는 방식</block>
  <block id="32b5af659fee51ef98e34710303d53ba" category="list-text">NetBIOS 이름(선택 사항).* 필요한 경우 서버의 NetBIOS 이름입니다. 이 기능은 Active Directory 연결을 사용하여 새 컴퓨터 계정을 만들 때 사용됩니다. 예를 들어 NetBIOS 이름이 CVS-East로 설정된 경우 컴퓨터 계정 이름은 CVS-East-{1234}가 됩니다. 섹션을 참조하십시오 <block ref="0bba591d00c255586e052c023629a690" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="00a4c212426e322a34af5aeccdc494f7" category="list-text">* OU(조직 단위) * 컴퓨터 계정을 만들 특정 OU. 이 기능은 컴퓨터 계정에 대해 특정 OU에 제어를 위임하는 경우에 유용합니다.</block>
  <block id="06852342816b885474a42d89311e2113" category="list-text">* AES 암호화. * AD 인증에 AES 암호화 사용 확인란을 선택하거나 선택 취소할 수도 있습니다. Active Directory 인증에 AES 암호화를 사용하면 사용자 및 그룹 조회 중에 Cloud Volumes Service에서 Active Directory로 통신하는 데 추가적인 보안을 제공할 수 있습니다. 이 옵션을 활성화하기 전에 도메인 관리자에게 문의하여 Active Directory 도메인 컨트롤러가 AES 인증을 지원하는지 확인하십시오.</block>
  <block id="7d51d6a8b37a2763f6c84b7b3a3a7e97" category="admonition">기본적으로 대부분의 Windows 서버는 약한 암호(예: DES 또는 RC4-HMAC)를 비활성화하지 않지만 약한 암호를 비활성화하도록 선택하는 경우 Cloud Volumes Service Active Directory 연결이 AES를 사용하도록 구성되었는지 확인합니다. 그렇지 않으면 인증 실패가 발생합니다. AES 암호화를 사용하도록 설정하면 약한 암호가 비활성화되지 않고 대신 Cloud Volumes Service SMB 시스템 계정에 AES 암호화에 대한 지원이 추가됩니다.</block>
  <block id="3da975567fcd6ebd164f43cca13384f2" category="section-title">Kerberos 영역 세부 정보</block>
  <block id="9a62ab6b4d79a99749d02cd8af945f25" category="paragraph">이 옵션은 SMB 서버에는 적용되지 않습니다. 대신, Cloud Volumes Service 시스템에 NFS Kerberos를 구성할 때 사용됩니다. 이러한 세부 정보가 채워지면 NFS Kerberos 영역이 구성되고(Linux의 krb5.conf 파일과 유사), Active Directory 연결이 NFS Kerberos 메일 센터(KDC) 역할을 하므로 Cloud Volumes Service 볼륨 생성에 NFS Kerberos가 지정될 때 사용됩니다.</block>
  <block id="e53ab7e80d5d436b4a496f0c2bef7cb2" category="admonition">Windows 이외의 KDC는 현재 Cloud Volumes Service에서 사용할 수 없습니다.</block>
  <block id="f447ac856e7e72435904956e3b15f433" category="section-title">지역</block>
  <block id="38da42463bdc613d24159bd6e0405ba6" category="paragraph">영역을 사용하면 Active Directory 연결이 있는 위치를 지정할 수 있습니다. 이 영역은 Cloud Volumes Service 볼륨과 동일한 영역이어야 합니다.</block>
  <block id="4dfb982db9679a6eec578ccd86af978a" category="list-text">* LDAP를 사용하는 로컬 NFS 사용자 * 이 섹션에는 LDAP를 사용하는 로컬 NFS 사용자를 허용하는 옵션도 있습니다. UNIX 사용자 그룹 구성원 지원을 NFS(확장 그룹)의 16개 그룹 제한 이상으로 확장하려면 이 옵션을 선택하지 않아야 합니다. 그러나 확장된 그룹을 사용하려면 UNIX ID에 대해 구성된 LDAP 서버가 필요합니다. LDAP 서버가 없는 경우 이 옵션을 선택되지 않은 상태로 둡니다. LDAP 서버가 있고 로컬 UNIX 사용자(예: 루트)도 사용하려면 이 옵션을 선택합니다.</block>
  <block id="5059a39455b0e2649d69d289516cdf1b" category="section-title">백업 사용자</block>
  <block id="0e051a51493712b34966f346e858a0c3" category="inline-link">해당 사용자 액세스에 대한 감사를 설정합니다</block>
  <block id="d3980aa1c5f0625161c9b0fb5a6cace0" category="paragraph">이 옵션을 사용하면 Cloud Volumes Service 볼륨에 대한 백업 권한이 있는 Windows 사용자를 지정할 수 있습니다. NAS 볼륨의 데이터를 올바르게 백업 및 복원하려면 일부 애플리케이션에 백업 권한(SeBackupPrivilege)이 필요합니다. 이 사용자는 볼륨의 데이터에 대한 높은 수준의 액세스 권한을 가지고 있으므로 고려해야 합니다<block ref="b5fba80299f6d29935863b6604a98277" category="inline-link-rx"></block>. 활성화된 감사 이벤트는 이벤트 뷰어 &gt; Windows 로그 &gt; 보안에 표시됩니다.</block>
  <block id="70136e0b9257bc91e1eb5216b32580de" category="paragraph"><block ref="70136e0b9257bc91e1eb5216b32580de" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6833e65d65b96c0d79b7fc114c9a2968" category="section-title">보안 권한 사용자</block>
  <block id="63a19a4d390181634079ba6ba20fe287" category="inline-link">SQL Server와 같은</block>
  <block id="c9a97779c6062109c66675cc5368a6b8" category="inline-link">사용자의 사용자 액세스 감사</block>
  <block id="296bdd6f36456d0f48d21431f3bd7853" category="paragraph">이 옵션을 사용하면 Cloud Volumes Service 볼륨에 대한 보안 수정 권한이 있는 Windows 사용자를 지정할 수 있습니다. 일부 응용 프로그램에는 보안 권한(SeSecurityPrivilege)이 필요합니다 <block ref="cef5278acd430b226f8e7bcad71f9075" category="inline-link-rx"></block>)를 클릭하여 설치 중에 권한을 적절하게 설정합니다. 이 권한은 보안 로그를 관리하는 데 필요합니다. 이 권한은 SeBackupPrivilege 권한만큼 강력하지는 않지만 NetApp이 권장합니다<block ref="2238ada9972b35c5f01addc7598ffd7a" category="inline-link-rx"></block> 필요한 경우 이 권한 수준을 사용합니다.</block>
  <block id="f044d72e46ac4189129dc6e27333c449" category="inline-link">새 로그온에 할당된 특수 권한</block>
  <block id="1384ec27890f8bac59aae8edf1ff83e9" category="paragraph">자세한 내용은 을 참조하십시오<block ref="791e82319c9cb432525cbf92f3a07623" category="inline-link-rx"></block>.</block>
  <block id="3fc6256a9aed6803167ff54873f78a00" category="paragraph">Cloud Volumes Service는 Active Directory에 일반 컴퓨터 계정 개체로 표시됩니다. 명명 규칙은 다음과 같습니다.</block>
  <block id="864917f152404280b59cd43c564f6733" category="list-text">CIFS/SMB 및 NFS Kerberos는 별도의 시스템 계정 객체를 생성합니다.</block>
  <block id="79adcd3b0eb62b997e160c91e737deb2" category="list-text">LDAP가 설정된 NFS는 Active Directory에서 Kerberos LDAP 바인드를 위한 컴퓨터 계정을 생성합니다.</block>
  <block id="2ed35f8c3fa643ff6b7226a2163085c5" category="list-text">LDAP가 있는 이중 프로토콜 볼륨은 LDAP 및 SMB의 CIFS/SMB 시스템 계정을 공유합니다.</block>
  <block id="3028cc04aacef3f671388051ac5a05cf" category="list-text">CIFS/SMB 시스템 계정은 시스템 계정에 대해 이름-1234(10자 이름에 하이픈이 추가된 4자리 임의 ID)의 명명 규칙을 사용합니다. Active Directory 연결에서 NetBIOS 이름 설정을 사용하여 이름을 정의할 수 있습니다(“ 절 참조)<block ref="7d2ad38c1c26cdc0446a7f473a720f92" category="inline-xref-macro-rx"></block>").</block>
  <block id="b3330aabe270fd3b52fec421dc299283" category="list-text">NFS Kerberos에서는 nfs-name-1234를 명명 규칙(최대 15자)으로 사용합니다. 15자 이상을 사용하는 경우 이름은 nfs-duncated-name-1234입니다.</block>
  <block id="50b0fcc303b033d01b24dbb96023de81" category="list-text">NFS 전용 CVS - LDAP가 설정된 성능 인스턴스는 CIFS/SMB 인스턴스와 동일한 명명 규칙을 사용하여 LDAP 서버에 바인딩하기 위한 SMB 시스템 계정을 생성합니다.</block>
  <block id="d4895b82fd7385bed173b438d89c807e" category="inline-link-macro">“숨겨진 기본 공유”</block>
  <block id="6d7a9f810c1df414bda9e341201f414b" category="list-text">SMB 컴퓨터 계정이 생성되면 숨겨진 기본 관리자 공유가 생성됩니다(섹션 참조) <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>)도 생성되지만(c$, admin$, ipc$) 해당 공유는 할당된 ACL이 없으며 액세스할 수 없습니다.</block>
  <block id="e1547130d9a70017a557e263270469eb" category="list-text">컴퓨터 계정 개체는 기본적으로 CN=Computers에 배치되지만 필요한 경우 다른 OU를 지정할 수 있습니다. 자세한 내용은 " 단원을 참조하십시오<block ref="99b866e46eaefba106810f4a564a9de4" category="inline-xref-macro-rx"></block>"Cloud Volumes Service에 대한 컴퓨터 계정 개체를 추가/제거하는 데 필요한 액세스 권한에 대한 정보를 제공합니다.</block>
  <block id="5a1324cda45cd652ecb95755709fd8e1" category="paragraph">Cloud Volumes Service가 Active Directory에 SMB 컴퓨터 계정을 추가하면 다음 필드가 채워집니다.</block>
  <block id="650ca2f93573bbd3b4e7f2e4fc5d536e" category="list-text">CN(지정된 SMB 서버 이름 포함)</block>
  <block id="493629591f73624fd57b9ff00cb6d94e" category="list-text">dNSHostName(SMBserver.domain.com 포함)</block>
  <block id="ed877e9b9c0c0bb19ecf1f342cdda00f" category="list-text">msDS-SupportedEncryptionTypes (AES 암호화가 활성화되지 않은 경우 DES_CBC_MD5, RC4_HMAC_MD5 허용; AES 암호화가 활성화된 경우 DES_CBC_MD5, RC4_HMAC_MD5, AES128_CTS_HMAC_SHA1_96, AES256_CTS_HMAC_SHA1_96은 SMB용 시스템 계정과 티켓 교환에 허용됨)</block>
  <block id="987e945fa65d0a9e76f890e3892961cc" category="list-text">이름(SMB 서버 이름 포함)</block>
  <block id="6c4b390273352496044f436350e3e996" category="list-text">sAMAccountName(SMBserver$ 사용)</block>
  <block id="603c37960edbea70b7dd05f369016869" category="list-text">servicePrincipalName(호스트 /smbserver.domain.com 및 Kerberos에 대한 호스트/smbserver SPN 포함)</block>
  <block id="e4d5beb18aee5989e4944d5f91b181e4" category="paragraph">컴퓨터 계정에서 약한 Kerberos 암호화 유형(enctype)을 비활성화하려면 컴퓨터 계정의 MSDS-SupportedEncryptionTypes 값을 다음 표의 값 중 하나로 변경하여 AES만 허용할 수 있습니다.</block>
  <block id="d7b35b0eb85a800cd27ae4d86378e957" category="cell">MSDS - SupportedEncryptionTypes 값입니다</block>
  <block id="b20e97401d06f2734903c9c8ce3bd34e" category="cell">Enctype이 활성화되었습니다</block>
  <block id="3afb17e90ee63072dfd4ad5496e22ecf" category="cell">DES_CBC_MD5</block>
  <block id="427e6bbc6e437e1008a5c41adc923d0e" category="cell">RC4_HMAC</block>
  <block id="16105c1a0d76dfdb5c1df287b56762db" category="cell">AES128_CTS_HMAC_SHA1_96만 해당</block>
  <block id="bdacd7093a31449b44a8d708a5a055de" category="cell">AES256_CTS_HMAC_SHA1_96만 해당</block>
  <block id="1ff1de774005f8da13f42943881c655f" category="cell">24</block>
  <block id="ea8f561ef42d9f42f97782208f239797" category="cell">AES128_CTS_HMAC_SHA1_96 및 AES256_CTS_HMAC_SHA1_96</block>
  <block id="34173cb38f07f89ddbebc2ac9128303f" category="cell">30</block>
  <block id="bbfe7622403fb2a786b158ba768ac4ca" category="cell">DES_CBC_MD5, RC4_HMAC, AES128_CTS_HMAC_SHA1_96 및 AES256_CTS_HMAC_SHA1_96</block>
  <block id="adfa4c5560980c9b2841dda24bda5935" category="paragraph">SMB 시스템 계정에 대해 AES 암호화를 활성화하려면 Active Directory 연결을 생성할 때 AD 인증에 AES 암호화 사용 을 클릭합니다.</block>
  <block id="fd0625de17999274e1465433cabc43a7" category="inline-link">Cloud Volumes Service 설명서를 참조하십시오</block>
  <block id="9e167fdd1e36cc753653d71cef598f95" category="paragraph">NFS Kerberos에서 AES 암호화를 사용하도록 설정하려면<block ref="a1ea73992eb480d81ba9d6fd0002e272" category="inline-link-rx"></block>.</block>
  <block id="c36c6a3451be9921bddbe958fc50f971" category="inline-link-macro">다음: 기타 NAS 인프라스트럭처 서비스 종속성(KDC, LDAP, DNS)</block>
  <block id="0a243881b9403f37a34293a498b9dcb8" category="paragraph"><block ref="0a243881b9403f37a34293a498b9dcb8" category="inline-link-macro-rx"></block></block>
  <block id="5e64a4b25a4f107aefb7d4e2a56b9dfb" category="summary">NAS 공유에 Cloud Volumes Service를 사용하는 경우 적절한 기능을 위해 외부 종속성이 필요할 수 있습니다. 이러한 종속성은 특정 상황에서 적용됩니다.</block>
  <block id="f4b5e0cbc9d84ca994a4dc85d6f45205" category="doc">기타 NAS 인프라스트럭처 서비스 종속성(KDC, LDAP 및 DNS)</block>
  <block id="619169033066c83ff7d1cc580d748cd6" category="inline-link-macro">이전: Active Directory 연결 생성 시 고려 사항</block>
  <block id="a67d66e488b843722a2bb6124e92d2c0" category="paragraph"><block ref="a67d66e488b843722a2bb6124e92d2c0" category="inline-link-macro-rx"></block></block>
  <block id="c4c97073fa9e6d604787db13592331a3" category="paragraph">NAS 공유에 Cloud Volumes Service를 사용하는 경우 적절한 기능을 위해 외부 종속성이 필요할 수 있습니다. 이러한 종속성은 특정 상황에서 적용됩니다. 다음 표에는 다양한 구성 옵션과 종속 항목이 필요한 항목이 나와 있습니다.</block>
  <block id="c9b3a27f085427ada9b946daa430f1f8" category="cell">종속성이 필요합니다</block>
  <block id="954898296a4e7ec7e15ab65964b50da0" category="cell">NFSv3만 해당</block>
  <block id="e69d896f8231ad7dd96dd4937ba18d07" category="cell">NFSv3 Kerberos만 해당</block>
  <block id="6040c1d5c15727690384a7cd3e8d3fa4" category="cell">Windows Active Directory: * KDC * DNS * LDAP</block>
  <block id="b88d0e1e32f67294d9d45e05a25495e7" category="cell">NFSv4.1만 해당</block>
  <block id="1cc44815edb1648976dd6fa410f26802" category="cell">클라이언트 ID 매핑 구성(/etc/idmap.conf)</block>
  <block id="c2e2e93edfc9ea6acddd551b71be27bf" category="cell">NFSv4.1 Kerberos만 해당</block>
  <block id="411c501ecf4d59f4ef8d7e9c444b838a" category="list-text">Windows Active Directory: KDC DNS LDAP</block>
  <block id="59b6dd4c5b36405b29c64750f1e82401" category="cell">SMB만 해당</block>
  <block id="11a431c64d07fefe0bbb5880e03069c5" category="cell">Active Directory: * KDC * DNS</block>
  <block id="420da7f0cb45485c925482687369c1ad" category="cell">멀티프로토콜 NAS(NFS 및 SMB)</block>
  <block id="b756e6f6a894749273e32e03e551180c" category="list-text">클라이언트 ID 매핑 구성(NFSv4.1 전용; /etc/idmap.conf)</block>
  <block id="8777a112bd8b1e9205dda0717a12965b" category="section-title">시스템 계정 개체에 대한 Kerberos 키 탭 회전/암호 재설정</block>
  <block id="b8333cf0e11040ea157a74560b3a6d77" category="paragraph">SMB 시스템 계정의 경우 Cloud Volumes Service는 SMB 시스템 계정에 대한 주기적인 암호 재설정을 예약합니다. 이러한 암호 재설정은 Kerberos 암호화를 사용하여 발생하며, 오후 11시부터 오전 1시 사이에 임의 시간에 매주 일요일 일정에 따라 작동합니다. 이러한 암호 재설정은 Kerberos 키 버전을 변경하고, Cloud Volumes Service 시스템에 저장된 키 탭을 회전하며, Cloud Volumes Service에서 실행되는 SMB 서버의 보안을 더욱 강화할 수 있도록 도와줍니다. 시스템 계정 암호는 무작위배정되며 관리자에게 알려져 있지 않습니다.</block>
  <block id="6df7123d2b1a64b11c7df1c2b837f752" category="paragraph">NFS Kerberos 시스템 계정의 경우 KDC와 새 키 탭이 생성/교환될 때만 암호 재설정이 적용됩니다. 현재 Cloud Volumes Service에서는 이 작업을 수행할 수 없습니다.</block>
  <block id="7631991924ea0015e269781ad88bd8d3" category="section-title">LDAP 및 Kerberos와 함께 사용할 네트워크 포트</block>
  <block id="52d1b9583b81da6bee6ba24d74c4018b" category="inline-link">보안 고려 사항에 대한 Cloud Volumes Service 문서</block>
  <block id="2363dee608bcd9f6ce7f980bfdad5789" category="section-title">LDAP를 지원합니다</block>
  <block id="d0a2de9b178b436803f7732ff69d0c14" category="paragraph">Cloud Volumes Service는 LDAP 클라이언트 역할을 하며 UNIX ID에 대한 사용자 및 그룹 조회를 위해 표준 LDAP 검색 쿼리를 사용합니다. Cloud Volumes Service에서 제공하는 표준 기본 사용자 이외의 사용자 및 그룹을 사용하려면 LDAP가 필요합니다. NFS Kerberos를 사용자 보안 주체(예: user1@domain.com 사용할 계획이라면 LDAP도 필요합니다. 현재 Microsoft Active Directory를 사용하는 LDAP만 지원됩니다.</block>
  <block id="2eaa173e56517db74fb0eb92806a0877" category="inline-link">RFC-2307-bis</block>
  <block id="50af1bf8bee07c6cb1c61e9c19599403" category="paragraph">Active Directory를 UNIX LDAP 서버로 사용하려면 UNIX ID에 사용할 사용자 및 그룹에 필요한 UNIX 속성을 채워야 합니다. Cloud Volumes Service에서는 에 따라 특성을 쿼리하는 기본 LDAP 스키마 템플릿을 사용합니다<block ref="54011f528a38d24d58a7f02f98da0d00" category="inline-link-rx"></block>. 따라서 다음 표에서는 사용자 및 그룹에 채울 최소 필수 Active Directory 속성과 각 속성이 사용되는 특성을 보여 줍니다.</block>
  <block id="a6e75b8341b03d08fb1d6817635b1d47" category="inline-link">이중 프로토콜 액세스 관리.</block>
  <block id="c0f3d72f07b570cdf3f5d1376c72a389" category="paragraph">Active Directory에서 LDAP 속성을 설정하는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="c2741a8ac44d0c827e11ee9004dcd081" category="inline-link-rx"></block></block>
  <block id="f2bbdf9f72c085adc4d0404e370f0f4c" category="cell">속성</block>
  <block id="b12c51b935d86f01d092fb23a1fa4f9f" category="cell">기능</block>
  <block id="e266bea072e01571abba7fc5075c2c86" category="cell">UID *</block>
  <block id="0689aaddc7bfae9cad3778f6d706bd7a" category="cell">UNIX 사용자 이름을 지정합니다</block>
  <block id="525f84e25602ba8efb61d7b8ca793b7c" category="cell">uidNumber *</block>
  <block id="604edb3bb733537b2d6c63b0b84fa1ec" category="cell">UNIX 사용자의 숫자 ID를 지정합니다</block>
  <block id="825c2f924ee564de1d57d2b63edd800d" category="cell">gidNumber *</block>
  <block id="eb91949970817d632278971bdf06baef" category="cell">UNIX 사용자의 기본 그룹 숫자 ID를 지정합니다</block>
  <block id="18b5aa92067bde95c39c3039f02bf70e" category="cell">objectClass *</block>
  <block id="ce41297dde1628c606d60ef2bbe154cd" category="cell">사용 중인 개체 유형을 지정합니다. Cloud Volumes Service에서는 "사용자"를 개체 클래스 목록에 포함해야 합니다(기본적으로 대부분의 Active Directory 배포에는 포함됨).</block>
  <block id="db108aa570113ecd6745a2e272d68544" category="cell">계정에 대한 일반 정보(실제 이름, 전화 번호 등, gecos라고도 함)</block>
  <block id="17a12df2f12fa6f25328eb6c9fcffedf" category="cell">unixUserPassword</block>
  <block id="4306442303f7519026403fc1912e8e2e" category="cell">NAS 인증을 위한 UNIX ID 조회에 사용되지 않으므로 설정할 필요가 없습니다. 이렇게 설정하면 구성된 unixUserPassword 값이 일반 텍스트로 설정됩니다.</block>
  <block id="d146b96a250f5bcf84b56d2a0f8a2f87" category="cell">unixHomeDirectory</block>
  <block id="1208d15552f3ca8721989c162201e0de" category="cell">사용자가 Linux 클라이언트에서 LDAP에 대해 인증할 때 UNIX 홈 디렉토리의 경로를 정의합니다. UNIX 홈 디렉토리 기능에 LDAP를 사용하려면 이 옵션을 설정합니다.</block>
  <block id="0693ba16c955b74875d26f79148b66f0" category="cell">LoginShell입니다</block>
  <block id="61940c4af8b62a3bb77f4ab0eb491c08" category="cell">사용자가 LDAP에 대해 인증할 때 Linux 클라이언트의 bash/profile 셸에 대한 경로를 정의합니다.</block>
  <block id="9ed4554644da662e0634bf83a7e18666" category="paragraph">* 는 Cloud Volumes Service의 적절한 기능을 위해 특성이 필요함을 나타냅니다. 나머지 속성은 클라이언트 측 전용입니다.</block>
  <block id="ac975e575ff07bee5423d326c261e07e" category="cell">CN *</block>
  <block id="b982e168cd50ef73d1f3ce851cb4ddac" category="cell">UNIX 그룹 이름을 지정합니다. LDAP에 Active Directory를 사용하는 경우 개체를 처음 만들 때 설정되지만 나중에 변경할 수 있습니다. 이 이름은 다른 개체와 같을 수 없습니다. 예를 들어, user1이라는 UNIX 사용자가 Linux 클라이언트의 user1이라는 그룹에 속해 있는 경우 Windows에서는 cn 특성이 같은 두 개체를 허용하지 않습니다. 이 문제를 해결하려면 Windows 사용자의 이름을 고유한 이름(예: user1-UNIX)으로 바꿉니다. Cloud Volumes Service의 LDAP는 UNIX 사용자 이름에 uid 속성을 사용합니다.</block>
  <block id="dc1d913bf6d70def379cf9f0d70abace" category="cell">UNIX 그룹 숫자 ID를 지정합니다.</block>
  <block id="1afbf0b9465b3d5c13329cd43dda4e9e" category="cell">사용 중인 개체 유형을 지정합니다. Cloud Volumes Service에서는 개체 클래스 목록에 그룹을 포함해야 합니다. 이 특성은 기본적으로 대부분의 Active Directory 배포에 포함됩니다.</block>
  <block id="5e4db984d78b91a65e9096eebf726d40" category="cell">memberUid</block>
  <block id="6cd5795a9ccf8fa0d1da852e88da95cd" category="cell">UNIX 그룹의 구성원인 UNIX 사용자를 지정합니다. Cloud Volumes Service에서 Active Directory LDAP를 사용할 경우 이 필드는 필요하지 않습니다. Cloud Volumes Service LDAP 스키마는 그룹 구성원 자격에 구성원 필드를 사용합니다.</block>
  <block id="cadd4e3eefdff4ed3ad7de830179c314" category="cell">구성원 *</block>
  <block id="defbfcaae1980c16f810c5ddaa1ecb87" category="cell">그룹 구성원 자격/보조 UNIX 그룹에 필요합니다. 이 필드는 Windows 그룹에 Windows 사용자를 추가하여 채워집니다. 그러나 Windows 그룹에 채워진 UNIX 특성이 없는 경우 UNIX 사용자의 그룹 구성원 목록에는 포함되지 않습니다. NFS에서 사용할 수 있어야 하는 모든 그룹은 이 표에 나열된 필수 UNIX 그룹 속성을 채워야 합니다.</block>
  <block id="14476f6ea303cd9ac37328cb484a1fa1" category="section-title">LDAP 바인딩 정보</block>
  <block id="af0c1d97230a1daa0f7341dc35f53a29" category="paragraph">LDAP에서 사용자를 쿼리하려면 Cloud Volumes Service가 LDAP 서비스에 바인딩(로그인)해야 합니다. 이 로그인에는 읽기 전용 권한이 있으며 디렉토리 조회를 위해 LDAP UNIX 속성을 쿼리하는 데 사용됩니다. 현재 LDAP 바인딩은 SMB 컴퓨터 계정을 통해서만 가능합니다.</block>
  <block id="4a9b831487cab83d7de4d5a515e0eadd" category="paragraph">'CVS 성능' 인스턴스에만 LDAP를 사용하도록 설정하고 NFSv3, NFSv4.1 또는 이중 프로토콜 볼륨에는 LDAP를 사용할 수 있습니다. LDAP 지원 볼륨을 성공적으로 배포하려면 Cloud Volumes Service 볼륨과 동일한 영역에 Active Directory 연결을 설정해야 합니다.</block>
  <block id="c41605f9de6fa81e35ab98dd9e8b1b02" category="paragraph">LDAP가 활성화된 경우 특정 시나리오에서 다음이 발생합니다.</block>
  <block id="f9f5dcaa4945ab96d402d905be4ed78c" category="list-text">Cloud Volumes Service 프로젝트에 NFSv3이나 NFSv4.1만 사용되는 경우 Active Directory 도메인 컨트롤러에서 새 컴퓨터 계정이 생성되고 Cloud Volumes Service의 LDAP 클라이언트는 시스템 계정 자격 증명을 사용하여 Active Directory에 바인딩됩니다. NFS 볼륨 및 숨겨진 기본 관리 공유에 대해 SMB 공유가 생성되지 않습니다(섹션 참조) <block ref="15f1050f174b7bbba32ef5b54c17bc40" category="inline-link-macro-rx"></block>)의 공유 ACL이 제거되었습니다.</block>
  <block id="f3dad67ce399cefb4b495c573d3ddcb8" category="list-text">Cloud Volumes Service 프로젝트에 이중 프로토콜 볼륨을 사용하는 경우 SMB 액세스용으로 생성된 단일 컴퓨터 계정만 Cloud Volumes Service의 LDAP 클라이언트를 Active Directory에 바인딩하는 데 사용됩니다. 추가 컴퓨터 계정이 생성되지 않습니다.</block>
  <block id="7168c010de7dd97d077c0e69f48cfbb5" category="list-text">전용 SMB 볼륨이 별도로 생성된 경우(LDAP가 설정된 NFS 볼륨 이전 또는 이후에) LDAP 바인딩의 컴퓨터 계정이 SMB 시스템 계정과 공유됩니다.</block>
  <block id="248e702975c1b53305536e1e9c698e19" category="list-text">NFS Kerberos도 사용하도록 설정된 경우 두 개의 시스템 계정이 생성됩니다. 하나는 SMB 공유 및/또는 LDAP 바인드이고 다른 하나는 NFS Kerberos 인증입니다.</block>
  <block id="738deb1a3cec2cc7d670e7de69d3a7c6" category="section-title">LDAP 쿼리입니다</block>
  <block id="a204dba492103f34b09fe60e7ab98921" category="paragraph">LDAP 바인딩은 암호화되지만 일반 LDAP 포트 389를 사용하여 LDAP 쿼리가 일반 텍스트로 회선을 통해 전달됩니다. 이 잘 알려진 포트는 현재 Cloud Volumes Service에서 변경할 수 없습니다. 따라서 네트워크에서 패킷 스니핑에 액세스할 수 있는 사용자는 사용자 및 그룹 이름, 숫자 ID 및 그룹 구성원 자격을 볼 수 있습니다.</block>
  <block id="d10f3c8108e06d8e622b7a6fb88adb08" category="inline-link-macro">“패킷 감지/추적 고려 사항”</block>
  <block id="b046f19aab64225d509f228ccd32fb2c" category="paragraph">그러나 Google Cloud VM은 다른 VM의 유니캐스트 트래픽을 스니프할 수 없습니다. LDAP 트래픽에 활성 중인 VM(즉, 바인딩 가능)만 LDAP 서버의 트래픽을 볼 수 있습니다. Cloud Volumes Service의 패킷 스니핑에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="d815e456141423f092087c21cd312f23" category="section-title">LDAP 클라이언트 구성 기본값</block>
  <block id="1c1b57ee3fb14f95067e88e579a44eec" category="paragraph">Cloud Volumes Service 인스턴스에서 LDAP가 활성화되면 기본적으로 특정 구성 세부 정보를 사용하여 LDAP 클라이언트 구성이 생성됩니다. 경우에 따라 옵션이 Cloud Volumes Service(지원되지 않음)에 적용되지 않거나 구성할 수 없습니다.</block>
  <block id="cc2eacdb2cc579f99a0f4359e61ed258" category="cell">LDAP 클라이언트 옵션입니다</block>
  <block id="31ce3cdcd67850870b616f75b555bbc5" category="cell">기본값</block>
  <block id="216a8093d27a97d2912ed6822d19d410" category="cell">변경할 수 있습니까?</block>
  <block id="ffe990396bf99448f8fe6e6fa1c3c3ea" category="cell">LDAP 서버 목록</block>
  <block id="0b22102603051537f2c4bfccc964b74e" category="cell">쿼리에 사용할 LDAP 서버 이름 또는 IP 주소를 설정합니다. Cloud Volumes Service에는 사용되지 않습니다. 대신 Active Directory 도메인을 사용하여 LDAP 서버를 정의합니다.</block>
  <block id="9ba66a9f92056682b7d86a38b4bc18c0" category="cell">설정되지 않았습니다</block>
  <block id="f490d3302e7cd81f3dafead6c8311b60" category="cell">Active Directory 도메인</block>
  <block id="63dfe9dc44b2881b25560d6d5bd5dff6" category="cell">LDAP 쿼리에 사용할 Active Directory 도메인을 설정합니다. Cloud Volumes Service는 DNS의 LDAP에 대한 SRV 레코드를 활용하여 도메인에서 LDAP 서버를 찾습니다.</block>
  <block id="6575821e7d2ff9eec297128f6e66933a" category="cell">Active Directory 연결에 지정된 Active Directory 도메인으로 설정합니다.</block>
  <block id="00227bc990a551282373139d6439feb4" category="cell">기본 Active Directory 서버</block>
  <block id="01d685ed68515214956910d3e26f1c71" category="cell">LDAP에 사용할 기본 Active Directory 서버를 설정합니다. Cloud Volumes Service에서 지원되지 않습니다. 대신 Active Directory 사이트를 사용하여 LDAP 서버 선택을 제어할 수 있습니다.</block>
  <block id="f41520c4ef898fb19bb93ee749be3fdd" category="cell">설정되지 않았습니다.</block>
  <block id="b626ddcd91311f0f7c4622fdcb7ba05e" category="cell">SMB 서버 자격 증명을 사용하여 바인딩합니다</block>
  <block id="cb97b8ae4a5bb23e8ffa9e1547fe5078" category="cell">SMB 시스템 계정을 사용하여 LDAP에 바인딩합니다. 현재 Cloud Volumes Service에서 지원되는 유일한 LDAP 바인딩 방법입니다.</block>
  <block id="f827cf462f62848df37c5e1e94a4da74" category="cell">참</block>
  <block id="d95e3278cf3c7f4cd1d7e40c5a89e7a7" category="cell">스키마 템플릿</block>
  <block id="33387315b367e8397cc901a4bf37ad44" category="cell">LDAP 쿼리에 사용되는 스키마 템플릿입니다.</block>
  <block id="16165a1c7229a30ce1a980b0e648d65f" category="cell">MS-AD-BIS</block>
  <block id="b825dd7cf8df99909db6f3117c567721" category="cell">LDAP 서버 포트입니다</block>
  <block id="731fba188f3670e36bac64d2ca64db37" category="cell">LDAP 쿼리에 사용되는 포트 번호입니다. Cloud Volumes Service는 현재 표준 LDAP 포트 389만 사용합니다. LDAPS/포트 636은 현재 지원되지 않습니다.</block>
  <block id="c86a7ee3d8ef0b551ed58e354a836f2b" category="cell">389</block>
  <block id="9a76dbbba394b04594907973bb6c192e" category="cell">LDAPS가 활성화되어 있습니다</block>
  <block id="98c3437e89f8128c7359f6b999731fcc" category="cell">SSL(Secure Sockets Layer)을 통한 LDAP가 쿼리 및 바인딩에 사용되는지 여부를 제어합니다. 현재 Cloud Volumes Service에서 지원되지 않습니다.</block>
  <block id="3452a15eecd4e9b3215025c747cfce4e" category="cell">쿼리 시간 제한(초)</block>
  <block id="4fbc7a2f8fb9f56de093d04afac67fa3" category="cell">쿼리 시간이 초과되었습니다. 쿼리가 지정된 값보다 오래 걸면 쿼리가 실패합니다.</block>
  <block id="4211f908e9b523117776324e2349a87c" category="cell">최소 바인딩 인증 레벨</block>
  <block id="cf6cfd37577ec3f1cc20caa7fb10bd45" category="cell">지원되는 최소 바인딩 레벨입니다. Cloud Volumes Service는 LDAP 바인딩에 컴퓨터 계정을 사용하고 Active Directory는 기본적으로 익명 바인딩을 지원하지 않으므로 이 옵션은 보안을 위해 사용되지 않습니다.</block>
  <block id="7079c72c21415131774625ba1d64f4b0" category="cell">익명</block>
  <block id="58384d924f3205aaac5f4a09d3b33801" category="cell">DN 바인딩</block>
  <block id="4d73cec492ef07eaddad38a4a553639d" category="cell">단순 바인딩이 사용될 때 바인딩에 사용되는 사용자/고유 이름(DN)입니다. Cloud Volumes Service는 LDAP 바인딩에 시스템 계정을 사용하며 현재 단순 바인딩 인증을 지원하지 않습니다.</block>
  <block id="6c22befafec962f5002017b68e639f92" category="cell">기본 DN</block>
  <block id="413689794b4599826344869870d6e0a7" category="cell">LDAP 검색에 사용되는 기본 DN입니다.</block>
  <block id="796658213567ec39e68bd43e48ac6eff" category="cell">Windows 도메인이 DN 형식(즉, DC=domain, DC=local)으로 Active Directory 연결에 사용됩니다.</block>
  <block id="30e8b85f236e0c0e7b13a8a98bd46d6f" category="cell">기본 검색 범위</block>
  <block id="26cbec2c997dd79e69cd5279817c5506" category="cell">기본 DN 검색에 대한 검색 범위입니다. 값은 기본, onelevel 또는 하위 트리를 포함할 수 있습니다. Cloud Volumes Service는 하위 트리 검색만 지원합니다.</block>
  <block id="187c471e7dfcb7890077311c532fffd0" category="cell">하위 트리</block>
  <block id="de20d00fd9f0840e6c05dce6aca169e4" category="cell">사용자 DN</block>
  <block id="4ddd431d35193d0d6dc9555aeecf86e1" category="cell">사용자가 LDAP 쿼리를 검색하는 DN을 정의합니다. 현재 Cloud Volumes Service에서는 지원되지 않으므로 모든 사용자 검색은 기본 DN에서 시작됩니다.</block>
  <block id="389048eda41eb7c0e810c83269814943" category="cell">사용자 검색 범위</block>
  <block id="0c5e0f35296916ccacc860481c53c663" category="cell">사용자 DN 검색에 대한 검색 범위입니다. 값은 기본, onelevel 또는 하위 트리를 포함할 수 있습니다. Cloud Volumes Service는 사용자 검색 범위 설정을 지원하지 않습니다.</block>
  <block id="68a7f97c57468e034a3f8016831c3c54" category="cell">그룹 DN</block>
  <block id="5874ce023df38d8485da62d095f714f5" category="cell">그룹 검색이 LDAP 쿼리를 시작하는 DN을 정의합니다. 현재 Cloud Volumes Service에 대해 지원되지 않으므로 모든 그룹 검색이 기본 DN에서 시작됩니다.</block>
  <block id="c76b264e7f1c2aadf6b61ca4a7b9dc52" category="cell">그룹 검색 범위</block>
  <block id="2d21b088cabd39a7f25a62fc99148f20" category="cell">그룹 DN 검색에 대한 검색 범위입니다. 값은 기본, onelevel 또는 하위 트리를 포함할 수 있습니다. Cloud Volumes Service는 그룹 검색 범위 설정을 지원하지 않습니다.</block>
  <block id="9819b4f0996b3e603488836501e3318e" category="cell">넷그룹 DN입니다</block>
  <block id="b5e1f3448b6d3c978f83c2d3d12a2d1e" category="cell">넷그룹이 LDAP 쿼리를 검색하는 DN을 정의합니다. 현재 Cloud Volumes Service에 대해 지원되지 않으므로 모든 넷그룹 검색은 기본 DN에서 시작됩니다.</block>
  <block id="de25b155c30a2cba210598b604a5b8c8" category="cell">넷그룹 검색 범위입니다</block>
  <block id="334dde86dbe71e59b3c942c6a2384d70" category="cell">넷그룹 DN 검색에 대한 검색 범위입니다. 값은 기본, onelevel 또는 하위 트리를 포함할 수 있습니다. Cloud Volumes Service에서는 넷그룹 검색 범위 설정을 지원하지 않습니다.</block>
  <block id="e2bdddbf27283c0eca38d39759107a44" category="cell">LDAP를 통해 start_tls를 사용합니다</block>
  <block id="24788f1c660aa47d895fa832d61d2fcf" category="cell">포트 389를 통한 인증서 기반 LDAP 연결에 Start TLS를 활용합니다. 현재 Cloud Volumes Service에서 지원되지 않습니다.</block>
  <block id="cb64fc71803a6196ec2185116e525243" category="cell">Netgroup-by-host 조회를 설정합니다</block>
  <block id="d92aed09a16438d9bc4cf2735e54815f" category="cell">넷그룹을 확장하여 모든 구성원을 나열하는 대신 호스트 이름별로 넷그룹 조회를 설정합니다. 현재 Cloud Volumes Service에서 지원되지 않습니다.</block>
  <block id="ae1e3e9f0f050830d9ad4ff1441a4080" category="cell">Netgroup-by-host DN입니다</block>
  <block id="6dc9eeb7bc11f937a1c509e27237db6f" category="cell">넷그룹별 검색이 LDAP 쿼리를 시작하는 DN을 정의합니다. Cloud Volumes Service에 대해 현재 호스트별 넷그룹이 지원되지 않습니다.</block>
  <block id="0b5200ff3b38841dd95a404d7e6ff385" category="cell">Netgroup-by-host 검색 범위입니다</block>
  <block id="4ce621e884478e7fc52e17ed91eed525" category="cell">Netgroup-by-host DN 검색에 대한 검색 범위입니다. 값은 기본, onelevel 또는 하위 트리를 포함할 수 있습니다. Cloud Volumes Service에 대해 현재 호스트별 넷그룹이 지원되지 않습니다.</block>
  <block id="19a0fc26f19842a9f7bc78040d0c381c" category="cell">클라이언트 세션 보안</block>
  <block id="16ed23b379774b2be1797f8efa0fe9a5" category="cell">LDAP 조회 추적</block>
  <block id="a408a02f7b8e36f4913d8dc2debb2b95" category="cell">여러 LDAP 서버를 사용하는 경우 조회 추적을 통해 첫 번째 서버에서 항목을 찾을 수 없을 때 클라이언트가 목록의 다른 LDAP 서버를 참조할 수 있습니다. 현재 Cloud Volumes Service에서는 지원되지 않습니다.</block>
  <block id="5f362229a019eb903f4b21e28b15a1f5" category="cell">그룹 구성원 필터</block>
  <block id="55ad576cc6cd581d8a2f558d69828312" category="cell">LDAP 서버에서 그룹 구성원을 검색할 때 사용할 사용자 지정 LDAP 검색 필터를 제공합니다. 현재 Cloud Volumes Service에서는 지원되지 않습니다.</block>
  <block id="b735835c02ee9b8eba41846beea27bc6" category="section-title">비대칭 이름 매핑에 LDAP를 사용합니다</block>
  <block id="10d248b3ae3729560e0f9f75ff23f70e" category="paragraph">Cloud Volumes Service는 기본적으로 특별한 구성 없이 양방향으로 동일한 사용자 이름을 가진 Windows 사용자와 UNIX 사용자를 매핑합니다. Cloud Volumes Service가 유효한 UNIX 사용자(LDAP 사용)를 찾을 수 있는 한 1:1 이름 매핑이 발생합니다. 예를 들어, 윈도우 사용자인 ‘johnsmith’를 사용하는 경우, Cloud Volumes Service가 LDAP에서 johnsmith라는 UNIX 사용자를 찾을 수 있다면, 해당 사용자에 대한 이름 매핑이 성공하면, johnsmith로 생성된 모든 파일/폴더에 올바른 사용자 소유권이 표시됩니다. 또한 사용 중인 NAS 프로토콜에 관계없이 "johnsmith"에 영향을 주는 모든 ACL이 적용됩니다. 이것을 대칭 이름 매핑이라고 합니다.</block>
  <block id="a4e6c429f8e2b5bc009025d9469cd6bd" category="paragraph">비대칭 이름 매핑은 Windows 사용자 및 UNIX 사용자 ID가 일치하지 않는 경우를 나타냅니다. 예를 들어, 윈도우 사용자인 주스미스(jsmith)가 유닉스의 ID를 갖고 있다면, Cloud Volumes Service는 그 변이에 대한 정보를 얻을 수 있는 방법이 필요합니다. Cloud Volumes Service는 현재 정적 이름 매핑 규칙 생성을 지원하지 않으므로, LDAP를 사용하여 Windows 및 UNIX ID 모두의 사용자 ID를 조회하여 파일 및 폴더의 올바른 소유권과 예상되는 권한을 확인해야 합니다.</block>
  <block id="159e0e9db457fce00641b7a639cdfef9" category="paragraph">기본적으로 Cloud Volumes Service는 이름 맵 데이터베이스 인스턴스의 ns-switch에 LDAP를 포함하므로 비대칭 이름에 LDAP를 사용하여 이름 매핑 기능을 제공하려면 Cloud Volumes Service의 모양을 반영하기 위해 일부 사용자/그룹 속성만 수정하면 됩니다.</block>
  <block id="5083578eb1523417a04b030704e11a97" category="paragraph">다음 표에서는 비대칭 이름 매핑 기능을 위해 LDAP에 채워야 하는 특성을 보여 줍니다. 대부분의 경우 Active Directory는 이미 이 작업을 수행하도록 구성되어 있습니다.</block>
  <block id="2e4b53007a09bf23d9111917c46d1902" category="cell">Cloud Volumes Service 특성입니다</block>
  <block id="009097a0950f2d6565c2cb446aa081dd" category="cell">Cloud Volumes Service에서 이름 매핑에 사용하는 값입니다</block>
  <block id="df642bb30c436da15b0b74923cb45806" category="cell">Windows에서 UNIX로의 객체 클래스</block>
  <block id="75f68f87af42701b9e548f875f39cefe" category="cell">사용 중인 개체의 형식을 지정합니다. (즉, 사용자, 그룹, posixAccount 등)</block>
  <block id="2b731e8ed189a8b7587c21b21d6620cf" category="cell">사용자를 포함해야 합니다(필요한 경우 다른 값을 여러 개 포함할 수 있음).</block>
  <block id="288eebd1d2cddc03953f475edbcb2d5f" category="cell">Windows에서 UNIX로의 속성</block>
  <block id="1b356493e583b25fdd7b1e44d6a4df0d" category="cell">그러면 생성 시 Windows 사용자 이름이 정의됩니다. Cloud Volumes Service는 Windows에서 UNIX로의 조회에 이 기능을 사용합니다.</block>
  <block id="5ce0ca6d681fede8d46460fed64bf8ef" category="cell">여기에서 변경할 필요가 없습니다. sAMAccountName은 Windows 로그인 이름과 동일합니다.</block>
  <block id="e7d22294bdcb7133967c3548ece982e5" category="cell">UID</block>
  <block id="d93b9102027ae26f7bbfa53ff0cd3f28" category="cell">UNIX 사용자 이름을 정의합니다.</block>
  <block id="abd2101078216980cdcf2dc6f87172b9" category="cell">원하는 UNIX 사용자 이름입니다.</block>
  <block id="78e7065e65f76fc53c1953f598d424de" category="paragraph">Cloud Volumes Service는 현재 LDAP 조회에서 도메인 접두사를 사용하지 않으므로 LDAP 이름 맵 조회에서 여러 도메인 LDAP 환경이 제대로 작동하지 않습니다.</block>
  <block id="1a19ad8ba3f26bc83d40bf699210c5b3" category="paragraph">다음 예에서는 Windows 이름 "비대칭", UNIX 이름 "UNIX-user"를 가진 사용자와 SMB 및 NFS에서 파일을 쓸 때 나타나는 동작을 보여 줍니다.</block>
  <block id="cf613896f3bf97cfe22b19367188faac" category="paragraph">다음 그림에서는 LDAP 특성이 Windows 서버에서 어떻게 표시되는지 보여 줍니다.</block>
  <block id="bb859b3ee7438471d7bd0441aec37b09" category="paragraph"><block ref="bb859b3ee7438471d7bd0441aec37b09" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74a3bb1b92afc37821849f4d2c6a2e08" category="paragraph">NFS 클라이언트에서 UNIX 이름을 쿼리할 수 있지만 Windows 이름은 쿼리할 수 없습니다.</block>
  <block id="9a9b54fd5d17009b1290538bd0bea332" category="paragraph">NFS에서 UNIX-USER로 파일을 쓸 때 NFS 클라이언트의 결과는 다음과 같습니다.</block>
  <block id="2d78fc711a4a8afa3553c40cb81a7f5a" category="paragraph">Windows 클라이언트에서 파일 소유자가 올바른 Windows 사용자로 설정되어 있는지 확인할 수 있습니다.</block>
  <block id="dd276babf175f2baaf7d31c63630e9ce" category="paragraph">반대로, SMB 클라이언트에서 Windows 사용자 '비대칭'으로 생성된 파일은 다음 텍스트에서와 같이 적절한 UNIX 소유자를 표시합니다.</block>
  <block id="840e343f2946d2e3ecafb4d3af6751c5" category="paragraph">SMB:</block>
  <block id="7369fcede1216c5a449bffa4016f597a" category="paragraph">NFS:</block>
  <block id="1a2ced64ce54d0878867c66c1264ef73" category="section-title">LDAP 채널 바인딩</block>
  <block id="7bc3122060898b084ade9ae81cb840d5" category="inline-link">Microsoft 보안 권고 ADV190023</block>
  <block id="9c2bd50d1c3b17373f80735ce60e0d91" category="paragraph">Windows Active Directory 도메인 컨트롤러의 취약점으로 인해<block ref="9230172696f08489abbbe06ad2878984" category="inline-link-rx"></block> DC에서 LDAP 바인드를 허용하는 방법을 변경합니다.</block>
  <block id="c389bcb5002ce56cb9cf28680eb6ff4c" category="paragraph">Cloud Volumes Service에 미치는 영향은 모든 LDAP 클라이언트와 동일합니다. Cloud Volumes Service는 현재 채널 바인딩을 지원하지 않습니다. Cloud Volumes Service는 협상을 통해 기본적으로 LDAP 서명을 지원하므로 LDAP 채널 바인딩은 문제가 되지 않습니다. 채널 바인딩이 설정된 LDAP에 바인딩하는 데 문제가 있는 경우 ADV190023의 개선 단계를 수행하여 Cloud Volumes Service에서 LDAP 바인딩이 성공하도록 허용합니다.</block>
  <block id="ed5f2bdecbd4bd349d09412d1ff6a6fb" category="section-title">DNS</block>
  <block id="8cc300201cbc74e712f45393efb60e69" category="inline-link">다이나믹 DNS</block>
  <block id="80052c998ef6da49a98a2d9004c75c33" category="paragraph">Active Directory와 Kerberos 모두 호스트 이름 대 IP/IP 대 호스트 이름 확인에 대한 DNS에 대한 종속성을 가집니다. DNS를 열려면 포트 53이 열려 있어야 합니다. Cloud Volumes Service는 DNS 레코드를 수정하지 않으며 현재 의 사용을 지원하지 않습니다<block ref="2df544fb17221302fef729d1eb6bd715" category="inline-link-rx"></block> 네트워크 인터페이스.</block>
  <block id="5f36386498075ef9c05d674112b69981" category="inline-link">Windows DNS 보안</block>
  <block id="e3aa134886f9dad39f14489844fe7763" category="paragraph">DNS 레코드를 업데이트할 수 있는 서버를 제한하도록 Active Directory DNS를 구성할 수 있습니다. 자세한 내용은 을 참조하십시오<block ref="1abda701cc77717e0b1a0b391ec2fed8" category="inline-link-rx"></block>.</block>
  <block id="e8ba0470f4bd2498fbecdead3ab1b183" category="paragraph">Google 프로젝트 내의 리소스는 기본적으로 Active Directory DNS와 연결되지 않은 Google Cloud DNS를 사용합니다. 클라우드 DNS를 사용하는 클라이언트는 Cloud Volumes Service에서 반환하는 UNC 경로를 확인할 수 없습니다. Active Directory 도메인에 참가한 Windows 클라이언트는 Active Directory DNS를 사용하도록 구성되어 있으며 이러한 UNC 경로를 확인할 수 있습니다.</block>
  <block id="71870bac7a9267067ab69566f75d36c3" category="inline-link">클라이언트가 SMB NetBIOS 이름을 확인할 수 없는 이유는 무엇입니까?</block>
  <block id="b0ffc266c9e05cd7ae80810305b932bf" category="paragraph">Active Directory에 클라이언트를 연결하려면 Active Directory DNS를 사용하도록 해당 DNS 구성을 구성해야 합니다. 필요에 따라 Active Directory DNS로 요청을 전달하도록 Cloud DNS를 구성할 수 있습니다. 을 참조하십시오<block ref="d568657413aac86de4b237a9edcddc2d" category="inline-link-rx"></block>를 참조하십시오.</block>
  <block id="a0c7db04deaabb45ee60d5a501e67eb8" category="admonition">Cloud Volumes Service는 현재 DNSSEC를 지원하지 않으며 DNS 쿼리는 일반 텍스트로 수행됩니다.</block>
  <block id="c3a18bc4fd14cf11bc551540f29f6375" category="section-title">파일 액세스 감사</block>
  <block id="cc6e776769986190d1536969ad7e5307" category="paragraph">현재 Cloud Volumes Service에서 지원되지 않습니다.</block>
  <block id="5cffe1f133f0ed3a472da05d0b1d3f0d" category="section-title">안티바이러스 보호</block>
  <block id="2b91875198ddd07e9b4cff7f1fe46663" category="paragraph">클라이언트의 Cloud Volumes Service에서 NAS 공유에 대한 바이러스 백신 검사를 수행해야 합니다. 현재 Cloud Volumes Service와 통합된 기본 바이러스 백신이 없습니다.</block>
  <block id="f0e8b8e3bd62a1e919cd1935e44bf79c" category="inline-link-macro">다음: 서비스 작업.</block>
  <block id="fba0107176535938bcee4c0774160668" category="paragraph"><block ref="fba0107176535938bcee4c0774160668" category="inline-link-macro-rx"></block></block>
  <block id="fd7d290d66c64aa2fc13dd9bbca9c540" category="summary">Cloud Volumes Service는 적절한 액세스 권한을 유지하면서 동일한 데이터 세트를 SMB 및 NFS 클라이언트 모두에 공유할 수 있는 기능을 제공합니다. 이중 프로토콜 이는 프로토콜 간 ID 매핑을 조정하고 중앙 집중식 백엔드 LDAP 서버를 사용하여 Cloud Volumes Service에 UNIX ID를 제공하는 방식으로 수행됩니다. Windows Active Directory를 사용하여 Windows 및 UNIX 사용자를 모두 편리하게 제공할 수 있습니다.</block>
  <block id="d27d01220b09abd6dc8be87dd2b7f8d4" category="doc">이중 프로토콜/멀티프로토콜</block>
  <block id="8c14d6d170254470aea76e2185e26901" category="inline-link-macro">이전: SMB.</block>
  <block id="692e0ebc2797e7ae1a9618bdac0b5c02" category="paragraph"><block ref="692e0ebc2797e7ae1a9618bdac0b5c02" category="inline-link-macro-rx"></block></block>
  <block id="9a5ba82ef925964774fad34d380585ce" category="inline-link">이중 프로토콜</block>
  <block id="afbf550dbb927e70d6e5e81aba4cf54e" category="paragraph">Cloud Volumes Service는 적절한 액세스 권한을 유지하면서 동일한 데이터 세트를 SMB 및 NFS 클라이언트 모두에 공유할 수 있는 기능을 제공합니다 <block ref="090248040bf8d7cbf59e0f5bcb2aeb23" category="inline-link-rx"></block>)를 클릭합니다. 이는 프로토콜 간 ID 매핑을 조정하고 중앙 집중식 백엔드 LDAP 서버를 사용하여 Cloud Volumes Service에 UNIX ID를 제공하는 방식으로 수행됩니다. Windows Active Directory를 사용하여 Windows 및 UNIX 사용자를 모두 편리하게 제공할 수 있습니다.</block>
  <block id="65bd83537129be15c8027ec94bec5bd3" category="section-title">액세스 제어</block>
  <block id="b481dc764d87d694bd99e41051212b98" category="inline-link-macro">"로컬/BUILTIN 관리자/백업 권한이 있는 계정."</block>
  <block id="4349221797619aa2539cd1d814d55cf3" category="inline-link">MMC/컴퓨터 관리</block>
  <block id="ab67de3b2d37b16da324871c9cd7f96b" category="list-text">* 공유 액세스 제어. * NAS 공유에 액세스할 수 있는 클라이언트 및/또는 사용자 및 그룹을 결정합니다. NFS의 경우 엑스포트 정책과 규칙을 사용하여 클라이언트 엑스포트 액세스를 제어합니다. NFS 내보내기는 Cloud Volumes Service 인스턴스에서 관리됩니다. SMB는 CIFS/SMB 공유를 사용하고 ACL을 공유하여 사용자 및 그룹 레벨에서 보다 세부적인 제어를 제공합니다. 을 사용하여 SMB 클라이언트의 공유 레벨 ACL만 구성할 수 있습니다<block ref="dbc4cec831b164bbb509e51caacd0209" category="inline-link-rx"></block> Cloud Volumes Service 인스턴스에 대한 관리자 권한이 있는 계정(섹션 참조) <block ref="c9946e41ec7364b03516e2beacd1b339" category="inline-link-macro-rx"></block>)를 클릭합니다.</block>
  <block id="1020ac8238c0e64a401514745b8a3c6a" category="list-text">* 파일 액세스 제어. * 파일 또는 폴더 수준에서 권한을 제어하고 항상 NAS 클라이언트에서 관리합니다. NFS 클라이언트는 기존 모드 비트(rwx) 또는 NFSv4 ACL을 사용할 수 있습니다. SMB 클라이언트는 NTFS 권한을 활용합니다.</block>
  <block id="dcfd17a407b936210845de342300e631" category="paragraph">NFS와 SMB 모두에 데이터를 제공하는 볼륨의 액세스 제어는 사용 중인 프로토콜에 따라 다릅니다. 이중 프로토콜의 사용 권한에 대한 자세한 내용은 “ 절을 참조하십시오<block ref="7251f6a3aba1b22d43e125a8c39f6f0a" category="inline-xref-macro-rx"></block>.”</block>
  <block id="20d918db09dacfd5fbfbaadfaede2f80" category="section-title">사용자 매핑</block>
  <block id="c9677302c2548820abda217b496a541b" category="paragraph">클라이언트가 볼륨에 액세스하면 Cloud Volumes Service는 들어오는 사용자를 반대 방향으로 유효한 사용자에게 매핑하려고 시도합니다. 이는 프로토콜 간에 적절한 액세스를 결정하고 액세스를 요청하는 사용자가 실제로 자신이 주장하는 사용자인지 확인하기 위해 필요합니다.</block>
  <block id="7e9b11fc569fee58c3b42b689df2fbec" category="paragraph">예를 들어, "joe"라는 Windows 사용자가 SMB를 통해 UNIX 사용 권한이 있는 볼륨에 액세스하려고 하면 Cloud Volumes Service는 검색을 수행하여 "joe"라는 해당 UNIX 사용자를 찾습니다. 이 파일이 있으면 Windows 사용자 Joe로 SMB 공유에 기록되는 파일이 NFS 클라이언트의 UNIX 사용자 Joe로 나타납니다.</block>
  <block id="b9e4f77748fb373f23ad2bc9eb2d3de0" category="paragraph">또는 UNIX 사용자인 "Joe"가 Windows 사용 권한이 있는 Cloud Volumes Service 볼륨에 대한 액세스를 시도할 경우 UNIX 사용자는 유효한 Windows 사용자에게 매핑할 수 있어야 합니다. 그렇지 않으면 볼륨에 대한 액세스가 거부됩니다.</block>
  <block id="98b9b81e4ad07f5198dd8381a0c5d43c" category="inline-link">AD 연결을 생성하는 중입니다</block>
  <block id="d6210f83492bb730b32d0e719a1d5100" category="paragraph">현재 LDAP를 사용하는 외부 UNIX ID 관리에는 Active Directory만 지원됩니다. 이 서비스에 대한 액세스 구성에 대한 자세한 내용은 을 참조하십시오<block ref="cfe0f81fca904ab10d3dcbbfceb0f3de" category="inline-link-rx"></block>.</block>
  <block id="7fc7c5bf3cd7f453807f2e17dc846957" category="section-title">권한 모델</block>
  <block id="94b74cdf7c7dc9ef00fc04cf642127d9" category="paragraph">이중 프로토콜 설정을 사용하는 경우 Cloud Volumes Service는 볼륨에 대한 보안 스타일을 사용하여 ACL 유형을 결정합니다. 이러한 보안 스타일은 지정된 NAS 프로토콜을 기반으로 설정되거나, 이중 프로토콜의 경우 Cloud Volumes Service 볼륨 생성 시 선택하는 것입니다.</block>
  <block id="b3544688f5ad40244fc991f13471c525" category="list-text">NFS만 사용하는 경우 Cloud Volumes Service 볼륨은 UNIX 사용 권한을 사용합니다.</block>
  <block id="95b899e9e3d21a94ae7e8ce04eac3bb3" category="list-text">SMB만 사용하는 경우 Cloud Volumes Service 볼륨은 NTFS 권한을 사용합니다.</block>
  <block id="51c16477dee3c257c4930e8614eda5ba" category="paragraph">이중 프로토콜 볼륨을 생성하는 경우 볼륨 생성 시 ACL 스타일을 선택할 수 있습니다. 이 결정은 원하는 권한 관리를 기반으로 해야 합니다. 사용자가 Windows/SMB 클라이언트의 권한을 관리하는 경우 NTFS 를 선택합니다. 사용자가 NFS 클라이언트 및 chmod/chown을 사용하려는 경우 UNIX 보안 스타일을 사용합니다.</block>
  <block id="fd859db4ea28a81227f07e2c125fc927" category="inline-link-macro">다음: Active Directory 연결 생성 시 고려 사항</block>
  <block id="bc695a7a8573373413beec401ab691e1" category="paragraph"><block ref="bc695a7a8573373413beec401ab691e1" category="inline-link-macro-rx"></block></block>
  <block id="451abeb07875465ff669fc3bfc502564" category="summary">특히, 인프라가 스토리지 관리자의 제어 범위를 벗어난 클라우드의 경우 보안은 데이터를 클라우드 공급자가 제공하는 서비스 제공에 맡기는 것이 무엇보다 중요합니다. 이 문서는 NetApp Cloud Volumes Service이 Google Cloud에 제공하는 보안 제품에 대한 개요입니다.</block>
  <block id="85f174d487aef272a0a9ea0f980e4827" category="doc">TR-4918: 보안 개요 - Google Cloud의 NetApp Cloud Volumes Service</block>
  <block id="09f7873d6f07efaef82aef2b95f42e0a" category="paragraph">Oliver Krause, Justin Parisi, NetApp</block>
  <block id="1e06922fd676ae97f9dc69dbbfc93992" category="section-title">문서 범위</block>
  <block id="c2f1a37c5b3a149d2e79ad5a41c86139" category="inline-link">Cloud Volumes Service는 Google Cloud에서 제공합니다</block>
  <block id="c2197b5184a5af948e5dc6e6dcf6e5c3" category="paragraph">특히, 인프라가 스토리지 관리자의 제어 범위를 벗어난 클라우드의 경우 보안은 데이터를 클라우드 공급자가 제공하는 서비스 제공에 맡기는 것이 무엇보다 중요합니다. 이 문서는 NetApp의 보안 제품에 대한 개요입니다<block ref="b29f7971c7793aea2bb4311fa5c38ee0" category="inline-link-rx"></block>.</block>
  <block id="f2b84afd0523a6df7547c404aa3647d8" category="section-title">대상</block>
  <block id="75ff467aeacdad8bd3ed9fe31431d022" category="paragraph">이 문서의 대상 고객은 다음과 같은 역할을 포함하지만 이에 국한되지 않습니다.</block>
  <block id="3487d2ed085064f5b68318d25038bcd6" category="list-text">설명합니다</block>
  <block id="203ea32883f92321782cc1a312345903" category="list-text">스토리지 관리자</block>
  <block id="7e89bd35a6b8558a95e9e4ec446df00d" category="list-text">스토리지 설계자</block>
  <block id="528efe83de18ec1cf2eb982cc641bb89" category="list-text">현장 리소스</block>
  <block id="a6205b388d7b872550efc1a57461e045" category="list-text">비즈니스 의사 결정자</block>
  <block id="d9a404dc3c51a0dfc2360a6f7f97c00c" category="inline-link-macro">“문의하기”</block>
  <block id="ec45e675f8dd5d470d6edacfc9ac6a2d" category="paragraph">이 기술 보고서의 내용에 대해 궁금한 점이 있으면 섹션을 참조하십시오 <block ref="bbd2d7f57ba5e479a6b271845e2b7ec0" category="inline-link-macro-rx"></block></block>
  <block id="b54d58d7e43c404563f91e38d3efbcac" category="cell">약어</block>
  <block id="0b890b1926b90387673882e6ccae7fdc" category="cell">정의</block>
  <block id="e898e7a5df4dec909ad011657b510e2d" category="cell">CVS-SW</block>
  <block id="3b558136fa0b6447d030d5fd2d28765b" category="cell">Cloud Volumes Service, 서비스 유형 CVS</block>
  <block id="439d7969e09b4b31626fcf209b8fdcb7" category="cell">CVS - 성능</block>
  <block id="3da305112390b1f2d5e6ad8818e00065" category="cell">클라우드 볼륨 서비스, 서비스 유형 CVS - 성능</block>
  <block id="041159b903daf7d5923837346de98407" category="cell">PSA</block>
  <block id="eb2108209f61048e4b7ebba4b61f91ee" category="inline-link-macro">다음: Google Cloud의 Cloud Volumes Service로 데이터를 보호하는 방법</block>
  <block id="4c9538193c211d1d025b959f6407da23" category="paragraph"><block ref="4c9538193c211d1d025b959f6407da23" category="inline-link-macro-rx"></block></block>
  <block id="60298c0c8282022dec640948e48114c1" category="summary">Cloud Volumes Service 팀은 Google Cloud에서 백엔드 서비스를 관리하고 여러 전략을 사용하여 플랫폼을 보호하고 원치 않는 액세스를 방지합니다.</block>
  <block id="d5558f87207ef258cc599e6b4f31fa1f" category="doc">서비스 작업</block>
  <block id="23fa70110ac44a6aa038c42f52919e60" category="inline-link-macro">이전: 기타 NAS 인프라스트럭처 서비스 종속성(KDC, LDAP, DNS)</block>
  <block id="09db248feade063e1b222ff7a6fa8bae" category="paragraph"><block ref="09db248feade063e1b222ff7a6fa8bae" category="inline-link-macro-rx"></block></block>
  <block id="01f3694459a5570182960c35de3adea0" category="paragraph">각 고객은 기본적으로 다른 고객으로부터 액세스 펜싱된 고유한 서브넷을 받게 되며, Cloud Volumes Service의 모든 테넌트는 전체 데이터 격리를 위한 고유한 네임스페이스와 VLAN을 갖게 됩니다. 사용자가 인증되면 SDE(Service Delivery Engine)는 해당 테넌트와 관련된 구성 데이터만 읽을 수 있습니다.</block>
  <block id="3efd389b601ec82d2d3d7d1fe8c7a952" category="section-title">물리적 보안</block>
  <block id="e6cbbd1872a42cfa36ceca16da55e6af" category="paragraph">적절한 사전 승인을 받은 경우, 현장 엔지니어와 NetApp 내부 현장 지원 엔지니어(FSE)만 물리적 작업을 위한 케이지 및 랙에 액세스할 수 있습니다. 스토리지 및 네트워크 관리는 허용되지 않습니다. 이러한 현장 리소스만 하드웨어 유지 관리 작업을 수행할 수 있습니다.</block>
  <block id="f4cc7ff420af18ead26b06b01e65be30" category="paragraph">현장 엔지니어의 경우 랙 ID 및 장치 위치(RU)가 포함된 SOW(Statement of Work)에 대한 티켓이 발행되고 기타 모든 세부 정보가 티켓에 포함됩니다. NetApp FSE의 경우 COLO를 통해 사이트 방문 티켓을 제기해야 하며 티켓에는 감사 목적을 위한 방문자의 세부 정보, 날짜 및 시간이 포함됩니다. FSE용 SOW는 내부적으로 NetApp에 전달됩니다.</block>
  <block id="e6da80db21921cfa31a2ec8ae71c8a44" category="section-title">운영팀</block>
  <block id="575c886f27b4fd6adbc422b9466a7d77" category="paragraph">Cloud Volumes Service의 운영 팀은 운영 엔지니어링과 SRE(Site Reliability Engineer)로 구성되며, 클라우드 볼륨 서비스를 위한 NetApp 현장 지원 엔지니어 및 파트너는 하드웨어에 대해 구성됩니다. 모든 운영 팀 구성원은 Google Cloud에서 작업할 수 있도록 인증되었으며, 제기된 모든 티켓에 대해 자세한 작업 기록이 유지됩니다. 또한 엄격한 변경 관리 및 승인 프로세스를 통해 각 결정이 적절하게 검토되는지 확인할 수 있습니다.</block>
  <block id="62b92b1afcd6e99ad8ef6fc6e66fe1c6" category="paragraph">SRE 팀은 컨트롤 플레인을 관리하고 데이터가 UI 요청에서 백엔드 하드웨어 및 Cloud Volumes Service 소프트웨어로 라우팅되는 방식을 관리합니다. SRE 팀은 또한 볼륨 및 inode 최대값과 같은 시스템 리소스를 관리합니다. SRE는 고객 데이터와 상호 작용하거나 고객 데이터에 액세스할 수 없습니다. 또한 SRE는 백엔드 하드웨어에 대한 새 디스크 또는 메모리 교체 요청과 같은 RMA(Return Material Authorizations)와 함께 조정을 제공합니다.</block>
  <block id="20ac318b6aafb241498518b27a204f2d" category="section-title">고객의 책임</block>
  <block id="5b18708f6a9b76d94aad073287e9c4aa" category="paragraph">Cloud Volumes Service 고객은 조직의 Active Directory 및 사용자 역할 관리와 볼륨 및 데이터 작업을 관리합니다. 고객은 NetApp과 Google Cloud(관리자 및 뷰어)가 제공하는 두 가지 사전 정의된 역할을 사용하여 관리 역할을 수행하고 동일한 Google Cloud 프로젝트 내의 다른 최종 사용자에게 권한을 위임할 수 있습니다.</block>
  <block id="70612d623f8ac2ccbad1aa9289e54eb2" category="paragraph">관리자는 고객 프로젝트 내의 모든 VPC를 고객이 적절하다고 판단한 Cloud Volumes Service에 연결할 수 있습니다. 고객은 Google Cloud Marketplace 구독에 대한 액세스를 관리하고 데이터 평면에 액세스할 수 있는 VPC를 관리해야 합니다.</block>
  <block id="1e9614b8d81927a9e9bad94fe64884d6" category="section-title">악성 SRE 보호</block>
  <block id="1ced9b3b1b2408070d8594c7310def52" category="paragraph">악성 SRE가 있거나 SRE 자격 증명이 손상된 경우 Cloud Volumes Service가 이를 어떻게 보호합니까?</block>
  <block id="0cf58dc2d9a00ecaeb191e61685b36e5" category="paragraph">운영 환경에 대한 액세스는 제한된 수의 SRE 사용자만 가능합니다. 관리 권한은 소수의 숙련된 관리자에게만 더욱 제한됩니다. Cloud Volumes Service 운영 환경의 모든 작업이 기록되고 기준 또는 의심스러운 활동에 대한 모든 이상 사항은 SIEM(Security Information and Event Management) 위협 인텔리전스 플랫폼에서 탐지됩니다. 따라서 Cloud Volumes Service 백엔드에 너무 많은 손상이 발생하기 전에 악의적인 작업을 추적하고 완화할 수 있습니다.</block>
  <block id="9893b21aa64e031fdfd6920fef8147a3" category="section-title">볼륨 수명 주기</block>
  <block id="1135939baa7babe550972f3d2430315f" category="paragraph">Cloud Volumes Service는 볼륨 내의 데이터가 아니라 서비스 내의 객체만 관리합니다. 볼륨에 액세스하는 클라이언트만 데이터, ACL, 파일 소유자 등을 관리할 수 있습니다. 이러한 볼륨의 데이터는 유휴 상태로 암호화되며 액세스는 Cloud Volumes Service 인스턴스 테넌트로 제한됩니다.</block>
  <block id="dd04bd242a373a0c9b066d0704ba4d66" category="paragraph">Cloud Volumes Service의 볼륨 라이프사이클은 create-update-delete입니다. 볼륨은 볼륨이 삭제될 때까지 볼륨의 스냅샷 복사본을 유지하며, 검증된 Cloud Volumes Service 관리자만 Cloud Volumes Service의 볼륨을 삭제할 수 있습니다. 관리자가 볼륨 삭제를 요청하는 경우 삭제를 확인하려면 볼륨 이름을 추가로 입력해야 합니다. 볼륨이 삭제된 후에는 볼륨이 사라지고 복구할 수 없습니다.</block>
  <block id="1744c1e09f5b1b7990b7f2b80a7a9500" category="paragraph">Cloud Volumes Service 계약이 종료된 경우 NetApp은 특정 기간 이후에 삭제할 볼륨을 표시합니다. 이 기간이 만료되기 전에 고객의 요청에 따라 볼륨을 복구할 수 있습니다.</block>
  <block id="13e637fe96062929286b911c16b3c2df" category="section-title">인증</block>
  <block id="af06a002abcc2b02896192d8fd1052cd" category="inline-link">규정 준수: 데이터 보안 및 데이터 개인 정보 보호</block>
  <block id="258a58248bd2280e3d97717c4150b3cf" category="paragraph">Cloud Volumes Services for Google Cloud는 현재 ISO/IEC 27001:2013 및 ISO/IEC 27018:2019 표준에 따라 인증되었습니다. 또한 이 서비스는 최근 SOC2 Type I Attestation 보고서를 받았습니다. 데이터 보안 및 개인 정보 보호에 대한 NetApp의 약속에 대한 자세한 내용은 을 참조하십시오<block ref="751448d9ace7c1569cfa25749b75ea26" category="inline-link-rx"></block>.</block>
  <block id="4e94c8ad46c8aef1ca637841dfbe2159" category="section-title">GDPR을 참조하십시오</block>
  <block id="ee69241049506ca93a3a1cd627e44851" category="inline-link">고객 계약</block>
  <block id="15655a5f67808f893102ffa3cbde3b01" category="inline-link">고객 데이터 처리 부록</block>
  <block id="cd0ae90a69c7d21d42b18252b9e1707d" category="inline-link">표준 계약 조항</block>
  <block id="de315e46a9bdf4936de71254f87d2fe0" category="paragraph">개인 정보 보호 및 GDPR 준수에 대한 NetApp의 약속은 당사의 다양한 규정으로 제공됩니다 <block ref="c2118342007d8714fcb1b4f6106c575c" category="inline-link-rx"></block>있습니다<block ref="7f657124cd056ea8e74c57dcafd4df75" category="inline-link-rx"></block>를 포함합니다 <block ref="85bd1a4ed188bfd53fcaef2fb6e1962a" category="inline-link-rx"></block> 유럽 위원회에서 제공. 또한 NetApp은 개인 정보 보호 정책에 이러한 의무를 이행하며, 이는 기업 행동 강령에 명시된 핵심 가치를 기반으로 합니다.</block>
  <block id="648d64814699b339816911e595b789cd" category="inline-link-macro">다음: 추가 정보, 버전 기록 및 연락처 정보</block>
  <block id="259ea0e5275404f9f6b7793a369cf8d5" category="paragraph"><block ref="259ea0e5275404f9f6b7793a369cf8d5" category="inline-link-macro-rx"></block></block>
  <block id="81e9930d895d3e301d9d41dffc998bf4" category="summary">클라우드 솔루션을 신뢰하는 것은 아키텍처와 보안 방식을 이해하는 것입니다. 이 섹션에서는 Google의 Cloud Volumes Service 아키텍처의 다양한 측면을 다루어 데이터 보안 방식에 대한 잠재적 우려를 완화하고 가장 안전한 배포를 위해 추가 구성 단계가 필요할 수 있는 영역을 설명합니다.</block>
  <block id="cce1d49f67059a9bd1ae8d0bdb0c40c6" category="inline-link-macro">이전: 보안 고려 사항 및 공격 표면</block>
  <block id="64ff582fefc046b48708216a4686161c" category="paragraph"><block ref="64ff582fefc046b48708216a4686161c" category="inline-link-macro-rx"></block></block>
  <block id="e5a9d7217b1490853e4230120cdedb32" category="paragraph">Cloud Volumes Service의 일반 아키텍처는 컨트롤 플레인과 데이터 플레인의 두 가지 주요 구성 요소로 나눌 수 있습니다.</block>
  <block id="650717c72d7a99e6505592f83821e4ed" category="section-title">컨트롤 플레인</block>
  <block id="b2b6e947ec64376b51417e89ab29e213" category="paragraph">Cloud Volumes Service의 제어 플레인은 Cloud Volumes Service 관리자와 NetApp 기본 자동화 소프트웨어가 관리하는 백엔드 인프라입니다. 이 방식은 최종 사용자에게 전혀 영향을 미치지 않으며 네트워킹, 스토리지 하드웨어, 소프트웨어 업데이트 등을 포함하여 Cloud Volumes Service와 같은 클라우드 상주 솔루션에 가치를 제공하는 데 도움을 줍니다.</block>
  <block id="52a0e67f81bfbe486860a8219dfb3707" category="section-title">데이터 플레인</block>
  <block id="9d4d4fccf74cab21d8073077985a0cf6" category="paragraph">Cloud Volumes Service의 데이터 계층에는 실제 데이터 볼륨과 전체 Cloud Volumes Service 구성(액세스 제어, Kerberos 인증 등)이 포함됩니다. 데이터 플레인은 전적으로 최종 사용자와 Cloud Volumes Service 플랫폼 소비자를 제어하는 것입니다.</block>
  <block id="099a80e29da5319c76116b6b2b41b2bf" category="paragraph">각 평면의 보안 및 관리 방법은 서로 다릅니다. 다음 섹션에서는 Cloud Volumes Service 아키텍처 개요부터 이러한 차이점에 대해 설명합니다.</block>
  <block id="69259c19ec0d9503c7d352a664a85953" category="inline-link-macro">다음: Cloud Volumes Service 아키텍처.</block>
  <block id="06ef1ecb5da986ebfb9901831437a0d8" category="paragraph"><block ref="06ef1ecb5da986ebfb9901831437a0d8" category="inline-link-macro-rx"></block></block>
  <block id="9114bfd7ba3e781df4e595c0a3199bfb" category="summary">데이터를 보호하는 방법을 이해하기 위한 첫 번째 단계는 위험 및 잠재적 공격 경로를 식별하는 것입니다.</block>
  <block id="d446619c29484b970941bed7884dfd57" category="doc">보안 고려 사항 및 공격 대상</block>
  <block id="9835bd91d6121b399eb4318f5f6aecab" category="inline-link-macro">이전: Google Cloud의 Cloud Volumes Service로 데이터를 보호하는 방법</block>
  <block id="00bbf283b6d94328be9e19fd69a5e57d" category="paragraph"><block ref="00bbf283b6d94328be9e19fd69a5e57d" category="inline-link-macro-rx"></block></block>
  <block id="da24915274d8feb20f2be6f37c42bb43" category="paragraph">데이터를 보호하는 방법을 이해하기 위한 첫 번째 단계는 위험 및 잠재적 공격 경로를 식별하는 것입니다. 여기에는 다음이 포함됩니다(이에 국한되지 않음).</block>
  <block id="1f48f12466296c53740ed0375b4d0111" category="list-text">관리 및 로그인</block>
  <block id="78b73d10586b526c3f0d3f97bd32dfba" category="list-text">사용되지 않는 데이터</block>
  <block id="42517361027a563c9ab61d813badc939" category="list-text">전송 중인 데이터</block>
  <block id="58be36e591707c2a60f9bed405a8ef25" category="list-text">네트워크 및 방화벽</block>
  <block id="3a7d83d110f5fe7d4f435b9594806caf" category="list-text">랜섬웨어, 맬웨어 및 바이러스</block>
  <block id="417a78919920edf51d22038b236740f1" category="paragraph">공격 경로를 이해하면 환경을 보다 안전하게 보호할 수 있습니다. Google Cloud의 Cloud Volumes Service는 이미 이러한 많은 항목을 고려하고 있으며 관리 개입 없이 기본적으로 보안 기능을 구현합니다.</block>
  <block id="70e43ccaf26985ea09dd44568ea9f36b" category="section-title">보안 로그인 보장</block>
  <block id="67fe2a3de92df4f2c45227cff1adea77" category="paragraph">중요 인프라 구성 요소를 보호할 때는 승인된 사용자만 환경에 로그인하여 관리할 수 있도록 해야 합니다. 공격자들이 관리 자격 증명을 위반하는 경우, 성을 위한 키가 있으며 구성 변경, 볼륨 및 백업 삭제, 백도어 생성, 스냅샷 스케줄 비활성화 등 원하는 모든 작업을 수행할 수 있습니다.</block>
  <block id="3a2f2973e275ef04d08d1dda935f1ee0" category="paragraph">Cloud Volumes Service for Google Cloud는 StaaS(Storage as a Service)의 난독화 기능을 통해 무단 관리 로그인으로부터 보호합니다. Cloud Volumes Service은 외부에서 로그인할 수 없는 상태에서 클라우드 공급자가 완벽하게 유지합니다. 모든 설정 및 구성 작업이 완전히 자동화되므로 매우 드문 경우를 제외하고, 사용자 관리자는 시스템과 상호 작용할 필요가 없습니다.</block>
  <block id="22b01eb5fb8c08ffb16c6ef9ef8b71b6" category="inline-link-macro">“Cloud Volumes Service 아키텍처.”</block>
  <block id="b019d60ff2b9589700c94d2d71d13c8f" category="paragraph">로그인이 필요한 경우, Google Cloud의 Cloud Volumes Service는 시스템에 로그인할 수 있는 매우 간단한 신뢰할 수 있는 관리자 목록을 유지하여 로그인을 보호합니다. 이 가문부수는 액세스 권한이 있는 잠재적 불량 행위자의 수를 줄이는 데 도움이 됩니다. 또한 Google Cloud 네트워킹은 네트워크 보안 계층 뒤에서 시스템을 숨기고 외부 환경에 필요한 것만 노출합니다. Google Cloud, Cloud Volumes Service 아키텍처에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="582157e9744c945cab3000f99e5c51f4" category="section-title">클러스터 관리 및 업그레이드</block>
  <block id="ac816ab3f2fb9ede37e87c223bf39690" category="paragraph">잠재적 보안 위험이 있는 두 가지 영역에는 클러스터 관리(잘못된 행위자가 관리자 액세스 권한을 가지고 있는 경우 발생하는 현상) 및 업그레이드(소프트웨어 이미지가 손상된 경우 발생하는 현상)가 포함됩니다.</block>
  <block id="e3f83199a3d154c9a938a90ed76188d4" category="section-title">스토리지 관리 보호</block>
  <block id="e9406b6097629a60364e6b24a83dd40b" category="inline-link-macro">“서비스 운영”</block>
  <block id="a16c40cfa1517a64fe23c8a84e7fca32" category="paragraph">서비스형 스토리지를 사용하면 클라우드 데이터 센터 외부의 최종 사용자에 대한 액세스를 제거하여 관리자가 노출될 가능성을 최소화할 수 있습니다. 대신 고객이 데이터 액세스 플레인을 위해 설정하는 것이 유일한 구성입니다. 각 테넌트는 자체 볼륨을 관리하며 테넌트가 다른 Cloud Volumes Service 인스턴스에 연결할 수 없습니다. 이 서비스는 자동화를 통해 관리되며, 이 섹션에서 설명하는 프로세스를 통해 시스템에 액세스할 수 있는 신뢰할 수 있는 관리자의 목록은 매우 적습니다 <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="bc94b58452719d0cfedd1ceb30c4fd53" category="paragraph">CVS - 성능 서비스 유형은 지역 간 복제를 옵션으로 제공하여 지역 장애가 발생할 경우 다른 지역에 데이터를 보호합니다. 이 경우 Cloud Volumes Service를 영향을 받지 않는 영역으로 페일오버하여 데이터 액세스를 유지할 수 있습니다.</block>
  <block id="b8bb5b62315a69e1364d070de73bbfa5" category="section-title">서비스 업그레이드</block>
  <block id="a5e1144c0e37d7facbd53bdffaa58f52" category="paragraph">업데이트는 취약한 시스템을 보호하는 데 도움이 됩니다. 각 업데이트는 공격 경로를 최소화하는 보안 향상 기능 및 버그 수정을 제공합니다. 소프트웨어 업데이트는 중앙 저장소에서 다운로드되고 업데이트가 공식 이미지가 사용되고 잘못된 행위자에 의해 업그레이드에 영향을 받지 않는지 확인하기 전에 검증됩니다.</block>
  <block id="79f1689ccfaec67bc50dd620185adbac" category="paragraph">Cloud Volumes Service를 사용하면 클라우드 제공업체 팀이 업데이트를 처리하므로 관리자가 프로세스를 자동화하고 완벽하게 테스트한 구성 및 업그레이드에 정통하여 위험에 노출될 가능성을 줄일 수 있습니다. 업그레이드는 무중단으로 수행할 수 있으며 Cloud Volumes Service는 최신 업데이트를 유지하여 전체적인 결과를 최대한 제공합니다.</block>
  <block id="6a274e2791c8f2a1f59a7a6f87261122" category="paragraph">이러한 서비스 업그레이드를 수행하는 관리자 팀에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="b466e98e9a7ec570a0e595b4839650b9" category="inline-link-macro-rx"></block></block>
  <block id="eeae9bcc33a487e1224ffb4815f79821" category="section-title">사용되지 않는 데이터의 보안</block>
  <block id="11062b94d57add7cf5c44a9ec7e9274c" category="paragraph">유휴 데이터 암호화는 디스크 도난, 반환 또는 용도 변경이 발생할 경우 중요한 데이터를 보호하는 데 중요합니다. Cloud Volumes Service의 데이터는 소프트웨어 기반 암호화를 사용하여 유휴 상태에서 보호됩니다.</block>
  <block id="ad04a8dc3b058793f75e8c97c787ceea" category="list-text">Google에서 생성한 키는 CVS-SW에 사용됩니다.</block>
  <block id="b114edcfa107ab9d459e2e75aea2cfdb" category="inline-link">FIPS 140-2 인증 번호 4144</block>
  <block id="855bcb8730de4b24527a09801b103d97" category="list-text">CVS - 성능의 경우 볼륨별 키는 Cloud Volumes Service에 내장된 키 관리자에 저장되며, NetApp ONTAP CryptoMod를 사용하여 AES-256 암호화 키를 생성합니다. CryptoMod는 CMVP FIPS 140-2 검증 모듈 목록에 나열되어 있습니다. 을 참조하십시오<block ref="c8bf3ef21e8efdca1f27a1e57e809607" category="inline-link-rx"></block>.</block>
  <block id="a934c8bfa11942a4baa792ed229b8bb8" category="paragraph">2021년 11월부터 CVS-Performance에 CMEK(Customer-managed Encryption) 기능을 미리 볼 수 있습니다. 이 기능을 사용하면 Google KMS(Key Management Service)에서 호스팅되는 프로젝트별, 지역별 마스터 키를 사용하여 볼륨별 키를 암호화할 수 있습니다. KMS를 사용하면 외부 키 관리자를 연결할 수 있습니다.</block>
  <block id="08a22fe6e00e4ceb40cd56453b4a5864" category="paragraph">아키텍처에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="d008df97450ac642ad54d58196f67862" category="inline-link-macro-rx"></block></block>
  <block id="fb787119808b111e9df5553be31361c8" category="section-title">전송 중인 데이터 보안</block>
  <block id="8255b8a6d9844c87b5ecd1d2287b2f60" category="paragraph">유휴 데이터의 보안 외에도 Cloud Volumes Service 인스턴스와 클라이언트 또는 복제 타겟 간에 전송 중인 데이터를 안전하게 보호할 수 있어야 합니다. Cloud Volumes Service는 Kerberos를 사용한 SMB 암호화, 패킷의 서명/봉인 및 데이터 전송의 엔드 투 엔드 암호화를 위한 NFS Kerberos 5p 등의 암호화 방법을 사용하여 NAS 프로토콜을 통해 전송 중인 데이터에 대한 암호화를 제공합니다.</block>
  <block id="c42b0018cf60c30c0490998e63dfdac1" category="paragraph">Cloud Volumes Service 볼륨의 복제는 TLS-GCM 암호화 방법을 활용하는 TLS 1.2를 사용합니다.</block>
  <block id="17882f1649689ee4f6fcf4aeba6d150b" category="paragraph">텔넷, NDMP 등과 같이 안전하지 않은 전송 중 프로토콜은 기본적으로 비활성화되어 있습니다. 그러나 DNS는 Cloud Volumes Service에 의해 암호화되지 않으며(DNS 초 지원 없음) 가능하면 외부 네트워크 암호화를 사용하여 암호화해야 합니다. 섹션을 참조하십시오 <block ref="051d363ef6081e123484b5da28bebf19" category="inline-link-macro-rx"></block> 전송 중인 데이터 보안에 대한 자세한 내용은 를 참조하십시오.</block>
  <block id="4bb00cc1adfaf9a4b73ae2593bc7d4e8" category="inline-link-macro">“NAS 프로토콜.”</block>
  <block id="d47f2c6bf1e6a3776038244ab35f5415" category="paragraph">NAS 프로토콜 암호화에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="386abb448925212e530f9be720946265" category="inline-link-macro-rx"></block></block>
  <block id="46dc4f8fa1d2951250a02fa29fccc4cb" category="section-title">NAS 권한에 대한 사용자 및 그룹</block>
  <block id="4a6786c54b7ea4a860834c0ffda11c7f" category="paragraph">클라우드에서 데이터를 보호하기 위해서는 적절한 사용자 및 그룹 인증이 필요합니다. 여기서 데이터에 액세스하는 사용자는 해당 환경의 실제 사용자로서 확인되고 그룹에는 유효한 사용자가 포함됩니다. 이러한 사용자 및 그룹은 스토리지 시스템의 파일 및 폴더에 대한 권한 검증뿐만 아니라 초기 공유 및 내보내기 액세스를 제공합니다.</block>
  <block id="52c7382ae7438c8a3366ad6f38d5d2a4" category="paragraph">Cloud Volumes Service는 SMB 공유 및 Windows 스타일 권한에 표준 Active Directory 기반 Windows 사용자 및 그룹 인증을 사용합니다. 또한 UNIX용 LDAP 사용자 및 NFS 내보내기, NFSv4 ID 검증, Kerberos 인증 및 NFSv4 ACL을 위한 그룹 등의 UNIX ID 공급자를 활용할 수 있습니다.</block>
  <block id="59935480b9f5ac6361a1a360ad8a9ec2" category="admonition">현재 Active Directory LDAP만 Cloud Volumes Service for LDAP 기능에서 지원됩니다.</block>
  <block id="7c47e0b7c3aa389a1b437364885d5562" category="section-title">랜섬웨어, 맬웨어 및 바이러스의 감지, 방지 및 완화</block>
  <block id="b647cba0e4b0ad0f479019e47713c5a2" category="paragraph">랜섬웨어, 맬웨어 및 바이러스는 관리자에게 지속적인 위협이며 이러한 위협을 탐지, 예방 및 완화하는 것은 엔터프라이즈 조직의 최우선 고려입니다. 중요 데이터 세트에서 랜섬웨어 이벤트를 한 번 수행해도 수백만 달러의 비용이 발생할 수 있으므로 위험을 최소화하는 것이 좋습니다.</block>
  <block id="ba1e21a6e8310b88e0349770718e717c" category="inline-link">자동 랜섬웨어 탐지</block>
  <block id="b80fb0d337605da9f0fdaf2687c3de1e" category="paragraph">Cloud Volumes Service에는 현재 바이러스 백신 보호 또는 같은 기본 감지 또는 방지 조치가 포함되어 있지 않습니다<block ref="2ed126fbf9f5caf3d13a90f230e3475a" category="inline-link-rx"></block>정기적인 Snapshot 일정을 활성화하여 랜섬웨어 이벤트에서 신속하게 복구할 수 있는 방법이 있습니다. 스냅샷 복사본은 변경할 수 없으며 파일 시스템의 변경된 블록에 대한 읽기 전용 포인터만 사용할 수 있으며, 거의 즉각적으로 성능에 미치는 영향이 최소화되고, 데이터가 변경 또는 삭제될 때만 공간을 사용합니다. 원하는 RPO(복구 시점 목표)/RTO(복구 시간 목표)에 맞게 Snapshot 복사본의 일정을 설정할 수 있으며 볼륨당 최대 1,024개의 Snapshot 복사본을 유지할 수 있습니다.</block>
  <block id="e9c1c7d4ca860adb553d87c2c1d9ef35" category="inline-link">랜섬웨어용 NetApp 솔루션</block>
  <block id="85ebd62090617323187e9e7827c343e7" category="paragraph">스냅샷 지원은 Cloud Volumes Service에서 추가 비용 없이(스냅샷 복사본에 의해 유지되는 변경된 블록/데이터에 대한 데이터 스토리지 비용 제외) 포함되며, 랜섬웨어 공격의 경우 공격이 발생하기 전에 스냅샷 복사본으로 롤백하는 데 사용할 수 있습니다. 스냅샷 복원을 완료하는 데 몇 초 밖에 걸리지 않습니다. 그런 다음 정상 데이터 상태로 되돌릴 수 있습니다. 자세한 내용은 을 참조하십시오<block ref="e347ba4858ee244fead32d2fe59a64dd" category="inline-link-rx"></block>.</block>
  <block id="7994d1312e8f4fe2cdf2f7e13347d8bf" category="paragraph">랜섬웨어가 비즈니스에 영향을 주지 않도록 하려면 다음 중 하나 이상이 포함된 다계층 접근 방식이 필요합니다.</block>
  <block id="7aa2bd35ac13684bd5c9434296dd6b03" category="list-text">엔드포인트 보호</block>
  <block id="9cdff1d919782c79338864086178c7b0" category="list-text">네트워크 방화벽을 통한 외부 위협으로부터 보호</block>
  <block id="eb4079f2ecc7735fcfaa169c5562cbfd" category="list-text">데이터 이상 감지</block>
  <block id="aac3c67c846910bdfd381a7101344e96" category="list-text">중요 데이터 세트에 대한 다중 백업(온사이트 및 오프사이트</block>
  <block id="3845e8b5ec9d78bcebac29ec50d8077f" category="list-text">백업의 정기적인 복원 테스트</block>
  <block id="a550fe6fd1b40af5260e9636cdea66fd" category="list-text">변경 불가능한 읽기 전용 NetApp Snapshot 복사본</block>
  <block id="533a4f72ffc639d4cc87d034dfe92f2c" category="list-text">중요 인프라를 위한 다단계 인증</block>
  <block id="b1d3b419f981a509b3c5203c7546b96b" category="list-text">시스템 로그인에 대한 보안 감사</block>
  <block id="4e329c801824e6bdc0209c98146064c3" category="paragraph">이 목록은 전체적인 것으로부터 멀리 떨어져 있지만 랜섬웨어 공격의 가능성을 해결할 때 따라야 할 좋은 청사진입니다. Google Cloud의 Cloud Volumes Service는 랜섬웨어 이벤트를 방지하고 효과를 줄일 수 있는 여러 방법을 제공합니다.</block>
  <block id="2fdb508dbc71674add1fe7fc21ccbf8e" category="section-title">변경 불가능한 스냅샷 복사본</block>
  <block id="1682a7464d9210c8161ec78abc8010e2" category="paragraph">Cloud Volumes Service은 데이터를 삭제하거나 랜섬웨어 공격으로 인해 전체 볼륨이 희생된 경우 사용자 지정이 가능한 일정에 따라 진행되는 변경 불가능한 읽기 전용 스냅샷 복사본을 기본적으로 제공합니다. 스냅샷 스케줄 및 RTO/RPO의 보존 기간을 기준으로 Snapshot을 이전 Snapshot 복제본으로 빠르게 복구하고 데이터 손실을 최소화합니다. 스냅샷 기술을 사용할 경우 성능 영향은 미미합니다.</block>
  <block id="c0bd33c36fff1f6dbb2bf9253a7f40dd" category="paragraph">Cloud Volumes Service의 스냅샷 복사본은 읽기 전용이므로 랜섬웨어가 데이터 세트에 확산되지 않고 Snapshot 복사본이 랜섬웨어에 의해 감염된 데이터를 가져가지 않는 한 랜섬웨어에 감염될 수 없습니다. 따라서 데이터 이상을 기반으로 랜섬웨어 탐지를 고려해야 하는 이유가 됩니다. Cloud Volumes Service는 현재 탐지 기능을 기본적으로 제공하지 않지만 외부 모니터링 소프트웨어를 사용할 수 있습니다.</block>
  <block id="9b641219ac63451505f5a25a887038d4" category="section-title">백업 및 복원</block>
  <block id="5e2f84170723d4cfed011f9ebc6c557e" category="paragraph">Cloud Volumes Service는 표준 NAS 클라이언트 백업 기능(예: NFS 또는 SMB를 통한 백업)을 제공합니다.</block>
  <block id="0d69441d7fc21e56d3cf2eb944fbf6c1" category="inline-link">볼륨 복제</block>
  <block id="161b127f579db2727ace94e4fb6f9e5b" category="inline-link">클라우드 백업</block>
  <block id="56a32ac982c7663e59f24c58cfb673d6" category="paragraph">볼륨 복제는 랜섬웨어 이벤트를 포함하여 재해 발생 시 신속한 페일오버를 위해 소스 볼륨의 정확한 복사본을 제공합니다.</block>
  <block id="ae2679a66d07f8c7efd50d972a34a112" category="section-title">지역 간 복제</block>
  <block id="1a094951f7e9c42a89c4ef4b0b328eee" category="paragraph">CVS - 성능은 Google 네트워크에서 실행되는 복제에 사용되는 특정 인터페이스를 사용하여 NetApp이 제어하는 백엔드 서비스 네트워크에서 TLS1.2 AES 256 GCM 암호화를 사용하여 데이터 보호 및 아카이브 사용 사례를 위해 Google Cloud 지역 전반에 걸쳐 볼륨을 안전하게 복제할 수 있게 해줍니다. 운영(소스) 볼륨에는 활성 운영 데이터가 포함되어 있으며 보조(대상) 볼륨에 복제하여 운영 데이터 세트의 정확한 복제본을 제공합니다.</block>
  <block id="f8e2c7b5b15f4332525ac9687a100a28" category="paragraph">초기 복제는 모든 블록을 전송하지만 업데이트는 변경된 블록만 운영 볼륨에서 전송합니다. 예를 들어, 기본 볼륨에 상주하는 1TB 데이터베이스가 보조 볼륨으로 복제되면 1TB 공간이 초기 복제 시 전송됩니다. 해당 데이터베이스에 초기화와 다음 업데이트 간에 변경되는 수백 개의 행(몇 MB)이 있는 경우 변경된 행이 있는 블록만 보조 블록(몇 MB)으로 복제됩니다. 이렇게 하면 전송 시간이 낮게 유지되고 복제 비용이 계속 감소되도록 할 수 있습니다.</block>
  <block id="fd25283b48ea77209e43fe9173df1354" category="paragraph">파일 및 폴더에 대한 모든 권한은 보조 볼륨으로 복제되지만 내보내기 정책 및 규칙, SMB 공유 및 ACL 공유 등의 공유 액세스 권한은 별도로 처리해야 합니다. 사이트 장애 조치의 경우 대상 사이트는 동일한 이름 서비스와 Active Directory 도메인 연결을 활용하여 사용자 및 그룹 ID와 사용 권한을 일관된 방식으로 처리해야 합니다. 재해 발생 시 보조 볼륨을 페일오버 타겟으로 사용할 수 있습니다. 즉, 2차 볼륨을 읽기-쓰기로 변환하는 복제 관계를 끊으면 됩니다.</block>
  <block id="940c6fa9c7eb366ae4e471e545edb27b" category="paragraph">볼륨 복사본은 읽기 전용이며, 바이러스가 감염된 데이터를 가지고 있거나 랜섬웨어가 기본 데이터 세트를 암호화한 경우 데이터를 빠르게 복구하기 위해 변경 불가능한 데이터 사본을 오프사이트에 제공합니다. 읽기 전용 데이터는 암호화되지 않지만 운영 볼륨이 영향을 받고 복제가 발생하는 경우 감염된 블록도 복제됩니다. 오래되고 영향을 받지 않는 Snapshot 복사본을 사용하여 복구할 수 있지만, 공격이 탐지되는 속도에 따라 SLA가 약속된 RTO/RPO의 범위를 벗어날 수 있습니다.</block>
  <block id="fe62647cc35dde214e0df1ae1fe9d0ab" category="inline-link">보안 고려 사항</block>
  <block id="8ee215caafa31f1ecdd53056d288eb19" category="paragraph">Cloud Volumes Service는 높은 데이터 내구성을 제공하지만 외부 이벤트는 데이터 손실을 일으킬 수 있습니다. 바이러스 또는 랜섬웨어와 같은 보안 이벤트가 발생할 경우, 백업 및 복원이 시기적절하게 데이터 액세스를 재개하는 데 중요한 역할을 합니다. 관리자가 실수로 Cloud Volumes Service 볼륨을 삭제할 수 있습니다. 또는 사용자가 단순히 데이터 백업 버전을 몇 개월 동안 유지하고 볼륨 내에 추가 Snapshot 복사본 공간을 유지하는 것은 비용 문제가 됩니다. Snapshot 복사본이 최근 몇 주 동안 손실된 데이터를 복원하는 백업 버전을 보관하는 기본 방법이어야 하지만, 볼륨 내에 있으며 볼륨이 없어지면 손실됩니다.</block>
  <block id="a5cef37749b0ea6b89d13e2bfc190bcc" category="paragraph">Cloud Volumes Service 백업은 GCS(Google Cloud Storage)에서 볼륨의 복사본을 생성합니다. 사용 가능한 공간이 아닌 볼륨 내에 저장된 실제 데이터만 백업합니다. 영구 증분 방식으로 작동하므로 볼륨 콘텐츠를 한 번 전송하고 변경된 데이터만 계속 백업합니다. 여러 개의 전체 백업을 사용하는 기존 백업 개념에 비해 많은 양의 백업 스토리지를 절약하여 비용을 절감합니다. 백업 공간의 월별 가격이 볼륨에 비해 낮기 때문에 백업 버전을 더 오래 유지하는 것이 좋습니다.</block>
  <block id="d41618915810c18642064f885af2a835" category="paragraph">사용자는 Cloud Volumes Service 백업을 사용하여 모든 백업 버전을 동일한 지역 내의 동일한 볼륨 또는 다른 볼륨으로 복원할 수 있습니다. 소스 볼륨이 삭제되면 백업 데이터가 보존되므로 독립적으로 관리(예: 삭제)해야 합니다.</block>
  <block id="3289695e643b478f0efa19edc74cf567" category="inline-link">Cloud Volumes Service 백업 설명서</block>
  <block id="be7923d42a302a1a86fdaa9f096fde63" category="inline-link">지원되는 최대 백업 버전 수입니다</block>
  <block id="59aab28b54594c59dab8d19afd9478e4" category="inline-link">가격</block>
  <block id="9a647ae53ed9b2a783aef42530e1fe97" category="paragraph">프로젝트의 모든 백업 데이터는 GCS 버킷 내에 저장되며, 이 버킷은 서비스에서 관리되며 사용자에게 표시되지 않습니다. 프로젝트마다 다른 버킷을 사용합니다. 현재 버킷은 Cloud Volumes Service 볼륨과 동일한 영역에 있지만 더 많은 옵션에 대해 논의 중입니다. 최신 상태는 설명서를 참조하십시오.</block>
  <block id="4e1c6d2a637d959db4ce4a09b3e5c580" category="paragraph">Cloud Volumes Service 버킷에서 GCS로 데이터를 전송하는 경우 HTTPS 및 TLS1.2가 포함된 서비스 내부 Google 네트워크를 사용합니다. 데이터는 Google에서 관리하는 키로 유휴 상태로 암호화됩니다.</block>
  <block id="5e467dce18f46b1803b06097fae60b82" category="inline-link">역할/netappcloudvolumes.admin</block>
  <block id="d5588adba169169b3d9fbc3d40fa9e91" category="inline-link-macro">다음: 아키텍처 개요</block>
  <block id="70c94a86f99e1aa5d40b6ca87c17a399" category="paragraph"><block ref="70c94a86f99e1aa5d40b6ca87c17a399" category="inline-link-macro-rx"></block></block>
  <block id="6ab0778deb23383f6063990e47d38567" category="summary">Cloud Volumes Service의 모든 볼륨은 AES-256 암호화를 사용하여 유휴 상태로 암호화되므로 미디어에 기록된 모든 사용자 데이터가 암호화되며 볼륨당 키를 통해서만 해독할 수 있습니다.</block>
  <block id="05a42723f4aebc1b8fea32f0da56f531" category="doc">유휴 데이터 암호화</block>
  <block id="914e9cc2016ed2891bc115163b671205" category="inline-link-macro">이전: 전송 중인 데이터 암호화.</block>
  <block id="3ab72ed338391088a345040cc4ede7e0" category="paragraph"><block ref="3ab72ed338391088a345040cc4ede7e0" category="inline-link-macro-rx"></block></block>
  <block id="4a41d68019f2643468ef37e122fc87a9" category="list-text">CVS-SW의 경우 Google에서 생성한 키가 사용됩니다.</block>
  <block id="68056df8fa340722ff859d534da347e4" category="list-text">CVS - 성능의 경우 볼륨별 키는 Cloud Volumes Service에 내장된 키 관리자에 저장됩니다.</block>
  <block id="e23c4fadd8e7d70663bc3393bca7d576" category="inline-link">Google KMS(키 관리 서비스).</block>
  <block id="387ccb6d293c8d2f51b2730c375c3f3a" category="paragraph">2021년 11월부터 CMEK(고객 관리 암호화 키) 기능을 미리 볼 수 있습니다. 이렇게 하면 에서 호스팅되는 프로젝트별, 지역별 마스터 키를 사용하여 볼륨별 키를 암호화할 수 있습니다<block ref="145d140dc09dde7f8aacc53f1269c2de" category="inline-link-rx"></block> KMS를 사용하면 외부 키 관리자를 연결할 수 있습니다.</block>
  <block id="1988a6b2308f38718c8100c2e344eb5c" category="inline-link">고객이 관리하는 암호화 키 설정</block>
  <block id="6a2064a5b36d77d1da28e1bb96fe613e" category="inline-link-macro">다음: 방화벽.</block>
  <block id="d78ea12f26e93e819db4dd4772e8cb6e" category="paragraph"><block ref="d78ea12f26e93e819db4dd4772e8cb6e" category="inline-link-macro-rx"></block></block>
  <block id="13a2c7416db43025d8318ec9db325859" category="summary">전송 중인 데이터는 NAS 프로토콜 계층에서 암호화할 수 있으며, Google Cloud 네트워크 자체는 다음 섹션에 설명된 대로 암호화됩니다.</block>
  <block id="f7ccd4455f141bba37dd989458bfd1f3" category="doc">전송 중인 데이터 암호화</block>
  <block id="44782cad8de83a97138ea3bcbd36c028" category="inline-link-macro">이전: 데이터 플레인 아키텍처.</block>
  <block id="9e17ee7c2f94201998bfd10292b5e098" category="paragraph"><block ref="9e17ee7c2f94201998bfd10292b5e098" category="inline-link-macro-rx"></block></block>
  <block id="8de1715de3864b137091fa8f6d71053f" category="section-title">Google Cloud 네트워크</block>
  <block id="a94ac9daf8e09a31f9e81f7de9ee7ab6" category="inline-link">전송 중인 암호화</block>
  <block id="57d5b464e5bc1a25ae2337c72e492c88" category="paragraph">Google Cloud는 에 설명된 대로 네트워크 수준의 트래픽을 암호화합니다<block ref="df3d10947a311abbd08a64a5cc9629d3" category="inline-link-rx"></block> Google 문서. “Cloud Volumes Services 아키텍처” 섹션에서 언급한 것처럼 Cloud Volumes Service는 NetApp이 제어하는 PSA 생산자 프로젝트를 통해 제공됩니다.</block>
  <block id="4322a5ae7fc781564c1349bf92846311" category="paragraph">CVS-SW의 경우 프로듀서 테넌트는 Google VM을 실행하여 서비스를 제공합니다. 사용자 VM과 Cloud Volumes Service VM 간의 트래픽은 Google에서 자동으로 암호화됩니다.</block>
  <block id="d3072f2789ba193441ddf485cc806a82" category="inline-link">IEEE 802.1AE 암호화(MACSec)</block>
  <block id="6141361c43c6e429fa93fd0f6f8b2dac" category="inline-link">캡슐화</block>
  <block id="2a5cd9c0503b957ff28d59f12a8bb05a" category="paragraph">CVS의 데이터 경로 - 성능은 네트워크 계층에서 완전히 암호화되지 않지만, NetApp과 Google은 이 조합을 사용합니다<block ref="83e770b09a2e800e59cae429b60dde07" category="inline-link-rx"></block>,<block ref="c5a2137e5d30663db35a2f990a0275f0" category="inline-link-rx"></block> (데이터 암호화) 및 물리적으로 제한된 네트워크를 통해 Cloud Volumes Service CVS - 성능 서비스 유형과 Google 클라우드 간에 전송 중인 데이터를 보호합니다.</block>
  <block id="95151e0beeb1cf14e98ed9e0e0ebc86f" category="section-title">NAS 프로토콜</block>
  <block id="7661437a0dea607fd6013193db5363be" category="paragraph">NFS 및 SMB NAS 프로토콜은 프로토콜 계층에서 선택적 전송 암호화를 제공합니다.</block>
  <block id="198a269fc15076e5cc8ab572d6711771" category="section-title">SMB 암호화</block>
  <block id="69c2cd6d510299a43f241a4afbeef373" category="paragraph"><block ref="ebb0763fea63f976f4d3ea586b6fe491" category="inline-link-rx"></block> SMB 데이터의 엔드 투 엔드 암호화를 제공하고 신뢰할 수 없는 네트워크에서 데이터를 도청하지 못하도록 보호합니다. 클라이언트/서버 데이터 연결(SMB3.x 가능 클라이언트에만 사용 가능)과 서버/도메인 컨트롤러 인증에 대해 암호화를 설정할 수 있습니다.</block>
  <block id="a8c42b910beec902a232a69b59a37847" category="paragraph">SMB 암호화가 활성화된 경우 암호화를 지원하지 않는 클라이언트는 공유에 액세스할 수 없습니다.</block>
  <block id="72635a952bf12498ca4ca124b1a14d51" category="paragraph">Cloud Volumes Service는 SMB 암호화를 위한 RC4-HMAC, AES-128-CTS-HMAC-SHA1 및 AES-256-CTS-HMAC-SHA1 보안 암호를 지원합니다. SMB는 서버에서 지원되는 가장 높은 암호화 유형으로 협상합니다.</block>
  <block id="980b28eb45b1ea66cdd07d05e78099a3" category="section-title">NFSv4.1 Kerberos</block>
  <block id="b97e4c9117cfcc0dd5d7a10e1a7a2631" category="inline-link">RFC7530</block>
  <block id="69a4f8e652e19cfdfb26e27d4447ae98" category="paragraph">NFSv4.1의 경우 CVS - 성능은 에서 설명한 대로 Kerberos 인증을 제공합니다<block ref="526af9c532c496dd16998f764e15dc87" category="inline-link-rx"></block>. 볼륨별로 Kerberos를 활성화할 수 있습니다.</block>
  <block id="b2833929a77bd8c490997197ed3f00be" category="paragraph">Kerberos에서 현재 가장 강력한 암호화 유형은 AES-256-CTS-HMAC-SHA1입니다. NetApp Cloud Volumes Service는 NFS용 AES-256-CTS-HMAC-SHA1, AES-128-CTS-HMAC-SHA1, DES3 및 DES를 지원합니다. 또한 CIFS/SMB 트래픽에 대해 ARCFOUR-HMAC(RC4)를 지원하지만 NFS에는 지원하지 않습니다.</block>
  <block id="59417c70dd426d4c6a1a81a09043bb7b" category="paragraph">Kerberos는 Kerberos 보안의 강화 방법을 선택할 수 있는 NFS 마운트에 대해 세 가지 서로 다른 보안 수준을 제공합니다.</block>
  <block id="710c8a535ea62cee124026e31e71a5bd" category="inline-link">일반 마운트 옵션</block>
  <block id="224b49d2f24ee42bbb73b2ca635c6d9a" category="paragraph">RedHat에 따름<block ref="1849b335749f623c227052141b2e8b11" category="inline-link-rx"></block> 설명서:</block>
  <block id="babd6b3b4aea27ca41d56a231f2625af" category="paragraph">일반적으로 Kerberos 보안 수준이 많을수록 클라이언트와 서버가 전송된 각 패킷의 NFS 작업을 암호화하고 해독하는 데 시간을 소비하므로 성능이 저하됩니다. 많은 클라이언트와 NFS 서버가 AES-NI 오프로딩을 CPU에 지원하므로 전반적인 환경이 개선되지만 Kerberos 5p(전체 엔드 투 엔드 암호화)의 성능 영향은 Kerberos 5(사용자 인증)의 영향보다 훨씬 큽니다.</block>
  <block id="986c123032dbfdac18bc180d1a2c3562" category="paragraph">다음 표에서는 보안 및 성능에 대한 각 수준의 차이점을 보여 줍니다.</block>
  <block id="f12149bd43eabe8557e021017cfb9b1f" category="cell">보안 수준</block>
  <block id="af75613ef5351b4f2563e49218c01d5b" category="cell">NFSv3 - 시스템</block>
  <block id="d65540b3d2f3c15e237b23f6d4d823e5" category="list-text">최소 보안, 숫자 사용자 ID/그룹 ID가 있는 일반 텍스트</block>
  <block id="2310efb28386099d85b1dbcaf5f9c51f" category="list-text">UID, GID, 클라이언트 IP 주소, 내보내기 경로, 파일 이름, 패킷 캡처의 권한</block>
  <block id="07b50706d3894aa894686195ddeed426" category="list-text">대부분의 경우에 적합합니다</block>
  <block id="54fcc149f825f18bfaaa374d6876e25a" category="cell">NFSv4.x - 시스템</block>
  <block id="3777f761befcdc3f42a4d77cde2962fe" category="list-text">NFSv3(클라이언트 ID, 이름 문자열/도메인 문자열 일치)보다 더 안전하지만 여전히 일반 텍스트입니다</block>
  <block id="25199bb4f6f6a3eadd28c84579d0fcf7" category="list-text">UID, GID, 클라이언트 IP 주소, 이름 문자열, 도메인 ID를 볼 수 있습니다. 패킷 캡처의 내보내기 경로, 파일 이름, 권한</block>
  <block id="5145a8956e4807aeba5a7a4a1677c598" category="list-text">순차적 워크로드(예: VM, 데이터베이스, 대용량 파일)에 적합</block>
  <block id="bc96a40b0174b0ec2f9133e1e704d7cb" category="list-text">파일 개수가 많음/메타데이터 많음(30~50% 악화)</block>
  <block id="f25baf1a23f237c73f28b4834def4161" category="cell">NFS — krb5</block>
  <block id="0661ead41dc806181d0a0bff696e49df" category="list-text">모든 NFS 패킷의 자격 증명에 대한 Kerberos 암호화 - GSS 래퍼의 RPC 호출에서 사용자/그룹의 UID/GID를 래핑합니다</block>
  <block id="b012a8b71e44e4c118c2a97f94c11c1f" category="list-text">마운트 액세스를 요청하는 사용자는 유효한 Kerberos 티켓(사용자 이름/암호 또는 수동 키 탭 교환)이 필요합니다. 티켓은 지정된 기간 후에 만료되며 사용자는 액세스를 위해 다시 인증해야 합니다</block>
  <block id="ab2293d06a9e3594a17eb02b827c471a" category="list-text">마운트/portmapper/NLM 같은 NFS 작업 또는 보조 프로토콜에 대한 암호화 없음(내보내기 경로, IP 주소, 파일 핸들, 권한, 파일 이름 패킷 캡처의 atime/mtime)</block>
  <block id="6d140d250a49ec533ff2211674c16138" category="list-text">Kerberos의 경우 대부분 최상, AUTH_SYS보다 나쁨</block>
  <block id="bc578f6162e4255fe0d1d4445ec8d975" category="cell">NFS — krb5i</block>
  <block id="7886fbf427a34b659783d690ee4ad3dd" category="list-text">마운트 액세스를 요청하는 사용자는 유효한 Kerberos 티켓(사용자 이름/암호 또는 수동 키 탭 교환)이 필요합니다. 티켓은 지정된 기간 후에 만료되며 사용자는 액세스를 위해 다시 인증해야 합니다</block>
  <block id="49d02d7e5db8eb8139c3777891f63e2e" category="list-text">Kerberos GSS 체크섬은 패킷을 가로챌 수 없도록 모든 패킷에 추가됩니다. 체크섬이 일치하면 대화가 허용됩니다.</block>
  <block id="0ea3431437c971e8ac8f271b60694b38" category="list-text">NFS 페이로드가 암호화되지 않기 때문에 krb5p보다 낫습니다. krb5와 비교하여 추가된 오버헤드만 무결성 체크섬입니다. krb5i의 성능은 krb5보다 훨씬 나쁘지는 않지만 약간의 성능 저하가 발생할 수 있습니다.</block>
  <block id="facbd78bc28fa0b36f521d74ff5f0cec" category="cell">NFS – krb5p</block>
  <block id="d11093694c8bd1d8897446e4cf645e48" category="list-text">마운트 액세스를 요청하는 사용자는 유효한 Kerberos 티켓(사용자 이름/암호 또는 수동 키 탭 교환)이 필요합니다. 티켓은 지정된 기간 이후에 만료되며 사용자는 액세스를 위해 다시 인증해야 합니다</block>
  <block id="29af1c9e08784f1ef0e42433aef21eee" category="list-text">모든 NFS 패킷 페이로드는 GSS 래퍼로 암호화됩니다(패킷 캡처에서 파일 핸들, 권한, 파일 이름, atime/mtime을 볼 수 없음).</block>
  <block id="70aa40903816c1fda65618ae32c56d8b" category="list-text">무결성 검사를 포함합니다.</block>
  <block id="3e7dfd7567a414307d5fe93ea83ce4f6" category="list-text">NFS 작업 유형이 표시됩니다(FSINFO, ACCESS, GETATTR 등).</block>
  <block id="6b375be1f905197ba21c586647e973f4" category="list-text">보조 프로토콜(마운트, 포트 맵, NLM 등)이 암호화되지 않음 - (내보내기 경로, IP 주소 확인 가능)</block>
  <block id="6de6f14759a24d6fcb16973384e01c00" category="list-text">보안 수준의 최악의 성능: krb5p는 더 많은 암호화/암호 해독을 해야 합니다.</block>
  <block id="abac32415b4bfbaf4765dec9d36149cd" category="paragraph">Cloud Volumes Service에서 구성된 Active Directory 서버는 Kerberos 서버 및 LDAP 서버로 사용됩니다(RFC2307 호환 스키마에서 사용자 ID를 조회하기 위해). 다른 Kerberos 또는 LDAP 서버는 지원되지 않습니다. Cloud Volumes Service에서 ID 관리를 위해 LDAP를 사용하는 것이 좋습니다. NFS Kerberos가 패킷 캡처에 표시되는 방법에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="e06a781bd551a4c8ed55a5dfd008a50c" category="inline-link-macro-rx"></block></block>
  <block id="656b94b95418723e2acea6b86dc53e48" category="inline-link-macro">다음: 유휴 데이터 암호화.</block>
  <block id="6ca1480f90da15333bae5670283ea19f" category="paragraph"><block ref="6ca1480f90da15333bae5670283ea19f" category="inline-link-macro-rx"></block></block>
  <block id="d1a7050a3a677e1c229160462a179103" category="doc">추가 정보, 버전 기록 및 연락처 정보</block>
  <block id="b67313323e9670f2b3cc78a36af15174" category="inline-link-macro">이전: 서비스 작업.</block>
  <block id="5390c35bfa9dd0545fb51b84c8af3252" category="paragraph"><block ref="5390c35bfa9dd0545fb51b84c8af3252" category="inline-link-macro-rx"></block></block>
  <block id="4780631a0451a6605045de3ace692cc6" category="list-text">Cloud Volumes Service용 Google Cloud 설명서</block>
  <block id="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link"><block ref="6e0173c8a46418c9ee6c916c7c275ef8" category="inline-link-rx"></block></block>
  <block id="8e65fc49f8ebbf3d9cc9651ce7940654" category="paragraph"><block ref="8e65fc49f8ebbf3d9cc9651ce7940654" category="inline-link-rx"></block></block>
  <block id="0e8aec42089c0c73812fa42d1888b3c8" category="list-text">Google 전용 서비스 액세스</block>
  <block id="02aed7d7f25878a636d26b696ed151bb" category="list-text">NetApp 제품 설명서</block>
  <block id="f670e58416e680d41a98914939ff8b4d" category="list-text">암호화 검증 모듈 프로그램 — NetApp CryptoMod</block>
  <block id="904728949094c548bcec2129979a28a6" category="inline-link"><block ref="904728949094c548bcec2129979a28a6" category="inline-link-rx"></block></block>
  <block id="50dc6dd0a76419597a78231ee45ad7f5" category="paragraph"><block ref="50dc6dd0a76419597a78231ee45ad7f5" category="inline-link-rx"></block></block>
  <block id="fb35bc32af8e0bce21ef22bad9052b39" category="inline-link"><block ref="0ea855bd074e3e4be70d90c120079c12" category="inline-link-rx"></block></block>
  <block id="56f0874ab11ee024b4419753f2a3f06f" category="paragraph"><block ref="801eea2aa1601f12cc3d53d718ad33a7" category="inline-link-rx"></block></block>
  <block id="61eb0e8494826dc8f30af9122fd97664" category="list-text">TR-4616: ONTAP에서 NFS Kerberos</block>
  <block id="ed78f5221deba5e60a950d28a62de702" category="inline-link"><block ref="ed78f5221deba5e60a950d28a62de702" category="inline-link-rx"></block></block>
  <block id="d677acd46c811ecd9bac37aa26d8668c" category="paragraph"><block ref="d677acd46c811ecd9bac37aa26d8668c" category="inline-link-rx"></block></block>
  <block id="b56a5394775a9f077c12cb3e770d913c" category="cell">2022년 5월</block>
  <block id="1bebe65011b1928d45d041533c04d2b1" category="paragraph">이 기술 보고서를 개선할 방법을 알려주십시오.</block>
  <block id="8b1418ea0c579605e873907335ca62c7" category="paragraph">이메일: mailto:doccomments@netapp.com [doccomments@netapp.com^]로 연락해 주십시오. 제목 줄에 기술 보고서 4918 포함.</block>
  <block id="402d245fd6f48d88ea661814c622456e" category="summary">NAS 프로토콜은 여러 클라이언트의 네트워크 상에서 Cloud Volumes Service on GCP와 같은 스토리지 시스템의 동일한 데이터에 액세스하는 방법입니다. NFS 및 SMB는 정의된 NAS 프로토콜로, Cloud Volumes Service이 서버 역할을 하는 클라이언트/서버 단위로 작동합니다.</block>
  <block id="900608117b1be22303e2a172c6d9b280" category="doc">NAS 프로토콜의 기본 사항</block>
  <block id="d23b6e095547133ec383cdcb0f080e6e" category="inline-link-macro">이전: NAS 프로토콜 개요</block>
  <block id="8de032a7ba389eddc7880273654515a6" category="paragraph"><block ref="8de032a7ba389eddc7880273654515a6" category="inline-link-macro-rx"></block></block>
  <block id="b03874a8574793b2c634d05da5dae732" category="paragraph">NAS 프로토콜은 여러 클라이언트의 네트워크 상에서 Cloud Volumes Service on GCP와 같은 스토리지 시스템의 동일한 데이터에 액세스하는 방법입니다. NFS 및 SMB는 정의된 NAS 프로토콜로, Cloud Volumes Service이 서버 역할을 하는 클라이언트/서버 단위로 작동합니다. 클라이언트는 서버에 액세스, 읽기 및 쓰기 요청을 보내고, 서버는 파일에 대한 잠금 메커니즘을 조정하고, 사용 권한을 저장하고, ID 및 인증 요청을 처리할 책임이 있습니다.</block>
  <block id="86a29faa66a25c7e3fd290cf1e53761c" category="paragraph">예를 들어, NAS 클라이언트가 폴더에 새 파일을 생성하려는 경우 다음과 같은 일반 프로세스가 적용됩니다.</block>
  <block id="817aaff54aa6b5cd0e96c54c0b20ea1d" category="list-text">클라이언트가 서버에 디렉터리(권한, 소유자, 그룹, 파일 ID, 사용 가능한 공간, 등). 서버는 요청한 클라이언트 및 사용자에게 상위 폴더에 대한 필요한 권한이 있는 경우 해당 정보로 응답합니다.</block>
  <block id="9ec40c2869366ebe8cf1a8c690bb6471" category="list-text">디렉토리의 사용 권한이 액세스를 허용할 경우 클라이언트는 생성 중인 파일 이름이 파일 시스템에 이미 있는지 서버에 묻습니다. 파일 이름이 이미 사용 중인 경우 생성이 실패합니다. 파일 이름이 없는 경우 서버는 클라이언트가 계속 진행할 수 있음을 알려 줍니다.</block>
  <block id="83a9d09522edde42d016b5f2649ad9b6" category="list-text">클라이언트는 디렉토리 핸들 및 파일 이름으로 파일을 만들기 위해 서버에 대한 호출을 수행하고 액세스 및 수정 시간을 설정합니다. 서버에서 파일에 고유한 파일 ID를 발급하여 동일한 파일 ID로 다른 파일이 생성되지 않도록 합니다.</block>
  <block id="4884742626257d3e2fee8f3fa6d74f9c" category="list-text">클라이언트는 쓰기 작업 전에 파일 특성을 확인하는 호출을 전송합니다. 권한이 허용하는 경우 클라이언트는 새 파일을 씁니다. 프로토콜/응용 프로그램에서 잠금을 사용하는 경우 클라이언트는 다른 클라이언트가 잠금 상태에서 파일에 액세스하지 못하도록 서버에 잠금을 요청합니다. 잠금 상태에서는 데이터 손상을 방지할 수 있습니다.</block>
  <block id="9f36fd781ab1b50b7d007cb7bbd31f1f" category="inline-link-macro">다음: NFS.</block>
  <block id="e120d5e9a70a32a053802947c9767294" category="paragraph"><block ref="e120d5e9a70a32a053802947c9767294" category="inline-link-macro-rx"></block></block>
  <block id="432be93985cd954e5f755048381e528d" category="summary">NFS는 RFC(Request for Comments)에 정의된 공개 IETF 표준인 분산 파일 시스템 프로토콜로, 누구나 프로토콜을 구현할 수 있도록 합니다.</block>
  <block id="ba3cb198ccc0137ff2861f85eff2b3ce" category="inline-link-macro">이전: NAS 프로토콜의 기본 사항_개요</block>
  <block id="2be8e5e3e57aed02dfb62a58afdadfad" category="paragraph"><block ref="2be8e5e3e57aed02dfb62a58afdadfad" category="inline-link-macro-rx"></block></block>
  <block id="b53dfc952aa9d99343d94971cf6c3fee" category="paragraph">Cloud Volumes Service의 볼륨은 클라이언트 또는 클라이언트 세트에 액세스할 수 있는 경로를 내보내 NFS 클라이언트에 공유됩니다. 이러한 내보내기를 마운트할 수 있는 권한은 Cloud Volumes Service 관리자가 구성할 수 있는 내보내기 정책 및 규칙에 의해 정의됩니다.</block>
  <block id="0e3cb63bde3f98dbd812d470d8b100cf" category="paragraph">NetApp NFS 구현은 프로토콜의 골드 표준으로 간주되며 수많은 엔터프라이즈 NAS 환경에서 사용됩니다. 다음 섹션에서는 NFS와 Cloud Volumes Service에서 사용할 수 있는 특정 보안 기능 및 구현 방법에 대해 설명합니다.</block>
  <block id="8b575afc20d2914501471190a68364ed" category="section-title">기본 로컬 UNIX 사용자 및 그룹</block>
  <block id="c9f0864944a97085b2897c473c91dccc" category="paragraph">Cloud Volumes Service에는 다양한 기본 기능을 위한 여러 기본 UNIX 사용자 및 그룹이 포함되어 있습니다. 이러한 사용자 및 그룹은 현재 수정 또는 삭제할 수 없습니다. 현재 새 로컬 사용자 및 그룹을 Cloud Volumes Service에 추가할 수 없습니다. 기본 사용자 및 그룹 외부의 UNIX 사용자 및 그룹은 외부 LDAP 이름 서비스에서 제공해야 합니다.</block>
  <block id="8002bcf6ec4e483483e32633f99bee00" category="paragraph">다음 표에서는 기본 사용자 및 그룹과 해당 숫자 ID를 보여 줍니다. LDAP 또는 이러한 숫자 ID를 다시 사용하는 로컬 클라이언트에서는 새 사용자 또는 그룹을 생성하지 않는 것이 좋습니다.</block>
  <block id="0346306b31bbb7a0ae5245da13ec03c4" category="cell">기본 사용자: 숫자 ID</block>
  <block id="c782adef8851cb8855543f329d548bb2" category="cell">기본 그룹: 숫자 ID</block>
  <block id="a38b2868ff594195dcec8e7fe562b0be" category="list-text">루트: 0</block>
  <block id="44b4512252320c293616b69743e2a445" category="list-text">pcuser: 65534</block>
  <block id="95312f9502cf30aaff5cbbd3a4585a68" category="list-text">아무도 없다: 65535</block>
  <block id="39fff4671c3793536f3df78e41aed899" category="list-text">데몬: 1</block>
  <block id="ffe991bd5946c28affb0a08326a88c3f" category="admonition">NFSv4.1을 사용하는 경우 NFS 클라이언트에서 디렉토리 목록 명령을 실행할 때 루트 사용자가 아무도 표시되지 않을 수 있습니다. 이는 클라이언트의 ID 도메인 매핑 구성 때문입니다. 의 섹션을 참조하십시오 <block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block> 이 문제에 대한 자세한 내용 및 해결 방법을 확인하십시오.</block>
  <block id="97d69dfca64d2bd85ec6cc9736cd662b" category="section-title">루트 사용자입니다</block>
  <block id="767a04b899f673915ec8d6d78f549f3b" category="paragraph">Linux에서 루트 계정은 Linux 기반 파일 시스템의 모든 명령, 파일 및 폴더에 액세스할 수 있습니다. 이 계정의 강력한 기능 때문에 보안 모범 사례에 따라 루트 사용자를 비활성화하거나 제한해야 하는 경우가 많습니다. NFS 내보내기에서 루트 사용자가 파일과 폴더에 가지고 있는 파워는 내보내기 정책과 규칙, 루트 스쿼시(root squash)라는 개념을 통해 Cloud Volumes Service에서 제어할 수 있습니다.</block>
  <block id="7cd60419657f1f0735c557afd44724f0" category="inline-link">setuid/setgid 명령(고정 비트)</block>
  <block id="b95ee7e499b2b5ee7f9c911c9c86f8a2" category="paragraph">루트 스쿼싱 기능을 사용하면 NFS 마운트에 액세스하는 루트 사용자가 익명 숫자 사용자 65534에 스쿼트됩니다(“ 섹션 참조)<block ref="07a7b24bc0f7cda943dc05060d1188d8" category="inline-xref-macro-rx"></block>") 및 은(는) 현재 CVS - Performance를 사용하는 경우에만 사용할 수 있습니다. 이 경우 내보내기 정책 규칙 생성 중 루트 액세스에 대해 Off를 선택합니다. 루트 사용자가 익명 사용자에게 스쿼트되면 chown 또는 을 실행할 수 있는 액세스 권한이 더 이상 없습니다<block ref="451ac5d05b7e3e41db0c92126d9290ad" category="inline-link-rx"></block> NFS 마운트의 파일 또는 폴더와 루트 사용자가 생성한 파일 또는 폴더에 anon UID가 소유자/그룹으로 표시됩니다. 또한 루트 사용자가 NFSv4 ACL을 수정할 수 없습니다. 그러나 루트 사용자는 chmod 및 삭제된 파일에 대한 명시적 권한이 없는 액세스 권한을 계속 가집니다. 루트 사용자의 파일 및 폴더 권한에 대한 액세스를 제한하려면 NTFS ACL을 사용하여 볼륨을 사용하고, "root"라는 Windows 사용자를 생성하고, 파일 또는 폴더에 원하는 권한을 적용하는 것이 좋습니다.</block>
  <block id="0b2cc4ee83c7e73e4426e294c95be2c7" category="section-title">익명 사용자</block>
  <block id="f489703ccadc6e9616bab479ace6cf03" category="paragraph">익명(anon) 사용자 ID는 유효한 NFS 자격 증명 없이 도착하는 클라이언트 요청에 매핑된 UNIX 사용자 ID 또는 사용자 이름을 지정합니다. 여기에는 루트 스쿼싱 사용 시 루트 사용자가 포함될 수 있습니다. Cloud Volumes Service의 anon 사용자는 65534입니다.</block>
  <block id="48da046d67add0ab58d9cbc2c2da421c" category="paragraph">이 UID는 일반적으로 Linux 환경의 사용자 이름 'nobody' 또는 'nfsnobody'와 관련이 있습니다. Cloud Volumes Service는 로컬 UNIX 사용자 ' pcuser ' 로 65534도 사용합니다(“ 절 참조)<block ref="21f1cd16f2baec63c7c604945762d1f2" category="inline-xref-macro-rx"></block>"). LDAP에서 일치하는 유효한 UNIX 사용자를 찾을 수 없는 경우 Windows에서 UNIX로의 이름 매핑의 기본 대체 사용자입니다.</block>
  <block id="1a64786b80a72f5b468ee5a6c27c19bb" category="paragraph">Linux의 사용자 이름과 UID 65534의 Cloud Volumes Service 간 사용자 이름 차이로 인해 65534에 매핑된 사용자의 이름 문자열이 NFSv4.1을 사용할 때 일치하지 않을 수 있습니다. 따라서 일부 파일 및 폴더에 대해 사용자로 'nobody'가 표시될 수 있습니다. 자세한 내용은 " 단원을 참조하십시오<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>"를 참조하십시오.</block>
  <block id="093b885796f6b6edbf133d153a574ee0" category="section-title">액세스 제어/내보내기</block>
  <block id="c40a72feaf9e622dcbd1a55edff6fdbf" category="paragraph">NFS 마운트에 대한 초기 엑스포트/공유 액세스는 엑스포트 정책 내에 포함된 호스트 기반 엑스포트 정책 규칙을 통해 제어됩니다. 호스트 IP, 호스트 이름, 서브넷, 넷그룹 또는 도메인이 정의되어 NFS 공유를 마운트하는 액세스 권한과 호스트에 허용되는 액세스 수준을 허용합니다. 엑스포트 정책 규칙 구성 옵션은 Cloud Volumes Service 레벨에 따라 다릅니다.</block>
  <block id="519377bf4a5b0a2078c3d66b249040aa" category="paragraph">CVS-SW의 경우 내보내기 정책 구성에 다음 옵션을 사용할 수 있습니다.</block>
  <block id="fdbbd602d808015eb2f536ce2add5b6e" category="list-text">* 클라이언트 일치. * 쉼표로 구분된 IP 주소 목록, 쉼표로 구분된 호스트 이름, 서브넷, 넷그룹, 도메인 이름 목록.</block>
  <block id="4984ee657e0bd2919476369a84dfe159" category="list-text">* RO/RW 액세스 규칙. * 읽기/쓰기 또는 읽기 전용 을 선택하여 내보내기에 대한 액세스 수준을 제어합니다.</block>
  <block id="3a3236a433ddc1bb46fe40e058aad584" category="list-text">* 루트 액세스(켜기/끄기). * 루트 스쿼시를 구성합니다(“ 절 참조)<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>"를 참조하십시오.)</block>
  <block id="0c1b0b2a02124e4f1e2111f36d28432e" category="list-text">* Protocol type. * 이 옵션은 NFS 마운트에 대한 액세스를 특정 프로토콜 버전으로 제한합니다. 볼륨에 대해 NFSv3과 NFSv4.1을 모두 지정할 때 두 확인란을 모두 비워 두거나 두 확인란을 모두 선택합니다.</block>
  <block id="553de93bd85985676f0ef4762f4de2ab" category="list-text">* Kerberos 보안 수준(Kerberos 활성화 가 선택된 경우). * 읽기 전용 또는 읽기-쓰기 액세스에 대해 krb5, krb5i 및/또는 krb5p의 옵션을 제공합니다.</block>
  <block id="a98abf6af551f8564e89efb200e37032" category="section-title">변경 소유권(chown) 및 변경 그룹(chgrp)</block>
  <block id="545978eda72a981e986a37d84621575d" category="paragraph">Cloud Volumes Service의 NFS에서는 루트 사용자만 파일 및 폴더에 대해 chown/chgrp를 실행할 수 있습니다. 다른 사용자는 자신이 소유한 파일에서도 'Operation not mitted(작업이 허용되지 않음)' 오류를 볼 수 있습니다. 루트 스쿼시를 사용하는 경우(“ 섹션에서 다룹니다<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>”), 루트가 비루트 사용자에게 스쿼트되고 chown 및 chgrp에 대한 액세스가 허용되지 않습니다. 현재 Cloud Volumes Service에는 루트 이외의 사용자에 대한 chown 및 chgrp를 허용하는 대안이 없습니다. 소유권을 변경해야 하는 경우 이중 프로토콜 볼륨을 사용하고 보안 스타일을 NTFS로 설정하여 Windows 측의 권한을 제어할 수 있습니다.</block>
  <block id="b40637b973f7941123dacf09ceef0fba" category="section-title">권한 관리</block>
  <block id="b48f3521890100492cddc30349f6e7b2" category="paragraph">Cloud Volumes Service는 모드 비트(예: rwx의 경우 644, 777 등)와 NFSv4.1 ACL을 모두 지원하여 UNIX 보안 스타일을 사용하는 볼륨의 NFS 클라이언트에 대한 사용 권한을 제어합니다. 이러한 사용자(chmod, chown 또는 nfs4_setfacl 등)에 대해 표준 권한 관리가 사용되며 이를 지원하는 모든 Linux 클라이언트와 함께 작동합니다.</block>
  <block id="a4f4a04396f203764eb677e59aeea059" category="paragraph">또한 NTFS로 설정된 이중 프로토콜 볼륨을 사용하는 경우 NFS 클라이언트는 Windows 사용자에 대한 Cloud Volumes Service 이름 매핑을 활용할 수 있으며, 이 이름 매핑은 NTFS 권한을 확인하는 데 사용됩니다. Cloud Volumes Service를 Windows 사용자 이름에 올바르게 매핑하려면 유효한 UNIX 사용자 이름이 필요하기 때문에 이를 위해서는 Cloud Volumes Service에 대한 LDAP 연결이 필요합니다.</block>
  <block id="40c93306b7b5fa43d5bdeaaf6446b5c8" category="section-title">NFSv3에 대한 세부적인 ACL 제공</block>
  <block id="38244b1450366af1bc12c6d85adcf6d2" category="paragraph">모드 비트 사용 권한은 소유자, 그룹 및 다른 모든 관련자만 사용할 수 있습니다. 즉, 기본 NFSv3에 대해 세부적인 사용자 액세스 제어를 사용할 수 없습니다. Cloud Volumes Service는 POSIX ACL 또는 확장된 특성(예: chattr)을 지원하지 않으므로 NFSv3을 사용하는 다음 시나리오에서만 세분화된 ACL을 사용할 수 있습니다.</block>
  <block id="15ad8d0b9866344d62ea9ffa4ae25982" category="list-text">유효한 UNIX와 Windows 사용자 간 매핑을 사용하는 NTFS 보안 스타일 볼륨(CIFS 서버 필요)</block>
  <block id="c14f9a108935fe84b2ee2c80664062d4" category="list-text">NFSv4.1 ACL은 관리 클라이언트 마운트 NFSv4.1을 사용하여 ACL을 적용하여 적용됩니다.</block>
  <block id="b90aebde70afe18a23fa55cafb7bd6e7" category="inline-link-macro">"LDAP"</block>
  <block id="fc96ac54908c774cd60159cf8c65272e" category="paragraph">두 방법 모두 UNIX ID 관리를 위한 LDAP 연결과 유효한 UNIX 사용자 및 그룹 정보를 채워야 합니다(섹션 참조) <block ref="941c88f858b9781fbfe78651e071df70" category="inline-link-macro-rx"></block>) 및 은 CVS - 성능 인스턴스에서만 사용할 수 있습니다. NFS에서 NTFS 보안 스타일 볼륨을 사용하려면 SMB 연결이 구성되어 있지 않더라도 이중 프로토콜(SMB 및 NFSv3) 또는 이중 프로토콜(SMB 및 NFSv4.1)을 사용해야 합니다. NFSv3 마운트에서 NFSv4.1 ACL을 사용하려면 프로토콜 유형으로 'both(NFSv3/NFSv4.1)'를 선택해야 합니다.</block>
  <block id="b9fd9ad6fc3c3b72bb1d8b9db35c4ff8" category="inline-link">NFS4_ACL-NFSv4 액세스 제어 목록</block>
  <block id="8454ec39d80a4c7dced33aed7bc5cc3c" category="paragraph">일반 UNIX 모드 비트는 NTFS 또는 NFSv4.x ACL이 제공하는 사용 권한과 동일한 수준의 세분성을 제공하지 않습니다. 다음 표에서는 NFSv3 모드 비트와 NFSv4.1 ACL 간의 사용 권한 세분화를 비교합니다. NFSv4.1 ACL에 대한 자세한 내용은 을 참조하십시오<block ref="6f8990d4da30b2d9c1096f2d7fdec422" category="inline-link-rx"></block>.</block>
  <block id="04bf6ba29148b02f9bc0aece8b1ab976" category="cell">NFSv3 모드 비트</block>
  <block id="ec969632045eaebe3e92b63bc00edf03" category="cell">NFSv4.1 ACL</block>
  <block id="b7073329ceba059aa3ad7875190c661f" category="list-text">실행 시 사용자 ID를 설정합니다</block>
  <block id="573fa671705c50ff1c121cd141dfeb90" category="list-text">실행 시 그룹 ID를 설정합니다</block>
  <block id="0ab8eb5c98bf5a8e01cc9dc03065fd63" category="list-text">바꾼 텍스트 저장(POSIX에 정의되지 않음)</block>
  <block id="78e3e57905e586d5d03519b5883d9b49" category="list-text">소유자에 대한 읽기 권한</block>
  <block id="07ea3a6ddfd17ab896abc34a5fb98c32" category="list-text">소유자의 쓰기 권한</block>
  <block id="ef1c725ac00a8daafb96e6f926b38e84" category="list-text">파일의 소유자에 대한 권한을 실행하거나 디렉터리에서 소유자를 찾기(검색) 권한을 실행합니다</block>
  <block id="d51cc2a74a686e9f6b08108c215a677e" category="list-text">그룹에 대한 읽기 권한</block>
  <block id="6750a7dbc586cfe9c3c1e6fc348bc47f" category="list-text">그룹에 대한 쓰기 권한</block>
  <block id="66471165b6102256624c1aaa1bf05ef9" category="list-text">파일의 그룹에 대한 권한을 실행하거나 디렉터리의 그룹에 대한 검색 권한을 찾습니다</block>
  <block id="860c8444d0dfe3bf1e1818fdbe8c3733" category="list-text">다른 사람의 읽기 권한</block>
  <block id="95663f359ae8aaa2910488b36c7168fb" category="list-text">다른 사람에 대한 권한을 작성합니다</block>
  <block id="54384d9f12231abb228dd692b2c7a689" category="list-text">파일의 다른 사람에 대한 권한을 실행하거나 디렉터리에서 다른 사람에 대한 검색 권한을 찾습니다</block>
  <block id="4d6deb7613496d18f12d0d0d0fe84ecb" category="paragraph">ACE(액세스 제어 항목) 형식(허용/거부/감사) * 상속 플래그 * directory-inherit * file-inherit * no-propagate-inherit * inherit-only</block>
  <block id="13640bb94453faf76256f49439337e2e" category="paragraph">권한 * 읽기-데이터(파일)/목록-디렉토리(디렉토리) * 쓰기-데이터(파일)/생성-파일(디렉토리) * 추가-데이터(파일)/생성-하위 디렉토리(디렉토리) * 실행(파일)/변경-디렉토리(디렉토리) * 삭제 * delete-child * read-attributes * write-named-attributes * write-named-acner-write-write-acl-write-write-write-write-acl-write-write-write-write-acl-write-write-write-write-</block>
  <block id="0bfe97b6a2010bf8a46c30c256d9bc67" category="paragraph">마지막으로, RPC 패킷 제한에 따라 NFS 그룹 멤버 자격(NFSv3 및 NFSv4.x에서 모두)은 AUTH_SYS에 대한 기본값 최대 16으로 제한됩니다. NFS Kerberos는 최대 32개의 그룹과 NFSv4 ACL을 제공하므로 사용자 및 그룹 ACL(ACE당 최대 1024개 항목)을 세부적으로 적용하여 제한을 제거할 수 있습니다.</block>
  <block id="27aabeb671232f388e6288cf9395fda9" category="inline-link">NFS 볼륨 생성 및 관리</block>
  <block id="75812520c9040a205064d0d2cb2263e9" category="section-title">NFSv3 사용자 및 그룹 ID</block>
  <block id="b1695eaaf5db3491be45228e42d7894f" category="paragraph">NFSv3 사용자 및 그룹 ID는 이름이 아닌 숫자 ID로 와이어를 통해 제공됩니다. Cloud Volumes Service는 NFSv3을 사용하는 이러한 숫자 ID에 대해 사용자 이름 확인을 수행하지 않으며 UNIX 보안 스타일 볼륨에서는 모드 비트만 사용합니다. NFSv4.1 ACL이 있으면 NFSv3을 사용하더라도 ACL을 제대로 해결하려면 숫자 ID 조회 및/또는 이름 문자열 조회가 필요합니다. NTFS 보안 스타일 볼륨에서 Cloud Volumes Service는 유효한 UNIX 사용자로 숫자 ID를 확인한 다음 유효한 Windows 사용자에게 매핑하여 액세스 권한을 협상해야 합니다.</block>
  <block id="c88acee1e86a1d4e088392362c04bb3b" category="section-title">NFSv3 사용자 및 그룹 ID의 보안 제한</block>
  <block id="51d0cb09f5edabf17b3490e1b53d7b22" category="paragraph">NFSv3에서는 클라이언트와 서버가 숫자 ID로 읽기 또는 쓰기를 시도하는 사용자가 유효한 사용자인지 확인할 필요가 없으며 암시적으로 신뢰됩니다. 이렇게 하면 숫자 ID를 스푸핑하여 파일 시스템이 잠재적 위반으로 열립니다. 이와 같은 보안 문제를 방지하기 위해 Cloud Volumes Service에서 몇 가지 옵션을 사용할 수 있습니다.</block>
  <block id="467b69ba310f54b371bbdbffe09e6497" category="list-text">NFS용 Kerberos를 구현하면 사용자가 사용자 이름 및 암호 또는 keytab 파일로 인증하여 Kerberos 티켓을 받아 마운트에 액세스할 수 있도록 합니다. Kerberos는 CVS에서 사용 가능 - 성능 인스턴스와 NFSv4.1에서만 지원됩니다.</block>
  <block id="9120b024c7fefc321f0ebc6fee670c59" category="list-text">엑스포트 정책 규칙에 따라 호스트 목록을 제한하면 NFSv3 클라이언트가 Cloud Volumes Service 볼륨에 액세스할 수 있는 범위가 제한됩니다.</block>
  <block id="1b652183dcffb7bab733d50929de6844" category="list-text">이중 프로토콜 볼륨을 사용하고 NTFS ACL을 볼륨에 적용하면 NFSv3 클라이언트가 숫자 ID를 유효한 UNIX 사용자 이름으로 확인하게 되어 액세스 마운트에 대한 올바른 인증이 필요합니다. 이를 위해서는 LDAP를 설정하고 UNIX 사용자 및 그룹 ID를 구성해야 합니다.</block>
  <block id="8d5c591e079f79f63fd9e9807dc0f747" category="list-text">루트 사용자를 스쿼팅하면 루트 사용자가 NFS 마운트에 수행할 수 있는 손상을 제한하지만 위험을 완전히 제거할 수는 없습니다. 자세한 내용은 " 단원을 참조하십시오<block ref="60067fcb7aeefdc389264d741499b983" category="inline-xref-macro-rx"></block>.”</block>
  <block id="2013c75e17676506ba3c06142530277a" category="paragraph">궁극적으로 NFS 보안은 고객이 제공하는 프로토콜 버전으로 제한됩니다. NFSv3은 일반적으로 NFSv4.1보다 더 우수한 성능을 제공하지만, 같은 수준의 보안을 제공하지 않습니다.</block>
  <block id="1d9f0263509a5bc0f447962105bb1a92" category="paragraph">NFSv4.1은 NFSv3과 비교할 때 다음과 같은 이유로 더욱 뛰어난 보안 및 안정성을 제공합니다.</block>
  <block id="11d0cb4a0817a571de35b1a57bcd7b86" category="list-text">임대 기반 메커니즘을 통한 통합 잠금</block>
  <block id="2a7079f12b8b7175a78aa4192442cceb" category="list-text">상태 저장 세션</block>
  <block id="78d4290f55bf351449981f773525bc0b" category="list-text">단일 포트에서 모든 NFS 기능 지원(2049)</block>
  <block id="53ec1aa3e51de041ca30580dcd5695db" category="list-text">TCP 전용</block>
  <block id="762c048886aaa3279e7ff7d4bbe56f5c" category="list-text">ID 도메인 매핑</block>
  <block id="7e6be8eb2ba9a556864cfd20857c1565" category="list-text">Kerberos 통합(NFSv3은 Kerberos 사용 가능, NFS에만 해당, NLM 같은 보조 프로토콜에는 사용할 수 없음)</block>
  <block id="1f2bcbb2c0049fcc033a40cb665f19fc" category="section-title">NFSv4.1 종속성</block>
  <block id="f83a89d33e724f74ff5a673c34fe9ac6" category="paragraph">NFSv4.1의 추가 보안 기능 덕분에 NFSv3을 사용할 필요가 없는 몇 가지 외부 의존성이 발생했습니다(Active Directory와 같은 SMB의 의존도 필요 방식과 유사).</block>
  <block id="0e8ff8f10d56a8534800018ecdbcbfb7" category="paragraph">Cloud Volumes Service는 NFSv4.x ACL을 지원하므로 다음과 같은 일반적인 POSIX 스타일 사용 권한에 비해 뚜렷한 이점을 제공합니다.</block>
  <block id="e7c21967cc185dee47ba9548ba30b26e" category="list-text">파일 및 디렉토리에 대한 사용자 액세스를 세부적으로 제어</block>
  <block id="a5e0d0cbd4020f568d08cdaed3dedd6b" category="list-text">NFS 보안 강화</block>
  <block id="fd272c227f4884473fc1b4409d1fa6f0" category="list-text">CIFS/SMB와의 상호 운용성 향상</block>
  <block id="1c0d9e3bfe82d85776be6deeefb1b8d1" category="list-text">AUTH_SYS 보안을 사용하여 사용자당 16개 그룹의 NFS 제한을 제거합니다</block>
  <block id="37c82add6470c2f73fad45f1e887f214" category="list-text">ACL은 GID(Group ID) 확인이 필요하지 않으므로 GID 리무진을 효과적으로 제거할 수 있습니다. 따라서 Cloud Volumes Service가 아닌 NFS 클라이언트에서 ACL을 제어할 수 있습니다. NFSv4.1 ACL을 사용하려면 클라이언트의 소프트웨어 버전이 이를 지원하고 적절한 NFS 유틸리티가 설치되어 있어야 합니다.</block>
  <block id="f497540fbfe4bb6c8784249b7ca44322" category="section-title">NFSv4.1 ACL과 SMB 클라이언트 간의 호환성</block>
  <block id="b18893becc5c5979b433330d581d0502" category="paragraph">NFSv4 ACL은 Windows 파일 레벨 ACL(NTFS ACL)과 다르지만 유사한 기능을 제공합니다. 그러나 멀티 프로토콜 NAS 환경에서 NFSv4.1 ACL이 있고 동일한 데이터 세트의 NFS 및 SMB(이중 프로토콜 액세스)를 사용 중인 경우에는 SMB2.0 이상을 사용하는 클라이언트에서 Windows 보안 탭의 ACL을 보거나 관리할 수 없습니다.</block>
  <block id="e24382a2de980eb4d0fad087c2279291" category="section-title">NFSv4.1 ACL의 작동 방식</block>
  <block id="65da9b80e25e8e6b76e6f95a27e33773" category="paragraph">참고로 다음 용어가 정의되어 있습니다.</block>
  <block id="3f33ebc7aedc435f5da6f0cdb363e903" category="list-text">* 액세스 제어 목록(ACL). * 권한 항목의 목록입니다.</block>
  <block id="e8b619b2feea9964d68e458010421937" category="list-text">* ACE(액세스 제어 항목).* 목록에 있는 권한 항목.</block>
  <block id="e22c8ddaa933012f7b9658b15556e1d9" category="paragraph">SetAttr 작업 중에 클라이언트가 파일에서 NFSv4.1 ACL을 설정하면 Cloud Volumes Service는 개체에 해당 ACL을 설정하여 기존 ACL을 대체합니다. 파일에 ACL이 없으면 파일에 대한 모드 권한은 owner@, group@ 및 everyone@에서 계산됩니다. 파일에 기존 SUID/SGID/고정 비트가 있으면 영향을 받지 않습니다.</block>
  <block id="bbfc3dd393a8c0fb0275a317ea92cdb6" category="paragraph">GETATTR 작업 중에 클라이언트가 파일에서 NFSv4.1 ACL을 받으면 Cloud Volumes Service는 오브젝트와 연결된 NFSv4.1 ACL을 읽고 ACE 목록을 생성하고 목록을 클라이언트에 반환합니다. 파일에 NT ACL 또는 모드 비트가 있는 경우 ACL은 모드 비트에서 구성되며 클라이언트로 반환됩니다.</block>
  <block id="e91b7b9c71eaf21c16d5232d74f4c5c3" category="paragraph">ACL에 거부 ACE가 있는 경우 액세스가 거부되고 ACE 허용 이 있는 경우 액세스가 부여됩니다. 그러나 ACL에 ACE가 없는 경우에도 액세스가 거부됩니다.</block>
  <block id="85e34118580ac115f838cd805832291e" category="paragraph">보안 설명자는 SACL(보안 ACL) 및 DACL(임의 ACL)으로 구성됩니다. NFSv4.1이 CIFS/SMB와 상호 운용될 경우 DACL은 NFSv4와 CIFS에 매핑된 일대일 매핑입니다. DACL은 allow 및 deny ACE로 구성됩니다.</block>
  <block id="f26fe9c5bd9a38964b075295ff6b600f" category="paragraph">NFSv4.1 ACL이 설정된 파일 또는 폴더에서 기본적인 "chmod"를 실행하면 기존 사용자 및 그룹 ACL이 유지되지만 기본 소유자 @, group@, everyone@acls는 수정됩니다.</block>
  <block id="51cdc67f907418899df11513b246dd1c" category="inline-link">상속 플래그</block>
  <block id="bfb9f4f4e0b3ee74bbf0624c3acb6f05" category="paragraph">NFSv4.1 ACL을 사용하는 클라이언트는 시스템의 파일 및 디렉토리에 대한 ACL을 설정하고 볼 수 있습니다. ACL이 있는 디렉터리에 새 파일이나 하위 디렉터리가 만들어지면 해당 개체는 해당 ACL로 태그가 지정된 ACL의 모든 ACE를 상속합니다<block ref="efe32d9e162a0a9bfdfda1b55921a64c" category="inline-link-rx"></block>.</block>
  <block id="4ede33bb65432e74e322d690608c2334" category="paragraph">파일 또는 디렉토리에 NFSv4.1 ACL이 있으면 해당 ACL을 사용하여 파일 또는 디렉토리에 액세스하는 데 사용되는 프로토콜에 관계없이 액세스를 제어할 수 있습니다.</block>
  <block id="0d733f1633c2aa51a107a6e21dfd5644" category="paragraph">파일 및 디렉토리는 ACE에 올바른 상속 플래그가 지정된 경우 상위 디렉토리의 NFSv4 ACL에서 ACE를 상속합니다(적절한 수정 사항이 있을 수 있음).</block>
  <block id="a61aaa9a4f599d5b80e71c232d23147a" category="paragraph">NFSv4 요청의 결과로 파일 또는 디렉토리가 생성되면 결과 파일 또는 디렉토리의 ACL은 파일 생성 요청에 ACL이 포함되어 있는지 또는 표준 UNIX 파일 액세스 권한만 포함되는지에 따라 달라집니다. ACL은 상위 디렉토리에 ACL이 있는지 여부에도 따라 달라집니다.</block>
  <block id="5ac8b682abcf5cc600bff1df60b6eeb0" category="list-text">요청에 ACL이 포함된 경우 해당 ACL이 사용됩니다.</block>
  <block id="68d4655ff3b6740e5735fd80c7910023" category="list-text">요청에 표준 UNIX 파일 액세스 권한만 있고 상위 디렉토리에 ACL이 없는 경우 클라이언트 파일 모드를 사용하여 표준 UNIX 파일 액세스 권한을 설정합니다.</block>
  <block id="2cf6ef9c801da66f5a80033edc51acf8" category="list-text">요청에 표준 UNIX 파일 액세스 권한만 있고 상위 디렉토리에 상속할 수 없는 ACL이 있는 경우, 요청에 전달된 모드 비트를 기반으로 하는 기본 ACL이 새 개체에 설정됩니다.</block>
  <block id="c1eac2f9759f1dd2f7680287789d03f9" category="list-text">요청에 표준 UNIX 파일 액세스 권한만 포함되어 있지만 상위 디렉토리에 ACL이 있는 경우 ACE에 적절한 상속 플래그가 지정된 경우 상위 디렉토리의 ACL에 있는 ACE는 새 파일 또는 디렉토리에 의해 상속됩니다.</block>
  <block id="1aeffd8cf8d8faca5f1d6379d7ad7b42" category="section-title">ACE 권한</block>
  <block id="be30a66f742a1c4b197f654c5456f525" category="inline-link">방법: NFSv4 ACL 사용</block>
  <block id="1e0ba766d5b81a0076401367c75ba49d" category="paragraph">NFSv4.1 ACL 사용 권한은 일련의 대문자 및 소문자 값('rxtncy' 등)을 사용하여 액세스를 제어합니다. 이러한 문자 값에 대한 자세한 내용은 을 참조하십시오<block ref="19e15d2b871d5802ed53b8bb943cfa1d" category="inline-link-rx"></block>.</block>
  <block id="e5db87d9c7835194478e833b1c2341a3" category="section-title">umask 및 ACL 상속을 사용하는 NFSv4.1 ACL 동작</block>
  <block id="2d01b8b9abf1cd5dd5dc3a87babfa478" category="inline-link">NFSv4 ACL을 사용하면 ACL 상속을 제공할 수 있습니다</block>
  <block id="90f70b82033cb9c398aab9c2ab8e4b97" category="inline-link">ACL 상속 플래그입니다</block>
  <block id="b40177dea06ae321d6ba903c296a8bf4" category="paragraph"><block ref="a4a4eca6555a8c7e71d54636b6d02bd2" category="inline-link-rx"></block>. ACL 상속은 NFSv4.1 ACL이 설정된 개체 아래에 생성된 파일 또는 폴더가 의 구성에 따라 ACL을 상속할 수 있음을 의미합니다<block ref="0dfdf6ea7cd5f3c14c3e752e09504ece" category="inline-link-rx"></block>.</block>
  <block id="e3847e2a1d0d27fe2e50f7b68080126e" category="inline-link">umask(umask</block>
  <block id="391e42635de569b9fd15585f0b03777a" category="inline-link">RFC 5661</block>
  <block id="a5147a6538ae36d50a705033dee8e1ea" category="paragraph"><block ref="63bfc707387dfd47bf50e485c5b4d27f" category="inline-link-rx"></block> 관리자 개입 없이 디렉터리에서 파일과 폴더를 만들 수 있는 권한 수준을 제어하는 데 사용됩니다. 기본적으로 Cloud Volumes Service에서는 umask 가 에 따라 예상되는 동작을 나타내는 상속된 ACL을 재정의할 수 있도록 합니다<block ref="c202d210fe4151f93fd56939449ae558" category="inline-link-rx"></block>.</block>
  <block id="c283f512453dfbe4a4d54a5de963c63a" category="section-title">ACL 형식 지정</block>
  <block id="af26ba96448cb4f36fa75d37c0c24884" category="paragraph">NFSv4.1 ACL에는 특정한 형식이 있습니다. 다음은 파일에 설정된 ACE 예제입니다.</block>
  <block id="90bdfef72a7e9f73c8492c28764bfecc" category="paragraph">앞의 예제는 의 ACL 형식 지침을 따릅니다.</block>
  <block id="7d665626903fe1069f3c052eb3b93597" category="inline-link"><block ref="7d665626903fe1069f3c052eb3b93597" category="inline-link-rx"></block></block>
  <block id="192707027419e02a79fe3b9af5a845c4" category="paragraph">A의 유형은 "허용"을 의미합니다. 이 경우 보안 주체가 그룹이 아니며 상속을 포함하지 않으므로 상속 플래그가 설정되지 않습니다. 또한 ACE는 감사 항목이 아니므로 감사 플래그를 설정할 필요가 없습니다. NFSv4.1 ACL에 대한 자세한 내용은 을 참조하십시오<block ref="588b628ed19e81b60db990218fbd0aa2" category="inline-link-rx"></block>.</block>
  <block id="767a03c18193757348519856b05f7d1c" category="paragraph">NFSv4.1 ACL이 제대로 설정되지 않았거나 클라이언트 및 서버에서 이름 문자열을 확인할 수 없는 경우 ACL이 예상대로 작동하지 않거나 ACL 변경이 적용되지 않고 오류가 발생할 수 있습니다.</block>
  <block id="e0ad83b43ccb7e44bcdb46bcdc1189d9" category="paragraph">샘플 오류에는 다음이 포함됩니다.</block>
  <block id="bf837e35002530c307569ba2ec195e9a" category="section-title">명시적 거부</block>
  <block id="68a14c985893a66fdf24403b891ddc6c" category="paragraph">NFSv4.1 권한에는 소유자, 그룹 및 모든 사용자에 대한 명시적 거부 특성이 포함될 수 있습니다. 따라서 NFSv4.1 ACL은 기본적으로 -deny를 사용하기 때문에 ACL이 명시적으로 ACE에 의해 부여되지 않으면 거부됩니다. 명시적 거부 특성은 액세스 ACE를 명시적 또는 명시적으로 재정의합니다.</block>
  <block id="22759a58413e45c1ab8a0a53300ea43c" category="paragraph">거부 ACE는 Ddes 특성 태그로 설정됩니다.</block>
  <block id="3bce872a832106c5038ea04d532162ba" category="paragraph">아래 예에서 group@은 모든 읽기 및 실행 권한을 허용하지만 모든 쓰기 액세스는 거부됩니다.</block>
  <block id="8b4ed201924d12a3d0ec41f5538460b2" category="paragraph">거부 ACE는 혼란스럽고 복잡할 수 있으므로 가능하면 피해야 합니다. 명시적으로 정의되지 않은 ACL 허용 은 암시적으로 거부됩니다. 거부 ACE가 설정되면 사용자에게 액세스 권한이 부여될 것으로 예상되는 경우 액세스가 거부될 수 있습니다.</block>
  <block id="fb976fa579c74ac9e0b64ac922a938d7" category="paragraph">앞의 ACE 집합은 모드 비트에서 755와 동일하며, 이는 다음을 의미합니다.</block>
  <block id="de9d71e2841fbf06bf2e96e40b0655d0" category="list-text">소유자에게는 모든 권한이 있습니다.</block>
  <block id="391533122a44e47fc6d7eed8f3d46152" category="list-text">그룹은 읽기 전용입니다.</block>
  <block id="233c314243fd8ff0f129355150358c9b" category="list-text">다른 사람들은 읽기 전용입니다.</block>
  <block id="004367158d382df49675a222d852e2c2" category="paragraph">그러나 사용 권한이 775 상응 권한으로 조정되더라도 모든 사용자에 대해 명시적 거부 설정이 설정되어 있으므로 액세스가 거부될 수 있습니다.</block>
  <block id="c9533a3d4ca28b597d9e4f0b7c2d7d28" category="section-title">NFSv4.1 ID 도메인 매핑 종속성</block>
  <block id="b8c7283821c3d4795f01644c47598298" category="paragraph">NFSv4.1은 ID 도메인 매핑 논리를 보안 계층으로 활용하여 NFSv4.1 마운트에 액세스하려는 사용자가 실제로 자신들이 주장하는 사용자인지 확인합니다. 이 경우 NFSv4.1 클라이언트에서 들어오는 사용자 이름 및 그룹 이름에 이름 문자열이 추가되고 Cloud Volumes Service 인스턴스로 보내집니다. 사용자 이름/그룹 이름 및 ID 문자열 조합이 일치하지 않으면 사용자 및/또는 그룹이 클라이언트의 '/etc/idmapd.conf' 파일에 지정된 기본 nobody 사용자로 충돌합니다.</block>
  <block id="5aec5d2b81e4e7bc2bb96b8eee7f6a1f" category="paragraph">이 ID 문자열은 특히 NFSv4.1 ACL 및/또는 Kerberos를 사용하는 경우 적절한 권한 준수를 위한 요구 사항입니다. 따라서 적절한 사용자 및 그룹 이름 ID 확인을 위해 클라이언트와 Cloud Volumes Service 간에 일관성을 유지하기 위해 LDAP 서버와 같은 이름 서비스 서버 종속성이 필요합니다.</block>
  <block id="ea6c924c6846969cae29ab27aa4c3d9e" category="paragraph">Cloud Volumes Service는 정적 기본 ID 도메인 이름 값인 ddefaultv4iddomain.com 를 사용합니다. NFS 클라이언트는 ID 도메인 이름 설정에 대해 DNS 도메인 이름으로 기본 설정되지만, '/etc/idmapd.conf'에서 ID 도메인 이름을 수동으로 조정할 수 있습니다.</block>
  <block id="a524142e9e2e4c80b2545aea06b82fb6" category="paragraph">Cloud Volumes Service에서 LDAP가 활성화된 경우 Cloud Volumes Service는 NFS ID 도메인을 자동화하여 DNS에서 검색 도메인에 대해 구성된 대로 변경할 수 있으며, 다른 DNS 도메인 검색 이름을 사용하지 않는 한 클라이언트를 수정할 필요가 없습니다.</block>
  <block id="13c371145cb8e423bcc06c41dafa7d27" category="paragraph">Cloud Volumes Service가 로컬 파일 또는 LDAP에서 사용자 이름 또는 그룹 이름을 확인할 수 있는 경우 도메인 문자열이 사용되고 일치하지 않는 도메인 ID는 아무도 입력할 수 없습니다. Cloud Volumes Service가 로컬 파일 또는 LDAP에서 사용자 이름 또는 그룹 이름을 찾을 수 없는 경우 숫자 ID 값이 사용되며 NFS 클라이언트가 이름을 제대로 확인합니다(NFSv3 동작과 유사).</block>
  <block id="2920d1231c77a15a148be7e24a4224a8" category="paragraph">클라이언트의 NFSv4.1 ID 도메인을 Cloud Volumes Service 볼륨에서 사용 중인 도메인과 일치하도록 변경하지 않고도 다음과 같은 동작이 발생합니다.</block>
  <block id="cf7f7139ed9bd9c2ce206642dd7fa858" category="list-text">로컬 UNIX 사용자 및 그룹에 정의된 루트와 같이 Cloud Volumes Service에 로컬 항목이 있는 UNIX 사용자 및 그룹이 nobody 값으로 스쿼트됩니다.</block>
  <block id="b4aa27a84e1a2079915902824805faed" category="list-text">LDAP에 항목이 있는 UNIX 사용자 및 그룹(Cloud Volumes Service가 LDAP를 사용하도록 구성된 경우)은 DNS 도메인이 NFS 클라이언트와 Cloud Volumes Service 간에 서로 다른 경우 아무도 사용하지 않습니다.</block>
  <block id="ef7ad0d3015777d2990a6af6b71f374b" category="list-text">로컬 항목이나 LDAP 항목이 없는 UNIX 사용자 및 그룹은 숫자 ID 값을 사용하고 NFS 클라이언트에 지정된 이름으로 확인합니다. 클라이언트에 이름이 없으면 숫자 ID만 표시됩니다.</block>
  <block id="62dcf28b3972264f1b30c2bd51a03def" category="paragraph">다음은 이전 시나리오의 결과입니다.</block>
  <block id="696c02f546b2ffcdac74d99c917daa24" category="paragraph">클라이언트 및 서버 ID 도메인이 일치하면 동일한 파일 목록이 표시됩니다.</block>
  <block id="406ef9702da9a43b3a7b54a25411d799" category="paragraph">이 문제와 해결 방법에 대한 자세한 내용은 “ 절을 참조하십시오<block ref="122d38ffc304701fda2219494370e55a" category="inline-xref-macro-rx"></block>.”</block>
  <block id="feb3aa3308fe030fd35a38b78a2300bd" category="section-title">Kerberos 종속성</block>
  <block id="40bbfae3ce12130d42058c7017ceb5ed" category="paragraph">NFS에서 Kerberos를 사용하려면 Cloud Volumes Service에서 다음 권한이 있어야 합니다.</block>
  <block id="97a82eff6d3d292af521c01da598a578" category="list-text">Kerberos KDC(메일 센터 서비스)용 Active Directory 도메인</block>
  <block id="7539d3051db830d97dee8f6d5d504289" category="list-text">LDAP 기능에 대한 UNIX 정보로 채워진 사용자 및 그룹 속성이 있는 Active Directory 도메인(Cloud Volumes Service의 NFS Kerberos에는 적절한 기능을 위해 사용자 SPN-UNIX 사용자 매핑이 필요합니다.)</block>
  <block id="39780a85d8e7edcc28fd4bc1f6b379f9" category="list-text">Cloud Volumes Service 인스턴스에 대해 LDAP가 설정되었습니다</block>
  <block id="9b306ebe81f909f9a456adcadd197090" category="list-text">DNS 서비스에 대한 Active Directory 도메인입니다</block>
  <block id="3f1e5b600401b83c49c16e0c80170842" category="section-title">NFSv4.1 및 그 누구도 사용자/그룹을 대상으로 하지 않습니다</block>
  <block id="5c79e57a072b5ea9e69b08395268c3fe" category="paragraph">NFSv4.1 구성에서 가장 흔히 발생하는 문제 중 하나는 'user:group'의 'nobody:nobody'의 조합으로 'ls'를 사용하여 파일 또는 폴더가 목록에 표시되는 것입니다.</block>
  <block id="2436a7de6f774d774219a86839e40d54" category="paragraph">숫자 ID는 99입니다.</block>
  <block id="89429eb5e6061e2e0b04707c39588b82" category="paragraph">경우에 따라 파일의 소유자가 올바르지만 '아무도'가 그룹에 표시되지 않을 수 있습니다.</block>
  <block id="8155be8c03c24d2ae2a39ba5b9659708" category="paragraph">아무도 없나요?</block>
  <block id="01e2f333d529d07a7774464ebe7c0d52" category="paragraph">NFSv4.1의 'nobody' 사용자는 nfsnobody 사용자와 다릅니다. "id" 명령을 실행하여 NFS 클라이언트가 각 사용자를 보는 방법을 볼 수 있습니다.</block>
  <block id="bb1a16c53f7bf27e8010e55518128316" category="paragraph">NFSv4.1에서는 'nobody' 사용자가 'idmapd.conf' 파일에 정의된 기본 사용자이며 사용할 모든 사용자로 정의할 수 있습니다.</block>
  <block id="25df38609547f38c12a30d2f7fa376e3" category="paragraph">이 문제가 발생하는 이유는 무엇입니까?</block>
  <block id="0c52fa2fe9ffee5f1757712d7b9151d3" category="paragraph">이름 문자열 매핑을 통한 보안은 NFSv4.1 작업의 핵심 요소이므로 이름 문자열이 제대로 일치하지 않을 때 기본 동작은 일반적으로 사용자와 그룹이 소유한 파일 및 폴더에 액세스할 수 없는 사용자에게 스쿼시를 하는 것입니다.</block>
  <block id="ee345fce71ab8dd58d64ab30df90665d" category="paragraph">파일 목록에서 사용자 및/또는 그룹에 대해 'nobody'가 표시되는 경우 이는 일반적으로 NFSv4.1에서 잘못 구성된 항목이 있음을 의미합니다. 케이스 민감도는 여기에서 확인할 수 있습니다.</block>
  <block id="6f0eaeb67bf8645d4cb5b6d6634d62e9" category="paragraph">예를 들어 user1@CVSDEMO.LOCA L(uid 1234, gid 1234)이 내보내기에 액세스하는 경우 Cloud Volumes Service에서 user1@CVSDEMO.LOCA L(uid 1234, gid 1234)을 찾을 수 있어야 합니다. Cloud Volumes Service의 사용자가 USER1@CVSDEMO.LOCA L인 경우 일치하지 않습니다(대문자 user1과 소문자 user1 비교). 대부분의 경우 클라이언트의 메시지 파일에서 다음을 볼 수 있습니다.</block>
  <block id="501dfba2ca7e696ebe3828fe0a72358d" category="paragraph">클라이언트와 서버는 모두 사용자가 실제로 자신이 주장하는 사람이라는 데 동의해야 합니다. 따라서 클라이언트가 보는 사용자에게 Cloud Volumes Service가 보는 사용자와 동일한 정보가 있는지 확인하려면 다음을 확인해야 합니다.</block>
  <block id="c45f88d46edf246ef524b5ae57bfd939" category="list-text">* NFSv4.x ID domain. * Client:'idmapd.conf' file; Cloud Volumes Service는 defaultv4iddomain.com 파일을 사용하며 수동으로 변경할 수 없습니다. NFSv4.1과 함께 LDAP를 사용하는 경우 Cloud Volumes Service는 ID 도메인을 AD 도메인과 동일한 DNS 검색 도메인이 사용 중인 것으로 변경합니다.</block>
  <block id="4ad682a8c77e394fdf80dd7dc8013933" category="list-text">* 사용자 이름 및 숫자 ID. * 이 옵션은 클라이언트가 사용자 이름을 찾는 위치를 결정하고 이름 서비스 스위치 구성(client: ' nsswitch.conf' 및/또는 로컬 passwd 및 group 파일)을 활용합니다. Cloud Volumes Service는 이를 수정할 수 없지만 활성화된 경우 구성에 LDAP를 자동으로 추가합니다.</block>
  <block id="278ba27763f1a046a43e86bd394f831b" category="list-text">* 그룹 이름 및 숫자 ID. * 이 옵션은 클라이언트가 그룹 이름을 찾는 위치를 결정하고 이름 서비스 스위치 구성(client: ' nsswitch.conf' 및/또는 로컬 passwd 및 group 파일)을 활용합니다. Cloud Volumes Service는 이를 수정할 수 없지만 활성화된 경우 구성에 LDAP를 자동으로 추가합니다.</block>
  <block id="6b9ce9cbf95dd872dc03e91534746dc9" category="paragraph">거의 모든 경우에 클라이언트의 사용자 및 그룹 목록에 'nobody'가 표시되면 Cloud Volumes Service와 NFS 클라이언트 간의 사용자 또는 그룹 이름 도메인 ID 변환입니다. 이 시나리오를 방지하려면 LDAP를 사용하여 클라이언트와 Cloud Volumes Service 간의 사용자 및 그룹 정보를 확인합니다.</block>
  <block id="55c4b4ea1ecc6c7d5d39c90a0b42830f" category="section-title">클라이언트의 NFSv4.1에 대한 이름 ID 문자열을 보는 중입니다</block>
  <block id="c194a1cc7281e9894e494f5ccc1267d9" category="paragraph">NFSv4.1을 사용하는 경우 앞서 설명한 대로 NFS 작업 중에 이름 문자열 매핑이 발생합니다.</block>
  <block id="600a8e1223f644dfc8fc6d9eaf7c6585" category="inline-link">nfsidmap -l</block>
  <block id="315b0c6cb599d172afa3879fb5aff687" category="paragraph">NFSv4 ID에 대한 문제를 찾기 위해 '/var/log/messages'를 사용하는 것 외에도 을 사용할 수 있습니다<block ref="b0f2e0837ffda1ff0550aeef038779e7" category="inline-link-rx"></block> NFSv4 도메인에 올바르게 매핑된 사용자 이름을 보려면 NFS 클라이언트에서 명령을 실행하십시오.</block>
  <block id="c72321f4072e32fa1625318fcee53b38" category="paragraph">예를 들어, 이 명령은 클라이언트에서 찾을 수 있는 사용자 및 Cloud Volumes Service가 NFSv4.x 마운트에 액세스하는 이후의 명령 출력입니다.</block>
  <block id="7fdd86c292924f1df8a7d9127ece25dc" category="paragraph">NFSv4.1 ID 도메인(이 경우, 즉 NetApp-user)에 제대로 매핑되지 않는 사용자가 동일한 마운트에 액세스하여 파일을 만지려고 하면 'nobody:nobody'가 예상한 대로 할당됩니다.</block>
  <block id="bf667093961d1f59e9282ef8a28d89f7" category="paragraph">nfsidmap-l 출력에서는 디스플레이에 사용자 pcuser가 표시되지만 NetApp-user는 표시되지 않습니다. 이는 엑스포트 정책 규칙('65534')의 익명 사용자입니다.</block>
  <block id="5ec4dbbd0b1975ade000088ec562aebe" category="inline-link-macro">다음: SMB.</block>
  <block id="a1989578ae6cff04ad5b049565c028a6" category="paragraph"><block ref="a1989578ae6cff04ad5b049565c028a6" category="inline-link-macro-rx"></block></block>
  <block id="f054dd8cc88786d8030b18d90271f377" category="summary">Cloud Volumes Service는 NFS 및 SMB 공유를 지원하기 위해 여러 TCP 포트를 노출합니다.</block>
  <block id="c5381dc540506dbb210e2d300554e4cd" category="doc">방화벽</block>
  <block id="3081ff6911f8297ddc53dab3c34d0811" category="inline-link-macro">이전: 저장된 데이터 암호화.</block>
  <block id="4591bc0b4ed2ba115e753bad56145791" category="paragraph"><block ref="4591bc0b4ed2ba115e753bad56145791" category="inline-link-macro-rx"></block></block>
  <block id="1e45092c94634e40f68ce647e16109a4" category="paragraph">Cloud Volumes Service는 NFS 및 SMB 공유를 지원하기 위해 여러 TCP 포트를 노출합니다.</block>
  <block id="8ace993e6a8c37342617dbf22185890a" category="inline-link">NFS 액세스에 필요한 포트 수</block>
  <block id="259c7a7ef42d8165caa2c0238cb6f9fe" category="inline-link">SMB 액세스에 필요한 포트</block>
  <block id="48e54afcf03ca45bfe38f6b7ff58764a" category="inline-link">구성됨</block>
  <block id="2957bc03d53f1be7c11d427906ed1479" category="inline-link">DNS 기반 DC 검색</block>
  <block id="02d7b2e18b6bb033bf88be07d39aab4c" category="inline-link">Cloud Volumes Service에 대한 온보딩</block>
  <block id="934adb56d62c2e8a1334785cbb6d4987" category="inline-link">여기에 설명된 대로 Cloud Volumes Service CIDR에 포트를 노출합니다</block>
  <block id="fa995eb117a30c2365b6a07bf00e36e4" category="inline-link-macro">다음: NAS 프로토콜 개요</block>
  <block id="6160acafbed3bd228bd0703f2991a4cb" category="paragraph"><block ref="6160acafbed3bd228bd0703f2991a4cb" category="inline-link-macro-rx"></block></block>
  <block id="4a3327b1b286d1e67b6b26ccadab7e11" category="paragraph">이메일: mailto:doccomments@netapp.com [doccomments@netapp.com^]로 연락해 주십시오. 제목 줄에 기술 보고서 4918 포함.</block>
  <block id="8a7d64073f6ea3e3562e48ad7babe165" category="summary">NAS 프로토콜에는 NFS(v3 및 v4.1) 및 SMB/CIFS(2.x 및 3.x)가 포함됩니다. 이러한 프로토콜은 CVS에서 여러 NAS 클라이언트 간에 데이터에 대한 공유 액세스를 허용하는 방법입니다. 또한 Cloud Volumes Service는 NFS 및 SMB/CIFS 클라이언트(이중 프로토콜)에 대한 액세스를 동시에 제공하는 동시에 NAS 공유의 파일 및 폴더에 대한 모든 ID 및 권한 설정을 존중할 수 있습니다.</block>
  <block id="90654829f21fcf187b576a4c4bad0d65" category="doc">NAS 프로토콜 개요</block>
  <block id="571468eb1eb9e9369a3f638191a66df7" category="inline-link-macro">이전: 방화벽.</block>
  <block id="01d123c65f0dd57ade00e4f9754df7de" category="paragraph"><block ref="01d123c65f0dd57ade00e4f9754df7de" category="inline-link-macro-rx"></block></block>
  <block id="2ea1602d2ad8b38f601e3e9a049c625d" category="paragraph">NAS 프로토콜에는 NFS(v3 및 v4.1) 및 SMB/CIFS(2.x 및 3.x)가 포함됩니다. 이러한 프로토콜은 CVS에서 여러 NAS 클라이언트 간에 데이터에 대한 공유 액세스를 허용하는 방법입니다. 또한 Cloud Volumes Service는 NFS 및 SMB/CIFS 클라이언트(이중 프로토콜)에 대한 액세스를 동시에 제공하는 동시에 NAS 공유의 파일 및 폴더에 대한 모든 ID 및 권한 설정을 존중할 수 있습니다. Cloud Volumes Service는 가장 높은 데이터 전송 보안을 유지하기 위해 SMB 암호화 및 NFS Kerberos 5p를 사용하여 전송 중인 프로토콜 암호화를 지원합니다.</block>
  <block id="4fbbc372dd84225f54ba28f08d3ff4c7" category="admonition">이중 프로토콜은 CVS에서 사용할 수 있습니다. - 성능만 지원됩니다.</block>
  <block id="51f1eaeaea4deb044aabf0797f51c5c0" category="inline-link-macro">다음: NAS 프로토콜의 기본 사항.</block>
  <block id="fcb7e93b14f588cd063c2c111732d865" category="paragraph"><block ref="fcb7e93b14f588cd063c2c111732d865" category="inline-link-macro-rx"></block></block>
  <block id="be0bbf78cc02e3b8c5c134bc7dd71544" category="summary">Cloud Volumes Service에 대한 모든 관리 작업은 API를 통해 수행됩니다. GCP 클라우드 콘솔에 통합된 Cloud Volumes Service 관리도 Cloud Volumes Service API를 사용합니다.</block>
  <block id="dd03419f7f2124dca2e83694ae1b7211" category="doc">컨트롤 플레인 아키텍처</block>
  <block id="1d2a3e9b2f45b43494c66482366a665a" category="inline-link-macro">이전: Cloud Volumes Service 아키텍처.</block>
  <block id="f73a9343c8393a91c87eda2847dfab85" category="paragraph"><block ref="f73a9343c8393a91c87eda2847dfab85" category="inline-link-macro-rx"></block></block>
  <block id="791716f366839a73d41b8ac1ae95bad0" category="section-title">ID 및 액세스 관리</block>
  <block id="41dff7155cc7aeb11c06434f6a450bb3" category="inline-link">IAM</block>
  <block id="d0455114933a93b857dff40ad9829c80" category="paragraph">ID 및 액세스 관리 <block ref="3e7f3b73b3f103986fbe162302b5e57e" category="inline-link-rx"></block>)는 Google Cloud 프로젝트 인스턴스에 대한 인증(로그인) 및 권한 부여(권한)를 제어할 수 있는 표준 서비스입니다. Google IAM은 권한 승인 및 제거에 대한 전체 감사 추적을 제공합니다. 현재 Cloud Volumes Service는 제어 평면 감사를 제공하지 않습니다.</block>
  <block id="697308a09680ed006fe009f5a90fd74c" category="section-title">인증/권한 개요</block>
  <block id="cb5b383a5c27210bdf8f2fd443c68ebb" category="inline-link">여기에서 세분화된 사용 권한의 전체 목록을 확인할 수 있습니다</block>
  <block id="f6c6a3fb346fa0197c1eeba05a4736c6" category="paragraph">IAM은 또한 netapcloudvolumes.admin과 netapcloudvolumes.viewer라는 두 가지 사전 정의된 역할을 제공합니다. 이러한 역할은 특정 사용자 또는 서비스 계정에 할당할 수 있습니다.</block>
  <block id="6d90e176a60105dd03d5580c615cc5fe" category="paragraph">IAM 사용자가 Cloud Volumes Service를 관리할 수 있도록 적절한 역할 및 권한을 할당합니다.</block>
  <block id="010558e705f1d93db66b5a129431b39d" category="paragraph">세분화된 사용 권한을 사용하는 예는 다음과 같습니다.</block>
  <block id="cf95655b33a1e3a77d897074d8353e7e" category="list-text">사용자가 볼륨을 삭제할 수 없도록 get/list/create/update 권한만 가진 사용자 지정 역할을 만듭니다.</block>
  <block id="fdc24340d58c0f0e7d38a4a3f6a7218c" category="list-text">'스냅샷 *' 권한으로만 사용자 지정 역할을 사용하여 애플리케이션 정합성 보장 스냅샷 통합을 구축하는 데 사용되는 서비스 계정을 생성합니다.</block>
  <block id="b1ef9a9445de9905dc5e0ab77e08e183" category="list-text">특정 사용자에게 '볼륨 증가 *'를 위임하는 사용자 지정 역할을 만듭니다.</block>
  <block id="c33f7c2cbeaca5f1462c1b3e1c276145" category="section-title">서비스 계정</block>
  <block id="303e96f80576360d0c7b07ae7528fa4b" category="inline-link">Terraform(Terraform</block>
  <block id="b6d8efd38d2a5551a2c43104314740bd" category="paragraph">또는 스크립트를 통해 Cloud Volumes Service API 호출을 수행하는 방법<block ref="d99d6c9612fe6a2189c372e0abf640d5" category="inline-link-rx"></block>역할/netapcloudvolumes.admin의 역할을 사용하여 서비스 계정을 생성해야 합니다. 이 서비스 계정을 사용하여 Cloud Volumes Service API 요청을 인증하는 데 필요한 JWT 토큰을 다음 두 가지 방법으로 생성할 수 있습니다.</block>
  <block id="87cacfdb2dd389d5d00fef712c2f874b" category="list-text">JSON 키를 생성하고 Google API를 사용하여 JWT 토큰을 파생시킵니다. 이 방법이 가장 간단한 방법이지만 수동 비밀(JSON 키) 관리와 관련이 있습니다.</block>
  <block id="d77fb2baf15918343921ee724cfacb2f" category="inline-link">서비스 계정 가장</block>
  <block id="9d8270b5a4616fc246d5f96cccc9f61e" category="inline-link">애플리케이션 기본 자격 증명</block>
  <block id="c1f48ac217f6b993bda4f82835777177" category="list-text">사용<block ref="09540132e155f93461287a2e21a4e25d" category="inline-link-rx"></block> 역할/iam.serviceAccountTokenCreator` 포함. 이 코드(스크립트, Terraform 등)는 에서 실행됩니다<block ref="ffba44c35d88772fc8c63157b8dc0cf7" category="inline-link-rx"></block> 서비스 계정을 가장하여 권한을 얻습니다. 이 접근 방식은 Google 보안 모범 사례를 반영합니다.</block>
  <block id="01aa2fa55c64df5a4122b637c9ababc7" category="inline-link">서비스 계정 및 개인 키 생성</block>
  <block id="a325b85a1545e8c507701fb5aa32e6b8" category="section-title">Cloud Volumes Service API를 참조하십시오</block>
  <block id="d06e940dcf329e87ca49cb2a665f5fd8" category="inline-link">Google Cloud 설명서에서 Cloud Volumes API를 참조하십시오</block>
  <block id="de13c3e3b25af602f2652dd51a503a8a" category="paragraph">API 엔드포인트는 표준 HTTPS(TLSv1.2) 기능을 사용하여 NetApp에서 작동 및 보안됩니다.</block>
  <block id="8eac7c9151aa7742216ac387e27479a7" category="section-title">JWT 토큰</block>
  <block id="56ebd33e81a27d6c3c78f2f67f2d3c1a" category="inline-link">RFC-7519</block>
  <block id="f2c16a4802323f9b9c1ac55acf92645f" category="paragraph">API에 대한 인증은 JWT 베어러 토큰을 사용하여 수행됩니다 <block ref="89a64c0d993ae56a4af8e7ccde6ee59e" category="inline-link-rx"></block>)를 클릭합니다. Google Cloud IAM 인증을 사용하여 유효한 JWT 토큰을 얻어야 합니다. 서비스 계정 JSON 키를 제공하여 IAM에서 토큰을 가져와 수행해야 합니다.</block>
  <block id="f45362733fe1dd1af3c58ae64471d466" category="section-title">로깅 감사</block>
  <block id="1ccbd48d467dc56358432c49ba82e95a" category="paragraph">현재 사용자가 액세스할 수 있는 컨트롤 플레인 감사 로그를 사용할 수 없습니다.</block>
  <block id="f2787c6d19935adb1d88d6c832b68083" category="inline-link-macro">다음: 데이터 플레인 아키텍처.</block>
  <block id="9025e4ef245b32ed6f318a902095bafc" category="paragraph"><block ref="9025e4ef245b32ed6f318a902095bafc" category="inline-link-macro-rx"></block></block>
  <block id="9dfacef1e7d01943a3363c481a0ab54f" category="summary">Cloud Volumes Service for Google Cloud는 Google Cloud 프라이빗 서비스 액세스 프레임워크를 활용합니다. 이 프레임워크에서는 사용자가 Cloud Volumes Service에 연결할 수 있습니다. 이 프레임워크는 다른 Google Cloud 서비스와 같은 서비스 네트워킹 및 VPC 피어링 구조를 사용하여 테넌트 간의 완전한 격리를 보장합니다.</block>
  <block id="65d49b550fb0a0afd0ad601dc275ea12" category="doc">데이터 플레인 아키텍처</block>
  <block id="bbabe197f6618c2911a8ad624a658a46" category="inline-link-macro">이전: 컨트롤 플레인 아키텍처</block>
  <block id="dfb92e74bf9227851402850c5c488e3c" category="paragraph"><block ref="dfb92e74bf9227851402850c5c488e3c" category="inline-link-macro-rx"></block></block>
  <block id="57e0a1cde7582cc59173756aff450054" category="paragraph">Cloud Volumes Service for Google Cloud는 Google Cloud를 활용합니다<block ref="466f20229cc0e1fa2efa2b4b45528417" category="inline-link-rx"></block> 프레임워크: 이 프레임워크에서는 사용자가 Cloud Volumes Service에 연결할 수 있습니다. 이 프레임워크는 다른 Google Cloud 서비스와 같은 서비스 네트워킹 및 VPC 피어링 구조를 사용하여 테넌트 간의 완전한 격리를 보장합니다.</block>
  <block id="fabc0e878e19ad7e95bb8e906ab9e8a1" category="inline-link">Cloud Volumes Service용 아키텍처</block>
  <block id="81001e33ae42635e6a292ced69cda439" category="paragraph">Google Cloud용 Cloud Volumes Service의 아키텍처 개요는 를 참조하십시오<block ref="7e96ff285aa6f06b814f61dc37a8da61" category="inline-link-rx"></block>.</block>
  <block id="dcfa6d27a1891efb4ad8492d3a127b28" category="paragraph">사용자 VPC(독립 실행형 또는 공유)는 볼륨을 호스팅하는 Cloud Volumes Service 관리 테넌트 프로젝트 내의 VPC에 대해 자세히 살펴봅니다.</block>
  <block id="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="paragraph"><block ref="fcf4e9439b20c7a36f8ee4116fd5bc6d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7e3d4716c5a2ddac5bbd6a03d58d03af" category="paragraph">위 그림에서는 Cloud Volumes Service에 연결된 VPC 네트워크 3개와 볼륨을 공유하는 GCE1-7(다중 컴퓨팅 엔진 VM)이 포함된 프로젝트(중간 CVS 소비자 프로젝트)를 보여 줍니다.</block>
  <block id="fbf1e8aceed7750d8ed8c4e7168cdb02" category="list-text">VPC1을 사용하면 GCE1이 볼륨 A와 B에 액세스할 수 있습니다</block>
  <block id="dc5d4ca9052ec8ea299a69ef985a32b0" category="list-text">VPC2는 GCE2와 GCE4가 볼륨 C에 액세스할 수 있도록 합니다</block>
  <block id="3274f78cc9286288af4912642932b72e" category="list-text">세 번째 VPC 네트워크는 공유 VPC로, 두 개의 서비스 프로젝트와 공유됩니다. GCE3, GCE4, GCE5 및 GCE6에서 D 및 E 볼륨에 액세스할 수 있습니다 공유 VPC 네트워크는 CVS 성능 서비스 유형의 볼륨에만 지원됩니다.</block>
  <block id="be3759e5f4a6574585df9e1159c20c30" category="admonition">GCE7은 어떤 볼륨에도 액세스할 수 없습니다.</block>
  <block id="597134b02aeec788dec5f24fa0adba89" category="paragraph">데이터는 전송 중(Kerberos 및/또는 SMB 암호화 사용) 및 Cloud Volumes Service에 저장된 데이터를 모두 암호화할 수 있습니다.</block>
  <block id="f8426b7150021bc2586e9c150051a408" category="inline-link-macro">다음: 전송 중인 데이터 암호화.</block>
  <block id="39148875a23c5a4ea00752d82ac14b14" category="paragraph"><block ref="39148875a23c5a4ea00752d82ac14b14" category="inline-link-macro-rx"></block></block>
  <block id="3e7c5a939584e1a53201dd8eddfe85d1" category="summary">CloudSQL, GCVE(Google Cloud VMware Engine) 및 파일 저장소와 같은 다른 Google Cloud 네이티브 서비스와 유사한 방식으로 Cloud Volumes Service는 Google PSA를 사용하여 서비스를 제공합니다.</block>
  <block id="16929468b925d0d420441bcbba519e7d" category="doc">Cloud Volumes Service 아키텍처</block>
  <block id="98cdf6a29cf39ecd5239e5071cb0dc88" category="inline-link">Google PSA</block>
  <block id="d4d6aaf620a68430d28b38f847f2a6af" category="inline-link">VPC 네트워크 피어링</block>
  <block id="353164decd5aa0c4f58b4e56559e1b13" category="inline-link">아키텍처 섹션을 참조하십시오</block>
  <block id="8055d5a25a1838f115c8636545abb21a" category="paragraph"><block ref="8055d5a25a1838f115c8636545abb21a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a6f34964d3060f5dd66e2cc7c8711679" category="paragraph">점선 위의 파트는 볼륨 수명 주기를 제어하는 서비스의 컨트롤 평면을 보여줍니다. 점선 아래의 부분은 데이터 평면을 나타냅니다. 왼쪽 파란색 상자는 사용자 VPC(서비스 소비자)를 나타내고 오른쪽 파란색 상자는 NetApp에서 제공하는 서비스 생산업체입니다. 둘 다 VPC 피어링을 통해 연결됩니다.</block>
  <block id="0d127864a05110e3053c2690dea7d914" category="section-title">테넌시 모델</block>
  <block id="dc947df9f7b14883cbc411bc0a7de469" category="paragraph">Cloud Volumes Service에서 개별 프로젝트는 고유한 테넌트로 간주됩니다. 즉, 볼륨, 스냅샷 복사본 등을 프로젝트 단위로 조작할 수 있습니다. 즉, 모든 볼륨은 자신이 만든 프로젝트의 소유이며 해당 프로젝트에서만 기본적으로 해당 볼륨 내의 데이터를 관리하고 액세스할 수 있습니다. 이는 서비스의 컨트롤 플레인 뷰로 간주됩니다.</block>
  <block id="b9ea9f76a11191d80f8fe1abc9437eb6" category="section-title">공유 VPC</block>
  <block id="cc11b3be8b129e07961938139b138eb5" category="paragraph">데이터 평면 보기에서 Cloud Volumes Service는 공유 VPC에 연결할 수 있습니다. 호스팅 프로젝트 또는 공유 VPC에 연결된 서비스 프로젝트 중 하나에서 볼륨을 생성할 수 있습니다. 공유 VPC에 연결된 모든 프로젝트(호스트 또는 서비스)는 네트워크 계층(TCP/IP)에서 볼륨에 연결할 수 있습니다. 공유 VPC에서 네트워크 연결을 사용하는 모든 클라이언트는 NAS 프로토콜을 통해 데이터에 액세스할 수 있으므로 개별 볼륨의 액세스 제어(예: 사용자/그룹 ACL(액세스 제어 목록) 및 NFS 내보내기의 호스트 이름/IP 주소)를 사용하여 데이터에 액세스할 수 있는 사용자를 제어해야 합니다.</block>
  <block id="0b97558649d416ff7a157c6ebb3415d9" category="paragraph">고객 프로젝트당 최대 5대의 VPC에 Cloud Volumes Service를 연결할 수 있습니다. 제어 플레인에서 프로젝트를 사용하면 연결된 VPC에 관계없이 생성된 모든 볼륨을 관리할 수 있습니다. 데이터 플레인에서 VPC는 서로 격리되며 각 볼륨은 하나의 VPC에만 연결할 수 있습니다.</block>
  <block id="be52fe1bd184b72048acd2ba911bb069" category="paragraph">개별 볼륨에 대한 액세스는 프로토콜별(NFS/SMB) 액세스 제어 메커니즘에 의해 제어됩니다.</block>
  <block id="a3328901555fee8fe9134fc5bd6e641b" category="paragraph">즉, 네트워크 계층에서 공유 VPC에 연결된 모든 프로젝트가 볼륨을 볼 수 있는 반면 관리 측면에서는 소유자 프로젝트만 볼륨을 볼 수 있습니다.</block>
  <block id="90f3668b3811dddcb8de24b77c6a6d64" category="section-title">VPC 서비스 제어</block>
  <block id="d5fc4459a5e756d9c4ad2c88c260092b" category="paragraph">VPC 서비스 제어는 인터넷에 연결되어 있고 전 세계적으로 액세스할 수 있는 Google Cloud 서비스에 대한 액세스 제어 경계를 설정합니다. 이러한 서비스는 사용자 ID를 통해 액세스 제어를 제공하지만 어떤 네트워크 위치 요청이 시작되기까지의 지 제한할 수 없습니다. VPC 서비스는 정의된 네트워크에 대한 액세스를 제한하는 기능을 도입하여 이러한 격차를 해소합니다.</block>
  <block id="601553f09795c6051748c4f4f63ce893" category="paragraph">Cloud Volumes Service 데이터 플레인은 외부 인터넷에 연결되지 않고 잘 정의된 네트워크 경계(경계)가 있는 전용 VPC에 연결됩니다. 해당 네트워크 내에서 각 볼륨은 프로토콜별 액세스 제어를 사용합니다. 외부 네트워크 연결은 Google Cloud 프로젝트 관리자가 명시적으로 만듭니다. 그러나 컨트롤 플레인은 데이터 플레인과 동일한 보호 기능을 제공하지 않으며 모든 곳에서 유효한 자격 증명( )을 사용하여 액세스할 수 있습니다<block ref="f0e6a8c8639b1f1713f124143221142a" category="inline-link-rx"></block>)를 클릭합니다.</block>
  <block id="7755a392158406ad802334080cd41f73" category="paragraph">즉, Cloud Volumes Service 데이터 플레인은 VPC 서비스 제어를 지원할 필요 없이 VPC 서비스 제어를 명시적으로 사용하지 않고 네트워크 액세스 제어 기능을 제공합니다.</block>
  <block id="892d60d0a1c71243b5ddff2c66ed584c" category="section-title">패킷 스니핑/추적 고려 사항</block>
  <block id="93b0389d05d1b6926967749b8692f2f6" category="paragraph">패킷 캡처는 네트워크 문제 또는 기타 문제(예: NAS 권한, LDAP 연결 등)를 해결하는 데 유용할 수 있지만 네트워크 IP 주소, MAC 주소, 사용자 및 그룹 이름 및 엔드포인트에서 사용되는 보안 수준에 대한 정보를 얻기 위해 악의적으로 사용할 수도 있습니다. Google Cloud 네트워킹, VPC 및 방화벽 규칙이 구성된 방식 때문에 사용자 로그인 자격 증명 또는 없이 네트워크 패킷에 대한 원치 않는 액세스를 얻기가 어렵습니다 <block ref="2a18c6d0cd80103144f47d02366a785f" category="inline-link-macro-rx"></block> 클라우드로 인스턴스. 공유 VPC 및/또는 외부 네트워크 터널/IP 전달을 사용하여 엔드포인트에 대한 외부 트래픽을 명시적으로 허용하지 않는 한 패킷 캡처는 엔드포인트(예: 가상 머신(VM))에서만 가능하며 VPC 내부 엔드포인트에서만 가능합니다. 클라이언트 외부의 트래픽을 스니핑할 수 있는 방법은 없습니다.</block>
  <block id="ce58b63a24bebe6bac29cfe248428477" category="paragraph"><block ref="ce58b63a24bebe6bac29cfe248428477" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c72e76f5c978aa82e296df17081b6836" category="admonition">unixUserPassword는 LDAP에 의해 쿼리되며 일반 텍스트로 전송되지 않고 소염 해시로 보내집니다. 기본적으로 Windows LDAP는 unixUserPassword 필드를 채우지 않습니다. 이 필드는 LDAP를 통해 클라이언트에 대화형 로그인을 위해 Windows LDAP를 활용해야 하는 경우에만 필요합니다. Cloud Volumes Service는 인스턴스에 대한 대화형 LDAP 로그인을 지원하지 않습니다.</block>
  <block id="01b21a51d124432b5b7fe641eae6a004" category="paragraph">다음 그림에서는 AUTH_SYS를 통한 NFS 캡처 옆에 있는 NFS Kerberos 대화의 패킷 캡처를 보여 줍니다. 추적에서 사용할 수 있는 정보가 두 가지 간에 어떻게 다른지, 그리고 전송 중 암호화를 사용하여 NAS 트래픽에 대한 전반적인 보안을 강화하는 방법을 확인하십시오.</block>
  <block id="0d66010f122b3df766abd8a0cb2ff598" category="paragraph"><block ref="0d66010f122b3df766abd8a0cb2ff598" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ba81028f56cfd4f5e21c7102a8eff68" category="paragraph"><block ref="5ba81028f56cfd4f5e21c7102a8eff68" category="inline-image-macro-rx" type="image"></block></block>
  <block id="04aa3ce627dbf5b220c8aa6d4955fb34" category="section-title">VM 네트워크 인터페이스</block>
  <block id="8ec45d68b7d371d25a3b82a76db3142b" category="inline-link">무차별 모드</block>
  <block id="e59b81e20588b0d3a3c495a545d75322" category="paragraph">공격자는 의 VM에 새 NIC(네트워크 인터페이스 카드)를 추가하려고 시도할 수 있습니다<block ref="39c80826df1f145e2784d4b04af9d477" category="inline-link-rx"></block> 모든 트래픽을 스니핑하기 위해 기존 NIC에서 Promiscuous 모드를 활성화(포트 미러링)하거나 활성화합니다. Google Cloud에서 새 NIC를 추가하려면 VM을 완전히 종료해야 하므로 경고가 생성되므로 공격자가 이를 놓치지 않고 확인할 수 없습니다.</block>
  <block id="b726bce4fa04e9b7a6d788f212f00c17" category="paragraph">또한 NIC를 무차별 모드로 설정할 수 없으며 Google Cloud에서 경고를 트리거합니다.</block>
  <block id="5be5e913f29871f00d216882fc58f26a" category="inline-link-macro">다음: 컨트롤 플레인 아키텍처</block>
  <block id="f9f0b661819d64fded86dba6dee4dd6b" category="paragraph"><block ref="f9f0b661819d64fded86dba6dee4dd6b" category="inline-link-macro-rx"></block></block>
  <block id="599e7197321e9ab772426d7187714f67" category="summary">SMB는 이더넷 네트워크를 통해 여러 SMB 클라이언트에 중앙 집중식 사용자/그룹 인증, 권한, 잠금 및 파일 공유를 제공하는 Microsoft에서 개발한 네트워크 파일 공유 프로토콜입니다.</block>
  <block id="b4fdd997b1f33e0d4c6964444c2bf399" category="doc">중소기업</block>
  <block id="b619a787e67dd6b7b38f5db3e4da5e80" category="inline-link-macro">이전: NFS.</block>
  <block id="d5c73fd283fc4c7fcf6fefda8649450f" category="paragraph"><block ref="d5c73fd283fc4c7fcf6fefda8649450f" category="inline-link-macro-rx"></block></block>
  <block id="e0a515b0910f55d3d1d5adda978e8e4f" category="paragraph"><block ref="395dbbdb78e4ae6be8daf8ab2b7828a7" category="inline-link-rx"></block> 는 이더넷 네트워크를 통해 여러 SMB 클라이언트에 중앙 집중식 사용자/그룹 인증, 권한, 잠금 및 파일 공유를 제공하는 Microsoft에서 개발한 네트워크 파일 공유 프로토콜입니다. 파일 및 폴더는 다양한 공유 속성으로 구성할 수 있고 공유 수준 권한을 통해 액세스 제어를 제공하는 공유를 통해 클라이언트에 제공됩니다. SMB는 Windows, Apple 및 Linux 클라이언트를 비롯하여 프로토콜을 지원하는 모든 클라이언트에 제공될 수 있습니다.</block>
  <block id="63f2e3eee09c9d71b23530e2205eb36a" category="paragraph">Cloud Volumes Service는 SMB 2.1 및 3.x 버전의 프로토콜을 지원합니다.</block>
  <block id="cc4a835dfb2ac9e7ba402c068a4ef9a0" category="section-title">액세스 제어/SMB 공유</block>
  <block id="f122c057113b41c182d10fddf2a82817" category="list-text">Windows 사용자 이름이 Cloud Volumes Service 볼륨에 대한 액세스를 요청하면 Cloud Volumes Service는 Cloud Volumes Service 관리자가 구성한 방법을 사용하여 UNIX 사용자 이름을 찾습니다.</block>
  <block id="ac960a1b86a1625e4ff98dbb3feef120" category="list-text">외부 UNIX ID 공급자(LDAP)가 구성되어 있고 Windows/UNIX 사용자 이름이 동일한 경우 Windows 사용자 이름은 추가 구성 없이 1:1을 UNIX 사용자 이름으로 매핑합니다. LDAP가 설정되면 Active Directory를 사용하여 사용자 및 그룹 객체에 대한 UNIX 속성을 호스팅합니다.</block>
  <block id="3c60aff1fcf4407fc40492eebac8e37b" category="inline-link-macro">"비대칭 이름 매핑에 LDAP 사용"</block>
  <block id="e4adb9d6d8d5650dfb0663dde5495dff" category="list-text">Windows 이름과 UNIX 이름이 동일하게 일치하지 않으면 Cloud Volumes Service에서 LDAP 이름 매핑 구성을 사용할 수 있도록 LDAP를 구성해야 합니다(섹션 참조) <block ref="1cca6755f54a82023ec645e8be5d4c82" category="inline-link-macro-rx"></block>)를 클릭합니다.</block>
  <block id="5205bf34161159f00d7f28cb5e6e2a89" category="list-text">LDAP를 사용하지 않는 경우 Windows SMB 사용자는 Cloud Volumes Service의 기본 로컬 UNIX 사용자 "pcuser"로 매핑됩니다. 즉, 멀티프로토콜 NAS 환경에서 pcuser로 매핑되는 사용자가 Windows에서 작성한 파일이 UNIX 소유권을 pcuser로 표시합니다. 여기에 있는 'pcuser'는 사실상 리눅스 환경(UID 65534)의 'nobody' 사용자입니다.</block>
  <block id="0ff58f508b02c651e0b4ee271b1792d9" category="paragraph">SMB만 사용하는 배포에서는 "pcuser" 매핑이 계속 발생하지만 Windows 사용자 및 그룹 소유권이 올바르게 표시되고 SMB 전용 볼륨에 대한 NFS 액세스가 허용되지 않으므로 문제가 되지 않습니다. 또한 SMB 전용 볼륨은 생성된 후 NFS 또는 이중 프로토콜 볼륨으로의 전환을 지원하지 않습니다.</block>
  <block id="9327392a148953617bfae88e7e46a666" category="paragraph">Windows는 Active Directory 도메인 컨트롤러에서 사용자 이름 인증에 Kerberos를 사용합니다. 이 경우 AD DC와 사용자 이름/암호 교환이 필요하며 이는 Cloud Volumes Service 인스턴스 외부에 있습니다. Kerberos 인증은 SMB 클라이언트가 '\\서버 이름' UNC 경로를 사용하는 경우 사용되며 다음 조건이 적용됩니다.</block>
  <block id="61caea7c1c859702c330a0781763fd23" category="list-text">서버 이름 에 대한 DNS A/AAAA 항목이 있습니다</block>
  <block id="de4327d512f4e62f9b3ae80f8bb719cc" category="list-text">SMB/CIFS 액세스에 유효한 SPN이 SERVERNAME에 존재합니다</block>
  <block id="f5c19a901f7d9431872c0e8893aaa498" category="inline-link-macro">"Cloud Volumes Service가 Active Directory에 표시되는 방식"</block>
  <block id="93c756ce24f344cc333703bcd2e7a06e" category="paragraph">Cloud Volumes Service SMB 볼륨이 생성되면 섹션에 정의된 대로 시스템 계정 이름이 생성됩니다 <block ref="087d516981f271a0b6f0df624ae1e840" category="inline-link-macro-rx"></block> Cloud Volumes Service는 DDNS(동적 DNS)를 활용하여 DNS에 필요한 A/AAAA 및 PTR 항목을 생성하고 시스템 계정 보안 주체에 필요한 SPN 항목을 생성하기 때문에 해당 시스템 계정 이름도 SMB 공유 액세스 경로가 됩니다.</block>
  <block id="aafa8c8c59e359a65d0c657f05772244" category="admonition">PTR 항목을 작성하려면 Cloud Volumes Service 인스턴스 IP 주소에 대한 역방향 조회 영역이 DNS 서버에 있어야 합니다.</block>
  <block id="ecd31d9efcb752f09a0690c2f62bf88f" category="paragraph">예를 들어, 이 Cloud Volumes Service 볼륨은 '\\cvs-east-433d.cvsdemo.local' UNC 공유 경로를 사용합니다.</block>
  <block id="c6ee58936680de9d2229f523a4c54ffb" category="paragraph">Active Directory에서는 Cloud Volumes Service에서 생성한 SPN 항목이 다음과 같습니다.</block>
  <block id="5c3c803198a53be899a500a43fcf1d24" category="paragraph"><block ref="5c3c803198a53be899a500a43fcf1d24" category="inline-image-macro-rx" type="image"></block></block>
  <block id="97422e33b69a5567af9908d5b2d397fc" category="paragraph">DNS 정방향/역방향 조회 결과입니다.</block>
  <block id="1d3d964bf7fdd6249507cb3738908e54" category="paragraph">선택적으로 Cloud Volumes Service에서 SMB 공유에 대한 SMB 암호화를 설정/요구하여 더 많은 액세스 제어를 적용할 수 있습니다. 엔드포인트 중 하나가 SMB 암호화를 지원하지 않는 경우 액세스가 허용되지 않습니다.</block>
  <block id="e5e9be92303e18ef3f22dfa57dcbd0d3" category="section-title">SMB 이름 별칭 사용</block>
  <block id="500c4de8d7a022d507313e514b85d485" category="paragraph">경우에 따라 최종 사용자가 Cloud Volumes Service에 사용 중인 컴퓨터 계정 이름을 알아야 하는 보안 문제가 발생할 수 있습니다. 또는 최종 사용자에게 더 간단한 액세스 경로를 제공하려는 경우도 있습니다. 이 경우 SMB 별칭을 생성할 수 있습니다.</block>
  <block id="6c7c194988807a9112adc7f6bc9b1dd5" category="paragraph">SMB 공유 경로에 대한 별칭을 만들려는 경우 DNS에서 CNAME 레코드로 알려진 별칭을 활용할 수 있습니다. 예를 들어 이름이 \\cvs-east-433d.cvssdemo.local이 아닌 공유에 액세스하기 위해 \\cifs"를 사용하되 Kerberos 인증을 계속 사용하려면 기존 A/AAAA 레코드를 가리키는 DNS의 CNAME과 기존 컴퓨터 계정에 추가된 추가 SPN이 Kerberos 액세스를 제공합니다.</block>
  <block id="620b0e4f14250d32e58b3411c5fd3044" category="paragraph"><block ref="620b0e4f14250d32e58b3411c5fd3044" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a030a66483dc3115cd014273bad041d" category="paragraph">CNAME을 추가한 후 생성되는 DNS 정방향 조회 결과입니다.</block>
  <block id="97ec437207d5ac6fb22613655e7e395e" category="paragraph">새 SPN을 추가한 후 생성되는 SPN 쿼리입니다.</block>
  <block id="5730e2788651b014b918d2ee1bfdfe67" category="paragraph"><block ref="5730e2788651b014b918d2ee1bfdfe67" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df91b2b002b78b2f9f87c79b56293060" category="paragraph">패킷 캡처에서는 CNAME에 연결된 SPN을 사용하여 세션 설정 요청을 볼 수 있습니다.</block>
  <block id="8b36b24049a6cda34019fd47ea0273fc" category="paragraph"><block ref="8b36b24049a6cda34019fd47ea0273fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65cc39e4fb8a95d5fcc2098d620ff3b6" category="section-title">SMB 인증 방언</block>
  <block id="fe9fdc3d8157e10bf5b31e8d28fe7827" category="inline-link">방언</block>
  <block id="c50c24feef6ada40d8e2f7be85359c0f" category="paragraph">Cloud Volumes Service는 다음을 지원합니다<block ref="88f3097f4ad7d144185bbacf0330fbeb" category="inline-link-rx"></block> SMB 인증의 경우:</block>
  <block id="dfd5b430bc4db2c2836d0227ad9ac0c4" category="list-text">LM</block>
  <block id="d11322c1a7a2383491c23f13113c59ea" category="list-text">NTLM</block>
  <block id="d0952ee882764dd5c3105f5b23a3e505" category="list-text">NTLMv2</block>
  <block id="87b3695bfd6f672e2c7c4da7ca2b46a8" category="list-text">Kerberos</block>
  <block id="11012bc0af4eda341c391c39cf6aa27c" category="paragraph">SMB 공유 액세스를 위한 Kerberos 인증은 사용할 수 있는 가장 안전한 인증 수준입니다. AES 및 SMB 암호화를 활성화하면 보안 수준이 더욱 높아집니다.</block>
  <block id="e5c584f1ac6fa07c9594321f8fc845e2" category="paragraph">또한 Cloud Volumes Service는 LM 및 NTLM 인증에 대한 이전 버전과의 호환성을 지원합니다. Kerberos가 잘못 구성된 경우(예: SMB 별칭 생성 시), 공유 액세스는 NTLMv2와 같은 취약한 인증 방법으로 되돌아갑니다. 이러한 메커니즘은 보안성이 떨어지기 때문에 일부 Active Directory 환경에서는 비활성화됩니다. 취약한 인증 방법을 사용하지 않도록 설정하고 Kerberos를 제대로 구성하지 않으면 다시 사용할 유효한 인증 방법이 없기 때문에 공유 액세스가 실패합니다.</block>
  <block id="d87250f3f8075c2dfbcfe941d0c7bde9" category="inline-link">네트워크 보안: LAN Manager 인증 레벨</block>
  <block id="f4457a3dba045094cb39418e2233c8c1" category="paragraph">Active Directory에서 지원되는 인증 수준을 구성/보는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="d671b936eec72b8caa6e3a555955a849" category="inline-link-rx"></block>.</block>
  <block id="6ccfb9a0791b337d38ef8ff2cdf26cf8" category="section-title">권한 모델</block>
  <block id="b1728e361f14c53940f081871f87e6ee" category="section-title">NTFS/파일 권한</block>
  <block id="3e5348fb86c26b3cabf2912e6e597902" category="paragraph">NTFS 권한은 NTFS 로직을 따르는 파일 시스템의 파일 및 폴더에 적용되는 권한입니다. 기본 또는 고급 에서 NTFS 권한을 적용할 수 있으며 액세스 제어를 위해 허용 또는 거부 로 설정할 수 있습니다.</block>
  <block id="80b0c49680a2b15ae6a40273fadefaa8" category="paragraph">기본 사용 권한은 다음과 같습니다.</block>
  <block id="704a2a0ea2e007dae9f25d038a988076" category="list-text">모든 권한</block>
  <block id="7f090bbab1cc7f9c08bf4e54d932d3c0" category="list-text">수정</block>
  <block id="3ed713666b4f5112539dd5ffb9376ff4" category="list-text">읽기 및 실행</block>
  <block id="7a1a5f3e79fdc91edf2f5ead9d66abb4" category="list-text">읽기</block>
  <block id="1129c0e4d43f2d121652a7302712cff6" category="list-text">쓰기</block>
  <block id="75484cb1059b92206b918bde1204007a" category="paragraph">ACE라고 하는 사용자 또는 그룹에 대한 사용 권한을 설정하면 ACL에 상주합니다. NTFS 권한은 UNIX 모드 비트와 동일한 읽기/쓰기/실행 기본 사항을 사용하지만 소유권 가져오기, 폴더 만들기/데이터 추가, 속성 쓰기 등과 같은 보다 세분화된 확장 액세스 제어(특수 권한이라고도 함)로 확장할 수도 있습니다.</block>
  <block id="77636166006179e57dc5edc6df25b80c" category="paragraph">표준 UNIX 모드 비트는 NTFS 권한과 동일한 수준의 세분화 수준을 제공하지 않습니다(예: ACL에서 개별 사용자 및 그룹 개체에 대한 권한을 설정하거나 확장 속성을 설정할 수 있음). 그러나 NFSv4.1 ACL은 NTFS ACL과 동일한 기능을 제공합니다.</block>
  <block id="9434d016806e0f50ac7f14efbfa3a3df" category="paragraph">NTFS 권한은 공유 권한보다 더 구체적이며 공유 권한과 함께 사용할 수 있습니다. NTFS 권한 구조에서는 가장 제한적인 권한이 적용됩니다. 따라서 사용자 또는 그룹에 대한 명시적 변명의 경우 액세스 권한을 정의할 때 전체 제어보다 우선합니다.</block>
  <block id="c0ad12f90a714e04744ab070d26a9c80" category="paragraph">NTFS 권한은 Windows SMB 클라이언트에서 제어됩니다.</block>
  <block id="ef950b5546945ec414f9da7909c4fe8a" category="section-title">공유 권한</block>
  <block id="3df5ef25e4045d2e51c43effb69aa5de" category="paragraph">공유 권한은 NTFS 권한(읽기/변경/모든 제어만 해당)보다 더 일반적이며, SMB 공유의 초기 항목을 제어합니다. 이는 NFS 내보내기 정책 규칙의 작동 방식과 유사합니다.</block>
  <block id="41123e00ec2463c8d7c60a10f3d3ede4" category="paragraph">NFS 내보내기 정책 규칙은 IP 주소 또는 호스트 이름과 같은 호스트 기반 정보를 통해 액세스를 제어하지만 SMB 공유 권한은 공유 ACL에서 사용자 및 그룹 ACE를 사용하여 액세스를 제어할 수 있습니다. Windows 클라이언트 또는 Cloud Volumes Service 관리 UI에서 공유 ACL을 설정할 수 있습니다.</block>
  <block id="7f455f054b3ad11fb335d2f9ec69e3ff" category="paragraph">기본적으로 공유 ACL 및 초기 볼륨 ACL에는 모든 권한이 있는 모든 사용자가 포함됩니다. 파일 ACL은 변경되어야 하지만 공유 권한은 공유의 객체에 대한 파일 권한에 의해 무시됩니다.</block>
  <block id="8d37bee954f03966b12b65871768a438" category="paragraph">예를 들어, 사용자가 Cloud Volumes Service 볼륨 파일 ACL에 대한 읽기 액세스만 허용되는 경우 다음 그림과 같이 공유 ACL이 모든 권한이 있는 사용자로 설정되어 있어도 파일 및 폴더 생성에 대한 액세스가 거부됩니다.</block>
  <block id="47ff9e7720c14a2a27bfa4ce12bbd268" category="paragraph"><block ref="47ff9e7720c14a2a27bfa4ce12bbd268" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef46360b81c847c0d6f5015920fd5f3e" category="paragraph"><block ref="ef46360b81c847c0d6f5015920fd5f3e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="316a22056a64a8465269d31ac436fc22" category="paragraph">최상의 보안 결과를 얻으려면 다음을 수행하십시오.</block>
  <block id="09fced4bea14e9b030bd1179b95f3b89" category="list-text">공유 및 파일 ACL에서 모든 사용자를 제거하고 대신 사용자 또는 그룹에 대한 공유 액세스를 설정합니다.</block>
  <block id="8941d253e49282460162b7dac68ad2ba" category="list-text">개별 사용자 대신 그룹을 사용하여 액세스 제어를 수행할 수 있어 관리가 용이하고 그룹 관리를 통해 ACL을 공유할 사용자를 더 빠르게 제거/추가할 수 있습니다.</block>
  <block id="f63df4fd4f9e10c567332b34b05d35ae" category="list-text">공유 권한에 있는 ACE에 대한 덜 제한적이고 보다 일반적인 공유 액세스를 허용하고 보다 세분화된 액세스 제어를 위한 파일 권한을 가진 사용자 및 그룹에 대한 액세스를 잠급니다.</block>
  <block id="afe52910905ef63730591f8a01bcb75e" category="list-text">명시적 거부 ACL은 ACL 허용 을 재정의하므로 일반적인 사용을 피합니다. 파일 시스템에 대한 액세스를 신속하게 제한해야 하는 사용자 또는 그룹의 명시적 거부 ACL 사용을 제한합니다.</block>
  <block id="9a2191ac8d9f65679cdf29455149f6cb" category="inline-link">ACL 상속</block>
  <block id="780d68252d03e9f7617f6bf5fe95c1ce" category="list-text">에 주의를 기울이십시오<block ref="19af65d9616f33b3ccaee367e8d4dc82" category="inline-link-rx"></block> 사용 권한을 수정할 때 설정; 파일 수가 많은 디렉토리 또는 볼륨의 최상위 레벨에서 상속 플래그를 설정하면 해당 디렉토리 또는 볼륨 아래의 각 파일에 상속된 사용 권한이 추가되었음을 의미합니다. 의도하지 않은 액세스/거부 및 각 파일이 조정될 때 권한 수정 장기 이탈과 같은 원치 않는 동작이 발생할 수 있습니다.</block>
  <block id="0c2104afa1bd6c96b5ccc9c7a7ee8a6a" category="section-title">SMB는 보안 기능을 공유합니다</block>
  <block id="05ec24f8004d55ad7596b79266cd4691" category="paragraph">Cloud Volumes Service에서 SMB 액세스가 가능한 볼륨을 처음 생성하면 해당 볼륨을 보호하기 위한 일련의 선택 사항이 표시됩니다.</block>
  <block id="53eaeead30ddbd2dcb1526241312aedf" category="paragraph">이러한 선택 사항 중 일부는 Cloud Volumes Service 레벨(성능 또는 소프트웨어)에 따라 달라지며 다음과 같은 옵션이 있습니다.</block>
  <block id="d65a6ba5ce40987a368f3f757b5721ae" category="list-text">* 스냅샷 디렉토리를 표시합니다(CVS - 성능 및 CVS - SW 모두에서 사용 가능). * 이 옵션은 SMB 클라이언트가 SMB 공유의 스냅샷 디렉토리에 액세스할 수 있는지 여부를 제어합니다('\\server\share\~snapshot' 및/또는 Previous Versions 탭). 기본 설정은 선택되지 않습니다. 즉, 볼륨이 기본적으로 `~snapshot' 디렉토리에 대한 액세스를 숨기거나 허용하지 않으며 볼륨의 이전 버전 탭에 스냅샷 복사본이 나타나지 않습니다.</block>
  <block id="9ebf5e1b6bf20c2942f0add8e979dd7a" category="paragraph"><block ref="9ebf5e1b6bf20c2942f0add8e979dd7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="baf0124343f1806f3ff44f011e92c73f" category="paragraph">보안 상의 이유, 성능상의 이유(AV 스캔에서 이러한 폴더 숨기기) 또는 기본 설정을 위해 최종 사용자로부터 스냅샷 복사본을 숨기는 것이 좋습니다. Cloud Volumes Service 스냅샷은 읽기 전용이므로 이러한 스냅샷이 표시되는 경우에도 최종 사용자는 스냅샷 디렉토리의 파일을 삭제하거나 수정할 수 없습니다. 스냅샷 복사본이 생성된 시점의 파일 또는 폴더에 대한 파일 권한이 적용됩니다. 파일 또는 폴더의 사용 권한이 Snapshot 복사본 간에 변경되면 변경 내용이 Snapshot 디렉토리의 파일 또는 폴더에도 적용됩니다. 사용자 및 그룹은 권한에 따라 이러한 파일 또는 폴더에 액세스할 수 있습니다. 스냅샷 디렉토리에서 파일을 삭제하거나 수정할 수는 없지만 스냅샷 디렉토리에서 파일 또는 폴더를 복사할 수는 있습니다.</block>
  <block id="2716bd858fb85bb9b111c5d51138cb40" category="list-text">* SMB 암호화 활성화(CVS - 성능 및 CVS - SW 모두에 사용 가능). * SMB 공유에서 SMB 암호화는 기본적으로 비활성화되어 있습니다(선택 취소됨). 이 확인란을 선택하면 SMB 암호화가 활성화됩니다. 즉, SMB 클라이언트와 서버 간의 트래픽은 협상된 가장 높은 암호화 수준으로 전송 중에 암호화됩니다. Cloud Volumes Service는 SMB에 대해 최대 AES-256 암호화를 지원합니다. SMB 암호화를 활성화하면 SMB 클라이언트에서 성능 저하가 발생할 수 있으며, 이는 대략 10~20% 범위에서 나타날 수도 있고 그렇지 않을 수도 있습니다. 테스트 결과, 성능 저하가 허용 가능한지 여부를 확인하는 것이 좋습니다.</block>
  <block id="ab7715a00a3e7691d84318bb2f1a3bc1" category="list-text">* SMB 공유 숨기기(CVS - 성능 및 CVS - SW 모두에 사용 가능) * 이 옵션을 설정하면 SMB 공유 경로가 일반 탐색에서 숨겨집니다. 즉, 공유 경로를 모르는 클라이언트는 기본 UNC 경로("\\CVS-SMB" 등)에 액세스할 때 공유를 볼 수 없습니다. 이 확인란을 선택하면 SMB 공유 경로를 명시적으로 알고 있거나 그룹 정책 개체에서 정의한 공유 경로를 가진 클라이언트만 액세스할 수 있습니다(난독 처리를 통한 보안).</block>
  <block id="67699a5a5f5ec8d69977d9f44b521201" category="inline-link">ABE(Access Based Enumeration)는 어떻게 작동합니까?</block>
  <block id="eb36f3383eadcd01f954bc9848b7de21" category="list-text">* ABE(액세스 기반 열거) 사용(CVS-SW만 해당). * SMB 공유를 숨기는 것과 비슷하지만, 공유 또는 파일이 개체에 액세스할 권한이 없는 사용자 또는 그룹에서만 숨겨지는 것을 제외하고는 차이가 있습니다. 예를 들어, Windows 사용자 'Joe'가 권한을 통한 읽기 액세스를 최소한 허용하지 않으면 Windows 사용자 'Joe'는 SMB 공유나 파일을 전혀 볼 수 없습니다. 이 기능은 기본적으로 비활성화되어 있으며 확인란을 선택하여 활성화할 수 있습니다. ABE에 대한 자세한 내용은 NetApp 기술 자료 문서를 참조하십시오<block ref="6d2d0139fec74415d85dc1015aa48640" category="inline-link-rx"></block></block>
  <block id="5ff6480cf15803c821d9cc9bb3dcbe5c" category="inline-link">지속적으로 사용 가능한 SMB 공유</block>
  <block id="17faa8cfb0bc70572c6d4f120cb6de10" category="list-text">* 지속적으로 사용 가능한(CA) 공유 지원 활성화(CVS - 성능만 해당) *<block ref="97476034cc2961d2c1c061d5bdcc519a" category="inline-link-rx"></block> Cloud Volumes Service 백엔드 시스템의 노드 간에 잠금 상태를 복제하여 페일오버 이벤트 중에 애플리케이션 중단을 최소화할 수 있는 방법을 제공합니다. 이 기능은 보안 기능이 아니지만 전반적으로 더 뛰어난 복원력을 제공합니다. 현재 이 기능에는 SQL Server 및 FSLogix 애플리케이션만 지원됩니다.</block>
  <block id="f816f594817af59eac10c8385f34d319" category="section-title">숨겨진 기본 공유</block>
  <block id="7ce84bf53b21b783ae6c62b61f60f9e3" category="inline-link">숨겨진 관리 공유</block>
  <block id="31a7b0c828b1a1039c3fe9e855430acd" category="paragraph">SMB 서버가 Cloud Volumes Service에서 생성되면 서버가 생성됩니다<block ref="e698db250309574e2563e69229bd950f" category="inline-link-rx"></block> ($ 명명 규칙 사용) - 데이터 볼륨 SMB 공유 이외에 생성됩니다. 여기에는 C$(네임스페이스 액세스) 및 IPC$(Microsoft Management Console(MMC) 액세스에 사용되는 RPC(원격 프로시저 호출)와 같은 프로그램 간 통신을 위한 명명된 파이프 공유)가 포함됩니다.</block>
  <block id="64667cec654fa57a129c5c1fe752d7ae" category="inline-link">Windows에서는 기본적으로 이러한 공유에 대한 익명 액세스를 허용하지 않습니다</block>
  <block id="7962a42fa319b5ea9ccf0429193d4f3c" category="paragraph">IPC$ 공유는 공유 ACL을 포함하지 않으며 수정할 수 없습니다. RPC 호출 및 에 엄격하게 사용됩니다<block ref="582b1e06ccfbbf9885ff446ec79f8b0f" category="inline-link-rx"></block>.</block>
  <block id="c2c8a4f76f99f203d14ee3c1adae3c40" category="paragraph">C$ 공유는 기본적으로 BUILTIN/Administrators 액세스를 허용하지만, Cloud Volumes Service 자동화는 공유 ACL을 제거하고, C$ 공유에 대한 액세스를 통해 Cloud Volumes Service 파일 시스템에 마운트된 모든 볼륨을 볼 수 있으므로 다른 사람에게 액세스를 허용하지 않습니다. 따라서 '\\server\C$'로 이동하려고 하면 실패합니다.</block>
  <block id="444613ce56f4180cf88b531783a9e3bc" category="section-title">로컬/BUILTIN 관리자/백업 권한이 있는 계정</block>
  <block id="5659f387517ed75a127b9a6bda6f1329" category="paragraph">Cloud Volumes Service SMB 서버는 일부 도메인 사용자 및 그룹에 액세스 권한을 적용하는 로컬 그룹(예: BUILTIN\Administrators)이 있다는 점에서 일반 Windows SMB 서버와 유사한 기능을 유지합니다.</block>
  <block id="709eb202e09b717ba82624b788948428" category="inline-link">SeBackupPrivilege 및 SeRestorePrivilege를 참조하십시오</block>
  <block id="03455d8db7797aab1e6e9efe9bf4d2a5" category="paragraph">백업 사용자에 추가할 사용자를 지정하면 해당 Active Directory 연결을 사용하는 Cloud Volumes Service 인스턴스의 BUILTIN\Backup Operators 그룹에 사용자가 추가되고 이 그룹에 이 사용자가 추가됩니다<block ref="3d66e5b4422b04db3b01ddbcafb3649a" category="inline-link-rx"></block>.</block>
  <block id="b5b39a908a856900d75e0b129fb9e349" category="inline-link">SMB 공유의 SQL Server</block>
  <block id="52f5e8856edf4d634cf608cb64bec885" category="paragraph">사용자를 보안 권한 사용자 에 추가하면 사용자에게 SeSecurityPrivilege 가 부여되며, 이 권한은 와 같은 일부 응용 프로그램 사용 사례에 유용합니다<block ref="b685ff2242ac25f5022af8207109cc39" category="inline-link-rx"></block>.</block>
  <block id="99c9211b9f5166d96d9e6613c4be9f77" category="paragraph"><block ref="99c9211b9f5166d96d9e6613c4be9f77" category="inline-image-macro-rx" type="image"></block></block>
  <block id="59976878f4cfcf8cd4a9bccf37270fec" category="paragraph">적절한 권한이 있는 MMC를 통해 Cloud Volumes Service 로컬 그룹 구성원 자격을 볼 수 있습니다. 다음 그림에서는 Cloud Volumes Service 콘솔을 사용하여 추가된 사용자를 보여 줍니다.</block>
  <block id="9b02abec53251430b553f5124b676b1f" category="paragraph"><block ref="9b02abec53251430b553f5124b676b1f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09e7cb53843328fd35bff1d1075e8e04" category="paragraph">다음 표에서는 기본 BUILTIN 그룹 목록과 기본적으로 추가되는 사용자/그룹을 보여 줍니다.</block>
  <block id="52087222d7968b7bd85e5698912f6cee" category="cell">로컬/BUILTIN 그룹</block>
  <block id="c899fa178e9ccd9c46154a79773b9e8e" category="cell">기본 멤버</block>
  <block id="f6c0ddae69a704e001f6cba9fba3f951" category="cell">BUILTIN\Administrators *</block>
  <block id="6930162f33d7d3cc792907afc2d709d6" category="cell">Domain\Domain Admins입니다</block>
  <block id="291b9d53abc37bd4eeab64a68607df4f" category="cell">BUILTIN\Backup Operators *</block>
  <block id="f87e4b3cc74234e59b0d07ad558b2c05" category="cell">BUILTIN\Guest입니다</block>
  <block id="bea5dc29e529ecf572942e7f6cbbf19b" category="cell">도메인\도메인 게스트입니다</block>
  <block id="bafee069f6320499a0f630485028a961" category="cell">BUILTIN\고급 사용자</block>
  <block id="d3ffae89384cc2219d9dc26887d6422c" category="cell">BUILTIN\도메인 사용자</block>
  <block id="a26444fe66f07a77f6e392ad714158ff" category="cell">도메인\도메인 사용자</block>
  <block id="ee6df957412594fad1ce714d75089e5f" category="paragraph">* Cloud Volumes Service Active Directory 연결 구성에서 그룹 멤버십이 제어됩니다.</block>
  <block id="c648fec724703de3d038fda21e884ef7" category="paragraph">MMC 창에서 로컬 사용자 및 그룹(및 그룹 구성원)을 볼 수 있지만 개체를 추가 또는 삭제하거나 이 콘솔에서 그룹 구성원을 변경할 수는 없습니다. 기본적으로 도메인 관리자 그룹 및 관리자만 Cloud Volumes Service의 BUILTIN\Administrators 그룹에 추가됩니다. 현재 수정할 수 없습니다.</block>
  <block id="39aedbfda9a943aea0e4c841bc68dc0a" category="paragraph"><block ref="39aedbfda9a943aea0e4c841bc68dc0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ae7d2b2ec0c231b6934886bf6690c9e" category="paragraph"><block ref="0ae7d2b2ec0c231b6934886bf6690c9e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="255c5bd3cdece4dd4a7891941d9c964e" category="section-title">MMC/컴퓨터 관리 액세스</block>
  <block id="7f956759e187dbb2b65022241e8053cd" category="paragraph">Cloud Volumes Service의 SMB 액세스는 공유를 보고, 공유 ACL을 관리하고, SMB 세션 및 열린 파일을 확인/관리할 수 있는 컴퓨터 관리 MMC에 대한 연결을 제공합니다.</block>
  <block id="e3d561744b3b4f6ab5953c2f96daaad7" category="paragraph">MMC를 사용하여 Cloud Volumes Service에서 SMB 공유 및 세션을 보려면 현재 로그인한 사용자가 도메인 관리자여야 합니다. 다른 사용자는 MMC에서 SMB 서버를 보거나 관리할 수 있으며 Cloud Volumes Service SMB 인스턴스에서 공유 또는 세션을 보려고 할 때 사용 권한 없음 대화 상자를 받을 수 있습니다.</block>
  <block id="aaf8b324d80834b9d235cb6b6d84be89" category="paragraph">SMB 서버에 연결하려면 컴퓨터 관리를 열고 컴퓨터 관리를 마우스 오른쪽 단추로 클릭한 다음 다른 컴퓨터에 연결을 선택합니다. 그러면 Cloud Volumes Service 볼륨 정보에 있는 SMB 서버 이름을 입력할 수 있는 컴퓨터 선택 대화 상자가 열립니다.</block>
  <block id="c34ce8bbe19f26cf58867de938f87920" category="paragraph">적절한 권한이 있는 SMB 공유를 보면 Active Directory 연결을 공유하는 Cloud Volumes Service 인스턴스에서 사용 가능한 모든 공유가 표시됩니다. 이 동작을 제어하려면 Cloud Volumes Service 볼륨 인스턴스에서 SMB 공유 숨기기 옵션을 설정합니다.</block>
  <block id="b939aeb87de29dc576ad4adc5fa19bce" category="paragraph"><block ref="b939aeb87de29dc576ad4adc5fa19bce" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c57a1134332b8bafcaa5f411a65b4a49" category="paragraph"><block ref="c57a1134332b8bafcaa5f411a65b4a49" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1325fb66f29e707e7e3402f0d45d59dc" category="paragraph">다음 표에는 MMC에서 지원/지원되지 않는 기능 목록이 나와 있습니다.</block>
  <block id="241bac47978fca670a6b9c52e3432067" category="cell">지원되는 함수</block>
  <block id="fe2de21fdfcaf4ed19a251aab83bf0ff" category="cell">지원되지 않는 함수</block>
  <block id="ad338fe21209358afd2f29eee14817c6" category="list-text">공유 보기</block>
  <block id="a5dc19ca94f052a57587a2f4f1433678" category="list-text">활성 SMB 세션을 봅니다</block>
  <block id="ff50826288707e494282b4cf6bec983b" category="list-text">열린 파일을 봅니다</block>
  <block id="8c006cf58f2706f56d65e1431b1e128e" category="list-text">로컬 사용자 및 그룹을 봅니다</block>
  <block id="bad02cc8e307a9ac8bf6899188811a54" category="list-text">로컬 그룹 구성원 자격을 봅니다</block>
  <block id="5ab1c0d0251d23bc086198a8fc219a69" category="list-text">시스템의 세션, 파일 및 트리 연결 목록을 열거합니다</block>
  <block id="bd7ff4b31e7eade785d74789a052242c" category="list-text">시스템에서 열려 있는 파일을 닫습니다</block>
  <block id="3a6cd2ea18cf077c57b65c28c40f9851" category="list-text">열려 있는 세션을 닫습니다</block>
  <block id="e5ded1413b3fd0a1690184029acf1845" category="list-text">공유 생성/관리</block>
  <block id="b4d1348a7ae3aa39ac1fbd299a07ebb9" category="list-text">새 로컬 사용자/그룹을 생성합니다</block>
  <block id="5c3d34e6fdaee1edee0722fcef147f8a" category="list-text">기존 로컬 사용자/그룹 관리/보기</block>
  <block id="1c79052ffd16d848acb6278dd54f0d33" category="list-text">이벤트 또는 성능 로그를 봅니다</block>
  <block id="eedf037c0977372c4f0adaa359d5f6e0" category="list-text">스토리지 관리</block>
  <block id="d5d1ca904ae55c0d5399eb923b8d6d21" category="list-text">서비스 및 애플리케이션 관리</block>
  <block id="dddaf61539328810b230a60430960038" category="section-title">SMB 서버 보안 정보</block>
  <block id="7c7ff5a0c882bba2c6d86dc13caa6e49" category="paragraph">Cloud Volumes Service의 SMB 서버는 Kerberos 클록 편중, 티켓 사용 기간, 암호화 등 SMB 연결에 대한 보안 정책을 정의하는 일련의 옵션을 사용합니다.</block>
  <block id="bdf80cb84c583e3d6af81c4778921102" category="paragraph">다음 표에는 이러한 옵션, 기능, 기본 설정 및 Cloud Volumes Service를 사용하여 수정할 수 있는 경우 등이 나와 있습니다. 일부 옵션은 Cloud Volumes Service에는 적용되지 않습니다.</block>
  <block id="708cc30ece03d9ba30511bea4ea09792" category="cell">보안 옵션</block>
  <block id="ad67361f283520dada90173b5fbfaad7" category="cell">최대 Kerberos 클럭 비뚤어짐(분)</block>
  <block id="ebd83f9f3f1a10793a7aaf199f57a32b" category="cell">Cloud Volumes Service와 도메인 컨트롤러 간의 최대 시간 편중 시간 차이가 5분을 초과하면 Kerberos 인증이 실패합니다. 이 값은 Active Directory 기본값으로 설정됩니다.</block>
  <block id="e4da3b7fbbce2345d7772b0674a318d5" category="cell">5</block>
  <block id="ccf9068a42f159a1b1cd3e07b84c5ecd" category="cell">Kerberos 티켓 수명(시간)</block>
  <block id="34c1c29ec6cffe3b75b5f4db3cd4e12f" category="cell">갱신이 요구되기 전에 Kerberos 티켓이 유효한 상태로 유지되는 최대 시간입니다. 10시간 전에 갱신이 발생하지 않으면 새 티켓을 받아야 합니다. Cloud Volumes Service는 이러한 갱신을 자동으로 수행합니다. Active Directory 기본값은 10시간입니다.</block>
  <block id="b63288488b52af4af602d79dce8aa252" category="cell">최대 Kerberos 티켓 갱신(일)</block>
  <block id="082ea39c709884c3439c0b1e937ee15a" category="cell">새 승인 요청이 필요해지기 전에 Kerberos 티켓을 갱신할 수 있는 최대 일 수입니다. Cloud Volumes Service는 SMB 연결에 대한 티켓을 자동으로 갱신합니다. 7일은 Active Directory 기본값입니다.</block>
  <block id="8f14e45fceea167a5a36dedd4bea2543" category="cell">7</block>
  <block id="2127af947646b417ab67c66e82922af5" category="cell">Kerberos KDC 연결 시간 초과(초)</block>
  <block id="4a4dfa50ac48d9523d22b929a8df2e01" category="cell">KDC 연결이 시간 초과되기 전의 시간(초)입니다.</block>
  <block id="09b779421f875a0831c9165f7730b710" category="cell">수신 SMB 트래픽에 서명 필요</block>
  <block id="8f4c5ae7b0c978c58bbe10790f9eb578" category="cell">SMB 트래픽에 서명 필요 로 설정합니다. true로 설정하면 서명을 지원하지 않는 클라이언트가 연결되지 않습니다.</block>
  <block id="c77326ff7e3ae38e2b7ed07e3bff97e8" category="cell">로컬 사용자 계정에 암호 복잡성 필요</block>
  <block id="fab3a355aeb5f939ba8dcdc4ae0ea4b8" category="cell">로컬 SMB 사용자의 암호에 사용됩니다. Cloud Volumes Service는 로컬 사용자 생성을 지원하지 않으므로 이 옵션은 Cloud Volumes Service에는 적용되지 않습니다.</block>
  <block id="a3ab2beb782b5f0d7b6d1eb3cacdff1f" category="cell">Active Directory LDAP 연결에 start_TLS를 사용합니다</block>
  <block id="0e46800ed1870ec055aaa1a1193ff94e" category="cell">Active Directory LDAP에 대한 TLS 연결 시작을 활성화하는 데 사용됩니다. Cloud Volumes Service에서는 현재 이 설정을 지원하지 않습니다.</block>
  <block id="b3734582301f762d04b757dd4bc38917" category="cell">Kerberos를 사용하도록 AES-128 및 AES-256 암호화를 사용합니다</block>
  <block id="4f36af6c9bdde3ebcee7b34176ffe895" category="cell">Active Directory 연결에 AES 암호화를 사용할지 여부를 제어하고 Active Directory 연결을 생성/수정할 때 Active Directory 인증에 AES 암호화 사용 옵션을 사용하여 제어합니다.</block>
  <block id="60a39bccb81f56ddfcbb75f0ffcd1fb6" category="cell">LM 호환성 수준</block>
  <block id="a4ada97522d5a887e144bf5d59b41a79" category="cell">Active Directory 연결에 대해 지원되는 인증 방언의 수준입니다. 자세한 내용은 " 단원을 참조하십시오<block ref="17dc1460fa48a825f7967ddb6804d663" category="inline-xref-macro-rx"></block>"를 참조하십시오.</block>
  <block id="cba8970659f15f342022079c22a97ee9" category="cell">NTLMv2 - KRB</block>
  <block id="5e22abe32604d6b7925fa4768934bb5d" category="cell">수신 CIFS 트래픽에 SMB 암호화 필요</block>
  <block id="ae7c4fcb353d520e8996acadf9c9c42f" category="cell">모든 공유에 SMB 암호화가 필요합니다. 이 기능은 Cloud Volumes Service에서 사용되지 않으며 대신 볼륨별로 암호화를 설정합니다(“ 절 참조)<block ref="6931acdfb95dc44f28af40d26d20d65c" category="inline-xref-macro-rx"></block>").</block>
  <block id="e00514b301b6206c1024de564d0d71fe" category="cell">클라이언트 세션 보안</block>
  <block id="b9e69cb6a219e02ada3e29b808558c45" category="inline-link-macro">“LDAP 채널 바인딩.”</block>
  <block id="d16466e25f07f41d5c768e32becc9751" category="cell">LDAP 통신에 대한 서명 및/또는 봉인을 설정합니다. 이 설정은 현재 Cloud Volumes Service에 설정되어 있지 않지만 향후 릴리즈에서 필요할 수 있습니다. Windows 패치로 인한 LDAP 인증 문제에 대한 해결 방법은 섹션에서 설명합니다 <block ref="4bb24ef2f48443c7e6d43902d0f8498e" category="inline-link-macro-rx"></block>.</block>
  <block id="b4c17f5cf25d927d8fb7dbab5e1d84c5" category="cell">SMB2가 DC 연결에 대해 설정됩니다</block>
  <block id="31a7643648d0d4454c1fd8a860f1a12d" category="cell">DC 연결에 SMB2를 사용합니다. 기본적으로 사용됩니다.</block>
  <block id="2cd88a3568a04efbfd46abb6cce9a411" category="cell">System - 기본값입니다</block>
  <block id="6158881a00903bd45b66955e6487a27c" category="cell">LDAP 조회</block>
  <block id="4ddc9ad0bd193ba15a48f662666ccd96" category="cell">보안 Active Directory 연결에 LDAPS를 사용합니다</block>
  <block id="4182d7f699521f08b56835082e7caf27" category="cell">SSL을 통한 LDAP 사용을 활성화합니다. 현재 Cloud Volumes Service에서 지원되지 않습니다.</block>
  <block id="b31e0a21b1fa97ab2faf1479ea00c9db" category="cell">DC 연결에 암호화가 필요합니다</block>
  <block id="23cc5b51f575d3c458ac112689f7a2f1" category="cell">성공적인 DC 연결을 위해 암호화가 필요합니다. Cloud Volumes Service에서 기본적으로 비활성화되어 있습니다.</block>
  <block id="595451bb2138edcd7bd73c4e11f8890d" category="inline-link-macro">다음: 이중 프로토콜/멀티프로토콜</block>
  <block id="47b43136bb3740d6abdf3823c798bd7e" category="paragraph"><block ref="47b43136bb3740d6abdf3823c798bd7e" category="inline-link-macro-rx"></block></block>
  <block id="ebd8431a0b14e9588377860f5d21d80b" category="sidebar">아키텍처 개요</block>
  <block id="a20fe2a1eb3b2546487a96f1e639d4f3" category="sidebar">기타 NAS 인프라스트럭처 서비스 종속성(KDC, LDAP, DNS)</block>
  <block id="92e704fe041898cac086cd4a192a1815" category="cell">2022년 5월 20일</block>
  <block id="efae07e57b0f279c460d1361b379cf52" category="cell">SuperPOD를 위한 새로운 BeeGFS 설계 및 구축 가이드</block>
  <block id="197d6fccbd337f46908b50e1ac3ece5d" category="sidebar">SuperPOD: NetApp 및 NVIDIA 솔루션</block>
  <block id="ed05ff1aa7ef3023c5dc2359de4e2d15" category="sidebar">NetApp 기반 BeeGFS(설계 가이드)</block>
  <block id="b877ddfe299c52df6f7a340fdcaa52eb" category="sidebar">NetApp 기반 BeeGFS(구축 가이드)</block>
  <block id="e6bec38fe69985a0817e3c0b2b3a0c20" category="cell">* 콘텐츠 랜딩 페이지 *</block>
  <block id="b1dc18184f115680e9fe3b64295c4678" category="cell">AI 기반 솔루션의 컬렉션 AI 랜딩 페이지는 콘텐츠 관련 "타일"으로 제공되는 인기 콘텐츠를 제공합니다.</block>
  <block id="e68818392f0eda6e918ccb9e7537e282" category="inline-link-macro">AI 콘텐츠</block>
  <block id="748eaad82fcc3f281aebd8c5467a4d91" category="cell"><block ref="748eaad82fcc3f281aebd8c5467a4d91" category="inline-link-macro-rx"></block></block>
  <block id="53840db4921094507c6397fb6ee31d58" category="cell">최신 데이터 분석 솔루션의 컬렉션(예 Splunk SmartStore, Apache Spark 등)를 사용할 수 있습니다. 최신 데이터 분석 랜딩 페이지는 콘텐츠별 "타일"으로 제공되는 인기 있는 콘텐츠를 제공합니다.</block>
  <block id="1b1956b226e3085af9e004e60ce183b4" category="inline-link-macro">최신 데이터 분석 콘텐츠</block>
  <block id="16321f09e6ea361ef5515d5939fa73f1" category="cell"><block ref="16321f09e6ea361ef5515d5939fa73f1" category="inline-link-macro-rx"></block></block>
  <block id="87867e178542e6ed3cf6ea885807d4f1" category="cell">데스크톱 가상화를 포함한 가상화 핵심 솔루션의 모음입니다. 가상화 소개 페이지는 컨텐츠 관련 "타일"으로 제공되는 인기 컨텐츠를 제공합니다.</block>
  <block id="5654a75155b39867a9f4372fcc292bab" category="inline-link-macro">가상화 콘텐츠</block>
  <block id="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="cell"><block ref="82e9b7248dcd1a1ae85e7fa485bf1f4b" category="inline-link-macro-rx"></block></block>
  <block id="24a8e607718680e8d1dd293b9d736add" category="cell">컨테이너 기반 솔루션의 모음입니다. 가상화 소개 페이지는 컨텐츠 관련 "타일"으로 제공되는 인기 컨텐츠를 제공합니다.</block>
  <block id="afb6dbef1b44c7f79b8883cae5cc3b30" category="inline-link-macro">컨테이너 콘텐츠</block>
  <block id="d76e9a2c09fc047c91b6cb4c2f340644" category="cell"><block ref="d76e9a2c09fc047c91b6cb4c2f340644" category="inline-link-macro-rx"></block></block>
  <block id="0cf49f958731e4b4c23d4b04f0802ba0" category="cell">비즈니스 애플리케이션 및 데이터베이스</block>
  <block id="73c685140b2461529432f6e9628ef281" category="cell">비즈니스 애플리케이션 및 데이터베이스 솔루션의 모음입니다. SAP 및 SAP HANA 랜딩 페이지 o는 콘텐츠별 "타일"에 나와 있는 인기 있는 콘텐츠를 제공합니다. 이 섹션에서는 Oracle 및 SQL Server 데이터베이스 솔루션에 대해 설명합니다.</block>
  <block id="ef0bea1a6ce6e68dd3ebae18ea2de71f" category="inline-link-macro">SAP 및 SAP HANA 콘텐츠</block>
  <block id="589c17157183d6295af608cccff7c8da" category="cell"><block ref="589c17157183d6295af608cccff7c8da" category="inline-link-macro-rx"></block></block>
  <block id="d7339a230985e723af5d49a6470f4fc8" category="cell">데이터 마이그레이션, 데이터 보호 및 데이터 보안 솔루션의 모음입니다.</block>
  <block id="d3d4dd76fc599d6c513fa0434537bc08" category="summary">모든 NetApp 솔루션 콘텐츠에 대한 솔루션 기능을 설명하는 블로그 시리즈</block>
  <block id="4d46b81ad5db47d845e86c95088ff47a" category="doc">NetApp 솔루션: 블로그</block>
  <block id="a93daa19938c1852de52ce10350307a4" category="paragraph">많은 NetApp 솔루션의 특정 기능을 소개하는 블로그를 소개합니다.</block>
  <block id="bf20a476dd72893f0f21a3d56a601784" category="open-title">인공 지능</block>
  <block id="e6c9e9316fee7048645938d93d674056" category="list-text"><block ref="e6c9e9316fee7048645938d93d674056" category="inline-link-macro-rx"></block></block>
  <block id="3e78754f8bb90f06073e18a2399d0b7f" category="list-text"><block ref="3e78754f8bb90f06073e18a2399d0b7f" category="inline-link-macro-rx"></block></block>
  <block id="821c35321bcc709868cdd0b7f31165ee" category="cell">2022-04-01/05</block>
  <block id="b4ea7c36c784b6da08e2b44d82018c65" category="open-title">AWS/VMC</block>
  <block id="b9b37266c1f6c6a5244f3fef48f644e1" category="list-text">VMware Cloud for AWS 구축 및 구성</block>
  <block id="57669ed11798d25a8216675c3f0f6ecf" category="inline-link-macro">VMC에 대한 구성 단계</block>
  <block id="fc835ae678d144f168b78fafb98286b2" category="paragraph">자세한 내용을 확인하십시오 <block ref="0bca421d9cd22e10e81bd0c987fad54b" category="inline-link-macro-rx"></block>.</block>
  <block id="9e88bf7f3ee359d8f536975aa39ab6a5" category="open-title">Azure/AVS</block>
  <block id="293193a848a4345d095f41ff490fd1a4" category="inline-link-macro">AVS의 구성 단계</block>
  <block id="e2501a40b45cdc3295c28e82fc2ffa18" category="paragraph">자세한 내용을 확인하십시오 <block ref="29745c898e96ab7473e2b2c19fa34fbf" category="inline-link-macro-rx"></block>.</block>
  <block id="7e7790ea083a371632d0764a881695f6" category="open-title">GCP/GCVE</block>
  <block id="e44b11e9adb07a14c72f48599f700cd4" category="inline-link-macro">GCVE에 대한 구성 단계</block>
  <block id="0969e77be69a346b123e1b2c625e25b0" category="paragraph">자세한 내용을 확인하십시오 <block ref="7ffa56a4f5c5cf9fb86200a4dd2e1a5d" category="inline-link-macro-rx"></block>.</block>
  <block id="52be4c6acc8cca3a598e3a651421de3d" category="inline-link-macro">VMC에 대한 게스트 연결 스토리지 옵션</block>
  <block id="a8e9a5787febc7740af29cd0bebf2e95" category="inline-link-macro">AVS용 게스트 연결 스토리지 옵션</block>
  <block id="2da991b20a7647acbdd67154515723cf" category="inline-link-macro">GCVE에 대한 게스트 연결 저장소 옵션</block>
  <block id="5d49b0ee57ad4b529c897b49789aa965" category="paragraph">자세한 내용을 확인하십시오 <block ref="39710aaf95ad3f60e444c45fa2d1a561" category="inline-link-macro-rx"></block>.</block>
  <block id="685435b4b2388bd8f370b8fbb6ef6cc7" category="cell">* 게스트 연결됨 *</block>
  <block id="8299249ba5f910704b6288ee7e271747" category="cell">* AWS *</block>
  <block id="eb35b03ceb49f5f06a4570454e08c34c" category="cell">CVO FSx ONTAP<block ref="999b20d9470091fda2e66b2dde5b0af7" category="inline-link-macro-rx"></block></block>
  <block id="1bdeba09294eb5abc383607bb93ff443" category="cell">* Azure *</block>
  <block id="06a1c60be3b7274c063385eaa240863f" category="cell">CVO ANF<block ref="f44f46a20eba78aa72ad4f68a0486a31" category="inline-link-macro-rx"></block></block>
  <block id="25bdffbd4ab087e994a0e54fe22ff6bd" category="cell">* GCP *</block>
  <block id="96e48152153beabed038aa4e41f2abf8" category="cell">CVO CVS<block ref="a54d2eac225d57696bf863778373ea0b" category="inline-link-macro-rx"></block></block>
  <block id="a46eb72d67c0cbcbbdfcde010fbc0b03" category="paragraph">NetApp이 Azure에 제공하는 솔루션에 대해 자세히 알아보십시오.</block>
  <block id="d8732ebfbd98db5a8cd9db59aa5b0637" category="paragraph">VMware는 클라우드 워크로드를 다음 세 가지 범주 중 하나로 정의합니다.</block>
  <block id="2cb256015e8585083bd2350f010676fb" category="list-text">보호(재해 복구 및 백업/복원 모두 포함)</block>
  <block id="3bc026b815790a05493fa56fc4b8d8bd" category="list-text">확장</block>
  <block id="2c0a3f21d3cbc96381e4c2fe29329ec1" category="paragraph">다음 섹션에서 사용 가능한 솔루션을 찾아봅니다.</block>
  <block id="97740c0c87b83b324e18993ba93f0617" category="open-title">보호</block>
  <block id="e74fe990166c1a4bb77dde7f12823b5d" category="paragraph">곧 출시 예정!!</block>
  <block id="3d98cfc43616995ea335b20aa9b10ef2" category="paragraph">Azure는 기본 Azure NetApp Files(ANF) 서비스 또는 CVO(Cloud Volumes ONTAP)를 통해 게스트 연결 NetApp 스토리지를 지원합니다.</block>
  <block id="8f53b5241aa3284f9058318dcbc2504d" category="section-title">Azure NetApp Files(ANF)</block>
  <block id="2295dc11d84df2756a1eaac36330b417" category="paragraph">Azure NetApp Files는 Azure에 엔터프라이즈급 데이터 관리 및 스토리지를 제공하므로 워크로드와 애플리케이션을 쉽게 관리할 수 있습니다. 워크로드를 클라우드로 마이그레이션하여 성능 저하 없이 실행할 수 있습니다.</block>
  <block id="806f1ffa4d2e1d7ee40a30337658a5ef" category="paragraph">Azure NetApp Files가 장애를 제거하므로 모든 파일 기반 애플리케이션을 클라우드로 이동할 수 있습니다. 따라서 애플리케이션을 재설계할 필요가 없으며 애플리케이션용 영구 스토리지를 간편하게 확보할 수 있습니다.</block>
  <block id="12eb3a27c6c1134f55e12f1349b87a91" category="paragraph">이 서비스는 Microsoft Azure Portal을 통해 제공되므로 사용자는 Microsoft 기업 계약의 일부로 완벽하게 관리되는 서비스를 이용할 수 있습니다. Microsoft에서 관리하는 세계 최고 수준의 지원을 통해 안심하고 사용할 수 있습니다. 단일 솔루션으로 멀티프로토콜 워크로드를 빠르고 쉽게 추가할 수 있습니다. 레거시 환경에서도 Windows 및 Linux 파일 기반 애플리케이션을 모두 구축하여 배포할 수 있습니다.</block>
  <block id="7afda8c8e445dfa1015ae8245fa8026e" category="section-title">CVO(Cloud Volumes ONTAP)</block>
  <block id="8560d03d6d9a5398acd72a06a8fddd12" category="paragraph">Cloud Volumes ONTAP, 즉 CVO는 NetApp의 ONTAP 스토리지 소프트웨어를 기반으로 하는 업계 최고의 클라우드 데이터 관리 솔루션으로, AWS(Amazon Web Services), Microsoft Azure 및 GCP(Google Cloud Platform)에서 기본적으로 제공됩니다.</block>
  <block id="12f2a9cf238d1339eddfc43be9f107e1" category="paragraph">ONTAP의 소프트웨어 정의 버전이며 클라우드 네이티브 스토리지를 사용합니다. 따라서 클라우드와 사내에서 동일한 스토리지 소프트웨어를 사용할 수 있으므로 데이터를 관리하는 새로운 방법을 통해 IT 직원을 재교육할 필요가 없습니다.</block>
  <block id="62c9becbf4c5643c0df4cbe868b09f0c" category="paragraph">CVO를 사용하면 데이터를 에지에서 데이터 센터, 클라우드로 원활하게 이동하고 다시 가져올 수 있습니다. 또한 단일 창 관리 콘솔인 NetApp Cloud Manager를 사용하여 하이브리드 클라우드를 통합할 수 있습니다.</block>
  <block id="aafae379e910c7a153b831ce5122f5e8" category="paragraph">설계상 CVO는 최고 성능과 고급 데이터 관리 기능을 제공하여 클라우드에서 가장 까다로운 애플리케이션도 충족합니다</block>
  <block id="6db49f93b02d752e6b80616d15759056" category="inline-link-macro">NetApp/VMware 클라우드 솔루션</block>
  <block id="a088d0b353502e225826d0feb3041d57" category="list-text"><block ref="a088d0b353502e225826d0feb3041d57" category="inline-link-macro-rx"></block></block>
  <block id="9e348c60eb79913385ed14a65efffff6" category="paragraph">자세한 내용을 확인하십시오 <block ref="be78464beb9b2a2b1696a7fe38c0e484" category="inline-link-macro-rx"></block>.</block>
  <block id="cb9ab2dcef988aa0eaa2da1d789cfdb4" category="section-title">솔루션 사용 사례</block>
  <block id="c9c270552e6f44a0219e4d2459cb4b90" category="paragraph">NetApp 및 VMware 클라우드 솔루션을 사용하면 많은 사용 사례를 Azure AVS에서 간단하게 구축할 수 있습니다. SE 사례는 VMware에서 정의한 각 클라우드 영역에 대해 정의됩니다.</block>
  <block id="3fac70d2bc4023bd8c5bb8f7c93b16e8" category="list-text">보호(재해 복구 및 백업/복원 모두 포함)</block>
  <block id="79e4e4c7346c156a268641272a85c01e" category="inline-link-macro">Azure AVS용 NetApp 솔루션을 찾아보십시오</block>
  <block id="6626f21cba60531fb6ab33c5b686fd03" category="paragraph"><block ref="6626f21cba60531fb6ab33c5b686fd03" category="inline-link-macro-rx"></block></block>
  <block id="ef3abc0e33a9bba2f6844fc8bc6416c6" category="section-title">VMware 환경을 위한 NetApp 솔루션</block>
  <block id="7c56979dc4b16fa4dd69a289608a432d" category="paragraph">NetApp은 하이브리드 클라우드 모델이든 "클라우드 우선" 모델이든 클라우드에서 워크로드를 관리하는 가장 일반적인 사용 사례를 지원하는 다양한 솔루션을 제공합니다.</block>
  <block id="14b428df74ec47d859b4b41c2a528f79" category="paragraph">각 하이퍼스케일러에서 사용할 수 있는 솔루션에 대한 자세한 내용은 다음을 참조하십시오.</block>
  <block id="d7d90ddf3d849c680942374007293390" category="inline-link-macro">AWS/VMC용 솔루션</block>
  <block id="3efe4c396a8490c63650f3271e66c5ab" category="list-text"><block ref="3efe4c396a8490c63650f3271e66c5ab" category="inline-link-macro-rx"></block></block>
  <block id="902d95c8e7b033260ed791d46b121684" category="inline-link-macro">Azure/AVS용 솔루션</block>
  <block id="a22d65ac7c37a480dfd6ea3cc467903d" category="list-text"><block ref="a22d65ac7c37a480dfd6ea3cc467903d" category="inline-link-macro-rx"></block></block>
  <block id="739e02805dc104b2c68811e1ea86f2e5" category="inline-link-macro">GCP/GCVE용 솔루션</block>
  <block id="72792598cb09eae6cc992790a3677b2d" category="list-text"><block ref="72792598cb09eae6cc992790a3677b2d" category="inline-link-macro-rx"></block></block>
  <block id="4c27cd4763075e77fef142db7e967384" category="paragraph">NetApp이 AWS에 제공하는 솔루션에 대해 자세히 알아보십시오.</block>
  <block id="6619dc0097706121ef2efa1294da110b" category="example-title">AWS 계정을 등록하십시오</block>
  <block id="3f01bd52a695afbced7f2a43525ec966" category="example-title">내 VMware 계정을 등록합니다</block>
  <block id="f52c436d16c8976963f940ce7dfbd3b0" category="paragraph">AWS는 네이티브 FSx 서비스(FSx ONTAP) 또는 Cloud Volumes ONTAP(CVO)를 사용하여 게스트로 연결된 NetApp 스토리지를 지원합니다.</block>
  <block id="480bc55cb0b0c11472f598d17424afa2" category="section-title">FSX ONTAP</block>
  <block id="6df37dbe4c736ce113cfd677b79431d8" category="paragraph">NetApp ONTAP용 Amazon FSx는 NetApp의 인기 있는 ONTAP 파일 시스템을 기반으로 구축된 매우 안정적이고 확장 가능하며 고성능 및 다양한 기능을 갖춘 파일 스토리지를 제공하는 완전 관리형 서비스입니다. ONTAP용 FSX는 NetApp 파일 시스템의 친숙한 기능, 성능, 기능 및 API 작업을 완벽하게 관리되는 AWS 서비스의 민첩성, 확장성 및 간편성과 결합합니다.</block>
  <block id="f1afd8f76dc3ed417abd5daffa1d5a5f" category="paragraph">ONTAP용 FSX는 AWS 또는 사내에서 실행되는 Linux, Windows 및 macOS 컴퓨팅 인스턴스에서 광범위하게 액세스할 수 있는 다양한 기능을 갖춘 빠르고 유연한 공유 파일 스토리지를 제공합니다. ONTAP용 FSX는 밀리초 미만의 지연 시간으로 고성능 SSD(Solid State Drive) 스토리지를 제공합니다. ONTAP용 FSx를 사용하면 SSD 스토리지 비용을 절감하면서 작업 부하에 대한 SSD 수준의 성능을 달성할 수 있습니다. 단, 데이터의 일부만이 가능합니다.</block>
  <block id="dd29cd696f931f8230a783a5d65ab8c4" category="paragraph">ONTAP용 FSx를 사용하면 버튼 클릭 한 번으로 파일을 스냅샷, 클론 생성 및 복제할 수 있으므로 데이터 관리가 더욱 쉬워집니다. 또한, ONTAP용 FSx는 데이터를 비용이 저렴하고 탄력적인 스토리지에 자동으로 계층화하므로 용량을 할당하거나 관리할 필요가 없습니다.</block>
  <block id="697c147172074c2927997e2d7c472fc0" category="paragraph">또한 ONTAP용 FSX는 완벽하게 관리되는 백업과 지역 간 재해 복구를 지원하는 고가용성의 내구성 스토리지를 제공합니다. 데이터를 보다 쉽게 보호하고 보안을 유지할 수 있도록 ONTAP용 FSx는 널리 사용되는 데이터 보안 및 바이러스 백신 응용 프로그램을 지원합니다.</block>
  <block id="461ab3a83d6c51e1cc25f42118f407bd" category="paragraph">자세한 내용을 확인하십시오 <block ref="f56028ac73883785be6a54941a0e4e64" category="inline-link-macro-rx"></block>.</block>
  <block id="3721bfebe60fa9888e0ea17bd294772d" category="paragraph">NetApp 및 VMware 클라우드 솔루션을 사용하면 많은 사용 사례를 AWS VMC에 쉽게 구축할 수 있습니다. 활용 사례는 VMware에서 정의한 각 클라우드 영역에 대해 정의됩니다.</block>
  <block id="7c9a6204c3d04cd593127efe773bc82e" category="inline-link-macro">AWS VMC용 NetApp 솔루션을 찾아보십시오</block>
  <block id="e9923439d335946afaff146da3d107ff" category="paragraph"><block ref="e9923439d335946afaff146da3d107ff" category="inline-link-macro-rx"></block></block>
  <block id="7c0dae765c7854235808e7e373346d06" category="paragraph">NetApp이 GCP에 제공하는 솔루션에 대해 자세히 알아보십시오.</block>
  <block id="370e7d693bc429e40244684cac20b0cf" category="list-text"><block ref="370e7d693bc429e40244684cac20b0cf" category="inline-link-macro-rx"></block></block>
  <block id="80d79003a84a32474624e54935709e67" category="paragraph">자세한 내용을 확인하십시오 <block ref="996ade122099ed78c4d5fea15d95f62c" category="inline-link-macro-rx"></block>.</block>
  <block id="80b43a415019d937ea5c38446043549a" category="paragraph">자세한 내용을 확인하십시오 <block ref="8e20eef09273fc2519292ca4ed666573" category="inline-link-macro-rx"></block>.</block>
  <block id="e67def868f3133574b28ffe738ad44c1" category="inline-link-macro">Google Cloud GCVE용 NetApp 솔루션을 찾아보십시오</block>
  <block id="5e7670e99ae7db80618f16965d677af6" category="paragraph"><block ref="5e7670e99ae7db80618f16965d677af6" category="inline-link-macro-rx"></block></block>
  <block id="f0f52a47448cc3bc6237a09f83ad3e74" category="example-title">GCVE 배포 및 구성</block>
  <block id="7973cdedf3e9a37ff146bc9fd29ff017" category="paragraph">GCP는 CVO(Cloud Volumes ONTAP) 또는 CVS(Cloud Volumes Service)를 통해 게스트 연결 NetApp 스토리지를 지원합니다.</block>
  <block id="622f93ad4ff43627a425523c5e2538ad" category="section-title">CVS(Cloud Volumes Service)</block>
  <block id="b5a9beef520c0dd1f8e978800f35268e" category="paragraph">CVS(Cloud Volumes Services)는 고급 클라우드 솔루션을 제공하는 완벽한 데이터 서비스 포트폴리오입니다. Cloud Volumes Services는 주요 클라우드 공급자를 위한 여러 파일 액세스 프로토콜(NFS 및 SMB 지원)을 지원합니다.</block>
  <block id="82c8cb0896f20daa9ddbb9d49332f9b6" category="paragraph">그 밖의 이점 및 기능: Snapshot을 통한 데이터 보호 및 복원, 온프레미스 또는 클라우드의 데이터 대상을 복제, 동기화, 마이그레이션할 수 있는 특별한 기능, 전용 플래시 스토리지 시스템 레벨에서 일관된 고성능 제공</block>
  <block id="443f43c84a8efb54c46feb5a61b1a9cc" category="paragraph">이 설명서 전체에서 VMware 활용 사례를 사용하여 클라우드 워크로드 참조를 자세히 설명합니다. 이러한 사용 사례는 다음과 같습니다.</block>
  <block id="0198315ccfb9d5c56e9c865f01bee365" category="paragraph">NetApp 및 VMware 클라우드 솔루션을 사용하면 대부분의 사용 사례를 하이퍼스케일러에서 간편하게 구축할 수 있습니다. VMware는 운영 클라우드 워크로드 사용 사례를 다음과 같이 정의합니다.</block>
  <block id="e0525641cbca59e199eed50739c0c3b8" category="inline-link-macro">AWS/VMC용 NetApp 솔루션을 찾아보십시오</block>
  <block id="3a602723648efc3d9a864906b6ec2d9c" category="paragraph"><block ref="3a602723648efc3d9a864906b6ec2d9c" category="inline-link-macro-rx"></block></block>
  <block id="d18a9fea9b4ca38bf7f042e32420e14e" category="inline-link-macro">Azure/AVS용 NetApp 솔루션을 찾아보십시오</block>
  <block id="bd6708bcf0c060976324512475c1a212" category="paragraph"><block ref="bd6708bcf0c060976324512475c1a212" category="inline-link-macro-rx"></block></block>
  <block id="cac969404c87e9e141b320e34ee1ba4b" category="inline-link-macro">Google Cloud Platform (GCP)/GCVE용 NetApp 솔루션을 찾아보십시오</block>
  <block id="7f86100566a3de37a45dc2bd4ea422a0" category="paragraph"><block ref="7f86100566a3de37a45dc2bd4ea422a0" category="inline-link-macro-rx"></block></block>
  <block id="95adefbc130d345041c4487820a9ab16" category="summary">NetApp 엔터프라이즈 데이터베이스 솔루션은 주요 엔터프라이즈 데이터베이스에서 NetApp 스토리지의 기능을 시연하는 전략적 및 기술 기능 집합입니다.</block>
  <block id="e890f04973d00c3664a44f4cc586bb5d" category="doc">NetApp 엔터프라이즈 데이터베이스 솔루션</block>
  <block id="809247403bb2b3e7178b69b038356678" category="inline-link-macro">vSphere 데이터 저장소 및 프로토콜 기능: NFS</block>
  <block id="ff7854cc2ae62511b4a52320f31aa005" category="paragraph"><block ref="ff7854cc2ae62511b4a52320f31aa005" category="inline-link-macro-rx"></block></block>
  <block id="6309162dffb4a082a2a106613c448e9f" category="doc">하이브리드 클라우드, 가상화 및 컨테이너 비디오 및 데모</block>
  <block id="ccf0b7773e492df3e851d36b689b69b1" category="paragraph">하이브리드 클라우드, 가상화 및 컨테이너 솔루션의 특정 기능을 소개하는 다음 비디오 및 데모를 참조하십시오.</block>
  <block id="ab5efb952cd51767fdde3f548f7d3f18" category="paragraph">NetApp SnapCenter Plug-in for VMware vSphere에 대한 자세한 내용은 를 참조하십시오 <block ref="39b49e6fd504a137658d6db31d129abd" category="inline-link-macro-rx"></block>.</block>
  <block id="0b59976821e81163a037c4ed7f21b209" category="paragraph"><block ref="0b59976821e81163a037c4ed7f21b209" category="inline-link-macro-rx"></block></block>
  <block id="4bff68299377013f00a500a01c7a2f19" category="list-text"><block ref="4bff68299377013f00a500a01c7a2f19" category="inline-link-macro-rx"></block></block>
  <block id="e5f4fe92e1832b16532011df56ee39a5" category="list-text"><block ref="c30f78a476776106411b5cd1ee097f4f" category="inline-link-macro-rx"></block></block>
  <block id="380fbb2dc2a4b42876553664c398fb3f" category="paragraph">NetApp은 오늘날의 비즈니스 과제를 해결할 수 있는 솔루션을 제공할 때 다음과 같은 목표를 가진 솔루션을 제공합니다.</block>
  <block id="008347e050bccf7e2812ae39dd816f41" category="list-text">검증된 구축 및 구성 단계 제공</block>
  <block id="4ef594072d2fdf53ad9ca6af7fe16569" category="list-text">쉽게 사용할 수 있는 솔루션 제공</block>
  <block id="3f68e576fe6e3e328b5feeea03707572" category="list-text">예측 가능한 결과를 제공하는 솔루션 구축은 고객 기업 전체에서 쉽게 반복되고 확장 가능합니다.</block>
  <block id="928a4532882b0eb0208abcae9b7fd6f0" category="paragraph">이러한 목표를 달성하기 위해서는 우리의 솔루션을 통해 제공되는 인프라 및/또는 애플리케이션의 구축과 구성이 자동화를 통해 간소화되는 것이 무엇보다 중요합니다. NetApp은 자동화를 통해 솔루션 소비를 단순화하기 위해 노력하고 있습니다.</block>
  <block id="d6d7e89b087a9e69ae7622847dc932e5" category="paragraph">NetApp 솔루션은 Red Hat Ansible, HashCorp Terraform 또는 Microsoft Powershell과 같은 오픈 소스 자동화 툴을 활용하여 애플리케이션 구축, 클라우드 프로비저닝, 구성 관리 및 기타 일반적인 IT 작업을 자동화할 수 있습니다. NetApp의 솔루션은 공개적으로 제공되는 자동화 아티팩트를 활용하는 동시에 NetApp에서 작성한 자동화를 제공하여 솔루션의 전체 구축을 단순화합니다.</block>
  <block id="e532e5979d2ecc30b8177530683810e2" category="paragraph">자동화 기능을 사용할 수 있는 경우 솔루션 자료는 특정 자동화 툴을 통해 솔루션 또는 솔루션 단계를 자동화하는 프로세스를 사용자에게 안내합니다.</block>
  <block id="aaac1ea7463ef799eaafc693b16b1f81" category="doc">NetApp 솔루션 자동화 시작하기</block>
  <block id="66bd3dbe1f46a5715420e201e457ff65" category="paragraph">NetApp 솔루션 자동화는 NetApp 솔루션에서 활용하는 많은 공통 작업에 대한 단순성과 반복성을 제공합니다.</block>
  <block id="bf7d92f5ef43a7e0ab10c8d11d28ef6e" category="paragraph">솔루션 자동화를 실행하기 전에 자동화를 실행하는 방법에 맞게 환경을 구성해야 합니다. 명령줄이나 AWX 또는 타워와 같은 도구를 통해 자동화를 실행할 수 있는 옵션이 있습니다.</block>
  <block id="dcdcb9b7436ca5ceca042e84e9c3ccf5" category="paragraph">다음 섹션에서는 지정된 각 환경에 맞게 환경을 구성하는 데 필요한 단계를 설명합니다.</block>
  <block id="60e34857d044a02ae86f645c2e97e40f" category="paragraph">stdin&gt;의 미해결 지시문 - 포함::containers/rh-os-n_overview_astra_cc_install_manual.adoc []</block>
  <block id="2b0a99e34b337bd6d8ed27dd9482c9e6" category="paragraph">stdin&gt;에서 해결되지 않은 지침 - 포함:: containers/rh-os-n_overview_astra_cc_install_Ansible.adoc []</block>
  <block id="245ab73d4b9beb43ff76c082e9bc77db" category="open-title">AI/데이터 분석</block>
  <block id="901b32f6abd15fbb3d43fbd044218a64" category="open-title">엔터프라이즈 애플리케이션 및 DB</block>
  <block id="71fbb346a6b64c94052f0e171d5d3eed" category="open-title">데이터 보호 및 데이터 마이그레이션</block>
  <block id="10b2aec15aae4d935355e27497e66c5f" category="summary">NetApp 솔루션의 다양한 기능을 소개하는 비디오 및 데모 시리즈</block>
  <block id="6354d74cd74c1d9f49224ac4e6209bab" category="doc">NetApp 솔루션: 비디오 및 데모</block>
  <block id="60b5065968cf0f66d862a344124f6415" category="paragraph">NetApp 솔루션의 다양한 기능을 소개하는 비디오 및 데모를 소개합니다.</block>
  <block id="ab440644113265a70e7e0bb7c44b2f63" category="paragraph">* 사례 연구 *</block>
  <block id="25aa061b5bc79f1f85182fd8ca1f3165" category="inline-link-macro">VMware 비디오 컬렉션</block>
  <block id="847fff0b97afdc8ceabb5c717634d413" category="list-text"><block ref="847fff0b97afdc8ceabb5c717634d413" category="inline-link-macro-rx"></block></block>
  <block id="55418abe87135e6107123ca2c087964c" category="sidebar">하이퍼스케일러 클라우드의 VMware용 NetApp 솔루션</block>
  <block id="195b49c0610d30d327f5440759b7b642" category="sidebar">지원되는 솔루션</block>
  <block id="3ffbc70cc0bdd47bd7c4ed3cfa35be8a" category="sidebar">FSX ONTAP를 게스트 연결 스토리지로 사용합니다</block>
  <block id="06e1970c26d133efed67d51224ceff1c" category="sidebar">보안 개요 - Google Cloud의 NetApp CVS(Cloud Volumes Service</block>
  <block id="c252fd6dfe5fa6dc4ba36515512a8070" category="sidebar">워크로드 보호 솔루션</block>
  <block id="2579e0b6258e495e90e159e678bd55a8" category="sidebar">AWS 기반 VMware 클라우드: 새로운 지역, 외부 스토리지 및 구매 옵션</block>
  <block id="f74a2791289e2f0411e5ffbd3e5a1d68" category="sidebar">NetApp Cloud Volumes Service를 사용하는 Google Cloud VMware Engine</block>
  <block id="30162ed78b6c10f731411f2fc440c24f" category="sidebar">오라클</block>
  <block id="51b19c4a2c13c8f8a69b0608959bdfca" category="sidebar">FlexPod 데이터 센터의 Oracle 19c RAC 데이터베이스</block>
  <block id="a71f76c3256e4c206a4841d8eb0fed35" category="sidebar">SQL 서버</block>
  <block id="81d59bad51a910734812cab3d20641b0" category="sidebar">하이브리드 클라우드 데이터베이스 솔루션</block>
  <block id="934553b3e6b7dd417ef37d2b3213dd00" category="sidebar">SAP SAP HANA를 참조하십시오</block>
  <block id="1f036821b23def9a55e4116bdbd60c1b" category="sidebar">변경 기록</block>
  <block id="bb5dc731b06d417365e41cb2d0230213" category="sidebar">비디오 데모</block>
  <block id="f9cffb4fda587c713c06e50699299f0f" category="sidebar">솔루션 랜딩 페이지</block>
  <block id="bf8e2974cd692b57a29e42874b662b52" category="sidebar">엔터프라이즈 데이터베이스</block>
  <block id="84145683557fc8692113a2a97c3ec239" category="sidebar">NetApp 하이브리드 멀티 클라우드 및 VMware</block>
  <block id="d4a3e435684aa9918c9dd0bada78d4fb" category="sidebar">AWS용 VMC를 구성합니다</block>
  <block id="883512106f2cef4187ee5f6b5a94c6f8" category="sidebar">Azure용 AVS를 구성합니다</block>
  <block id="a271625e92b27bca4202ba79dab27301" category="sidebar">GCP에 대한 GCVE를 구성합니다</block>
  <block id="76862b378878c90a8052499ae898932f" category="sidebar">VMC를 위한 게스트 연결 스토리지</block>
  <block id="5703f41cd5551fad387ed46631532278" category="sidebar">AVS용 게스트 연결 스토리지</block>
  <block id="1f9511a418cf9a352bacd19d937a5237" category="sidebar">GCVE용 게스트 연결 저장소</block>
  <block id="a0e8297bc18713002f47301829625ea1" category="sidebar">NetApp for AWS/VMC</block>
  <block id="d530fb3a1e80511b2d7787728700d3fa" category="sidebar">NetApp for Azure/AVS</block>
  <block id="8d9d90a84ad6b34129f140e0b3e23326" category="sidebar">NetApp for GCP/GCVE</block>
  <block id="a3e92580de1a77cd25163bb63cd24a7d" category="inline-image-macro">링크 =<block ref="9b22e52230cfacf7992c01194e7a95d2" category="inline-link-rx"></block></block>
  <block id="f9da9dedda46425dea9fe2b0092e4b1a" category="paragraph"><block ref="f9da9dedda46425dea9fe2b0092e4b1a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46ded0be5f6c48090d38435b6dafa3e2" category="summary">이 섹션에서는 이 솔루션에서 검증된 세 가지 시나리오에 대해 간략하게 설명합니다.</block>
  <block id="71446ef316489c70b5279867eb81a86b" category="doc">테스트 및 검증 계획</block>
  <block id="8e593eca45d74047c3d169456d36d74a" category="paragraph"><block ref="8e593eca45d74047c3d169456d36d74a" category="inline-link-macro-rx"></block></block>
  <block id="68cdc250e271cc43502e5f009d0ebec7" category="paragraph">이 솔루션 설계의 경우 다음 세 가지 시나리오를 검증했습니다.</block>
  <block id="83c38d8dc6bc37fe6bb9691e75d0f881" category="list-text">Kubernetes용 NetApp DataOps Toolkit을 사용하여 조율된 JupyterLab 작업 공간 내의 프로토피아 난독 처리 기능을 사용하거나 사용하지 않는 추론 작업.</block>
  <block id="da4ec54ac3b4b67b77d52ccf0ebaefc0" category="list-text">Kubernetes용 NetApp DataOps Toolkit을 사용하여 오케스트레이션된 데이터 볼륨을 사용하는 Kubernetes에서 프로토피아 난독 처리를 사용하거나 사용하지 않는 배치 추론 작업</block>
  <block id="5526e24c695504cfa8b2187b0a3da212" category="list-text">Kubernetes용 NetApp DataOps 툴킷을 사용하여 조정된 NVIDIA Triton Inference Server 인스턴스를 사용한 추론 작업 네트워크를 통해 전송되는 모든 데이터가 난독 처리되어야 한다는 일반적인 요구 사항을 시뮬레이션하기 위해 Triton 추론 API를 호출하기 전에 이미지에 Protopia 난독 처리를 적용했습니다. 이 워크플로는 신뢰할 수 있는 영역 내에서 데이터를 수집하지만 추론을 위해 신뢰할 수 있는 영역 외부로 전달해야 하는 사용 사례에 적용됩니다. Protopia 난독 처리를 사용하지 않으면 중요한 데이터가 신뢰할 수 있는 영역을 벗어나지 않으면 이러한 유형의 워크플로를 구현할 수 없습니다.</block>
  <block id="9a1eb36c3c2949c4b9618b70f9947341" category="paragraph"><block ref="9a1eb36c3c2949c4b9618b70f9947341" category="inline-link-macro-rx"></block></block>
  <block id="91bc87f1c8c087219cec868bb9eec3e7" category="summary">이 검증에서는 일련의 원시 이미지를 사용하여 이미지 검색 사용 사례에 대한 추론을 수행했습니다. 그런 다음 추론 전에 Protopia 난독 처리를 추가하여 동일한 이미지 집합에서 동일한 추론 작업을 수행했습니다. 우리는 프로토피아 난독 처리 구성 요소에 대해 서로 다른 알파 값을 사용하여 작업을 반복했습니다.</block>
  <block id="f63c4677c27e0489f346c0711720cc39" category="doc">추론 정확도 비교</block>
  <block id="c06030c36071611ee2f3a9a21205eaf8" category="paragraph"><block ref="c06030c36071611ee2f3a9a21205eaf8" category="inline-link-macro-rx"></block></block>
  <block id="0c71eb4e1fba60fba81db988197da57d" category="paragraph">이 검증에서는 일련의 원시 이미지를 사용하여 이미지 검색 사용 사례에 대한 추론을 수행했습니다. 그런 다음 추론 전에 Protopia 난독 처리를 추가하여 동일한 이미지 집합에서 동일한 추론 작업을 수행했습니다. 우리는 프로토피아 난독 처리 구성 요소에 대해 서로 다른 알파 값을 사용하여 작업을 반복했습니다. Protopia 난독 처리 컨텍스트에서 알파 값은 더 높은 난독 처리 수준을 나타내는 더 높은 알파 값으로 적용되는 난독 처리 양을 나타냅니다. 그런 다음 이 서로 다른 실행 간에 추론 정확도를 비교합니다.</block>
  <block id="93d52a2c23957d4188c7b2ce8b2ae884" category="paragraph">다음 두 표에서는 사용 사례에 대한 자세한 내용과 결과에 대해 설명합니다.</block>
  <block id="65a3419ae19e457df9db4c0e110b2538" category="paragraph">Protopia는 고객과 직접 협력하여 특정 사용 사례에 적합한 알파 값을 결정합니다.</block>
  <block id="e558777bd1568637c97294a33389e930" category="cell">FaceBoXes(PyTorch) -</block>
  <block id="20172a059ee71423ad0d94393e819e10" category="cell">FDDB 데이터 세트</block>
  <block id="06a8fb4576a28a6488c929097c870fe1" category="cell">프로토피아 난독화</block>
  <block id="002101f8725e5c78d9f30d87f3fa4c87" category="cell">알파</block>
  <block id="d78f1fb7e69f7cddcf3e168f2663db20" category="cell">정확성</block>
  <block id="646738dcd35eaf5c3f3c9bfdc6a90b78" category="cell">0.9337148153739079</block>
  <block id="b14399cbaac6da4b5b733b483106383f" category="cell">0.05</block>
  <block id="bcf8c22771ff8c7065180f5a6526d4a6" category="cell">0.902876627325002</block>
  <block id="cb5ae17636e975f9bf71ddf5bc542075" category="cell">0.1</block>
  <block id="1336b1cb08d93aa0a453c53e27efa594" category="cell">0.9024301009661478</block>
  <block id="b1cb1b288bfae3850c74795f5691dc4e" category="cell">0.9081836283186224</block>
  <block id="b9e8c964d5c5d3e7c815896cd6235239" category="cell">0.9073066107482036</block>
  <block id="57489d9101ec373d9e2841292a5b3af9" category="cell">0.8847816568680239</block>
  <block id="57eeec0a6974ecb4e9fcf68fab052f7b" category="cell">0.8</block>
  <block id="8ab8d7756b82eb70d635bc66c1bc532b" category="cell">0.8841195749171925</block>
  <block id="a894124cc6d5c5c71afe060d5dde0762" category="cell">0.9</block>
  <block id="226cc0951c1f30973a4c71f0f567936a" category="cell">0.8455427675252052</block>
  <block id="248a7444f08189bb31ba143eabebe4e5" category="cell">0.95</block>
  <block id="0f39c006b0d74178bc826c1d567a79dc" category="inline-link-macro">다음: 난독 처리 속도.</block>
  <block id="ca9c4b25b025c5564f5ffb65a712a47c" category="paragraph"><block ref="ca9c4b25b025c5564f5ffb65a712a47c" category="inline-link-macro-rx"></block></block>
  <block id="a41206687a4ac62c15fc883554a75883" category="summary">이 섹션에서는 솔루션 설계 검증 환경에 대해 간략하게 설명합니다.</block>
  <block id="172ddae93475d6ccf42e145bb593da46" category="inline-link-macro">이전: 테스트 및 검증 계획.</block>
  <block id="9ea432ca0ec547aa219093f8f5f560cc" category="paragraph"><block ref="9ea432ca0ec547aa219093f8f5f560cc" category="inline-link-macro-rx"></block></block>
  <block id="0d013965bb31fe1cc0ba44ef3b846d09" category="paragraph">다음 표에서는 솔루션 설계 검증 환경을 간략하게 보여 줍니다.</block>
  <block id="32f014d18e1f60596057834de2864322" category="cell">1.21.6</block>
  <block id="b0f69588db488e358ab3c85429ab6b3a" category="cell">NetApp Astra Trident CSI 드라이버</block>
  <block id="297924c1d3fec9d97f9a1f3b49ee0709" category="cell">Kubernetes용 NetApp DataOps 툴킷</block>
  <block id="70e2b24f7d348efe6b30b41469d5070c" category="cell">2.3.0</block>
  <block id="2c5e74d45708e2fae638e03f88353b75" category="cell">NVIDIA Triton Inference Server를 참조하십시오</block>
  <block id="099d96b4d8f70fb73f1d4661f98c337a" category="cell">21.11-3장</block>
  <block id="53e01217bc7db361f46a1f8e0e601655" category="paragraph"><block ref="53e01217bc7db361f46a1f8e0e601655" category="inline-link-macro-rx"></block></block>
  <block id="fcd8d375e90bbb5d8febe3b3eac09c2b" category="doc">추가 정보, 확인 및 버전 기록을 찾을 수 있는 위치</block>
  <block id="86a4acc956f71e307a08f732dd442d3f" category="paragraph"><block ref="86a4acc956f71e307a08f732dd442d3f" category="inline-link-macro-rx"></block></block>
  <block id="f85150beb9ce598095b212b1de60815f" category="list-text">NetApp ONTAP 데이터 관리 소프트웨어 - ONTAP 정보 라이브러리</block>
  <block id="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link"><block ref="eb87ce8a565e070f3b8c09faa4e840c1" category="inline-link-rx"></block></block>
  <block id="20a0f3ab42054c3aa4add8c8901b4aa9" category="paragraph"><block ref="20a0f3ab42054c3aa4add8c8901b4aa9" category="inline-link-rx"></block></block>
  <block id="2cd8f6bd0ec1bbc37315b8bc134e16c5" category="list-text">컨테이너용 NetApp 영구 스토리지 - NetApp Astra Trident</block>
  <block id="89f170193efdf8434f549c8e91adf860" category="list-text">토폴로지 AI - 기밀 추론</block>
  <block id="62faa8d62bfb6098877b809cce925de5" category="inline-link"><block ref="62faa8d62bfb6098877b809cce925de5" category="inline-link-rx"></block></block>
  <block id="45b79877f4c11139882c88df94d50fa6" category="paragraph"><block ref="45b79877f4c11139882c88df94d50fa6" category="inline-link-rx"></block></block>
  <block id="2c54e28a12ce15452929a28550a30a96" category="inline-link"><block ref="2c54e28a12ce15452929a28550a30a96" category="inline-link-rx"></block></block>
  <block id="bc5345c4517d46bdf8a87f10d404839f" category="paragraph"><block ref="bc5345c4517d46bdf8a87f10d404839f" category="inline-link-rx"></block></block>
  <block id="fba4b133e329411c361e02e05efed0b9" category="list-text">NVIDIA Triton Inference Server 설명서</block>
  <block id="cce40efbd4a717916ccbab694b676e9c" category="inline-link"><block ref="cce40efbd4a717916ccbab694b676e9c" category="inline-link-rx"></block></block>
  <block id="170ba65f4e4807f3643de39afb3f2e16" category="paragraph"><block ref="170ba65f4e4807f3643de39afb3f2e16" category="inline-link-rx"></block></block>
  <block id="ba1d5cc71378020998752955821460b2" category="list-text">PyTorch의 FaceBoxes</block>
  <block id="ace8d80d2ede0fadf07325408b376b83" category="inline-link"><block ref="ace8d80d2ede0fadf07325408b376b83" category="inline-link-rx"></block></block>
  <block id="a688d324b63c4f882d06673058aa2f61" category="paragraph"><block ref="a688d324b63c4f882d06673058aa2f61" category="inline-link-rx"></block></block>
  <block id="121ef407a6a3c08ce9fa247e382d7637" category="list-text">Mark Cates, 수석 제품 관리자, NetApp</block>
  <block id="fb345adb43ea24ffc891d20327bdca09" category="list-text">NetApp 기술 마케팅 엔지니어 Sufian Ahmad</block>
  <block id="711ba3fec382e550526a6ab0f49bdf3a" category="list-text">Hadi Esmaeilzadeh, 최고 기술 책임자 및 Protopia AI 교수</block>
  <block id="0844bd2427e754de1d07ca91d15284a5" category="cell">문서 버전 기록</block>
  <block id="cd24a85c5cf2d1a7af0bade6066be0aa" category="summary">데이터는 사용되지 않는 상태, 전송 중 상태, 컴퓨팅 중 세 가지 상태로 존재합니다. AI 추론 서비스의 중요한 부분은 전체 프로세스 동안 위협으로부터 데이터를 보호하는 것이 되어야 합니다. 추론 도중에 데이터를 보호하는 것은 매우 중요합니다. 이 프로세스에서는 외부 고객과 추론 서비스를 제공하는 회사 모두에 대한 비공개 정보를 표시할 수 있기 때문입니다.</block>
  <block id="fd8d4cefd4e31d8ce81b0b6c4cf90ae2" category="inline-link-macro">이전: 난독 처리 속도.</block>
  <block id="12deb7181b69808aaa08117bd40978a3" category="paragraph"><block ref="12deb7181b69808aaa08117bd40978a3" category="inline-link-macro-rx"></block></block>
  <block id="4282c9ab06938351529fcc9258e39d5a" category="paragraph">데이터는 세 가지 상태, 즉 유휴 상태, 전송 중 상태 및 계산 중에 있습니다. AI 추론 서비스의 중요한 부분은 전체 프로세스 동안 위협으로부터 데이터를 보호하는 것이 되어야 합니다. 추론 도중에 데이터를 보호하는 것은 매우 중요합니다. 이 프로세스에서는 외부 고객과 추론 서비스를 제공하는 회사 모두에 대한 비공개 정보를 표시할 수 있기 때문입니다. Protopia AI는 오늘날의 시장에서 기밀 AI 추론을 위한 비간섭 소프트웨어 전용 솔루션입니다. Protopia를 통해 AI는 현재 AI/ML 작업을 수행하는 데 필수적인 데이터 레코드에 변환된 정보만 제공합니다. 이 확률적 변환은 마스킹의 형태가 아니며 큐레이션 노이즈를 사용하여 데이터의 표현을 수학적으로 변경하는 것을 기반으로 합니다.</block>
  <block id="945691f1b395ce7af4d5e818b4e62b9b" category="paragraph">ONTAP 기능을 갖춘 NetApp 스토리지 시스템은 로컬 SSD 스토리지와 동일하거나 더 우수한 성능을 제공하며 NetApp DataOps Toolkit과 함께 데이터 과학자, 데이터 엔지니어, AI/ML 개발자 및 비즈니스 또는 엔터프라이즈 IT 의사 결정자에게 다음과 같은 이점을 제공합니다.</block>
  <block id="2d1d64cb5768a8ce2a6d6bda322d2ecd" category="list-text">재해 복구, 비즈니스 연속성 및 규정 요구사항을 충족하는 엔터프라이즈급 데이터 보호 및 데이터 거버넌스</block>
  <block id="58b8e67477c25a96d3b430f4ee8d75cf" category="list-text">Jupyter 노트북에 있는 NetApp DataOps Toolkit에서 데이터 과학자 작업 공간의 Snapshot 복사본을 신속하게 만들어 백업 및 추적 기능을 제공합니다.</block>
  <block id="57e858ddb0a3e1c340cfe4ba7d5c3a14" category="paragraph">NetApp 및 Protopia 솔루션은 엔터프라이즈급 AI 추론 구축에 이상적인 유연한 스케일아웃 아키텍처를 제공합니다. 이 솔루션은 사내 및 하이브리드 클라우드 구축 모두에서 책임 있는 AI 사례를 충족할 수 있는 기밀 AI 추론 요구사항을 충족하는 중요한 정보에 대해 데이터 보호를 지원합니다.</block>
  <block id="6073423c521e84b849e3b84fa1cc380c" category="inline-link-macro">다음: 추가 정보, 확인 및 버전 기록을 찾을 위치.</block>
  <block id="9eebc409a853e8c97008be61e4a0b83a" category="paragraph"><block ref="9eebc409a853e8c97008be61e4a0b83a" category="inline-link-macro-rx"></block></block>
  <block id="6bee97571af49e4c38ff85a4abbbe0e9" category="summary">이 섹션에서는 검증을 완료하는 데 필요한 작업에 대해 설명합니다.</block>
  <block id="c17e6835560e56c00184a993e1b0bfdb" category="paragraph"><block ref="c17e6835560e56c00184a993e1b0bfdb" category="inline-link-macro-rx"></block></block>
  <block id="df06a8aa3d194f798e70c253c55d915c" category="paragraph">이 섹션에 설명된 작업을 실행하려면 다음 도구가 설치 및 구성되어 있는 Linux 또는 macOS 호스트에 대한 액세스 권한이 있어야 합니다.</block>
  <block id="c0ffe26d3756a5c964ff9bc591e1fc16" category="list-text">Kubectl(기존 Kubernetes 클러스터에 액세스하도록 구성)</block>
  <block id="e436fe7c4ecfcca0f0327b41471955df" category="list-text">설치 및 구성 지침을 찾을 수 있습니다<block ref="f6d4f9e359e394de0cb3015a4518672c" category="inline-link-rx"></block>.</block>
  <block id="e3e34254666d96b8967227676b54e135" category="list-text">설치 지침을 찾을 수 있습니다<block ref="9535953c30e005e9672e48b24a3ac733" category="inline-link-rx"></block>.</block>
  <block id="1a66086f406852b100e9d8f85d007b87" category="section-title">시나리오 1 – JupyterLab의 온디맨드 추론</block>
  <block id="28876e2d40a33fcbc3630d7408b14046" category="list-text">AI/ML 추론 워크로드를 위한 Kubernetes 네임스페이스를 생성합니다.</block>
  <block id="1464ad61957a8ed3db5f67edbc20cc41" category="list-text">NetApp DataOps 툴킷을 사용하여 추론을 수행할 데이터를 저장할 영구 볼륨을 프로비저닝합니다.</block>
  <block id="da33a6119aa0b49526bd284e9a865ed5" category="list-text">NetApp DataOps Toolkit을 사용하여 새로운 JupyterLab 작업 공간을 생성합니다. '--mount-PVC' 옵션을 사용하여 이전 단계에서 생성한 영구 볼륨을 마운트합니다. 필요한 경우 '--nVidia-GPU' 옵션을 사용하여 NVIDIA GPU를 작업 공간에 할당합니다.</block>
  <block id="810e88d69a6b7f454f24db3a25ba375a" category="paragraph">다음 예에서는 영구 볼륨 '추론 데이터'가 '/home/jovyan/data'의 JupyterLab 작업 영역 컨테이너에 마운트됩니다. Jupytter의 공식 컨테이너 이미지를 사용할 때 JupyterLab 웹 인터페이스 내의 최상위 디렉토리로 /home/jovyan이 표시됩니다.</block>
  <block id="ecca64929aad192e0cdba66d89af6fc2" category="list-text">'jupyterlab 생성' 명령의 출력에 지정된 URL을 사용하여 JupyterLab 작업 영역에 액세스합니다. 데이터 디렉토리는 작업 공간에 마운트된 영구 볼륨을 나타냅니다.</block>
  <block id="1f069f45990199d6afbe5926fb26f127" category="paragraph"><block ref="1f069f45990199d6afbe5926fb26f127" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5989087fa6f30a7b2ad79b3b28f4f68" category="list-text">"ata" 디렉토리를 열고 추론을 수행할 파일을 업로드합니다. 파일이 데이터 디렉토리에 업로드되면 작업 공간에 마운트된 영구 볼륨에 자동으로 저장됩니다. 파일을 업로드하려면 다음 이미지와 같이 파일 업로드 아이콘을 클릭합니다.</block>
  <block id="f6d07c27f458648455903cf09530655f" category="paragraph"><block ref="f6d07c27f458648455903cf09530655f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c6da42e23b9d4e193c2fb146b8189581" category="list-text">최상위 디렉토리로 돌아가서 새 전자 필기장을 만듭니다.</block>
  <block id="59e51e40d73317a796f7d0b25d8fa003" category="paragraph"><block ref="59e51e40d73317a796f7d0b25d8fa003" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d6d5c0ae1c38484d2d4fd513ff80f90" category="list-text">노트북에 추론 코드를 추가합니다. 다음 예에서는 이미지 감지 사용 사례에 대한 추론 코드를 보여 줍니다.</block>
  <block id="901ae9d6148669912b400c6d2647bfbf" category="paragraph"><block ref="901ae9d6148669912b400c6d2647bfbf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f10850488ed018cdad31f8ac9e8bab" category="paragraph"><block ref="45f10850488ed018cdad31f8ac9e8bab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="296d40736553e2033f5cf8817174bc7c" category="list-text">추론 코드에 Protopia 난독 처리를 추가합니다. Protopia는 고객과 직접 협력하여 사용 사례별 문서를 제공하며 이 기술 보고서의 범위를 벗어납니다. 다음 예제에서는 Protopia 난독 처리를 추가한 이미지 검색 사용 사례에 대한 추론 코드를 보여 줍니다.</block>
  <block id="5a10342224477df560528e700989b536" category="paragraph"><block ref="5a10342224477df560528e700989b536" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20f77c05fa583bdc62074b26870e07e7" category="paragraph"><block ref="20f77c05fa583bdc62074b26870e07e7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9d5709eb5c3d3d4a700397ee447f9818" category="section-title">시나리오 2 – Kubernetes의 배치 추론</block>
  <block id="77b69d61f1889c8321dce66f3c3e2e1a" category="list-text">추론을 수행할 데이터로 새 영구 볼륨을 채웁니다.</block>
  <block id="8b6983cc7986c7b0553983d8ab669289" category="inline-link">NetApp DataOps 툴킷 S3 Data Mover 기능</block>
  <block id="2933df0ebac7b47c349bd6bd7099fb90" category="paragraph">PVC로 데이터를 로드하는 방법은 여러 가지가 있습니다. 현재 데이터가 NetApp StorageGRID 또는 Amazon S3와 같은 S3 호환 오브젝트 스토리지 플랫폼에 저장되어 있는 경우 를 사용할 수 있습니다<block ref="5d1617256d53e0547b237f3cf3fda5b0" category="inline-link-rx"></block>. 또 하나의 간단한 방법은 JupyterLab 작업 공간을 만든 다음, 섹션 “의 3-5단계에 설명된 대로 JupyterLab 웹 인터페이스를 통해 파일을 업로드하는 것입니다<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>.”</block>
  <block id="a62147e18dbac7ad5eab17791c371ad4" category="list-text">배치 추론 작업을 위해 Kubernetes 작업을 생성합니다. 다음 예는 이미지 감지 사용 사례에 대한 배치 추론 작업을 보여줍니다. 이 작업은 이미지 세트의 각 이미지에서 추론을 수행하고 추론 정확도 메트릭을 stdout에 씁니다.</block>
  <block id="a883fb9f7bda67c6fbcab6dfb8f091ce" category="list-text">추론 작업이 성공적으로 완료되었는지 확인합니다.</block>
  <block id="590888c60942c47f5268c19f273109ee" category="list-text">추론 작업에 Protopia 난독 처리를 추가합니다. 이 기술 보고서의 범위를 벗어나는 Protopia에서 직접 Protopia 난독 처리를 추가하기 위한 사용 사례별 지침을 찾을 수 있습니다. 다음 예제는 알파 값 0.8을 사용하여 Protopia 난독 처리가 추가된 얼굴 인식 사용 사례에 대한 일괄 추론 작업을 보여 줍니다. 이 작업은 이미지 세트의 각 이미지에 대한 추론을 수행하기 전에 Protopia 난독 처리를 적용한 다음 추론 정확도 메트릭을 stdout에 기록합니다.</block>
  <block id="7a1adb5cebbf78f3eddc08a64751149e" category="inline-link-macro">“추론 정확도 비교.”</block>
  <block id="da2c9dc305dff324654e67571156b295" category="paragraph">알파 값 0.05, 0.1, 0.2, 0.4, 0.6, 0.8, 0.9 및 0.95. 에서 결과를 볼 수 있습니다 <block ref="af158494e4986d64d04037857fed2d1c" category="inline-link-macro-rx"></block></block>
  <block id="76d6540fbdbbcd913fb6272a50d0e3f2" category="section-title">시나리오 3 – NVIDIA Triton Inference Server</block>
  <block id="c470d7124546c64e8539c39ced806428" category="list-text">NetApp DataOps 툴킷을 사용하여 NVIDIA Triton Inference Server의 모델 저장소로 사용할 영구 볼륨을 프로비저닝합니다.</block>
  <block id="1ddcb92ade31c8fbd370001f9b29a7d9" category="inline-link">형식</block>
  <block id="97be18cb741b4fd763ebe22e034705fa" category="list-text">의 새 영구 볼륨에 모델을 저장합니다<block ref="bfcdc35d352d3deff6efdd3b8b2ac7ac" category="inline-link-rx"></block> 이 기능은 NVIDIA Triton Inference Server에서 인식됩니다.</block>
  <block id="6c21d87641bab7a6c49bc29065185e4f" category="paragraph">PVC로 데이터를 로드하는 방법은 여러 가지가 있습니다. 간단한 방법은 “의 3-5단계에 설명된 대로 JupyterLab 작업 공간을 만든 다음 JupyterLab 웹 인터페이스를 통해 파일을 업로드하는 것입니다<block ref="db54c391b2f7c3a38c2e40a69aa744e3" category="inline-xref-macro-rx"></block>. ”</block>
  <block id="fc35606f82a544f9c79f09561d7a234d" category="list-text">NetApp DataOps 툴킷을 사용하여 새 NVIDIA Triton Inference Server 인스턴스를 구축합니다.</block>
  <block id="27a920b35a8f949700a98b22803c70fc" category="list-text">Triton 클라이언트 SDK를 사용하여 추론 작업을 수행합니다. 인용된 다음 Python 코드는 Triton Python 클라이언트 SDK를 사용하여 얼굴 감지 사용 사례에 대한 추론 작업을 수행합니다. 이 예에서는 Triton API를 호출하고 추론을 위해 이미지를 전달합니다. 그런 다음 Triton Inference Server가 요청을 수신하고 모델을 호출하고 추론 출력을 API 결과의 일부로 반환합니다.</block>
  <block id="7b5e296090a5d063fdbd3ebb69fc6547" category="list-text">추론 코드에 Protopia 난독 처리를 추가합니다. Protopia에서 직접 Protopia 난독 처리를 추가하기 위한 사용 사례별 지침을 찾을 수 있지만 이 프로세스는 이 기술 보고서의 범위를 벗어납니다. 다음 예제에서는 앞의 5단계에서 표시되지만 Protopia 난독 처리를 추가한 것과 동일한 Python 코드를 보여 줍니다.</block>
  <block id="c3069165ee6fb9d5dde8d8472d8b4602" category="paragraph">이 경우, Triton API로 전달되기 전에 Protopia 난독 처리 기능이 이미지에 적용됩니다. 따라서, 난독 처리된 이미지가 로컬 시스템에서 절대 빠져나가지는 않습니다. 난독 처리된 이미지만 네트워크를 통해 전달됩니다. 이 워크플로는 신뢰할 수 있는 영역 내에서 데이터를 수집한 다음 추론을 위해 신뢰할 수 있는 영역 외부로 전달해야 하는 사용 사례에 적용됩니다. Protopia 난독 처리를 사용하지 않으면 중요한 데이터가 신뢰할 수 있는 영역을 벗어나지 않으면 이러한 유형의 워크플로를 구현할 수 없습니다.</block>
  <block id="38bb883cb543c747fc0f113099f5072d" category="inline-link-macro">다음: 추론 정확도 비교.</block>
  <block id="1f2c820475fbde991c6219936a645aea" category="paragraph"><block ref="1f2c820475fbde991c6219936a645aea" category="inline-link-macro-rx"></block></block>
  <block id="c46aabfbeb0af662ede62f7325853fa2" category="summary">디지털 이미지 프로세싱은 많은 이점을 제공하므로 많은 조직에서 시각적 표현과 관련된 데이터를 최대한 활용할 수 있습니다. 이 NetApp 및 Protopia 솔루션은 ML/DL 수명 주기 동안 AI/ML 데이터를 보호하고 민영화 할 수 있는 고유한 AI 추론 설계를 제공합니다. 고객은 이 모델을 통해 기밀 데이터에 대한 소유권을 유지하고, 개인 정보 보호와 관련된 문제를 완화하여 규모에 맞게 퍼블릭 또는 하이브리드 클라우드 구축 모델을 사용하거나, 에지에 AI 추론을 배포할 수 있습니다.</block>
  <block id="b7aff368ab91b524750e403085893177" category="paragraph"><block ref="b7aff368ab91b524750e403085893177" category="inline-link-macro-rx"></block></block>
  <block id="55ece983a5251583397e3db1cd3926ec" category="section-title">환경 인텔리전스</block>
  <block id="d0f24bc92f5b7838f03e893b41066a90" category="paragraph">업계가 환경적 위험 영역에서 지리 공간 분석을 활용할 수 있는 방법은 여러 가지가 있습니다. 정부 및 공공사업 부서는 전염병 또는 산불과 같은 자연 재해 발생 시 공공 보건 및 기상 조건에 대한 실행 가능한 통찰력을 제공하여 일반에게 보다 나은 조언을 제공할 수 있습니다. 예를 들어, 영향을 받는 개인의 사생활을 침해하지 않고 공항 또는 병원과 같은 공공 장소에서 COVID-양성 환자를 식별하고 관련 당국과 인근 직원에게 필요한 안전 조치를 알릴 수 있습니다.</block>
  <block id="4f9352e4f65872238d755155cd23edec" category="section-title">에지 장치 웨어러블</block>
  <block id="315a1bbca88dbcbdc95471a0061c333f" category="paragraph">군대와 전쟁터에서 군인의 사생활을 보호하고 보호하면서 군인의 건강을 추적하고, 운전자의 행동을 모니터링하고, 군용 차량에 접근하는 안전 및 관련 위험에 대해 당국에게 경고하기 위해 엣지에서 AI 추론을 웨어러블 장치로 사용할 수 있습니다. 군대의 미래는 전투지 사물 인터넷(IoT)과 웨어러블 전투기용 사물 인터넷(IoMT)을 통해 첨단 기술로 나아가고 있습니다. 이 장비는 신속한 에지 컴퓨팅을 통해 군인들이 적들을 식별하고 전투에서 더 나은 성과를 달성할 수 있도록 지원합니다. 드론과 웨어러블 기어와 같은 에지 장치에서 수집된 시각적 데이터를 보호하고 보존하는 것은 해커와 적에게 항상 보안을 유지하는 데 매우 중요합니다.</block>
  <block id="d6dded41a42f767150e641793fc0c929" category="section-title">비전투원 대피 작전</block>
  <block id="c5b381de9b2a4ee73bcc524aa380d725" category="paragraph">비전투원 대피 작전(Neos)은 미 국방부가 미국 시민과 국적을 대피시키기 위해, 국방부 민간인 직원, 그리고 적절한 안전한 피난처로 목숨을 걸고 있는 지정된 사람(HN)과 제3국 국민(TCN)을 대피시키기 위해 실시합니다. 현재 행정적 통제는 대부분 수작업을 통해 선별검사 프로세스를 비우는 데 사용됩니다. 그러나 AI/ML 비디오 난독 처리 기술과 결합된 고도로 자동화된 AI/ML 도구를 사용하면 비우는 ID, 비우는 방법 추적 및 위협 선별의 정확성, 보안 및 속도를 개선할 수 있습니다.</block>
  <block id="2d930616ec617ae047b7b7eaefb0822c" category="section-title">AI/ML 분석의 클라우드 마이그레이션</block>
  <block id="073395e7b5fc53b602884ac0aaf757fb" category="inline-link">데이터 보호</block>
  <block id="c9f2e6462caf995f1d336ab4bb33a7c2" category="inline-link">TR-4886 Ai Inferencing at the Edge(가장자리 기준 TR-4886 AI 추론</block>
  <block id="ae1b6ac445119145d739025d55fe616f" category="inline-link">인텔리전스와 개인 정보 보호 비교</block>
  <block id="215649425fa669fb4825e25a6ace492e" category="paragraph">다른 업계에서의 에지 컴퓨팅 및 AI 추론의 추가 사용 사례는 를 참조하십시오<block ref="922342ea98ca297422c6dc441f974a04" category="inline-link-rx"></block> 그리고 NetApp AI 블로그,<block ref="bc130be57ffb0325128dc7274bbdbc64" category="inline-link-rx"></block>.</block>
  <block id="5318c453b0f0b1d5351026eca9f9899d" category="paragraph"><block ref="5318c453b0f0b1d5351026eca9f9899d" category="inline-link-macro-rx"></block></block>
  <block id="4c787c1632a0a940cb0b44706b1d24c6" category="summary">이 섹션에서는 이 솔루션을 완료하는 데 필요한 다양한 기술 구성 요소에 대해 간략하게 설명합니다.</block>
  <block id="2c6beb1e15771dbe426409f9b5d4aaf9" category="inline-link-macro">이전: 솔루션 영역.</block>
  <block id="8a26bc3756fc01f4b929845a326e9b9d" category="paragraph"><block ref="8a26bc3756fc01f4b929845a326e9b9d" category="inline-link-macro-rx"></block></block>
  <block id="a6d48b22bcf266404bdb8c57102c14a4" category="section-title">프로토피아</block>
  <block id="b2cbc1ff8afd6c872961a852572e1782" category="paragraph">Protopia AI는 오늘날 시장에서 기밀 추론을 위한 방해되지 않는 소프트웨어 전용 솔루션을 제공합니다. Protopia 솔루션은 중요한 정보의 노출을 최소화하여 추론 서비스를 위한 탁월한 보호 기능을 제공합니다. AI는 현재 작업을 수행하는 데 꼭 필요한 데이터 레코드의 정보만 제공합니다. 대부분의 추론 작업에서는 모든 데이터 레코드에 있는 모든 정보를 사용하지 않습니다. AI가 이미지, 음성, 비디오 또는 구조화된 표 형식 데이터를 소비하고 있는지 여부와 관계없이 Protopia는 추론 서비스에 필요한 것만 제공합니다. 특허를 획득한 코어 기술은 수학적으로 선별된 소음을 사용하여 데이터를 변환하고 지정된 ML 서비스에서 필요하지 않은 정보를 제공합니다. 이 솔루션은 데이터를 마스킹하지 않고 선별된 랜덤 노이즈를 사용하여 데이터 표현을 변경합니다.</block>
  <block id="46ce082967eab6fe2e33798614d50861" category="paragraph">프로토피아 솔루션은 모델의 기능과 관련하여 입력 기능 공간에 관련 정보를 계속 유지하는 경사 기반 퍼터버레이션 최대화 방법으로 표현을 변경하는 문제를 공식화합니다. 이 검색 프로세스는 ML 모델 교육을 마칠 때 미세 조정 통과로 실행됩니다. 통과가 자동으로 확률 분포 세트를 생성한 후 오버헤드가 낮은 데이터 변환은 이러한 분포의 노이즈 샘플을 데이터에 적용하고 추론을 위해 모델에 전달하기 전에 난독 처리 합니다.</block>
  <block id="4fb9892dc0183c3142a3629cecc3104a" category="paragraph">DGX A100 시스템과 NetApp 클라우드 연결형 스토리지 시스템에 기반한 NetApp ONTAP AI 참조 아키텍처는 NetApp과 NVIDIA가 개발 및 검증했습니다. 이 아키텍처는 IT 조직에 다음과 같은 이점을 제공하는 아키텍처를 제공합니다.</block>
  <block id="988d7b305f79b990bbacdaed46f4b2bf" category="paragraph">ONTAP AI는 DGX A100 시스템과 NetApp AFF A800 스토리지 시스템을 최첨단 네트워킹과 긴밀하게 통합합니다. ONTAP AI는 설계 복잡성과 추측을 제거함으로써 AI 배포를 단순화합니다. 고객은 작은 규모로 시작한 후 에지에서 코어 및 클라우드까지 포괄하여 데이터를 지능적으로 관리하면서 중단 없이 확장할 수 있습니다.</block>
  <block id="57e22b018aa5130ece9890cd6b45e779" category="paragraph">다음 그림은 DGX A100 시스템과 ONTAP AI 솔루션 제품군의 다양한 변형을 보여줍니다. 최대 8개의 DGX A100 시스템에서 AFF A800 시스템 성능 검증 ONTAP 클러스터에 스토리지 컨트롤러 쌍을 추가하면 아키텍처를 여러 개의 랙으로 확장하여 선형 성능으로 많은 DGX A100 시스템과 페타바이트급 스토리지 용량을 지원할 수 있습니다. 이 접근 방식은 사용되는 DL 모델의 크기와 필요한 성능 메트릭을 기준으로 컴퓨팅 대 스토리지 비율을 독립적으로 변경할 수 있는 유연성을 제공합니다.</block>
  <block id="316a5094893ef1b058844a75c53aaf04" category="paragraph"><block ref="316a5094893ef1b058844a75c53aaf04" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ecc164061fb57b585c892f0faa6f4dcf" category="inline-link">NVA-1153: NVIDIA DGX A100 시스템 및 Mellanox Spectrum 이더넷 스위치를 포함하는 NetApp ONTAP AI</block>
  <block id="3046083f382853b50c004323f2cda8f9" category="paragraph">ONTAP AI에 대한 자세한 내용은 를 참조하십시오<block ref="2c1616ab9baa55036487e7ef75b3821d" category="inline-link-rx"></block></block>
  <block id="862dcadd0f2887701abaa60bf59d5aa5" category="paragraph">NetApp의 최신 세대 스토리지 관리 소프트웨어인 ONTAP 9.11을 통해 기업은 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있습니다. ONTAP는 업계 최고 수준의 데이터 관리 기능을 활용하여 데이터가 상주하는 위치와 상관없이 단일 툴셋으로 데이터를 관리하고 보호할 수 있습니다. 필요에 따라 에지, 코어, 클라우드 등 어느 위치로도 데이터를 자유롭게 이동할 수 있습니다. ONTAP 9.11에는 데이터 관리를 단순화하고, 중요 데이터를 가속화하고, 보호하며, 하이브리드 클라우드 아키텍처 전반에 걸쳐 차세대 인프라 기능을 지원하는 다양한 기능이 포함되어 있습니다.</block>
  <block id="94c4b42bd5bfaa12f328387b161a1686" category="paragraph">NetApp DataOps Toolkit은 개발자, 데이터 과학자, DevOps 엔지니어 및 데이터 엔지니어가 새로운 데이터 볼륨의 거의 즉각적인 프로비저닝 또는 JupyterLab 작업 공간, 데이터 볼륨의 거의 즉각적인 클론 복제 또는 JupyterLab 작업 공간과 같은 다양한 데이터 관리 작업을 간단하게 수행할 수 있는 Python 라이브러리입니다. 추적 기능 또는 베이스라인 기능을 위해 데이터 볼륨의 스냅샷 또는 JupyterLab 작업 공간을 거의 즉각적으로 생성합니다. 이 Python 라이브러리는 명령행 유틸리티 또는 Python 프로그램이나 Jupyter 노트북으로 가져올 수 있는 기능의 라이브러리로 작동할 수 있습니다.</block>
  <block id="dea84e2e635ce73ddc479a38d5616c98" category="paragraph">NVIDIA Triton Inference Server는 모델 구축 및 실행을 표준화하여 운영 환경에서 신속하고 확장 가능한 AI를 제공하는 오픈 소스 추론 제공 소프트웨어입니다. Triton Inference Server는 팀이 GPU 또는 CPU 기반 인프라의 모든 프레임워크에서 훈련된 AI 모델을 구축, 실행 및 확장할 수 있도록 지원하여 AI 추론을 간소화합니다. Triton Inference Server는 TensorFlow, NVIDIA TensorRT, PyTorch, MXNet, OpenVINO 등 Triton은 모든 주요 퍼블릭 클라우드 AI 및 Kubernetes 플랫폼에서 사용할 수 있는 오케스트레이션 및 확장을 위해 Kubernetes와 통합됩니다. 또한 많은 MLOps 소프트웨어 솔루션과 통합됩니다.</block>
  <block id="95b88f180e9eb5678e0f9ebac2cbe643" category="section-title">PyTorch</block>
  <block id="04f7f16178ab3e9bddfd0837b64d21a2" category="paragraph"><block ref="7b17fc2d2143dfdbd3bff6783f73e17c" category="inline-link-rx"></block> 는 오픈 소스 ML 프레임워크입니다. GPU 및 CPU를 사용하는 딥 러닝용으로 최적화된 텐서 라이브러리입니다. PyTorch 패키지에는 여러 유용한 유틸리티 간에 효율적인 서너 직렬화를 위한 여러 유틸리티를 제공하는 다차원 Tensor용 데이터 구조가 포함되어 있습니다. 또한 컴퓨팅 기능이 있는 NVIDIA GPU에서 텐서 컴퓨팅을 실행할 수 있는 CUDA 상대가 있습니다. 이 검증에서는 OpenCV-Python(CV2) 라이브러리를 사용하여 모델을 검증하고 Python의 가장 직관적인 컴퓨터 비전 개념을 활용합니다.</block>
  <block id="47b2e74e56111387efd2ff8314d1154c" category="paragraph">데이터 관리는 AI 애플리케이션에 적합한 리소스를 사용하고 AI/ML 데이터 세트를 교육할 수 있도록 엔터프라이즈 IT 운영 및 데이터 과학자에게 매우 중요합니다. NetApp 기술에 대한 다음 추가 정보는 이 검증의 범위에 포함되지 않지만, 배포에 따라 달라질 수 있습니다.</block>
  <block id="31c0318dee8b7049a328f752c457824f" category="paragraph">ONTAP 데이터 관리 소프트웨어에는 운영을 간소화 및 단순화하고 총 운영 비용을 절감하는 다음과 같은 기능이 있습니다.</block>
  <block id="258ce6748736436345d3a4ade7bfcd47" category="list-text">인라인 데이터 컴팩션 및 확대된 중복제거: 데이터 컴팩션은 스토리지 블록 내부의 낭비되는 공간을 줄이고, 중복제거는 실제 용량을 상당히 늘려줍니다. 이는 로컬에 저장된 데이터와 클라우드로 계층화된 데이터에 적용됩니다.</block>
  <block id="e0243dd3e4c9bff6b7a18cab1c1e37c8" category="list-text">최소, 최대 및 적응형 서비스 품질(AQoS): 세부적인 서비스 품질(QoS) 제어로 고도의 공유 환경에서 중요 애플리케이션의 성능 수준을 유지할 수 있습니다.</block>
  <block id="c3528a5e48bbe189e76cf8d737aa5961" category="inline-link">TR-4598: FabricPool 모범 사례</block>
  <block id="adc171e1d8b6a0bed3a98762139c9875" category="list-text">NetApp FabricPool를 참조하십시오. AWS(Amazon Web Services), Azure, NetApp StorageGRID 스토리지 솔루션을 포함한 퍼블릭 클라우드 및 프라이빗 클라우드 스토리지에 콜드 데이터를 자동으로 계층화합니다. FabricPool에 대한 자세한 내용은 를 참조하십시오<block ref="234c921b7066bc1bdd676ae1a510e5c5" category="inline-link-rx"></block>.</block>
  <block id="d9cd75773d759d63134b34db3490eab3" category="paragraph">ONTAP는 탁월한 수준의 성능과 데이터 보호를 제공하며 다음과 같은 방법으로 이러한 기능을 확장합니다.</block>
  <block id="cdea8196113c492688981e0a035baa29" category="list-text">성능 및 짧은 지연 시간: ONTAP는 가장 짧은 지연 시간으로 가장 높은 처리량을 제공합니다.</block>
  <block id="fa126db4297464dd03b3ceef190df0d0" category="list-text">데이터 보호: ONTAP는 모든 플랫폼에서 공통 관리를 지원하는 내장 데이터 보호 기능을 제공합니다.</block>
  <block id="892dd840b39835d7da795bbd29f99987" category="list-text">NVE(NetApp 볼륨 암호화). ONTAP는 온보드 및 외부 키 관리를 모두 지원하는 기본 볼륨 레벨 암호화를 제공합니다.</block>
  <block id="1f17e94c6f48114ff29ad3267277420c" category="list-text">멀티테넌시 및 다단계 인증. ONTAP를 사용하면 인프라 리소스를 최고 수준의 보안으로 공유할 수 있습니다.</block>
  <block id="836ed833c0dea3b588f04d16ca3f850d" category="paragraph">ONTAP은 다음과 같은 기능을 통해 끊임없이 변화하는 까다로운 비즈니스 요구사항을 충족할 수 있도록 지원합니다.</block>
  <block id="b816bfff9511bcd88a9aa06fe0fd6389" category="list-text">원활한 확장 및 무중단 운영: ONTAP은 운영 중단 없이 기존 컨트롤러 및 스케일아웃 클러스터에 용량을 추가할 수 있도록 지원합니다. 고객은 고비용이 따르는 데이터 마이그레이션이나 운영 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="74c384c0caae9c39b0e414cecc8c66ea" category="list-text">클라우드 연결: ONTAP은 클라우드에 가장 많이 연결된 스토리지 관리 소프트웨어로, 모든 퍼블릭 클라우드에서 ONTAP Select(소프트웨어 정의 스토리지) 및 NetApp Cloud Volumes Service(클라우드 네이티브 인스턴스)에 대한 옵션을 제공합니다.</block>
  <block id="2a7e7bc180cc3d059089e02f091bac27" category="list-text">새로운 애플리케이션과 통합: ONTAP은 기존 엔터프라이즈 앱을 지원하는 인프라와 동일한 인프라를 사용하여 자율주행 차량, 스마트 시티, Industry 4.0과 같은 차세대 플랫폼 및 애플리케이션을 위한 엔터프라이즈급 데이터 서비스를 제공합니다.</block>
  <block id="377c9a91b43c5423691b5ce75db91350" category="section-title">NetApp Astra Control</block>
  <block id="35b46e301702b6fcb16192f9f4cf4533" category="inline-link">Astra 제어 서비스</block>
  <block id="eb75cc706ac8cc6c0f4cb17f4fb073dd" category="paragraph">NetApp Astra 제품군은 온프레미스 및 퍼블릭 클라우드에서 Kubernetes 애플리케이션을 위한 스토리지 및 애플리케이션 인식 데이터 관리 서비스를 제공하며, NetApp 스토리지 및 데이터 관리 기술을 기반으로 합니다. Kubernetes 애플리케이션을 쉽게 백업하고, 데이터를 다른 클러스터로 마이그레이션하고, 작업 중인 애플리케이션 클론을 즉시 생성할 수 있습니다. 퍼블릭 클라우드에서 실행 중인 Kubernetes 애플리케이션을 관리해야 하는 경우에는 의 문서를 참조하십시오<block ref="6d442ad773e9d31651277931acd1583a" category="inline-link-rx"></block>. Astra Control Service는 GKE(Google Kubernetes Engine) 및 AKS(Azure Kubernetes Service)에서 Kubernetes 클러스터의 애플리케이션 인식 데이터 관리를 제공하는 NetApp 관리 서비스입니다.</block>
  <block id="545b3003eeeed3a05db492712188eaa8" category="paragraph">아스트라<block ref="b792e70a7bbe82fe69049fd18abe3c18" category="inline-link-rx"></block> NetApp은 Docker 및 Kubernetes용 오픈 소스 동적 스토리지 오케스트레이터로서 영구 스토리지의 생성, 관리 및 사용을 단순화합니다. Kubernetes 네이티브 애플리케이션인 Trident는 Kubernetes 클러스터 내에서 직접 실행됩니다. Trident를 사용하면 고객이 DL 컨테이너 이미지를 NetApp 스토리지에 원활하게 배포하고 AI 컨테이너 배포를 위한 엔터프라이즈급 경험을 제공할 수 있습니다. Kubernetes 사용자(ML 개발자, 데이터 과학자 등)는 오케스트레이션 및 클론 복제를 생성, 관리 및 자동화하여 NetApp 기술이 제공하는 고급 데이터 관리 기능을 활용할 수 있습니다.</block>
  <block id="434636f83b39076d7f319707cddbd844" category="paragraph"><block ref="f0ec1a9d50acb3759e364a1cdfa9961d" category="inline-link-rx"></block> 는 빠르고 안전한 데이터 동기화를 제공하는 NetApp 서비스입니다. 온프레미스 NFS 또는 SMB 파일 공유, NetApp StorageGRID, NetApp ONTAP S3, NetApp Cloud Volumes Service, Azure NetApp Files, Amazon S3(Amazon Simple Storage Service), Amazon Elastic File System(Amazon EFS), Azure Blob, Google Cloud Storage 간에 파일을 전송해야 하는 경우 또는 IBM 클라우드 오브젝트 스토리지인 Cloud Sync를 사용하면 파일을 필요한 곳으로 빠르고 안전하게 이동할 수 있습니다. 데이터가 전송되면 소스와 타겟 모두에서 사용할 수 있습니다. Cloud Sync는 미리 정의된 일정에 따라 데이터를 지속적으로 동기화하여 추가된 부분만 이동하여 데이터 복제에 소비되는 시간과 비용을 최소화합니다. Cloud Sync는 매우 간편한 설정 및 사용이 가능한 SaaS(Software-as-a-Service) 툴입니다. Cloud Sync에 의해 트리거되는 데이터 전송은 데이터 브로커가 수행합니다. AWS, Azure, Google Cloud Platform 또는 온프레미스에서 Cloud Sync 데이터 브로커를 구축할 수 있습니다.</block>
  <block id="66b5cd4a3c9ce410ceb216447176b92c" category="section-title">NetApp 클라우드 데이터 감지</block>
  <block id="37b37a18c5e4fe4e0985503adba1ee06" category="paragraph">강력한 AI 알고리즘을 기반으로 <block ref="41205542004b3a03df744ae454bd65c9" category="inline-link-rx"></block> 전체 데이터 자산에 걸쳐 자동화된 제어 및 데이터 거버넌스를 제공합니다. 비용 절감 효과를 쉽게 파악하고 규정 준수 및 개인 정보 보호에 대한 우려 사항을 파악하며 최적화 기회를 찾을 수 있습니다. Cloud Data Sense 대시보드에서는 중복 데이터를 식별할 수 있는 통찰력을 제공하여 중복 데이터를 제거하고 개인, 개인 및 개인 정보가 아닌 중요 데이터를 매핑하며 중요한 데이터와 이상 상태에 대한 알림을 설정할 수 있습니다.</block>
  <block id="b391770315ecce50e9dae3b6506d3513" category="inline-link-macro">다음: 테스트 및 검증 계획.</block>
  <block id="d063081c0d1c6aff0b7c690b473d4045" category="paragraph"><block ref="d063081c0d1c6aff0b7c690b473d4045" category="inline-link-macro-rx"></block></block>
  <block id="fb0e25ed6b061ae8d5a55a94457e445e" category="summary">이 검증을 위해 Protopia 난독 처리를 1920 x 1080 픽셀 이미지에 5회 적용하고 난독 처리 단계가 매번 완료되는 데 걸리는 시간을 측정했습니다.</block>
  <block id="9c6852dd5556b48ff70dd2583a5d3aa0" category="doc">난독화 속도</block>
  <block id="237d31dab91fe077925e5102e132072f" category="inline-link-macro">이전: 추론 정확도 비교.</block>
  <block id="6e3fd8b18c15e04e41fb57acfcafc5aa" category="paragraph"><block ref="6e3fd8b18c15e04e41fb57acfcafc5aa" category="inline-link-macro-rx"></block></block>
  <block id="d6edf1cfcac22abc6c577706f85eb816" category="paragraph">이 검증을 위해 Protopia 난독 처리를 1920 x 1080 픽셀 이미지에 5회 적용하고 난독 처리 단계가 매번 완료되는 데 걸리는 시간을 측정했습니다. 난독 처리를 적용하기 위해 단일 NVIDIA V100 GPU에서 실행되는 PyTorch를 사용했고 실행 간에 GPU 캐시를 지웠습니다. 난독화 단계는 5회 실행에서 각각 5.47ms, 5.27ms, 4.54ms, 5.24ms, 4.84ms를 완료하는 데 각각 걸렸습니다. 평균 속도는 5.072ms였습니다.</block>
  <block id="eee25724989c730f34a19e19a1db23b2" category="paragraph"><block ref="eee25724989c730f34a19e19a1db23b2" category="inline-link-macro-rx"></block></block>
  <block id="6d01d0026564c98aa0d6274cd39c586a" category="summary">이 문서에서는 개인 정보 보호 유지 및 책임 있는 AI 솔루션 배포와 관련된 이미지 난독 처리를 사용하는 경우와 사용하지 않는 세 가지 시나리오에서 검증된 설계 솔루션에 대해 설명합니다.</block>
  <block id="0bbb7f0a0d464779fc0832c366f3a4e7" category="paragraph">사티아가라잔, 마이클 오글즈비야, NetApp 병훈 안, 제니퍼 와겐버그, 프로토피아</block>
  <block id="c110f3156d66710a207ebd7135164ec1" category="paragraph">시각적 해석은 이미지 캡처와 이미지 처리의 등장과 함께 커뮤니케이션의 핵심 요소가 되었습니다. 디지털 이미지 처리의 인공 지능(AI)은 암 및 기타 질병 식별을 위한 의료 분야, 환경 위험 연구, 패턴 인식, 범죄 퇴치를 위한 비디오 처리 등을 위한 지리공간 시각적 분석 등 새로운 비즈니스 기회를 제공합니다. 그러나 이 기회에는 특별한 책임이 있습니다.</block>
  <block id="0159205b6d54375adfabd56a2258fcb9" category="paragraph">AI에 대한 조직의 의사 결정이 내려질수록 데이터에 대한 개인 정보 보호, 보안, 법률, 윤리 및 규제 문제와 관련된 위험에 노출될 위험은 커집니다. 책임감 있는 AI를 통해 기업과 정부 조직이 대규모 기업에서 AI에 중요한 신뢰 및 거버넌스 구축을 지원할 수 있습니다. 이 문서에서는 Protopia 데이터 난독 처리 소프트웨어와 함께 NetApp 데이터 관리 기술을 사용하여 중요한 데이터를 민화하고 위험과 윤리적 문제를 줄임으로써 NetApp에서 검증한 AI 추론 솔루션에 대해 설명합니다.</block>
  <block id="fade8b24490b0ba74a7ffa05d3f8631a" category="paragraph">소비자와 기업 모두 다양한 디지털 장치를 사용하여 매일 수백만 개의 이미지가 생성됩니다. 결과적으로 데이터가 폭발적으로 증가하고 컴퓨팅 작업 부하가 발생함에 따라 기업은 규모와 효율성을 위해 클라우드 컴퓨팅 플랫폼으로 전환하게 됩니다. 한편, 이미지 데이터에 포함된 민감한 정보에 대한 개인 정보 보호는 퍼블릭 클라우드로 이전될 때 발생합니다. 보안 및 개인 정보 보호 보장이 없기 때문에 이미지 처리 AI 시스템을 배포하는 데 주요 장애물이 되고 있습니다.</block>
  <block id="e9ac7ec9dd27fe52477986ab1dccbcae" category="inline-link">삭제권</block>
  <block id="49dca35d3e0662046425327194fd8965" category="inline-link">개인정보보호법</block>
  <block id="f615b294f87bd53494e01691ab95c654" category="paragraph">또한 이 있습니다<block ref="ac9ac606204db63758cb1efd6e89e43e" category="inline-link-rx"></block> GDPR에 따라, 조직에서 모든 개인 데이터를 삭제하도록 요청할 수 있는 개인의 권리. 또한 도 있습니다<block ref="fd57f794f9c27951b4a5b543db96bdb6" category="inline-link-rx"></block>이것은 공정 정보 관리 코드를 설정합니다. 사진과 같은 디지털 이미지는 데이터를 수집, 처리 및 지우는 방법을 제어하는 GDPR의 개인 데이터를 구성할 수 있습니다. 그렇지 않으면 GDPR을 준수하지 않아 조직에 심각한 피해를 줄 수 있는 규정 준수 위반에 대한 무거운 벌금이 부과될 수 있습니다. 개인 정보 보호 원칙은 머신 러닝(ML) 및 딥 러닝(DL) 모델 예측의 공정성을 보장하고 개인 정보 보호 또는 규정 준수 위반과 관련된 위험을 줄이는 책임 있는 AI 구현의 근간입니다.</block>
  <block id="d365f4ef3ed2b414236f81df850880a3" category="paragraph">이 문서에서는 개인 정보 보호 유지 및 책임 있는 AI 솔루션 배포와 관련된 이미지 난독 처리를 사용하는 경우와 사용하지 않는 세 가지 시나리오에서 검증된 설계 솔루션을 설명합니다.</block>
  <block id="bd12a6b0ed0be7808c1e30b1e360bee6" category="list-text">* 시나리오 1. * Jupyter 노트북 내 필요 시 추론.</block>
  <block id="bf93b5af78256f2e49d2c0351133b08d" category="list-text">* 시나리오 2. * Kubernetes의 배치 추론</block>
  <block id="d5a10e810e1d293a064388e4980bde15" category="list-text">* 시나리오 3. * NVIDIA Triton 추론 서버</block>
  <block id="870f1cf4b101c66b438e8dd024f24118" category="paragraph">이 솔루션에서는 FDDB(얼굴 인식 데이터 세트 및 벤치마크)를 사용합니다. FDDB는 페이스 보스의 구현을 위한 PyTorch 기계 학습 프레임워크와 함께, 구속되지 않은 얼굴 감지 문제를 연구하도록 설계된 얼굴 영역 데이터 세트입니다. 이 데이터 세트에는 다양한 해상도의 2845 이미지 세트에 있는 5171면에 대한 주석이 포함되어 있습니다. 또한 이 기술 보고서에서는 이 솔루션이 적용 가능한 상황에 대해 NetApp 고객 및 현장 엔지니어를 통해 수집된 일부 솔루션 영역 및 관련 사용 사례를 소개합니다.</block>
  <block id="e28a169eb64ee1d32c878a26595922f0" category="paragraph">이 기술 보고서는 다음 대상자를 대상으로 합니다.</block>
  <block id="167e9693dfa764051f26b64ec22356a9" category="list-text">책임 있는 AI를 설계 및 구축하고 공공 장소에서의 얼굴 이미지 처리와 관련된 데이터 보호 및 개인 정보 문제를 처리하고자 하는 비즈니스 리더 및 엔터프라이즈 설계자</block>
  <block id="304e871b0b1ea55fe3e4f07ead7a7d42" category="list-text">개인 정보를 보호하고 유지하고자 하는 데이터 과학자, 데이터 엔지니어, AI/기계 학습(ML) 연구자 및 AI/ML 시스템 개발자.</block>
  <block id="dcf26996b3ab9f385a95f72c1d0a0dce" category="list-text">GDPR, CCPA 또는 국방부(DoD) 및 정부 조직의 개인정보 보호법과 같은 규정 표준을 준수하는 AI/ML 모델 및 애플리케이션에 대한 데이터 난독 처리 솔루션을 설계하는 엔터프라이즈 설계자</block>
  <block id="bb6887ed7c7b07cbb7bd3ec71f951e6f" category="list-text">중요한 정보를 보호하는 딥 러닝(DL) 및 AI/ML/DL 추론 모델을 효율적으로 구축하는 방법을 찾고 있는 데이터 과학자 및 AI 엔지니어</block>
  <block id="69adf8f52a6229e7062bda4b2b9679fb" category="paragraph">이 솔루션은 GPU의 처리 성능과 기존 CPU를 함께 사용하여 대규모 데이터 세트에서 AI 워크로드를 실시간으로 일괄 처리하고 추론하도록 설계되었습니다. 이 검증에서는 책임 있는 AI 배포를 원하는 조직에 필요한 ML에 대한 개인 정보 보호 추론과 최적의 데이터 관리를 보여줍니다. 이 솔루션은 Jupyter Lab 및 CLI 인터페이스를 사용하여 코어 사내 NetApp ONTAP AI와 상호 연결된 에지 및 클라우드 컴퓨팅을 위한 단일 또는 다중 노드 Kubernetes 플랫폼, NetApp DataOps 툴킷, Protopia 난독화 소프트웨어에 적합한 아키텍처를 제공합니다. 다음 그림에서는 DataOps Toolkit 및 Protopia를 지원하는 NetApp 기반의 Data Fabric에 대한 논리적 아키텍처 개요를 보여 줍니다.</block>
  <block id="950724ad73ee22fd3b76ae9570281f64" category="paragraph"><block ref="950724ad73ee22fd3b76ae9570281f64" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7dfea85fd355e4966805c3504348aa8b" category="paragraph">Protopia 난독 처리 소프트웨어는 NetApp DataOps Toolkit에서 원활하게 실행되며 스토리지 서버를 떠나기 전에 데이터를 변환합니다.</block>
  <block id="3d68457cd44385c7acbd55eeda70e8f8" category="inline-link-macro">다음: 솔루션 영역.</block>
  <block id="55da59d3fe9630935dbd4fc25d52b939" category="paragraph"><block ref="55da59d3fe9630935dbd4fc25d52b939" category="inline-link-macro-rx"></block></block>
  <block id="c94ba9961c97321b49a2f0af40a3c81b" category="sidebar">책임 AI 및 기밀 추론 - NetApp AI 및 Protopia 이미지 변환</block>
  <block id="2ffe7358ce461fb4d630742ed966cf0b" category="example-title">VMware vSphere용 NetApp ONTAP 툴</block>
  <block id="e78afc9f7bd61b3284539108287c91ca" category="example-title">NetApp ONTAP용 AWS FSx가 있는 AWS 기반 VMware Cloud</block>
  <block id="f83bc0ebbeff6798c7394f8638db2695" category="example-title">VMware용 ONTAP 툴 - 개요</block>
  <block id="f1d501df2ff1e67b18b06eedd1bad6e8" category="example-title">ONTAP를 사용한 VMware iSCSI 데이터 저장소 용량 할당</block>
  <block id="a5e8a94cc8a28008eb4e2e719f658780" category="example-title">ONTAP를 사용한 VMware NFS 데이터 저장소 용량 할당</block>
  <block id="d69c8ea377286ab60d47066fa2946919" category="example-title">iSCSI를 사용하는 FSx ONTAP가 있는 Windows 게스트 연결 스토리지</block>
  <block id="113249c2329945af0bbbc9830088e9ea" category="example-title">NFS를 사용하는 FSx ONTAP가 있는 Linux 게스트 연결 스토리지</block>
  <block id="05799bad32c5bd80547efe4144fb57af" category="example-title">VMware vSphere용 SnapCenter 플러그인 - 솔루션 전제 조건</block>
  <block id="47d7646bd1c6577d907ac316431ae609" category="example-title">VMware vSphere용 SnapCenter 플러그인 - 구축</block>
  <block id="11d13047d237d5bccdd941bafda45d9d" category="example-title">VMware vSphere용 SnapCenter 플러그인 - 백업 워크플로우</block>
  <block id="16bbc152851c33a02fcac2fbf943ffee" category="example-title">VMware vSphere용 SnapCenter 플러그인 - 복구 워크플로우</block>
  <block id="305f1daa74a8ec01eaf0ce2c9a8ce355" category="example-title">SnapCenter - SQL 복원 워크플로</block>
  <block id="891220762a1a15ebfba11cf98afb3729" category="cell">2022년 6월 7일</block>
  <block id="e19e98a669ae21f94ffd1659998fd072" category="cell">데이터 분석</block>
  <block id="c32698794f1279b1f46bacea38a72264" category="cell">Splunk Enterprise 솔루션을 사용하는 NetApp EF600에 대한 링크가 추가되었습니다</block>
  <block id="32e9989956756ffe28b84c0dab24eb03" category="cell">2022년 6월 2일</block>
  <block id="9ceed07936bb73f756027dc20e7869e5" category="open-title">미주</block>
  <block id="a58c228b4723aee54800749a595ee3d1" category="cell">* AWS 지역 *</block>
  <block id="0ea8853bd99df0275ce197d81b4acdf3" category="cell">* VMC 가용성 *</block>
  <block id="da5de74c1914c54c36141e9bbc0bfb2c" category="cell">* FSx ONTAP 가용성 *</block>
  <block id="db1904255fd919e193388d9dfc4066ae" category="cell">* NFS 데이터 저장소 가용성 *</block>
  <block id="34f9a39dcbb737fbdd35cfb9214308b5" category="cell">미국 동부(노던 버지니아)</block>
  <block id="227b0fc1350a24236051cdda52db89ae" category="cell">미국 동부(오하이오)</block>
  <block id="578ab1f7b2f00d70184a6fd055855a32" category="cell">미국 서부(캘리포니아 북부)</block>
  <block id="2826ad747baf050dc2cfb69d5171f78f" category="cell">미국 서부(오리건주)</block>
  <block id="1978cc170637ba3fa169853b7c5b2791" category="cell">GovCloud(미국 서부)</block>
  <block id="86378e5a26945a10df6434e3cebc709b" category="cell">캐나다(중부)</block>
  <block id="1289483fccf49359b30e09d42f550943" category="cell">남아메리카(상파울루)</block>
  <block id="dbb56fbaa43a12cf5dc69fde5096e785" category="paragraph">마지막 업데이트: 2022년 6월 2일.</block>
  <block id="0f1c6d45b761226679e0927cc47d24d3" category="open-title">유럽</block>
  <block id="8c0594d8d8e156a108f31e22903e4349" category="cell">유럽(아일랜드)</block>
  <block id="05f6cd9d18df6f52665dab10eda2ebe1" category="cell">유럽(런던)</block>
  <block id="5efd079b952b87c886a8a02de8dd5d83" category="cell">유럽(프랑크푸르트)</block>
  <block id="5be61c2e880e77ca057a65a4ff532d45" category="cell">유럽(파리)</block>
  <block id="ecb3d21f3ca319a515169d4aafe9ed99" category="cell">유럽(밀라노)</block>
  <block id="529f3fee69162e06098d8924e8084ca6" category="cell">유럽(스톡홀름)</block>
  <block id="2ebc1f6a39f03ec89f2b4bfdaf802f4c" category="open-title">아시아 태평양</block>
  <block id="4c2aaaa08c4d6f6e7e5af0e5fecf29df" category="cell">아시아 태평양(시드니)</block>
  <block id="60b549aa334760e9f2bd47c8296afb7b" category="cell">아시아 태평양(도쿄)</block>
  <block id="dfbd3a51c0e9a689817234013c0d51ee" category="cell">아시아 태평양(오사카)</block>
  <block id="c8d7db357b2344e3ebeab70a1e63c6c9" category="cell">아시아 태평양(싱가포르)</block>
  <block id="5294ca76dd36c8368fcafd7e951115ef" category="cell">아시아 태평양(서울)</block>
  <block id="78c8c0f60d4851b109cbd33284f812ca" category="cell">아시아 태평양(뭄바이)</block>
  <block id="82f98bf67698e189fc9d846325345bbd" category="cell">아시아 태평양(자카르타)</block>
  <block id="1b15cf1d695d130132edd42a701b41a1" category="cell">아시아 태평양(홍콩)</block>
  <block id="3b041c1182ede15a52a683344c9512e0" category="section-title">AWS 지역 가용성</block>
  <block id="c5fde59b3560ee1ea5aeeebaf94bdf39" category="section-title">Azure 지역 가용성</block>
  <block id="844f1178f4ff7b95030ee50d8917da61" category="sidebar">NFS 데이터 저장소에 대한 지역 지원</block>
  <block id="15b1cf33f2d910f9ab5e6fdaeb331bcc" category="sidebar">AWS에서 NFS 데이터 저장소에 대한 지역 지원</block>
  <block id="81a6037600add9bb79d72eb49534ff94" category="sidebar">Azure에서 NFS 데이터 저장소에 대한 지역 지원</block>
  <block id="1da3fb2408fde551ca108534afed1987" category="sidebar">Splunk Enterprise 기반의 NetApp EF600</block>
  <block id="419f5ca56c881443509bda0a14523c9c" category="cell">공개 미리 보기 공지/지원과 일치하도록 AVS 지역 지원이 업데이트되었습니다</block>
  <block id="40640c0c34d4427f5d18b9ca476e3158" category="summary">이 페이지에서는 NetApp ONTAP 스토리지에서 Oracle19c의 자동화된 데이터 보호에 대해 설명합니다.</block>
  <block id="19c95c19bd7c939577775cd0ecce3df1" category="section-title">의료 및 생의학 연구</block>
  <block id="a047c61461aba5a84a0a221900c33984" category="paragraph">영상 처리는 컴퓨터 단층촬영(CT) 또는 자기공명영상(MRI)에서 얻은 3D 영상에서 외과적 계획을 위한 병리를 진단하는 데 사용됩니다. HIPAA 개인 정보 보호 규칙은 모든 개인 정보 및 사진과 같은 디지털 이미지에 대해 조직에서 데이터를 수집, 처리 및 지우는 방법을 규정합니다. HIPAA 세이프 하버 규정에 따라 데이터를 공유할 수 있는 자격을 갖추려면 전체 사진 이미지와 비교 이미지를 제거해야 합니다. 구조적 CT/MR 영상에서 개인의 얼굴 특징을 모호하게 하는 데 사용되는 식별 해제 또는 두개골 스트리핑 알고리즘과 같은 자동화 기술은 생물 의학 연구 기관의 데이터 공유 프로세스에서 필수적인 부분이 되었습니다.</block>
  <block id="2c5c3872e94de8a36eac45213c5bf2e6" category="paragraph">엔터프라이즈 고객은 전통적으로 AI/ML 모델을 온프레미스에 교육 및 배포했습니다. 규모의 경제 및 효율성 측면에서 이러한 고객은 AI/ML 기능을 퍼블릭, 하이브리드 또는 멀티 클라우드 클라우드 구현 환경으로 이전하기 위해 확장하고 있습니다. 그러나 다른 인프라에 노출될 수 있는 데이터에 바인딩됩니다. NetApp 솔루션은 에 필요한 모든 범위의 사이버 보안 위협을 해결합니다<block ref="9da3a9a08c9461b229d33f221e8caa37" category="inline-link-rx"></block> 또한, 보안 평가 및 프로토피아 데이터 변환과 결합하면 이미지 처리 AI/ML 워크로드를 클라우드로 마이그레이션하는 데 따른 위험을 최소화할 수 있습니다.</block>
  <block id="236e54165aafef697c2c82c667e05d36" category="doc">TR-4928: AI 및 기밀 추론 지원 - NetApp AI 및 Protopia 이미지 및 데이터 변환</block>
  <block id="5b8a88d59edea26637f628caefd05974" category="list-text">Kubernetes 작업 클러스터가 이미 있으며, Trident에서 지원하는 Kubernetes 버전을 실행 중입니다. 지원되는 버전 목록은 를 참조하십시오<block ref="77881c904b113f84b0f08c355b95174f" category="inline-link-rx"></block>.</block>
  <block id="b81146e6af95bf6e22cf57459890216f" category="inline-link">백엔드</block>
  <block id="f652904c3bfb48fb25a0a75f485f0ff6" category="inline-link">StorageClaes를 참조하십시오</block>
  <block id="05543563edfd7ed0348edd3b47280705" category="list-text">NVIDIA DeepOps를 사용하여 Kubernetes 클러스터를 배포하지 않았거나 Trident를 수동으로 배포하려는 경우 에 따라 Trident를 배포할 수 있습니다<block ref="e119dd171387190517d77417752a581c" category="inline-link-rx"></block> Trident 문서 구성 방법에 대한 자세한 내용은 Trident 백엔드와 하나 이상의 Kubernetes StorageClass를 생성해야 합니다<block ref="9e44c6ae604c64be7a70b0384fa1cccd" category="inline-link-rx"></block> 및<block ref="336146b6899186b663ba5a7b38e8c39b" category="inline-link-rx"></block> NetApp Docs에서 연결된 하위 섹션을 참조하십시오.</block>
  <block id="36522cc6d4eb67d30ef19d321901fa6e" category="cell">2022년 6월 16일</block>
  <block id="e1ea84e227dd99913363ade155774bcf" category="cell">NetApp 설계 가이드를 통해 NVIDIA DGX SuperPOD 추가</block>
  <block id="1edbb6849585c57ecbf402c0706ecf2d" category="sidebar">NetApp을 포함한 NVIDIA DGX SuperPOD(설계 가이드)</block>
  <block id="e340bc103d02ce2b8e016eb60705029c" category="sidebar">SAP 및 SAP HANA</block>
  <block id="f1fc5bef6accc6d1fab4ab73142df7f3" category="list-text">Ansible 플레이북을 사용하여 Astra Control Center를 배포하려면 Ansible이 설치된 Ubuntu/RHEL 시스템이 필요합니다. 다음 절차를 따르십시오<block ref="3c36e2d6ece22f6d90a18a4cf2722cef" category="inline-link-rx"></block> Ubuntu 및 절차의 경우<block ref="94346839427703f278bfb2bc5962a814" category="inline-link-rx"></block> RHEL의 경우</block>
  <block id="703fd9e283392bf196948a4c2ed72680" category="list-text">NetApp Support 사이트에 로그인하여 NetApp Astra Control Center의 최신 버전을 다운로드하십시오. 그렇게 하려면 NetApp 계정에 연결된 라이센스가 필요합니다. 타볼을 다운로드한 후 워크스테이션으로 전송합니다.</block>
  <block id="42042ccfc3ffee97e94beca237148ed4" category="list-text">Astra Control Center가 설치될 OpenShift 클러스터에 대한 관리자 액세스 권한이 있는 kubecononfig 파일을 만들거나 얻습니다.</block>
  <block id="aff7b433e7f33e585c67f69803192117" category="list-text">VAR/VAR.yml 파일을 편집하여 필요한 정보로 변수를 입력합니다.</block>
  <block id="b4ca5df207a7b1e22a2f19cac43dd6ad" category="paragraph">사용자에게 암호 기반 sudo 액세스가 구성된 경우 다음 명령을 실행하여 플레이북을 실행한 다음 sudo 암호를 입력합니다.</block>
  <block id="f04c9d184475a1c831571242df5998ca" category="paragraph">Astra Control Center의 유료 버전 외에 90일 평가판 라이센스도 제공됩니다. 평가판 버전은 이메일과 Community Slack 채널을 통해 지원됩니다. 고객은 제품 내 지원 대시보드에서 이러한 리소스, 기타 기술 자료 문서 및 문서를 사용할 수 있습니다.</block>
  <block id="9c38b2d834f16a22a033cc493828d911" category="paragraph">NetApp Cloud Volumes ONTAP는 클라우드 구축 버전의 NetApp ONTAP로, Amazon AWS, Microsoft Azure, Google Cloud를 비롯한 다양한 퍼블릭 클라우드에 구축할 수 있습니다.</block>
  <block id="c48c25afacd7dddac49ab104ad056df0" category="paragraph">Astra Trident는 컨테이너 및 Kubernetes 배포용 {k8s_distribution_name}의 완전 지원되는 오픈 소스 스토리지 오케스트레이터입니다. Trident는 NetApp ONTAP 및 Element 스토리지 시스템을 포함한 전체 NetApp 스토리지 포트폴리오와 연동되며 NFS 및 iSCSI 연결도 지원합니다. Trident는 최종 사용자가 스토리지 관리자의 개입 없이 NetApp 스토리지 시스템에서 스토리지를 프로비저닝 및 관리할 수 있도록 하여 DevOps 워크플로우를 가속합니다.</block>
  <block id="7654a00ca744e9bf01021439190e3119" category="doc">VMware Tanzu Kubernetes Grid Integrated Edition(TKGI) 개요</block>
  <block id="644bd75ee9c13f7d8778e4638d9eb2b2" category="paragraph">VMware Tanzu Kubernetes Grid Integrated(TKGI) Edition, 이전의 VMware Enterprise PKS는 수명 주기 관리, 클러스터 상태 모니터링, 고급 네트워킹, 컨테이너 레지스트리 등의 기능을 갖춘 Kubernetes 기반의 독립형 컨테이너 오케스트레이션 플랫폼입니다. TKGI는 Bosh 및 Ops Manager로 구성된 TKGI 제어 플레인을 통해 Kubernetes 클러스터를 프로비저닝하고 관리합니다.</block>
  <block id="a84b33dfae5a2fdc1618084442bc3df0" category="paragraph">TKGI는 해당 IaaS 제품의 온프레미스 또는 주요 퍼블릭 클라우드 중 하나에서 vSphere 또는 OpenStack 환경에 설치 및 운영할 수 있습니다. 또한 TKGI를 NSX-T 및 Harbor와 통합하면 엔터프라이즈 워크로드를 더 폭넓게 사용할 수 있습니다. TKGI 및 그 기능에 대한 자세한 내용은 설명서를 참조하십시오 <block ref="0b1e387b87be5caa8371b58b8e02b1f8" category="inline-link-macro-rx"></block>.</block>
  <block id="26f1f37ed65557967fe3a789aa75c364" category="paragraph">TKGI는 다양한 사용 사례와 설계를 기반으로 다양한 플랫폼에 다양한 구성으로 설치됩니다. 가이드를 따릅니다 <block ref="54093918574a441541c9219fc9d087f1" category="inline-link-macro-rx"></block> TKGI 및 해당 사전 요구 사항을 설치 및 구성합니다. TKGI는 변경 불가능한 구성 이미지를 실행하는 Tanzu Kubernetes 클러스터의 노드로 Bosh VM을 사용하며, Bosh VM의 수동 변경은 재부팅 후에도 지속되지 않습니다.</block>
  <block id="58959a34911d9e88e191f3453ddc81f0" category="paragraph">중요 참고 사항:</block>
  <block id="d7fc6fcd5f3c3c3fca9edded9bf380e1" category="list-text">NetApp Trident에는 권한 있는 컨테이너 액세스가 필요합니다. 따라서 TKGI 설치 중에 Tanzu Kubernetes 클러스터 노드 계획을 구성하려면 단계에서 권한 있는 컨테이너 활성화 확인란을 선택해야 합니다.</block>
  <block id="651650f759262b05cb38b56003e55784" category="image-alt">TKGI의 특별 컨테이너</block>
  <block id="956d281862a0ec3c4bb386cd28bf959c" category="list-text">NetApp은 모든 운영 환경을 여러 마스터 구축 환경에 구축하여 내결함성을 제공하고 원하는 워크로드 요구사항을 충족하는 작업자 노드의 구성을 선택할 것을 권장합니다. 따라서 권장되는 TKGI 클러스터 계획은 높은 작업 부하를 처리하기 위해 최소 3명의 마스터와 최소 4개의 vCPU 및 12GB RAM을 갖춘 3명의 작업자로 구성됩니다.</block>
  <block id="74d32c3e98de18a4adf66bd3f05e6088" category="inline-link-macro">다음은 NetApp 스토리지 시스템 개요입니다.</block>
  <block id="86de08c652cda2ec18cd6f36a36cfcfa" category="paragraph"><block ref="86de08c652cda2ec18cd6f36a36cfcfa" category="inline-link-macro-rx"></block></block>
  <block id="71417a3dd01aa388d35bf54aa4c401fa" category="summary">이 페이지에는 이 문서에 설명된 일부 기능을 시연하는 비디오 링크가 포함되어 있습니다.</block>
  <block id="952be0b8dee874c73cd76a4d6a526b27" category="doc">비디오 및 데모: NetApp의 VMware Tanzu</block>
  <block id="811263b3dba6ff02a02f70eb9730ca2e" category="inline-link-macro">Astra Trident를 사용하여 VMware Tanzu에서 영구 스토리지를 프로비저닝합니다</block>
  <block id="6aa25c5e03abeab0ced9fac672bb2330" category="list-text"><block ref="6aa25c5e03abeab0ced9fac672bb2330" category="inline-link-macro-rx"></block></block>
  <block id="03a87e35f2de41c34385d72c2c717acf" category="inline-link-macro">Astra Control Center를 사용하여 VMware Tanzu에서 애플리케이션을 복제합니다</block>
  <block id="591774815c932f725e0adbded50b634b" category="list-text"><block ref="591774815c932f725e0adbded50b634b" category="inline-link-macro-rx"></block></block>
  <block id="bf6a387fea3d3444126eab19bcb4bbcd" category="inline-link-macro">다음: 추가 정보: NetApp의 VMware Tanzu</block>
  <block id="df2a7ac55fe19fad5a5006603cfd8662" category="paragraph"><block ref="df2a7ac55fe19fad5a5006603cfd8662" category="inline-link-macro-rx"></block></block>
  <block id="84053bd81ac19b225e107ad3b65ca58d" category="paragraph"><block ref="84053bd81ac19b225e107ad3b65ca58d" category="inline-link-macro-rx"></block></block>
  <block id="de15ad9e760a3587b2effb60a58133b1" category="summary">Astra Trident는 VMware Tanzu를 비롯한 컨테이너 및 Kubernetes 배포를 위한 오픈 소스 및 완벽하게 지원되는 스토리지 오케스트레이터입니다.</block>
  <block id="143c9ea21ac76ba425aa94411fbba07b" category="doc">Astra Trident 개요</block>
  <block id="ebe5598ec22d01fe25c02071b488309b" category="section-title">Helm을 사용하여 Trident 연산자를 배포합니다</block>
  <block id="a082551b03c5e35829be23792317ac16" category="list-text">NetApp Astra Trident Helm 저장소를 추가합니다.</block>
  <block id="836237f5ff429cb9283688cdfaa56c76" category="list-text">Helm 리포지토리를 업데이트합니다.</block>
  <block id="875c7439b686e253522033c63d909efe" category="list-text">Trident를 설치할 새 네임스페이스를 만듭니다.</block>
  <block id="82b1cf842f022e618212caef5d3c942d" category="list-text">DockerHub 자격 증명으로 암호를 만들어 Astra Trident 이미지를 다운로드합니다.</block>
  <block id="e5073fdda88ef7d6b18ac4f938abbece" category="list-text">관리 클러스터 구축이 포함된 TKGS(Tanzu가 설치된 vSphere) 또는 TKG에서 관리하는 사용자 또는 워크로드 클러스터의 경우 다음 절차에 따라 Astra Trident를 설치합니다.</block>
  <block id="d409e9c69dd2082fd0ed8a86d87258e8" category="list-text">로그인한 사용자에게 삼중임 네임스페이스에서 서비스 계정을 만들 수 있는 권한이 있는지, 삼중임 네임스페이스의 서비스 계정에 POD를 만들 수 있는 권한이 있는지 확인합니다.</block>
  <block id="397ae57f2a6cbd8444c419c896f19886" category="list-text">생성된 네임스페이스에 Trident 연산자를 설치하려면 아래 helm 명령을 실행합니다.</block>
  <block id="eef6352658410e2218bd7027ae8ff351" category="list-text">TKGI 배포가 관리하는 사용자 또는 워크로드 클러스터의 경우 다음 helm 명령을 실행하여 생성된 네임스페이스에 Trident 연산자를 설치합니다.</block>
  <block id="12d34565a0d56eff4f8d3f99b138e11a" category="list-text">Trident Pod가 가동되어 실행 중인지 확인합니다.</block>
  <block id="f48fa73c7f509e20ce14901e4639f13d" category="paragraph">Astra Trident Operator 설치를 완료한 후에는 사용 중인 특정 NetApp 스토리지 플랫폼에 대한 백엔드를 구성해야 합니다. Astra Trident의 설정 및 구성을 계속하려면 아래 링크를 따라가십시오.</block>
  <block id="c060cacb4d77409e1402a5dcab49bf8b" category="list-text"><block ref="c060cacb4d77409e1402a5dcab49bf8b" category="inline-link-macro-rx"></block></block>
  <block id="2280e7f4e3cc9a8caee65d058e1db860" category="list-text"><block ref="2280e7f4e3cc9a8caee65d058e1db860" category="inline-link-macro-rx"></block></block>
  <block id="fca47dd46473e4571bb1904fe2d5f3f5" category="inline-link-macro">다음: NetApp의 비디오 및 데모: VMware Tanzu</block>
  <block id="61a5a682a4430d961b9bc43c2f902e94" category="paragraph"><block ref="61a5a682a4430d961b9bc43c2f902e94" category="inline-link-macro-rx"></block></block>
  <block id="fa6f7af807ffa3ac6e2efb5c31463a4f" category="paragraph">NFS를 통해 NetApp ONTAP 스토리지 시스템과의 Trident 통합을 활성화하려면 스토리지 시스템과의 통신을 지원하는 백엔드를 생성해야 합니다. 이 솔루션에 기본 백엔드를 구성하지만, 보다 맞춤화된 옵션을 원할 경우 설명서를 참조하십시오 <block ref="f72d871ae286e7b7cf7d9ea12426661a" category="inline-link-macro-rx"></block>.</block>
  <block id="aaa6c6e969e6e978f9a8bce54e31b5f7" category="section-title">ONTAP에서 SVM을 생성합니다</block>
  <block id="b1c04b7e96694453a1307ecc81208ae5" category="list-text">ONTAP System Manager에 로그인하고 스토리지 &gt; 스토리지 VM으로 이동한 다음 추가를 클릭합니다.</block>
  <block id="f53bd08113ff367a9bcd470b70a036d8" category="list-text">SVM의 이름을 입력하고 NFS 프로토콜을 설정한 다음 Allow NFS Client Access 확인란을 선택하고, 워크로드 클러스터에서 볼륨을 PVS로 마운트하도록 허용하는 엑스포트 정책 규칙에 작업자 노드가 있는 서브넷을 추가합니다.</block>
  <block id="0cdb2a8f015b7a7d81ab5c3d73de88a5" category="image-alt">NFS를 사용하여 SVM 생성</block>
  <block id="e570ad3092406b5118fcd78a9374e048" category="admonition">NSX-T를 사용하여 NAT로 구축된 사용자 클러스터 또는 워크로드 클러스터를 사용하는 경우 송신 서브넷(TKGS0의 경우 또는 TKGI의 경우 부동 IP 서브넷)을 엑스포트 정책 규칙에 추가해야 합니다.</block>
  <block id="8f254daa71e82320e11e55258b095b00" category="list-text">데이터 LIF와 SVM 관리 계정에 대한 세부 정보를 제공한 다음 저장을 클릭합니다.</block>
  <block id="02ffb816541fbf18a204c877564fb92e" category="image-alt">SVM 데이터 LIF 및 SVM 관리</block>
  <block id="491df82049a4ac2d8b8b2fe6b773d65d" category="list-text">SVM에 애그리게이트를 할당합니다. Storage &gt; Storage VMs 로 이동하고 새로 생성된 SVM 옆에 있는 줄임표를 클릭한 다음 Edit 를 클릭합니다. Limit Volume Creation to Preferred Local Tiers 확인란을 선택하고 필요한 애그리게이트를 이 체크박스에 연결합니다.</block>
  <block id="85c5adc69f6da0ebb2ebf365c4211508" category="image-alt">SVM 애그리게이트 할당</block>
  <block id="95fdf7e31ffa1073f8c42359589c334e" category="list-text">Trident가 설치될 사용자 또는 워크로드 클러스터의 NAT가 구축된 경우 SNAT로 인해 비표준 포트에서 스토리지 마운트 요청이 도착할 수 있습니다. 기본적으로 ONTAP에서는 루트 포트에서 시작된 볼륨 마운트 요청만 허용합니다. 따라서 ONTAP CLI에 로그인하고 설정을 수정하여 비표준 포트의 마운트 요청을 허용합니다.</block>
  <block id="03c8ff4111bb9cfc032f786c9bd7c6e8" category="section-title">백엔드 및 StorageClasses를 생성합니다</block>
  <block id="e15177ebae9bfb9adab94a9ccf5f2e96" category="list-text">NFS를 지원하는 NetApp ONTAP 시스템의 경우 backendName, managementLIF, datLIF, svm, 사용자 이름을 사용하여 jumphost에 백엔드 구성 파일을 생성합니다. 암호 및 기타 세부 정보</block>
  <block id="c75cfbdcbbe9d48dc121fc816d4a2ccf" category="list-text">다음 명령을 실행하여 Trident 백엔드를 생성합니다.</block>
  <block id="ad2008cda12d454189828df19b2f9742" category="list-text">백엔드가 생성되면 다음 번에 스토리지 클래스를 생성해야 합니다. 다음 샘플 저장소 클래스 정의에서는 필수 및 기본 필드를 강조 표시합니다. 매개 변수 'backendType'은 새로 생성된 Trident 백엔드의 스토리지 드라이버를 반영해야 합니다.</block>
  <block id="0286d73690ed0ef54af06bd9175945cd" category="list-text">kubeck 명령을 실행하여 스토리지 클래스를 생성합니다.</block>
  <block id="8d8b689e86dbd34b31294b3f829db499" category="list-text">스토리지 클래스를 생성한 후 첫 번째 영구 볼륨 클레임(PVC)을 생성해야 합니다. 다음은 샘플 PVC 정의입니다. 'torageClassName' 필드가 방금 만든 스토리지 클래스의 이름과 일치하는지 확인합니다. 프로비저닝 워크로드에 따라 필요에 따라 PVC 정의를 추가로 사용자 지정할 수 있습니다.</block>
  <block id="c764ff1d25a2f9241afec7161127f74d" category="list-text">kubbeck 명령을 실행하여 PVC를 생성한다. 생성 중인 백업 볼륨의 크기에 따라 생성 시간이 다소 걸릴 수 있으므로 완료 시 프로세스를 확인할 수 있습니다.</block>
  <block id="5f87e8fbf603b28eb84592d8e64980c6" category="doc">추가 정보: NetApp의 VMware Tanzu</block>
  <block id="a6f4f5f0d313fa8894e4ad13a09339c0" category="list-text">VMware Tanzu 설명서</block>
  <block id="57a35ee57ca4eb666386f668ebc74599" category="inline-link"><block ref="57a35ee57ca4eb666386f668ebc74599" category="inline-link-rx"></block></block>
  <block id="35d5768f9d0ee829a3e2cae0cba15216" category="paragraph"><block ref="35d5768f9d0ee829a3e2cae0cba15216" category="inline-link-rx"></block></block>
  <block id="2839dd9e9e31ca41ba6399c0a64d3333" category="list-text">VMware Tanzu Kubernetes Grid 설명서</block>
  <block id="94ecd750f91f6d1908b92ec42eb37398" category="inline-link"><block ref="94ecd750f91f6d1908b92ec42eb37398" category="inline-link-rx"></block></block>
  <block id="f0a59887fc9e8ee88512ff6312c13efa" category="paragraph"><block ref="f0a59887fc9e8ee88512ff6312c13efa" category="inline-link-rx"></block></block>
  <block id="9cf21c31f745a435ac892addf1fd1a3f" category="list-text">VMware Tanzu Kubernetes Grid Service 설명서</block>
  <block id="98978b88e05533d45b79613d9ee6f26d" category="inline-link"><block ref="98978b88e05533d45b79613d9ee6f26d" category="inline-link-rx"></block></block>
  <block id="56c4cea9b33fd23cf082d00ca92d5a46" category="paragraph"><block ref="56c4cea9b33fd23cf082d00ca92d5a46" category="inline-link-rx"></block></block>
  <block id="c23715ed7437fed1084a24cebb89e63c" category="list-text">VMware Tanzu Kubernetes Grid Integrated Edition 설명서</block>
  <block id="fd2560680b89b39b1b988587bf383fb4" category="inline-link"><block ref="fd2560680b89b39b1b988587bf383fb4" category="inline-link-rx"></block></block>
  <block id="f4b2873e621660e86074a62e5a6c5eac" category="paragraph"><block ref="f4b2873e621660e86074a62e5a6c5eac" category="inline-link-rx"></block></block>
  <block id="3ff1ba174bc4d7824738ba1a0c0b4035" category="summary">NetApp Astra Control Center는 NetApp의 신뢰할 수 있는 데이터 보호 기술을 기반으로 사내 환경에 구축된 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공합니다.</block>
  <block id="678f429fd30f5d3718b72e260e17f5f0" category="paragraph">Astra Control REST API와 상호 작용하기 위해 미리 만들어진 소프트웨어 개발 툴킷을 찾고 있다면 NetApp에서 다운로드할 수 있는 Astra Control Python SDK와 함께 툴킷을 제공합니다 <block ref="ccffe56769527505ab07c82206690bfe" category="inline-link-macro-rx"></block>.</block>
  <block id="6b24baf9bd0e230b887612f836d0fbd5" category="paragraph">프로그래밍이 현재 상황에 맞지 않고 구성 관리 툴을 사용하려는 경우 NetApp에서 게시하는 Ansible 플레이북을 클론 복제 및 실행할 수 있습니다 <block ref="8c91b346fb645d82eb54fe01a7c0cd36" category="inline-link-macro-rx"></block>.</block>
  <block id="c90524de7ee251d8a5128ac3f59847c6" category="paragraph">Astra Control Center를 설치하려면 다음과 같은 필수 구성 요소가 필요합니다.</block>
  <block id="9f2559e9a5f31fdb3d5489aa3367ae35" category="list-text">관리 클러스터 또는 TKGS 또는 TKGI에서 관리하는 하나 이상의 Tanzu Kubernetes 클러스터 TKG 워크로드 클러스터 1.4+ 및 TKGI 사용자 클러스터 1.12.2+가 지원됩니다.</block>
  <block id="c94e1287a80d82c490967572d336083d" category="list-text">Astra Trident는 각 Tanzu Kubernetes 클러스터에 이미 설치 및 구성되어 있어야 합니다.</block>
  <block id="ba1c516a3e7a998469a5ac73695127ce" category="admonition">사이트에 각 Tanzu Kubernetes를 설치하여 영구 스토리지용 전용 SVM을 사용하는 것이 모범 사례입니다. 다중 사이트 배포에는 추가 스토리지 시스템이 필요합니다.</block>
  <block id="c756010e6a027d7d6ae199c033f4b1db" category="list-text">Trident 스토리지 백엔드는 ONTAP 클러스터에서 지원하는 SVM을 사용하여 각 Tanzu Kubernetes 클러스터에서 구성해야 합니다.</block>
  <block id="dd7ed1e31baf27a40282a08242cf6efc" category="list-text">스토리지 프로비저닝자로 Astra Trident가 있는 각 Tanzu Kubernetes 클러스터에 구성된 기본 StorageClass입니다.</block>
  <block id="e8ed7f9c94a716f73364706e6db9c1c6" category="list-text">로드 밸런싱을 위해 각 Tanzu Kubernetes 클러스터에 로드 밸런싱 장치를 설치하고 구성해야 하며, 이때 ingressType 'AccTraefik'를 사용하는 경우 Astra Control Center가 표시됩니다.</block>
  <block id="6b769b6cd8bf0a312e04e05973e13018" category="list-text">ingressType "Generic"을 사용하는 경우 Astra Control Center를 노출하기 위해 각 Tanzu Kubernetes 클러스터에 수신 컨트롤러를 설치하고 구성해야 합니다.</block>
  <block id="0e6886020b4adf5871ebc7346b63c3a0" category="list-text">Astra Control Center가 설치되어 있는 Tanzu Kubernetes 클러스터에 대한 클러스터 관리자 액세스 권한이 있어야 합니다.</block>
  <block id="8bd3433e327d75f3a3c33d9998840fce" category="list-text">RHEL 또는 Ubuntu 관리 워크스테이션.</block>
  <block id="ed060d0439d2eda03baa2005199d9bc1" category="paragraph">이 솔루션은 Ansible 플레이북을 사용하여 Astra Control Center를 설치하는 자동화된 절차를 설명합니다. Astra Control Center를 설치하기 위한 수동 절차를 찾고 있는 경우 자세한 설치 및 작동 설명서를 따르십시오 <block ref="30c5ae998902105fcf03dc0b9654af4c" category="inline-link-macro-rx"></block>.</block>
  <block id="662609908ab8e0f372d83dea3511370b" category="inline-link">절차를 참조하십시오</block>
  <block id="8575c02ec176b0f64904bcbd79e81cba" category="list-text">Astra Control Center를 배포하는 Ansible 플레이북을 사용하려면 Ansible이 설치된 Ubuntu/RHEL 시스템이 있어야 합니다. 다음 단계를 따르십시오<block ref="c1972c5d94c51919767b49f6cefbf6ba" category="inline-link-rx"></block> Ubuntu 및 이에 대한<block ref="c4dab530b5bf152ded398881b8308451" category="inline-link-rx"></block> RHEL의 경우</block>
  <block id="df57d245f4173d8ac23df756917bb6ae" category="list-text">Astra Control Center가 설치될 사용자 또는 워크로드 Tanzu Kubernetes 클러스터에 대한 관리자 액세스 권한이 있는 kubecon무그림 파일을 만들거나 얻습니다.</block>
  <block id="b2d9440273952d4b05aed1b36c66494d" category="list-text">디렉터리를 na_Astra_control_suite로 변경합니다.</block>
  <block id="7489123185b81a6e11b42218fabb4c3b" category="list-text">VAR/VAR.yml 파일을 편집하여 필요한 정보로 변수를 입력합니다.</block>
  <block id="2b6b49be82749b9e141c2f0a23c8d11f" category="paragraph">Playbook을 실행하는 사용자가 root 이거나 암호 없는 sudo가 구성된 경우 다음 명령을 실행하여 플레이북을 실행합니다.</block>
  <block id="111dd0947a16442f317af649a2aac536" category="list-text">ingressType이 AccTraefik인 경우 traefik 서비스 로드 밸런싱 장치 IP를 가져옵니다.</block>
  <block id="25ce05402248633e67c7cbc234573b60" category="list-text">Astra Control Center를 사용하려면 모든 기능을 사용할 수 있는 라이센스가 필요합니다. 라이센스를 추가하려면 계정 &gt; 라이센스 로 이동하고 라이센스 추가 를 클릭한 다음 라이센스 파일을 업로드합니다.</block>
  <block id="bf3293f2603ff733102e45d1152bc0a1" category="admonition">NetApp Astra Control Center의 설치 또는 구성 관련 문제가 발생할 경우 알려진 문제에 대한 기술 자료를 이용할 수 있습니다<block ref="695f48b1d8b7348c0e2828947d24161e" category="inline-link-rx"></block>.</block>
  <block id="1e89038a8ae648db9dd4b203267abd3a" category="inline-link-macro">다음: Tanzu Kubernetes 클러스터를 등록하십시오.</block>
  <block id="c7f57c40ce02379584ec7748d9444ee0" category="paragraph"><block ref="c7f57c40ce02379584ec7748d9444ee0" category="inline-link-macro-rx"></block></block>
  <block id="318a4bce7f9fca07a60ed82408fbcd29" category="doc">TKG(VMware Tanzu Kubernetes Grid) 개요</block>
  <block id="11e5f8209ef45e9884518caf7b5bc68d" category="paragraph">TKG라고도 하는 VMware Tanzu Kubernetes Grid를 사용하면 하이브리드 클라우드 또는 퍼블릭 클라우드 환경에 Tanzu Kubernetes 클러스터를 구축할 수 있습니다. TKG는 Kubernetes 클러스터 자체인 관리 클러스터로 설치되며 Tanzu Kubernetes 클러스터를 구축하고 운영합니다. 이러한 Tanzu Kubernetes 클러스터는 실제 워크로드가 구축된 워크로드 Kubernetes 클러스터입니다.</block>
  <block id="9a67a32e17609515d2fc11383d1a7b59" category="paragraph">Tanzu Kubernetes Grid는 몇몇 유망한 업스트림 커뮤니티 프로젝트를 기반으로 구축되고 VMware에서 개발, 마케팅 및 지원하는 Kubernetes 플랫폼을 제공합니다. Kubernetes 배포 외에도 Tanzu Kubernetes Grid는 레지스트리, 로드 밸런싱, 인증 등과 같은 필수 운영 수준 서비스인 추가 기능을 제공합니다. 관리 클러스터를 사용하는 VMware TKG는 vSphere 6.7 환경에서 널리 사용되고 있으며, TKGS는 vSphere 7과 기본 통합 기능을 갖추고 있으므로 이를 지원하더라도 vSphere 7 환경에 구축하는 것은 권장되지 않습니다.</block>
  <block id="4e6c29e9760f3e53993a64a5f6c63aaa" category="image-alt">관리 클러스터가 포함된 VMware Tanzu Kubernetes Grid</block>
  <block id="ec30336a82729146050b0931adab64f2" category="paragraph">Tanzu Kubernetes Grid에 대한 자세한 내용은 설명서를 참조하십시오 <block ref="f4dbc56b610d9f5cd603e1a13bb6dedf" category="inline-link-macro-rx"></block>.</block>
  <block id="86fcbed2a7f5b8edced11b10bd1e4266" category="paragraph">Tanzu Kubernetes Grid가 vSphere 클러스터에 설치되어 있는지 클라우드 환경에 설치되어 있는지 여부에 따라 설치 가이드에 따라 Tanzu Kubernetes Grid를 준비하고 구축하십시오 <block ref="492c3fae38681e036fd18bedc1bf8ae5" category="inline-link-macro-rx"></block>.</block>
  <block id="c1f07986544fbf96897f8099577b0e72" category="paragraph">Tanzu Kubernetes Grid용 관리 클러스터를 설치한 후 설명서에 따라 필요에 따라 사용자 클러스터 또는 워크로드 클러스터를 구축합니다 <block ref="7d3f6d9f879d392af501006eacd0d221" category="inline-link-macro-rx"></block>. VMware TKG 관리 클러스터에서는 Tanzu Kubernetes 클러스터의 설치 및 운영을 위해 SSH 키를 제공해야 합니다. 이 키는 capv 사용자를 사용하여 클러스터 노드에 로그인하는 데 사용할 수 있습니다.</block>
  <block id="07f15dfb0f84a062c67184adcee67a8b" category="summary">이 참조 문서는 NetApp에서 검증된 다양한 데이터 센터 환경에서 Tanzu Kubernetes Grid(TKG), Tanzu Kubernetes Grid Service(TKGS) 또는 Tanzu Kubernetes Grid Integrated(TKGI) 방식으로 구축된 VMware Tanzu Kubernetes 솔루션의 다양한 배포 유효성 검사를 제공합니다.</block>
  <block id="bec8bc9f783c7d01005b7e64d1ad1785" category="doc">NVA-1166: NetApp을 사용하는 VMware Tanzu</block>
  <block id="c837e955d75d674feb57af7e68b3d74c" category="paragraph">이 참조 문서는 NetApp에서 검증된 다양한 데이터 센터 환경에서 Tanzu Kubernetes Grid(TKG), Tanzu Kubernetes Grid Service(TKGS) 또는 Tanzu Kubernetes Grid Integrated(TKGI) 방식으로 구축된 VMware Tanzu Kubernetes 솔루션의 다양한 배포 유효성 검사를 제공합니다. 또한 NetApp 스토리지 시스템과의 스토리지 통합 및 영구 스토리지를 위한 Astra Trident 스토리지 오케스트레이터와 해당 영구 스토리지를 사용하는 상태 저장 애플리케이션의 백업 및 복제를 위한 Astra Control Center에 대해 설명합니다. 마지막으로 솔루션 통합 및 검증에 대한 비디오 데모를 제공합니다.</block>
  <block id="c0a14f456cfcfac669f2cf374f60561b" category="paragraph">NetApp 솔루션을 사용하는 VMware Tanzu는 다음과 같은 사용 사례를 통해 고객에게 뛰어난 가치를 제공하도록 설계되었습니다.</block>
  <block id="8cc1d80dbdd5d6d142f0173d8c8f2261" category="list-text">VMware vSphere에 구축되어 NetApp 스토리지 시스템과 통합된 VMware Tanzu Kubernetes Grid 제품을 손쉽게 구축 및 관리할 수 있습니다.</block>
  <block id="8796988ff3c4f065733c3b887d886609" category="list-text">엔터프라이즈 컨테이너 및 가상화 워크로드를 VMware Tanzu Kubernetes Grid 오퍼링과 함께 사용할 수 있습니다.</block>
  <block id="d7071bc518e2fa9a30b1debdd8e721f1" category="list-text">NetApp 스토리지 및 NetApp Astra 제품군과 함께 사용할 경우 VMware Tanzu의 기능을 강조하는 실제 구성 및 사용 사례를 소개합니다.</block>
  <block id="3d4565b89cb9591acc32839ce0d48627" category="list-text">Astra Control Center를 사용하여 NetApp 스토리지 시스템에 데이터가 상주하는 VMware Tanzu Kubernetes Grid 클러스터에 구축된 컨테이너식 워크로드를 애플리케이션 정합성이 보장된 방식으로 보호 또는 마이그레이션할 수 있습니다.</block>
  <block id="29375f7cc2c5eece7fdd9c99f40eb3f8" category="list-text">사내 데이터 센터와 클라우드에서 실행 중인 컨테이너를 포함하는 하이브리드 클라우드 모델에 구축할 수 있는 역량</block>
  <block id="ddea0381617b5a4b43a0a98a440c6658" category="paragraph">NetApp의 VMware Tanzu는 이러한 과제를 인정하며 고객이 선택한 하이브리드 클라우드 환경에 VMware Tanzu Kubernetes 오퍼링을 구현하여 각 문제를 해결하는 솔루션을 제공합니다.</block>
  <block id="c57f369df48137f738543c0e5012006c" category="paragraph">NetApp 솔루션을 사용하는 VMware Tanzu는 다음과 같은 주요 구성요소로 이루어져 있습니다.</block>
  <block id="67d7b0b61202e57bcae8cda82f02e2b3" category="section-title">VMware Tanzu Kubernetes 플랫폼</block>
  <block id="55ad4cb8f0feecb71e184ef92cff1f70" category="paragraph">VMware Tanzu는 NetApp의 솔루션 엔지니어링 팀이 연구소에서 검증한 다양한 솔루션을 제공합니다. 각 Tanzu 릴리즈는 NetApp 스토리지 포트폴리오와 성공적으로 통합되며, 각 스토리지 포트폴리오는 특정 인프라 요구를 충족하는 데 도움이 됩니다. 다음 글머리 기호 하이라이트는 이 문서에 설명된 Tanzu의 각 버전의 기능과 제공 사항을 설명합니다.</block>
  <block id="5849f8d5cb1d66cb095da163e533dea7" category="paragraph">VMware Tanzu Kubernetes Grid(TKG)</block>
  <block id="45915535ce313f81567f3b3c41571fe9" category="list-text">VMware vSphere 환경에 구축된 표준 업스트림 Kubernetes 환경</block>
  <block id="32fcd5c42dc47b5cc021d74a489dee4f" category="list-text">이전 명칭 Essential PKS (Heptio 획득, 2019년 2월).</block>
  <block id="16196833d09cc8d52a1ef3790b4e15d3" category="list-text">TKG는 vSphere 6.7U3 이상에서 지원하기 위해 별도의 관리 클러스터 인스턴스와 함께 구축됩니다.</block>
  <block id="08f2ff1c0826ffc53a185010cce7dac7" category="list-text">TKG 구축은 AWS 또는 Azure와 함께 클라우드에도 구축할 수 있습니다.</block>
  <block id="15aa7eec2d32a1ba74b5cea8af5241ec" category="list-text">Windows 또는 Linux 작업자 노드(Ubuntu/Photon)를 사용할 수 있습니다.</block>
  <block id="89a8813ef0f3f2c1a9b0f20dab87e2a2" category="list-text">NSX-T, HA 프록시, AVI 네트워킹 또는 로드 밸런서를 컨트롤 플레인에 사용할 수 있습니다.</block>
  <block id="2ad16c86af27df82ae725dfd15176212" category="list-text">TKG는 애플리케이션/데이터 평면에 대해 MetalLB를 지원합니다.</block>
  <block id="7bf259c507ef53db8da3607757164b2e" category="list-text">vSphere CSI와 NetApp Astra Trident와 같은 타사 CSIS를 사용할 수 있습니다.</block>
  <block id="c840af216b38aff44cc5ba246da60e17" category="paragraph">VMware Tanzu Kubernetes Grid Service(TKGS)</block>
  <block id="27077307fac1683851c72a97ba11c62e" category="list-text">TKGS는 vSphere 7.0U1 이상에만 감독자 클러스터 및 워크로드 클러스터와 함께 배포됩니다.</block>
  <block id="3ee27cde76894c76ad60736ecbca78da" category="list-text">TKGS는 애플리케이션/데이터 평면에 대해 MetalLB를 지원합니다.</block>
  <block id="443c9bd7eeb4bc3d39f67cc555b4aab2" category="list-text">는 vSphere Pod와 Tanzu를 지원하므로 Pod가 환경의 활성화된 ESXi 호스트에서 직접 실행될 수 있습니다.</block>
  <block id="f4ef19f9ee886fa602632ef3f35019ad" category="list-text">이전 명칭 Enterprise PKS(Heptio 획득, 2019년 2월).</block>
  <block id="28789df26df63aa440b3aded601e67a6" category="list-text">NSX-T, HA 프록시 또는 AVI를 사용할 수 있습니다. 또한 고유한 로드 밸런서를 제공할 수도 있습니다.</block>
  <block id="2b681f710a75cd56332534e50fe625ff" category="list-text">vSphere 6.7U3 이상, AWS, Azure 및 GCP에서 지원됩니다.</block>
  <block id="f09eefe449cf027cce033ceb064c2fae" category="list-text">마법사를 통해 설정을 하면 배포가 용이합니다.</block>
  <block id="78c9a89b579a1005676bf4b1a4b3aad7" category="list-text">Bosh에서 관리하는 제어된 불변 VM에서 Tanzu를 실행합니다.</block>
  <block id="46c96f35ab6c6f57dd96776e1f115737" category="list-text">vSphere CSI 및 NetApp Astra Trident와 같은 타사 CSIS를 사용할 수 있습니다(일부 조건이 적용됨).</block>
  <block id="b63d5ee355078976e86c94b5c978788e" category="paragraph">NetApp Astra Control Center는 상태 저장 Kubernetes 워크로드를 위한 풍부한 스토리지 및 애플리케이션 인식 데이터 관리 서비스 세트를 제공하며, 온프레미스 환경에 구축되며, 신뢰할 수 있는 NetApp 데이터 보호 기술을 기반으로 합니다.</block>
  <block id="e764fe6b8f8825a307a87cedbef45678" category="cell">22.04</block>
  <block id="63355c54bd7e8ff73915da41610ec6f7" category="cell">22.04.0</block>
  <block id="22053fd2d26d3a313aea03b09e9a776c" category="cell">VMware Tanzu Kubernetes Grid Service</block>
  <block id="c99c6e88d4de8db879b1b5ec64d1f7ed" category="cell">0.0.15 [vSphere 네임스페이스]</block>
  <block id="8eb1302ead60c09b6d757b2b7ab84040" category="cell">1.22.6 [Supervisor Cluster Kubernetes]</block>
  <block id="caf617dd6edf29fd289caff7469ea66b" category="cell">VMware Tanzu Kubernetes Grid 통합</block>
  <block id="1d5bc9367c9565bbe31cc00aa1f870a4" category="cell">1.13.3</block>
  <block id="5d9dd4ee62c5446f01e895cd118d98dd" category="cell">VMware NSX-T 데이터 센터</block>
  <block id="7bc09c21b8fa1161768459982f0ec89e" category="cell">네트워킹 및 보안</block>
  <block id="b1179856b0372cb8777975cb658548ac" category="cell">3.1.3</block>
  <block id="cc540661734771d2e0272e8b4ef5c228" category="cell">VMware NSX 고급 로드 밸런서</block>
  <block id="50382c1137e78c7c038faabadb85d9fd" category="cell">로드 밸런서</block>
  <block id="d08680d7e9b745c4d4b81a2d6df7a012" category="cell">20.1.3</block>
  <block id="743cb170909d5e6e5936fc4783a59de5" category="inline-link-macro">다음: VMware Tanzu 개요</block>
  <block id="4b362af24230ce2d990680198c520d44" category="paragraph"><block ref="4b362af24230ce2d990680198c520d44" category="inline-link-macro-rx"></block></block>
  <block id="30a7219728f2665214ac7ae0458c27a8" category="list-text"><block ref="30a7219728f2665214ac7ae0458c27a8" category="inline-link-macro-rx"></block></block>
  <block id="40ef898131b1ea0532620ff9cb12840c" category="summary">이 페이지에는 Astra Trident를 사용하여 VMware Tanzu에서 영구 스토리지를 프로비저닝하는 방법에 대한 비디오 데모 링크가 포함되어 있습니다.</block>
  <block id="e0d2648924bbf778345db6153fddf464" category="doc">Astra Trident를 사용하여 VMware Tanzu에서 영구 스토리지를 프로비저닝합니다</block>
  <block id="db70f2aaf062f269f45b2fe61ad31160" category="admonition">이 데모는 TKG 버전 1.3.1 및 Astra Control Center 버전 21.12를 사용한 기술 미리보기로 기록되었습니다. 지원되는 공식 버전은 Support Matrix를 참조하십시오.</block>
  <block id="945f7593bacdce2a986b2ea8ab58220b" category="summary">이 페이지에서는 Astra Control Center를 사용하여 VMware Tanzu에서 애플리케이션을 복제하는 방법을 보여 주는 비디오 데모로 이동합니다.</block>
  <block id="ff56b2be4aa6be0d45adf0bbeb76166d" category="doc">Astra Control Center를 사용하여 VMware Tanzu에서 애플리케이션을 복제합니다</block>
  <block id="15693c045ae1b118bd5c3f8e9cee5c08" category="summary">Astra Control Center에서 워크로드를 관리할 수 있도록 하려면 먼저 Tanzu Kubernetes 클러스터를 등록해야 합니다.</block>
  <block id="3a16c17a7d5ce69951add72b2e46c340" category="doc">Astra Control Center에 VMware Tanzu Kubernetes 클러스터를 등록합니다</block>
  <block id="a723b0aede16ae3d3bdd6761d359595b" category="section-title">VMware Tanzu Kubernetes 클러스터 등록</block>
  <block id="779e6578abb36499d7c5399b33269c9c" category="list-text">첫 번째 단계는 Astra Control Center에 Tanzu Kubernetes 클러스터를 추가하고 관리하는 것입니다. 클러스터 로 이동하고 클러스터 추가 를 클릭하고 Tanzu Kubernetes 클러스터에 대한 kubecon무화과 파일을 업로드한 다음 스토리지 선택 을 클릭합니다.</block>
  <block id="d9687c204aa759a004b29f4f41e01908" category="list-text">클러스터를 추가하면 검색 상태로 이동하고 Astra Control Center에서 클러스터를 검사하고 필요한 에이전트를 설치합니다. 정상적으로 등록되면 클러스터 상태가 정상 상태로 바뀝니다.</block>
  <block id="1e7084bafe0fe7d10e28e10eea2641aa" category="admonition">Astra Control Center에서 관리할 모든 Tanzu Kubernetes 클러스터는 관리 클러스터에 설치된 에이전트가 해당 레지스트리에서 이미지를 가져올 때 설치에 사용된 이미지 레지스트리에 액세스할 수 있어야 합니다.</block>
  <block id="f3eca6ba1067d4a61b1229f18ab1a463" category="list-text">Astra Control Center에서 백엔드를 관리할 스토리지 리소스로 ONTAP 클러스터를 가져옵니다. Tanzu Kubernetes 클러스터를 Astra에 추가하고 스토리지 클래스를 구성하면 스토리지 클래스를 지원하는 ONTAP 클러스터를 자동으로 검색하고 검사하지만 관리를 위해 Astra Control Center로 가져오지 않습니다.</block>
  <block id="3c786ecd99f0ebd5edd64d81ad32375c" category="list-text">ONTAP 클러스터를 가져오려면 백엔드에서 드롭다운을 클릭하고 관리할 ONTAP 클러스터 옆의 관리를 선택합니다. ONTAP 클러스터 자격 증명을 입력하고 정보 검토 를 클릭한 다음 스토리지 백엔드 가져오기 를 클릭합니다.</block>
  <block id="af64f63e0642401224fc8f9c2ec7d1c5" category="list-text">백엔드가 추가되면 상태가 사용 가능으로 변경됩니다. 이러한 백엔드는 이제 Tanzu Kubernetes 클러스터의 영구 볼륨과 ONTAP 시스템의 해당 볼륨에 대한 정보를 갖게 됩니다.</block>
  <block id="688cdc8b62507f4c74f7452e7889821d" category="list-text">Astra Control Center를 사용하여 Tanzu Kubernetes 클러스터 전체에서 백업 및 복구를 수행하려면 S3 프로토콜을 지원하는 오브젝트 스토리지 버킷을 프로비저닝해야 합니다. 현재 지원되는 옵션은 ONTAP S3, StorageGRID, AWS S3, Microsoft Azure Blob 스토리지입니다. 이 설치를 위해 AWS S3 버킷을 구성하려고 합니다. Bucket 으로 이동하여 Bucket 추가 를 클릭하고 Generic S3 를 선택합니다. S3 버킷과 자격 증명에 액세스하기 위한 세부 정보를 입력하고 이 Bucket을 클라우드의 기본 버킷으로 설정 확인란을 클릭한 다음 추가를 클릭합니다.</block>
  <block id="f1b8312f03a9ec379a8e0fc00f20be33" category="paragraph"><block ref="f1b8312f03a9ec379a8e0fc00f20be33" category="inline-link-macro-rx"></block></block>
  <block id="9c5a4b54facfb25c9699e51ca3728574" category="summary">VMware Tanzu Kubernetes 클러스터를 등록하면 Astra Control Center를 통해 구축 및 관리하는 애플리케이션을 검색할 수 있습니다.</block>
  <block id="ada6daf9261af1429947be91dd72757b" category="paragraph">Tanzu Kubernetes 클러스터를 등록한 후에는 Astra Control Center를 통해 구축된 애플리케이션을 검색하고 관리할 수 있습니다.</block>
  <block id="48652ad0d003928f33825c84d5c8d950" category="list-text">Tanzu Kubernetes 클러스터 및 ONTAP 백엔드가 Astra Control Center에 등록되면, 제어 센터는 지정된 ONTAP 백엔드로 구성된 스토리지 시스템을 사용하는 모든 네임스페이스에서 애플리케이션을 자동으로 검색하기 시작합니다.</block>
  <block id="a013472d7ab7df6d0e423dbb7e238f7a" category="paragraph"><block ref="a013472d7ab7df6d0e423dbb7e238f7a" category="inline-link-macro-rx"></block></block>
  <block id="96b5419ab713b49685af4d923930ce22" category="summary">iSCSI를 통해 영구 볼륨의 NetApp ONTAP 스토리지 시스템을 VMware Tanzu Kubernetes 클러스터와 통합하기 위한 첫 번째 단계는 각 노드에 로그인하고 iSCSI 볼륨을 마운트하기 위한 iSCSI 유틸리티 또는 패키지를 구성하여 노드를 준비하는 것입니다.</block>
  <block id="da883967924519350a1c423bd85906dd" category="paragraph">iSCSI를 통해 영구 볼륨의 NetApp ONTAP 스토리지 시스템을 VMware Tanzu Kubernetes 클러스터와 통합하여 각 노드에 로그인하고 iSCSI 볼륨을 마운트하는 iSCSI 유틸리티 또는 패키지를 구성하여 노드를 준비합니다. 이렇게 하려면 여기에 설명된 절차를 따르십시오 <block ref="fb2092145032d18c9376d95ca453f9a7" category="inline-link-macro-rx"></block>.</block>
  <block id="50c35de69200a8b9e4be302372e74851" category="admonition">NetApp은 VMware Tanzu Kubernetes 클러스터의 NAT 구현 시 이 절차를 권장하지 않습니다.</block>
  <block id="bfc5022105ee1678e96b6f9991116647" category="admonition">TKGI는 변경 불가능한 구성 이미지를 실행하는 Tanzu Kubernetes 클러스터의 노드로 Bosh VM을 사용하며, Bosh VM에서 iSCSI 패키지를 수동으로 변경하는 경우 재부팅 후에도 지속되지 않습니다. 따라서 TKGI에서 구축 및 운영하는 Tanzu Kubernetes 클러스터의 영구 스토리지에는 NFS 볼륨을 사용하는 것이 좋습니다.</block>
  <block id="16e4431f428a4ec8abdfbee6ec2c2889" category="paragraph">클러스터 노드가 iSCSI 볼륨에 대해 준비된 후에는 스토리지 시스템과의 통신을 지원하는 백엔드를 생성해야 합니다. 이 솔루션에 기본 백엔드를 구성했지만, 보다 맞춤화된 옵션을 원하는 경우 설명서를 참조하십시오 <block ref="f151238ff3a8d488c82b6303d676eaa3" category="inline-link-macro-rx"></block>.</block>
  <block id="31cd969d7cf1970993d449ccccaeddfe" category="paragraph">ONTAP에서 SVM을 생성하려면 다음 단계를 완료하십시오.</block>
  <block id="70d94c82da2765251783d499556773b7" category="list-text">SVM의 이름을 입력하고 iSCSI 프로토콜을 설정한 다음 데이터 LIF에 대한 세부 정보를 제공합니다.</block>
  <block id="9305b9f7555d613129963713b0c214e6" category="image-alt">iSCSI SVM 데이터 LIF</block>
  <block id="f9edece6d4cf48c209a5fe7da61f0ecb" category="list-text">SVM 관리 계정의 세부 정보를 입력한 다음 저장을 클릭합니다.</block>
  <block id="2b44a7a64e9a3efc0b4e423d6339aaa7" category="image-alt">iSCSI SVM 관리</block>
  <block id="f61c0f70e825557a7be7fe0ac432bdf7" category="list-text">SVM에 애그리게이트를 할당하려면 스토리지 &gt; 스토리지 VM으로 이동하고, 새로 생성한 SVM 옆의 줄임표를 클릭한 다음 편집 을 클릭합니다. Limit Volume Creation to Preferred Local Tiers 확인란을 선택하고 필요한 애그리게이트를 이 체크박스에 연결합니다.</block>
  <block id="74ede5d2e56e369e9eda54f4095292f5" category="list-text">백엔드를 생성한 후 다음 번에 스토리지 클래스를 생성해야 합니다. 다음 샘플 저장소 클래스 정의에서는 필수 및 기본 필드를 강조 표시합니다. 매개 변수 'backendType'은 새로 생성된 Trident 백엔드의 스토리지 드라이버를 반영해야 합니다. 또한 이름 필드 값을 기록해 둡니다. 이 값은 나중에 참조해야 합니다.</block>
  <block id="cf2c5963ca8332d4f43e6c3a955da4da" category="admonition">이 파일에 정의된 fschType이라는 선택적 필드가 있습니다. iSCSI 백엔드에서 이 값을 특정 Linux 파일 시스템 유형(XFS, ext4 등)으로 설정하거나 삭제하여 Tanzu Kubernetes 클러스터가 사용할 파일 시스템을 결정할 수 있도록 할 수 있습니다.</block>
  <block id="af4fcf3aff174981414dc5c9fce2f4ec" category="section-title">애플리케이션 스냅샷을 생성합니다</block>
  <block id="29335406e75e8b137ee91c9f44068bc6" category="paragraph">애플리케이션의 스냅샷은 ONTAP 스냅샷 복사본과 애플리케이션 메타데이터의 복사본을 생성합니다. 이 복사본은 스냅샷 복사본을 기준으로 애플리케이션을 특정 시점으로 복원 또는 클론 복제하는 데 사용할 수 있습니다.</block>
  <block id="9bb92323cd91f66cadcdc492341cddd5" category="section-title">애플리케이션 백업을 생성합니다</block>
  <block id="c4c29bc3f7db6d04fde98415386e1e7f" category="list-text">응용 프로그램을 복원하려면 앱 &gt; 관리 탭으로 이동하여 해당 앱을 클릭합니다. 응용 프로그램 이름 옆의 드롭다운 메뉴를 클릭하고 복원 을 클릭합니다.</block>
  <block id="2c0d64177d5c89bc452e9f1eb0fd4f65" category="list-text">새 네임스페이스의 세부 정보를 입력하고 복제할 클러스터를 선택한 다음 기존 스냅샷, 백업 또는 애플리케이션의 현재 상태에서 클론을 생성할지 여부를 선택합니다. 세부 정보를 검토한 후 다음 을 클릭하고 검토 창에서 복제 를 클릭합니다.</block>
  <block id="ef0b684dddd1cea4885513d892f39cfa" category="paragraph"><block ref="ef0b684dddd1cea4885513d892f39cfa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3901d4e16e17c29d42ccb430b94cc402" category="paragraph"><block ref="3901d4e16e17c29d42ccb430b94cc402" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62772f599e4130a9b43b483c82338681" category="summary">VMware Tanzu는 기업이 애플리케이션과 인프라를 현대화할 수 있도록 지원하는 제품 포트폴리오입니다. VMware Tanzu의 전체 기능 스택은 개발 및 IT 운영 팀을 단일 플랫폼으로 통합하여 사내 및 하이브리드 클라우드 환경 전반에서 애플리케이션과 인프라의 현대화를 일관되게 수용함으로써 더 나은 소프트웨어를 지속적으로 운영 환경에 제공합니다.</block>
  <block id="969f4a20d38cf3096e1659b96da1b729" category="doc">VMware Tanzu 개요</block>
  <block id="c395793804bd9dfa82ff727781faf3c5" category="image-alt">VMware Tanzu 포트폴리오</block>
  <block id="3614585a8ed284306a5eadc9e31585b8" category="paragraph">Tanzu 포트폴리오의 다양한 제공 서비스 및 기능에 대한 자세한 내용은 설명서를 참조하십시오 <block ref="e9fed892b98a6bbccfc15bfe67c5aa96" category="inline-link-macro-rx"></block>.</block>
  <block id="3ff60e0bc78c13ace612734741c1e1da" category="paragraph">Tanzu의 Kubernetes Operations 카탈로그와 관련하여 VMware는 다양한 플랫폼을 기반으로 Tanzu Kubernetes 클러스터의 라이프사이클을 프로비저닝 및 관리하는 Tanzu Kubernetes Grid를 위한 다양한 구현을 보유하고 있습니다. Tanzu Kubernetes 클러스터는 VMware에서 구축 및 지원하는 완전한 Kubernetes 배포 서비스입니다.</block>
  <block id="caaf1eb22b79381e3d4a2b2b9a7d1698" category="paragraph">NetApp은 연구실에서 VMware Tanzu 포트폴리오에 포함된 다음 제품의 배포와 상호 운용성을 테스트하고 검증했습니다.</block>
  <block id="0fe3792ebba34a6c12f05656d54ecb49" category="list-text"><block ref="0fe3792ebba34a6c12f05656d54ecb49" category="inline-link-macro-rx"></block></block>
  <block id="eac001284f9380ccf17ee4490dbe13e1" category="list-text"><block ref="eac001284f9380ccf17ee4490dbe13e1" category="inline-link-macro-rx"></block></block>
  <block id="d6a1da4b26eb2ae838f5db5e80c44aee" category="inline-link-macro">VMware Tanzu Kubernetes Grid Integrated(TKGI)</block>
  <block id="57729a0bf5ad457403cd6505bdfeb143" category="list-text"><block ref="57729a0bf5ad457403cd6505bdfeb143" category="inline-link-macro-rx"></block></block>
  <block id="aa7b3dace1453f21689852e3b066f673" category="summary">VMware Tanzu Kubernetes Grid Service(Tanzu 및 vSphere라고도 함)를 사용하면 vSphere에서 기본적으로 Tanzu Kubernetes 클러스터를 생성하고 작동할 수 있을 뿐만 아니라 ESXi 호스트에서 일부 소규모 워크로드를 직접 실행할 수 있습니다.</block>
  <block id="b71ad38bc3fd2c1a10efc2b09270e430" category="doc">TKGS(VMware Tanzu Kubernetes Grid Service) 개요</block>
  <block id="9f0bacdd758242392df6d215d34d9b8e" category="paragraph">VMware Tanzu Kubernetes Grid Service(Tanzu 및 vSphere라고도 함)를 사용하면 vSphere에서 기본적으로 Tanzu Kubernetes 클러스터를 생성하고 작동할 수 있을 뿐만 아니라 ESXi 호스트에서 일부 소규모 워크로드를 직접 실행할 수 있습니다. 이를 통해 vSphere를 하이퍼바이저 계층에서 기본적으로 컨테이너화된 워크로드를 실행하는 플랫폼으로 전환할 수 있습니다. Tanzu Kubernetes Grid Service는 작업 부하에 필요한 클러스터를 구축하고 운영하는 설정된 경우 vSphere에 감독자 클러스터를 구축합니다. vSphere 7과 기본적으로 통합되며 vCenter SSO, Content Library, vSphere 네트워킹, vSphere 스토리지, vSphere HA 및 DRS, vSphere 보안 등 안정적인 여러 vSphere 기능을 활용하여 Kubernetes를 더욱 원활하게 사용할 수 있습니다.</block>
  <block id="6b25ac3e69375bd4a52dbffeb5c9cb14" category="paragraph">vSphere with Tanzu는 컨테이너나 VM에서 애플리케이션 구성 요소를 실행할 수 있는 하이브리드 애플리케이션 환경을 위한 단일 플랫폼을 제공하므로 개발자, DevOps 엔지니어 및 vSphere 관리자에게 더 나은 가시성과 운영 용이성을 제공합니다. VMware TKGS는 vSphere 7 환경에서만 지원되며, ESXi 호스트에서 POD를 직접 실행할 수 있는 Tanzu Kubernetes 운영 포트폴리오에서 유일한 제품입니다.</block>
  <block id="0e1d3327747a52bdd78d80247d5b6500" category="image-alt">VMware Tanzu Kubernetes 서비스</block>
  <block id="6e1adc41159b779c5ef1a0c9c934a673" category="paragraph">Tanzu Kubernetes Grid Service에 대한 자세한 내용은 설명서를 참조하십시오 <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>.</block>
  <block id="767b04965a47baa63782400d36a0c62e" category="paragraph">기능 세트, 네트워킹 등과 관련하여 많은 아키텍처 고려사항이 있습니다. 선택한 아키텍처에 따라 Tanzu Kubernetes Grid Service의 사전 요구사항과 구축 프로세스가 다릅니다. 사용자 환경에 Tanzu Kubernetes Grid Service를 구축 및 구성하려면 가이드를 따르십시오 <block ref="5e5ad4985bdb8ab17883db4008c7c4a2" category="inline-link-macro-rx"></block>. 또한 TKGS를 통해 구축된 Tanzu Kubernetes 클러스터 노드에 로그인하려면 이 절차에 따르십시오<block ref="7db41b551ba1165c4dfa4cf2d8a36e55" category="inline-link-rx"></block>.</block>
  <block id="46d890e88b951c5a84a444aad08079ae" category="paragraph">NetApp은 원하는 워크로드 요구사항을 충족하기 위해 작업자 노드의 구성을 선택하여 내결함성을 지원하기 위해 모든 운영 환경을 다중 마스터 구축에 구축할 것을 권장합니다. 따라서 사용량이 많은 워크로드에 권장되는 VM 클래스에는 최소 4개의 vCPU와 12GB RAM이 있습니다.</block>
  <block id="e8a4d3a2e07c429150e133b7fedebd64" category="paragraph">Tanzu Kubernetes 클러스터를 네임스페이스로 생성할 때 소유자 또는 "편집" 권한이 있는 사용자는 사용자 계정을 사용하여 네임스페이스에서 직접 포드를 만들 수 있습니다. 소유자나 편집 권한이 있는 사용자에게 클러스터 관리자 역할이 할당되기 때문입니다. 그러나 모든 네임스페이스에서 배포, 데몬 집합, 상태 저장 집합 등을 만들 때는 필요한 권한이 있는 역할을 해당 서비스 계정에 할당해야 합니다. 이 작업은 구축 또는 데몬 세트가 서비스 계정을 사용하여 Pod를 구축하기 때문에 필요합니다.</block>
  <block id="dc4ab077311e2aad5b5af968844fc5fe" category="paragraph">클러스터의 모든 서비스 계정에 클러스터 관리자 역할을 할당하려면 다음 ClusterRoleBinding 예제를 참조하십시오.</block>
  <block id="5851271128193658704cec246f4fd21c" category="doc">NetApp 스토리지 통합 개요</block>
  <block id="c21c42ee74a060038cdb9ea059b7702a" category="list-text"><block ref="c21c42ee74a060038cdb9ea059b7702a" category="inline-link-macro-rx"></block></block>
  <block id="bbf3919625853b65280d28c2d26004fd" category="list-text"><block ref="bbf3919625853b65280d28c2d26004fd" category="inline-link-macro-rx"></block></block>
  <block id="7c83f61ffb36cd4e6fa256ea9573bcff" category="inline-link-macro">다음: NetApp Astra Control 개요</block>
  <block id="9fefc82351a3a2abfcae01d825253856" category="paragraph"><block ref="9fefc82351a3a2abfcae01d825253856" category="inline-link-macro-rx"></block></block>
  <block id="22a3cd730895fa6285f7ee2b7838bc34" category="list-text">Astra Control Center가 설치될 {k8s_usercluster_name} 클러스터에 대한 관리자 액세스 권한이 있는 kubecon무그림 파일을 생성하거나 얻습니다.</block>
  <block id="c67346d734cf1873532bdc9f9a1421da" category="list-text">컨테이너화된 가상화 워크로드를 동시에 실행할 수 있습니다</block>
  <block id="71d00a17a6d603b0b4ebb168354950db" category="list-text">워크로드 요구사항에 따라 인프라를 독립적으로 확장할 수 있는 능력</block>
  <block id="1722f248c3b6574ad844b53f30ac236c" category="sidebar">NetApp의 VMware Tanzu</block>
  <block id="c9fc26b21b932419e6f167a5ef97a61a" category="sidebar">VMware Tanzu 웹 사이트</block>
  <block id="8a22a6c667b205ca4e784c0364ccc5ea" category="sidebar">VMware TKG(Tanzu Kubernetes Grid) 개요</block>
  <block id="e5103defcbafcf380570238b4848f4a1" category="sidebar">VMware TKGS(Tanzu Kubernetes Grid Service) 개요</block>
  <block id="a2ec151aed88d77a34df663b329daf31" category="sidebar">VMware TKGI(Tanzu Kubernetes Grid Integrated Edition) 개요</block>
  <block id="e47703dd1fad3279269dda3b343b2272" category="sidebar">Tanzu Kubernetes 클러스터를 등록합니다</block>
  <block id="84f09994e75c5ede8e07c6ab4070faae" category="summary">이 섹션에서는 Swingbench 시뮬레이션 OLTP 워크로드의 성능 검증 및 벤치마크 결과에 대해 자세히 설명합니다.</block>
  <block id="d9a4da5bae7f5f09fa9c3850a052c626" category="doc">성능 검증 및 벤치마크 결과</block>
  <block id="b944009da5cbc8c34fbaa084f3b1d385" category="inline-link-macro">이전: Oracle 데이터베이스 관리.</block>
  <block id="2a07c9ef23ed37175e1063bb7d752c54" category="paragraph"><block ref="2a07c9ef23ed37175e1063bb7d752c54" category="inline-link-macro-rx"></block></block>
  <block id="4e71b9ce7d16c817e38c3c0b45825062" category="paragraph">이 성능 검증의 목표는 마크를 설정하지 않는 것입니다. 대신 이 문서에 설명된 구현 절차 및 모범 사례를 따르는 경우 퍼블릭 클라우드의 Oracle 데이터베이스 구축에 대해 유사한 성능 메트릭을 기대할 수 있습니다.</block>
  <block id="0215fc4537f81bbc2d6ff19ba75efeb5" category="paragraph">Swingbench SOE(Sales Order Entry) 모듈을 사용하여 OLTP 유형의 워크로드를 시뮬레이션했으며 NFS 프로토콜의 FSx 스토리지 볼륨이 있는 M5 EC2 인스턴스에 구축된 Oracle 데이터베이스에 워크로드를 적용했습니다. 기본 Swingbench SOE I/O 프로필은 80/20 읽기/쓰기 분할에 근접하며, 이는 실제 OLTP Oracle 워크로드 프로필과 가깝습니다.</block>
  <block id="611831b4b814ffa8e208ff6b01e797d9" category="paragraph">작업 부하는 판매 주문 입력, 검색, 재고 쿼리 등을 수행하는 클라이언트 측의 동시 사용자 수를 늘려 증가합니다. 테스트한 숫자는 8, 16, 32, 64 및 128명의 동시 사용자였습니다. 이 알고리즘은 서버 측에서 상당한 트랜잭션 볼륨을 푸시하고 Oracle 서버 제한을 테스트하기 위해 Swingbench를 사용합니다. 128명의 동시 사용자가 EC2 인스턴스 CPU 활용률은 약 80-90%에 달하는 것으로 확인되었습니다.</block>
  <block id="a5cbb12f8f9f28c970230ab16d36e184" category="paragraph">다음 섹션에서는 설정 및 테스트 결과에 대한 세부 정보를 제공합니다.</block>
  <block id="e018eaf806fedc0fa46d2acde6f60425" category="section-title">테스트 환경 설정</block>
  <block id="ff4adf700c0c4ba7e493af033a81ac29" category="paragraph">우리는 8vCPU, 32G RAM, 10Gps 네트워크 대역폭을 갖춘 EC2 M5 인스턴스를 구축했습니다.</block>
  <block id="2940f21a2cd7581a414576699c946a28" category="paragraph"><block ref="2940f21a2cd7581a414576699c946a28" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5e18ca4731d9d72ae0bd4438c7e84b5" category="section-title">FSX 저장소</block>
  <block id="dc29ebaf5cc1f622aabb0ae70efeced6" category="paragraph">다음과 같이 세 개의 데이터베이스 볼륨을 생성하고 EC2 인스턴스에 NFS를 사용하여 볼륨을 마운트했습니다.</block>
  <block id="829e4dfdaee315e0cfdba47e5047adf7" category="list-text">/u01 - Oracle 바이너리</block>
  <block id="5853f5304485ce536b44cd0dfb18bdbc" category="list-text">/u02 - Oracle 데이터 파일, 제어 파일</block>
  <block id="ee6ac3c6792e507ea8c5717f79c8ab46" category="list-text">/u03 - Oracle 로그 파일, 제어 파일</block>
  <block id="363dd83f018d937efa507464961997c5" category="paragraph">이중화를 위해 중요한 제어 파일의 복사본 2개를 보관했습니다.</block>
  <block id="009187ce6b03d07047e46c6ed738f305" category="paragraph"><block ref="009187ce6b03d07047e46c6ed738f305" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c8184a7a7a9ecb63af93d93759b393" category="paragraph">FSx 파일 시스템은 80,000 IOPS 용량과 2GiBps 입출력 처리량으로 구성됩니다.</block>
  <block id="3570146db42993029d30dbd022107030" category="section-title">Oracle 구성</block>
  <block id="9daecb8faf1751109e100894205a6aef" category="paragraph">Oracle 버전 19c와 RU 패치 19.8을 설치했습니다. 서버에서 dNFS가 설정되었습니다.</block>
  <block id="9041eebdfc5395440a43baff789c663b" category="paragraph">이 데이터베이스는 PDB 3개가 포함된 컨테이너형 데이터베이스로 배포되었습니다. 성능 테스트에 하나의 PDB 인스턴스를 사용했습니다. 다음 그림에서는 NFS 마운트 지점의 Oracle 스토리지 사이징을 보여 줍니다.</block>
  <block id="9ae30014c647d5fd5e38a292d1061810" category="paragraph"><block ref="9ae30014c647d5fd5e38a292d1061810" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8da929e8cdb57e8ea66260e3f7090d35" category="section-title">Swingbench 구성</block>
  <block id="6af00d716d36ee74995307e004b66d3f" category="paragraph">Windows 호스트에 8vCPU 및 32G RAM이 있는 Swingbench 2.6(최신 버전)을 구축했습니다. SOE PLSQL 테스트 모듈 버전 2를 벤치마크에 사용했습니다. 기본 로드 프로필은 80/20 읽기/쓰기 비율을 제공하여 실제 OLTP 트랜잭션 워크로드를 시뮬레이션합니다.</block>
  <block id="5850fdbd1ed0c58b02c8d3797381e7c6" category="paragraph">우리가 사용한 스키마 척도 계수는 50으로, 초기 데이터 로드 크기는 160G이고 임시 공간 할당은 30G입니다. 이러한 확장 요인으로 SOE 스키마는 온라인 주문 처리 시뮬레이션을 위해 1000개의 물류창고와 5천만 명의 고객을 제공했습니다.</block>
  <block id="9bc139569eaa30f1804b313d21ab69fa" category="paragraph">다음 스크린 샷에서는 Swingbench Windows UI의 워크로드 프로필과 일반적인 트랜잭션 실행 메트릭을 보여 줍니다.</block>
  <block id="4da81979345d8adfb02c96de8993662a" category="paragraph"><block ref="4da81979345d8adfb02c96de8993662a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5531d1590836e811c3ace97db7e230eb" category="paragraph">이 그래프에서 알 수 있듯이 테스트 실행 동안 트랜잭션 수준은 동일한 수준으로 유지되었습니다.</block>
  <block id="6c805c8ead51e13766957cbda36fd2c0" category="section-title">테스트 결과 분석</block>
  <block id="54f9f904b574caddc93a83f3057be251" category="paragraph">각 테스트 실행에 대한 Swingbench 결과를 캡처하고 성능 분석을 위한 해당 Oracle AWR 보고서를 확보했습니다.</block>
  <block id="9126019861ad7339333760b7b3bd5174" category="paragraph">최종 사용자 측에서 트랜잭션 볼륨 및 사용자 응답 시간과 같은 주요 메트릭을 살펴보았습니다. 두 메트릭 모두 시스템에 로그인하는 동시 사용자 수와 사용자가 주문을 입력한 후 트랜잭션을 완료하고 응답을 다시 받을 수 있는 속도를 기준으로 영업 주문 입력 시스템에서 사용자가 실행할 수 있는 트랜잭션 수를 보여 줍니다.</block>
  <block id="809217313025f03af0a774770ed7688d" category="paragraph">Oracle 서버 엔드에서 Oracle AWR 보고서를 구문 분석하여 사용자 트랜잭션 속도를 늦출 수 있는 주요 대기 이벤트를 파악했습니다. 상위 10개 Oracle 대기 이벤트에는 Swingbench 시뮬레이션 트랜잭션 테스트 실행 중에 Oracle 서버가 대부분 I/O로 바인딩되어 있으며, 데이터베이스 시간의 50%~60%는 Db 파일 순차 읽기에 소비됩니다. 로그 파일 동기화도 트랜잭션 커밋이 로그 I/O를 버퍼 캐시에서 디스크의 로그 파일로 플러시하도록 하는 Oracle 로깅 프로세스가 데이터베이스 시간 비율 수준의 더 작은 요소이기 때문에 중요한 요소입니다.</block>
  <block id="4da3501ef8d9ebc196009ef0bf4e4360" category="paragraph">트랜잭션 실행 중 동시 사용자 수에 대한 사용자 트랜잭션 볼륨, 사용자 응답 시간 및 Oracle 상위 대기 이벤트를 차트로 작성하였습니다. 결과는 다음과 같습니다.</block>
  <block id="911fadede55cdf4e5db896695fd4f9c3" category="paragraph"><block ref="911fadede55cdf4e5db896695fd4f9c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b225219fb0a32b17f3f7f3964edfa599" category="paragraph">이러한 결과는 지속적으로 낮은 I/O 지연 시간과 사용자 응답 시간을 유지하면서 동시 사용자 수가 증가하는 사용자 트랜잭션 볼륨을 꾸준히 늘릴 수 있다는 것을 나타냅니다. 이는 Oracle 애플리케이션에 적합한 성능입니다.</block>
  <block id="ccc7b98ab0c81e5b7e4033e88910e92e" category="paragraph">128명의 동시 사용자에 도달하면 I/O 지연 시간과 사용자 응답 시간이 다소 증가하기 시작했습니다. 다음 다이어그램과 같이 EC2 인스턴스가 전체 서버 용량에 거의 도달하므로 이 작업이 필요합니다.</block>
  <block id="0cc8a57e10ae7e4e152d74423527f2f0" category="paragraph"><block ref="0cc8a57e10ae7e4e152d74423527f2f0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faf8392c1e8a1c488f303b45f48fd31d" category="paragraph">마찬가지로 다음 다이어그램은 해당 시점의 사용자 트랜잭션 볼륨을 충족하는 동시에 해당 FSx IOPS 및 처리량을 보여 줍니다.</block>
  <block id="a18559304ff06a743412352fbfb82b00" category="paragraph"><block ref="37451e9b66358e4a66c6a1b882f378a1" category="inline-image-macro-rx" type="image"></block>
<block ref="b0d8c670dcd70932cfb6876c97b62036" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d8430502705720b257f565ec9140e72" category="inline-link-macro">Oracle 데이터베이스 구축에 고려해야 할 요인</block>
  <block id="b25a4c32c9b6cc39890fa799e15301dc" category="paragraph">Oracle 서버 EC2 인스턴스가 제한 요소가 되었을 때 IOPS 또는 처리량으로 프로비저닝된 FSx 스토리지 용량에 도달하지 않았습니다. 따라서 섹션에 나와 있는 것처럼 사용자 애플리케이션 레벨 트랜잭션 볼륨에 따라 컴퓨팅 및 스토리지의 크기를 적절하게 지정해야 합니다 <block ref="fa519ff010063f0b425f11c556e4445d" category="inline-link-macro-rx"></block></block>
  <block id="fefc87f11b675de356ca673f3a346ac7" category="inline-link-macro">다음: 데이터베이스 마이그레이션.</block>
  <block id="8996ba3a1cc79692db90ae4be7ef8dd3" category="paragraph"><block ref="8996ba3a1cc79692db90ae4be7ef8dd3" category="inline-link-macro-rx"></block></block>
  <block id="c739a7ae4891c6665d1f2f715d2efa3f" category="paragraph"><block ref="c739a7ae4891c6665d1f2f715d2efa3f" category="inline-link-macro-rx"></block></block>
  <block id="ca449b8ca808c6d325abf6b1a047318c" category="paragraph">다음 아키텍처 다이어그램은 FSx 스토리지 서비스가 있는 AWS EC2 인스턴스에 고가용성 Oracle 데이터베이스 구축을 보여 줍니다. 유사한 배포 체계이지만 다른 지역의 대기 구성을 재해 복구에 설정할 수 있습니다.</block>
  <block id="228488653f80c4dfe7bd79d5f9634ea4" category="paragraph">반면에 FSx 볼륨의 Oracle 데이터베이스 스토리지는 AWS FSx 콘솔 또는 CLI와 함께 구축됩니다. 이후에 Oracle 바이너리, 데이터 또는 로그 볼륨을 제공하고 EC2 인스턴스 Linux 호스트에 마운트합니다. 사용된 기본 스토리지 프로토콜에 따라 각 데이터 또는 로그 볼륨에 여러 개의 LUN이 할당될 수 있습니다.</block>
  <block id="be571c48040d6c3bf764ba40188888d2" category="paragraph">SnapCenter는 Oracle 데이터베이스 시점 복구 또는 필요한 경우 운영 또는 대기 영역에서 데이터베이스 클론 복제를 위한 워크플로우를 제공합니다. SnapCenter UI를 통해 Oracle 데이터베이스 백업 및 복제를 스탠바이 FSx 스토리지에 구성하여 RTO 또는 RPO 목표에 따라 고가용성 또는 재해 복구를 수행할 수 있습니다.</block>
  <block id="be22c0b35f58a932be14c9e55b163ac4" category="paragraph">이 솔루션은 Oracle RAC 및 Data Guard 구축에서 사용할 수 있는 기능과 유사한 기능을 제공하는 대체 프로세스를 제공합니다.</block>
  <block id="72db8e2a11aee3fd6b5ea401c9adcbd6" category="inline-link-macro">다음: 배포 절차.</block>
  <block id="f3b25b37995dab3a1b6c753dd74ca21e" category="summary">이 섹션에서는 AWS RDS 콘솔 UI를 보완하기 위해 SnapCenter UI를 통해 Oracle 데이터베이스용 AWS RDS Custom을 관리하는 방법에 대해 자세히 설명합니다.</block>
  <block id="39ebdf3133bce223758100b117a98e70" category="inline-link-macro">이전: 배포 절차.</block>
  <block id="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="paragraph"><block ref="cac2d984db56d4f9cd9b1f85b3cf0c5c" category="inline-link-macro-rx"></block></block>
  <block id="cf8b301cbf8aa698c578ff1f8e64ccc2" category="paragraph">AWS EC2 및 FSx 관리 콘솔 외에도 Ansible 제어 노드 및 SnapCenter UI 툴이 이 Oracle 환경에서 데이터베이스 관리를 위해 구축되었습니다.</block>
  <block id="ab1b9a020f08729c00ecee14e5a3be69" category="paragraph">Ansible 제어 노드를 사용하면 커널 또는 패치 업데이트를 위해 운영 인스턴스와 대기 인스턴스를 동기화된 상태로 유지하는 병렬 업데이트를 통해 Oracle 환경 구성을 관리할 수 있습니다. NetApp 자동화 툴킷을 통해 페일오버, 재동기화 및 페일백을 자동화하여 Ansible을 통해 빠른 애플리케이션 복구 및 가용성을 아카이브할 수 있습니다. 플레이북을 사용하여 반복적인 데이터베이스 관리 작업을 실행하여 사람의 실수를 줄일 수 있습니다.</block>
  <block id="53bd53a68bce8fe697a7455feae3861b" category="inline-link-macro">Oracle 데이터베이스용 SnapCenter 플러그인 개요</block>
  <block id="8dad283458f149f04a674f7c674818ed" category="paragraph">SnapCenter UI 툴은 Oracle 데이터베이스용 SnapCenter 플러그인을 사용하여 데이터베이스 스냅샷 백업, 시점 복구, 데이터베이스 클론 복제 등을 수행할 수 있습니다. Oracle 플러그인 기능에 대한 자세한 내용은 를 참조하십시오 <block ref="053f091ffb001fc31a47d30bc3d11350" category="inline-link-macro-rx"></block>.</block>
  <block id="c165a519b858dc997da23262308d6463" category="paragraph">다음 섹션에서는 SnapCenter UI를 통해 Oracle 데이터베이스 관리의 주요 기능을 수행하는 방법에 대해 자세히 설명합니다.</block>
  <block id="95154aa7c50b812d3683b6995bed8771" category="list-text">데이터베이스 스냅샷 백업</block>
  <block id="b055b8a9cd44d5f8e1fa330c20aa1dc3" category="list-text">데이터베이스 시점 복원</block>
  <block id="20f913ca57379280e5f37dce9cd0de61" category="list-text">데이터베이스 클론 생성</block>
  <block id="e724243c3ef9e2c58168b76f3f537412" category="paragraph">데이터베이스 클론 복제는 논리적 데이터 오류 또는 손상 시 데이터 복구를 위해 별도의 EC2 호스트에 운영 데이터베이스의 복제본을 생성하고 애플리케이션 테스트, 디버깅, 패치 검증 등에 클론을 사용할 수도 있습니다.</block>
  <block id="418768c00fe9ab38a23d8417250d676b" category="section-title">스냅샷 찍기</block>
  <block id="c018c634b9245f8522eaf32d3fffaa7a" category="paragraph">사용자가 구성한 간격으로 EC2/FSx Oracle 데이터베이스가 정기적으로 백업됩니다. 언제든지 한 번의 스냅샷 백업을 수행할 수도 있습니다. 이는 전체 데이터베이스 스냅샷 백업과 아카이브 로그 전용 스냅샷 백업에 모두 적용됩니다.</block>
  <block id="0a1758b0d7a64bf446ccd6c9ea2a559d" category="section-title">전체 데이터베이스 스냅샷 생성</block>
  <block id="6aa82df330acc0ad1c1859bf7d19d8c6" category="paragraph">전체 데이터베이스 스냅샷에는 데이터 파일, 제어 파일 및 아카이브 로그 파일을 포함한 모든 Oracle 파일이 포함됩니다.</block>
  <block id="71a81fc61b4bde806ab23dbb0dff87ab" category="list-text">SnapCenter UI에 로그인하고 왼쪽 메뉴에서 리소스 를 클릭합니다. 보기 드롭다운에서 자원 그룹 보기로 변경합니다.</block>
  <block id="097f9e0f1d7d03a8b8db3110da618df1" category="paragraph"><block ref="097f9e0f1d7d03a8b8db3110da618df1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3a16fe4e102f4f80c9a0ebe875e00921" category="list-text">전체 백업 리소스 이름을 클릭한 다음 지금 백업 아이콘을 클릭하여 임시 백업을 시작합니다.</block>
  <block id="b157c6d0dbf1f6fc8e66e048cdf587dc" category="paragraph"><block ref="b157c6d0dbf1f6fc8e66e048cdf587dc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c41836f211ec5f0aee4024039682c6d3" category="list-text">백업을 클릭한 다음 백업을 확인하여 전체 데이터베이스 백업을 시작합니다.</block>
  <block id="de38ecf82e29f57be2cb258095500ffc" category="paragraph"><block ref="de38ecf82e29f57be2cb258095500ffc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5114009902f821226811cd39b519e8ae" category="paragraph">데이터베이스의 리소스 보기에서 데이터베이스 관리 백업 복사본 페이지를 열어 일회성 백업이 성공적으로 완료되었는지 확인합니다. 전체 데이터베이스 백업에서는 데이터 볼륨용 스냅샷 하나와 로그 볼륨용 스냅샷 두 개를 생성합니다.</block>
  <block id="23c2c3d9fc4ea06c4f1744caa77dd75f" category="paragraph"><block ref="23c2c3d9fc4ea06c4f1744caa77dd75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc2bc8e691b80fc2b94cd487cd59a41e" category="section-title">아카이브 로그 스냅샷 생성</block>
  <block id="c2a2cc866aaa30cb6344e65c853429a7" category="paragraph">아카이브 로그 스냅샷은 Oracle 아카이브 로그 볼륨에 대해서만 생성됩니다.</block>
  <block id="973f07a93ca1636baa391407a84cb38b" category="list-text">SnapCenter UI에 로그인하고 왼쪽 메뉴 모음에서 리소스 탭을 클릭합니다. 보기 드롭다운에서 자원 그룹 보기로 변경합니다.</block>
  <block id="47f0395291ce13022063147f4981f69f" category="list-text">로그 백업 리소스 이름을 클릭한 다음 지금 백업 아이콘을 클릭하여 아카이브 로그에 대한 임시 백업을 시작합니다.</block>
  <block id="1417f1fbdcb104994815efb345497300" category="paragraph"><block ref="1417f1fbdcb104994815efb345497300" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b8ee5a2ad5f43fcd955b6b30854d2f98" category="list-text">백업 을 클릭한 다음 백업 확인 을 클릭하여 아카이브 로그 백업을 시작합니다.</block>
  <block id="03cb3b3b0da0531d726d5e6b4af1920c" category="paragraph"><block ref="03cb3b3b0da0531d726d5e6b4af1920c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40cffcacb55d81916f38114aac845d4b" category="paragraph">데이터베이스의 리소스 보기에서 데이터베이스 관리 백업 복사본 페이지를 열어 일회성 아카이브 로그 백업이 성공적으로 완료되었는지 확인합니다. 아카이브 로그 백업에서는 로그 볼륨에 대해 하나의 스냅샷을 생성합니다.</block>
  <block id="01422619a982004bea1ad1e237269525" category="paragraph"><block ref="01422619a982004bea1ad1e237269525" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e16045e122b02913b74ef1e8bd29d75c" category="section-title">특정 시점으로 복원 중</block>
  <block id="7d2260465121189e3f5aef56d1734e86" category="paragraph">동일한 EC2 인스턴스 호스트에서 특정 시점으로 SnapCenter 기반 복원이 실행됩니다. 복구를 수행하려면 다음 단계를 수행하십시오.</block>
  <block id="52443d446e6aa795d8e3a08e581684cb" category="list-text">SnapCenter 리소스 탭 &gt; 데이터베이스 보기에서 데이터베이스 이름을 클릭하여 데이터베이스 백업을 엽니다.</block>
  <block id="51d148134901f85184886bb72062b2a0" category="paragraph"><block ref="51d148134901f85184886bb72062b2a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6bc3aa5bd0c870df97abdd69ef227826" category="list-text">데이터베이스 백업 사본과 복원할 원하는 시점을 선택합니다. 또한 해당 시점의 해당 SCN 번호를 표시합니다. 시점 복원은 시간 또는 SCN을 사용하여 수행할 수 있습니다.</block>
  <block id="f4a16324772958025bfa77d2ed8af61e" category="paragraph"><block ref="f4a16324772958025bfa77d2ed8af61e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="acee7bbe553399023f78a7ac814d7a94" category="list-text">로그 볼륨 스냅샷을 강조 표시하고 마운트 버튼을 클릭하여 볼륨을 마운트합니다.</block>
  <block id="b068acd736c964d27b5833d30c220f7c" category="paragraph"><block ref="b068acd736c964d27b5833d30c220f7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d06beb2a91e58c7e57367e901abc09fd" category="list-text">로그 볼륨을 마운트할 운영 EC2 인스턴스를 선택합니다.</block>
  <block id="94bf51064baf8263a5c7e0d6dba0f38a" category="paragraph"><block ref="94bf51064baf8263a5c7e0d6dba0f38a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f83a9f884d94d22d3c52d510a051ac90" category="list-text">마운트 작업이 성공적으로 완료되었는지 확인합니다. 또한 EC2 인스턴스 호스트에서 해당 로그 볼륨과 마운트 지점 경로를 확인합니다.</block>
  <block id="53044f6472847053eea58f6f40258b7c" category="paragraph"><block ref="01717ad5eefdb68ab0f128386310e509" category="inline-image-macro-rx" type="image"></block>
<block ref="684c418b818adf3876d8fd9877edd90f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12a7a64116d859fb64b3f841a43e6fac" category="list-text">마운트된 로그 볼륨에서 현재 아카이브 로그 디렉토리로 아카이브 로그를 복사합니다.</block>
  <block id="f57c6961965ccab84762e9b4bbdd72f0" category="list-text">SnapCenter 리소스 탭 &gt; 데이터베이스 백업 페이지로 돌아가서 데이터 스냅샷 복사본을 강조 표시하고 복원 버튼을 클릭하여 데이터베이스 복원 워크플로우를 시작합니다.</block>
  <block id="eb283dcbcce9c21f038d1985c87645da" category="paragraph"><block ref="eb283dcbcce9c21f038d1985c87645da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a08ce545f0f81946ee65326ff4608df" category="list-text">"모든 데이터 파일" 및 "복원 및 복구에 필요한 경우 데이터베이스 상태 변경"을 선택하고 "다음"을 클릭합니다.</block>
  <block id="c53b030895e9cee782d7dfcea4a679ad" category="paragraph"><block ref="c53b030895e9cee782d7dfcea4a679ad" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e589c1295b0849053e2d8cc2bbf96a1e" category="list-text">SCN 또는 시간을 사용하여 원하는 복구 범위를 선택합니다. 6단계에서 설명된 대로 마운트된 아카이브 로그를 현재 로그 디렉토리에 복사하는 대신, 마운트된 아카이브 로그 경로는 복구를 위해 "외부 아카이브 로그 파일 위치 지정"에 나열될 수 있습니다.</block>
  <block id="12bfd26a9c7f1551fe3664e25975f022" category="paragraph"><block ref="12bfd26a9c7f1551fe3664e25975f022" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2f3b533a6c9cd757a311b56318115bbe" category="list-text">필요한 경우 실행할 옵션 처방을 지정합니다.</block>
  <block id="0c61f73092ad29b6a823f67f23872ffb" category="paragraph"><block ref="0c61f73092ad29b6a823f67f23872ffb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="16a70e704c6e5104eff1adca9f951c36" category="list-text">필요한 경우 실행할 선택적 애프터스크립트를 지정합니다. 복구 후 열려 있는 데이터베이스를 확인합니다.</block>
  <block id="5e5add6f904fa1973ca9f5564c87bdab" category="paragraph"><block ref="5e5add6f904fa1973ca9f5564c87bdab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="975952869f93fd5cb45acf8a19b97834" category="list-text">작업 알림이 필요한 경우 SMTP 서버 및 이메일 주소를 제공합니다.</block>
  <block id="125beea11cb628a2850a9c3b01628d3b" category="paragraph"><block ref="125beea11cb628a2850a9c3b01628d3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f92d4c842e7343ab2f69eac4e3561bc" category="list-text">작업 요약을 복원합니다. 마침 을 클릭하여 복원 작업을 시작합니다.</block>
  <block id="0dac703b5b68b8ce38eae7f7224a3de3" category="paragraph"><block ref="0dac703b5b68b8ce38eae7f7224a3de3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e783d4afe611873ddc32a5a59ff2078" category="list-text">SnapCenter에서 복원을 검증합니다.</block>
  <block id="7cc0ed8d8b03fe709b0d004e75183201" category="paragraph"><block ref="7cc0ed8d8b03fe709b0d004e75183201" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6e8e06b3f3e03bdb3391888df78e46" category="list-text">EC2 인스턴스 호스트에서 복원을 확인합니다.</block>
  <block id="06adcc9a574fcfaa717309c54d0fc7e9" category="paragraph"><block ref="06adcc9a574fcfaa717309c54d0fc7e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="983d6ea8d6962c3e0f9abef0c4c948f4" category="list-text">복구 로그 볼륨을 마운트 해제하려면 4단계의 단계를 역순으로 수행합니다.</block>
  <block id="ca0c306ba98701576c42d241b48d4038" category="section-title">데이터베이스 클론 생성</block>
  <block id="a8bd304fe0995bcddba8dd93a8d447a6" category="paragraph">다음 섹션에서는 SnapCenter 클론 워크플로우를 사용하여 운영 데이터베이스에서 대기 EC2 인스턴스로 데이터베이스 클론을 생성하는 방법을 보여 줍니다.</block>
  <block id="91956afde8e3bc7ac47e37b9821ca6f9" category="list-text">SnapCenter에서 전체 백업 리소스 그룹을 사용하여 기본 데이터베이스의 전체 스냅샷 백업을 수행합니다.</block>
  <block id="023d426483e83bc3abf204154e323eba" category="paragraph"><block ref="023d426483e83bc3abf204154e323eba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b08a0a4966d6a40934f84e0367df5124" category="list-text">SnapCenter 리소스 탭 &gt; 데이터베이스 보기에서 복제본을 생성할 기본 데이터베이스에 대한 데이터베이스 백업 관리 페이지를 엽니다.</block>
  <block id="f14aaf01a42159b842a496f880063869" category="paragraph"><block ref="f14aaf01a42159b842a496f880063869" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6b265d526ea8d86f13a3ee5b3df11ce5" category="list-text">4단계에서 생성한 로그 볼륨 스냅샷을 스탠바이 EC2 인스턴스 호스트에 마운트합니다.</block>
  <block id="160b6f6b07db1490de7e1252e8f6ec84" category="paragraph"><block ref="074cfbf53cae79233eac44ac8a4aa5f8" category="inline-image-macro-rx" type="image"></block>
<block ref="a75c3f795382693108f8d772396f248b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15c2865196d70f81dd791b3329d2604e" category="list-text">복제본에 대해 클론 복제할 스냅샷 복제본을 강조 표시하고 클론 버튼을 클릭하여 클론 절차를 시작합니다.</block>
  <block id="568f30b58394b2e0d4e795beb731c0eb" category="paragraph"><block ref="568f30b58394b2e0d4e795beb731c0eb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3ebc0e83f8e5d02518da0756a18aaab4" category="list-text">기본 데이터베이스 이름과 다르게 복제본 이름을 변경합니다. 다음 을 클릭합니다.</block>
  <block id="b77619cc2b53d1b603e6051036b122b6" category="paragraph"><block ref="b77619cc2b53d1b603e6051036b122b6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6ba0975a31e144349d50f09393a5ca21" category="list-text">클론 호스트를 스탠바이 EC2 호스트로 변경하고 기본 이름을 그대로 사용하고 Next를 클릭합니다.</block>
  <block id="d39fd3bd4059fb775d174eef3e53919b" category="paragraph"><block ref="d39fd3bd4059fb775d174eef3e53919b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eeda8df21c3391dcc7a327cfec8f8704" category="list-text">Oracle 홈 설정을 타겟 Oracle 서버 호스트에 대해 구성된 설정과 일치하도록 변경하고 Next를 클릭합니다.</block>
  <block id="8cb5c7c55cf01620e1eaae0dd817ad2c" category="paragraph"><block ref="8cb5c7c55cf01620e1eaae0dd817ad2c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f10b26890bad0f92387ad2c8efb9b532" category="list-text">시간 또는 SCN 및 마운트된 아카이브 로그 경로를 사용하여 복구 지점을 지정합니다.</block>
  <block id="9d2a5645a731a8a3af7ee677133ba312" category="paragraph"><block ref="9d2a5645a731a8a3af7ee677133ba312" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684abeacd08eb59922d70d928ce47f45" category="list-text">필요한 경우 SMTP 이메일 설정을 전송합니다.</block>
  <block id="84bb684b488190f680f548303196f5b9" category="paragraph"><block ref="84bb684b488190f680f548303196f5b9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e2cc0c6ba26bdf7b30e39313a0ad4098" category="list-text">작업 요약을 클론하고 마침 을 클릭하여 클론 작업을 시작합니다.</block>
  <block id="3461ca6663823ff26ef7d3121d8592c7" category="paragraph"><block ref="3461ca6663823ff26ef7d3121d8592c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5cd909b2ce2e22f0bb8734426ea9e9a" category="list-text">클론 작업 로그를 검토하여 복제본 클론을 확인합니다.</block>
  <block id="c6c9a361716f3695e5f582cbbaf857f6" category="paragraph"><block ref="c6c9a361716f3695e5f582cbbaf857f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="66a858d0c53f7ecef6ff665372a428c5" category="paragraph">복제된 데이터베이스는 즉시 SnapCenter에 등록됩니다.</block>
  <block id="8fc5846614431a858445f7c55fe6f8bf" category="paragraph"><block ref="8fc5846614431a858445f7c55fe6f8bf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9b70fde27d9d03d393dc2fd619546988" category="list-text">Oracle 아카이브 로그 모드를 해제합니다. EC2 인스턴스에 Oracle 사용자로 로그인하여 다음 명령을 실행합니다.</block>
  <block id="ca1a9785bb111fcadc4527aae18f822d" category="admonition">대신 기본 Oracle 백업 복제본을 사용하여 동일한 절차를 통해 타겟 FSx 클러스터의 복제된 보조 백업 복제본에서 클론을 생성할 수도 있습니다.</block>
  <block id="2a75f5115dab8b39875560a4d7252d2f" category="section-title">HA가 대기 및 재동기화로 페일오버됩니다</block>
  <block id="f5bc6d05191457096f9da00e0fa56d40" category="paragraph">대기 Oracle HA 클러스터는 컴퓨팅 계층 또는 스토리지 계층에서 운영 사이트에 장애가 발생할 경우 고가용성을 제공합니다. 이 솔루션의 중요한 이점 중 하나는 사용자가 언제든지 빈도로 인프라를 테스트하고 검증할 수 있다는 것입니다. 페일오버는 실제 장애로 인해 사용자 시뮬레이션하거나 트리거될 수 있습니다. 페일오버 프로세스는 동일하며 빠른 애플리케이션 복구를 위해 자동화될 수 있습니다.</block>
  <block id="6775249aa36196ee3d9c71774992f2c4" category="paragraph">다음 페일오버 절차 목록을 참조하십시오.</block>
  <block id="eb171dc2d1f739dfee2e358326abd0e9" category="list-text">시뮬레이트된 페일오버의 경우 로그 스냅샷 백업을 실행하여 섹션에 설명된 대로 최신 트랜잭션을 대기 사이트로 플러시합니다 <block ref="58f2fe5f16b910e6ad4f8b3f8679e256" category="inline-xref-macro-rx"></block>. 실제 장애로 인해 트리거된 페일오버의 경우 마지막으로 성공한 예약 로그 볼륨 백업을 사용하여 복구 가능한 마지막 데이터가 대기 사이트에 복제됩니다.</block>
  <block id="abdc57f5efdfeac30fe822d9eda2fc9f" category="list-text">기본 FSx 클러스터와 대기 FSx 클러스터 간의 SnapMirror를 중단하십시오.</block>
  <block id="bd54ae4d51454c6a89990f066be03d35" category="list-text">스탠바이 EC2 인스턴스 호스트에 복제된 대기 데이터베이스 볼륨을 마운트합니다.</block>
  <block id="588698147b1d63f4f9f6d78dd8d83595" category="list-text">복제된 Oracle 바이너리가 Oracle 복구에 사용되는 경우 Oracle 바이너리를 다시 링크합니다.</block>
  <block id="0f1ac3f743fcb2d14875c7a731c3d251" category="list-text">대기 Oracle 데이터베이스를 사용 가능한 마지막 아카이브 로그로 복구합니다.</block>
  <block id="ab933bdc7c043f4a3c977049791f0640" category="list-text">애플리케이션 및 사용자 액세스를 위해 대기 Oracle 데이터베이스를 엽니다.</block>
  <block id="6928cb13e9136438c86e16b724b3b64f" category="list-text">실제 운영 사이트 장애의 경우 대기 Oracle 데이터베이스는 이제 새로운 운영 사이트의 역할을 수행하며, 데이터베이스 볼륨을 사용하여 역방향 SnapMirror 방법을 사용하여 장애가 발생한 운영 사이트를 새로운 대기 사이트로 재구축할 수 있습니다.</block>
  <block id="13e25eed8fa423975f854101e3be1e89" category="list-text">테스트 또는 검증을 위해 시뮬레이션된 운영 사이트 오류의 경우 테스트 연습을 완료한 후 대기 Oracle 데이터베이스를 종료합니다. 그런 다음 대기 EC2 인스턴스 호스트에서 대기 데이터베이스 볼륨을 마운트 해제하고 운영 사이트에서 대기 사이트로 복제를 다시 동기화합니다.</block>
  <block id="c3fd0f78855e219b0fd44077ce74e7b5" category="paragraph">이러한 절차는 NetApp Automation Toolkit을 사용하여 퍼블릭 NetApp GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="ba4d6e5d6eeea04cdc5a4f243b1e5dd8" category="paragraph">설정 및 페일오버 테스트를 시도하기 전에 README 지침을 주의 깊게 읽으십시오.</block>
  <block id="7d34df46082e5771e092eb8736597ee0" category="summary">이 섹션에서는 FSx 스토리지와 함께 Oracle RDS 사용자 지정 데이터베이스를 구축하는 구축 절차를 설명합니다.</block>
  <block id="072a1cb4963593f78b428b4c9a0dcc4f" category="inline-link-macro">이전: 솔루션 아키텍처.</block>
  <block id="ef081c8f35bca2da08c6dbdd6f48a6cd" category="paragraph"><block ref="ef081c8f35bca2da08c6dbdd6f48a6cd" category="inline-link-macro-rx"></block></block>
  <block id="f70ec60e40ece5900605229a28081b13" category="section-title">EC2 콘솔을 통해 Oracle용 EC2 Linux 인스턴스를 구축합니다</block>
  <block id="03d6d2463e27b63c2d7f7ad0e62697af" category="paragraph">AWS를 처음 사용하는 경우, 먼저 AWS 환경을 설정해야 합니다. AWS 웹 사이트 랜딩 페이지의 문서 탭에는 AWS EC2 콘솔을 통해 Oracle 데이터베이스를 호스팅하는 데 사용할 수 있는 Linux EC2 인스턴스를 구축하는 방법에 대한 EC2 지침 링크가 제공됩니다. 다음 섹션은 이러한 단계를 요약한 것입니다. 자세한 내용은 연결된 AWS EC2 관련 문서를 참조하십시오.</block>
  <block id="e1fc23220db46fe659667702f62b75e4" category="section-title">AWS EC2 환경 설정</block>
  <block id="6d0669826a2bd6e9eb35ea7e89cbe3f4" category="paragraph">EC2 및 FSx 서비스에서 Oracle 환경을 실행하는 데 필요한 리소스를 프로비저닝하려면 AWS 계정을 만들어야 합니다. 필요한 세부 정보는 다음 AWS 문서를 참조하십시오.</block>
  <block id="2966cbe914210fb4f4a3e5fe6adf4762" category="inline-link-macro">Amazon EC2를 사용하도록 설정합니다</block>
  <block id="1e4a01fe43fb3542c08649e20440f5f1" category="list-text"><block ref="1e4a01fe43fb3542c08649e20440f5f1" category="inline-link-macro-rx"></block></block>
  <block id="df6ca3590d3bec198846463f0ef1c6a8" category="paragraph">주요 주제:</block>
  <block id="74122bb32fc969b565a8b132d4178581" category="list-text">AWS에 등록하십시오.</block>
  <block id="fe536eddec5cc1d661347011844ba132" category="list-text">키 쌍을 생성합니다.</block>
  <block id="6582688edf89986f408a52095794f65b" category="list-text">보안 그룹을 만듭니다.</block>
  <block id="c78747962ae12e635749aa6b08a4da09" category="section-title">AWS 계정 특성에 여러 가용성 영역 설정</block>
  <block id="2d5ade6857f59cf6d198344d5049da40" category="paragraph">아키텍처 다이어그램에 표시된 Oracle 고가용성 구성의 경우 한 지역에서 최소 4개의 가용성 영역을 활성화해야 합니다. 여러 가용성 영역을 여러 지역에 배치하여 재해 복구에 필요한 거리를 충족할 수도 있습니다.</block>
  <block id="b6067af8a0645a7009ccfb45c5271f1e" category="paragraph"><block ref="b6067af8a0645a7009ccfb45c5271f1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8faa9e48d0380a023114890a62861d0f" category="section-title">Oracle 데이터베이스를 호스팅하기 위한 EC2 인스턴스 생성 및 연결</block>
  <block id="82499151e189f9313aa1450e912f4ffd" category="inline-link-macro">Amazon EC2 Linux 인스턴스를 시작합니다</block>
  <block id="822fd31d54c32c4886e9010d12a8dce7" category="paragraph">자습서를 참조하십시오 <block ref="6d0a9d65d170226042c573685041d5e9" category="inline-link-macro-rx"></block> 을 참조하십시오.</block>
  <block id="a15c0d1773407cc677a49f4cc169a63c" category="list-text">개요.</block>
  <block id="4d99c712f714ff14ae3b251667dda4b2" category="list-text">필수 구성 요소.</block>
  <block id="67b035efef4b92412bb7a8a903121da6" category="list-text">1단계: 인스턴스를 시작합니다.</block>
  <block id="6640566c783363c8a66fe226c2a7227b" category="list-text">2단계: 인스턴스에 연결합니다.</block>
  <block id="c271b00c470f8a1fb17c05dc6092d9af" category="list-text">3단계: 인스턴스를 정리하십시오.</block>
  <block id="9e0cd4f11314aeaa31fce7e3f5960c4c" category="paragraph">다음 스크린샷에서는 Oracle 실행을 위해 EC2 콘솔을 사용하여 M5 형식의 Linux 인스턴스를 구축하는 방법을 보여 줍니다.</block>
  <block id="993b6250c7c69b01670a8165c0cf949d" category="list-text">EC2 대시보드에서 노란색 Launch Instance 버튼을 클릭하여 EC2 인스턴스 구축 워크플로우를 시작합니다.</block>
  <block id="37266a1d594801e15c8f2a455a3ea854" category="paragraph"><block ref="37266a1d594801e15c8f2a455a3ea854" category="inline-image-macro-rx" type="image"></block></block>
  <block id="71a4046454ceb8a1793ee0cfa14dc581" category="list-text">1단계에서 "Red Hat Enterprise Linux 8(HVM), SSD 볼륨 유형 - AMI-0b0af3577fe5e3532(64비트 x86)/AMI-01fc429821bf1f4b4(64비트 ARM)"를 선택합니다.</block>
  <block id="755d0918a7bfcbc1b7541acd1235598e" category="paragraph"><block ref="755d0918a7bfcbc1b7541acd1235598e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5956dcc5f6331fe980094b6ddba4650c" category="list-text">2단계에서 Oracle 데이터베이스 작업 부하에 따라 적절한 CPU 및 메모리 할당이 있는 M5 인스턴스 유형을 선택합니다. "다음: 인스턴스 세부 정보 구성"을 클릭합니다.</block>
  <block id="55898408b090c35ed97aede8b9893299" category="paragraph"><block ref="55898408b090c35ed97aede8b9893299" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302a3b9b8b1d7dfc842dbfcaa5468b1a" category="list-text">3단계에서 인스턴스를 배치할 VPC 및 서브넷을 선택하고 공용 IP 할당을 활성화합니다. "다음: 스토리지 추가"를 클릭합니다.</block>
  <block id="86ec5cd603e5f7341f3f213d5b660cbb" category="paragraph"><block ref="86ec5cd603e5f7341f3f213d5b660cbb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e421be5ecc966b1d156d7f0a6f81716a" category="list-text">4단계에서 루트 디스크에 충분한 공간을 할당합니다. 스왑을 추가하려면 공간이 필요할 수 있습니다. 기본적으로 EC2 인스턴스는 0 스왑 공간을 할당하며, 이 공간은 Oracle 실행에 최적화되어 있지 않습니다.</block>
  <block id="5246bec51cd11bdee5a098fd3d3d5909" category="paragraph"><block ref="5246bec51cd11bdee5a098fd3d3d5909" category="inline-image-macro-rx" type="image"></block></block>
  <block id="843f8ce7ab50f800b312d3d109724de6" category="list-text">5단계에서 필요한 경우 인스턴스 식별용 태그를 추가합니다.</block>
  <block id="30a97756451355fd7db0bfd07cc6f667" category="paragraph"><block ref="30a97756451355fd7db0bfd07cc6f667" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f3ab3dbfdf3bf87e86423bcf042be111" category="list-text">6단계에서 기존 보안 그룹을 선택하거나 인스턴스에 대해 원하는 인바운드 및 아웃바운드 정책을 사용하여 새 보안 그룹을 생성합니다.</block>
  <block id="bdeb5b41f7c9bee78d1e7264990c0a27" category="paragraph"><block ref="bdeb5b41f7c9bee78d1e7264990c0a27" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6232d41ab5791353e400740b1c677c4b" category="list-text">7단계에서 인스턴스 구성 요약을 검토하고 시작을 클릭하여 인스턴스 배포를 시작합니다. 인스턴스에 액세스하기 위해 키 쌍을 생성하거나 키 쌍을 선택하라는 메시지가 표시됩니다.</block>
  <block id="fdd8bffe3363802212b12c3b1a7626da" category="paragraph"><block ref="8dc5efc0ebc99dc3e7017ef07cffd6c3" category="inline-image-macro-rx" type="image"></block>
<block ref="ea979786416bbc8ec09d933e3d57cfc7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="640d800543e4acd4be5582f719fe45e6" category="list-text">SSH 키 쌍을 사용하여 EC2 인스턴스에 로그인합니다. 필요에 따라 키 이름과 인스턴스 IP 주소를 변경합니다.</block>
  <block id="69321a8301f0cb7557529f92163852a6" category="paragraph">아키텍처 다이어그램에 표시된 대로 지정된 가용성 영역에 2개의 EC2 인스턴스를 운영 및 대기 Oracle 서버로 만들어야 합니다.</block>
  <block id="de55d86dd430c134cc875c8122ebfd71" category="section-title">Oracle 데이터베이스 스토리지용 ONTAP 파일 시스템용 FSx를 프로비저닝합니다</block>
  <block id="2a0b48da85066bd283380f9313f9cd2f" category="paragraph">EC2 인스턴스 구축은 운영 체제에 EBS 루트 볼륨을 할당합니다. ONTAP 파일 시스템용 FSX는 Oracle 바이너리, 데이터 및 로그 볼륨을 비롯한 Oracle 데이터베이스 스토리지 볼륨을 제공합니다. FSx 스토리지 NFS 볼륨은 AWS FSx 콘솔 또는 Oracle 설치에서 프로비저닝될 수 있으며 사용자가 자동화 매개 변수 파일에서 구성할 때 볼륨을 할당하는 구성 자동화도 가능합니다.</block>
  <block id="3560913f6885261f7b64e7cfeea69eab" category="section-title">ONTAP 파일 시스템용 FSx 생성</block>
  <block id="db188150cd7e1fbc9cfd2bc034c7b4bb" category="inline-link">ONTAP 파일 시스템용 FSx 관리</block>
  <block id="3b46f3b2334f11bf806517b04969429a" category="paragraph">이 문서를 참조했습니다<block ref="eea1efb396f41a443a43d43b53db120b" category="inline-link-rx"></block> ONTAP 파일 시스템용 FSx를 생성하는 데 사용됩니다.</block>
  <block id="f992b6bed702bc01496187fcaec0b8c6" category="paragraph">주요 고려 사항:</block>
  <block id="c6d0abeaa6d014ec6632e6b8493487d2" category="list-text">SSD 스토리지 용량: 최소 1024GiB, 최대 192TiB</block>
  <block id="2b410cef067f8cb6a53d05ad2271439b" category="list-text">프로비저닝된 SSD IOPS입니다. 워크로드 요구사항에 따라 파일 시스템당 최대 80,000 SSD IOPS</block>
  <block id="3ab61d0f90da3f61b5741ceb5eb191cc" category="list-text">처리량 용량:</block>
  <block id="94412c99e275ca9b650dc655a6e69119" category="list-text">관리자 fsxadmin/vsadmin 암호를 설정합니다. FSx 구성 자동화에 필요합니다.</block>
  <block id="c9de3d23d86cd04ff4ebf9b1458d70c4" category="list-text">백업 및 유지 관리. 자동 일일 백업을 사용하지 않도록 설정합니다. 데이터베이스 스토리지 백업은 SnapCenter 일정을 통해 실행됩니다.</block>
  <block id="b2ad37d85471ba4bcaf2c2141b1a576d" category="list-text">SVM 세부 정보 페이지에서 SVM 관리 IP 주소와 프로토콜별 액세스 주소를 검색합니다. FSx 구성 자동화에 필요합니다.</block>
  <block id="da6dd59d1114c8c42782cf7be16609b7" category="paragraph"><block ref="da6dd59d1114c8c42782cf7be16609b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="15d09dd6ced339d4022eb28264e99543" category="paragraph">기본 또는 대기 HA FSx 클러스터를 설정하려면 다음 단계별 절차를 참조하십시오.</block>
  <block id="b2232ae7fcc8b0c89d7c5f62a079a0f9" category="list-text">FSx 콘솔에서 파일 시스템 생성 을 클릭하여 FSx 프로비저닝 워크플로우를 시작합니다.</block>
  <block id="97a3753a6b826d3f7027a60fbc138cac" category="paragraph"><block ref="97a3753a6b826d3f7027a60fbc138cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8863368642c82b76b987f6f94659021d" category="list-text">NetApp ONTAP용 Amazon FSx 를 선택합니다. 다음 을 클릭합니다.</block>
  <block id="064467bccc8ccdcdddef0abbcb9694e0" category="paragraph"><block ref="064467bccc8ccdcdddef0abbcb9694e0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4912f49d35e15fbe2d9881db397feb" category="list-text">Standard Create를 선택하고 File System Details에서 파일 시스템의 이름을 Multi-AZ HA로 지정합니다. 데이터베이스 워크로드에 따라 자동 또는 사용자 프로비저닝 IOPS 최대 80,000 SSD IOPS를 선택합니다. FSX 스토리지는 백엔드에서 최대 2TiB NVMe 캐싱과 함께 제공되므로 더욱 높은 측정 IOPS를 제공할 수 있습니다.</block>
  <block id="989e0e2825ffa339331f1712bf630fb4" category="paragraph"><block ref="989e0e2825ffa339331f1712bf630fb4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="463daf4dcf56c33aa1c738fb16d15a27" category="list-text">네트워크 및 보안 섹션에서 VPC, 보안 그룹 및 서브넷을 선택합니다. FSx 배포 전에 만들어야 합니다. FSx 클러스터(기본 또는 대기)의 역할에 따라 FSx 스토리지 노드를 적절한 영역에 배치합니다.</block>
  <block id="3e99b854fb0db94f93ca0ee83bec339a" category="paragraph"><block ref="3e99b854fb0db94f93ca0ee83bec339a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="461a86bccdfc4b32cbc62af43ea97bb3" category="list-text">보안 및 암호화 섹션에서 기본값을 적용하고 fsxadmin 암호를 입력합니다.</block>
  <block id="82d80f8b6e156fcc9a64215b60433630" category="paragraph"><block ref="82d80f8b6e156fcc9a64215b60433630" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e500f789aeb2255be7988000eaff0e8" category="list-text">SVM 이름과 vsadmin 암호를 입력합니다.</block>
  <block id="84f414cec0c77118741eb2dde6127c3b" category="paragraph"><block ref="84f414cec0c77118741eb2dde6127c3b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979fcc33806fd9594ae032fb4fe33c03" category="list-text">볼륨 구성은 비워 둡니다. 이 시점에서는 볼륨을 생성할 필요가 없습니다.</block>
  <block id="9cc80fc34e28347ad7a346e723ff34ac" category="paragraph"><block ref="9cc80fc34e28347ad7a346e723ff34ac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18c8eecfeb7f2ef5acbe5fe3fc1eb398" category="list-text">Summary 페이지를 검토하고 Create File System을 클릭하여 FSx 파일 시스템 프로비저닝을 완료합니다.</block>
  <block id="992da039cb86b69379ac2a507ea018b2" category="paragraph"><block ref="992da039cb86b69379ac2a507ea018b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="edbcb61873336784ce88a841052fa45e" category="section-title">Oracle 데이터베이스용 데이터베이스 볼륨 프로비저닝</block>
  <block id="2dd5d229a6d07b62ae8943394f3a9a05" category="inline-link-macro">ONTAP 볼륨용 FSx 관리 - 볼륨 생성</block>
  <block id="846568a6ddb0b9c5539e3bffbecefada" category="paragraph">을 참조하십시오 <block ref="031a801f4fdac5974fa88d05f1809883" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="ca3a40f13fd000ce8baf0adbf73ee561" category="list-text">데이터베이스 볼륨의 크기를 적절하게 조정합니다.</block>
  <block id="383e4b0acf358da05802b9571408fa27" category="list-text">성능 구성을 위해 용량 풀 계층화 정책을 사용하지 않도록 설정합니다.</block>
  <block id="086994099a77453bffc426910b6c783b" category="list-text">NFS 스토리지 볼륨에 대해 Oracle dNFS를 사용하도록 설정합니다.</block>
  <block id="814d7476ebeabfd3208ed0432cb5ea38" category="list-text">iSCSI 스토리지 볼륨에 대한 다중 경로 설정</block>
  <block id="398cf8d5f0d4c7da2b945809849b5105" category="section-title">FSx 콘솔에서 데이터베이스 볼륨을 생성합니다</block>
  <block id="6afbf36a53c717018bd3d99a6d735c98" category="paragraph">AWS FSx 콘솔에서 Oracle 데이터베이스 파일 스토리지용 볼륨 3개를 생성할 수 있습니다. 하나는 Oracle 바이너리용이고, 다른 하나는 Oracle 데이터용이고, 다른 하나는 Oracle 로그용입니다. 볼륨 이름이 올바른 식별을 위해 Oracle 호스트 이름(자동화 툴킷의 hosts 파일에 정의되어 있음)과 일치하는지 확인하십시오. 이 예에서는 EC2 인스턴스의 일반적인 IP 주소 기반 호스트 이름 대신 db1을 EC2 Oracle 호스트 이름으로 사용합니다.</block>
  <block id="a732ebfc126f02de82d9e2cb4cba3b30" category="paragraph"><block ref="680b0ab2cf542daf748f396bdb970bee" category="inline-image-macro-rx" type="image"></block>
<block ref="7cf576b202936b23771e87094082b21e" category="inline-image-macro-rx" type="image"></block>
<block ref="9a3c4da48152c48ddee14308524b2023" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05980643a3cf9b987fd426669d474257" category="admonition">iSCSI LUN 생성은 현재 FSx 콘솔에서 지원되지 않습니다. Oracle용 iSCSI LUN 구축의 경우 NetApp 자동화 툴킷을 통해 ONTAP용 자동화 를 사용하여 볼륨 및 LUN을 생성할 수 있습니다.</block>
  <block id="09ee5fa03999e48e0789df07dd602d40" category="section-title">FSx 데이터베이스 볼륨이 있는 EC2 인스턴스에 Oracle을 설치 및 구성합니다</block>
  <block id="9f92271be71e4bc6eb96033a9ca6d798" category="paragraph">NetApp 자동화 팀은 모범 사례에 따라 EC2 인스턴스에서 Oracle 설치 및 구성을 실행할 수 있는 자동화 키트를 제공합니다. 현재 버전의 자동화 키트는 기본 RU 패치 19.8을 사용하여 NFS에서 Oracle 19c를 지원합니다. 필요한 경우 자동화 키트를 다른 RU 패치에 쉽게 적용할 수 있습니다.</block>
  <block id="61790d4e19b846282d97e8ceb58e84e0" category="section-title">자동화를 실행하도록 Ansible 컨트롤러를 준비합니다</block>
  <block id="20f3b4bca246eb128d1c7a63ca954276" category="paragraph">다음 섹션의 지침을 따르십시오."<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>"Ansible 컨트롤러를 실행할 작은 EC2 Linux 인스턴스를 프로비저닝합니다. RedHat을 사용하는 대신 2vCPU 및 8G RAM을 사용하는 Amazon Linux T2.Large로 충분합니다.</block>
  <block id="6d42906c67a4432124b27f032f56e4dc" category="section-title">NetApp Oracle 구현 자동화 툴킷을 살펴보십시오</block>
  <block id="7beb3cf1c62df8d836bddc0d2b6a3e57" category="paragraph">1단계에서 EC2-USER로 프로비저닝한 EC2 Ansible 컨트롤러 인스턴스에 로그인하고 EC2-user 홈 디렉토리에서 "git clone" 명령을 실행하여 자동화 코드 복사본을 복제합니다.</block>
  <block id="49130c144c12238cfeca4888e29fbef6" category="section-title">자동화 툴킷을 사용하여 자동화된 Oracle 19c 구축을 실행합니다</block>
  <block id="ad5d9ee07a5238092f01b66ae1b4ecca" category="paragraph">자세한 지침을 참조하십시오 <block ref="1d838bac5e7032e3241598fe6496fbd6" category="inline-link-macro-rx"></block> CLI 자동화를 통해 Oracle 19c를 구축합니다. 호스트 액세스 인증에 암호 대신 SSH 키 쌍을 사용하고 있기 때문에 플레이북 실행을 위한 명령 구문이 약간 변경됩니다. 다음 목록은 요약 정보입니다.</block>
  <block id="dc8e3956f25fc431225feacc016616b5" category="list-text">기본적으로 EC2 인스턴스는 액세스 인증을 위해 SSH 키 쌍을 사용합니다. Ansible 컨트롤러 자동화 루트 디렉토리 '/home/EC2-user/na_oracle19c_deploy' 및 '/home/EC2-user/na_RDS_FSX_oranfs_config'에서 단계에 구축된 Oracle 호스트에 대한 SSH 키 'accessstkey.pem'의 복사본을 만듭니다."<block ref="9331131dd8a4a5b5cf5956c248324151" category="inline-xref-macro-rx"></block>있습니다."</block>
  <block id="9391c5feaa671121befe114951f00442" category="list-text">EC2 인스턴스 DB 호스트에 EC2-USER로 로그인하여 python3 라이브러리를 설치합니다.</block>
  <block id="03c10a897f1e18c6adaea250b9f30f19" category="inline-link-macro">스왑 파일을 사용하여 Amazon EC2 인스턴스에서 스왑 공간으로 사용할 메모리를 어떻게 할당합니까?</block>
  <block id="85e9698f3736149506cd49ab88086364" category="list-text">루트 디스크 드라이브에서 16G 스왑 공간을 만듭니다. 기본적으로 EC2 인스턴스는 0 스왑 공간을 만듭니다. 다음 AWS 설명서를 참조하십시오. <block ref="53c9867a131506eab4afe1a1678bb974" category="inline-link-macro-rx"></block>.</block>
  <block id="be82130abf6bfa8956a5648b39ad4aa8" category="list-text">Ansible 컨트롤러('cd/home/EC2-user/na_RDS_FSX_oranfs_config')로 돌아가서 적절한 요구 사항과 'linux_config' 태그를 사용하여 사전 클론 플레이북을 실행합니다.</block>
  <block id="83e233b8fca25fb162266daf344246e4" category="list-text">'/home/EC2-user/na_oracle19c_deploy-master' 디렉토리로 전환하고 README 파일을 읽은 다음 글로벌 'vars.yml' 파일에 관련 글로벌 매개 변수를 채웁니다.</block>
  <block id="aed4b8eabfef5056093412d8609b5b9a" category="list-text">host_name.yml 파일을 host_vars 디렉토리에 관련 파라미터로 채웁니다.</block>
  <block id="4b8d8efa08e1060a3db2c7693c4de645" category="list-text">Linux용 플레이북을 실행하고 vsadmin 암호를 묻는 메시지가 표시되면 Enter 키를 누릅니다.</block>
  <block id="4d552f393608513441eb151998098b4a" category="list-text">Oracle용 플레이북을 실행하고 vsadmin 암호를 묻는 메시지가 표시되면 Enter 키를 누릅니다.</block>
  <block id="af392a54b9a2464fdd334372589f1a39" category="paragraph">필요한 경우 SSH 키 파일의 사용 권한 비트를 400으로 변경합니다. host_vars' 파일의 Oracle 호스트('abilities_host')를 EC2 인스턴스 공용 주소로 변경합니다.</block>
  <block id="ac52b3f8d77eb6814ddf5c761b019c22" category="section-title">기본 및 대기 FSx HA 클러스터 간에 SnapMirror를 설정합니다</block>
  <block id="3798adb983c6ffabbcf459359d5ddd4c" category="paragraph">고가용성 및 재해 복구를 위해 기본 및 대기 FSx 스토리지 클러스터 간에 SnapMirror 복제를 설정할 수 있습니다. 다른 클라우드 스토리지 서비스와 달리 FSx를 사용하면 원하는 빈도와 복제 처리량으로 스토리지 복제를 제어 및 관리할 수 있습니다. 또한 사용자는 가용성에 영향을 주지 않고 HA/DR을 테스트할 수 있습니다.</block>
  <block id="5414f0571ab88c4269ee945ce4291f65" category="paragraph">다음 단계에서는 운영 FSx 스토리지 클러스터와 대기 FSx 스토리지 클러스터 간에 복제를 설정하는 방법을 보여 줍니다.</block>
  <block id="006c42f009ead3331b1f69ac1979609d" category="list-text">기본 및 대기 클러스터 피어링을 설정합니다. fsxadmin 사용자로 운영 클러스터에 로그인하고 다음 명령을 실행합니다. 이 상호 생성 프로세스는 운영 클러스터와 대기 클러스터 모두에서 create 명령을 실행합니다. 'standby_cluster_name'을 환경에 적합한 이름으로 바꿉니다.</block>
  <block id="c725d46c724a573eb994f08a1f309eec" category="list-text">기본 클러스터와 대기 클러스터 간에 SVM 피어링을 설정합니다. vsadmin 사용자로 운영 클러스터에 로그인하고 다음 명령을 실행합니다. 기본_vserver_name, 'standby_vserver_name', 'tandby_cluster_name'을 환경에 적합한 이름으로 바꾸십시오.</block>
  <block id="91ba2ff3a22b9830c626441ad69c84ce" category="list-text">클러스터 및 SVM 발길이 올바르게 설정되었는지 확인합니다.</block>
  <block id="7b39dc0f7648c038ec8ac59504316d0e" category="paragraph"><block ref="7b39dc0f7648c038ec8ac59504316d0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4cb6743e20f6b87b419d9386d784acc" category="list-text">기본 FSx 클러스터의 각 소스 볼륨에 대해 스탠바이 FSx 클러스터에서 타겟 NFS 볼륨을 생성합니다. 환경에 맞게 볼륨 이름을 바꿉니다.</block>
  <block id="8f65518a43c3a1ba084510438fa2d7d3" category="list-text">iSCSI 프로토콜을 데이터 액세스에 사용하는 경우 Oracle 바이너리, Oracle 데이터 및 Oracle 로그에 대한 iSCSI 볼륨 및 LUN을 생성할 수도 있습니다. 볼륨에 약 10%의 여유 공간을 남겨 둡니다.</block>
  <block id="43aea99cd4b66a7a2f8efdc090e3a5ad" category="paragraph">vol create-volume dr_db1_log-aggregate aggr1-size 250g-state online-policy default-unix-permissions -- rwxr-XR-x-type rw</block>
  <block id="18274474e00c13f064a0b4df0b516185" category="list-text">iSCSI LUN의 경우 바이너리 LUN을 예로 사용하여 각 LUN에 대한 Oracle 호스트 이니시에이터에 대한 매핑을 생성합니다. 사용자 환경에 적합한 이름으로 igroup을 교체하고 각 추가 LUN에 대해 LUN-ID를 늘립니다.</block>
  <block id="0c2c0f6ddcbbbf39434893162abce545" category="list-text">기본 데이터베이스 볼륨과 대기 데이터베이스 볼륨 사이에 SnapMirror 관계를 생성합니다. 해당 환경에 적합한 SVM 이름을 교체합니다</block>
  <block id="a25539ee33148e6d4880b87e1378cafe" category="paragraph">이 SnapMirror 설정은 NFS 데이터베이스 볼륨용 NetApp 자동화 툴킷을 사용하여 자동화할 수 있습니다. 이 툴킷은 NetApp 공개 GitHub 사이트에서 다운로드할 수 있습니다.</block>
  <block id="f9f129d1122f9209f8f27fa07a5ee4b2" category="paragraph">설정 및 페일오버 테스트를 시도하기 전에 README 지침을 주의 깊게 읽으십시오.</block>
  <block id="03b2167f2383aa796f361c5c1c689a49" category="admonition">Oracle 바이너리를 기본 클러스터에서 대기 클러스터로 복제하면 Oracle 라이센스가 영향을 받을 수 있습니다. 자세한 내용은 Oracle 라이센스 담당자에게 문의하십시오. 또는 복구 및 페일오버 시 Oracle을 설치 및 구성해야 합니다.</block>
  <block id="fa697481d9c5655bd57d6ee69f0e9f07" category="section-title">SnapCenter 배포</block>
  <block id="3f4b23cd1391b97e8a33f3973471103b" category="section-title">SnapCenter 설치</block>
  <block id="4c88778182d61374292e3c4ad43ae50e" category="inline-link-macro">SnapCenter 서버 설치</block>
  <block id="282e73196d7c89bb5ec3820592ecee7c" category="paragraph">를 따릅니다 <block ref="9cac1dd5d049b670d2cd847d9e42d30c" category="inline-link-macro-rx"></block> SnapCenter 서버를 설치합니다. 이 문서에서는 독립 실행형 SnapCenter 서버를 설치하는 방법에 대해 설명합니다. SnapCenter SaaS 버전은 베타 검토 중이며 곧 제공될 예정입니다. 필요한 경우 NetApp 담당자에게 문의하십시오.</block>
  <block id="a4c2182f79a7834db47fccf9c264332d" category="section-title">EC2 Oracle 호스트용 SnapCenter 플러그인을 구성합니다</block>
  <block id="8d0edf4e55e8bc1a96862466762dcdd6" category="list-text">자동화된 SnapCenter 설치 후 SnapCenter 서버가 설치된 Windows 호스트의 관리 사용자로 SnapCenter에 로그인합니다.</block>
  <block id="27ee26e15e1da051ff520bf3f87f2a03" category="paragraph"><block ref="27ee26e15e1da051ff520bf3f87f2a03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4af2386526da94f1d101d825c0a623e0" category="list-text">왼쪽 메뉴에서 설정, 자격 증명 및 새로 만들기 를 차례로 클릭하여 SnapCenter 플러그인 설치를 위한 EC2 사용자 자격 증명을 추가합니다.</block>
  <block id="252932f5140410e8d8795c4236e41b47" category="paragraph"><block ref="252932f5140410e8d8795c4236e41b47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="37fc637fcb7f9b2e4336350dd7d4775e" category="list-text">EC2 인스턴스 호스트에서 '/etc/ssh/sshd_config' 파일을 편집하여 EC2-user 암호를 재설정하고 암호 SSH 인증을 활성화합니다.</block>
  <block id="c1e0ecc2d0f187a040af9ef1e783314d" category="list-text">"Sudo 권한 사용" 확인란이 선택되어 있는지 확인합니다. 이전 단계에서 EC2-user 암호를 재설정했습니다.</block>
  <block id="cc57c2c5394de6466406382d198ba244" category="paragraph"><block ref="cc57c2c5394de6466406382d198ba244" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3326cea52418b74168243fb56340785" category="list-text">이름 확인을 위해 SnapCenter 서버 이름과 IP 주소를 EC2 인스턴스 호스트 파일에 추가합니다.</block>
  <block id="59c8e627359bc3d4ce92126cbb1356cc" category="list-text">SnapCenter 서버 Windows 호스트에서 Windows 호스트 파일 'C:\Windows\System32\drivers\etc\hosts'에 EC2 인스턴스 호스트 IP 주소를 추가합니다.</block>
  <block id="4f91fe76ef9595ef98ee3b0c06a43160" category="list-text">왼쪽 메뉴에서 호스트 &gt; 관리 호스트 를 선택한 다음 추가 를 클릭하여 EC2 인스턴스 호스트를 SnapCenter에 추가합니다.</block>
  <block id="a5714b50c71edc910f423bfdc433d799" category="paragraph"><block ref="a5714b50c71edc910f423bfdc433d799" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb20727c22e9cab381fd0cd7e817ab85" category="paragraph">Oracle Database를 선택하고 제출하기 전에 기타 옵션을 클릭합니다.</block>
  <block id="7fab569defa89099ea4c5d28723e2031" category="paragraph"><block ref="7fab569defa89099ea4c5d28723e2031" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43e249b54031e8a30915659857356cab" category="paragraph">사전 설치 검사 건너뛰기 를 선택합니다. Preinstall Checks(사전 설치 검사)를 건너뛰는지 확인한 다음 Save(저장) 후 Submit(제출)을 클릭합니다.</block>
  <block id="3d82631a68b3ec0960761342005b2eca" category="paragraph"><block ref="3d82631a68b3ec0960761342005b2eca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d66b31e61ce12ed5022484588882f5f" category="paragraph">지문 확인 메시지가 표시되면 확인 및 제출 을 클릭합니다.</block>
  <block id="795d864d6ec7d5ca3d8c36c9a83bba6e" category="paragraph"><block ref="795d864d6ec7d5ca3d8c36c9a83bba6e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99177ab734274d9f5f703761e4b2deef" category="paragraph">플러그인 구성이 성공적으로 완료되면 관리 호스트의 전체 상태가 실행 중 으로 표시됩니다.</block>
  <block id="1fa50503e60bc51f7dea31d9e91c9c20" category="paragraph"><block ref="1fa50503e60bc51f7dea31d9e91c9c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="112fdeb0eaa93f627cf0effc06f49c76" category="section-title">Oracle 데이터베이스에 대한 백업 정책을 구성합니다</block>
  <block id="30baaa9bedea395f88f6183eda043198" category="paragraph">이 섹션을 참조하십시오 <block ref="5b001af64dcc5050a16c7369f5f2fae2" category="inline-link-macro-rx"></block> Oracle 데이터베이스 백업 정책 구성에 대한 자세한 내용은 를 참조하십시오.</block>
  <block id="6bfb2a8edb5f9cfb06059a588dda9cc0" category="paragraph">일반적으로 전체 스냅샷 Oracle 데이터베이스 백업에 대한 정책과 Oracle 아카이브 로그 전용 스냅샷 백업에 대한 정책을 생성해야 합니다.</block>
  <block id="708ae75a87a6997af6838bc2e5149a28" category="admonition">백업 정책에서 Oracle 아카이브 로그 잘라내기 기능을 활성화하여 로그 아카이브 공간을 제어할 수 있습니다. HA 또는 DR을 위해 대기 위치에 복제해야 하는 경우 "2차 복제 옵션 선택"에서 "로컬 스냅샷 복사본을 생성한 후 SnapMirror 업데이트"를 선택합니다.</block>
  <block id="acea2698961ae21a708203b9a9b86b94" category="section-title">Oracle 데이터베이스 백업 및 예약을 구성합니다</block>
  <block id="56f3e355b3a4359c9a0808d978ca484c" category="paragraph">SnapCenter의 데이터베이스 백업은 사용자가 구성할 수 있으며 리소스 그룹에서 개별적으로 또는 그룹으로 설정할 수 있습니다. 백업 간격은 RTO 및 RPO 목표에 따라 달라집니다. 전체 데이터베이스 백업을 몇 시간마다 실행하고 빠른 복구를 위해 10-15분 등의 높은 빈도로 로그 백업을 아카이브하는 것이 좋습니다.</block>
  <block id="cd6290f31cba79c826366f0927d0dc94" category="paragraph">의 Oracle 섹션을 참조하십시오 <block ref="6d8b99fb2ff81ed91f5551e33542f4f8" category="inline-link-macro-rx"></block> 섹션에 생성된 백업 정책을 구현하기 위한 자세한 단계별 프로세스를 참조하십시오 <block ref="f2afcb5a9b8ad2d8fe33e91cb4edb80f" category="inline-xref-macro-rx"></block> 백업 작업 스케줄링에 대한 것입니다.</block>
  <block id="b47b1d2e2c373fd6c07f22a130e90a41" category="paragraph">다음 이미지는 Oracle 데이터베이스를 백업하도록 설정된 리소스 그룹의 예입니다.</block>
  <block id="9736ab13cec4c0e5ba0c09476a101fb2" category="paragraph"><block ref="9736ab13cec4c0e5ba0c09476a101fb2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2d9cc2beb2b12bdad529e6d42551092" category="inline-link-macro">다음: 데이터베이스 관리.</block>
  <block id="454fb11269c81c93532752028abffbcd" category="paragraph"><block ref="454fb11269c81c93532752028abffbcd" category="inline-link-macro-rx"></block></block>
  <block id="8a1d7e9120e3db2795bd53b504018b4e" category="summary">이 백서에서는 여러 가용성 영역 구축에서 AWS FSx 스토리지 서비스를 활용하여 AWS 맞춤형 Oracle RDS 데이터베이스 HA 및 DR용 솔루션의 개요와 검증을 제공합니다.</block>
  <block id="b4c8c277e19db14e178b1060214b896e" category="paragraph">Allen Cao, Niyaz Mohamed, Jeffrey Steiner, NetApp</block>
  <block id="6848412b0f30d614f7e0bcd903cac052" category="paragraph">많은 미션 크리티컬 엔터프라이즈 Oracle 데이터베이스는 여전히 사내에서 호스팅되며, 많은 기업은 이러한 Oracle 데이터베이스를 퍼블릭 클라우드로 마이그레이션하려고 합니다. 종종 이러한 Oracle 데이터베이스는 애플리케이션 중심이므로 많은 서비스형 데이터베이스 퍼블릭 클라우드 오퍼링에서 누락되는 사용자별 구성이 필요합니다. 따라서 현재의 데이터베이스 환경에서는 고유한 요구 사항을 수용할 수 있는 고성능의 확장 가능한 컴퓨팅 및 스토리지 서비스를 통해 구축된 퍼블릭 클라우드 기반 Oracle 데이터베이스 솔루션이 필요합니다. AWS EC2 컴퓨팅 인스턴스 및 AWS FSx 스토리지 서비스는 미션 크리티컬 Oracle 데이터베이스 워크로드를 퍼블릭 클라우드로 구축 및 마이그레이션하는 데 활용할 수 있는 이 퍼즐의 누락된 조각일 수 있습니다.</block>
  <block id="37b7c86d51875922e0a9f122a670aa62" category="paragraph">Amazon EC2(Amazon Elastic Compute Cloud)는 클라우드에서 안전하고 크기 조정이 가능한 컴퓨팅 용량을 제공하는 웹 서비스입니다. 이 솔루션은 기업이 웹 기반 클라우드 컴퓨팅을 보다 쉽게 사용할 수 있도록 설계되었습니다. 간단한 Amazon EC2 웹 서비스 인터페이스를 사용하면 최소한의 마찰로 용량을 확보하고 구성할 수 있습니다. 컴퓨팅 리소스를 완벽하게 제어하고 Amazon의 검증된 컴퓨팅 환경에서 실행할 수 있습니다.</block>
  <block id="c9550c9d9c1b379ad427d739b5c69f00" category="paragraph">ONTAP용 Amazon FSx는 업계 최고의 NetApp ONTAP 블록 및 파일 스토리지를 사용하는 AWS 스토리지 서비스로, NFS, SMB 및 iSCSI를 제공합니다. 이처럼 강력한 스토리지 엔진을 사용하여 1밀리초 미만의 응답 시간, 수 Gbps의 처리량, 데이터베이스 인스턴스당 100,000 이상의 IOPS를 제공하는 미션 크리티컬 Oracle 데이터베이스 애플리케이션을 AWS로 재배치하는 것이 그 어느 때보다 쉬워졌습니다. 또한 FSx 스토리지 서비스에는 기본 복제 기능이 포함되어 있어 온프레미스 Oracle 데이터베이스를 AWS로 쉽게 마이그레이션하거나 미션 크리티컬 Oracle 데이터베이스를 HA 또는 DR용 보조 AWS 가용성 영역으로 복제할 수 있습니다.</block>
  <block id="b3f95d0186b2e4989ad81f07a21d72c5" category="paragraph">이 문서의 목표는 FSx 스토리지와 내부 시스템과 유사한 성능을 제공하는 EC2 인스턴스를 사용하여 Oracle 데이터베이스를 구축하고 구성하는 방법에 대한 단계별 프로세스, 절차 및 모범 사례 지침을 제공하는 것입니다. 또한 NetApp은 AWS 퍼블릭 클라우드에서 Oracle 데이터베이스 워크로드를 구현, 구성, 관리하는 데 필요한 대부분의 작업을 자동화하는 자동화 툴킷을 제공합니다.</block>
  <block id="15d62938aed0de1248a55c07bc0c547c" category="paragraph"><block ref="15d62938aed0de1248a55c07bc0c547c" category="inline-link-macro-rx"></block></block>
  <block id="32800a2387c1d841d80eab97ff7205c2" category="summary">이 섹션에서는 AWS EC2 인스턴스 및 FSx 스토리지에 Oracle 데이터베이스를 구축할 때 고려해야 할 요소에 대해 자세히 설명합니다.</block>
  <block id="c53749244d982efb6aa5653328227c2a" category="doc">Oracle 데이터베이스 구축에 고려해야 할 요인</block>
  <block id="0dd9b4b69c30ae87b4322df28758dc18" category="paragraph"><block ref="0dd9b4b69c30ae87b4322df28758dc18" category="inline-link-macro-rx"></block></block>
  <block id="96f819dcc02d1203a3923ddad366ff4b" category="paragraph">퍼블릭 클라우드는 다양한 컴퓨팅 및 스토리지 옵션을 제공하므로 정확한 유형의 컴퓨팅 인스턴스 및 스토리지 엔진을 사용하여 데이터베이스를 구축할 수 있습니다. 또한 Oracle 데이터베이스에 최적화된 컴퓨팅 및 스토리지 구성을 선택해야 합니다.</block>
  <block id="e958329ac331abb8419551328745ce28" category="paragraph">다음 섹션에서는 FSx 스토리지가 있는 EC2 인스턴스의 AWS 퍼블릭 클라우드에서 Oracle 데이터베이스를 구축할 때의 주요 고려 사항에 대해 설명합니다.</block>
  <block id="af9adf45d47438d70bedeea4353827c3" category="paragraph">공용 클라우드에서 관계형 데이터베이스의 성능을 최적화하려면 올바른 VM 크기를 선택하는 것이 중요합니다. 더 나은 성능을 위해 데이터베이스 워크로드에 최적화된 EC2 M5 Series 인스턴스를 Oracle 구축에 사용하는 것이 좋습니다. AWS에서 Oracle용 RDS 인스턴스를 실행하는 데에도 같은 인스턴스 유형이 사용됩니다.</block>
  <block id="1dbc89cff7796dd99cbe9338453d04d7" category="list-text">워크로드 특성에 따라 올바른 vCPU 및 RAM 조합을 선택합니다.</block>
  <block id="ff1a938ecebc5237c31b8f5d9a9b87ce" category="list-text">VM에 스왑 공간을 추가합니다. 기본 EC2 인스턴스 구축은 데이터베이스에 적합하지 않은 스왑 공간을 생성하지 않습니다.</block>
  <block id="d4d5d0e2fb33dadfad4435489bd718a4" category="section-title">스토리지 레이아웃 및 설정</block>
  <block id="0fe994abd6c200feb672e77242fe9fcb" category="paragraph">권장되는 스토리지 레이아웃은 다음과 같습니다.</block>
  <block id="c1b542506bceb69c76148851e217c49f" category="list-text">NFS 스토리지의 경우 권장되는 볼륨 레이아웃은 세 개의 볼륨입니다. 하나는 Oracle 바이너리용이고, 다른 하나는 Oracle 데이터 및 중복 제어 파일용이며, 다른 하나는 Oracle 액티브 로그, 아카이브 로그 및 제어 파일용입니다.</block>
  <block id="02833700de6eac537733ce81ef6352a3" category="paragraph"><block ref="02833700de6eac537733ce81ef6352a3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9fc828f321000aae204feb1f0f945893" category="list-text">iSCSI 스토리지의 경우 권장되는 볼륨 레이아웃은 Oracle 바이너리용 볼륨 1개, Oracle 데이터 및 중복 제어 파일용 볼륨 1개, Oracle 액티브 로그, 아카이브 로그 및 제어 파일용 볼륨 3개입니다. 그러나 각 데이터 및 로그 볼륨에는 4개의 LUN이 포함되어 있어야 합니다. LUN은 HA 클러스터 노드에서 균형을 유지하는 것이 이상적입니다.</block>
  <block id="cddd034875839504dacaa29e5dca803f" category="paragraph"><block ref="cddd034875839504dacaa29e5dca803f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7810ed5b0bbb3acf153d353ac803a51" category="list-text">스토리지 IOPS 및 처리량의 경우 FSx 스토리지 클러스터의 프로비저닝된 IOPS 및 처리량에 대한 임계값을 선택할 수 있으며, 워크로드가 변경될 때마다 이러한 매개 변수를 즉석에서 조정할 수 있습니다.</block>
  <block id="c5493cd0fe001da987655ad852808dc7" category="list-text">자동 IOPS 설정은 할당된 스토리지 용량 또는 최대 80,000개의 사용자 정의 스토리지 용량(GiB)당 3IOPS입니다.</block>
  <block id="6524d7ff1096fc6a10590b6d1f7163b6" category="list-text">처리량 수준은 128, 256, 512, 1024, 2045Mbps와 같이 증가합니다.</block>
  <block id="bc4bb24d5e702fb79be623b84e7cf47e" category="inline-link-macro">NetApp ONTAP 성능을 위한 Amazon FSx</block>
  <block id="b59267e60b3253fa9c2edeed17c1340f" category="paragraph">를 검토합니다 <block ref="a572b0e55a3a15b7b3460602e8714ba1" category="inline-link-macro-rx"></block> 처리량 및 IOPS 사이징 관련 문서</block>
  <block id="10edbbba4e4c39fc161aeac9fbb88aef" category="section-title">NFS 구성</block>
  <block id="b6e1b7fd7aad364a8ad758d8ae8ba50d" category="paragraph">가장 일반적인 운영 체제인 Linux에는 네이티브 NFS 기능이 포함되어 있습니다. Oracle은 Oracle에 기본적으로 통합된 직접 NFS(dNFS) 클라이언트를 제공합니다. Oracle은 20년 이상 NFSv3을 지원해 왔으며 NFSv4는 Oracle 12.1.0.2 이상에서 지원됩니다. NetApp 자동화 툴킷을 사용하여 자동화된 Oracle 구축은 NFSv3에서 dNFS를 자동으로 구성합니다.</block>
  <block id="2b7570eaa12a3e472e9d0cbac6631d57" category="paragraph">기타 고려 사항:</block>
  <block id="6841f6ce9d9a2af93222223df564ca34" category="list-text">TCP 슬롯 테이블은 호스트 버스 어댑터(HBA) 큐 길이(queue depth)와 동등한 NFS의 기능입니다. 이들 테이블은 한 번에 수행될 수 있는 최대 NFS 작업의 수를 제어합니다. 기본값은 보통 16이며 최적의 성능을 발휘하기에 너무 낮습니다. 최신 Linux 커널에서는 반대의 문제가 발생하는데, 요청을 통해 NFS 서버를 포화시키는 수준까지 TCP 슬롯 테이블의 한계를 자동으로 높일 수 있습니다.</block>
  <block id="5a749fcdd97cee211c5fea00babe8691" category="paragraph">최적의 성능을 제공하고 성능 문제를 방지하려면 TCP 슬롯 테이블을 제어하는 커널 매개 변수를 128로 조정합니다.</block>
  <block id="dcd7ebfa96f217f8d20c58a185a48531" category="list-text">다음 표에는 Linux NFSv3 - 단일 인스턴스에 대한 권장 NFS 마운트 옵션이 나와 있습니다.</block>
  <block id="4780ee7b64d0ec83e06977206e8a35b5" category="paragraph"><block ref="4780ee7b64d0ec83e06977206e8a35b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4492ef7005cdef278b0b767179a1ecb9" category="admonition">dNFS를 사용하기 전에 Oracle Doc 1495104.1에 설명된 패치가 설치되어 있는지 확인하십시오. Oracle 12c를 시작으로 DNFS에는 NFSv3, NFSv4, NFSv4.1 지원이 포함되어 있습니다. NetApp 지원 정책은 모든 클라이언트에서 v3 및 v4를 지원하지만 작성 당시에는 NFSv4.1이 Oracle dNFS에 사용하도록 지원되지 않습니다.</block>
  <block id="2fe1fc26875d6d38f4b15a3a03d498fb" category="paragraph">솔루션 아키텍처에 설명된 대로 HA는 스토리지 레벨 복제를 기반으로 합니다. 따라서 Oracle의 시작 및 가용성은 컴퓨팅 및 스토리지를 얼마나 빠르게 가동 및 복구할 수 있는지에 따라 다릅니다. 다음 주요 요소를 참조하십시오.</block>
  <block id="137bc4c57a9561d086601728a3db1a90" category="list-text">대기 컴퓨팅 인스턴스를 준비하고 두 호스트에 대한 Ansible 병렬 업데이트를 통해 기본 컴퓨팅 인스턴스와 동기화하십시오.</block>
  <block id="d653e9032c9904901af96f496db98a3e" category="list-text">맨 마지막에 Oracle을 설치할 필요가 없도록 기본 볼륨에서 바이너리 볼륨을 복제하고 설치 및 패치 작업을 수행해야 하는 항목을 파악할 수 있습니다.</block>
  <block id="77991416cd2e0bfc66a77d32e3fbb45a" category="list-text">복제 빈도는 서비스를 사용할 수 있도록 Oracle 데이터베이스를 복구하는 속도를 나타냅니다. 복제 빈도와 스토리지 소비는 서로 상충됩니다.</block>
  <block id="0797ee9bca14d1064492a93ac7cc7fa1" category="list-text">자동화를 활용하여 복구를 수행하고 인적 오류 없이 신속하게 대기 상태로 전환합니다. NetApp은 이러한 목적을 위한 자동화 툴킷을 제공합니다.</block>
  <block id="0a076fda3d30e9959f9332ce7c42445c" category="paragraph"><block ref="0a076fda3d30e9959f9332ce7c42445c" category="inline-link-macro-rx"></block></block>
  <block id="90a0d380974aa73acb8330f1ff9a7930" category="summary">이 섹션에서는 사내에서 AWS EC2 인스턴스 및 FSx 스토리지로 Oracle 데이터베이스를 마이그레이션할 때 고려해야 할 요소에 대해 자세히 설명합니다.</block>
  <block id="895a8d39dd9ae7fe795349bdbc3f05dc" category="doc">사내에서 퍼블릭 클라우드로 데이터베이스 마이그레이션</block>
  <block id="64d625665f42751b8036cb9a6403a0fe" category="inline-link-macro">이전: 데이터베이스 관리.</block>
  <block id="69dd1b6ab585f33a36445376492ea8de" category="paragraph"><block ref="69dd1b6ab585f33a36445376492ea8de" category="inline-link-macro-rx"></block></block>
  <block id="373ae4e24c2daa280a4a5aca82dd3818" category="paragraph">데이터베이스 마이그레이션은 어떤 방법으로든 어려운 작업입니다. Oracle 데이터베이스를 사내에서 클라우드로 마이그레이션하는 경우도 예외는 아닙니다.</block>
  <block id="d1e968e04e34c971d41e644820094cef" category="paragraph">다음 섹션에서는 Oracle 데이터베이스를 AWS EC2 컴퓨팅 및 FSx 스토리지 플랫폼을 통해 AWS 퍼블릭 클라우드로 마이그레이션할 때 고려해야 할 주요 요소를 제공합니다.</block>
  <block id="84639b5fb3b348e6a053dde95414e039" category="section-title">ONTAP 스토리지는 온프레미스에서 사용할 수 있습니다</block>
  <block id="df2111c23e70fa013a85041e1415639e" category="list-text">온프레미스 인스턴스와 일치하는 타겟 컴퓨팅 EC2 인스턴스를 구축합니다.</block>
  <block id="1931f75e563d3dc9ee112e9b4ebd66b7" category="list-text">FSx 콘솔에서 동일한 크기의 일치하는 데이터베이스 볼륨을 프로비저닝합니다.</block>
  <block id="98201e355445ae8a2eff3b7c33132cc6" category="list-text">FSx 데이터베이스 볼륨을 EC2 인스턴스에 마운트합니다.</block>
  <block id="53fad15133e494dc37bbd0494b8f3a6c" category="list-text">온프레미스 데이터베이스 볼륨에서 타겟 FSx 데이터베이스 볼륨으로의 SnapMirror 복제를 설정합니다. 초기 동기화는 운영 소스 데이터를 이동하는 데 시간이 다소 걸릴 수 있지만 다음과 같은 증분 업데이트는 훨씬 더 빠릅니다.</block>
  <block id="8da4f0ed2ee5c7e68c3fe9ec3dde280e" category="list-text">미러링된 볼륨을 분할하고 타겟에서 Oracle 복구를 실행하고 서비스를 위해 데이터베이스를 불러옵니다.</block>
  <block id="6efd103fd0a488a3d023523ab6377e4e" category="list-text">애플리케이션을 클라우드의 Oracle 데이터베이스에 지정</block>
  <block id="86afa353cad293784396216eab80ee52" category="section-title">ONTAP 스토리지는 온프레미스에서 사용할 수 없습니다</block>
  <block id="c11080183211191097c120f87656c802" category="paragraph">사내 Oracle 데이터베이스가 ONTAP 이외의 타사 스토리지에서 호스팅되는 경우 데이터베이스 마이그레이션은 Oracle 데이터베이스 백업 복사본의 복원을 기반으로 합니다. 전환하기 전에 아카이브 로그를 재생하여 최신 상태로 만들어야 합니다.</block>
  <block id="722283478873a13974c4b1b6ea967a40" category="paragraph">AWS S3를 데이터베이스 이동 및 마이그레이션을 위한 스테이징 스토리지 영역으로 사용할 수 있습니다. 이 방법에 대한 자세한 내용은 다음 단계를 참조하십시오.</block>
  <block id="9312555163563ac6b35994e42f15d009" category="list-text">사내 인스턴스와 유사한 새로운 EC2 인스턴스를 프로비저닝합니다.</block>
  <block id="8705a6dedde3ea188c113bda4fe97c14" category="list-text">FSx 스토리지에서 동일한 데이터베이스 볼륨을 프로비저닝하고 EC2 인스턴스에 볼륨을 마운트합니다.</block>
  <block id="6aeff6e3d9f2f107fa5584191966f816" category="list-text">디스크 레벨의 Oracle 백업 복사본을 생성합니다.</block>
  <block id="0f90c0c06dae8f50c3f93d33a7547df2" category="list-text">백업 복사본을 AWS S3 스토리지로 이동합니다.</block>
  <block id="d8fd670e7724b3db99919ea02cd762cc" category="list-text">S3 스토리지에서 데이터와 아카이브 로그를 가져와 Oracle 제어 파일을 다시 생성하고 데이터베이스를 복원 및 복구합니다.</block>
  <block id="c4a99d505e8ebe4d5f04ae86d2a724b7" category="list-text">타겟 Oracle 데이터베이스를 사내 소스 데이터베이스와 동기화합니다.</block>
  <block id="3bac7326688b384ce82c7c9807cae4b7" category="list-text">전환 시 애플리케이션과 소스 Oracle 데이터베이스를 종료합니다. 최근 몇 개의 아카이브 로그를 복사하여 대상 Oracle 데이터베이스에 적용하여 최신 상태로 만듭니다.</block>
  <block id="98cf6a7f87338026b5b95afee91d5676" category="list-text">사용자 액세스를 위해 대상 데이터베이스를 시작합니다.</block>
  <block id="021e473c3a779caff7d794ce36c8ef68" category="list-text">대상 데이터베이스로 애플리케이션을 리디렉션하여 전환을 완료합니다.</block>
  <block id="a8fba1abc3fbaa027d18daed3f6e170d" category="doc">MetalLB 로드 밸런서 설치</block>
  <block id="48501496ee9b06b63701de94b6ffc3a5" category="paragraph">이 페이지에는 MetalLB 관리 로드 밸런서에 대한 설치 및 구성 지침이 나와 있습니다.</block>
  <block id="ccd779a5e754b22c1589256334866c0a" category="paragraph">MetalLB 로드 밸런서는 VMware의 Anthos 클러스터와 완벽하게 통합되며 1.11 릴리즈부터 관리 및 사용자 클러스터 설정의 일부로 자동 배포가 수행됩니다. 각 '클러스터.YAML' 구성 파일에는 로드 밸런서 정보를 제공하기 위해 수정해야 하는 텍스트 블록이 있습니다. 지원되는 다른 로드 밸런서 솔루션과 같은 외부 리소스를 구축해야 하는 대신, Anthos 클러스터에서 자체 호스팅됩니다. 또한, 클라우드 공급자에서 실행되지 않는 클러스터에서 로드 밸런서 유형의 Kubernetes 서비스를 생성하여 주소를 자동으로 할당하는 IP 풀을 생성할 수도 있습니다.</block>
  <block id="b938ac6243408826bd53c58d2a6a6f1f" category="paragraph">Anthos admin의 MetalLB 로드 밸런서를 활성화할 때는 'admin-cluster.yAML' 파일에 있는 'loadbalancer:' 섹션에서 몇 줄을 수정해야 합니다. 수정해야만 하는 유일한 값은 'controlPlaneVIP:' 주소를 설정한 다음 'kind:'를 MetalLB로 설정하는 것입니다. 예제를 보려면 다음 코드 조각을 참조하십시오.</block>
  <block id="79fdf71abab382ca3fbab93d863f835c" category="paragraph">Anthos 사용자 클러스터에 대한 MetalLB 로드 밸런서를 활성화할 때 업데이트해야 하는 각 "user-cluster.yAML" 파일에는 두 가지 영역이 있습니다. 먼저 ADMIN-cluster.YAML 파일과 비슷한 방식으로 controlPlaneVIP:, ressVIP:, Kind: 등의 값을 'loadbalancer:' 섹션의 값으로 수정해야 합니다. 예제를 보려면 다음 코드 조각을 참조하십시오.</block>
  <block id="c173f58ae6718fb7dc80d6ddb9b392e5" category="admonition">ingressVIP IP 주소는 나중에 구성에서 MetalLB 로드 밸런서에 할당된 IP 주소 풀 내에 있어야 합니다.</block>
  <block id="77960f17a334c28c4bacd9515ac55817" category="paragraph">그런 다음 metalLB: 하위 섹션으로 이동하여 -name: 변수에 풀 이름을 지정하여 addressPools: 섹션을 수정해야 합니다. 또한 MetalLB가 'address:' 변수에 범위를 제공하여 부하 분산 서비스의 서비스에 할당할 수 있는 IP 주소 풀을 만들어야 합니다.</block>
  <block id="8dfd015968f24ba6c3e2d8386cd40cbe" category="admonition">주소 풀은 예를 들어 특정 서브넷의 여러 주소로 제한하거나 전체 서브넷을 사용할 수 있는 경우 CIDR 표기법으로 제공할 수 있습니다.</block>
  <block id="ea4a20324a094d5f515252d5669a60ca" category="list-text">로드 밸런서 유형의 Kubernetes 서비스가 생성되면 MetalLB는 서비스에 외부 IP를 자동으로 할당하고 ARP 요청에 응답하여 IP 주소를 알립니다.</block>
  <block id="c09bdf0c852b6f771b10fb71482778db" category="paragraph">애플리케이션의 백업은 애플리케이션의 활성 상태와 해당 리소스의 구성을 캡처하여 파일로 저장한 다음 원격 오브젝트 스토리지 버킷에 저장합니다.</block>
  <block id="3805fe09ab2fab11e5a88285db1ba4f1" category="paragraph">응용 프로그램 백업을 만들려면 다음 단계를 수행하십시오.</block>
  <block id="17937980068cd45516e074151c756bab" category="list-text">Astra Control Center에서 관리 대상 응용 프로그램의 백업을 생성하려면 Apps &gt; Managed 로 이동한 다음 백업을 수행할 응용 프로그램을 클릭합니다. 응용 프로그램 이름 옆의 드롭다운 메뉴를 클릭하고 백업을 클릭합니다.</block>
  <block id="d587342349a123dddff71bef9eb7b6e6" category="paragraph">응용 프로그램을 복원하려면 다음 단계를 수행하십시오.</block>
  <block id="804e8c9205cc0caea9e5cb6645febba7" category="list-text">앱 &gt; 관리 탭으로 이동하고 해당 앱을 클릭합니다. 응용 프로그램 이름 옆의 드롭다운 메뉴를 클릭하고 복원 을 클릭합니다.</block>
  <block id="b0ff29eefb84e5d7a2cdae616ae42213" category="list-text">새 네임스페이스의 세부 정보를 입력하고 복제할 클러스터를 선택한 다음 기존 스냅샷, 백업 또는 애플리케이션의 현재 상태에서 클론을 생성할지 여부를 선택합니다. 세부 정보를 검토한 후 다음 을 클릭하고 검토 창에서 복제 를 클릭합니다.</block>
  <block id="4c0e19abe22935505e774d4d3b2e8449" category="list-text">새 애플리케이션이 검색 상태로 전환되지만 Astra Control Center는 선택한 클러스터에 애플리케이션을 생성합니다. 응용 프로그램의 모든 리소스가 Astra에 의해 설치 및 감지되면 응용 프로그램은 사용 가능 상태로 전환됩니다.</block>
  <block id="858674153e1f55409f3ea08cdc502f53" category="inline-link-macro">다음: 고급 구성 옵션.</block>
  <block id="9bb9f32bf0692d68fe53042de73b0c6a" category="paragraph"><block ref="9bb9f32bf0692d68fe53042de73b0c6a" category="inline-link-macro-rx"></block></block>
  <block id="abb33c60fb7710d77680621bb6bb0433" category="doc">F5 BIG-IP 로드 밸런서 설치</block>
  <block id="4f3422718812b2a40b70340da35b565c" category="paragraph">F5 BIG-IP는 ADC(Application Delivery Controller)로서 L4-L7 로드 밸런싱, SSL/TLS 오프로드, DNS, 방화벽 등과 같은 다양한 고급 프로덕션 등급 트래픽 관리 및 보안 서비스를 제공합니다. 이러한 서비스는 애플리케이션의 가용성, 보안 및 성능을 대폭 향상시킵니다.</block>
  <block id="81d91349803cba0e1b0d0f84948ff37c" category="paragraph">F5 BIG-IP는 전용 하드웨어, 클라우드 또는 온프레미스 가상 어플라이언스 등 다양한 방식으로 배포 및 사용할 수 있습니다. F5 BIG-IP를 탐색하고 배포하려면 여기 있는 설명서를 참조하십시오.</block>
  <block id="cb9f661ea2c5b0b25cb936398de81286" category="admonition">F5 BIG-IP는 독립 실행형 모드 또는 클러스터 모드로 구축할 수 있습니다. 이러한 검증을 위해 F5 BIG-IP는 독립 실행형 모드로 배포되었습니다. 그러나 운영 목적상 단일 장애 지점을 피하기 위해 빅IP 인스턴스 클러스터를 생성하는 것이 좋습니다.</block>
  <block id="9c62eb7c12e4e6a75fc74fffecb2db09" category="paragraph">NetApp의 솔루션 엔지니어링 팀은 당사 랩의 다음 표에 있는 릴리스가 사내 Anthos의 배포와 연동되어 작동되고 있다는 것을 검증했습니다.</block>
  <block id="930835cee46ee894bb92b5627c286380" category="paragraph"><block ref="930835cee46ee894bb92b5627c286380" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5869793ca55f5fc50960cbd965138c70" category="inline-image-macro">Big_IP 어플라이언스 구축, 2부</block>
  <block id="b395903460348cc88bfae6fcad255f21" category="paragraph"><block ref="b395903460348cc88bfae6fcad255f21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ca9eda681850d46169f2940362b1548f" category="inline-image-macro">Big-IP 어플라이언스 구축, 3부</block>
  <block id="9c7b1162de6217dfe316b9d57d67b16f" category="paragraph"><block ref="9c7b1162de6217dfe316b9d57d67b16f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="372bcca75330a5dc5675a722489ff49b" category="paragraph"><block ref="372bcca75330a5dc5675a722489ff49b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e7de45031877e6ff00d3069664fbcaf" category="inline-image-macro">BIG-IP 구성, 2부</block>
  <block id="cee8fbb1e19d03d10bbd1e01e76cf77b" category="paragraph"><block ref="cee8fbb1e19d03d10bbd1e01e76cf77b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b648434aacde9879c494bb807f510d0a" category="inline-image-macro">BIG-IP 구성, 3부</block>
  <block id="abc7fe3f8ac78f7eef2f5ca730be051c" category="paragraph"><block ref="abc7fe3f8ac78f7eef2f5ca730be051c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48f2578529c2f8c811567604f610cb5f" category="inline-image-macro">BIG-IP 구성, 4부</block>
  <block id="7032ef2cca6e17b4d3590ecbbce7ff16" category="paragraph"><block ref="7032ef2cca6e17b4d3590ecbbce7ff16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c9fd499e062b35d18ef68efd381c6c09" category="inline-image-macro">BIG-IP 구성, 6부</block>
  <block id="78df99aca47bd680a19574eebccf4249" category="paragraph"><block ref="78df99aca47bd680a19574eebccf4249" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4e4f5e5f31a0b8312fb2338d9015dd0" category="inline-image-macro">BIG-IP 구성, 7부</block>
  <block id="72cb9d54a4958e24c358ee0871b24454" category="paragraph"><block ref="72cb9d54a4958e24c358ee0871b24454" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c574654bbbf1cf9927e54a1cf4152c71" category="list-text">마법사의 첫 번째 페이지에서 이중화를 구성합니다. 기본값을 그대로 두고 Next를 클릭합니다. 다음 페이지에서는 로드 밸런서에 내부 인터페이스를 구성할 수 있습니다. 인터페이스 1.1은 OVF 배포 마법사에서 내부 레이블이 지정된 VMNIC에 매핑됩니다.</block>
  <block id="19ee7bbff17fca60aeffed9079a87c6b" category="inline-image-macro">BIG-IP 구성, 8부</block>
  <block id="93e0638cb95146eb8773223a90aa6d86" category="list-text">다음 페이지에서는 Kubernetes에 구축된 Pod에 서비스를 매핑하는 데 사용되는 외부 네트워크를 구성할 수 있습니다. VM_Network 범위, 해당 서브넷 마스크 및 해당 범위의 부동 IP에서 고정 IP를 선택합니다. 인터페이스 1.2는 OVF 배포 마법사에서 External이라고 표시된 VMNIC에 매핑됩니다.</block>
  <block id="803c8b846cb5b5c6c8d5a2b0b07f4dba" category="inline-image-macro">BIG-IP 구성, 9부</block>
  <block id="9cd42351da162e75b1a0178bdd0ded20" category="inline-image-macro">BIG-IP 구성, 10부</block>
  <block id="ad99125325ea694a08a4db92eabb18a1" category="inline-image-macro">BIG-IP 구성, 11부</block>
  <block id="d71ac8787685cb0f3b8f800520d684b1" category="paragraph"><block ref="d71ac8787685cb0f3b8f800520d684b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="99a0344c261b0475e6caf01bb585530f" category="list-text">표시된 화면에는 현재 공통 파티션만 표시됩니다. 오른쪽에서 Create를 클릭하여 첫 번째 추가 파티션을 만들고 이름을 GKE-Admin 으로 지정합니다. 그런 다음 반복 을 클릭하고 파티션 이름을 사용자 클러스터 1 로 지정합니다. Repeat 버튼을 다시 클릭하여 다음 파티션 이름을 User-Cluster-2 로 지정합니다. 마지막으로 완료 를 클릭하여 마법사를 완료합니다. Partition list(파티션 목록) 화면이 모든 파티션을 나열한 상태로 돌아갑니다.</block>
  <block id="938c47fe40c045ae4bc242bf2339ab01" category="inline-image-macro">BIG-IP 구성, 12부</block>
  <block id="598f9d349e1cb4c318e78a0d182dd743" category="paragraph"><block ref="598f9d349e1cb4c318e78a0d182dd743" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1dc19630e1d9c7f2a85a541796c5ec51" category="paragraph">각 구성 파일에는 관리 클러스터에 대한 섹션과 온프레미스 Anthos가 관리하도록 부하 분산 장치를 구성하기 위해 배포하기로 선택한 각 사용자 클러스터가 각각 하나씩 있습니다.</block>
  <block id="38779167fbee63015f17c4c1b453dd32" category="paragraph">다음 스크립트는 GKE-Admin 클러스터에 대한 파티션 구성의 샘플입니다. 주석 및 수정이 필요한 값은 아래 굵은 텍스트로 표시됩니다.</block>
  <block id="288c554e356764c1144e77f0d78f97bf" category="doc">로드 밸런서 옵션 탐색</block>
  <block id="807a04fd6be3315608f66b00ab708987" category="paragraph">Anthos에 배포된 애플리케이션은 Anthos의 온프레미스 환경에 배포된 로드 밸런서에 의해 제공되는 서비스에 의해 전 세계에 노출됩니다.</block>
  <block id="4f8cee548fdf2c886e16bf694eb06522" category="paragraph"><block ref="4f8cee548fdf2c886e16bf694eb06522" category="inline-link-macro-rx"></block></block>
  <block id="dc89b61e16e84216193885f3a7c62fb9" category="inline-link-macro">다음: Red Hat OpenShift Cluster를 등록하십시오.</block>
  <block id="13d5bf8d97a187ca5d13b7429c268342" category="paragraph"><block ref="13d5bf8d97a187ca5d13b7429c268342" category="inline-link-macro-rx"></block></block>
  <block id="7cdcf7845d98f304186a5184cd2161ac" category="inline-link-macro">다음은 NetApp ONTAP의 차례입니다.</block>
  <block id="1a4c8966068ddb4b2fda6d5bc54054c3" category="paragraph"><block ref="1a4c8966068ddb4b2fda6d5bc54054c3" category="inline-link-macro-rx"></block></block>
  <block id="a5fcf88905522eca0a7500198fc13ea9" category="paragraph">예를 들면 다음과 같습니다.</block>
  <block id="231a9d200c75839cf9b4ffeecde45821" category="list-text">*자신의 Linux OS를 가져오십시오.* Anthos-on-bare-metal 환경을 배포할 Linux OS를 선택하면 Anthos 환경이 기존 인프라 및 관리 체계에 잘 맞는지 확인할 수 있습니다.</block>
  <block id="8f3c025cf8c4fb1a7841163ea4213611" category="list-text">성능 향상 및 비용 절감. * 하이퍼바이저가 없어도 Anthos-on-bare-metal 클러스터는 GPU와 같이 성능에 최적화된 하드웨어 장치를 비롯한 서버 하드웨어 리소스에 직접 액세스할 수 있어야 합니다.</block>
  <block id="5c96e444541cebd597916a4a84177f6b" category="list-text">* 네트워크 성능 향상 및 지연 시간 감소. * Anthos-on-bare-metal 서버 노드는 가상화된 추상화 계층 없이 네트워크에 직접 연결되므로 지연 시간과 성능을 낮게 최적화할 수 있습니다.</block>
  <block id="08c2b93847522285403aa57a50c67356" category="paragraph">Anthos-on-bare-metal 노드는 고객이 선택한 여러 가지 Linux 배포판으로 구성하여 현재 데이터센터 인프라에 맞게 지원할 수 있습니다.</block>
  <block id="cb9cc8981898224a2fe45ac6ff7d4244" category="cell">1.11</block>
  <block id="969f1705e87aebac2415f45faaf8ef89" category="cell">A250, A220</block>
  <block id="6ff97c39e8de9255f8ab9ffb6a483dce" category="cell">9.9.1, 9.10.1</block>
  <block id="9401797270b98418222b9be6674161bc" category="admonition">이 멀티 OS 환경은 Anthos-on-bare-metal 솔루션의 지원되는 OS 버전과의 상호 운용성을 보여줍니다. 우리는 고객이 구축을 위해 하나 또는 일부 운영 체제를 표준화할 것으로 예상하고 있습니다.</block>
  <block id="3a6810b280d17ed872c226f7c95dac46" category="list-text">관리 네트워크에서 액세스할 수 있는 전체 호스트 이름 확인을 제공하는 DNS 서버가 하나 이상 있어야 합니다.</block>
  <block id="14de5275438fed7bf294f7d1ef6ebfce" category="list-text">관리 네트워크에서 액세스할 수 있는 하나 이상의 NTP 서버입니다.</block>
  <block id="ab851d2f29c7c89b9bc55851dd1002d2" category="list-text">(선택 사항) 대역 내 관리 네트워크 모두에 대한 아웃바운드 인터넷 연결.</block>
  <block id="82d4df3a9be244e5548f2913b75e403c" category="admonition">이 문서의 비디오 및 데모 섹션에서 Anthos의 Bare Metal 배포에 대한 데모 비디오를 볼 수 있습니다.</block>
  <block id="8a31087c2de67e51ba9270956af09594" category="paragraph"><block ref="8a31087c2de67e51ba9270956af09594" category="inline-link-macro-rx"></block></block>
  <block id="e66e12138810859d8abf5fa2081fb491" category="summary">Google Cloud Console을 사용하여 온프레미스 Anthos GKE 클러스터에 응용 프로그램을 배포하는 방법</block>
  <block id="0fedf382c8cab1bb4bd4137b2edd4ddf" category="doc">Google Cloud Console Marketplace에서 애플리케이션을 배포합니다</block>
  <block id="db974f321885ec32e283b3ba19624bf5" category="list-text">Anthos 클러스터는 Google Cloud Console에 배포되어 등록되어 있습니다</block>
  <block id="86baa7935f2da05d24c2736b997d56af" category="list-text">Anthos 클러스터에 구성된 MetalLB 로드 밸런서</block>
  <block id="0e4a5cc43eded7fb6f9688b4db42749c" category="list-text">클러스터에 애플리케이션을 배포할 수 있는 권한이 있는 계정입니다</block>
  <block id="0abcad93e8aa42fe77227a82e7bfac88" category="list-text">관련 비용이 있는 애플리케이션을 선택한 경우 Google Cloud의 청구 계정(선택 사항)</block>
  <block id="241b7771ea8f8a56aa7c79c94ea05b45" category="section-title">응용 프로그램 배포</block>
  <block id="7519665b833135b7a83098238355d197" category="paragraph">이 활용 사례에서는 Google Cloud Console을 사용하여 Anthos 클러스터 중 하나에 간단한 WordPress 애플리케이션을 배포합니다. 구축 시 NetApp ONTAP에서 제공하는 영구 스토리지가 사전 정의된 스토리지 클래스 형태로 사용됩니다. 그런 다음 MetalLB 로드 밸런서가 IP 주소를 제공하고 이를 전 세계에 노출하도록 애플리케이션 기본 서비스를 수정하는 두 가지 방법을 시연합니다.</block>
  <block id="0f46ecb3b1113d47388dd5a45b007f77" category="paragraph">이러한 방식으로 응용 프로그램을 배포하려면 다음 단계를 수행하십시오.</block>
  <block id="284e9ebcc65faa3412015e1aef0b212f" category="list-text">배포하려는 클러스터에 Google Cloud Console에서 액세스할 수 있는지 확인합니다.</block>
  <block id="c5ae9e1da0751273beff7dba35e9f3a0" category="inline-image-macro">등록된 클러스터</block>
  <block id="113157b1187558580348ca8d41e0e09d" category="paragraph"><block ref="113157b1187558580348ca8d41e0e09d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ffca2e9c9a134c6025fcd79da7b2c759" category="list-text">왼쪽 메뉴에서 응용 프로그램 을 선택하고 맨 위에 있는 3점 옵션 메뉴를 선택한 다음 Marketplace에서 배포 를 선택합니다. 그러면 Google Cloud Marketplace에서 응용 프로그램을 선택할 수 있는 새 창이 나타납니다.</block>
  <block id="0684d335d9a7c1f72f6bfcd5a3f89e00" category="inline-image-macro">마켓플레이스 를 참조하십시오</block>
  <block id="c2c2bcc598caddf4725c028c7db228b2" category="paragraph"><block ref="c2c2bcc598caddf4725c028c7db228b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1116a3fdba8715414e3ef4e4f99912" category="list-text">이 경우 WordPress에서 설치할 응용 프로그램을 검색합니다.</block>
  <block id="822f5bce2ee65cbb4bdffaba2710ba34" category="inline-image-macro">WordPress를 검색합니다</block>
  <block id="660eb3f5a04738d18f35a59427836264" category="paragraph"><block ref="660eb3f5a04738d18f35a59427836264" category="inline-image-macro-rx" type="image"></block></block>
  <block id="510d39751378d8f38e07c02ea0fc6be6" category="list-text">WordPress 응용 프로그램을 선택하면 개요 화면이 표시됩니다. 구성 버튼을 클릭합니다.</block>
  <block id="10caa5e50634911a226bf4aadc5a0c7a" category="inline-image-macro">WordPress 개요 화면</block>
  <block id="096a5432cb51a4b959599922c18c06c1" category="paragraph"><block ref="096a5432cb51a4b959599922c18c06c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6ef5c869d6fe64bd1b351a45360b963" category="list-text">다음 페이지에서 구축할 클러스터를 선택해야 합니다(여기서는 Demo-Cluster). 새 네임스페이스 및 애플리케이션 인스턴스 이름을 선택하거나 생성하고 WordPress 애플리케이션과 그 지원 MariaDB 데이터베이스에 필요한 스토리지 클래스 및 영구 볼륨 크기를 선택합니다. 두 경우 모두 ONTAP-NAS-CSI 스토리지 클래스를 선택했습니다.</block>
  <block id="355246a53a979cfb1041a2b1940f6879" category="inline-image-macro">WordPress 구성</block>
  <block id="d888949dd50bbca6d60ecc23eaef49f9" category="paragraph"><block ref="d888949dd50bbca6d60ecc23eaef49f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d655c70f06a3434e67cbfc80248a9a" category="admonition">공용 IP 액세스 사용 을 선택하지 마십시오. 이렇게 하면 사내 Anthos 배포에서 액세스할 수 없는 NodePort 유형의 서비스가 생성됩니다.</block>
  <block id="afab588b2fdc93623ccf8cb877caf4da" category="list-text">배포 단추를 클릭하면 응용 프로그램 세부 정보를 제공하는 페이지가 나타납니다. CLI를 사용하여 이 페이지를 새로 고치거나 클러스터에 로그인하여 배포 상태를 확인할 수 있습니다.</block>
  <block id="31e41095bfaa14799239e8d9ba7ad438" category="inline-image-macro">애플리케이션 세부 정보</block>
  <block id="d0354e2068a16698befdae7925d598c8" category="paragraph"><block ref="d0354e2068a16698befdae7925d598c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="182bdd798d19f66a7142e53dc7ba7d03" category="list-text">CLI는 응용 프로그램 네임스페이스에서 POD 정보를 가져오기 위한 명령을 실행하여 응용 프로그램 배포 시 응용 프로그램의 상태를 확인하는 데 사용할 수 있습니다. "kubbtl get POD-n anthos-wp"</block>
  <block id="4fdb8b8bf983b608be34dc4a03f63bae" category="inline-image-macro">큐벡틀은 포드를 받습니다</block>
  <block id="5d15d1dcdf1862334a130d3d7fe69ccc" category="paragraph"><block ref="5d15d1dcdf1862334a130d3d7fe69ccc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e9914dac3fe74f2b341b37fde931ccc8" category="admonition">이 스크린샷에는 오류 상태의 배포자 POD가 있습니다. 이는 정상적인 현상입니다. 이 POD는 Google Cloud Console에서 다른 포드가 초기화 프로세스를 시작한 후 자동으로 종료되는 응용 프로그램을 배포하는 데 사용하는 도우미 포드입니다.</block>
  <block id="9d8881c161170e208f09b8b2a142a66f" category="list-text">잠시 후 응용 프로그램이 실행 중인지 확인합니다.</block>
  <block id="ce0590d3b5f26b188a077af82f7344a2" category="inline-image-macro">응용 프로그램이 실행 중입니다</block>
  <block id="011a851bc4637452cc423fc951144521" category="paragraph"><block ref="011a851bc4637452cc423fc951144521" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3acabe74bca98e10c24bed74bda730" category="section-title">응용 프로그램을 노출합니다</block>
  <block id="76ce15c259c30934261379d5c782fb7a" category="paragraph">애플리케이션을 배포한 후 두 가지 방법으로 전 세계에 연결할 수 있는 IP를 할당할 수 있습니다.</block>
  <block id="636274e5bcac1260da12a33d8dae0b1e" category="section-title">Google Cloud Console 사용</block>
  <block id="affe13ca759d7abbd8dd52510dcccb9d" category="paragraph">Google Cloud Console을 사용하여 응용 프로그램을 노출하고 브라우저에서 서비스에 대한 YAML 출력을 편집하여 공개적으로 연락할 수 있는 IP를 설정할 수 있습니다. 이렇게 하려면 다음 단계를 수행하십시오.</block>
  <block id="e14de37e4860e0a27178cce381f79223" category="list-text">Google Cloud Console의 왼쪽 메뉴에서 서비스 및 수신 을 클릭합니다.</block>
  <block id="7888520f99ee2ce14da11b431d5ae318" category="inline-image-macro">서비스 및 수신</block>
  <block id="a30c95bc1250f0f260b3859484a79e52" category="paragraph"><block ref="a30c95bc1250f0f260b3859484a79e52" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6187f833f4cb9c4f7b8ee4db49498f1b" category="list-text">워드프레스-워드프레스-svc 서비스를 클릭합니다. 그러면 서비스 세부 정보 화면이 열립니다. 맨 위에 있는 편집 단추를 클릭합니다.</block>
  <block id="d203ca99d4a0afdab1bcfe540a547944" category="inline-image-macro">서비스 세부 정보를 편집합니다</block>
  <block id="572acf06c07873db504c906b27cd9089" category="paragraph"><block ref="572acf06c07873db504c906b27cd9089" category="inline-image-macro-rx" type="image"></block></block>
  <block id="668b0ecfd7e72dc665e312c2993930b3" category="list-text">서비스에 대한 YAML 정보가 포함된 편집 서비스 세부 정보 페이지가 열립니다. 'clusterIP'로 설정된 'sepec:' 섹션과 'type:' 값이 표시될 때까지 아래로 스크롤합니다. 이 값을 'loadbalancer'로 변경하고 Save 버튼을 클릭한다.</block>
  <block id="d6b6ff61b6af359d37d3635e95073c9d" category="inline-image-macro">ClusterIP 값을 입력합니다</block>
  <block id="198f2e2e4e51b005096e30bd1dc74de8" category="paragraph"><block ref="198f2e2e4e51b005096e30bd1dc74de8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c5f9f0194a478fbc7f5f93f46c2953de" category="inline-image-macro">로드 밸런서 값을 입력합니다</block>
  <block id="51301646eb8394e4ac0765ad84f0d777" category="paragraph"><block ref="51301646eb8394e4ac0765ad84f0d777" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e7331da14461f4638eebbff81857db51" category="list-text">서비스 세부 정보 페이지로 돌아가면 이제 Type: 필드에 로드 밸런서가 나열되고 External endpoints: 필드에 MetalLB 풀에서 할당된 IP 주소와 애플리케이션에 액세스할 수 있는 포트가 나열됩니다.</block>
  <block id="3ec7f6e26f5dfb369960a71540f97a1f" category="inline-image-macro">서비스 세부 정보 최종</block>
  <block id="e5b2b641e4db64d79ddda6476267c442" category="paragraph"><block ref="e5b2b641e4db64d79ddda6476267c442" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74e17d078471c59b2bf53ed27db0fb1f" category="section-title">Kubbtl로 서비스 패치</block>
  <block id="f022ee3e39dabcf83208cc99a6eb4a8b" category="paragraph">CLI 및 "kubbeck patch" 명령을 사용하여 배포를 수정하고 공개적으로 연결할 수 있는 IP를 설정하여 응용 프로그램을 노출할 수 있습니다. 이렇게 하려면 다음 단계를 완료하십시오.</block>
  <block id="7d217d270c695202071f85ac46866514" category="list-text">"kubbeck get services -n anthos -wp" 명령을 사용하여 네임스페이스에서 POD와 관련된 서비스를 나열합니다.</block>
  <block id="fe7c7c8f844859020a7db7a331ade810" category="inline-image-macro">서비스 나열</block>
  <block id="45c0563dbcc7191f2f4360b2e8740e4a" category="paragraph"><block ref="45c0563dbcc7191f2f4360b2e8740e4a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6969be1fd50af4592e0d142a1d8d70cd" category="list-text">다음 명령어를 이용하여 서비스 유형을 ClusterIP에서 loadbalancer를 입력하여 수정한다.</block>
  <block id="ee64374fc07de409e3af533d716265a7" category="paragraph">이 새로운 서비스 유형에는 MetalLB 풀에서 사용 가능한 IP 주소가 자동으로 할당됩니다.</block>
  <block id="c2a179dcfc744c6d0e1f8e669f780a31" category="inline-image-macro">Type loadbalancer에 대한 패치 서비스입니다</block>
  <block id="ee6e2870bddeced39fa0bbc481e1cd21" category="paragraph"><block ref="ee6e2870bddeced39fa0bbc481e1cd21" category="inline-image-macro-rx" type="image"></block></block>
  <block id="515ddbc3d2b92a28024949cdc11effe0" category="section-title">노출된 외부 IP에서 애플리케이션을 방문합니다</block>
  <block id="9f32f710fb943684fe7ac71944e06000" category="paragraph">공개적으로 연결할 수 있는 IP 주소를 사용하여 응용 프로그램을 노출했으므로 브라우저를 사용하여 WordPress 인스턴스를 방문할 수 있습니다.</block>
  <block id="3922853243ef47d8d33c4ed74259c64a" category="inline-image-macro">브라우저의 WordPress</block>
  <block id="d989de00c947c6c543a0711c796da0b3" category="paragraph"><block ref="d989de00c947c6c543a0711c796da0b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f498970d77b95b37672534275d7e8b40" category="paragraph"><block ref="f498970d77b95b37672534275d7e8b40" category="inline-link-macro-rx"></block></block>
  <block id="21e8ffc6f822b183559b39b43061c1d2" category="summary">NetApp은 Anthos와 같은 컨테이너 기반 환경에서 고객이 영구 데이터를 오케스트레이션하고 관리하도록 지원하는 다양한 제품을 제공합니다.</block>
  <block id="7a8b9d74335d44fbaaf7f5d5aebf0cfd" category="paragraph">Google Cloud는 Anthos Ready 스토리지 파트너 프로그램을 통해 Anthos의 새 릴리스와 파트너 스토리지 통합의 업데이트된 검증을 주기적으로 요청합니다. 현재 검증된 스토리지 솔루션, CSI 드라이버, 사용 가능한 기능 및 지원되는 Anthos의 버전 목록을 찾을 수 있습니다<block ref="0ccc93736ba595a77f031ff105798de0" category="inline-link-rx"></block>.</block>
  <block id="ea3b8c601657928fee815e0d16908cf1" category="paragraph">NetApp은 Anthos 버전에서 Astra Trident CSI를 준수하는 스토리지 오케스트레이터와 ONTAP 및 요소 스토리지 시스템의 검증을 위한 요청을 통해 분기별로 정기적인 규정 준수를 유지해 왔습니다.</block>
  <block id="d9c9cc94777c7797db966b663b32ce4d" category="paragraph">다음 표에는 Anthos Ready 스토리지 파트너 프로그램의 일부로 NetApp 및 NetApp 파트너 엔지니어가 NetApp Astra Trident CSI 드라이버 및 기능 세트를 검증하기 위해 테스트한 Anthos 버전이 포함되어 있습니다.</block>
  <block id="84aafd4e962655f32c5bdea750278fba" category="paragraph">NetApp은 Anthos와 같은 컨테이너 기반 환경에서 영구 데이터를 오케스트레이션하고 관리하는 데 도움이 되는 다양한 제품을 제공합니다.</block>
  <block id="55713395841bbe573d35c776279d08cc" category="paragraph">NetApp Astra Trident는 Anthos를 비롯한 컨테이너 및 Kubernetes 배포를 위한 완전히 지원되는 오픈 소스 스토리지 오케스트레이터입니다. 자세한 내용은 Astra Trident 웹 사이트를 참조하십시오<block ref="845024b96ab150d9f628b33995c60669" category="inline-link-rx"></block>.</block>
  <block id="7b83f653c093c1509ca751b06a9ba82f" category="inline-link-macro">다음: NetApp Astra Trident 개요</block>
  <block id="ee33055a07370e6d1e33ad7480a57a7b" category="paragraph"><block ref="ee33055a07370e6d1e33ad7480a57a7b" category="inline-link-macro-rx"></block></block>
  <block id="305e92355c5c05eac28d2fbad20eaa5c" category="list-text">Anthos 관리 워크스테이션.* Anthos 배포와 상호 작용하기 위해 gkectl 및 kubbeck 명령을 실행할 수 있는 배포 호스트입니다.</block>
  <block id="3cd74a54f5924b896bf9cb97397e8b35" category="list-text">* 관리 클러스터. * VMware에서 Anthos 클러스터를 설정할 때 배포된 초기 클러스터. 이 클러스터는 배포, 확장 및 업그레이드를 포함한 모든 하위 사용자 클러스터 작업을 관리합니다.</block>
  <block id="11b774f9c0d1531100a341b6da7d98fa" category="list-text">* 사용자 클러스터. * 각 사용자 클러스터는 고유한 로드 밸런서 인스턴스 또는 파티션으로 구축되므로, 개별 사용자 또는 그룹을 위한 독립 실행형 Kubernetes 클러스터 역할을 하여 전체 멀티 테넌시를 달성할 수 있습니다.</block>
  <block id="b4dfd3f706cb0162d524cf7c36093e7c" category="paragraph">다음 그림은 Anthos-cluster-on-VMware 배포에 대한 설명입니다.</block>
  <block id="f34111b15d3f3387462dd512dde1392f" category="list-text">비용 절감. * 최종 사용자는 Google Cloud 환경 또는 대규모 베어 메탈 클러스터에서 리소스를 프로비저닝하지 않고 여러 사용자 클러스터를 동일한 물리적 환경에 구축하고 애플리케이션 배포를 위한 자체 물리적 리소스를 활용하여 상당한 비용 절감을 실현할 수 있습니다.</block>
  <block id="f89d1a459fed3d81a3b4a7360d0e85fc" category="list-text">* VMware vSphere vMotion. * VMware vCenter를 사용하면 요청 시 중단 없이 클러스터 내의 노드 간에 VM을 핫 마이그레이션할 수 있습니다.</block>
  <block id="e7a811d106a4076d6c6992a7b97734a0" category="paragraph">다음 표에는 솔루션을 검증하는 데 NetApp과 파트너가 사용한 vSphere 버전 목록이 포함되어 있습니다.</block>
  <block id="0dc619d5fd0af9a7a1c5ddea5b3e05a4" category="paragraph">시승 또는 평가 목적으로 3개 미만의 노드로 구성된 vSphere 클러스터에 Anthos를 설치할 수는 있지만 운영 워크로드에 권장되지 않습니다. 두 노드가 기본적인 HA 및 내결함성을 지원하지만 Anthos 클러스터 구성을 수정하여 기본 호스트 선호도를 비활성화해야 하며, 이 구축 방법은 Google Cloud에서 지원되지 않습니다.</block>
  <block id="67243afe565a819d977d538c55049340" category="admonition">Anthos는 각 개별 'cluster.yAML' 파일에 구성 옵션을 사용하여 사용자 환경의 ESXi 호스트 수에 따라 활성화 또는 비활성화할 수 있는 노드 선호도 규칙을 자동으로 생성합니다.</block>
  <block id="748635e1daf718400c0f3bdeb448cf73" category="inline-link-macro">다음: 베어 메탈(Bare Metal)의 Anthos.</block>
  <block id="3f3ed1875910e0d28d2c97b78338cc3d" category="paragraph"><block ref="3f3ed1875910e0d28d2c97b78338cc3d" category="inline-link-macro-rx"></block></block>
  <block id="941b2b9e397e77b597402b51e7ef131d" category="paragraph"><block ref="941b2b9e397e77b597402b51e7ef131d" category="inline-link-macro-rx"></block></block>
  <block id="2f0792348007b672e999da06f311bd6f" category="summary">Astra Trident는 Anthos를 비롯한 컨테이너 및 Kubernetes 배포를 위한 완전히 지원되는 오픈 소스 스토리지 오케스트레이터입니다.</block>
  <block id="c91efa18f13fad38864e99107352d0c5" category="paragraph">Astra Trident는 Anthos를 비롯한 컨테이너 및 Kubernetes 배포를 위한 완전히 지원되는 오픈 소스 스토리지 오케스트레이터입니다. Trident는 NetApp ONTAP 및 Element 스토리지 시스템을 포함한 전체 NetApp 스토리지 포트폴리오와 연동되며 NFS 및 iSCSI 연결도 지원합니다. Trident는 최종 사용자가 스토리지 관리자의 개입 없이 NetApp 스토리지 시스템에서 스토리지를 프로비저닝 및 관리할 수 있도록 하여 DevOps 워크플로우를 가속합니다.</block>
  <block id="e16f8b7c3b79f3d80b3d5b5862b4481a" category="paragraph">관리자는 프로젝트 요구 사항과 특정 수준의 성능을 보장하는 압축, 특정 디스크 유형, QoS 수준 등의 고급 스토리지 기능을 지원하는 스토리지 시스템 모델을 기반으로 여러 스토리지 백엔드를 구성할 수 있습니다. 이러한 백엔드를 정의한 후, 개발자는 프로젝트의 이러한 백엔드를 사용하여 지속적인 PVC(Volume Claim)를 생성하고 필요에 따라 컨테이너에 영구 저장소를 연결할 수 있습니다.</block>
  <block id="239c66c0132fd8324d609e4f1ce89f79" category="paragraph">Astra Trident의 최신 버전인 22.04는 2022년 4월에 출시되었습니다. Kubernetes 배포를 찾을 수 있는 Trident의 버전에 대한 지원 매트릭스입니다<block ref="34562000b9988739736848a0014e5230" category="inline-link-rx"></block>.</block>
  <block id="1efa4d2f8950cdd5154a6c130953c9f2" category="paragraph">22.04 릴리즈를 통해 Trident Operator의 설치를 용이하게 하는 Helm 차트가 제공됩니다.</block>
  <block id="27bed77b9cf648bc4592d40c2806fb43" category="paragraph">Helm을 사용하여 배포된 사용자 클러스터에 Trident 설치를 자동화하고 영구 볼륨을 프로비저닝하려면 다음 단계를 완료하십시오.</block>
  <block id="c9c8f06cd5f25063dedfc6eea2b08fa7" category="inline-link">Helm 설치 페이지</block>
  <block id="43eba64dcd06763432addbcf8db2d367" category="list-text">Trident Helm 저장소 추가:</block>
  <block id="6a05a869c72ac896a6f7473fba5c9b1e" category="paragraph">구축된 사용자 클러스터에 Trident를 수동으로 설치하고 영구 볼륨을 프로비저닝하려면 다음 단계를 완료하십시오.</block>
  <block id="79273cfc4ab66c2763755b11b14fedb9" category="list-text">설치 아카이브를 관리 워크스테이션에 다운로드하고 압축을 풉니다. Trident의 현재 버전은 22.04이며 다운로드할 수 있습니다<block ref="c7e04c62da3fb5014b467863172d941c" category="inline-link-rx"></block>.</block>
  <block id="f0d8974fd014601f60573d339d525772" category="list-text">Trident에는 이 파일을 전달할 수 있는 옵션이 없으므로 사용자 클러스터의 "kubecononfig" 파일의 위치를 참조할 필요가 없도록 환경 변수로 설정합니다.</block>
  <block id="1b8283857d1e7c1a4e80a12b3ba66ad9" category="paragraph"><block ref="1b8283857d1e7c1a4e80a12b3ba66ad9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2540200d51d81caebf749b3eb92aa66f" category="paragraph"><block ref="2540200d51d81caebf749b3eb92aa66f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="695cc7df9129054b4e4bd425d0094832" category="paragraph"><block ref="695cc7df9129054b4e4bd425d0094832" category="inline-image-macro-rx" type="image"></block></block>
  <block id="79cdad7595deba66ecab4005ebe50206" category="paragraph"><block ref="79cdad7595deba66ecab4005ebe50206" category="inline-image-macro-rx" type="image"></block></block>
  <block id="235db056b84e051c45e51c19dc088d7a" category="paragraph"><block ref="235db056b84e051c45e51c19dc088d7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="54132be89475e52a0550d90f4b162e74" category="paragraph"><block ref="54132be89475e52a0550d90f4b162e74" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7f329dfec2100f6b17e76aecd655cac" category="paragraph"><block ref="a7f329dfec2100f6b17e76aecd655cac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ec1ad0944f93fe082ef02313cd33db47" category="paragraph"><block ref="ec1ad0944f93fe082ef02313cd33db47" category="inline-image-macro-rx" type="image"></block></block>
  <block id="28eb5fe5f641c3ffa32f2488fa166a36" category="paragraph">이 참조 문서는 여러 데이터 센터 환경에 배포될 NetApp 및 엔지니어링 파트너가 NetApp Anthos with NetApp 솔루션에 대한 배포 검증을 제공합니다. 또한, 영구 스토리지 관리를 위한 Astra Trident 스토리지 오케스트레이터를 사용하여 NetApp 스토리지 시스템과의 스토리지 통합에 대해 자세히 설명합니다. 마지막으로 여러 솔루션 검증 및 실제 사용 사례를 살펴보고 문서화합니다.</block>
  <block id="0d3aabd1c9ad032e07b543d0aff99cb1" category="list-text">VMware vSphere의 "gkectl" 툴 또는 베어 메탈에 제공된 "bmctl" 툴을 사용하여 배포된 Anthos 환경을 쉽게 배포 및 관리할 수 있습니다.</block>
  <block id="ee1ef628edbfb6bb102163064fbd3d8e" category="paragraph">NetApp 솔루션의 Anthos는 이러한 문제를 인식하고 고객이 선택한 데이터 센터 환경에서 온프레미스 Anthos의 완전 자동화된 배포를 구현하여 각 문제를 해결하는 솔루션을 제시합니다.</block>
  <block id="ff870d33a6cd8a05e92781267ae2d76c" category="inline-link-macro">다음: Anthos 개요.</block>
  <block id="c3d162eb5f173883de1167105528ba0b" category="paragraph"><block ref="c3d162eb5f173883de1167105528ba0b" category="inline-link-macro-rx"></block></block>
  <block id="ffedc012b4decbb02d6a5ca1791f3d60" category="admonition">kubeadmin 사용자를 사용하여 개인 레지스트리에 로그인하는 경우 암호 대신 토큰을 사용합니다.</block>
  <block id="b0215348c4b61c9ef3af7e95c45db79b" category="doc">시소 부하 밸런서 설치</block>
  <block id="2498fd03c323b46a1d209aa07977fa55" category="paragraph">seesaw는 VMware 환경의 Anthos 클러스터에 설치된 버전 1.6에서 1.10에 이르는 기본 관리형 네트워크 로드 밸런싱 장치입니다.</block>
  <block id="1de0bfc08643a28f36a8fcd5662e17f0" category="section-title">시소 로드 밸런서 설치</block>
  <block id="7e83a37698e612c5150b6c3a383cf59b" category="paragraph">시소 로드 밸런서는 VMware의 Anthos Cluster와 완벽하게 통합되며 관리 및 사용자 클러스터 설정의 일부로 자동 배포를 수행합니다. 클러스터.YAML 구성 파일에는 로드 밸런서 정보를 제공하도록 수정해야 하는 텍스트 블록이 있으며, 클러스터 배포 전에 내장된 gkectl 도구를 사용하여 로드 밸런서를 배포하기 위한 추가 단계가 있습니다.</block>
  <block id="3d4d180e7186ad7195269636446a1c4c" category="admonition">시소 로드 밸런서는 HA 또는 비 HA 모드로 구축할 수 있습니다. 이 검증을 위해 시소 로드 밸런서가 비 HA 모드로 배포되었으며, 이 모드가 기본 설정입니다. 운영을 위해 HA 구성에서 시소를 구축하여 내결함성과 안정성을 높이는 것이 좋습니다.</block>
  <block id="613f73d2545e2e4434e09e47400d96a6" category="paragraph">각 구성 파일에는 관리 클러스터에 대한 섹션과 온프레미스 Anthos가 관리하도록 부하 분산 장치를 구성하기 위해 배포하기로 선택한 각 사용자 클러스터에 대한 섹션이 있습니다.</block>
  <block id="71f92aabf82706f3d2a00af1b3a34f95" category="paragraph">시소 로드 밸런서는 또한 각 클러스터 배포에 대해 제공해야 하는 별도의 정적 '시소 블록.YAML' 파일을 가지고 있습니다. 이 파일은 cluster.yAML 배포 파일과 관련된 동일한 디렉토리에 있어야 하며, 그렇지 않으면 위의 섹션에서 전체 경로를 지정해야 합니다.</block>
  <block id="cda0b5b1eab2f931076d0edc39a6920a" category="paragraph">관리자-시소-블록.YAML 파일의 예는 다음과 같습니다.</block>
  <block id="967a8ba34c500bbb53dbf69cee7587d9" category="doc">Astra Control Center에 Red Hat OpenShift 클러스터를 등록합니다</block>
  <block id="d2b3fd1f3d8ac38be89cec192a9d1558" category="list-text">첫 번째 단계는 OpenShift 클러스터를 Astra Control Center에 추가하고 관리하는 것입니다. 클러스터 로 이동하여 클러스터 추가 를 클릭하고 OpenShift 클러스터에 대한 kubecononfig 파일을 업로드한 다음 저장소 선택 을 클릭합니다.</block>
  <block id="0fafca9f5d93d0accfd1e6ed440a772b" category="list-text">Astra Control Center를 사용하여 OpenShift 클러스터 전체에서 백업 및 복원을 수행하려면 S3 프로토콜을 지원하는 오브젝트 스토리지 버킷을 프로비저닝해야 합니다. 현재 지원되는 옵션은 ONTAP S3, StorageGRID 및 AWS S3입니다. 이 설치를 위해 AWS S3 버킷을 구성하려고 합니다. Bucket 으로 이동하여 Bucket 추가 를 클릭하고 Generic S3 를 선택합니다. S3 버킷에 대한 세부 정보와 액세스할 자격 증명을 입력하고 이 Bucket을 클라우드의 기본 버킷으로 설정 확인란을 클릭한 다음 추가를 클릭합니다.</block>
  <block id="048fd5f2b27a172a00e3a014fbc0161b" category="inline-link-macro">다음: 보호할 응용 프로그램을 선택합니다.</block>
  <block id="6178a48a7c4c2e616e1caf9190bf41e6" category="paragraph"><block ref="6178a48a7c4c2e616e1caf9190bf41e6" category="inline-link-macro-rx"></block></block>
  <block id="8a7ac28f4ab44e0d4f4da82c8faf774a" category="summary">이 페이지에서 에 연결된 이 비디오는 베어 메탈 클러스터에 Anthos를 배포하는 방법을 보여 줍니다.</block>
  <block id="6ca531ff48fc42e961c1b239f4302fab" category="doc">베어 메탈 클러스터에서 Anthos 배포</block>
  <block id="cb0b7b75afe3f65d378ff6ab2c93d899" category="paragraph">이 링크의 비디오는 Anthos를 베어 메탈 클러스터에 배포하는 방법을 보여 줍니다.</block>
  <block id="97c62d2df3f6258616bde0882c4b890e" category="inline-link-macro">다음: 추가 정보.</block>
  <block id="5866caac5ce4e920cd3e5d0cd82ea8b7" category="paragraph"><block ref="5866caac5ce4e920cd3e5d0cd82ea8b7" category="inline-link-macro-rx"></block></block>
  <block id="fc31dc82d7754f65126c60eab5625947" category="inline-link-macro">Google Cloud Console을 사용하여 응용 프로그램을 설치합니다</block>
  <block id="627662d598c35dc9438ec1747d7766dc" category="paragraph"><block ref="627662d598c35dc9438ec1747d7766dc" category="inline-link-macro-rx"></block></block>
  <block id="ee1514b17e642c9cd1384a20cec220e3" category="summary">이 페이지에서 에 연결된 비디오는 이 문서에 설명되어 있는 몇 가지 기능을 보여 줍니다.</block>
  <block id="63e2e4c63022a2ca3a58778bd242195b" category="paragraph">다음 비디오에서는 이 문서에 설명되어 있는 몇 가지 기능을 설명합니다.</block>
  <block id="1adda60fb6ef5adf0c35c53442bdd87d" category="inline-link-macro">비디오: 베어 메탈에 Anthos의 배포</block>
  <block id="81082fb0b2db5311a27c6cd75db69481" category="paragraph"><block ref="81082fb0b2db5311a27c6cd75db69481" category="inline-link-macro-rx"></block></block>
  <block id="18d4f7e36efb77494db296ea83bc4753" category="paragraph">NetApp과 함께 배포된 베어 메탈 클러스터의 Anthos에 대한 자세한 내용은 를 참조하십시오 <block ref="eb911f2bc48f3132c014132a2870169f" category="inline-link-macro-rx"></block>.</block>
  <block id="d6c97ba6a05169248582981cf5627522" category="inline-link-macro">다음: VMware의 Anthos 클러스터.</block>
  <block id="9954fadf8d7c9568ecdb434ffa0a15c1" category="paragraph"><block ref="9954fadf8d7c9568ecdb434ffa0a15c1" category="inline-link-macro-rx"></block></block>
  <block id="5ac7b083aa99c6ec0d7a272c37dc611d" category="sidebar">구현 절차</block>
  <block id="71ab9d8f34c9ab92ef83627b823e9825" category="sidebar">데이터베이스 관리</block>
  <block id="c3b88d5ff29715f5f8dd3c907b3f1bc3" category="sidebar">데이터베이스 마이그레이션</block>
  <block id="f1d1e6ba9a2b7db0fa9da49e0e72d8e2" category="inline-link-macro">다음: 시소 로드 밸런서 설치</block>
  <block id="bbceb5257bbc998fe84b078ef4d5062b" category="paragraph"><block ref="bbceb5257bbc998fe84b078ef4d5062b" category="inline-link-macro-rx"></block></block>
  <block id="1781760e35ea460b2019eb0440baf384" category="paragraph"><block ref="1781760e35ea460b2019eb0440baf384" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6909280d84c97f4c2d6301b2d570e37a" category="paragraph"><block ref="6909280d84c97f4c2d6301b2d570e37a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="441be298f9b7d68522f3e6df5d9629e2" category="inline-link-macro">다음: MetalLB 로드 밸런서 설치</block>
  <block id="9c79b190423dda0c207aac371557f50a" category="paragraph"><block ref="9c79b190423dda0c207aac371557f50a" category="inline-link-macro-rx"></block></block>
  <block id="bf19992eca1061913e185b60f91a8344" category="list-text"><block ref="bf19992eca1061913e185b60f91a8344" category="inline-link-macro-rx"></block></block>
  <block id="297afb95cdd3600afb3f67c77b24215f" category="list-text"><block ref="297afb95cdd3600afb3f67c77b24215f" category="inline-link-macro-rx"></block></block>
  <block id="0395f03c04f82443f0fc31b418d2ded6" category="list-text"><block ref="0395f03c04f82443f0fc31b418d2ded6" category="inline-link-macro-rx"></block></block>
  <block id="6f838db94915ec121c6b32b1df99a983" category="inline-link-macro">다음: F5 BIG-IP 로드 밸런서 설치.</block>
  <block id="ecdb02c5420667abdb9a61d02af359c2" category="paragraph"><block ref="ecdb02c5420667abdb9a61d02af359c2" category="inline-link-macro-rx"></block></block>
  <block id="ea3f2894c4df21a157c45dcbcf989bda" category="paragraph">다음 페이지는 NetApp 솔루션의 Anthos에서 애플리케이션 및 영구 스토리지 관리를 위해 검증된 NetApp 제품에 대한 추가 정보를 제공합니다.</block>
  <block id="c49053fbce1331670d3c2e81d9625fec" category="admonition">Helm은 GKE-Admin 워크스테이션에 기본적으로 설치되지 않습니다. Ubuntu에서 작동하는 바이너리 형식으로 에서 다운로드할 수 있습니다<block ref="3d578643c15f985f07ca6d975ab0e791" category="inline-link-rx"></block>.</block>
  <block id="deae9c61cc109057bffb21d54fd54cdc" category="paragraph">Astra Trident Operator 설치를 완료한 후에는 사용 중인 특정 NetApp 스토리지 플랫폼에 대한 백엔드를 구성해야 합니다. Astra Trident의 설정 및 구성을 계속하려면 아래 링크를 따라가십시오.</block>
  <block id="6ed9d9e6160cedf6c16c9fa74e9d08aa" category="inline-link-macro">다음으로, NetApp ONTAP NFS를 살펴보겠습니다.</block>
  <block id="86beb69e1e89df92a89baa0d004b08b8" category="paragraph"><block ref="86beb69e1e89df92a89baa0d004b08b8" category="inline-link-macro-rx"></block></block>
  <block id="06a9f54df07db88477918bd7c3f597de" category="inline-link-macro">다음: NetApp Element iSCSI.</block>
  <block id="dd8532ad7059feaef43031ffa5970de1" category="paragraph"><block ref="dd8532ad7059feaef43031ffa5970de1" category="inline-link-macro-rx"></block></block>
  <block id="0a180196354cfbb6ec70b20db067fa6b" category="inline-link-macro">다음: NetApp Element.</block>
  <block id="73978739caea0775c3c807ecfc27f0c0" category="paragraph"><block ref="73978739caea0775c3c807ecfc27f0c0" category="inline-link-macro-rx"></block></block>
  <block id="5aad41fe64600c5795950512637ebae3" category="inline-link-macro">다음: 로드 밸런서 옵션 탐색</block>
  <block id="0b44acd6b2e7596e640212aa28de05c5" category="paragraph"><block ref="0b44acd6b2e7596e640212aa28de05c5" category="inline-link-macro-rx"></block></block>
  <block id="d0ee5cd6f53ec708670800837b7502b7" category="inline-link-macro">다음으로, NetApp ONTAP iSCSI를 살펴보겠습니다.</block>
  <block id="884a92818052da7764b1c5b7589bd458" category="paragraph"><block ref="884a92818052da7764b1c5b7589bd458" category="inline-link-macro-rx"></block></block>
  <block id="eec34a14279b64231b91793978a204da" category="paragraph"><block ref="eec34a14279b64231b91793978a204da" category="inline-link-macro-rx"></block></block>
  <block id="f6762efea56447c717fea204b2676851" category="list-text">Next(다음) 를 클릭하여 각 단계를 계속 진행하고 Storage selection(저장 선택) 화면이 나타날 때까지 표시된 각 화면의 기본값을 그대로 적용합니다. 가상 머신을 구축할 VM_Datastore를 선택하고 Next를 클릭합니다.</block>
  <block id="da0289d58f35e36d18325d6e8038b226" category="admonition">이 파일에 정의된 fschType이라는 선택적 필드가 있습니다. iSCSI 백엔드에서 이 값은 특정 Linux 파일 시스템 유형(XFS, ext4 등)으로 설정하거나 작업자 노드 OS가 사용할 파일 시스템을 결정할 수 있도록 삭제할 수 있습니다.</block>
  <block id="ca2835359be5e4e2e79ed5b6fd777515" category="paragraph"><block ref="ca2835359be5e4e2e79ed5b6fd777515" category="inline-image-macro-rx" type="image"></block></block>
  <block id="43f154001e329eb4cb13b7745ba16dac" category="doc">VMware를 사용하는 NetApp 하이브리드 멀티 클라우드에 지원되는 구성</block>
  <block id="9daaf09aeccc99c61fe453295253eae0" category="doc">요약 및 결론: NetApp 하이브리드 멀티 클라우드를 VMware와 함께 사용해야 하는 이유</block>
  <block id="0c17a5e22f572303947d9e14cd98db39" category="paragraph">주요 하이퍼스케일러를 위한 VMware 솔루션과 NetApp Cloud Volumes는 하이브리드 클라우드를 활용하려는 조직에 최고의 잠재력을 제공합니다. 이 섹션의 나머지 부분에서는 NetApp Cloud Volumes의 통합을 통해 진정한 하이브리드 멀티 클라우드 기능을 실현하는 사용 사례를 소개합니다.</block>
  <block id="17c56e542773e2aafc2645d0e9f0d8ec" category="summary">VMware 솔루션을 사용하는 NetApp 하이브리드 멀티 클라우드는 주요 퍼블릭 클라우드 하이퍼스케일러에 있는 NetApp 스토리지의 기능을 시연하는 일련의 전략적 기술 기능입니다.</block>
  <block id="eee9b49313d921d448286765fe05bd22" category="doc">AWS/VMC용 NetApp 하이브리드 멀티 클라우드 솔루션</block>
  <block id="27dafc6e4e2e3563b0434812fa3fee7c" category="section-title">GCP 지역 가용성</block>
  <block id="68c6fcf9f9393805f0529c36994a9266" category="paragraph">GCP가 공개 가용성에 진입할 때 GCP 지역 가용성이 릴리스됩니다.</block>
  <block id="b632c27ff82cfe142baffd346253a21b" category="doc">VMware를 사용하는 NetApp 하이브리드 멀티 클라우드의 사용 사례</block>
  <block id="0257f1ddf73d49021a7feba150b7ea8b" category="paragraph">이 시나리오에 대한 가장 쉬운 답은 각 하이퍼스케일러의 VMware 오퍼링입니다. NetApp ® Cloud Volumes와 마찬가지로 VMware는 사내 VMware 환경을 클라우드로 이동 또는 확장하는 방법을 제공하므로 클라우드에서 워크로드를 기본적으로 실행하면서 기존 온프레미스 자산, 기술 및 툴을 유지할 수 있습니다. 따라서 서비스 중단이나 IP 변경이 필요하지 않고 IT 팀이 기존 기술과 툴을 사용하여 사내에서 작업하는 방식을 운영할 수 있으므로 위험이 감소합니다. 따라서 클라우드 마이그레이션을 가속화하고 하이브리드 멀티 클라우드 아키텍처로의 전환이 한층 원활해질 수 있습니다.</block>
  <block id="33a1a24f2edf4ad9358baef7fb3c9cdf" category="doc">ANF 및 Jetstream을 통한 재해 복구</block>
  <block id="14f4fb472fe43e084476c5d8329b15f8" category="paragraph">클라우드로 재해 복구는 사이트 운영 중단 및 데이터 손상 이벤트(예: 랜섬웨어)로부터 워크로드를 보호하는 복원력이 있고 비용 효율적인 방법입니다. VMware VAIO 프레임워크를 사용하여 온프레미스 VMware 워크로드를 Azure Blob 스토리지에 복제하고 복구하여 데이터 손실과 제로급 RTO를 최소화하거나 최소화할 수 있습니다.</block>
  <block id="b614fc13a076bceeca03cda9c4b1fdce" category="paragraph">Jetstream DR을 사용하면 사내에서 AVS로, 특히 Azure NetApp Files로 복제된 워크로드를 원활하게 복구할 수 있습니다. DR 사이트에서 최소한의 리소스와 비용 효율적인 클라우드 스토리지를 사용하여 비용 효율적으로 재해 복구를 수행할 수 있습니다. Jetstream DR은 Azure Blob Storage를 통해 ANF 데이터 저장소에 대한 복구를 자동화합니다. Jetstream DR은 네트워크 매핑에 따라 독립적인 VM 또는 관련 VM 그룹을 복구 사이트 인프라로 복구하고 랜섬웨어 보호를 위한 시점 복구를 제공합니다.</block>
  <block id="29d141d1797b070195b4a3a5af842d35" category="paragraph">이 문서에서는 Jetstream DR 운영 원리 및 주요 구성 요소에 대해 설명합니다.</block>
  <block id="0b3b3c3ee7cf95d87f597441efd5f743" category="example-title">솔루션 구축 개요</block>
  <block id="1dff5e9fa7f5c212df3e98d343d6a771" category="list-text">사내 데이터 센터에 Jetstream DR 소프트웨어를 설치합니다.</block>
  <block id="7b87ce74b3d0f7e81fef7a7994f9c8ed" category="list-text">Azure Marketplace(ZIP)에서 Jetstream DR 소프트웨어 번들을 다운로드하고 지정된 클러스터에 Jetstream DR MSA(OVA)를 배포합니다.</block>
  <block id="56c27e9a114a51f4863d0fef4cab3eba" category="list-text">I/O 필터 패키지를 사용하여 클러스터를 구성합니다(Jetstream VIB 설치).</block>
  <block id="43de8924da88a34109307d6aac84811a" category="list-text">DR AVS 클러스터와 동일한 영역에서 Azure Blob(Azure Storage Account)를 프로비저닝합니다.</block>
  <block id="2cee29b70a6ea4765a6365e4d71775c7" category="list-text">DRVA 어플라이언스를 구축하고 복제 로그 볼륨(기존 데이터 저장소 또는 공유 iSCSI 스토리지의 VMDK)을 할당합니다.</block>
  <block id="9c6ca12d0f999d69d715e02482665e5d" category="list-text">보호된 도메인(관련 VM 그룹)을 생성하고 DRVA 및 Azure Blob Storage/ANF를 할당합니다.</block>
  <block id="04fd46fc4d0422c8562609b47b636797" category="list-text">보호를 시작합니다.</block>
  <block id="8391f9ad7383911e1b8e67d8dfd23ffb" category="list-text">Azure VMware Solution 프라이빗 클라우드에 Jetstream DR 소프트웨어를 설치합니다.</block>
  <block id="81aaea44e289ce199fea205f7d0b8cd9" category="list-text">실행 명령을 사용하여 Jetstream DR을 설치 및 구성합니다.</block>
  <block id="ef261b549f401ed8d66b72f8310d7376" category="list-text">동일한 Azure Blob 컨테이너를 추가하고 Scan Domains 옵션을 사용하여 도메인을 검색합니다.</block>
  <block id="3c22f96e96fb514aec06cc03a6d35958" category="list-text">필요한 DRVA 어플라이언스를 배포합니다.</block>
  <block id="a8930e0df42395d789466e0695d11ce7" category="list-text">사용 가능한 vSAN 또는 ANF 데이터 저장소를 사용하여 복제 로그 볼륨을 생성합니다.</block>
  <block id="087316b53a71d576c6dfeda2385ef108" category="list-text">보호된 도메인을 가져오고 RockVA(복구 VA)를 구성하여 VM 배치에 ANF 데이터 저장소를 사용합니다.</block>
  <block id="f47df812f6139d9d12dc179df9e7da57" category="list-text">적절한 페일오버 옵션을 선택하고 제로급 RTO 도메인 또는 VM에 대한 연속 재수화를 시작합니다.</block>
  <block id="eb50fc931b0aff72e9034088a04a260b" category="list-text">재해 이벤트 중에 지정된 AVS DR 사이트에서 Azure NetApp Files 데이터 저장소로 장애 조치를 트리거합니다.</block>
  <block id="21e74b3c28d006317f38a2bc8eb1da3b" category="inline-link">Azure 마켓플레이스 를 참조하십시오</block>
  <block id="f314a6aa5faf9dfffba2cdac4d4dd420" category="list-text">보호된 사이트를 복구한 후 보호된 사이트에 대한 페일백을 호출합니다. 시작하기 전에 이 지침에 따라 사전 요구 사항이 충족되는지 확인합니다<block ref="600591f3feccd7454d660dd4d2972306" category="inline-link-rx"></block> 또한 Jetstream Software에서 제공하는 BWT(대역폭 테스트 도구)를 실행하여 Jetstream DR 소프트웨어와 함께 사용할 경우 Azure Blob 스토리지의 잠재적 성능과 해당 복제 대역폭을 평가합니다. 연결을 포함한 사전 요구 사항이 준비된 후에는 에서 Jetstream DR for AVS를 설정하고 구독하십시오<block ref="e842a0f9c9000f3898fd5cb9408b8b3e" category="inline-link-rx"></block>. 소프트웨어 번들을 다운로드한 후 위에 설명된 설치 프로세스를 진행합니다.</block>
  <block id="01543f177a0cc07917f4dc3510b8649e" category="paragraph">많은 수의 VM(예: 100+)에 대한 보호를 계획하고 시작할 때는 Jetstream DR Automation Toolkit의 CPT(Capacity Planning Tool)를 사용하십시오. RTO 및 복구 그룹 기본 설정과 함께 보호할 VM 목록을 제공한 다음 CPT를 실행합니다.</block>
  <block id="ddfb9ed8decef8b3db76f88d682c7f1e" category="paragraph">CPT는 다음과 같은 기능을 수행합니다.</block>
  <block id="ab5991781a05bc72668a8bf941d7a4a5" category="list-text">RTO에 따라 VM을 보호 도메인에 결합합니다.</block>
  <block id="b3229123cf8dd56b28f1a8e13f79ddde" category="list-text">최적의 DRVA 수 및 해당 리소스 정의</block>
  <block id="2c3b2c6c87689b15c4cd3ea75cb40ef8" category="list-text">필요한 복제 대역폭을 추정하는 중입니다.</block>
  <block id="88d06f884976bb7a1ce66e51624c0196" category="list-text">복제 로그 볼륨 특성(용량, 대역폭 등) 식별</block>
  <block id="60a85cb526817dd0f1172dcdacc94700" category="list-text">필요한 오브젝트 스토리지 용량을 예측하는 등</block>
  <block id="ea56b8a01683ebc544ddabe2f0fcf571" category="admonition">규정된 도메인의 수와 컨텐츠는 평균 IOPS, 총 용량, 우선 순위(페일오버 순서를 정의하는 경우), RTO 등과 같은 다양한 VM 특성에 따라 달라집니다.</block>
  <block id="fc321ed0fcff278e628765c7a327d1c0" category="section-title">온프레미스 데이터 센터에 Jetstream DR을 설치합니다</block>
  <block id="87674fd676f223da1c84cd30ba47e2d2" category="paragraph">Jetstream DR 소프트웨어는 Jetstream DR Management Server Virtual Appliance(MSA), DR 가상 어플라이언스(DRVA) 및 호스트 구성 요소(I/O 필터 패키지)의 세 가지 주요 구성 요소로 구성됩니다. MSA는 컴퓨팅 클러스터에 호스트 구성 요소를 설치 및 구성한 다음 Jetstream DR 소프트웨어를 관리하는 데 사용됩니다. 다음 목록에는 설치 프로세스에 대한 자세한 설명이 나와 있습니다.</block>
  <block id="44a5c8a42b561b0a83b98c7dffe66dc4" category="list-text">필수 구성 요소를 확인하십시오.</block>
  <block id="6035c664a9aaf8fa1c40e58c8beaab92" category="list-text">리소스 및 구성 권장 사항에 대해 용량 계획 툴을 실행합니다(선택 사항이지만 개념 증명 평가에는 권장됨).</block>
  <block id="ccc2ab66d8941e0dddf26ed50f55ba4c" category="list-text">Jetstream DR MSA를 지정된 클러스터의 vSphere 호스트에 구축합니다.</block>
  <block id="efdd725636035b733a89826db0da74f4" category="list-text">브라우저에서 DNS 이름을 사용하여 MSA를 실행합니다.</block>
  <block id="39602c8241f165da483e3678f5d62871" category="list-text">MSA에 vCenter Server를 등록합니다. 설치를 수행하려면 다음 세부 단계를 완료하십시오.</block>
  <block id="f6a1019b86d486190fed5e4a0c122f59" category="list-text">Jetstream DR MSA를 구축하고 vCenter Server를 등록한 후에는 vSphere Web Client를 사용하여 Jetstream DR 플러그인에 액세스합니다. 이 작업은 데이터 센터 &gt; 구성 &gt; Jetstream DR로 이동하여 수행할 수 있습니다.</block>
  <block id="623c8f2c05001c7eeecb0781c049f16b" category="paragraph"><block ref="623c8f2c05001c7eeecb0781c049f16b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5b9a2e255ce372cd80d886148efdd00" category="list-text">Jetstream DR 인터페이스에서 적절한 클러스터를 선택합니다.</block>
  <block id="699c846ab66a56017e37da99f6ea7320" category="paragraph"><block ref="699c846ab66a56017e37da99f6ea7320" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3d18d2901e95370132a2545c2f511db3" category="list-text">I/O 필터 패키지를 사용하여 클러스터를 구성합니다.</block>
  <block id="34896ae2be725a2f3d42bd7b4b7888fd" category="paragraph"><block ref="34896ae2be725a2f3d42bd7b4b7888fd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0598abb730b378c25cbbc28507342260" category="list-text">복구 사이트에 있는 Azure Blob Storage를 추가합니다.</block>
  <block id="76ef667a7a95f046d391e54cea1b9142" category="list-text">Appliances(어플라이언스) 탭에서 DR Virtual Appliance(DRVA)를 구축합니다.</block>
  <block id="ba445d98067e8161fa165b8f25ad294d" category="admonition">DRVA는 CPT에 의해 자동으로 생성될 수 있지만 POC 평가에서는 DR 주기를 수동으로 구성 및 실행하는 것이 좋습니다(시작 보호 &gt; 장애 조치 &gt; 장애 복구).</block>
  <block id="60de8eac7ca6ad5f7321abf5b462b65d" category="paragraph">Jetstream DRVA는 데이터 복제 프로세스의 주요 기능을 용이하게 하는 가상 어플라이언스입니다. 보호되는 클러스터에는 DRVA가 하나 이상 포함되어야 하며, 일반적으로 호스트당 DRVA가 하나씩 구성됩니다. 각 DRVA는 여러 개의 보호된 도메인을 관리할 수 있습니다.</block>
  <block id="f55f11c27893cdacff776d302a9b9d07" category="paragraph"><block ref="f55f11c27893cdacff776d302a9b9d07" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ece649567fdf82717852e0f8662d070" category="paragraph">이 예에서는 80개의 가상 머신에 대해 4개의 DRVA가 생성되었습니다.</block>
  <block id="cf5c65945851f67013f23b2d83d4a346" category="list-text">사용 가능한 데이터 저장소 또는 독립 공유 iSCSI 스토리지 풀에서 VMDK를 사용하여 각 DRVA에 대한 복제 로그 볼륨을 생성합니다.</block>
  <block id="9ad06750519e0664bc1ec852cc5e07b6" category="list-text">보호 도메인 탭에서 Azure Blob 저장소 사이트, DRVA 인스턴스 및 복제 로그에 대한 정보를 사용하여 필요한 수의 보호된 도메인을 만듭니다. 보호 도메인은 함께 보호되고 장애 조치/장애 복구 작업에 우선 순위가 할당된 클러스터 내의 특정 VM 또는 VM 집합을 정의합니다.</block>
  <block id="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="paragraph"><block ref="fae4ab5e0fd81c7cdb44eba33dbe42fc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e68391e0d2ed07243f438a1d725a243a" category="list-text">보호할 VM을 선택하고 보호된 도메인의 VM 보호를 시작합니다. 그러면 지정된 Blob 저장소에 대한 데이터 복제가 시작됩니다.</block>
  <block id="24e5f5b0186cca0606b176380e3ee45c" category="admonition">보호 도메인의 모든 VM에 동일한 보호 모드가 사용되는지 확인합니다.</block>
  <block id="9870cb575efa482fab7fa9aa1fdf16ac" category="admonition">VMDK(Write-Back) 모드에서는 더 높은 성능을 제공할 수 있습니다.</block>
  <block id="895d59858a04439859a33d3288706702" category="paragraph"><block ref="895d59858a04439859a33d3288706702" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0e6ea2b1c670425ac09f1aadbc26e266" category="paragraph">복제 로그 볼륨이 고성능 스토리지에 배치되었는지 확인합니다.</block>
  <block id="3237de27ecac8fd3a072d337514991eb" category="admonition">페일오버 실행 도서를 구성하여 VM(복구 그룹)을 그룹화하고 부팅 순서 시퀀스를 설정하고 IP 구성과 함께 CPU/메모리 설정을 수정할 수 있습니다.</block>
  <block id="840c65296e1af99a67123dd9459e5548" category="section-title">실행 명령을 사용하여 Azure VMware 솔루션 프라이빗 클라우드에 AVS용 Jetstream DR을 설치합니다</block>
  <block id="d2441f955b3d04e99be7845bb7af68a6" category="paragraph">복구 사이트(AVS)의 모범 사례는 3노드 파일럿 라이트 클러스터를 미리 생성하는 것입니다. 이렇게 하면 다음 항목을 포함하여 복구 사이트 인프라를 사전 구성할 수 있습니다.</block>
  <block id="dab895f226673c73578b4c45dead73c0" category="list-text">대상 네트워킹 세그먼트, 방화벽, DHCP 및 DNS 등의 서비스 등</block>
  <block id="188d8743a82411348e186c7118e92c9a" category="list-text">AVS용 Jetstream DR 설치</block>
  <block id="fd3bf57ff38b27ccbf66886b71a34f76" category="list-text">ANF 볼륨을 데이터 저장소로 구성하고, moreJetStream DR은 미션 크리티컬 도메인에 대해 제로급 RTO 모드를 지원합니다. 이러한 도메인의 경우 대상 스토리지가 사전 설치되어 있어야 합니다. ANF는 이 경우 권장되는 스토리지 유형입니다.</block>
  <block id="89aa12cc0cd4846ef86fbe8dfd78d8bc" category="admonition">세그먼트 생성을 포함한 네트워크 구성은 AVS 클러스터에서 사내 요구 사항과 일치하도록 구성해야 합니다.</block>
  <block id="d50efdb8ff06cd2518521c1d4f68a67a" category="paragraph">SLA 및 RTO 요구 사항에 따라 지속적인 페일오버 또는 일반(표준) 페일오버 모드를 사용할 수 있습니다. 제로급 RTO의 경우 복구 사이트에서 연속 재수화를 시작해야 합니다.</block>
  <block id="7c1dc76f383d9b6253a273d35f636909" category="paragraph">Azure VMware 솔루션 프라이빗 클라우드에 AVS용 Jetstream DR을 설치하려면 다음 단계를 수행하십시오.</block>
  <block id="7f0bec83fc0010707471d9d3b84fd45b" category="list-text">Azure 포털에서 Azure VMware 솔루션으로 이동하여 프라이빗 클라우드를 선택한 다음 명령 실행 &gt; 패키지 &gt; JSDR.Configuration을 선택합니다.</block>
  <block id="6e37d4d4f3c60de2fb2e2e218753f9ea" category="admonition">Azure VMware 솔루션의 기본 CloudAdmin 사용자는 AVS용 Jetstream DR을 설치할 권한이 없습니다. Azure VMware 솔루션을 사용하면 Jetstream DR용 Azure VMware 솔루션 실행 명령을 호출하여 Jetstream DR을 간단하고 자동으로 설치할 수 있습니다.</block>
  <block id="832830e8d1c5e28f4e206c65a067fbfc" category="paragraph">다음 스크린샷은 DHCP 기반 IP 주소를 사용한 설치를 보여 줍니다.</block>
  <block id="1ca67a15b29b11c686a17480c2ecde9c" category="paragraph"><block ref="1ca67a15b29b11c686a17480c2ecde9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23fac09aaa7dcea6eb534251f50feae2" category="list-text">AVS 설치를 위한 Jetstream DR이 완료되면 브라우저를 새로 고칩니다. Jetstream DR UI에 액세스하려면 SDDC 데이터 센터 &gt; 구성 &gt; Jetstream DR로 이동하십시오.</block>
  <block id="58517d8d2fa977f39ca2b76c09c43dc4" category="paragraph"><block ref="58517d8d2fa977f39ca2b76c09c43dc4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="50bf7f298e2ed24c67b98b8d5c4e6dbe" category="list-text">Jetstream DR 인터페이스에서 온프레미스 클러스터를 저장소 사이트로 보호하는 데 사용된 Azure Blob 저장소 계정을 추가한 다음 도메인 검사 옵션을 실행합니다.</block>
  <block id="1e976589dd0f1f098c13f4564f91813c" category="paragraph"><block ref="1e976589dd0f1f098c13f4564f91813c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b4e7f9056aa9f52fd1bff1e2837a4e84" category="list-text">보호된 도메인을 가져온 후 DRVA 어플라이언스를 구축합니다. 이 예에서는 Jetstream DR UI를 사용하여 복구 사이트에서 수동으로 연속 재수화를 시작합니다.</block>
  <block id="7aa502331a6314a8d66df611c4538f75" category="admonition">CPT 생성 계획을 사용하여 이러한 단계를 자동화할 수도 있습니다.</block>
  <block id="bf4fdf975fae154bdca78e36bd7edbe3" category="list-text">보호된 도메인을 가져오고 VM 배치에 ANF 데이터 저장소를 사용하도록 복구 VA를 구성합니다.</block>
  <block id="0a4fc536683686b518331dd2531934b5" category="paragraph"><block ref="0a4fc536683686b518331dd2531934b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="827098a514e7d7fc1579120ec370bfd9" category="admonition">선택한 세그먼트에서 DHCP가 활성화되어 있고 사용 가능한 IP가 충분한지 확인합니다. 도메인이 복구되는 동안 동적 IP가 일시적으로 사용됩니다. 복구 중인 각 VM(연속 재수화 포함)에는 개별 동적 IP가 필요합니다. 복구가 완료되면 IP가 해제되고 다시 사용할 수 있습니다.</block>
  <block id="10e011fef535dced7a4095544de7266d" category="list-text">적절한 페일오버 옵션(무중단 페일오버 또는 페일오버)을 선택합니다. 이 예에서는 연속 재수화(연속 페일오버)가 선택됩니다.</block>
  <block id="adac1a1b7a65bae37b6bd9cbd66b248a" category="paragraph"><block ref="adac1a1b7a65bae37b6bd9cbd66b248a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f6a68077ca82bffe5f08d96bdcd36e18" category="section-title">페일오버/페일백 수행</block>
  <block id="61a6473493a7f05f03d606cdfeb234d6" category="list-text">사내 환경의 보호 클러스터에서 재해가 발생한 후(부분 장애 또는 전체 장애) 페일오버를 트리거합니다.</block>
  <block id="3a09da9a187f9208fcd685b78b772764" category="admonition">CPT를 사용하여 Azure Blob Storage에서 AVS 클러스터 복구 사이트로 VM을 복구하는 페일오버 계획을 실행할 수 있습니다.</block>
  <block id="f66e570f82bdb271d0adb30435ad5b2b" category="admonition">AVS에서 보호된 VM이 시작될 때 장애 조치(연속 또는 표준 재수화) 후 보호가 자동으로 재개되고 Jetstream DR은 Azure Blob Storage의 해당/원래 컨테이너로 데이터를 계속 복제합니다.</block>
  <block id="d27309d11731255db072c47f9675d22f" category="paragraph"><block ref="d27309d11731255db072c47f9675d22f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4a8f8fdcb45687697d39da1e99dc36" category="paragraph"><block ref="ef4a8f8fdcb45687697d39da1e99dc36" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bf84d29276236d6a8b8e75f1a2c8f115" category="paragraph">작업 표시줄에 장애 조치 작업의 진행률이 표시됩니다.</block>
  <block id="8430656d9f62a51ed63ade1e47ad34f7" category="list-text">작업이 완료되면 복구된 VM에 액세스하고 비즈니스가 정상적으로 계속됩니다.</block>
  <block id="f89c6dfb9ae23126d1e04570e23dcda9" category="paragraph"><block ref="f89c6dfb9ae23126d1e04570e23dcda9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3c8214eaedd2bb37ba1d1b018bf4aa63" category="paragraph">운영 사이트가 다시 가동된 후 페일백을 수행할 수 있습니다. VM 보호가 재개되고 데이터 일관성을 확인해야 합니다.</block>
  <block id="2743b11e431e1c7f8504d917d4ffc4d6" category="list-text">사내 환경을 복원합니다. 재해 발생 유형에 따라 보호 클러스터의 구성을 복원 및/또는 확인해야 할 수도 있습니다. 필요한 경우 Jetstream DR 소프트웨어를 재설치해야 할 수 있습니다.</block>
  <block id="232732afcd0f951efbcfaea123f0a632" category="admonition">참고: 자동화 툴킷에 제공된 RECOVERY_UTILITY_Prepare_failback" 스크립트를 사용하여 오래된 VM, 도메인 정보 등의 원래 보호 사이트를 정리할 수 있습니다.</block>
  <block id="6d52b59b59572c39053e3858b37fcc57" category="list-text">복원된 온프레미스 환경에 액세스하고 Jetstream DR UI로 이동한 다음 적절한 보호 도메인을 선택합니다. 보호 사이트가 페일백될 준비가 되면 UI에서 페일백 옵션을 선택합니다.</block>
  <block id="7350f3b9fc85111b45034212957d9d98" category="paragraph"><block ref="7350f3b9fc85111b45034212957d9d98" category="inline-image-macro-rx" type="image"></block></block>
  <block id="82bc01d2feed0849423b6b5676888f97" category="admonition">CPT에서 생성한 페일백 계획을 사용하여 VM과 해당 데이터를 오브젝트 저장소에서 원래 VMware 환경으로 되돌릴 수도 있습니다.</block>
  <block id="36e8c86c253ad3dad15eaab2f5de961c" category="admonition">복구 사이트에서 VM을 일시 중지하고 보호 사이트에서 다시 시작한 후 최대 지연 시간을 지정합니다. 여기에는 대체 작동 VM 중지 후 복제 완료, 복구 사이트를 정리하기 위한 시간, 보호 사이트에서 VM을 다시 만드는 시간이 포함됩니다. NetApp이 권장하는 값은 10분입니다.</block>
  <block id="c53daff4bd6065c0627bf739410f7e88" category="paragraph">페일백 프로세스를 완료한 다음 VM 보호 및 데이터 정합성 재개를 확인합니다.</block>
  <block id="ddd33ab61759ca3d4dcfcd934ab83b04" category="section-title">Ransomeware 복구</block>
  <block id="459d2a2d25c4ad6db53b9e0b367f3d4c" category="paragraph">랜섬웨어에서 복구하는 것은 매우 힘든 작업이 될 수 있습니다. 특히, IT 조직이 안전한 반환 지점을 결정하고 결정된 후에는 복구된 워크로드가 재발생하는 공격으로부터 보호하는 방법(휴면 맬웨어로부터 또는 취약한 응용 프로그램을 통해)을 확인하기 어려울 수 있습니다.</block>
  <block id="414dfaa4bcffbd76b7f5ed891cdf1535" category="paragraph">Azure NetApp Files 데이터 저장소와 함께 AVS용 Jetstream DR을 사용하면 조직에서 사용 가능한 시점으로부터 복구할 수 있으므로 필요에 따라 분리된 기능적 네트워크로 워크로드를 복구할 수 있습니다. 복구 기능을 사용하면 애플리케이션이 기능을 수행하고 서로 통신하면서 남북의 트래픽에 노출되지 않도록 함으로써 보안 팀이 법의학 및 기타 필요한 조치를 수행할 수 있는 안전한 장소를 제공할 수 있습니다.</block>
  <block id="a20215628470de7f6faa691cc18c4971" category="paragraph"><block ref="a20215628470de7f6faa691cc18c4971" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f95900d5509fa4de2d1c7e9489f4dc6" category="summary">클라우드로 재해 복구는 랜섬웨어 등 사이트 운영 중단 및 데이터 손상 이벤트로부터 워크로드를 보호하는 복원력이 있는 비용 효율적인 방법입니다. NetApp SnapMirror를 사용하면 게스트 연결 스토리지를 사용하는 사내 VMware 워크로드를 Azure에서 실행되는 NetApp Cloud Volumes ONTAP에 복제할 수 있습니다.</block>
  <block id="48b47eaa686f297ed741f5cb81de709d" category="paragraph">저자: Ravi BCB, Niyaz Mohamed, NetApp</block>
  <block id="be93173f941fd10be0e9fddb606bd940" category="paragraph">클라우드로 재해 복구는 랜섬웨어 등 사이트 운영 중단 및 데이터 손상 이벤트로부터 워크로드를 보호하는 복원력이 있는 비용 효율적인 방법입니다. NetApp SnapMirror를 사용하면 게스트 연결 스토리지를 사용하는 사내 VMware 워크로드를 Azure에서 실행되는 NetApp Cloud Volumes ONTAP에 복제할 수 있습니다. 여기에는 애플리케이션 데이터가 포함됩니다. 하지만 실제 VM 자체는 어떻습니까? 재해 복구는 가상 머신, VMDK, 애플리케이션 데이터 등을 비롯한 모든 종속 구성 요소를 포함해야 합니다. 이를 위해 Jetstream과 함께 SnapMirror를 사용하면 VM VMDK에 vSAN 스토리지를 사용하는 동시에 사내에서 Cloud Volumes ONTAP로 복제된 워크로드를 원활하게 복구할 수 있습니다.</block>
  <block id="b25b60af8de6f7256f832e93e5651972" category="paragraph">이 문서에서는 NetApp SnapMirror, Jetstream 및 AVS(Azure VMware Solution)를 사용하여 재해 복구를 설정하고 수행하기 위한 단계별 접근 방식을 제공합니다.</block>
  <block id="8f0e380cfb4a39395f72ab50e67ea50e" category="paragraph"><block ref="8f0e380cfb4a39395f72ab50e67ea50e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="72916c3a8dffc193957f3809a8b4acbf" category="paragraph">이 문서에서는 애플리케이션 데이터(게스트 연결)를 위한 게스트 내 스토리지에 초점을 두고 사내 환경에서 애플리케이션 정합성 보장 백업을 위해 SnapCenter를 사용하고 있다고 가정합니다.</block>
  <block id="d2e057fdab62f3ae766c18c66acc57fd" category="admonition">이 문서는 타사 백업 또는 복구 솔루션에 적용됩니다. 환경에 사용된 솔루션에 따라 Best Practice를 따라 조직 SLA를 충족하는 백업 정책을 생성합니다.</block>
  <block id="380a8e9be36984cc009caa1b7aaadc5d" category="paragraph">온프레미스 환경과 Azure 가상 네트워크 간의 연결을 위해 고속 경로 글로벌 도달 범위 또는 VPN 게이트웨이가 있는 가상 WAN을 사용합니다. 세그먼트는 사내 VLAN 설계를 기반으로 생성해야 합니다.</block>
  <block id="057412b2bc7b34ca7066f70b80b69510" category="admonition">온프레미스 데이터 센터를 Azure에 연결하는 여러 가지 옵션이 있어 이 문서의 특정 워크플로 개요를 볼 수 없습니다. Azure 설명서를 참조하여 적절한 Azure-사내와 Azure 간 연결 방법을 확인하십시오.</block>
  <block id="ecc1cadbbbb0ef1d84ddc861f4497661" category="section-title">DR 솔루션 구축</block>
  <block id="5497ec7c1fdee07126ed64bf9fed5d87" category="section-title">솔루션 구축 개요</block>
  <block id="8eaa61639db3e085f8c7eb12151b3736" category="list-text">필요한 RPO 요구 사항에 따라 SnapCenter를 사용하여 애플리케이션 데이터를 백업했는지 확인합니다.</block>
  <block id="a04938b02e6c8ce6c9dbb34eac7d6a0a" category="list-text">적절한 서브스크립션 및 가상 네트워크 내에서 Cloud Manager를 사용하여 올바른 인스턴스 크기로 Cloud Volumes ONTAP를 프로비저닝합니다.</block>
  <block id="15a6eec061b4c7d026aa504c05f01405" category="list-text">관련 애플리케이션 볼륨에 대해 SnapMirror를 구성합니다.</block>
  <block id="3d1e7fac653a4e240c35721f0e3902da" category="list-text">예약된 작업 후 SnapMirror 업데이트를 트리거하도록 SnapCenter의 백업 정책을 업데이트합니다.</block>
  <block id="2a690d204d02bcc25768246a5c2082bb" category="list-text">Jetstream DR 소프트웨어를 사내 데이터 센터에 설치하고 가상 시스템을 보호합니다.</block>
  <block id="060b718b1c12d4bed763206429b5c467" category="list-text">재해 이벤트 중에 Cloud Manager를 사용하여 SnapMirror 관계를 중단시키고 지정된 AVS DR 사이트의 Azure NetApp Files 또는 vSAN 데이터스토어로 가상 시스템의 페일오버를 트리거합니다.</block>
  <block id="16193a2e612115bbf00cb18e7a9ec1aa" category="list-text">애플리케이션 VM에 대한 iSCSI LUN 및 NFS 마운트를 다시 연결합니다.</block>
  <block id="d274e9c5c862dd28666a25176c344293" category="list-text">운영 사이트가 복구된 후 SnapMirror를 다시 동기화하여 보호 사이트에 대한 페일백을 호출합니다.</block>
  <block id="c99b24a6817b7fd3c4d8687fc4bb35df" category="section-title">배포 세부 정보</block>
  <block id="eb5301ce7e383557ea1c2ecc5d8df8a4" category="example-title">Azure에서 CVO를 구성하고 볼륨을 CVO로 복제합니다</block>
  <block id="97e7c9a7d06eac006a28bf05467fcc8b" category="inline-link">링크</block>
  <block id="ebcd981f8224ab4325994da29465cf8c" category="paragraph">첫 번째 단계는 Azure에서 Cloud Volumes ONTAP를 구성하는 것입니다 <block ref="4e2a8d8afd7d7aca598f792d5d04f9c7" category="inline-link-rx"></block>)를 사용하여 원하는 볼륨을 Cloud Volumes ONTAP에 복제하고 원하는 빈도와 스냅샷 보존 기능을 사용할 수 있습니다.</block>
  <block id="30200baf346b021de0310f8f8307fd8e" category="paragraph"><block ref="30200baf346b021de0310f8f8307fd8e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b453212f1c9ff723da2989dbb439d57e" category="example-title">AVS 호스트 및 CVO 데이터 액세스를 구성합니다</block>
  <block id="46fdc14ede3dd0a84faa31cf1cde9624" category="paragraph">SDDC를 구축할 때 고려해야 할 두 가지 중요한 요소는 Azure VMware 솔루션에서 SDDC 클러스터의 크기와 SDDC를 사용할 수 있는 기간을 결정하는 것입니다. 재해 복구 솔루션의 두 가지 주요 고려 사항은 전체 운영 비용을 절감하는 데 도움이 됩니다. SDDC는 최대 3개의 호스트까지 구성할 수 있으며, 전체 구축 환경에서 다중 호스트 클러스터까지 가능합니다.</block>
  <block id="938f299f0522c6e7bea183a8ea437225" category="paragraph">AVS 클러스터의 구축 결정은 주로 RPO/RTO 요구 사항을 기반으로 합니다. Azure VMware 솔루션을 사용하면 SDDC를 테스트 또는 실제 재해 이벤트에 대비하여 적시에 프로비저닝할 수 있습니다. SDDC를 적시에 구축하면 재해 발생 시 ESXi 호스트 비용을 절감할 수 있습니다. 그러나 이러한 구축 형태는 SDDC를 프로비저닝하는 동안 RTO에 몇 시간 정도 영향을 줍니다.</block>
  <block id="595875340c961d4ff4461ee8fe8a3ce3" category="paragraph">가장 일반적인 구축 옵션은 SDDC를 상시 작동, 파일럿 라이트 모드로 실행하는 것입니다. 이 옵션은 항상 사용 가능한 호스트 세 개로 구성된 작은 공간을 제공하며 시뮬레이션 활동 및 규정 준수 검사를 위한 실행 기준을 제공하여 복구 작업 속도를 높이고 운영 사이트와 DR 사이트 간의 운영 드리프트가 발생하지 않도록 합니다. 실제 DR 이벤트를 처리하는 데 필요한 경우 파일럿 라이트 클러스터를 원하는 레벨로 신속하게 확장할 수 있습니다.</block>
  <block id="2f5ab77fee006682ed15a6dbfb54c2a0" category="paragraph">AVS SDDC를 구성하려면(온디맨드 또는 파일럿 라이트 모드여야 함) 을 참조하십시오<block ref="86c283cfb3c0f32634050918a847eb2d" category="inline-link-rx"></block>. 사전 요구 사항으로, 연결이 설정된 후 AVS 호스트에 상주하는 게스트 VM이 Cloud Volumes ONTAP의 데이터를 사용할 수 있는지 확인합니다.</block>
  <block id="f63f01c08cfc3f386ad47993e097e207" category="paragraph">Cloud Volumes ONTAP 및 AVS를 올바르게 구성한 후에는 VAIO 메커니즘을 사용하고 Cloud Volumes ONTAP에 애플리케이션 볼륨 복사본을 위한 SnapMirror를 활용하여 Jetstream을 구성하여 온프레미스 워크로드를 AVS(게스트 내 스토리지가 있는 응용 프로그램 VMDK 및 VM이 있는 VM)로 자동으로 복구합니다.</block>
  <block id="9f9a4d5afd3892f2b17ecc3ed2ad2630" category="example-title">사내 데이터 센터에 Jetstream DR을 설치합니다</block>
  <block id="68027d729e644485691d1aa185f22dad" category="paragraph">Jetstream DR 소프트웨어는 Jetstream DR Management Server Virtual Appliance(MSA), DR 가상 어플라이언스(DRVA) 및 호스트 구성 요소(I/O 필터 패키지)의 세 가지 주요 구성 요소로 구성됩니다. MSA는 컴퓨팅 클러스터에 호스트 구성 요소를 설치 및 구성한 다음 Jetstream DR 소프트웨어를 관리하는 데 사용됩니다. 설치 프로세스는 다음과 같습니다.</block>
  <block id="2e5f490166b4cbb95848c72a3f3296cd" category="list-text">필수 구성 요소를 확인하십시오.</block>
  <block id="01eb617ea64b2e2237c95fa866dc6c99" category="list-text">리소스 및 구성 권장 사항에 대해 용량 계획 툴을 실행합니다.</block>
  <block id="91d290eafae733f57fe1874a21a706be" category="list-text">Jetstream DR MSA를 지정된 클러스터의 각 vSphere 호스트에 구축합니다.</block>
  <block id="130231ab3f0401b0c0e0f66fadd45d5d" category="list-text">MSA에 vCenter Server를 등록합니다.</block>
  <block id="6f621d6c94ab64b27eea06de601902d1" category="list-text">Jetstream DR MSA를 구축하고 vCenter Server를 등록한 후 vSphere Web Client를 사용하여 Jetstream DR 플러그인으로 이동합니다. 이 작업은 데이터 센터 &gt; 구성 &gt; Jetstream DR로 이동하여 수행할 수 있습니다.</block>
  <block id="874efc870db36a204a974a32ac47c11e" category="paragraph"><block ref="874efc870db36a204a974a32ac47c11e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9aad471e9824a9ef2c43fae648b07613" category="list-text">Jetstream DR 인터페이스에서 다음 작업을 완료합니다.</block>
  <block id="7ab4f3b382b4ad9e82615cacd27d739c" category="paragraph"><block ref="7ab4f3b382b4ad9e82615cacd27d739c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc59cbc4a86e6676ff3d70ba71ba6c0c" category="list-text">복구 사이트에 있는 Azure Blob 저장소를 추가합니다.</block>
  <block id="c86146f54b5d798bebf8802ac8b9fcde" category="paragraph"><block ref="c86146f54b5d798bebf8802ac8b9fcde" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47d0f0f8f33fcbb5e022f9d64bbbed63" category="list-text">Appliances 탭에서 필요한 수의 DR 가상 어플라이언스(DRVA)를 구축합니다.</block>
  <block id="f609ba6f20a39912fd585d05df8bc4de" category="admonition">용량 계획 툴을 사용하여 필요한 DRVA의 수를 추정합니다.</block>
  <block id="4c16a641767d4c33c410687e7b6613ef" category="paragraph"><block ref="4c16a641767d4c33c410687e7b6613ef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1a6b84958a757d2c38048bdf788c590f" category="paragraph"><block ref="1a6b84958a757d2c38048bdf788c590f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b7fbe3ea0d16e8cdd943c71406ee9095" category="list-text">사용 가능한 데이터 저장소 또는 독립 공유 iSCSI 스토리지 풀에서 VMDK를 사용하여 각 DRVA에 대한 복제 로그 볼륨을 생성합니다.</block>
  <block id="376f9301b1fb23692806f601a501bc1d" category="paragraph"><block ref="376f9301b1fb23692806f601a501bc1d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3603870d5d8cd5f384cf0b1258a4276a" category="list-text">보호 도메인 탭에서 Azure Blob 저장소 사이트, DRVA 인스턴스 및 복제 로그에 대한 정보를 사용하여 필요한 수의 보호된 도메인을 만듭니다. 보호 도메인은 함께 보호되고 장애 조치/장애 복구 작업에 우선 순위 순서를 할당하는 클러스터 내의 특정 VM 또는 애플리케이션 VM 세트를 정의합니다.</block>
  <block id="fc72030b6d0a9889fccd2facfedc6b0e" category="paragraph"><block ref="fc72030b6d0a9889fccd2facfedc6b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="09795e4b943747b98cfc63dfc54275c3" category="paragraph"><block ref="09795e4b943747b98cfc63dfc54275c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb05314ca50bac72a0b13f171a2b6912" category="list-text">보호할 VM을 선택하고 종속성을 기반으로 VM을 애플리케이션 그룹으로 그룹화합니다. 애플리케이션 정의를 사용하면 VM 세트를 부팅 순서, 부팅 지연 및 복구 시 실행할 수 있는 선택적 애플리케이션 검증을 포함하는 논리 그룹으로 그룹화할 수 있습니다.</block>
  <block id="818cadd78e726fcca2ca69a99c22df63" category="admonition">보호 도메인의 모든 VM에 동일한 보호 모드가 사용되는지 확인합니다.</block>
  <block id="8cc32e4f2682b9a5731a285459a5d9c5" category="admonition">VMDK(Write-Back) 모드는 더 높은 성능을 제공합니다.</block>
  <block id="639f5dd27b8ff76608b346f78c673b4c" category="paragraph"><block ref="639f5dd27b8ff76608b346f78c673b4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c916465a580d8d569bd369e8e7f6d609" category="list-text">복제 로그 볼륨이 고성능 스토리지에 배치되었는지 확인합니다.</block>
  <block id="1fc3826d710244fdb6c4a09d89f98d5f" category="paragraph"><block ref="1fc3826d710244fdb6c4a09d89f98d5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5038dd04f28442b45e40cc394920ed6" category="list-text">작업을 완료한 후 보호 도메인에 대한 보호 시작 을 클릭합니다. 그러면 선택한 VM에 대한 데이터 복제가 지정된 Blob 저장소로 시작됩니다.</block>
  <block id="5ed7580bd1e6ae0cef691df5ee3b54a2" category="paragraph"><block ref="5ed7580bd1e6ae0cef691df5ee3b54a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e860406ba63567c5eccf30055287b47" category="list-text">복제가 완료되면 VM 보호 상태가 복구 가능으로 표시됩니다.</block>
  <block id="c873c8c59414399f210af5ec22a764d8" category="paragraph"><block ref="c873c8c59414399f210af5ec22a764d8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a918d27a636eddf2d16b9e8544402c44" category="admonition">페일오버 런북은 VM(복구 그룹이라고 함)을 그룹화하고 부팅 순서 시퀀스를 설정하고 IP 구성과 함께 CPU/메모리 설정을 수정하도록 구성할 수 있습니다.</block>
  <block id="90ee2ee79e46dfb341705824bdba5b5a" category="list-text">설정 을 클릭한 다음 Runbook 구성 링크를 클릭하여 Runbook 그룹을 구성합니다.</block>
  <block id="92471f4927394b88148206ffbdc25dbd" category="paragraph"><block ref="92471f4927394b88148206ffbdc25dbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6c352449075dfd7c55f51cc486cc2541" category="list-text">새 Runbook 그룹을 생성하려면 Create Group 버튼을 클릭합니다.</block>
  <block id="e2fbd552cab46f747bc672bf2e1b0fe9" category="admonition">필요한 경우 화면 아래쪽에 사용자 지정 사전 스크립트 및 사후 스크립트를 적용하여 Runbook 그룹의 작업 전후에 자동으로 실행합니다. Runbook 스크립트가 관리 서버에 있는지 확인합니다.</block>
  <block id="27601285770e6db675411c9282459b87" category="paragraph"><block ref="27601285770e6db675411c9282459b87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f26b7048f93345b3726eb88bd506893a" category="list-text">필요에 따라 VM 설정을 편집합니다. 부팅 순서, 부팅 지연(초 단위로 지정), CPU 수 및 할당할 메모리 양을 포함하여 VM을 복구하기 위한 매개 변수를 지정합니다. 위쪽 또는 아래쪽 화살표를 클릭하여 VM의 부팅 순서를 변경합니다. MAC를 유지하기 위한 옵션도 제공됩니다.</block>
  <block id="ff0274a4eb386ebd23581a082f3b5b5b" category="paragraph"><block ref="ff0274a4eb386ebd23581a082f3b5b5b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c2cb19a0ef20564c20014e97d134168" category="list-text">정적 IP 주소는 그룹의 개별 VM에 대해 수동으로 구성할 수 있습니다. VM의 NIC View 링크를 클릭하여 IP 주소 설정을 수동으로 구성합니다.</block>
  <block id="f26795dd104c3568722b09bce335c904" category="paragraph"><block ref="f26795dd104c3568722b09bce335c904" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a85bcb54a31960de00ecac27985d3f3a" category="list-text">구성 버튼을 클릭하여 해당 VM에 대한 NIC 설정을 저장합니다.</block>
  <block id="d6431b9ceb7168220978cc8a6f804dc2" category="paragraph"><block ref="d6431b9ceb7168220978cc8a6f804dc2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c295c7835a978c48c9f8253edc92e6ab" category="paragraph"><block ref="c295c7835a978c48c9f8253edc92e6ab" category="inline-image-macro-rx" type="image"></block></block>
  <block id="423aff401e73269c665789c2a91cd2ba" category="paragraph">이제 페일오버 및 페일백 Runbook의 상태가 모두 Configured로 표시됩니다. 페일오버 및 페일백 Runbook 그룹은 동일한 초기 VM 및 설정 그룹을 사용하여 쌍으로 생성됩니다. 필요한 경우 각 Runbook 그룹의 세부 정보 링크를 클릭하고 설정을 변경하여 Runbook 그룹의 설정을 개별적으로 사용자 지정할 수 있습니다.</block>
  <block id="8868e7fa41b895d0441f3c000558500e" category="example-title">프라이빗 클라우드에 AVS용 Jetstream DR을 설치합니다</block>
  <block id="ca2d476f98a102308a1ca46e0314f094" category="paragraph">복구 사이트(AVS)의 모범 사례는 3노드 파일럿 라이트 클러스터를 미리 생성하는 것입니다. 이를 통해 다음을 포함하여 복구 사이트 인프라를 사전 구성할 수 있습니다.</block>
  <block id="03bd3d186e1fc83d47907ac1797d8eaf" category="list-text">대상 네트워킹 세그먼트, 방화벽, DHCP 및 DNS 등의 서비스 등</block>
  <block id="543c0ee14bc42e7f38251e99ace0ea62" category="list-text">데이터 저장소 등을 사용하여 ANF 볼륨 구성</block>
  <block id="1e09668d117c7996e6a76a4aa2e44013" category="paragraph">Jetstream DR은 미션 크리티컬 도메인에 대해 제로급 RTO 모드를 지원합니다. 이러한 도메인의 경우 대상 스토리지가 사전 설치되어 있어야 합니다. ANF는 이 경우 권장되는 스토리지 유형입니다.</block>
  <block id="d9a7d19a656972791042b00bc2a308fa" category="admonition">SLA 및 RTO 요구 사항에 따라 연속 페일오버 또는 일반(표준) 페일오버 모드를 사용할 수 있습니다. 제로급 RTO의 경우 복구 사이트에서 연속 재수화를 시작해야 합니다.</block>
  <block id="4b2287bada3112a86338f8d33bb7f745" category="list-text">Azure VMware 솔루션 프라이빗 클라우드에 AVS용 Jetstream DR을 설치하려면 실행 명령을 사용하십시오. Azure 포털에서 Azure VMware 솔루션으로 이동하고 프라이빗 클라우드를 선택한 다음 명령 실행 &gt; 패키지 &gt; JSDR.Configuration을 선택합니다.</block>
  <block id="f36d2f16d7b758d071070007e41f1dc3" category="admonition">Azure VMware 솔루션의 기본 CloudAdmin 사용자는 AVS용 Jetstream DR을 설치할 권한이 없습니다. Azure VMware 솔루션을 사용하면 Jetstream DR용 Azure VMware 솔루션 실행 명령을 호출하여 Jetstream DR을 간단하고 자동으로 설치할 수 있습니다.</block>
  <block id="d5c094ac3602dc70c812b6f203db3080" category="paragraph"><block ref="d5c094ac3602dc70c812b6f203db3080" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1059f69ded45aab3e16676f7655ce33e" category="paragraph"><block ref="1059f69ded45aab3e16676f7655ce33e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f56ba70e80cd5a9d7e833ae9c2a8d00b" category="list-text">온-프레미스 클러스터를 저장소 사이트로 보호하는 데 사용된 Azure Blob 저장소 계정을 추가한 다음 도메인 검사 옵션을 실행합니다.</block>
  <block id="d46ac425273c7af91c98f03afab4d05d" category="list-text">나타나는 팝업 대화 상자에서 가져올 보호된 도메인을 선택한 다음 해당 가져오기 링크를 클릭합니다.</block>
  <block id="8f6ce8893e72ca9a99ea54a38aa9123c" category="paragraph"><block ref="8f6ce8893e72ca9a99ea54a38aa9123c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="258e652acbaceeb040a052eb56f710ff" category="list-text">복구를 위해 도메인을 가져옵니다. 보호 도메인 탭으로 이동하여 원하는 도메인이 선택되었는지 확인하거나 보호 도메인 선택 메뉴에서 원하는 도메인을 선택합니다. 보호된 도메인에 있는 복구 가능한 VM 목록이 표시됩니다.</block>
  <block id="44f0914b6b6c354b3ed0d0f5c88f5f40" category="paragraph"><block ref="44f0914b6b6c354b3ed0d0f5c88f5f40" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ab8894857a9c27d55e00ceb59f0a0a9d" category="list-text">보호된 도메인을 가져온 후 DRVA 어플라이언스를 구축합니다.</block>
  <block id="a594598fd21c66eb364972e1018fc5b1" category="admonition">CPT 생성 계획을 사용하여 이러한 단계를 자동화할 수도 있습니다.</block>
  <block id="5dbd13899d13d449aaa288efb68bc4e7" category="list-text">보호된 도메인을 가져오고 VM 배치에 ANF 데이터 저장소를 사용하도록 복구 VA를 구성합니다.</block>
  <block id="30c90d4c81b9e156fa124f63997bd267" category="paragraph"><block ref="30c90d4c81b9e156fa124f63997bd267" category="inline-image-macro-rx" type="image"></block></block>
  <block id="27ece16fa591c8a94d158b6371824318" category="admonition">선택한 세그먼트에서 DHCP가 활성화되어 있고 사용 가능한 IP가 충분한지 확인합니다. 도메인이 복구되는 동안 동적 IP가 일시적으로 사용됩니다. 복구 중인 각 VM(연속 재수화 포함)에는 개별 동적 IP가 필요합니다. 복구가 완료되면 IP가 해제되고 다시 사용할 수 있습니다.</block>
  <block id="221af48bbe7986080d7f1ef43b7cc9af" category="admonition">연속 페일오버 모드와 페일오버 모드는 구성이 수행될 때 다르지만, 두 페일오버 모드는 동일한 단계를 사용하여 구성됩니다. 장애 조치 단계는 재해 이벤트에 따라 함께 구성 및 수행됩니다. 지속적인 페일오버는 언제든지 구성할 수 있으며, 이후 정상적인 시스템 작동 중에 백그라운드에서 실행될 수 있습니다. 재해 이벤트가 발생한 후 지속적인 페일오버가 완료되어 보호된 VM의 소유권을 복구 사이트로 즉시 전송합니다(제로급 RTO).</block>
  <block id="12d3f891efb3e0286e3d610d87fa763c" category="paragraph"><block ref="12d3f891efb3e0286e3d610d87fa763c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fad47d76ebfb2068cc150f23d3abc231" category="paragraph">지속적인 장애 조치 프로세스가 시작되고 UI에서 진행 상태를 모니터링할 수 있습니다. 현재 단계 섹션에서 파란색 아이콘을 클릭하면 페일오버 프로세스의 현재 단계에 대한 세부 정보를 보여주는 팝업 창이 표시됩니다.</block>
  <block id="07216bb55061288a2fa29cda954742e3" category="example-title">페일오버 및 페일백</block>
  <block id="3dd9279db501526060882c484e7fa2eb" category="list-text">사내 환경의 보호된 클러스터에서 재해가 발생한 후(일부 또는 전체 장애) 해당 애플리케이션 볼륨에 대한 SnapMirror 관계를 끊은 후 Jetstream을 사용하여 VM에 대한 페일오버를 트리거할 수 있습니다.</block>
  <block id="4e26d6c9cc7404940d6c72a71775d261" category="paragraph"><block ref="4e26d6c9cc7404940d6c72a71775d261" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7c749826108cc466667dcaeb67965a7" category="paragraph"><block ref="f7c749826108cc466667dcaeb67965a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="253d2b2bed504833d82e064634bbf83e" category="admonition">이 단계는 복구 프로세스를 용이하게 하기 위해 쉽게 자동화할 수 있습니다.</block>
  <block id="9824ceea6f74aa9d72ed2bd7473b9362" category="list-text">AVS SDDC(대상 측)에서 Jetstream UI에 액세스하고 페일오버 옵션을 트리거하여 페일오버를 완료합니다. 작업 표시줄에 장애 조치 작업의 진행률이 표시됩니다.</block>
  <block id="b39966f9c6438e5d60c1de37dfa3ed05" category="paragraph">페일오버를 완료할 때 나타나는 대화 상자에서 페일오버 작업을 계획대로 지정하거나 강제 작업으로 가정할 수 있습니다.</block>
  <block id="684bb098f20646b3f18e10bc17e2d3c4" category="paragraph"><block ref="684bb098f20646b3f18e10bc17e2d3c4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="562cb54fd49a347cfb889e6021e0be34" category="paragraph"><block ref="562cb54fd49a347cfb889e6021e0be34" category="inline-image-macro-rx" type="image"></block></block>
  <block id="979b519fc9d5e27e5d114696ce4b1366" category="paragraph">강제 대체 작동 에서는 운영 사이트에 더 이상 액세스할 수 없으며 보호 도메인의 소유권이 복구 사이트에 의해 직접 가정되어야 한다고 가정합니다.</block>
  <block id="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="paragraph"><block ref="cfb2ac66b6e4f6580c9c1fb2cf3b42a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9be51d726dd7c6ae76c2545a91f36d11" category="paragraph"><block ref="9be51d726dd7c6ae76c2545a91f36d11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fce15eac6afaa8615d7a00cc4972808" category="list-text">연속 페일오버가 완료되면 작업 완료를 확인하는 메시지가 나타납니다. 작업이 완료되면 복구된 VM에 액세스하여 iSCSI 또는 NFS 세션을 구성합니다.</block>
  <block id="53839296d302ef4a3faf8220562c1ce4" category="admonition">페일오버 모드가 페일오버에서 실행 중으로 변경되고 VM 상태는 복구 가능합니다. 이제 보호 도메인의 모든 VM이 페일오버 Runbook 설정에 지정된 상태의 복구 사이트에서 실행됩니다.</block>
  <block id="50ff3dc4ca6f3eb140f2099f2b480b83" category="admonition">장애 조치 구성 및 인프라를 확인하기 위해 Jetstream DR을 테스트 모드(장애 조치 테스트 옵션)로 작동하여 가상 시스템 및 해당 데이터가 개체 저장소에서 테스트 복구 환경으로 복구되는 것을 관찰할 수 있습니다. 테스트 모드에서 페일오버 절차를 실행하면 실제 페일오버 프로세스와 비슷합니다.</block>
  <block id="a6687fcac4b89ac042d0bf01e0eed2c7" category="paragraph"><block ref="a6687fcac4b89ac042d0bf01e0eed2c7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf3e40ce09f6fe770361fe49d398cad9" category="list-text">가상 머신이 복구된 후 게스트 내 스토리지에 스토리지 재해 복구를 사용합니다. 이 프로세스를 시연하기 위해 이 예에서는 SQL Server가 사용됩니다.</block>
  <block id="e5007f72fe428769908e4b66a64b1ace" category="list-text">AVS SDDC에서 복구된 SnapCenter VM에 로그인하고 DR 모드를 활성화합니다.</block>
  <block id="8bc57e8e0debd3b1f0e1c01431ceb73b" category="list-text">browserN을 사용하여 SnapCenter UI에 액세스합니다.</block>
  <block id="b29ffa42af1df2e35cdf88be1740bdf8" category="paragraph"><block ref="b29ffa42af1df2e35cdf88be1740bdf8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="392d143fa78a9868b2d56197de458a8d" category="list-text">설정 페이지에서 설정 &gt; 글로벌 설정 &gt; 재해 복구 로 이동합니다.</block>
  <block id="f4060a5dfc75e427eab8fc559b5c3873" category="list-text">재해 복구 활성화 를 선택합니다.</block>
  <block id="79bee17b4293b619c241ae80aef8ef62" category="list-text">적용 을 클릭합니다.</block>
  <block id="24049296b222c98c12a36098c1928b9f" category="paragraph"><block ref="24049296b222c98c12a36098c1928b9f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f31c54b6a166b6ab176f034d0f52e291" category="list-text">모니터 &gt; 작업 을 클릭하여 DR 작업이 활성화되었는지 확인합니다.</block>
  <block id="a194386b24136c162d5de560f2c4b3c9" category="admonition">스토리지 재해 복구에 NetApp SnapCenter 4.6 이상을 사용해야 합니다. 이전 버전의 경우 SnapMirror를 사용하여 복제된 애플리케이션 정합성 보장 스냅샷을 사용해야 하며, 재해 복구 사이트에서 이전 백업을 복구해야 하는 경우 수동 복구를 실행해야 합니다.</block>
  <block id="a1e59d581c6cda40186a3488aa35c0b5" category="list-text">SnapMirror 관계가 끊어져 있는지 확인합니다.</block>
  <block id="ab99ab9f50b0f74bd7b676fbb522f5e8" category="paragraph"><block ref="ab99ab9f50b0f74bd7b676fbb522f5e8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5fabb74faf982c31918e4a241092e386" category="list-text">Cloud Volumes ONTAP의 LUN을 동일한 드라이브 문자로 복구된 SQL 게스트 VM에 연결합니다.</block>
  <block id="faedf38240e42a0e3f085f6acdc22aec" category="paragraph"><block ref="faedf38240e42a0e3f085f6acdc22aec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="458585a8fad71bd63549d32afd2c2f69" category="list-text">iSCSI 초기자를 열고, 이전에 연결이 끊긴 세션을 지우고, 복제된 Cloud Volumes ONTAP 볼륨에 대한 다중 경로와 함께 새 대상을 추가합니다.</block>
  <block id="5d06816a9331ccf1bde11d80e2438672" category="paragraph"><block ref="5d06816a9331ccf1bde11d80e2438672" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2483b40da799327d80d5aa5c4683efee" category="list-text">DR 이전에 사용한 드라이브 문자와 동일한 드라이브 문자를 사용하여 모든 디스크가 연결되어 있는지 확인합니다.</block>
  <block id="75c3e1de048df1f08f612bb44462afd4" category="paragraph"><block ref="75c3e1de048df1f08f612bb44462afd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6048d3c947f6b9163f72586701cec853" category="list-text">MSSQL 서버 서비스를 다시 시작합니다.</block>
  <block id="9f8472ea6d004535fc1659d1e6863867" category="paragraph"><block ref="9f8472ea6d004535fc1659d1e6863867" category="inline-image-macro-rx" type="image"></block></block>
  <block id="632dc72bd4eb731f74582d644a0f4b3c" category="list-text">SQL 리소스가 다시 온라인 상태인지 확인합니다.</block>
  <block id="9d19926e46fa4cd818065a2726bcf42d" category="paragraph"><block ref="9d19926e46fa4cd818065a2726bcf42d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="01fb98a09bb6b1d922a6275724f31823" category="admonition">NFS의 경우 mount 명령을 사용하여 볼륨을 연결하고 '/etc/fstab' 항목을 업데이트합니다.</block>
  <block id="8145668f843709bddb7b6c8b3f3abbfb" category="paragraph">이 시점에서는 작업을 실행하고 정상적으로 비즈니스를 계속할 수 있습니다.</block>
  <block id="8020518363652d35b23a9585c780e480" category="admonition">NSX-T 엔드에서는 페일오버 시나리오를 시뮬레이션하기 위해 별도의 전용 Tier-1 게이트웨이를 생성할 수 있습니다. 이렇게 하면 모든 워크로드가 서로 통신할 수 있지만, 트래픽이 환경 내외부로 라우팅될 수는 없으므로 교차 오염의 위험 없이 모든 분류, 억제 또는 강화 작업을 수행할 수 있습니다. 이 작업은 이 문서의 범위를 벗어나지만 격리 시뮬레이션을 위해 쉽게 수행할 수 있습니다.</block>
  <block id="7d7b7ba342280685358aeb9937ce1118" category="paragraph">운영 사이트가 다시 가동된 후 페일백을 수행할 수 있습니다. Jetstream에 의해 VM 보호가 재개되고 SnapMirror 관계가 역전되어야 합니다.</block>
  <block id="5a24d57462c6d674800fbb2a7e0c59ce" category="list-text">사내 환경을 복원합니다. 재해 발생 유형에 따라 보호 클러스터의 구성을 복원 및/또는 확인해야 할 수도 있습니다. 필요한 경우 Jetstream DR 소프트웨어를 재설치해야 할 수 있습니다.</block>
  <block id="5cf6cc1cdb0715aca121fb45bdc4f42e" category="admonition">CPT에서 생성한 페일백 계획을 사용하여 VM과 해당 데이터를 오브젝트 저장소에서 원래 VMware 환경으로 되돌릴 수도 있습니다.</block>
  <block id="130f86be5d695ec045cce675d14637b8" category="paragraph"><block ref="130f86be5d695ec045cce675d14637b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="504e0be50ebedab76e2a7714a22354d3" category="admonition">복구 사이트에서 VM을 일시 중지하고 보호 사이트에서 다시 시작한 후 최대 지연 시간을 지정합니다. 이 프로세스를 완료하는 데 필요한 시간은 장애 조치 VM을 중지한 후 복제 완료, 복구 사이트를 청소하는 데 필요한 시간, 보호 사이트에서 VM을 다시 만드는 데 필요한 시간 등을 포함합니다. 10분을 권장합니다.</block>
  <block id="41f8873d7ef0fd0767f8ed6d7798fe87" category="paragraph"><block ref="41f8873d7ef0fd0767f8ed6d7798fe87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5752ed9acb85541568eca0327a24e09f" category="list-text">페일백 프로세스를 완료한 다음 VM 보호 및 데이터 정합성 재개를 확인합니다.</block>
  <block id="f872505992d08e75adcaa8a9adbc0d18" category="paragraph"><block ref="f872505992d08e75adcaa8a9adbc0d18" category="inline-image-macro-rx" type="image"></block></block>
  <block id="684bcaaa7dda535165cb0b8f8e76a5ea" category="list-text">VM이 복구된 후 호스트에서 보조 스토리지를 분리하고 운영 스토리지에 접속합니다.</block>
  <block id="79f47ff1cd40017f1ef0eb31e7397d75" category="paragraph"><block ref="79f47ff1cd40017f1ef0eb31e7397d75" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18f7dd50970b99e8a3cdeab8c42567b0" category="paragraph"><block ref="18f7dd50970b99e8a3cdeab8c42567b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f0269cfb1a6f24731b2bb3a15b436b2" category="list-text">SQL 리소스가 다시 온라인 상태인지 확인합니다.</block>
  <block id="bb9592df1a1b3d7ea469affe88be679f" category="paragraph"><block ref="bb9592df1a1b3d7ea469affe88be679f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f41823ca0d78e787fda8ba7b1c398a29" category="admonition">운영 스토리지로 페일백하려면 역방향 재동기화 작업을 수행하여 페일오버 전과 관계 방향이 동일한지 확인합니다.</block>
  <block id="6decfeed5d1c375e40e96552e631df25" category="admonition">역재동기화 작업 후 운영 스토리지와 보조 스토리지의 역할을 유지하려면 역방향 재동기화 작업을 다시 수행하십시오.</block>
  <block id="2087f49e4433786c996468974c61ae4a" category="paragraph">이 프로세스는 Oracle과 같은 다른 애플리케이션, 유사한 데이터베이스 유형 및 게스트 연결 스토리지를 사용하는 다른 애플리케이션에 적용됩니다.</block>
  <block id="33b4e9a3c1a928dbdf5273b34d899e61" category="paragraph">항상 그렇듯이 중요한 워크로드를 운영 환경으로 포팅하기 전에 해당 워크로드를 복구하는 단계를 테스트하십시오.</block>
  <block id="4932435adc5992fde32a04e44fd251b8" category="section-title">이 솔루션의 이점</block>
  <block id="3a02a011f551429a5ec8b46a00017abd" category="list-text">SnapMirror의 효율적이고 복원력이 뛰어난 복제를 사용합니다.</block>
  <block id="74915666b8d10f77a73b526e91724cc8" category="list-text">ONTAP 스냅샷 보존을 사용하여 사용 가능한 모든 시점 복구</block>
  <block id="a3704e4802422c6765dd406472307ba1" category="list-text">스토리지, 컴퓨팅, 네트워크 및 애플리케이션 검증 단계에서 수백 또는 수천 개의 VM을 복구하는 데 필요한 모든 단계에서 완전한 자동화가 가능합니다.</block>
  <block id="c0e8bb909ee76b5f9683012fd9418729" category="list-text">SnapCenter는 복제된 볼륨을 변경하지 않는 클론 생성 메커니즘을 사용합니다.</block>
  <block id="d92ea079cd9d83d3d60c1269804b766c" category="list-text">이렇게 하면 볼륨 및 스냅숏에 대한 데이터 손상 위험이 방지됩니다.</block>
  <block id="843b8877e30b7587ad87b95cd115df4a" category="list-text">DR 테스트 워크플로우 중에 복제 중단 방지</block>
  <block id="a29a4a29d457d4322f1f22ed58f9b06a" category="list-text">개발/테스트, 보안 테스트, 패치 및 업그레이드 테스트, 수정 테스트 등 DR 이외의 워크플로우에 DR 데이터를 활용합니다.</block>
  <block id="e04e963feedf7f0157e360dc2be6d7b3" category="list-text">CPU 및 RAM 최적화를 통해 보다 작은 컴퓨팅 클러스터로 복구할 수 있으므로 클라우드 비용을 절감할 수 있습니다.</block>
  <block id="bd3260deba05f8c5831890f164f83733" category="doc">ANF 데이터 저장소 솔루션 개요</block>
  <block id="626c4c46c0b0900648e0b954a96c4399" category="paragraph">성공적인 모든 조직은 혁신과 현대화의 길을 따라 있습니다. 이 프로세스의 일환으로, 기업은 일반적으로 기존 VMware 투자를 활용하는 동시에 클라우드의 이점을 활용하고 마이그레이션, 버스트, 확장 및 재해 복구 프로세스를 최대한 원활하게 만드는 방법을 모색합니다. 클라우드로 마이그레이션하는 고객은 탄력성 및 폭발적 문제, 데이터 센터 이탈, 데이터 센터 통합, 수명 종료 시나리오, 인수 합병 등을 평가해야 합니다. 각 조직에서 채택한 접근 방식은 각 비즈니스 우선순위에 따라 다를 수 있습니다. 클라우드 기반 운영을 선택할 때 적절한 성능과 최소 장애 요인을 갖춘 저렴한 모델을 선택하는 것이 중요한 목표입니다. 적합한 플랫폼을 선택할 뿐만 아니라, 스토리지 및 워크플로우 오케스트레이션은 클라우드의 강력한 기능과 탄력성을 최대한 활용하는 데 특히 중요합니다.</block>
  <block id="bcc2a83e573fb5cbbcd097908c609fa6" category="paragraph">Azure VMware 솔루션은 고객에게 고유한 하이브리드 기능을 제공하지만, 제한된 기본 스토리지 옵션으로 스토리지 집약적인 워크로드를 사용하는 조직의 유용성이 제한됩니다. 스토리지가 호스트에 직접 연결되어 있으므로 스토리지를 확장하는 유일한 방법은 호스트를 추가하는 것입니다. 이렇게 하면 스토리지 집약적인 워크로드에서 비용이 35-40% 이상 증가할 수 있습니다. 이러한 워크로드는 추가 처리 능력이 아니라 추가 스토리지를 필요로 합니다. 즉, 추가 호스트에 대한 비용을 지불해야 합니다.</block>
  <block id="abc79d01b4318a1c67504eb7714e360f" category="paragraph">다음 시나리오를 고려해 보겠습니다. 고객은 마력(vCPU/vmem)을 위해 6개의 호스트를 필요로 하지만 스토리지에 대한 요구 사항도 상당히 있습니다. 평가를 기준으로 볼 때 스토리지 요구사항을 충족하기 위해 12개의 호스트가 필요합니다. 이렇게 하면 실제로 필요한 모든 것이 더 많은 스토리지일 때 마력을 추가로 구입해야 하기 때문에 전체 TCO가 증가합니다. 마이그레이션, 재해 복구, 사용 급증, 개발/테스트, 등.</block>
  <block id="f6faa113f88d1f8c4795fe189493d34f" category="paragraph">Azure VMware 솔루션의 또 다른 일반적인 사용 사례는 DR(재해 복구)입니다. 대부분의 조직은 재해 복구 전략이 없거나 DR을 위한 고스트 데이터 센터의 실행을 정당화하는 데 어려움을 겪을 수 있습니다. 관리자는 파일럿 라이트 클러스터 또는 온디맨드 클러스터를 통해 설치 공간이 필요 없는 DR 옵션을 탐색할 수 있습니다. 그런 다음 호스트를 추가하지 않고 스토리지를 확장할 수 있으므로 매력적인 옵션이 될 수 있습니다.</block>
  <block id="feb87b8a766262f1649eb73f664b5237" category="paragraph">요약하자면, 사용 사례는 다음 두 가지 방법으로 분류할 수 있습니다.</block>
  <block id="113270f68f35ffcbf2a57597bd22e665" category="list-text">ANF 데이터 저장소를 사용하여 스토리지 용량을 확장합니다</block>
  <block id="a46f3b69652b37f2becc5ad8def389fe" category="list-text">소프트웨어 정의 데이터 센터(SDDC) 간의 사내 또는 Azure 지역 내에서 비용 최적화된 복구 워크플로를 위해 ANF 데이터 저장소를 재해 복구 타겟으로 사용합니다. 이 가이드에서는 Azure NetApp Files를 사용하여 데이터 저장소에 최적화된 스토리지(현재 공개 미리 보기)를 제공하는 방법에 대해 설명합니다. Azure VMware 솔루션에서 동급 최고의 데이터 보호 및 DR 기능을 제공하므로 vSAN 스토리지에서 스토리지 용량을 오프로드할 수 있습니다.</block>
  <block id="301964836d84fb491fca23f51f902cd0" category="admonition">Azure NetApp Files 데이터 저장소 기능은 현재 공개 미리 보기에 있습니다. 자세한 내용은 해당 지역의 NetApp 또는 Microsoft 솔루션 설계자에게 문의하십시오.</block>
  <block id="9d5486edf9a5ddec98d7f7509d50101c" category="section-title">Azure의 VMware 클라우드 옵션</block>
  <block id="809dd7fcec8077467eab0222ea68e259" category="paragraph">Azure VMware 솔루션(AVS)은 Microsoft Azure 퍼블릭 클라우드 내에서 완벽하게 작동하는 VMware SDDC를 제공하는 하이브리드 클라우드 서비스입니다. AVS는 Microsoft에서 완벽하게 관리 및 지원하고 Azure 인프라를 사용하는 VMware에서 검증한 최초의 솔루션입니다. 따라서 고객은 컴퓨팅 가상화를 위한 VMware ESXi, 하이퍼 컨버지드 스토리지를 위한 vSAN 및 네트워킹 및 보안을 위한 NSX를 얻는 동시에 Microsoft Azure의 세계적인 입지, 동급 최고의 데이터 센터 시설 및 네이티브 Azure 서비스 및 솔루션의 풍부한 에코시스템에 근접할 수 있는 이점을 누릴 수 있습니다. Azure VMware 솔루션 SDDC와 Azure NetApp Files를 함께 사용하면 네트워크 지연 시간을 최소화하면서 최상의 성능을 얻을 수 있습니다.</block>
  <block id="8718654ef588a85b2a2e46a7727fa16d" category="paragraph">사용된 클라우드에 관계없이 VMware SDDC를 구축할 때 초기 클러스터에 포함되는 구성 요소는 다음과 같습니다.</block>
  <block id="b6955e4f04d87bd186e8f355b710c814" category="list-text">관리를 위해 vCenter Server 어플라이언스를 사용하여 컴퓨팅 가상화를 위한 VMware ESXi 호스트</block>
  <block id="c865d5c3f7aef0fea827cecdf6da386c" category="list-text">VMware vSAN 하이퍼 컨버지드 스토리지는 각 ESXi 호스트의 물리적 스토리지 자산을 통합합니다.</block>
  <block id="4d53c4a03b478ccb8f5a4a2cde37db71" category="list-text">관리를 위해 NSX Manager 클러스터를 사용하여 가상 네트워킹 및 보안을 위한 VMware NSX</block>
  <block id="94d43b2c8702afe74d26d3a9052e59b4" category="paragraph">All-Cloud와 하이브리드 클라우드 중 무엇을 목표로 하고 있든 Azure NetApp Files는 애플리케이션 계층과 함께 애플리케이션 워크로드를 구축하고 관리하는 탁월한 옵션을 제공하는 한편 데이터 요구사항을 애플리케이션 계층으로 원활하게 충족하여 TCO를 줄여줍니다. 어떤 사용 사례에서든 Azure NetApp Files와 함께 Azure VMware 솔루션을 선택하면 클라우드의 이점, 일관된 인프라, 온프레미스 및 멀티 클라우드 전반의 운영, 워크로드의 양방향 이동성, 엔터프라이즈급 용량 및 성능을 빠르게 실현할 수 있습니다. 스토리지를 연결하는 데 사용되는 것과 동일한 친숙한 프로세스 및 절차입니다. 이는 새로운 이름과 함께 변경된 데이터의 위치일 뿐입니다. 도구 및 프로세스는 모두 동일하며 Azure NetApp Files는 전체 배포를 최적화하는 데 도움이 됩니다.</block>
  <block id="7017a5961c414dfbe07b539da73560fb" category="list-text">이제 AVS SDDC에서 Azure NetApp Files를 데이터 저장소로 사용할 수 있습니다.</block>
  <block id="1997ea39c8d744bf66dd1b36df20eca0" category="list-text">애플리케이션 응답 시간을 단축하고 가용성을 높여 필요할 때 언제 어디서나 액세스 워크로드 데이터를 제공합니다.</block>
  <block id="d229778544c20c94bc3a4e634983743a" category="list-text">간단하고 즉각적인 크기 조정 기능을 통해 vSAN 스토리지의 전반적인 복잡성을 단순화합니다.</block>
  <block id="220eb8ba4e87069e79226f808999d319" category="list-text">동적 재구성 기능을 사용하여 미션 크리티컬 워크로드의 성능 보장</block>
  <block id="de55b3d8d98ed7c720c8410fbbce524e" category="list-text">Azure VMware 솔루션 클라우드가 그 목적이라면 Azure NetApp Files는 최적의 구축을 위한 최적의 스토리지 솔루션입니다.</block>
  <block id="a13de136306e099dce523fd8db3f037c" category="list-text">Azure VMware 솔루션 설명서</block>
  <block id="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link"><block ref="2f2e78e0c7d7ff0caf67f34519d3f5e5" category="inline-link-rx"></block></block>
  <block id="5e65b51c08430d6fa3dc13275b00da9d" category="paragraph"><block ref="5e65b51c08430d6fa3dc13275b00da9d" category="inline-link-rx"></block></block>
  <block id="6c32a3d0f1a665987b98dde5a0f96d7d" category="list-text">Azure NetApp Files 설명서</block>
  <block id="ac236475735595f1237223b0184c5cca" category="inline-link"><block ref="ac236475735595f1237223b0184c5cca" category="inline-link-rx"></block></block>
  <block id="742cb4a55dadc1d5ca8efd2956575138" category="paragraph"><block ref="742cb4a55dadc1d5ca8efd2956575138" category="inline-link-rx"></block></block>
  <block id="8d60f49fa5ec93fd2bea5e083359bdc1" category="paragraph">NFS 데이터 저장소 지원은 vSphere의 스토리지 기능을 크게 확장해 주는 사내 구축 환경의 ESXi 버전 3에서 도입되었습니다.</block>
  <block id="1aaea72f240547a6a057b9a88a27144b" category="paragraph">vSphere on NFS는 강력한 성능과 안정성을 제공하기 때문에 사내 가상화 구축에 널리 채택되는 옵션입니다. 사내 데이터 센터에 NAS(Network-Attached Storage)가 많이 있는 경우 Azure NetApp 파일 데이터 저장소와 Azure에 Azure VMware 솔루션 SDDC를 구축하여 용량 및 성능 문제를 해결하는 것이 좋습니다.</block>
  <block id="19fb9916968211db983d13bffe0cc6af" category="inline-link">99.99%</block>
  <block id="ad25c186e2eeaa2ec5fa0b9d3fa4b8c7" category="paragraph">Azure NetApp Files는 업계 최고의 고가용성 NetApp ONTAP 데이터 관리 소프트웨어를 기반으로 구축되었습니다. Microsoft Azure 서비스는 기본, 메인스트림, 전문 등 세 가지 범주로 분류됩니다. Azure NetApp Files는 특수 범주에 속하며 이미 여러 지역에 배포된 하드웨어를 통해 지원됩니다. Azure NetApp Files에는 고가용성(HA)이 내장되어 있어 대부분의 운영 중단으로부터 데이터를 보호하고 업계 최고 수준의 SLA를 제공합니다<block ref="404362048587970f5f15a4d9376a71ea" category="inline-link-rx"></block> 가동 시간.</block>
  <block id="1b69b6091c2756a0aac2b81e4a880f93" category="paragraph">Azure NetApp Files 데이터 저장소 기능을 도입하기 전에 성능 및 스토리지 집약적인 워크로드를 호스팅하려는 고객을 위한 스케일아웃 작업에 컴퓨팅 및 스토리지를 모두 확장해야 했습니다.</block>
  <block id="09d432ffd44a3af2e2524362730628cf" category="paragraph">다음 문제를 명심하십시오.</block>
  <block id="79786892120b18078ded972068ce7cab" category="list-text">SDDC 클러스터에서는 불균형 클러스터 구성을 사용하지 않는 것이 좋습니다. 따라서 스토리지 확장이란 호스트를 더 추가하는 것을 의미하며, 이는 더 많은 TCO를 의미합니다.</block>
  <block id="4d7a269595fa13e9d4bb48449c996a41" category="list-text">하나의 vSAN 환경만 가능합니다. 따라서 모든 스토리지 트래픽이 운영 워크로드와 직접 경쟁합니다.</block>
  <block id="99407e1fc016dc5a4f17896a330e66b0" category="list-text">애플리케이션 요구사항, 성능, 비용을 맞추기 위해 여러 성능 계층을 제공하는 옵션은 없습니다.</block>
  <block id="f5188d9f655a6ac9c3d0dccb20d81997" category="list-text">클러스터 호스트 위에 구축된 vSAN의 스토리지 용량 제한에 쉽게 도달할 수 있습니다. Azure NetApp Files와 같은 Azure 네이티브 PaaS(Platform-as-a-Service) 오퍼링을 데이터 저장소로 통합하여 고객은 스토리지를 독립적으로 확장하고 필요에 따라 SDDC 클러스터에만 컴퓨팅 노드를 추가할 수 있습니다. 이 기능을 통해 위에서 설명한 과제를 극복할 수 있습니다.</block>
  <block id="cf1c082028930ec1827badc0e64627c6" category="admonition">스토리지의 계획 및 사이징, 필요한 호스트 수를 결정하려면 Azure 및 NetApp 솔루션 설계자와 접촉하십시오. 테스트, POC 및 운영 구축을 위한 데이터 저장소 레이아웃을 최종적으로 완료하기 전에 스토리지 성능 요구사항을 파악하는 것이 좋습니다.</block>
  <block id="1622404dda50f5803c9577efc058ec11" category="paragraph"><block ref="1622404dda50f5803c9577efc058ec11" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3488e5e13ca2586de3bcc01700bd61b" category="paragraph">마이그레이션 또는 재해 복구의 가장 중요한 측면은 타겟 환경에 적합한 크기를 결정하는 것입니다. 온프레미스에서 Azure VMware 솔루션으로 이동하는 데 필요한 노드 수를 이해하는 것이 매우 중요합니다.</block>
  <block id="b39d58eedf7db669f2a65fd75198d49e" category="paragraph">크기를 조정하려면 RVTools(권장) 또는 Live Optics 또는 Azure Migrate 등의 다른 도구를 사용하여 온프레미스 환경의 기록 데이터를 사용합니다. RVTools는 vCPU, vmem, vDisk 및 전원이 켜져 있거나 꺼진 VM을 비롯한 모든 필수 정보를 캡처하여 타겟 환경의 특성을 파악하는 데 이상적인 툴입니다.</block>
  <block id="9b45f8f524f59dcb44852dc933d31d60" category="paragraph">RVtools를 실행하려면 다음 단계를 완료하십시오.</block>
  <block id="b9b14f9a77af6302e167ec8031bac435" category="list-text">RVTools를 다운로드하여 설치합니다.</block>
  <block id="a379941a0582174b350ce316b1e64b36" category="list-text">RVTools를 실행하고 필요한 정보를 입력하여 온-프레미스 vCenter Server에 연결한 다음 Login을 누릅니다.</block>
  <block id="7d0ff8053a5012b379d5e45f7d80bd81" category="list-text">재고를 Excel 스프레드시트로 내보냅니다.</block>
  <block id="ad7235861abcfd585f9793a320142cb9" category="list-text">스프레드시트를 편집하고 vInfo 탭에서 적합한 대상이 아닌 VM을 제거합니다. 이 접근 방식은 필요한 수의 호스트를 사용하여 Azure VMware SDDC 클러스터의 크기를 올바르게 지정하는 데 사용할 수 있는 스토리지 요구 사항에 대한 명확한 출력을 제공합니다.</block>
  <block id="66a03e4bdc70563bcc83f39fd18f2993" category="admonition">게스트 내 스토리지와 함께 사용되는 게스트 VM은 별도로 계산되어야 합니다. 그러나 Azure NetApp Files는 추가 스토리지 용량을 쉽게 처리할 수 있으므로 전체 TCO를 낮게 유지할 수 있습니다.</block>
  <block id="ee7f083efd1984641bff3ff302c447a9" category="section-title">Azure VMware 솔루션 구축 및 구성</block>
  <block id="95220678e12ace3a65339c08bb6019e5" category="paragraph">온프레미스와 마찬가지로 Azure VMware 솔루션을 계획하는 것은 가상 머신 생성 및 마이그레이션을 위한 성공적인 프로덕션 준비 환경에 매우 중요합니다.</block>
  <block id="1b3379256eb1cb0d26126368cc62ab52" category="paragraph">이 섹션에서는 게스트 내 스토리지를 포함하는 데이터 저장소로서 Azure NetApp Files와 함께 사용할 AVS를 설정하고 관리하는 방법에 대해 설명합니다.</block>
  <block id="449e01682ffd6d9e79c75acf22fa249b" category="list-text">리소스 공급자를 등록하고 프라이빗 클라우드를 생성합니다.</block>
  <block id="17d7be5e1d44a11ff74be89af34822c9" category="list-text">새 또는 기존 ExpressRoute 가상 네트워크 게이트웨이에 연결합니다.</block>
  <block id="28325f137394bcd829a01024c035cb5e" category="list-text">네트워크 연결을 확인하고 프라이빗 클라우드에 액세스합니다. 이를 참조하십시오 <block ref="c494c3efc2923b26ad63800ea1f5c612" category="inline-link-macro-rx"></block> Azure VMware SDDC 솔루션 구축 프로세스에 대한 단계별 안내를 제공합니다.</block>
  <block id="b2666a13d31389019b43a9085ffd2fe8" category="section-title">Azure VMware 솔루션으로 Azure NetApp Files를 구성합니다</block>
  <block id="dbfbac0b1aee2557c747f90a52c200ed" category="paragraph">Azure NetApp Files 간의 새로운 통합을 통해 Azure VMware 솔루션 리소스 공급자 API/CLI를 통해 Azure NetApp Files 볼륨을 포함하는 NFS 데이터 저장소를 생성하고 프라이빗 클라우드에서 원하는 클러스터에 데이터 저장소를 마운트할 수 있습니다. VM 및 애플리케이션 VMDK를 구축하는 것 외에도 Azure NetApp 파일 볼륨은 Azure VMware Solution SDDC 환경에서 생성된 VM에서 마운트할 수 있습니다. Azure NetApp Files는 SMB(서버 메시지 블록) 및 NFS(네트워크 파일 시스템) 프로토콜을 지원하기 때문에 Linux 클라이언트에 볼륨을 마운트하고 Windows 클라이언트에 매핑할 수 있습니다.</block>
  <block id="3fcf61e60f3486b366489a2db86e92c0" category="admonition">최적의 성능을 위해 Azure NetApp Files를 프라이빗 클라우드와 동일한 가용성 영역에 구축하십시오. Express Route Fastpath가 포함된 코로케이션을 통해 최소한의 네트워크 지연 시간으로 최고의 성능을 제공합니다.</block>
  <block id="2a499560ec410b1e1caeb95f6021ac1e" category="admonition">이 기능은 현재 공개 미리보기에 있습니다.</block>
  <block id="7042805ebe69bccc6ab09f9518f94556" category="paragraph">Azure NetApp File 볼륨을 Azure VMware Solution 프라이빗 클라우드의 VMware 데이터 저장소로 연결하려면 다음 사전 요구 사항이 충족되어야 합니다.</block>
  <block id="49588f95c73f4a9df95958ba5e856d0c" category="list-text">az 로그인을 사용하고 구독이 Microsoft.AVS 네임스페이스의 CloudSanExperience 기능에 등록되어 있는지 확인합니다.</block>
  <block id="c0e46e4183896be214bad3fd077b5834" category="list-text">등록되지 않은 경우 등록한다.</block>
  <block id="8fb14eb63139db9a1c626865766368e4" category="admonition">등록을 완료하는 데 약 15분 정도 걸릴 수 있습니다.</block>
  <block id="91bc7290f2d4745c25033c52b73c0662" category="list-text">등록 상태를 확인하려면 다음 명령을 실행합니다.</block>
  <block id="bd00d81bc80103cfbf6f24470f9de4fa" category="list-text">등록이 15분 이상 중간 상태로 고착된 경우 등록을 취소한 다음 플래그를 다시 등록하십시오.</block>
  <block id="30d4986a1e28c78ed243b8fe94ebe5be" category="list-text">구독이 Microsoft.AVS 네임스페이스의 AnfDatastoreExperience 기능에 등록되어 있는지 확인합니다.</block>
  <block id="10b9b69a3124f921ee9a3a8271028b78" category="list-text">VMware 확장 프로그램이 설치되어 있는지 확인합니다.</block>
  <block id="329e9fb0e53008fcf269d03c5476847d" category="list-text">내선이 이미 설치되어 있는 경우 버전이 3.0.0인지 확인합니다. 이전 버전이 설치된 경우 확장을 업데이트하십시오.</block>
  <block id="f5e4a463688cab0acae8d53e64bd5e36" category="list-text">확장자가 아직 설치되지 않은 경우 설치하십시오.</block>
  <block id="11d2eb5b9d070e139a779747ce885490" category="list-text">Azure Portal에 로그인하고 Azure NetApp Files에 액세스합니다. az provider register"--namespace Microsoft.NetApp –wait 명령을 사용하여 Azure NetApp Files 서비스에 대한 액세스를 확인하고 Azure NetApp Files 리소스 공급자를 등록합니다. 등록 후 NetApp 계정을 만드십시오. 이를 참조하십시오<block ref="2c2f4008511e047aaaf92ad514e98ec9" category="inline-link-rx"></block> 를 참조하십시오.</block>
  <block id="09e7af76fc12c4b14e8fbca51314b508" category="paragraph"><block ref="09e7af76fc12c4b14e8fbca51314b508" category="inline-image-macro-rx" type="image"></block></block>
  <block id="187927c7525fb36ec9428b4d84fe0aff" category="list-text">NetApp 계정을 생성한 후 필요한 서비스 수준 및 크기의 용량 풀을 설정합니다. 자세한 내용은 이를 참조하십시오<block ref="0a52e91c67ac030fc237a7b13d0404c6" category="inline-link-rx"></block>.</block>
  <block id="c7d6fd5f235d0c8a960facf04a79e4a7" category="paragraph"><block ref="c7d6fd5f235d0c8a960facf04a79e4a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c573a9eace62b9790820458dd59448b0" category="list-text">Azure NetApp Files에서 데이터 저장소에 대해 NFSv3이 지원됩니다.</block>
  <block id="62dfd4c1cc43e59ef3c56bb615d3b182" category="list-text">최적의 성능을 위해 Premium 또는 Ultra 계층을 사용합니다.</block>
  <block id="0d55d5c3a7459f59fd437a2311322791" category="list-text">Azure NetApp Files에 대해 위임된 서브넷을 구성하고 볼륨을 생성할 때 이 서브넷을 지정합니다. 위임된 서브넷을 생성하는 자세한 단계는 이것을 참조하십시오<block ref="e84891bed408b1977d062f4ccc1816aa" category="inline-link-rx"></block>.</block>
  <block id="36fc58c2c3fa32ac586d5628570e9499" category="list-text">용량 풀 블레이드 아래에 있는 볼륨 블레이드를 사용하여 데이터 저장소에 대한 NFS 볼륨을 추가합니다.</block>
  <block id="2832d137c1714a9759f87412fb05253e" category="paragraph"><block ref="2832d137c1714a9759f87412fb05253e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="47e7f43ca3ba65dbd1b1edbe26db8cc4" category="paragraph">크기 또는 할당량별 Azure NetApp Files 볼륨 성능에 대한 자세한 내용은 을 참조하십시오<block ref="bcd13cd67f856c9e615d78327e957b9c" category="inline-link-rx"></block>.</block>
  <block id="372d7a6604390fe9757888aff0a92970" category="example-title">Azure NetApp Files 데이터 저장소를 프라이빗 클라우드에 추가합니다</block>
  <block id="0f9e7cabe2f81455810e96baca91c6a7" category="paragraph">Azure NetApp Files 데이터 저장소를 프라이빗 클라우드에 추가하려면 다음 단계를 수행하십시오.</block>
  <block id="b1248573ef968f7d6fc7eaa453fa4d45" category="list-text">필요한 기능을 등록한 후 적절한 명령을 실행하여 NFS 데이터 저장소를 Azure VMware Solution 프라이빗 클라우드 클러스터에 연결합니다.</block>
  <block id="567531ac8390e0378f43db080cbeec2b" category="list-text">Azure VMware Solution 프라이빗 클라우드 클러스터에서 기존 ANF 볼륨을 사용하여 데이터 저장소를 생성합니다.</block>
  <block id="ed491060b6ac47e89ad70eecda183065" category="paragraph">c:\Users\niyaz&gt;VMware 데이터 저장소 목록 -- resource-group anfavsval2--cluster cluster cluster cluster -1--private-cloud ANFDataClus [{"diskPoolVolume":null, "id":"/Subscriptions/0efa2dffb-917c-bourceGroup" vav-vav "AVS Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecods/volumes/ANFRecoDS001"" vev-vav-vav-vav-vev-vav-vav-vav "AVS" AVS" AVS" vav "AVS/recev-vav-vav-vav-vav-vav-vav-vav-vav-vav-av-av-av-av-av "AVS" AVS" AVS" AVS".2" ev-av-av-av-vev-av-av-vev-vav "AVS" vav-av-av- {"diskPoolVolume":null, "id":"/Subscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourceGroups/anfavsourceGroup/anfavource2/providers/microsoft.AVS/privateClouds/ae4recorivae17002 "Microsoft.NetApp/netAppAccounts/anfdatastoreacct/capacityPools/anfrecodsu/volumes/anfrecodsU002" AVS" AVaeAVaeae4aeaeaea.va.va.va.va.2" va.vaeae4a.va.va.va.va.va.va.va.va.vaea.va.va.va.veaea.vea.vaea.va.vea.va.va.va.va.vea.vea.va.vea.vea.vea.va.vea.va.vea.vea.vea</block>
  <block id="d1903b7932291ae49bf265e5af7a75f4" category="list-text">필요한 접속이 구성된 후에는 볼륨이 데이터 저장소로 마운트됩니다.</block>
  <block id="b9eb0553d93e0e4bbee4142fec9403f9" category="paragraph"><block ref="b9eb0553d93e0e4bbee4142fec9403f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="078f601da77f62e8c7e097d5744f9b1b" category="section-title">사이징 및 성능 최적화</block>
  <block id="2954ff66e26b577154cf218d077ff1a9" category="paragraph">Azure NetApp Files는 Standard(테라바이트당 16MBps), Premium(테라바이트당 64MBps), Ultra(테라바이트당 128MBps)의 세 가지 서비스 수준을 지원합니다. 데이터베이스 워크로드의 성능을 최적화하려면 적절한 볼륨 크기를 프로비저닝하는 것이 중요합니다. Azure NetApp Files에서는 다음 요소를 기준으로 볼륨 성능과 처리량 한도를 결정합니다.</block>
  <block id="a5d62ae512b963e1f05e839467577f19" category="paragraph"><block ref="a5d62ae512b963e1f05e839467577f19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ce18fddaa7dc898334afc4ab63a163b" category="list-text">최적의 성능을 위해 데이터 저장소 볼륨에 Premium 또는 Ultra 계층을 사용합니다.</block>
  <block id="f681df268b9e05fa5155bbf1f38d672f" category="list-text">게스트 VM에 대한 파일 공유 요구 사항은 Standard 또는 Premium 계층 볼륨을 사용합니다.</block>
  <block id="1261ba8eeb83d9d138ff9e9a37214a7e" category="section-title">성능 고려 사항</block>
  <block id="f4479400cc63a0bc54ea3a609d8d89aa" category="paragraph">NFS 버전 3에서는 ESXi 호스트와 단일 스토리지 타겟 간의 접속에 대해 하나의 활성 파이프만 있다는 점을 이해하는 것이 중요합니다. 즉, 페일오버에 대체 연결을 사용할 수 있지만 단일 데이터 저장소 및 기본 스토리지의 대역폭은 단일 연결이 제공할 수 있는 범위로 제한됩니다.</block>
  <block id="f4c57c87dfa0d5843279b51c6e10d0a6" category="paragraph">Azure NetApp Files 볼륨에서 사용 가능한 대역폭을 더 많이 활용하려면 ESXi 호스트에 스토리지 타겟에 대한 여러 개의 접속이 있어야 합니다. 이 문제를 해결하려면 각 데이터 저장소에서 ESXi 호스트와 스토리지 간의 개별 연결을 사용하여 여러 데이터 저장소를 구성할 수 있습니다.</block>
  <block id="bde357669435115ce8fac67e3a3a5786" category="paragraph">더 높은 대역폭을 얻으려면 여러 ANF 볼륨을 사용하여 여러 데이터 저장소를 생성한 후 VMDK를 생성하고 VMDK 간에 논리적 볼륨을 스트라이핑하는 것이 좋습니다.</block>
  <block id="c01a936a44f773bc3d0a636cb655c28c" category="list-text">Azure VMware 솔루션에서는 기본적으로 8개의 NFS 데이터 저장소를 허용합니다. 이 문제는 지원 요청을 통해 증가할 수 있습니다.</block>
  <block id="cd58e3b202d882202a16834028640630" category="list-text">더 높은 대역폭과 낮은 지연 시간을 위해 ER fastpath와 Ultra SKU를 함께 활용합니다. 추가 정보</block>
  <block id="6ef5173b6cc36d0f4efabbafeeee7443" category="list-text">Azure NetApp Files의 "기본" 네트워크 기능을 사용하면 Azure VMware 솔루션을 연결하는 데 ExpressRoute 회로 및 ExpressRoute 게이트웨이의 대역폭이 사용됩니다.</block>
  <block id="0a8e9b67042320d1a2f3f6155fc3e096" category="list-text">"표준" 네트워크 기능이 있는 Azure NetApp Files 볼륨(현재 공개 미리 보기)의 경우 ExpressRoute FastPath가 지원됩니다. FastPath가 활성화되면 네트워크 트래픽이 Azure NetApp Files 볼륨으로 직접 전송되어 더 높은 대역폭과 낮은 대기 시간을 제공하는 게이트웨이를 우회합니다.</block>
  <block id="1b75d86136a5cde892b315650fd5ea43" category="section-title">성능 최적화</block>
  <block id="213debd5ccd87a89487239a8460a0f0e" category="paragraph">NFS 데이터 저장소당 권장되는 가상 머신 수는 주관적이지만, 많은 요소가 각 데이터 저장소에 배치할 수 있는 최적의 VM 수를 결정합니다. 대부분의 관리자가 용량만 고려하지만 VMDK에 전송되는 동시 I/O의 양은 전체 성능을 위한 가장 중요한 요소 중 하나입니다. ESXi 호스트에는 데이터 저장소 리소스에 대해 경쟁하는 가상 시스템 간의 공정성을 보장하기 위한 여러 메커니즘이 있습니다. 그러나 성능을 제어하는 가장 쉬운 방법은 각 데이터 저장소에 배치할 가상 머신 수를 조절하는 것입니다. 동시 가상 머신 I/O 패턴이 너무 많은 트래픽을 데이터 저장소로 전송하는 경우 디스크 대기열이 채워지며 지연 시간이 길어집니다.</block>
  <block id="f9fd5bbf2764cc5b16e9eeeb8b57ee91" category="section-title">볼륨 및 데이터 저장소 사이징</block>
  <block id="01ab7b17836cfa3916b003d7febafe43" category="paragraph">데이터 저장소를 위해 Azure NetApp Files에서 볼륨을 생성하는 경우 가장 좋은 방법은 필요한 것보다 더 큰 볼륨을 생성하는 것입니다. 최대 볼륨 크기는 100TB까지 가능하지만 작은 데이터 저장소 용량으로 시작하여 필요에 따라 늘리는 것이 좋습니다. 데이터 저장소를 적절하게 사이징하면 데이터 저장소에 너무 많은 가상 머신을 실수로 배치하는 것을 방지하고 리소스 경합 가능성을 줄일 수 있습니다. 가상 머신에 추가 용량이 필요한 경우 데이터 저장소 및 VMDK 크기를 쉽게 늘릴 수 있으므로 필요한 것보다 큰 데이터 저장소를 생성할 필요가 없습니다. 최적의 성능을 위해 크기를 늘리는 대신 데이터 저장소의 수를 늘리는 것이 좋습니다.</block>
  <block id="fad725216d945a6443f15949ae73b316" category="cell">기억해야 할 사항</block>
  <block id="28c7e0cc515aa1271633669cf0e579ad" category="list-text">ANF NFS 데이터 저장소의 적절한 크기는 4TB에서 8TB입니다.</block>
  <block id="90f9dde25089c324af635a76b75a7509" category="list-text">15-20개의 VM을 단일 데이터 저장소에 배치합니다. VM 요구 사항에 따라 VM을 35-40 까지 늘릴 수 있습니다.</block>
  <block id="3236c97f9f8c9cb7fcbc35b9ff162ab3" category="list-text">최상의 성능과 관리 효율성을 얻으려면 게스트가 데이터베이스와 같은 높은 I/O 애플리케이션을 위해 관리하는 NFS/SMB 파일 시스템과 같은 게스트 소유 파일 시스템을 고려하십시오.</block>
  <block id="0d3f5dc8a647758ee9ad71d0af34e75e" category="section-title">데이터 저장소의 크기를 증가시킵니다</block>
  <block id="9ae97248366686f76c6f9f6ac9b8d073" category="paragraph">SDDC에 대한 볼륨 재구성 및 동적 서비스 수준 변경은 전혀 투명합니다. Azure NetApp Files에서 이러한 기능은 지속적인 성능, 용량 및 비용 최적화를 제공합니다. Azure Portal에서 또는 CLI를 사용하여 볼륨의 크기를 조정하여 NFS 데이터 저장소의 크기를 늘립니다. 작업을 완료한 후 vCenter를 액세스하고 데이터 저장소 탭으로 이동하여 해당 데이터 저장소를 마우스 오른쪽 버튼으로 클릭하고 용량 정보 새로 고침 을 선택합니다. 이 접근 방식을 사용하면 데이터 저장소 용량을 늘리고 다운타임 없이 데이터 저장소의 성능을 동적으로 높일 수 있습니다. 또한 이 프로세스는 애플리케이션에 전혀 영향을 미치지 않습니다.</block>
  <block id="264b475cf0374b319edf3b094fe25874" category="list-text">볼륨에 대한 재구성 및 동적 서비스 수준 기능을 사용하면 안정적인 워크로드 크기를 조정하여 비용을 최적화하고 오버 프로비저닝을 방지할 수 있습니다.</block>
  <block id="c38ea7c6c5e1aef9a1df0cebd81737d9" category="list-text">공용 미리 보기 중에는 VAAI가 설정되어 있지 않습니다.</block>
  <block id="35084d885dea7b061e6894c1cf3036d9" category="section-title">워크로드</block>
  <block id="f7458ac9343d5418ff038f156d9b29fc" category="paragraph">가장 일반적인 사용 사례 중 하나는 마이그레이션입니다. VMware HCX 또는 vMotion을 사용하여 사내 VM으로 이동합니다. 또는 Riverfadow를 사용하여 VM을 Azure NetApp Files 데이터 저장소로 마이그레이션할 수 있습니다.</block>
  <block id="36e402ac6b1a4b9a31bd376a7f89c68e" category="paragraph">VM을 백업하고 신속하게 복구하는 것은 ANF 데이터 저장소의 뛰어난 장점 중 하나입니다. Snapshot 복사본을 사용하여 성능에 영향을 주지 않고 VM 또는 데이터 저장소의 빠른 복사본을 만든 다음, 재해 복구를 위해 지역 간 복제를 사용하여 Azure 스토리지 또는 2차 지역으로 장기 데이터 보호를 위해 전송합니다. 이러한 접근 방식은 변경된 정보만 저장하여 스토리지 공간과 네트워크 대역폭을 최소화합니다.</block>
  <block id="2bd24edc1157f2ea366bbf67e980b57e" category="paragraph">일반 보호를 위해 Azure NetApp Files 스냅샷 복사본을 사용하고, 애플리케이션 툴을 사용하여 SQL Server 또는 게스트 VM에 상주하는 Oracle과 같은 트랜잭션 데이터를 보호합니다. 이러한 스냅샷 복사본은 VMware(정합성 보장) 스냅샷과 다르며 장기 보호에 적합합니다.</block>
  <block id="c69157396b1ac0cb910d839c99a0a9e3" category="admonition">ANF 데이터 저장소를 사용하면 새 볼륨으로 복원 옵션을 사용하여 전체 데이터 저장소 볼륨을 복제할 수 있으며, 복구된 볼륨을 AVS SDDC 내의 호스트에 다른 데이터 저장소로 마운트할 수 있습니다. 데이터 저장소가 마운트된 후에는 해당 데이터 저장소 내의 VM을 개별적으로 클론 복제된 VM처럼 등록, 재구성 및 사용자 지정할 수 있습니다.</block>
  <block id="92b97805e00b695b9f8aeddf2cc8828d" category="example-title">가상 머신용 클라우드 백업</block>
  <block id="3b0ec96ab43930bb5b0f274d7a4733bd" category="paragraph">가상 머신용 Cloud Backup은 vCenter에서 vSphere 웹 클라이언트 GUI를 제공하여 백업 정책을 통해 Azure VMware 솔루션 가상 머신 및 Azure NetApp Files 데이터 저장소를 보호합니다. 이러한 정책은 스케줄, 보존 및 기타 기능을 정의할 수 있습니다. Cloud Backup for Virtual Machine 기능은 Run 명령을 사용하여 구축할 수 있습니다.</block>
  <block id="ad15ef62ee17e83e2a2c4de5cfc0a7e0" category="paragraph">설정 및 보호 정책은 다음 단계를 수행하여 설치할 수 있습니다.</block>
  <block id="68efc774d1525ecfc4ad132a4f363c10" category="list-text">실행 명령을 사용하여 Azure VMware Solution 프라이빗 클라우드에 가상 머신용 Cloud Backup을 설치합니다.</block>
  <block id="3a1d9263efa0039dd46c2e2d0dfc2dec" category="list-text">클라우드 구독 자격 증명(클라이언트 및 기밀 값)을 추가한 다음 보호할 리소스가 포함된 클라우드 구독 계정(NetApp 계정 및 관련 리소스 그룹)을 추가합니다.</block>
  <block id="60d5826756f013d28eadac75aec57698" category="list-text">리소스 그룹 백업에 대한 보존, 빈도 및 기타 설정을 관리하는 백업 정책을 하나 이상 생성합니다.</block>
  <block id="6ad3833cba216d2fe6639be4726ad69e" category="list-text">컨테이너를 생성하여 백업 정책으로 보호해야 하는 하나 이상의 리소스를 추가합니다.</block>
  <block id="f0c88a652a15d9fedafa82483a1959b4" category="list-text">장애가 발생할 경우 전체 VM 또는 특정 개별 VMDK를 동일한 위치로 복구합니다.</block>
  <block id="52c902402ab9b60471632cf95f1940b6" category="admonition">Azure NetApp Files 스냅샷 기술을 사용하면 백업 및 복원 속도가 매우 빨라집니다.</block>
  <block id="08042ba10c942968c10ed6576a20c1e6" category="paragraph"><block ref="08042ba10c942968c10ed6576a20c1e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3a1d923fd4fc5d2bc1c7e9ac58f59ef" category="example-title">Azure NetApp Files, Jetstream DR 및 Azure VMware 솔루션을 사용한 재해 복구</block>
  <block id="93460124cbffe590c9cee7667d85d1da" category="paragraph">클라우드로 재해 복구는 사이트 운영 중단 및 데이터 손상 이벤트(예: 랜섬웨어)로부터 워크로드를 보호하는 복원력이 있고 비용 효율적인 방법입니다. VMware VAIO 프레임워크를 사용하여 온프레미스 VMware 워크로드를 Azure Blob 스토리지에 복제하고 복구하여 데이터 손실과 제로급 RTO를 최소화하거나 최소화할 수 있습니다. Jetstream DR을 사용하면 사내에서 AVS로, 특히 Azure NetApp Files로 복제된 워크로드를 원활하게 복구할 수 있습니다. DR 사이트에서 최소한의 리소스와 비용 효율적인 클라우드 스토리지를 사용하여 비용 효율적으로 재해 복구를 수행할 수 있습니다. Jetstream DR은 Azure Blob Storage를 통해 ANF 데이터 저장소에 대한 복구를 자동화합니다. Jetstream DR은 네트워크 매핑에 따라 독립적인 VM 또는 관련 VM 그룹을 복구 사이트 인프라로 복구하고 랜섬웨어 보호를 위한 시점 복구를 제공합니다.</block>
  <block id="8b8adea1567023f8a36745e1e256b41e" category="inline-link-macro">ANF, Jetstream 및 AVS를 사용한 DR 솔루션</block>
  <block id="adeb8aee914844a07a855dd7b8fe7ffc" category="paragraph"><block ref="d016a1e57ae2464bcf00474caa126151" category="inline-link-macro-rx"></block>.</block>
  <block id="7a328b7e18172ee10e60d198b9fc26f7" category="doc">Azure/AVS용 NetApp 하이브리드 멀티 클라우드 솔루션</block>
  <block id="12709db6944c7fef6c2f181c42bd4741" category="doc">GCP/GCVE를 위한 NetApp 하이브리드 멀티 클라우드 솔루션</block>
  <block id="fcee9cbc5f0c4f0ed62751d0d5f181ef" category="doc">VMware 솔루션을 사용하는 NetApp 하이브리드 멀티 클라우드</block>
  <block id="980ba21a8b1f775a9fae0552d8594171" category="doc">VMware를 사용하는 NetApp 하이브리드 멀티 클라우드 개요</block>
  <block id="6e74d566879067f078b210f01e393989" category="paragraph">개략적인 관점에서 볼 때 이 아키텍처(아래 그림에 표시)에서는 NetApp Cloud Volumes ONTAP, Cloud Volumes Service for Google Cloud 및 Azure NetApp Files를 추가 게스트 스토리지 옵션으로 사용하여 여러 클라우드 공급자 간에 하이브리드 멀티 클라우드 연결 및 애플리케이션 이동성을 달성하는 방법을 설명합니다.</block>
  <block id="3fe4ff67f6902f4d03e2aff729e6ca40" category="cell">2022년 7월 21일</block>
  <block id="c1cb2a6b83f79bd02d9023a9dc25d399" category="cell">AVS용 CVO 및 Jetstream을 사용한 DR 솔루션 추가(게스트 연결 스토리지)</block>
  <block id="ac0f5de8cc00db2cb13da85ebd7e8780" category="cell">2022년 6월 10일</block>
  <block id="e92ea8797c2bfc161566c53da6321114" category="cell">AVS 및 ANF 기본 데이터 저장소 개요 및 Jetstream을 통한 DR 추가</block>
  <block id="b481ba8b3ad7fbb6a9786c9907a7c1ba" category="cell">VMware 지원 NetApp 하이브리드 멀티 클라우드를 위한 NFS 데이터 저장소의 지역 가용성 목록 추가</block>
  <block id="27f04e57a2bba90c65656f5f47785def" category="open-title">VMware를 사용하는 하이브리드 멀티 클라우드</block>
  <block id="24fef7dbaeab186ae1ddf8a1fa31ef68" category="cell">퍼블릭 클라우드의 VMware와 각 하이퍼스케일러의 NetApp 스토리지 옵션을 포함하는 하이브리드 멀티 클라우드 모델로 NetApp을 정의합니다. 하이브리드 멀티 클라우드 랜딩 페이지는 콘텐츠별 '타일'에 나와 있는 인기 있는 콘텐츠를 제공합니다.</block>
  <block id="91ef1e01c1592f4e80d47d11c68ddf5c" category="inline-link-macro">VMware 콘텐츠가 포함된 하이브리드 멀티 클라우드</block>
  <block id="356bcf8558d9911b876554df23345496" category="cell"><block ref="356bcf8558d9911b876554df23345496" category="inline-link-macro-rx"></block></block>
  <block id="9c155d9143dcac03a6b69afd6ec499b0" category="open-title">하이브리드 멀티 클라우드</block>
  <block id="749354a37dc4552d3c41bbf24ba08598" category="sidebar">VMC를 위한 VMware로 NetApp 하이브리드 멀티 클라우드 실행</block>
  <block id="045ec2e9b9dff589c32c257549300273" category="sidebar">CVO를 게스트 연결 스토리지로 사용</block>
  <block id="ff106355f094608231dc8d7116a273e1" category="sidebar">VMC용 하이브리드 멀티 클라우드 솔루션</block>
  <block id="0ab50f8c17f87a8eecee4603b22f16c8" category="sidebar">AVS용 VMware를 사용하는 NetApp 하이브리드 멀티 클라우드</block>
  <block id="5ab938ef85bdfd3c94e8c4c5f1cfa448" category="sidebar">게스트 연결 스토리지로서의 ANF</block>
  <block id="5ab22899d20e83b71d3c1cbbedea208e" category="sidebar">AVS용 하이브리드 멀티 클라우드 솔루션</block>
  <block id="9fe80f9f1edda788e503795e34b7eb80" category="sidebar">GCVE를 위한 VMware의 NetApp 하이브리드 멀티 클라우드</block>
  <block id="f0476be9310e3a4606daded5c91d346f" category="sidebar">CVS를 게스트 연결 스토리지로</block>
  <block id="e809dfa83f36389270c46ad868461471" category="sidebar">GCVE용 하이브리드 멀티 클라우드 솔루션</block>
  <block id="d4cc78732ab0fdcd767ab42a015d34e0" category="sidebar">보안 개요 - Google Cloud의 NetApp CVS</block>
  <block id="538d26f438b9f54f2e02fe3eff3093f8" category="sidebar">VMware를 사용하는 NetApp 하이브리드 멀티 클라우드</block>
  <block id="b8aef6e50d3ed85ad8f7568c45050629" category="sidebar">워크로드 보호</block>
  <block id="a3e69dd4d9f892aab0dcbf0a5dd246e2" category="cell">1.4 이상</block>
  <block id="f78d920d9d248820ddf7a3acdd9a34c0" category="doc">Tanzu가 포함된 VMware vSphere 개요</block>
  <block id="bac31e763c1b2955be0a10de0a4d8012" category="image-alt">Kubernetes를 포함한 VMware vSphere</block>
  <block id="c2e55cf1007600b25e0708bfe26a41f3" category="paragraph">Tanzu 환경을 사용하는 VMware vSphere는 기본 TKGS 클러스터와 마찬가지로 워크로드 관리 아래에서 사용할 수 있습니다.</block>
  <block id="9ff6aa8ffa487db2f0aebe3967972d77" category="image-alt">Supervisor Cluster(감독자 클러스터</block>
  <block id="b3ba0fe968ce39dcfc6fe8cc0f1b02da" category="image-alt">네임스페이스</block>
  <block id="516a32af5ad38dd3b9ca9c156da39add" category="inline-link-macro">VMware vSphere 및 Tanzu(vSphere Pod)</block>
  <block id="a6726486b20bc2510c7d0b189955e69c" category="list-text"><block ref="a6726486b20bc2510c7d0b189955e69c" category="inline-link-macro-rx"></block></block>
  <block id="9fa345c6a2f967ec80e8b940a9d2a1c3" category="summary">고객은 Splunk 데이터 분석을 더욱 쉽고 원활하게 사용할 수 있다는 것을 알게 되므로 당연히 계속해서 증가하는 데이터를 인덱싱하기를 원합니다. 데이터의 양이 증가할수록 서비스를 제공하는 데 필요한 컴퓨팅 및 스토리지 인프라도 증가합니다.</block>
  <block id="f9a3e09b74e61e83c0352f2953dcdc87" category="doc">지능형 계층화 및 비용 절감</block>
  <block id="7bcf31269131a9e7ab4d163f239fc4e5" category="inline-link-macro">이전: 이 솔루션의 이점</block>
  <block id="b27eab207fc06febce259cb1c08777a3" category="paragraph"><block ref="b27eab207fc06febce259cb1c08777a3" category="inline-link-macro-rx"></block></block>
  <block id="e09913e41f1a0082ec190482abfeff57" category="paragraph">고객은 Splunk 데이터 분석을 더욱 쉽고 원활하게 사용할 수 있다는 것을 알게 되므로 당연히 계속해서 증가하는 데이터를 인덱싱하기를 원합니다. 데이터의 양이 증가할수록 서비스를 제공하는 데 필요한 컴퓨팅 및 스토리지 인프라도 증가합니다. 오래된 데이터를 자주 참조하지 않기 때문에 동일한 양의 컴퓨팅 리소스를 커밋하고 값비싼 기본 스토리지를 사용하는 것은 점점 비효율적입니다. 고객은 규모에 맞게 운영하는 데 필요한 데이터를 보다 비용 효율적인 계층으로 이동하여 사용 빈도가 높은 데이터를 위한 컴퓨팅과 운영 스토리지를 확보함으로써 이점을 누릴 수 있습니다.</block>
  <block id="f7300ec91634b8cd535c45fd11ee503f" category="paragraph">StorageGRID를 포함한 Splunk SmartStore는 확장 가능하고 성능 기준에 부합하는 비용 효율적인 솔루션을 제공합니다. SmartStore는 데이터를 인식하기 때문에 데이터 액세스 패턴을 자동으로 평가하여 실시간 분석(핫 데이터)을 위해 액세스해야 하는 데이터와 저렴한 장기 스토리지(웜 데이터)에 상주해야 하는 데이터를 결정합니다. SmartStore는 업계 표준인 AWS S3 API를 동적으로 지능적으로 사용하여 StorageGRID에서 제공하는 S3 스토리지에 데이터를 배치합니다. StorageGRID의 유연한 스케일아웃 아키텍처를 사용하면 웜 데이터 계층을 필요에 따라 비용 효율적으로 확장할 수 있습니다. StorageGRID의 노드 기반 아키텍처는 성능 및 비용 요구사항을 최적의 상태로 충족합니다.</block>
  <block id="d75fb5ef86bb0625c22c38dd2229c627" category="paragraph">다음 그림은 Splunk 및 StorageGRID 계층화를 보여줍니다.</block>
  <block id="821f09f0a5870b1dd3ee40e65f17b546" category="paragraph"><block ref="821f09f0a5870b1dd3ee40e65f17b546" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b6821c40fa59a17fa0f78dbb9e556be5" category="paragraph">업계 최고 수준의 Splunk SmartStore와 NetApp StorageGRID를 결합하여 전체 스택 솔루션을 통해 분리 아키텍처의 이점을 제공합니다.</block>
  <block id="32c614a5724d73faf7f06f754330bbac" category="paragraph"><block ref="32c614a5724d73faf7f06f754330bbac" category="inline-link-macro-rx"></block></block>
  <block id="f362fde28c17f629ded4d965d576f423" category="summary">Splunk Enterprise는 업계 최고의 SIEM 솔루션으로 보안, IT 및 DevOps 팀 전반에서 결과를 주도하고 있습니다. 고객 조직 전반에서 Splunk를 사용할 때 성능이 크게 향상되었습니다. 따라서 더 많은 데이터 소스를 추가해야 할 뿐만 아니라 데이터를 더 오래 보관해야 하므로 Splunk 인프라가 강조됩니다.</block>
  <block id="3613797d0f4ca076e9cb8ba4c75e87e6" category="inline-link-macro">이전: 단일 사이트 SmartStore 성능.</block>
  <block id="5fdd4eaa62513aac277472bf713d1bee" category="paragraph"><block ref="5fdd4eaa62513aac277472bf713d1bee" category="inline-link-macro-rx"></block></block>
  <block id="25c2a1fd1c8874a3e0526920fe7f440d" category="paragraph">Splunk SmartStore와 NetApp StorageGRID의 결합을 통해 조직은 확장 가능한 아키텍처를 제공하여 SmartStore 및 StorageGRID 오브젝트 스토리지를 통해 수집 성능을 높이고 여러 지리적 지역에서 Splunk 환경을 위한 확장성을 향상할 수 있습니다.</block>
  <block id="fbf1f1e6f0848252d39ef48e7e18146f" category="list-text">NetApp StorageGRID 문서 리소스</block>
  <block id="68d4d5362a15088f2ac3fa494c971af5" category="inline-link"><block ref="68d4d5362a15088f2ac3fa494c971af5" category="inline-link-rx"></block></block>
  <block id="580c43c30953ec671dd4a70120e1b513" category="paragraph"><block ref="580c43c30953ec671dd4a70120e1b513" category="inline-link-rx"></block></block>
  <block id="2e85fc867cab94d246e0bf6043b361cd" category="paragraph"><block ref="2e85fc867cab94d246e0bf6043b361cd" category="inline-link-rx"></block></block>
  <block id="e145cc414457b4a232fb0b63ce9f44ab" category="list-text">Splunk Enterprise 문서</block>
  <block id="f710d46c12a05abcfde056d779cb608c" category="inline-link"><block ref="f710d46c12a05abcfde056d779cb608c" category="inline-link-rx"></block></block>
  <block id="2ab8bf37a62983163c96b3c2f9a275d4" category="paragraph"><block ref="2ab8bf37a62983163c96b3c2f9a275d4" category="inline-link-rx"></block></block>
  <block id="14c366ebe94ed0bdf5d5eecad5a08411" category="list-text">Splunk Enterprise는 SmartStore를 기반으로 합니다</block>
  <block id="98bda64923adc1da4a0e009dd52832a4" category="inline-link"><block ref="98bda64923adc1da4a0e009dd52832a4" category="inline-link-rx"></block></block>
  <block id="86d261d18a8cb6ce8f95f58af41452e5" category="paragraph"><block ref="86d261d18a8cb6ce8f95f58af41452e5" category="inline-link-rx"></block></block>
  <block id="b437e6537685614b8004334bad18e424" category="list-text">Splunk Enterprise Distributed Deployment Manual을 참조하십시오</block>
  <block id="048c67f334d3e1bbcb765e563d076b7d" category="inline-link"><block ref="048c67f334d3e1bbcb765e563d076b7d" category="inline-link-rx"></block></block>
  <block id="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="paragraph"><block ref="0a25fd44eb7af79f8d9bb0e91d7dfec3" category="inline-link-rx"></block></block>
  <block id="d043516086780b04d9c8b38186019be3" category="list-text">Splunk Enterprise 인덱서 및 인덱서 클러스터 관리</block>
  <block id="87fbe590fc8f855078f14ba53325eb46" category="inline-link"><block ref="87fbe590fc8f855078f14ba53325eb46" category="inline-link-rx"></block></block>
  <block id="d0438efbc1a0dbee965023150ccf9334" category="paragraph"><block ref="d0438efbc1a0dbee965023150ccf9334" category="inline-link-rx"></block></block>
  <block id="e4c2e8edac362acab7123654b9e73432" category="cell">1.0</block>
  <block id="d1cdbd3c8324f3afbc5b420ce471feff" category="cell">2022년 7월</block>
  <block id="881214767967db331c99550277ceb793" category="summary">이 페이지에서는 주요 정의, Splunk 분산 구축, Splunk SmartStore, 데이터 흐름, 하드웨어 및 소프트웨어 요구사항, 단일 및 다중 사이트 요구사항 등</block>
  <block id="1e6ade59f7284c0bca28eaeeeeed0a30" category="doc">Splunk 아키텍처</block>
  <block id="aa91789a439fe45bd8d608e61ca9da8c" category="inline-link-macro">이전: Splunk SmartStore를 위한 유연한 StorageGRID 기능</block>
  <block id="263af6ab01a543147e86a15ed7794682" category="paragraph"><block ref="263af6ab01a543147e86a15ed7794682" category="inline-link-macro-rx"></block></block>
  <block id="a8449bda57f23b9282f766113987bdf2" category="section-title">키 정의</block>
  <block id="56eee8e9cc278d0a414a6d5697a4675f" category="paragraph">다음 두 표에는 Splunk 구축 시 사용되는 Splunk 및 NetApp 구성요소가 나와 있습니다.</block>
  <block id="5078bea36734bcaa4a0c1e3a0e6e4606" category="paragraph">이 표에는 분산형 Splunk Enterprise 구성을 위한 Splunk 하드웨어 구성요소가 나와 있습니다.</block>
  <block id="5e536c35aec296fa99efa02703d1eb07" category="cell">Splunk 구성 요소</block>
  <block id="84f200201a8fe699d8d701c940bade8e" category="cell">인덱서</block>
  <block id="a5aa1df4c3c47c407c84c66303cf0ece" category="cell">Splunk Enterprise 데이터를 위한 저장소입니다</block>
  <block id="872c8a2437dfbfa5be0882eabc86bcd3" category="cell">범용 포워더</block>
  <block id="66d25b75f626d8f6c535a4b4d25c9906" category="cell">데이터를 수집하여 인덱서에 데이터를 전달하는 역할을 합니다</block>
  <block id="c91b59f2eae5ebf309d600609f87a36f" category="cell">검색 헤드</block>
  <block id="5873147385b9bd833ffd9a046374c97b" category="cell">인덱서의 데이터를 검색하는 데 사용되는 사용자 프런트 엔드</block>
  <block id="a6230a0628a31d41191b4ef7800745ed" category="cell">클러스터 마스터</block>
  <block id="e4ae9d4eb2313305a17cde160f405a17" category="cell">인덱서와 검색 헤드의 Splunk 설치를 관리합니다</block>
  <block id="805ac84d9852820feaf2e2b643a07efb" category="cell">모니터링 콘솔</block>
  <block id="5cf5006c1d7fdc954614a4e4185a2c62" category="cell">전체 구축 환경에서 사용되는 중앙 집중식 모니터링 툴입니다</block>
  <block id="fdccec582408614d1e2f7428910b1c8f" category="cell">라이선스 마스터</block>
  <block id="7c3b9b8892864eb6fa5cb2a32b85cc93" category="cell">라이센스 마스터는 Splunk Enterprise 라이센스를 처리합니다</block>
  <block id="06262b5ad14fe5851defa5b0b70c86c6" category="cell">배포 서버</block>
  <block id="ebe1fa5d8a359a6db13876ab1142fa50" category="cell">구성을 업데이트하고 애플리케이션을 처리 구성 요소에 배포합니다</block>
  <block id="4fabea287d13a082b71f046f9d8be91d" category="cell">스토리지 구성 요소</block>
  <block id="b1edd0b37872fd00feb3bb2738987b41" category="cell">핫 계층 데이터를 관리하는 데 사용되는 All-Flash 스토리지입니다. 로컬 스토리지라고도 합니다.</block>
  <block id="518d90155e7eb8bf96c6b7852ba519a6" category="cell">계층 데이터를 관리하는 데 사용되는 S3 오브젝트 스토리지 SmartStore에서 핫 계층과 웜 계층 간에 데이터를 이동하는 데 사용됩니다. 원격 스토리지라고도 합니다.</block>
  <block id="310a27e25811a8eca9b6e5edd921a267" category="paragraph">이 표에는 Splunk 스토리지 아키텍처의 구성요소가 나와 있습니다.</block>
  <block id="40f14800d20c9cecbec85dbb2cf35592" category="cell">책임 구성 요소</block>
  <block id="a5847d984bf6ac525e00b95b93be4e94" category="cell">스마트 스토어</block>
  <block id="6b64d740ca8627e515d54827d95bc7cb" category="cell">인덱서에 로컬 스토리지의 데이터를 오브젝트 스토리지로 계층화할 수 있는 기능을 제공합니다.</block>
  <block id="2f9304fe9b427489507405bef9a0bb9f" category="cell">더 효율적인 데이터 센터</block>
  <block id="4194726ee334e1085d93e002837b73f0" category="cell">핫</block>
  <block id="cc42c7d2fb33f9ccc06f2e23486a9b0e" category="cell">유니버설 포워더(Universal Forwarders)가 새로 작성된 데이터를 배치하는 착륙장. 스토리지는 쓰기 가능하며 데이터는 검색 가능합니다. 이 데이터 계층은 일반적으로 SSD 또는 고속 HDD로 구성됩니다.</block>
  <block id="f156996831cd546988bf05451ede7b02" category="cell">캐시 관리자</block>
  <block id="52520fc1f4cef574661d086d8efcb1f8" category="cell">인덱싱된 데이터의 로컬 캐시를 관리하고, 검색 시 원격 스토리지에서 웜 데이터를 가져오고, 캐시에서 가장 자주 사용되지 않는 데이터를 제거됩니다.</block>
  <block id="18297117d3d251afceed9ecbe797c849" category="cell">따뜻합니다</block>
  <block id="810be2ef6ffed5e543f948bf5984d544" category="cell">데이터는 버킷에 논리적으로 롤링되며, 핫 계층에서 먼저 웜 계층으로 이름이 변경됩니다. 이 계층 내의 데이터는 보호되며 핫 계층과 마찬가지로 대용량 SSD 또는 HDD로 구성될 수 있습니다. 공통 데이터 보호 솔루션을 사용하면 증분 백업과 전체 백업이 모두 지원됩니다.</block>
  <block id="392d70ca39f31f10bd637936769788df" category="cell">StorageGRID</block>
  <block id="7cf9c58117f9052c5d5a43b3add7f6a4" category="section-title">Splunk 분산 배포</block>
  <block id="11c2b5859cb0c1d37b40f8df716542e2" category="paragraph">많은 시스템에서 데이터가 생성되는 대규모 환경을 지원하려면 대용량 데이터를 처리해야 합니다. 많은 사용자가 데이터를 검색해야 하는 경우 Splunk Enterprise 인스턴스를 여러 시스템에 배포하여 배포를 확장할 수 있습니다. 이를 분산 배포라고 합니다.</block>
  <block id="113f0bd975880424e2c87874233b2afb" category="paragraph">일반적인 분산 구축에서 각 Splunk Enterprise 인스턴스는 특화된 작업을 수행하며 주요 처리 기능에 해당하는 세 가지 처리 계층 중 하나에 상주합니다.</block>
  <block id="ac31b29e5bbd68654aeb200e66227fb8" category="paragraph">다음 표에는 Splunk Enterprise 처리 계층이 나와 있습니다.</block>
  <block id="9483f17a69bd0b52dbc44f9106718634" category="cell">계층</block>
  <block id="7d38267cdf833b2983d3487954ebf88e" category="cell">데이터 입력</block>
  <block id="2d361d5fe6d74b7550e0aa35d94342ec" category="cell">운송주선인</block>
  <block id="b2eebf5023a2a2ba3b35711069723656" category="cell">전달자는 데이터를 소비한 다음 데이터를 인덱서 그룹으로 전달합니다.</block>
  <block id="521d4edc7c22d5f63bc5912ff2afa61a" category="cell">인덱싱</block>
  <block id="65265b43bef75c5bacc53c21e38eb8fc" category="cell">인덱서는 일반적으로 전달자 그룹에서 받는 들어오는 데이터를 인덱싱합니다. 인덱서를 사용하면 데이터가 이벤트로 변환되고 이벤트가 인덱스에 저장됩니다. 인덱서도 검색 헤드에서 검색 요청에 대한 응답으로 인덱싱된 데이터를 검색합니다.</block>
  <block id="ff5b0dc94726e93d5db5cf7922183f2b" category="cell">검색 관리</block>
  <block id="d4c174b1ebc77694020097497547d218" category="cell">검색 헤드는 검색을 위한 중앙 리소스 역할을 합니다. 클러스터의 검색 헤드는 상호 교환이 가능하며 검색 헤드 클러스터의 모든 구성원으로부터 동일한 검색, 대시보드, 지식 개체 등에 액세스할 수 있습니다.</block>
  <block id="86f51d8f8fa8928e0f6ddba31139676e" category="paragraph">다음 표에는 분산 Splunk Enterprise 환경에서 사용되는 주요 구성요소가 나와 있습니다.</block>
  <block id="dee8af298acfc4c4bcb9fda657125917" category="cell">책임</block>
  <block id="3b656ff8459bec2d80d19d367bd71d19" category="cell">인덱스 클러스터 마스터입니다</block>
  <block id="407a3e34682f31b649e8cbd865fdf50c" category="cell">인덱서 클러스터의 활동 및 업데이트를 조정합니다</block>
  <block id="dad2f7ca532f008e8192d418406da758" category="cell">인덱스 관리</block>
  <block id="85ba71585b2b8c323c8eb899fa033227" category="cell">인덱스 클러스터</block>
  <block id="f13c7b75bef35de7c42cc0569f76e366" category="cell">데이터를 서로 복제하도록 구성된 Splunk Enterprise 인덱서의 그룹입니다</block>
  <block id="f8b32f50f478eb80dca360b13aa78e92" category="cell">검색 헤드 배포자</block>
  <block id="9f45bd6fe25c3f5597af0f46bfdb20db" category="cell">클러스터 마스터에 대한 배포 및 업데이트를 처리합니다</block>
  <block id="bc2eef462c1a0c8b778b607c304ba877" category="cell">검색 헤드 관리</block>
  <block id="58f4a17edb05ffec840bf2b176bf6eca" category="cell">검색 헤드 클러스터</block>
  <block id="70f36c7a653c3724df8921edce177b22" category="cell">검색을 위한 중앙 리소스 역할을 하는 검색 헤드 그룹입니다</block>
  <block id="2ddcaa7e88a6ad9c095422ca4e601d85" category="cell">부하 분산 장치</block>
  <block id="fe613dab61d63209235cf49513b00d8a" category="cell">클러스터 구성 요소에서 사용되어 클러스터 구성 요소 간에 로드를 분산하기 위해 검색 헤드, 인덱서 및 S3 대상을 통해 증가하는 수요를 처리합니다.</block>
  <block id="184f98cf6a6dd19d0815179e63be4298" category="cell">클러스터링된 구성 요소에 대한 로드 관리</block>
  <block id="e32d50596edede1bfe3978d8b7b5c5ac" category="paragraph">Splunk Enterprise 분산 구축의 다음과 같은 이점을 알아보십시오.</block>
  <block id="9431943c093a5cc181eccd505ca50f4c" category="list-text">다양한 데이터 소스 또는 분산된 데이터 소스에 액세스</block>
  <block id="e825b2fa62f5af51541982cc503c8825" category="list-text">규모와 복잡성에 관계없이 기업의 데이터 요구사항을 처리할 수 있는 기능을 제공합니다</block>
  <block id="c63fa16ec4ed3d9b3803c2d1e1548fe6" category="list-text">데이터 복제 및 다중 사이트 구축을 통해 고가용성을 실현하고 재해 복구를 보장합니다</block>
  <block id="fb289ff7f529e1f2477823c61e7d9c8f" category="section-title">Splunk SmartStore를 참조하십시오</block>
  <block id="e2475a05ae25f0e8f31932cc309db3f1" category="paragraph">SmartStore는 Amazon S3와 같은 원격 오브젝트 저장소에서 인덱싱된 데이터를 저장할 수 있는 인덱서 기능입니다. 배포의 데이터 볼륨이 증가하면 일반적으로 스토리지 수요가 컴퓨팅 리소스에 대한 수요보다 앞입니다. SmartStore를 사용하면 개별 리소스를 확장하여 인덱서 스토리지를 관리하고 컴퓨팅 리소스를 비용 효율적으로 관리할 수 있습니다.</block>
  <block id="4b253fe4960ecb87fdd7a6c05a125003" category="paragraph">SmartStore는 원격 스토리지 계층과 캐시 관리자를 도입했습니다. 이러한 기능을 통해 데이터는 인덱서 또는 원격 스토리지 계층에 로컬로 상주할 수 있습니다. 캐시 관리자는 인덱서와 인덱서에 구성된 원격 스토리지 계층 간의 데이터 이동을 관리합니다.</block>
  <block id="98941a2e255442c92447b445a4a6bc6e" category="paragraph">SmartStore를 사용하면 인덱서 스토리지 공간을 최소한으로 줄이고 I/O에 최적화된 컴퓨팅 리소스를 선택할 수 있습니다. 대부분의 데이터는 원격 스토리지에 있습니다. 인덱서를 사용하면 핫 버킷, 활성 또는 최근 검색에 사용되는 웜 버킷 복제본, 버킷 메타데이터 등 최소한의 데이터가 포함된 로컬 캐시를 유지할 수 있습니다.</block>
  <block id="2d153b33a50f3343c2aeb68789ee8e26" category="section-title">Splunk SmartStore 데이터 흐름</block>
  <block id="3306b50d7dd22a0698c2245e7cd06bee" category="paragraph">다양한 소스에서 들어오는 데이터가 인덱서에 도달하면 데이터가 인덱싱되어 핫 버킷에 로컬로 저장됩니다. 인덱서는 또한 핫 버킷 데이터를 타겟 인덱서에 복제합니다. 지금까지 데이터 흐름은 비 SmartStore 인덱스의 데이터 흐름과 동일합니다.</block>
  <block id="ad1e15c21ba7587e1631977abe48ab09" category="paragraph">핫 버킷이 웜(Warm)으로 롤링되면 데이터 흐름은 분기됩니다. 소스 인덱서를 사용하면 웜 버킷이 원격 객체 저장소(원격 스토리지 계층)에 복제되는 동시에 기존 복제본이 캐시에 남아 있게 됩니다. 이는 검색이 최근에 인덱싱된 데이터에 걸쳐 실행되는 경향이 있기 때문입니다. 그러나 원격 저장소가 여러 로컬 복제본을 유지 관리하지 않고 고가용성을 제공하므로 타겟 인덱서는 복제본을 삭제합니다. 이제 버켓의 마스터 카피가 원격 저장소에 상주합니다.</block>
  <block id="3d39641a906c56e9e12b0f019f23bc1d" category="paragraph">다음 이미지는 Splunk SmartStore 데이터 흐름을 보여줍니다.</block>
  <block id="9fb3b10aa394792f93ac799606bd8ed5" category="paragraph"><block ref="9fb3b10aa394792f93ac799606bd8ed5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7fa16046e839496393e84b6a20e9604e" category="paragraph">인덱서의 캐시 관리자는 SmartStore 데이터 흐름의 핵심입니다. 검색 요청을 처리하는 데 필요한 경우 원격 저장소에서 버킷 복사본을 가져옵니다. 또한 검색에 참여할 가능성이 시간이 지남에 따라 줄어들기 때문에 캐시에서 버킷 복사본이 오래되거나 적게 검색됩니다.</block>
  <block id="715f39bb7952ceb84a6bd1bb44c1ac4d" category="paragraph">캐시 관리자의 작업은 사용 가능한 캐시의 사용을 최적화하는 동시에 검색에 필요한 버킷에 즉시 액세스할 수 있도록 하는 것입니다.</block>
  <block id="4b2ba4c21a026c9139cf1484818f31c0" category="paragraph">아래 표에는 솔루션을 구현하는 데 필요한 소프트웨어 구성요소가 나와 있습니다. 솔루션 구현에 사용되는 소프트웨어 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="aa76f43f5e0552119cc8d5313c67296e" category="cell">제품군</block>
  <block id="df644ae155e79abf54175bd15d75f363" category="cell">제품 이름</block>
  <block id="892b5a336dfe285f2d5c04ccd3d6c465" category="cell">제품 버전</block>
  <block id="1b3e6de2b0fe97c3177ea5a4ad142554" category="cell">StorageGRID 오브젝트 스토리지</block>
  <block id="36552b079970ffb2dd1314115af76c4b" category="cell">11.6</block>
  <block id="66985170e641a7e20698bfec3c1d889f" category="cell">CentOS 7.x</block>
  <block id="5dba46907e72d7502229329d2aafd8a2" category="cell">Splunk Enterprise</block>
  <block id="9d8d169ace12276d008f0d0b88b61261" category="cell">Splunk Enterprise 및 SmartStore</block>
  <block id="75809dde56e3fe2c2fb740f1b55807ac" category="cell">8.0.3</block>
  <block id="3192356dc19e9b4ec43ba340bad657ee" category="section-title">단일 및 다중 사이트 요구 사항</block>
  <block id="98b8bd4f9670277f1f0e59a574019582" category="paragraph">데이터가 많은 시스템에서 발생하며 많은 사용자가 데이터를 검색해야 하는 엔터프라이즈 Splunk 환경(중간 규모 및 대규모 구축)에서는 단일 및 여러 사이트에 Splunk Enterprise 인스턴스를 배포하여 배포를 확장할 수 있습니다.</block>
  <block id="22e1b76cf9acbfd35603b013eefcb079" category="paragraph">다음 표에는 분산 Splunk Enterprise 환경에서 사용되는 구성요소가 나와 있습니다.</block>
  <block id="1fbd0b2f11fe7779db6380b6d09478df" category="cell">서로 데이터를 복제하도록 구성된 Splunk Enterprise 인덱서의 그룹입니다</block>
  <block id="4e21e57c1860bf98fe3d0af8068f827d" category="cell">부하 분산 장치</block>
  <block id="03d7fbb295d0abb68bf4d3ce22d6d448" category="cell">클러스터링된 구성 요소에 대한 로드 관리</block>
  <block id="a0ebc1066e0250b1b42f1a66ae974836" category="paragraph">이 그림은 단일 사이트 분산 배포의 예를 보여 줍니다.</block>
  <block id="733ecc3327823660187d1d7d76df7079" category="paragraph"><block ref="733ecc3327823660187d1d7d76df7079" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf99a89b389bc74dc1a403695b28d6cd" category="paragraph">이 그림은 다중 사이트 분산 구축의 예를 보여 줍니다.</block>
  <block id="d10d5e57a05119c14c599013d15d6553" category="paragraph"><block ref="d10d5e57a05119c14c599013d15d6553" category="inline-image-macro-rx" type="image"></block></block>
  <block id="80d955d16c5178cc40e347dfe675a443" category="paragraph">다음 표에는 솔루션을 구현하는 데 필요한 최소 하드웨어 구성 요소 수가 나와 있습니다. 특정 솔루션 구현에 사용되는 하드웨어 구성요소는 고객 요구사항에 따라 다를 수 있습니다.</block>
  <block id="40b955882ffd3093985177c3721cfed2" category="admonition">단일 사이트 또는 여러 사이트에 Splunk SmartStore 및 StorageGRID를 구축했는지와 관계없이 모든 시스템은 단일 창에서 StorageGRID 그리드 관리자에서 관리됩니다. 자세한 내용은 "Grid Manager를 사용한 간단한 관리" 섹션을 참조하십시오.</block>
  <block id="1605af3a62fa950fe8374a69086fdc94" category="paragraph">이 표에는 단일 사이트에 사용되는 하드웨어가 나열되어 있습니다.</block>
  <block id="380dbc8d9d2c8a17f6ebb0b2c62d3e85" category="cell">디스크</block>
  <block id="b3e1f4c67ee07a73dcdaff1cf34f2640" category="cell">사용 가능한 용량</block>
  <block id="3b0649c72650c313a357338dcdfb64ec" category="cell">참고</block>
  <block id="1c594a38f9aafa3a439c25bc55815b40" category="cell">StorageGRID SG1000</block>
  <block id="b179d20c2d3e6e91708b69931e8fcf32" category="cell">관리 노드 및 로드 밸런서</block>
  <block id="48f09b085e666c51e35dbe89367de826" category="cell">StorageGRID SG6060</block>
  <block id="ab570142c34522356bdf33666f6532a3" category="cell">X48, 8TB(NL-SAS HDD)</block>
  <block id="1792805a48a4da5ef5a78aa014da1f84" category="cell">1PB</block>
  <block id="ecefe4d01bf4079d1e2833e9a7de2db7" category="cell">원격 스토리지</block>
  <block id="9327a762e04913fc832ee2b182848716" category="paragraph">이 표에는 사이트별 다중 사이트 구성에 사용되는 하드웨어가 나와 있습니다.</block>
  <block id="41cac74c281e47bb6feb1ef8db664ce4" category="cell">관리 노드 및 로드 밸런서</block>
  <block id="aadc7d80b20e9c743c2920297937f9fd" category="section-title">NetApp StorageGRID 로드 밸런서: SG1000</block>
  <block id="b3f51763a6ba0ae7fe6d83095cb24299" category="paragraph">오브젝트 스토리지에는 클라우드 스토리지 네임스페이스를 제공하는 로드 밸런서가 필요합니다. StorageGRID는 F5 및 Citrix와 같은 주요 공급업체의 타사 로드 밸런싱 장치를 지원하지만 많은 고객이 단순성, 복원력 및 고성능을 위해 엔터프라이즈급 StorageGRID 밸런서를 선택합니다. StorageGRID 로드 밸런서는 VM, 컨테이너 또는 특수 제작된 어플라이언스로 사용할 수 있습니다.</block>
  <block id="01f9bf7333b91ead20b7d1ac12ba4bca" category="paragraph">StorageGRID SG1000은 S3 데이터 경로 연결을 위한 고가용성(HA) 그룹 및 지능형 로드 밸런싱을 손쉽게 사용합니다. 다른 온프레미스 오브젝트 스토리지 시스템은 맞춤형 로드 밸런서를 제공하지 않습니다.</block>
  <block id="2f1a2bc20d9d0cddf636827860bdeb21" category="paragraph">SG1000 어플라이언스는 다음과 같은 기능을 제공합니다.</block>
  <block id="fee5222c1281869dd7c4e3e4b7225065" category="list-text">로드 밸런서와 선택적으로 StorageGRID 시스템에 대한 관리 노드가 작동합니다</block>
  <block id="7ea5a035cfe0609861da7628e7dedc64" category="list-text">노드 배포 및 구성을 간소화하는 StorageGRID 어플라이언스 설치 프로그램</block>
  <block id="224d05cfece712836874ae47446c6d1b" category="list-text">S3 엔드포인트 및 SSL의 간편한 구성</block>
  <block id="59bf11863992b10be7d53c81c21a0220" category="list-text">전용 대역폭(타사 로드 밸런싱 장치를 다른 애플리케이션과 공유하는 대신)</block>
  <block id="1436fddc15afc971733cc42610be3718" category="list-text">최대 4 x 100Gbps 통합 이더넷 대역폭</block>
  <block id="4ff66456ad21f2aa88ad918b2a19287d" category="paragraph">다음 이미지는 SG1000 게이트웨이 서비스 어플라이언스를 나타냅니다.</block>
  <block id="3e44556364ce6907a44a9fb5c09eab69" category="paragraph"><block ref="3e44556364ce6907a44a9fb5c09eab69" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c69ff1785c16ab7db216e04b62e5ef4f" category="section-title">SG6060</block>
  <block id="40b11d9d6e72b8f3d6f6cd150ea6d5b3" category="paragraph">StorageGRID SG6060 어플라이언스에는 2개의 스토리지 컨트롤러와 60개의 드라이브를 포함하는 컴퓨팅 컨트롤러(SG6060) 및 스토리지 컨트롤러 쉘프(E-Series E2860)가 포함되어 있습니다. 본 제품은 다음과 같은 기능을 제공합니다.</block>
  <block id="5d61368716b8937ccfa3ae30bdeb3add" category="list-text">단일 네임스페이스에서 최대 400PB까지 확장 가능</block>
  <block id="b08da7d555d413c82fa9476b78a3d1b4" category="list-text">최대 4배의 25Gbps 애그리게이트 이더넷 대역폭</block>
  <block id="3b384482ee0276a75964f52aab736cac" category="list-text">노드 배포 및 구성을 간소화하는 StorageGRID 어플라이언스 설치 프로그램이 포함되어 있습니다.</block>
  <block id="3d6b68fb6989ac04a76612b7d50b5046" category="list-text">각 SG6060 어플라이언스는 총 180개 드라이브에 대해 하나 또는 두 개의 추가 확장 쉘프를 가질 수 있습니다.</block>
  <block id="470503fbecc72cbe91b61c6e9b999cbe" category="list-text">스토리지 컨트롤러 페일오버를 지원하기 위한 2개의 E-Series E2800 컨트롤러(이중 구성)</block>
  <block id="920a659800fa3289516e73f0b8d0cd70" category="list-text">60개의 3.5인치 드라이브(SSD 2개, NL-SAS 드라이브 58개)를 보관하는 5개의 드로어 드라이브 쉘프</block>
  <block id="d60b006794c926c67e95ce7f49fffbed" category="paragraph">다음 이미지는 SG6060 어플라이언스를 나타냅니다.</block>
  <block id="8d3bb0a39a1d477f7f0b8789769c96c5" category="paragraph"><block ref="8d3bb0a39a1d477f7f0b8789769c96c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad24897680a673883f3a8e9467ea3271" category="section-title">Splunk 설계</block>
  <block id="c2d7b4acc3efe890969906f2a0be4bea" category="paragraph">다음 표에는 단일 사이트를 위한 Splunk 구성이 나와 있습니다.</block>
  <block id="95dd022b7af0f9fcfb9ed21236830169" category="cell">코어</block>
  <block id="5132d0e71971db5ca9827d470220eae9" category="cell">16개 코어</block>
  <block id="f4e3903ba78addf6fadac4a2d7285203" category="cell">32GB RAM</block>
  <block id="3988099dd7392a8b60a290ca560ac95d" category="cell">CentOS 8.1</block>
  <block id="aa7f73db0dcc93a83403f1afb650efdd" category="cell">사용자 데이터를 관리합니다</block>
  <block id="86e7f660faa5812369ca3195a6ab944a" category="cell">사용자 프런트 엔드에서 인덱서의 데이터를 검색합니다</block>
  <block id="e14f0b3b9201c717d9cae1db6969fb64" category="cell">검색 헤드 클러스터에 대한 업데이트를 처리합니다</block>
  <block id="0ac993c5a472613a0cd368ccfefd6009" category="cell">Splunk 설치 및 인덱싱을 관리합니다</block>
  <block id="a91966f90c29f7d9420d2fd902f4aac2" category="cell">모니터링 콘솔 및 라이센스 마스터</block>
  <block id="0cb149f6f77c10496cf7645357f9fd17" category="cell">전체 Splunk 구축을 중앙 집중식으로 모니터링하고 Splunk 라이센스를 관리합니다</block>
  <block id="9bc779a08fe3e6d54c4355c4ee8c4a95" category="paragraph">다음 표에서는 다중 사이트 구성을 위한 Splunk 구성에 대해 설명합니다.</block>
  <block id="9605b47d211de50422182b81685da619" category="paragraph">이 표에는 다중 사이트 구성(사이트 A)을 위한 Splunk 구성이 나와 있습니다.</block>
  <block id="d9de1b6846e3235226dba66773043a15" category="cell">데이터를 수집하여 인덱서에 데이터를 전달하는 역할을 합니다.</block>
  <block id="76132c1712ff61ff02378720304f6529" category="cell">전체 Splunk 구축을 중앙 집중식으로 모니터링하고 Splunk 라이센스를 관리합니다.</block>
  <block id="2d3db4a7f27e8f892b40be60e8c003b4" category="paragraph">이 표에는 다중 사이트 구성(사이트 B)을 위한 Splunk 구성이 나와 있습니다.</block>
  <block id="b9006101b0f69e04590f5276d5cab52a" category="inline-link-macro">다음: 단일 사이트 SmartStore 성능.</block>
  <block id="f7c6952971373a408f0b926fb7202e6f" category="paragraph"><block ref="f7c6952971373a408f0b926fb7202e6f" category="inline-link-macro-rx"></block></block>
  <block id="722462e25c63551f73985fc89f6a2139" category="summary">이 솔루션을 사용하면 컴퓨팅, 핫 스토리지 또는 S3 리소스를 추가하여 사용자 수나 단일 사이트 및 다중 사이트 구축 시 수집 속도 측면에서 증가하는 수요를 충족할 수 있습니다.</block>
  <block id="0dd05c4d24d98f033770c01356b3ce26" category="paragraph"><block ref="0dd05c4d24d98f033770c01356b3ce26" category="inline-link-macro-rx"></block></block>
  <block id="bf89e1232480b95d07f648df24c3695b" category="list-text">* 성능. * Splunk SmartStore와 NetApp StorageGRID를 함께 사용하면 오브젝트 스토리지를 사용하여 핫 버킷과 웜 버킷 간에 데이터를 빠르게 마이그레이션할 수 있습니다. StorageGRID은 대규모 오브젝트 워크로드를 위한 빠른 성능을 제공하여 마이그레이션 프로세스를 강력하게 지원합니다.</block>
  <block id="e0be1ad556d6601e63eb8f1b6208c55e" category="list-text">* 멀티 사이트 지원 * StorageGRID 분산 아키텍처를 사용하면 Splunk SmartStore에서 단일 글로벌 네임스페이스를 통해 단일 및 여러 사이트에 걸쳐 구축을 확장할 수 있습니다. 단일 글로벌 네임스페이스를 통해 데이터가 어디에 있든 모든 사이트에서 데이터에 액세스할 수 있습니다.</block>
  <block id="9efd709ebdaac869f02b49e17fe9e92b" category="list-text">* 확장성 향상 * 컴퓨팅 리소스와 별개로 스토리지 리소스를 확장하여 Splunk 환경의 변화하는 요구 사항과 수요를 충족함으로써 TCO를 개선합니다.</block>
  <block id="52fb1ca9da3811c1cb86cd4347f98a64" category="list-text">* 용량 * 단일 네임스페이스를 560PB 이상으로 확장하여 StorageGRID를 통해 Splunk 구축 시 빠르게 증가하는 볼륨을 충족합니다.</block>
  <block id="ff501c8a6a8c7b1ee7a3c656b6f4055a" category="list-text">데이터 가용성 * 데이터 가용성, 성능, 지리적 분산, 보존, 보호, 변화하는 데이터의 비즈니스 가치에 맞춰 동적으로 조정할 수 있는 메타데이터 기반 정책을 통해 스토리지 비용을 절감합니다.</block>
  <block id="bf1b0e32d877d343f0b3bc9ba43cb688" category="inline-link">Splunk에서 제공하는 지침</block>
  <block id="29c3e2f956fc4b206ef3c7bbbb3730b0" category="paragraph">로컬(핫)과 원격(웜) 스토리지 간의 버킷 복사본 전송을 처리하는 인덱서의 구성 요소인 SmartStore 캐시를 사용하여 성능을 높입니다. 이 솔루션을 위한 Splunk 사이징은 을 기반으로 합니다<block ref="d615ab802f29a9ee4a18e420480d049f" category="inline-link-rx"></block>. 이 솔루션을 사용하면 컴퓨팅, 핫 스토리지 또는 S3 리소스를 추가하여 사용자 수나 단일 사이트 및 다중 사이트 구축 시 수집 속도 측면에서 증가하는 수요를 충족할 수 있습니다.</block>
  <block id="a013f15cce9510e1b717f058d9322b0f" category="inline-link-macro">다음 단계: 지능형 계층화 및 비용 절감.</block>
  <block id="1dd4851efea44091fc608ccfa49a8da6" category="paragraph"><block ref="1dd4851efea44091fc608ccfa49a8da6" category="inline-link-macro-rx"></block></block>
  <block id="c7ebb883721f7d9264fd6ef2ae03fc71" category="summary">이 기술 보고서에서는 NetApp이 Splunk SmartStore 솔루션에 제공하는 이점을 간략하게 설명하고, 사용자 환경에서 Splunk SmartStore를 설계 및 사이징하기 위한 프레임워크를 소개합니다. 따라서 탁월한 TCO를 제공하는 단순하고 확장 가능하며 복원력이 뛰어난 솔루션이 탄생했습니다.</block>
  <block id="766d1a96c4f198ecfe92484b980e9b31" category="doc">TR-4869: Splunk SmartStore를 지원하는 NetApp StorageGRID</block>
  <block id="2dafc6e921d43527cceb2ba642abf973" category="paragraph">카르티키안 나가링감, 바비 오먼스, 조셉 칸다틸파람빌</block>
  <block id="648e525fafbee4c7b749ab8740beb0d3" category="paragraph">Splunk Enterprise는 업계 최고의 SIEM(Security Information and Event Management) 솔루션으로 보안, IT 및 DevOps 팀 전체에서 결과를 이끌어낼 수 있습니다. 데이터는 기하급수적으로 계속 증가하기 때문에 이러한 대규모 리소스를 활용할 수 있는 기업에게는 큰 기회가 됩니다. Splunk Enterprise는 광범위한 사용 사례에서 계속해서 채택되고 있습니다. 사용 사례가 증가함에 따라 Splunk Enterprise가 베스트 및 처리하는 데이터의 양도 증가하고 있습니다. Splunk Enterprise의 기존 아키텍처는 분산 스케일아웃 설계로 뛰어난 데이터 액세스 및 가용성을 제공합니다. 하지만 이 아키텍처를 사용하는 기업은 빠르게 증가하는 데이터 볼륨을 충족하기 위해 확장하는 데 따른 비용 증가에 직면해 있습니다.</block>
  <block id="6a7254f4c4c618a79510973c24f6b258" category="paragraph">NetApp StorageGRID가 포함된 Splunk SmartStore는 컴퓨팅과 스토리지가 분리 가능한 새로운 구축 모델을 제공함으로써 이러한 문제를 해결합니다. 또한, 이 솔루션은 고객이 단일 및 다중 사이트 간에 확장할 수 있도록 지원하는 동시에 컴퓨팅 및 스토리지를 독립적으로 확장하고 비용 효율적인 클라우드 기반 S3 오브젝트 스토리지에 지능형 계층화를 추가하여 비용을 절감하여 Splunk Enterprise 환경에 탁월한 확장성과 탄력성을 제공합니다.</block>
  <block id="f8ff71716eed4ad221efc3e0d60beaf6" category="paragraph">이 솔루션은 검색 성능을 유지하면서 로컬 스토리지의 데이터 양을 최적화하므로 필요에 따라 컴퓨팅 및 스토리지를 확장할 수 있습니다. SmartStore는 데이터 액세스 패턴을 자동으로 평가하여 실시간 분석을 위해 액세스해야 하는 데이터와 저렴한 S3 오브젝트 스토리지에 상주해야 하는 데이터를 결정합니다.</block>
  <block id="5c56ae45ba2fb5c42451dffdb2e64b55" category="paragraph">이 기술 보고서에서는 NetApp이 Splunk SmartStore 솔루션에 제공하는 이점을 간략하게 설명하고, 사용자 환경에서 Splunk SmartStore를 설계 및 사이징하기 위한 프레임워크를 소개합니다. 따라서 탁월한 TCO를 제공하는 단순하고 확장 가능하며 복원력이 뛰어난 솔루션이 탄생했습니다. StorageGRID는 확장 가능하고 비용 효율적인 S3 프로토콜/API 기반 오브젝트 스토리지(원격 스토리지라고도 함)를 제공하므로 조직에서는 Splunk 솔루션을 더 낮은 비용으로 확장하는 동시에 복원력을 높일 수 있습니다.</block>
  <block id="9841b81741e6066deac80b48e24f10fd" category="admonition">Splunk SmartStore는 오브젝트 스토리지를 원격 저장소 또는 원격 스토리지 계층으로 의미합니다.</block>
  <block id="4c1ead791cca9ec5a7b94356255ce5ef" category="section-title">NetApp StorageGRID 정보</block>
  <block id="57f13ae6637bd7ac5af4d0b1c4342cf7" category="paragraph">NetApp StorageGRID는 대규모 아카이브, 미디어 저장소 및 웹 데이터 저장소를 위한 소프트웨어 정의 오브젝트 스토리지 솔루션입니다. StorageGRID과 함께 NetApp은 20년 간의 경험을 활용하여 업계 최고의 혁신 및 데이터 관리 솔루션을 제공하면서, 조직이 사내 및 퍼블릭, 프라이빗 또는 하이브리드 클라우드 구현 모두에서 정보의 가치를 관리하고 최대화할 수 있도록 지원합니다.</block>
  <block id="6281e52aec6aad8556d89bbf44d95436" category="paragraph">StorageGRID는 비정형 데이터를 대규모로 저장할 수 있는 안전하고 내구성 있는 스토리지를 제공합니다. 메타데이터 중심의 통합 라이프사이클 관리 정책은 라이프사이클 전반에서 데이터 위치를 최적화합니다. 콘텐츠가 적절한 위치에 적시에 적절한 스토리지 계층에 배치되어 비용을 절감합니다. 단일 네임스페이스를 사용하면 StorageGRID 스토리지의 지리적 위치에 관계없이 단일 호출을 통해 데이터에 액세스할 수 있습니다. 고객은 데이터 센터와 클라우드 인프라 간에 여러 StorageGRID 인스턴스를 구축하고 관리할 수 있습니다.</block>
  <block id="d0a72d49cbe69b32b6e889db2e1429c9" category="paragraph">StorageGRID 시스템은 전세계적으로 분산된 중복 노드로 구성되며, 기존 및 차세대 클라이언트 애플리케이션과 모두 통합될 수 있습니다.</block>
  <block id="5680b078511221b1538af544a52a477e" category="paragraph"><block ref="5680b078511221b1538af544a52a477e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4077a77339f68c64c1e50f20961e468f" category="paragraph">IDC MarketScape가 최근 보고서, IDC MarketScape: Worldwide Object-based Storage 2019 Vendor Assessment 에서 NetApp을 리더로 선정했습니다. 가장 까다로운 업계에서 20년 가까이 운영 및 배포 작업을 진행 중인 StorageGRID는 비정형 데이터 부문에서 인정받는 선두 기업입니다.</block>
  <block id="a2146cca70b8afc5500f690b84357813" category="paragraph">StorageGRID를 사용하면 다음과 같은 이점을 얻을 수 있습니다.</block>
  <block id="0d29e2d2977160f50fc59018cd24d6ee" category="list-text">수백 페타바이트로 손쉽게 확장 가능한 단일 네임스페이스를 통해 여러 StorageGRID 인스턴스를 구축하여 데이터 센터와 클라우드 사이의 모든 위치에서 데이터에 액세스합니다.</block>
  <block id="770d656b5273d26168b61ba6ede38cfd" category="list-text">인프라 전반에서 유연하게 구축하고 중앙 집중식으로 관리</block>
  <block id="5926e6b363cbfe237a46219c7f92fe02" category="list-text">계층적 EC(삭제 코딩)를 활용하여 내구성이 15%에 달하는 최고 수준의 내구성을 제공합니다.</block>
  <block id="77a48d0beb74ba75ef47c32ed1115a01" category="list-text">Amazon S3 Glacier 및 Azure Blob에 대한 검증된 통합으로 더 많은 하이브리드 멀티 클라우드 기능을 지원합니다.</block>
  <block id="ffa0a5ca524779112b69eb9e53aacf31" category="list-text">전용 API 또는 공급업체에 종속되지 않고 조작 방지 데이터 보존을 통해 규정 준수 의무를 충족하고 규정 준수를 촉진합니다.</block>
  <block id="6e9d67cdb6f2e5564ae28e0389bcc679" category="inline-link">NetApp StorageGRID 홈 페이지</block>
  <block id="206008935f811359069d9b35cb5c874e" category="paragraph">StorageGRID를 통해 가장 복잡한 비정형 데이터 관리 문제를 해결하는 방법에 대한 자세한 내용은 를 참조하십시오<block ref="56ef38793a035acc851dabaa0c795287" category="inline-link-rx"></block>.</block>
  <block id="04bfb82e5f80fda36ff56ad540caaa63" category="section-title">Splunk Enterprise 정보</block>
  <block id="a643f0cfa3f1b40b8f79f3609f0aa84f" category="paragraph">Splunk Enterprise는 데이터를 다른 업무 스토리지로 전환할 수 있는 플랫폼입니다. 로그 파일, 웹 사이트, 장치, 센서, 애플리케이션 등과 같은 다양한 소스에서 생성되는 데이터가 Splunk Indexers에 의해 전송 및 구문 분석되므로 데이터를 통해 풍부한 통찰력을 얻을 수 있습니다. 또한 데이터 유출을 식별하고, 고객 및 제품 동향을 파악하고, 인프라를 최적화할 기회를 찾거나, 다양한 사용 사례에서 실질적인 통찰력을 얻을 수 있습니다.</block>
  <block id="6118f726dd6c9b9e82e01638e958e5c8" category="section-title">Splunk SmartStore 정보</block>
  <block id="9ce6098334cce9db7edb3314ee645a2e" category="paragraph">Splunk SmartStore는 Splunk 아키텍처의 이점을 확장하는 동시에 비용 효율적으로 확장할 수 있는 기능을 단순화합니다. 컴퓨팅 리소스와 스토리지 리소스를 분리함으로써 인덱서 노드가 I/O에 최적화되고, 데이터 서브셋만 캐시로 저장되기 때문에 스토리지 요구사항이 크게 줄어듭니다. 이러한 리소스 중 하나만 필요한 경우에는 추가 컴퓨팅 또는 스토리지를 추가할 필요가 없습니다. 따라서 상당한 비용을 절감할 수 있습니다. 또한 비용 효율적이고 확장 가능한 S3 기반 오브젝트 스토리지를 사용하여 환경을 더욱 단순화하고 비용을 절감하며 더 방대한 데이터 세트를 유지할 수 있습니다.</block>
  <block id="fde880b7e5def5ccc70e3e98ba15b442" category="paragraph">Splunk SmartStore는 다음과 같이 조직에 중요한 가치를 제공합니다.</block>
  <block id="16fc7d5921f88ca7b8070e1913a6fb74" category="list-text">웜 데이터를 비용 최적화된 S3 오브젝트 스토리지로 이동하여 스토리지 비용 절감</block>
  <block id="9ce78e75b3ecebf85fe0d43f2cf80505" category="list-text">스토리지와 컴퓨팅을 분리하여 원활한 확장</block>
  <block id="1dd6f3d1f3ac2a43dc2e69386b1b15ca" category="list-text">복원력을 갖춘 클라우드 네이티브 스토리지를 활용하여 비즈니스 연속성을 단순화합니다</block>
  <block id="8db09dd9a1d2508a1e11189bfe47d246" category="inline-link-macro">다음: 이 솔루션의 이점</block>
  <block id="0032cf08702e09af53bf601b3f83e323" category="paragraph"><block ref="0032cf08702e09af53bf601b3f83e323" category="inline-link-macro-rx"></block></block>
  <block id="95ae2f11a98975eca88411c818226d25" category="paragraph">엔드포인트 구성을 더욱 개선하기 위해 StorageGRID는 관리 노드에 내장된 트래픽 분류 정책을 제공하고, 워크로드 트래픽을 모니터링하고, 워크로드에 다양한 QoS(서비스 품질) 제한을 적용할 수 있도록 지원합니다. 트래픽 분류 정책은 게이트웨이 노드 및 관리 노드에 대한 StorageGRID 부하 분산 서비스의 끝점에 적용됩니다. 이러한 정책은 트래픽 셰이핑 및 모니터링을 지원할 수 있습니다.</block>
  <block id="7d68f597b217695f6702ae71ae4eb455" category="summary">StorageGRID는 사용자가 끊임없이 변화하는 환경에 맞게 활용하고 사용자 지정할 수 있는 다양한 기능을 제공합니다. Splunk SmartStore를 구축하여 확장하는 데 이르기까지, 환경의 변화에 빠르게 대처해야 하며 Splunk를 중단하지 않아야 합니다. StorageGRID의 유연한 데이터 관리 정책(ILM)과 트래픽 분류자(QoS)를 사용하여 사용자 환경을 계획하고 조정할 수 있습니다.</block>
  <block id="0fc3cf31004e01f169ca3af4ef687576" category="doc">Splunk SmartStore를 위한 유연한 StorageGRID 기능</block>
  <block id="0a0da304981bebd25b6bd55cb6151bf0" category="paragraph"><block ref="0a0da304981bebd25b6bd55cb6151bf0" category="inline-link-macro-rx"></block></block>
  <block id="5b552d68210e15d5ed4e4d186264b453" category="paragraph">Grid Manager는 브라우저 기반의 그래픽 인터페이스로, 다음 이미지와 같이 전 세계적으로 분산된 단일 창에서 StorageGRID 시스템을 구성, 관리 및 모니터링할 수 있습니다.</block>
  <block id="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="paragraph"><block ref="9c4d5c64a1fc501b7fb5d68cb8048ddc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52d198c85ec187eb3bbff17442a01baa" category="paragraph">Grid Manager 인터페이스를 사용하여 다음 작업을 수행합니다.</block>
  <block id="356e4420bfe7b6226984261d66ec9e0b" category="section-title">Splunk용 NetApp StorageGRID 애플리케이션</block>
  <block id="d4503ceebebf47c506c3003f760662a2" category="paragraph">Splunk용 NetApp StorageGRID 앱은 Splunk Enterprise용 애플리케이션입니다. 이 앱은 Splunk용 NetApp StorageGRID 애드온과 함께 작동합니다. 이 제품은 StorageGRID 상태, 계정 사용 정보, 보안 감사 세부 정보, 리소스 사용 및 모니터링 등에 대한 가시성을 제공합니다.</block>
  <block id="c7b8ad57a7270e26eba0ed9da1fa0b6c" category="paragraph">다음 그림은 Splunk용 StorageGRID 앱을 보여줍니다.</block>
  <block id="7c39625522ddbadc65ea87056e2d32c9" category="paragraph"><block ref="7c39625522ddbadc65ea87056e2d32c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a7e07b036910adce42ba90efc47f818e" category="section-title">ILM 정책</block>
  <block id="fce13f2ee25ffdd1859d6a17a94b0e73" category="paragraph">StorageGRID은 오브젝트의 여러 복사본을 유지하고 2+1, 4+2(및 기타 여러 복사본)와 같은 EC(삭제 코딩) 스키마를 사용하여 특정 성능 및 데이터 보호 요구사항에 따라 오브젝트를 저장하는 등의 유연한 데이터 관리 정책을 제공합니다. 시간에 따라 워크로드와 요구사항이 달라지날수록 ILM 정책도 시간에 따라 바뀌어야 합니다. ILM 정책을 수정하는 것은 핵심 기능이므로 StorageGRID 고객은 끊임없이 변화하는 환경에 빠르고 쉽게 적응할 수 있습니다.</block>
  <block id="3f7d13681fac5c1ca00c53ae2a27efaa" category="paragraph">StorageGRID는 VM이나 SG5712, SG5760, SG6060, SGF6024와 같이 특별히 제작된 어플라이언스, 베어 메탈 또는 특수 용도의 어플라이언스에 사용할 수 있는 노드를 추가하여 성능을 확장합니다. 테스트에서는 SG6060 어플라이언스를 사용하는 최소 크기의 3노드 그리드로 SmartStore의 주요 성능 요구사항을 초과했습니다. 고객이 추가 인덱서로 Splunk 인프라를 확장함에 따라 더 많은 스토리지 노드를 추가하여 성능과 용량을 높일 수 있습니다.</block>
  <block id="8a0453356d4720c8c5a67e5e2a16b419" category="section-title">로드 밸런서 및 엔드포인트 구성</block>
  <block id="08de46c3a8d44cfa799d969abfa407eb" category="paragraph">StorageGRID의 관리 노드는 StorageGRID 시스템을 보고, 구성하고, 관리할 수 있는 그리드 관리자 UI(사용자 인터페이스) 및 REST API 엔드포인트와 시스템 작업을 추적할 수 있는 감사 로그를 제공합니다. Splunk SmartStore 원격 스토리지에 가용성이 높은 S3 엔드포인트를 제공하기 위해 StorageGRID 로드 밸런서가 구축되었으며, 이 밸런서는 관리 노드와 게이트웨이 노드에서 서비스로 실행됩니다. 또한 로드 밸런서는 로컬 트래픽을 관리하고 GSLB(Global Server Load Balancing)에 연결하여 재해 복구를 지원합니다.</block>
  <block id="d2134190f6b031237d4b1523c86c29a2" category="paragraph">엔드포인트 구성을 더욱 개선하기 위해 StorageGRID는 관리 노드에 내장된 트래픽 분류 정책을 제공하고, 워크로드 트래픽을 모니터링하고, 워크로드에 다양한 QoS(서비스 품질) 제한을 적용할 수 있도록 지원합니다. 트래픽 분류 정책은 게이트웨이 노드 및 관리 노드에 대한 StorageGRID 부하 분산 서비스의 끝점에 적용됩니다. 이러한 정책은 트래픽 제한 및 모니터링을 지원할 수 있습니다.</block>
  <block id="923a187b8784c27278acc68df21738b8" category="inline-link-macro">다음으로, Splunk 아키텍처:</block>
  <block id="ec27327edf763f5474f1428dfcc067b1" category="paragraph"><block ref="ec27327edf763f5474f1428dfcc067b1" category="inline-link-macro-rx"></block></block>
  <block id="b27064a5ca31ea524411e6ce281c8f0c" category="paragraph">NetApp은 뛰어난 TCO를 제공하는 동시에 성능과 복원력을 극대화하는 Splunk SmartStore를 위한 간단하고 확장 가능한 솔루션을 지원합니다.</block>
  <block id="39e4c49e9af8047395aa4031e5c5f3a9" category="summary">이 페이지에서는 NetApp StorageGRID, Splunk Enterprise, Splunk SmartStore를 비롯하여 이 솔루션을 완료하는 데 사용되는 구성요소를 설명합니다.</block>
  <block id="0f641483b3a1a8cfcb4b0ad971a2d016" category="inline-link-macro">이전: 지능형 계층화 및 비용 절감.</block>
  <block id="b1320bfc03a3d1edb16e0f717149a713" category="paragraph"><block ref="b1320bfc03a3d1edb16e0f717149a713" category="inline-link-macro-rx"></block></block>
  <block id="5ab9d0d9b506bd4b5bf294baccd4ef0a" category="paragraph">NetApp StorageGRID는 비용 효율적인 고성능 오브젝트 스토리지 플랫폼입니다. 분산된 노드 기반 그리드 아키텍처를 사용하여 정책 중심의 지능형 글로벌 데이터 관리를 제공합니다. 정교한 데이터 관리 기능과 결합된 유비쿼터스 글로벌 오브젝트 네임스페이스를 통해 페타바이트 단위의 비정형 데이터와 수십억 개의 오브젝트 관리를 간소화합니다. 단일 호출 개체 액세스는 사이트 간에 확장되고 고가용성 아키텍처를 단순화하는 동시에 사이트 또는 인프라 중단과 관계없이 지속적인 개체 액세스를 보장합니다.</block>
  <block id="d67c579ad5ceca0ec4f8fe6a86f203cf" category="paragraph">멀티 테넌시를 사용하면 여러 클라우드와 엔터프라이즈의 비정형 데이터 애플리케이션을 동일한 그리드 내에서 안전하게 서비스할 수 있으므로 StorageGRID의 ROI 및 사용 사례가 증가합니다. 여러 지역에서 내구성, 보호, 성능, 인접성을 최적화하여 메타데이터 기반 오브젝트 라이프사이클 정책에 따라 여러 서비스 레벨을 생성할 수 있습니다. 사용자는 정책을 조정하고 요구 사항이 변경됨에 따라 데이터 환경을 중단 없이 재조정할 수 있습니다.</block>
  <block id="0d2b0fb2b312d872db772396e149b541" category="paragraph">SmartStore는 StorageGRID를 원격 스토리지 계층으로 활용하고 고객이 지리적으로 분산된 여러 사이트를 구축하여 단일 오브젝트 네임스페이스로 제공되는 강력한 가용성과 내구성을 확보할 수 있도록 지원합니다. 이를 통해 Splunk SmartStore는 StorageGRID의 고성능, 고밀도 용량을 활용할 수 있으며, 단일 URL을 사용하여 여러 물리적 사이트에서 수백 개의 노드로 확장할 수 있습니다. 또한 단일 URL을 통해 스토리지 확장, 업그레이드 및 수리를 단일 사이트 외부에서도 무중단으로 수행할 수 있습니다. StorageGRID의 고유한 데이터 관리 정책 엔진은 최적의 성능 및 내구성 수준을 제공하며 데이터 지역성 요구사항을 준수합니다.</block>
  <block id="f9ed96cf2d028d3cfa9c658c6ec5ae72" category="paragraph">Splunk는 머신 생성 데이터의 수집 및 분석을 선도하는 기업으로, 운영 분석 기능을 통해 IT를 간소화 및 현대화하도록 지원합니다. 또한 비즈니스 분석, 보안, IoT 사용 사례로 확장됩니다. 스토리지는 성공적인 Splunk 소프트웨어 구축을 위한 중요한 지원 요소입니다.</block>
  <block id="1812fb837f2c63812e909b4457b0fa17" category="paragraph">시스템에서 생성되는 데이터는 가장 빠르게 증가하는 빅 데이터 유형입니다. 이 형식은 예측할 수 없으며 많은 소스에서 가져온 것으로, 대개 높은 속도와 큰 볼륨에서 사용됩니다. 이러한 워크로드 특성을 디지털 배기가라고 합니다. Splunk SmartStore를 사용하면 이러한 데이터를 쉽게 파악할 수 있으며 가장 비용 효율적인 스토리지 계층에 핫 데이터와 웜 데이터를 최적의 위치에 배치할 수 있는 스마트 데이터 계층화를 제공합니다.</block>
  <block id="bd069a1be23f237559be08ae79727806" category="paragraph">Splunk SmartStore는 StorageGRID와 같은 오브젝트 스토리지(원격 스토리지 또는 원격 스토리지 계층이라고도 함)를 사용하여 S3 프로토콜을 사용하여 웜 데이터를 저장하는 인덱서 기능입니다.</block>
  <block id="9e5e9e455aa469c6579c4cde82cf69fc" category="paragraph">배포의 데이터 볼륨이 증가하면 일반적으로 컴퓨터 리소스에 대한 스토리지 요구가 보다 커집니다. SmartStore를 사용하면 컴퓨팅과 스토리지를 별도로 확장하여 인덱서 스토리지와 컴퓨팅 리소스를 비용 효율적으로 관리할 수 있습니다.</block>
  <block id="1ab3873a2fa155a27933ac3e2b4ae709" category="paragraph">SmartStore는 S3 프로토콜 및 캐시 관리자를 사용하여 원격 스토리지 계층을 도입했습니다. 이러한 기능을 통해 데이터는 인덱서 또는 원격 스토리지에 로컬로 상주할 수 있습니다. 인덱서에 상주하는 캐시 관리자는 인덱서와 원격 스토리지 계층 간의 데이터 이동을 관리합니다. 버킷 메타데이터와 함께 버킷(핫 및 웜)에 데이터가 저장됩니다.</block>
  <block id="85a6e51e1b2fd3e4be531f269e108f39" category="paragraph">SmartStore를 사용하면 대부분의 데이터가 원격 스토리지 계층에 상주하므로 인덱서 스토리지 공간을 최소한으로 줄이고 I/O에 최적화된 컴퓨팅 리소스를 선택할 수 있습니다. 인덱서를 사용하면 로컬 캐시가 유지되므로 요청되고 예측된 결과를 반환하는 데 필요한 최소한의 데이터가 표시됩니다. 로컬 캐시에는 핫 버킷, 활성 또는 최근 검색에 사용되는 웜 버킷의 복사본 및 버킷 메타데이터가 포함됩니다.</block>
  <block id="8cc78103debf2dcfe53620b96565dad4" category="paragraph">고객은 Splunk SmartStore와 StorageGRID를 함께 사용하여 고성능 및 비용 효율적인 원격 스토리지를 통해 환경을 증분 확장하는 동시에 전체 솔루션에 높은 수준의 탄력성을 제공할 수 있습니다. 따라서 고객은 더 많은 인덱서와 데이터 보존 변경, 운영 중단 없이 수집 속도를 향상하든 관계없이 언제든지 특정 시간에 모든 구성요소(핫 스토리지 및/또는 웜 S3 스토리지)를 추가할 수 있습니다.</block>
  <block id="5cb48860c8dadcd442724a4122e031bd" category="inline-link-macro">그 다음: Splunk SmartStore를 위한 유연한 StorageGRID 기능</block>
  <block id="9a206b91ebbd6c75f73fba261d1eed1c" category="paragraph"><block ref="9a206b91ebbd6c75f73fba261d1eed1c" category="inline-link-macro-rx"></block></block>
  <block id="5273463fa2459ed38da1af200de6f150" category="summary">이 페이지에서는 NetApp StorageGRID 컨트롤러의 Splunk SmartStore 성능을 설명합니다. Splunk SmartStore는 성능 검증에서 StorageGRID 오브젝트 스토리지인 원격 스토리지로 웜 데이터를 이동합니다.</block>
  <block id="b646ed758d0eaa12ba9fab12788f9ad4" category="doc">단일 사이트 SmartStore 성능</block>
  <block id="47251bcda6f5d3ff81fc5968fa702aad" category="inline-link-macro">이전: Splunk 아키텍처.</block>
  <block id="10da3263ceac590ab423073945a99eac" category="paragraph"><block ref="10da3263ceac590ab423073945a99eac" category="inline-link-macro-rx"></block></block>
  <block id="b72db8dc34d5e01f398d66c9de42c11f" category="paragraph">이 섹션에서는 NetApp StorageGRID 컨트롤러의 Splunk SmartStore 성능을 설명합니다. Splunk SmartStore는 웜 데이터를 원격 스토리지로 이동합니다. 이 경우 성능 검증을 위한 StorageGRID 오브젝트 스토리지가 사용됩니다.</block>
  <block id="1d01dcffdd1257afb01e4194d766d2f9" category="paragraph"><block ref="1d01dcffdd1257afb01e4194d766d2f9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="32b74ac1eb4eb0530a3f976e96e3120d" category="paragraph">NetApp은 핫/캐시 스토리지에 EF600을 사용하고 원격 스토리지에 StorageGRID 6060을 사용했습니다. 성능 검증을 위해 다음 아키텍처를 사용했습니다. 당사는 2개의 검색 헤드, 4개의 무거운 전달자를 사용하여 데이터를 인덱서에 전달했으며, 7개의 Splunk Event Generator(Eventgens)를 사용하여 실시간 데이터를 생성하고 18개의 인덱서(indexers)를 사용하여 데이터를 저장했습니다.</block>
  <block id="a2fd19ff7e04cf04d5d99320b979cd00" category="paragraph"><block ref="a2fd19ff7e04cf04d5d99320b979cd00" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45940e86de61b51821b0ec7959b3d551" category="paragraph">이 표에는 SmartStorage 성능 검증에 사용된 하드웨어가 나열되어 있습니다.</block>
  <block id="2fda610cb12c654fe037d4130498d5ae" category="cell">중량지 전달자</block>
  <block id="6d53d218eec402993fef5394aef9acdf" category="cell">16개 코어</block>
  <block id="d3dd61dd737f0e824caf9d717bc1a59d" category="cell">SLED 15 SP2</block>
  <block id="6f4922f45568161a8cdf4ad2299f6d23" category="cell">18</block>
  <block id="21dd53b3176e5a03137d603514a60ece" category="cell">사용자 프런트 엔드에서 인덱서의 데이터를 검색합니다</block>
  <block id="c247e74124395bc7279d790ac384786e" category="section-title">SmartStore 원격 저장소 성능 검증</block>
  <block id="30cf0ca744869370aafb6cfecdd7b4c6" category="paragraph">이 성능 검증에서 10일 동안 모든 인덱서의 로컬 스토리지에 SmartStore 캐시를 구성했습니다. Splunk 클러스터 관리자에서 'axDataSize=auto'(750MB 버킷 크기)를 활성화하고 모든 인덱서에 변경 사항을 푸시했습니다. 업로드 성능을 측정하기 위해 매일 10TB를 10일 동안 수집하여 모든 핫 버킷을 동시에 웜(warm)으로 롤오버한 후 SmartStore 모니터링 콘솔 대시보드에서 인스턴스당 최대 처리량과 평균 처리량을 캡처했습니다.</block>
  <block id="4fc95542b54fee8da424a2e0ab281aeb" category="paragraph">이 이미지는 하루 만에 수집된 데이터를 보여 줍니다.</block>
  <block id="c1b0c9568cd6b9bf236fb9566021d8a4" category="paragraph"><block ref="c1b0c9568cd6b9bf236fb9566021d8a4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b72140907b2e824ba4a35a2f01bac4e6" category="paragraph">클러스터 마스터에서 다음 명령을 실행했습니다. 인덱스 이름은 eventgen-test입니다. 그런 다음 SmartStore 모니터링 콘솔 대시보드를 통해 인스턴스당 최대 및 평균 업로드 처리량과 배포 전체를 캡처했습니다.</block>
  <block id="94a0389fcc3ce42eea7a3f351f5d39b5" category="admonition">클러스터 마스터는 모든 인덱서에 암호 없는 인증을 가집니다(RTP-idx0001… RTP-idx0018).</block>
  <block id="d27688c7ebc58e3f620120997e317180" category="paragraph">다운로드 성능을 측정하기 위해 다음 명령을 사용하여 evict CLI를 두 번 실행하여 캐시에서 모든 데이터를 퇴거했습니다.</block>
  <block id="4faf8abcf7e17175784cdc9d58df1608" category="admonition">클러스터 마스터에서 다음 명령을 실행하여 StorageGRID의 원격 스토어에서 10일 이상의 데이터를 검색헤드에서 검색했습니다. 그런 다음 SmartStore 모니터링 콘솔 대시보드를 통해 인스턴스당 최대 및 평균 업로드 처리량 및 전체 배포를 캡처했습니다.</block>
  <block id="995931f06acb79ea5ac83df17d692a1d" category="paragraph">인덱서 구성이 SmartStore 클러스터 마스터에서 푸시되었습니다. 클러스터 마스터는 인덱서에 대해 다음과 같은 구성을 가지고 있습니다.</block>
  <block id="514109dd07ed0bb93081e9e36291b879" category="paragraph">성능 매트릭스를 수집하기 위해 검색 헤드에서 다음 검색 쿼리를 실행했습니다.</block>
  <block id="39b8fe84a2982bcbeb6d733343e0678d" category="paragraph"><block ref="39b8fe84a2982bcbeb6d733343e0678d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67e03c2395d7a876b5160fefc76f9bb9" category="paragraph">클러스터 마스터에서 성능 정보를 수집했습니다. 최고 성능은 61.34GBps였습니다.</block>
  <block id="0feb590fe449a8a847517a38f1e0415f" category="paragraph"><block ref="0feb590fe449a8a847517a38f1e0415f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2850e7edd48f5666ab4f82242ddb37d2" category="paragraph">평균 성능은 약 29GBps였습니다.</block>
  <block id="2a1437158884c9696a6d4cac546972b1" category="paragraph"><block ref="2a1437158884c9696a6d4cac546972b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="283456e93c96a11ef44a18693dd6c886" category="section-title">StorageGRID 성능</block>
  <block id="f5451e9a153b2f625ec0bc944af01be5" category="inline-link">이벤트</block>
  <block id="764a1901ab00adf1e8e26712bf39c23a" category="paragraph">SmartStore 성능은 대량의 데이터에서 특정 패턴 및 문자열을 검색하는 것을 기반으로 합니다. 이 검증에서 이벤트는 를 사용하여 생성됩니다<block ref="6cec2d19baf7e588a52847e567dab457" category="inline-link-rx"></block> 검색을 통해 특정 Splunk 인덱스(eventgen-test)에서 요청이 대부분의 쿼리에 대한 StorageGRID로 전송됩니다. 다음 이미지는 쿼리 데이터의 적중 횟수와 실패 횟수를 보여 줍니다. 적중 데이터는 로컬 디스크에서 가져온 데이터이고 누락된 데이터는 StorageGRID 컨트롤러에서 가져온 것입니다.</block>
  <block id="3b8a6855a0eb4beaf2c787f34a2428d7" category="admonition">녹색은 적중 데이터를 표시하고 주황색은 누락된 데이터를 표시합니다.</block>
  <block id="0bf13ffd9c4e3655384eea9760fdd547" category="paragraph"><block ref="0bf13ffd9c4e3655384eea9760fdd547" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6fa8244cc2900d6f36b3144c7e748ac" category="paragraph">StorageGRID에서 검색을 위해 쿼리를 실행하면 StorageGRID에서 S3 검색 속도에 대한 시간이 다음 이미지에 표시됩니다.</block>
  <block id="5e789be14498e5bac09395d944ced093" category="paragraph"><block ref="5e789be14498e5bac09395d944ced093" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5e3fd399eb98a5a8fae1dc144ff614f3" category="section-title">StorageGRID 하드웨어 사용</block>
  <block id="8e8a6c088425467c00be94a9d15d015b" category="paragraph">StorageGRID 인스턴스에는 로드 밸런서 1개와 StorageGRID 컨트롤러 3개가 있습니다. 3개 컨트롤러 모두의 CPU 활용률은 75%에서 100%입니다.</block>
  <block id="5c78f5ad926b76e88a749362fb6e3412" category="paragraph"><block ref="5c78f5ad926b76e88a749362fb6e3412" category="inline-image-macro-rx" type="image"></block></block>
  <block id="140097f96ea2b213b6f37f9d71009a5e" category="section-title">NetApp 스토리지 컨트롤러가 포함된 SmartStore - 고객이 누리는 이점</block>
  <block id="7f18772207b4ab40d0e7574fc68b95b6" category="list-text">* 컴퓨팅과 스토리지를 분리 * Splunk SmartStore는 컴퓨팅과 스토리지를 분리하여 독립적으로 확장할 수 있도록 지원합니다.</block>
  <block id="4e1a3208fe0742415bc087d082943293" category="list-text">* 필요 시 데이터. * SmartStore는 필요에 따라 컴퓨팅에 가까운 데이터를 제공하며 컴퓨팅 및 스토리지의 탄력성과 비용 효율성을 통해 규모에 따라 데이터를 더 오래 보존할 수 있도록 지원합니다.</block>
  <block id="f3295a31a8b7a9b5d76cb1a1e7f67f28" category="list-text">* AWS S3 API 호환 * SmartStore는 AWS S3 API를 사용하여 복원 스토리지와 통신합니다. 이 저장소는 AWS S3 및 StorageGRID와 같은 S3 API 호환 오브젝트 저장소입니다.</block>
  <block id="4fda7aba03882818928ff7bc3a03f0e5" category="list-text">* 스토리지 요구사항 및 비용 절감 * SmartStore를 사용하면 오래된 데이터의 스토리지 요구사항을 줄일 수 있습니다(웜/콜드). NetApp 스토리지는 데이터 보호 기능을 제공하고 장애 및 고가용성을 지원하기 때문에 단일 데이터 복사본만 필요합니다.</block>
  <block id="c27703d92f7f2316dfa63670f02dd6b6" category="list-text">* 하드웨어 장애. * SmartStore 배포에서 노드 장애가 발생해도 데이터에 액세스할 수 없으며 하드웨어 장애 또는 데이터 불균형으로 인해 인덱서를 훨씬 더 빠르게 복구할 수 있습니다.</block>
  <block id="ed20f2e9df3c744293f044d87722ce0f" category="list-text">애플리케이션 및 데이터 인식 캐시:</block>
  <block id="f57d44dedead861d1eef7e912b9cbd86" category="list-text">추가/제거 인덱서와 설정-분해 클러스터를 필요에 따라 사용할 수 있습니다.</block>
  <block id="98613866f09e0e2416018bef4be916d3" category="list-text">스토리지 계층이 더 이상 하드웨어에 종속되지 않습니다.</block>
  <block id="a2a5916477583887c69c752ae6366750" category="paragraph"><block ref="a2a5916477583887c69c752ae6366750" category="inline-link-macro-rx"></block></block>
  <block id="f0fa38f675f888f14af946299f91a36a" category="summary">VMware vSphere는 데이터 센터와 모든 주요 클라우드 공급업체에 가상화 인프라스트럭처를 제공합니다. 이 에코시스템은 위치에 관계없이 가상화된 컴퓨팅을 일관되게 유지하는 재해 복구 시나리오에 이상적입니다. 이 솔루션은 데이터 센터 위치와 AWS의 VMware 클라우드 모두에서 VMware 가상화 컴퓨팅 리소스를 사용합니다.</block>
  <block id="c0b7ac0f313be4f2bef55fc6cf3a1947" category="paragraph">이 솔루션은 VMware vSphere v7.0U3을 실행하는 HPE ProLiant DL360 Gen 10 서버를 사용합니다. 우리는 6개의 컴퓨팅 인스턴스를 구축하여 SQL Server 및 Oracle 서버에 적절한 리소스를 제공했습니다.</block>
  <block id="ff1600196b624f9503bddaca0ce10f5d" category="paragraph">SQL Server 2019를 실행하는 10개의 Windows Server 2019 VM을 다양한 데이터베이스 크기로, Oracle 19c를 실행하는 10개의 Oracle Linux 8.5 VM을 다시 구축했습니다.</block>
  <block id="20f748e1f003c63ad3c63122e1629424" category="paragraph">VMware Cloud on AWS에 SDDC를 구축하고, 두 개의 호스트를 사용하여 운영 사이트에서 복구된 가상 머신을 실행할 수 있는 적절한 리소스를 제공했습니다.</block>
  <block id="a84e981cfea0f9fca307649d4e7bd364" category="paragraph"><block ref="a84e981cfea0f9fca307649d4e7bd364" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6f10db05e58b527be630ad143ec566a5" category="summary">이 문서에 제공된 사용 사례는 NetApp과 VMware의 통합을 강조하는 검증된 재해 복구 기술에 초점을 맞춥니다. NetApp ONTAP 스토리지 시스템은 검증된 데이터 미러링 기술을 제공하므로 조직이 주요 클라우드 공급자와 함께 상주하면서 사내 및 ONTAP 기술을 아우르는 재해 복구 솔루션을 설계할 수 있습니다.</block>
  <block id="86082b0bfc7279f0a1feebe1de23f618" category="paragraph">AWS 기반 ONTAP용 FSX는 SnapCenter 및 SyncMirror와 원활하게 통합되어 애플리케이션 데이터를 클라우드로 복제할 수 있는 솔루션 중 하나입니다. Veeam 백업 및 복제는 NetApp ONTAP 스토리지 시스템과 긴밀하게 통합되며 vSphere 기본 스토리지에 대한 페일오버를 제공할 수 있는 또 다른 잘 알려진 기술입니다.</block>
  <block id="81127e42ddbedbb1cad03bf70d694aa9" category="paragraph">이 솔루션은 SQL Server 및 Oracle 애플리케이션 데이터를 호스팅하는 ONTAP 시스템의 게스트 연결 스토리지를 사용하는 재해 복구 솔루션을 제공합니다. SnapCenter with SnapMirror를 사용하면 ONTAP 시스템에서 애플리케이션 볼륨을 보호하고 클라우드에 있는 FSx 또는 CVO로 복제할 수 있는 관리가 쉬운 솔루션을 제공할 수 있습니다. SnapCenter는 모든 애플리케이션 데이터를 AWS의 VMware 클라우드로 페일오버하는 DR 지원 솔루션입니다.</block>
  <block id="66e5d5ad5173b295e6b59ee5152216d0" category="list-text">솔루션 설명서 링크</block>
  <block id="4f6300de9742001d9f7a797da5d53a27" category="paragraph"><block ref="4f6300de9742001d9f7a797da5d53a27" category="inline-link-rx"></block></block>
  <block id="6590e8ec3c5ce0748f55250c70ec048c" category="paragraph"><block ref="6590e8ec3c5ce0748f55250c70ec048c" category="inline-link-rx"></block></block>
  <block id="314695da56c7e601cdf6cfc3227858d9" category="paragraph">이 솔루션에 설명된 페일오버 프로세스가 성공적으로 완료되면 SnapCenter 및 Veeam이 AWS에서 백업 기능을 재개합니다. 이제 ONTAP용 FSx는 원래 사내 데이터 센터와 SnapMirror 관계가 없는 기본 스토리지로 지정됩니다. 정상적인 기능을 사내에서 다시 시작한 후 이 설명서에 나와 있는 것과 동일한 프로세스를 사용하여 데이터를 사내 ONTAP 스토리지 시스템에 다시 미러링할 수 있습니다.</block>
  <block id="44ee07074aaf6f8c932889c7158c9906" category="paragraph">또한 이 설명서에 나와 있는 것처럼 SnapCenter를 구성하여 ONTAP용 FSx에서 온프레미스에 있는 ONTAP 스토리지 시스템으로 애플리케이션 데이터 볼륨을 미러링할 수 있습니다. 마찬가지로, Veeam을 구성하여 스케일아웃 백업 저장소를 사용하여 Amazon S3에 백업 복사본을 복제함으로써 사내 데이터 센터에 상주하는 Veeam 백업 서버에 액세스할 수 있습니다.</block>
  <block id="fd41e9ec1db4527e12ae403974c6c63c" category="paragraph">페일백은 이 문서의 범위를 벗어나지만 장애 복구는 여기에 설명된 세부 프로세스와 거의 차이가 없습니다.</block>
  <block id="cd39f47230bb959e72acb3eb9e5be469" category="paragraph">이 솔루션에는 NetApp, VMware, AWS(Amazon Web Services), Veeam의 혁신적인 기술이 포함되어 있습니다.</block>
  <block id="ded9cd19cde727f824d72e3ad8ef7662" category="section-title">VMware 클라우드 기반</block>
  <block id="66c9de10f8f96cbfebae805c8a5d0c23" category="paragraph">VMware Cloud Foundation 플랫폼은 관리자가 이기종 환경에서 논리적 인프라를 프로비저닝할 수 있도록 여러 제품 오퍼링을 통합합니다. 이러한 인프라(도메인)는 프라이빗 클라우드와 퍼블릭 클라우드 전반에서 일관된 운영을 제공합니다. Cloud Foundation 소프트웨어와 함께 제공되는 BOM은 사전 검증된 구성 요소와 검증된 구성 요소를 식별하여 고객의 위험을 줄이고 구축을 용이하게 합니다.</block>
  <block id="6fa493c0540d656a06e5bc7de182aa5d" category="paragraph">Cloud Foundation BOM의 구성 요소는 다음과 같습니다.</block>
  <block id="ea712de8051099e742f7b2832804bbe4" category="list-text">클라우드 빌더</block>
  <block id="719175eb8771501a012c6d964c29be69" category="list-text">SDDC 관리자</block>
  <block id="beb9456af324db48fa76084e755d8d0b" category="list-text">VMware vCenter Server 어플라이언스</block>
  <block id="f7eea647714641318ee86fedbbed4691" category="list-text">VMware ESXi</block>
  <block id="4ef3d5ade4e00a1767e0cb9da8f6a895" category="list-text">VMware NSX</block>
  <block id="8b1198108d735d15d15ede582012a434" category="list-text">자동화 표준화</block>
  <block id="ea7e7011cc6c20fceefe3f63a6f66b73" category="list-text">Suite Lifecycle Manager vRealize</block>
  <block id="7b0dffec85c977f50577ae9e44323ccc" category="list-text">로그 통찰력 vRealize</block>
  <block id="9170490ac213e0fff83de34c7e91bcae" category="inline-link">VMware Cloud Foundation 설명서</block>
  <block id="d48b3b75cdd9d69e243c551b712f75e8" category="paragraph">VMware Cloud Foundation에 대한 자세한 내용은 을 참조하십시오<block ref="c470e518572535c6a48639b6f7d6e5a7" category="inline-link-rx"></block>.</block>
  <block id="776e392281968fc227c904b7efb2c82d" category="paragraph">VMware vSphere는 물리적 리소스를 고객의 워크로드 및 애플리케이션 요구 사항을 충족하는 데 사용할 수 있는 컴퓨팅, 네트워크 및 스토리지 풀로 전환하는 가상화 플랫폼입니다. VMware vSphere의 주요 구성 요소는 다음과 같습니다.</block>
  <block id="ef424b79c70de97da1b97dc4f12fadee" category="list-text">* ESXi. * 이 VMware 하이퍼바이저는 컴퓨팅 프로세서, 메모리, 네트워크 및 기타 리소스를 추상화하여 가상 머신 및 컨테이너 워크로드에 사용할 수 있도록 합니다.</block>
  <block id="b061e8a5ed8a3a3c319736ff70d51a55" category="list-text">* vCenter. * VMware vCenter는 가상 인프라의 일부로 컴퓨팅 리소스, 네트워킹 및 스토리지와 상호 작용할 수 있는 중앙 관리 환경을 제공합니다.</block>
  <block id="d42d5a3f8818d925febb1ccce5b5ea10" category="paragraph">고객은 NetApp ONTAP와 함께 강력한 제품 통합, 강력한 지원, 강력한 기능 및 스토리지 효율성을 제공하여 강력한 하이브리드 멀티 클라우드를 구축함으로써 vSphere 환경의 잠재력을 완벽하게 실현할 수 있습니다.</block>
  <block id="841d75538dc45858ed53ac16358cc7ad" category="paragraph">VMware vSphere에 대한 자세한 내용은 을 참조하십시오<block ref="e516b39e5a9a3597e0dc419e086e5395" category="inline-link-rx"></block>.</block>
  <block id="95d57daea7acbc2a7bbae6ded68ee952" category="paragraph">VMware와 함께 제공되는 NetApp 솔루션에 대한 자세한 내용은 다음 웹 사이트를 참조하십시오<block ref="3137e9e57f0cd434b880b626db7b2f62" category="inline-link-rx"></block>.</block>
  <block id="3c7164d9420b263a215271d6db617f2b" category="paragraph">일반적으로 네트워크 하이퍼바이저라고 하는 VMware NSX는 소프트웨어 정의 모델을 사용하여 가상화된 워크로드를 연결합니다. VMware NSX는 온프레미스 및 AWS 기반의 VMware Cloud에서 어디에나 존재하며, 이 곳에서 고객 애플리케이션 및 워크로드를 위한 네트워크 가상화 및 보안을 강화합니다.</block>
  <block id="0b044c7db1e40b4d475fb5b8e225f65e" category="paragraph">VMware NSX에 대한 자세한 내용은 를 참조하십시오<block ref="24474a71eda89537e8233714a7d94cc5" category="inline-link-rx"></block>.</block>
  <block id="1299e00bdf464c0bee14fc2f6aab0f37" category="paragraph">NetApp ONTAP 소프트웨어는 약 20년 동안 VMware vSphere 환경을 위한 최고의 스토리지 솔루션으로, 혁신적인 기능을 지속적으로 추가하여 관리를 단순화하는 동시에 비용을 절감했습니다. ONTAP와 vSphere를 함께 사용하면 호스트 하드웨어 및 VMware 소프트웨어 비용을 절감할 수 있습니다. 또한 기본 스토리지 효율성을 활용하면서도 일관된 고성능을 통해 저렴한 비용으로 데이터를 보호할 수 있습니다.</block>
  <block id="00f8f930135e2662dd01e1e4fc65ec48" category="paragraph">NetApp ONTAP에 대한 자세한 내용은 다음 웹 사이트를 참조하십시오<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>.</block>
  <block id="cc1cc96c6bd7a597d867c658bca3b7d2" category="section-title">VMware용 NetApp ONTAP 툴</block>
  <block id="f19b4defe5bd521861bd47f062cab40e" category="paragraph">VMware용 ONTAP 툴은 여러 플러그인을 NetApp 스토리지 시스템을 사용하는 VMware 환경에서 가상 머신의 라이프사이클을 완벽하게 관리하는 단일 가상 어플라이언스에 결합했습니다. VMware용 ONTAP 툴은 다음과 같습니다.</block>
  <block id="dd167aeb5a59f14930ce90d7b32a1310" category="list-text">* VSC(가상 스토리지 콘솔) * 는 NetApp 스토리지를 사용하여 VM 및 데이터 저장소에 대한 포괄적인 관리 작업을 수행합니다.</block>
  <block id="caba40f1f4e68f7405c7405bbdf4067a" category="list-text">* ONTAP용 VASA Provider. * VMware 가상 볼륨(VVol) 및 NetApp 스토리지를 통해 SPBM(스토리지 정책 기반 관리)을 지원합니다.</block>
  <block id="52d97a7fde4d2984a3335c87380d5ab4" category="list-text">* SRA(Storage Replication Adapter) *. VMware SRM(Site Recovery Manager)과 함께 사용할 경우 장애가 발생할 경우 vCenter 데이터 저장소와 가상 머신을 복구합니다.</block>
  <block id="829e52698f21d046badfc12c5846a723" category="paragraph">VMware용 ONTAP 툴을 사용하면 외부 스토리지를 관리할 뿐만 아니라 VVOL 및 VMware 사이트 복구 관리자도 통합할 수 있습니다. 따라서 vCenter 환경에서 NetApp 스토리지를 훨씬 쉽게 구축하고 운영할 수 있습니다.</block>
  <block id="88d6ca70545898ecc8709b701555225b" category="paragraph">VMware용 NetApp ONTAP 툴에 대한 자세한 내용은 다음 사이트를 참조하십시오<block ref="c1c4ef8e79ad3b0cab24049eb01885be" category="inline-link-rx"></block>.</block>
  <block id="805c9517e95d3e9efc4b46738ab825fc" category="section-title">NetApp SnapCenter를 참조하십시오</block>
  <block id="de29da4940709c9f9b03e3d597dcb7cd" category="paragraph">NetApp SnapCenter 소프트웨어는 애플리케이션, 데이터베이스 및 파일 시스템 전반에서 데이터 보호를 안전하게 조율하고 관리하는 사용하기 쉬운 엔터프라이즈 플랫폼입니다. SnapCenter는 스토리지 시스템의 활동 감독 및 규제 범주에는 영향을 받지 않으면서 이러한 작업을 애플리케이션 소유자에게 오프로드하여 백업, 복원 및 클론 라이프사이클 관리를 단순화합니다. SnapCenter는 스토리지 기반 데이터 관리를 활용하여 성능 및 가용성을 높이는 동시에 테스트 및 개발 시간을 단축합니다.</block>
  <block id="a1f54fde77874bbd5be133ca3970d7e8" category="paragraph">VMware vSphere용 SnapCenter 플러그인은 VM(가상 머신), 데이터 저장소 및 VMDK(가상 머신 디스크)에 대해 충돌 시에도 정합성이 보장되고 VM 정합성이 보장되는 백업 및 복원 작업을 지원합니다. 또한 SnapCenter 애플리케이션별 플러그인을 지원하여 가상화된 데이터베이스 및 파일 시스템에 대한 애플리케이션 정합성이 보장되는 백업 및 복구 작업을 보호합니다.</block>
  <block id="f655858b5e82a216de5b6aea071de457" category="paragraph">NetApp SnapCenter에 대한 자세한 내용은 다음 웹 사이트를 참조하십시오<block ref="aa600981aea381f09908ce10e8269417" category="inline-link-rx"></block>.</block>
  <block id="98c2040e71eaa6795dfe7287a8c6ad93" category="section-title">타사 데이터 보호</block>
  <block id="a03670ab805efda6af1029d0cc6ed56e" category="paragraph">Veeam Backup &amp; Replication은 클라우드, 가상 및 물리적 워크로드를 위한 백업, 복구 및 데이터 관리 솔루션입니다. Veeam Backup &amp; Replication은 NetApp Snapshot 기술과의 전문적인 통합으로 vSphere 환경을 더욱 보호합니다.</block>
  <block id="a174e33a347bdf86d254ef6b64ebb844" category="paragraph">Veeam Backup &amp; Replication에 대한 자세한 내용은 을 참조하십시오<block ref="ff5498b1e93a9fbc10c4f9b6c05db801" category="inline-link-rx"></block>.</block>
  <block id="e1d618f208de1e0652f995ea9ef70c8a" category="section-title">AWS ID 및 액세스 관리</block>
  <block id="72e3b385ab9dce0490acd4320d69b190" category="paragraph">AWS 환경에는 컴퓨팅, 스토리지, 데이터베이스, 네트워크, 분석, 데이터 관리 등 및 기타 다양한 기능을 통해 비즈니스 과제를 해결할 수 있습니다. 기업은 이러한 제품, 서비스 및 리소스에 액세스할 수 있는 권한이 있는 사용자를 정의할 수 있어야 합니다. 사용자가 설정을 조작, 변경 또는 추가할 수 있는 조건을 결정하는 것도 마찬가지로 중요합니다.</block>
  <block id="e0371101cd60437f116ae662823d656b" category="paragraph">AWS AIM(Identity and Access Management)은 AWS 서비스 및 제품에 대한 액세스를 관리할 수 있는 안전한 제어 환경을 제공합니다. 적절하게 구성된 사용자, 액세스 키 및 사용 권한을 통해 AWS 및 Amazon FSx에서 VMware Cloud를 구축할 수 있습니다.</block>
  <block id="f97bd254f4560b300dffc1c8320c079a" category="paragraph">AIM에 대한 자세한 내용은 을 참조하십시오<block ref="51dd129a9a709f0af102f91347214719" category="inline-link-rx"></block>.</block>
  <block id="f93a7ad035f2ab23b92d7f904c204a67" category="paragraph">VMware Cloud on AWS는 기본 AWS 서비스에 최적화된 액세스를 통해 VMware의 엔터프라이즈급 SDDC 소프트웨어를 AWS 클라우드에 제공합니다. VMware Cloud Foundation을 기반으로 하는 VMware Cloud on AWS는 VMware의 컴퓨팅, 스토리지 및 네트워크 가상화 제품(VMware vSphere, VMware vSAN 및 VMware NSX)과 유연하고 탄력적인 전용 AWS 인프라에서 실행되도록 최적화된 VMware vCenter Server 관리를 통합합니다.</block>
  <block id="21b9508ecf23f768b8172f58ec935a32" category="paragraph">AWS 기반 VMware Cloud에 대한 자세한 내용은 를 참조하십시오<block ref="2fb3b932a008429024fefba27ce7f6c0" category="inline-link-rx"></block>.</block>
  <block id="4d82a1ec1af02725042c8c785564ee7a" category="section-title">NetApp ONTAP용 Amazon FSx</block>
  <block id="5588d719a2e52cc2437eac404a5afac6" category="paragraph">NetApp ONTAP용 Amazon FSx는 모든 기능을 갖추고 있으며 완벽하게 관리되는 ONTAP 시스템으로, 기본 AWS 서비스로 제공됩니다. NetApp ONTAP을 기반으로 구축된 이 제품은 친숙한 기능을 제공하는 동시에 완전 관리형 클라우드 서비스의 단순성을 제공합니다.</block>
  <block id="4f706209d760c6b9c796b171e747ba84" category="paragraph">ONTAP용 Amazon FSx는 퍼블릭 클라우드 또는 온프레미스의 VMware를 비롯한 다양한 컴퓨팅 유형에 대한 멀티 프로토콜 지원을 제공합니다. 현재 게스트 연결 사용 사례 및 기술 미리 보기의 NFS 데이터 저장소에 사용할 수 있는 Amazon FSx for ONTAP를 사용하면 기업은 사내 환경과 클라우드에서 익숙한 기능을 활용할 수 있습니다.</block>
  <block id="97461b19a572ee6589bfdc8bb87cf344" category="paragraph">NetApp ONTAP용 Amazon FSx에 대한 자세한 내용은 를 참조하십시오<block ref="8010f27a5d53263c1742228bc262a2e3" category="inline-link-rx"></block>.</block>
  <block id="b7dd764025f54c4b3bccf4f05424bf77" category="doc">SQL Server 응용 프로그램 데이터를 복원합니다</block>
  <block id="95f316bb0a092035f960a46cc12705d3" category="paragraph">다음 프로세스에서는 사내 사이트가 작동 불능 상태가 되는 재해가 발생할 경우 AWS의 VMware Cloud Services에서 SQL Server를 복구하는 방법에 대한 지침을 제공합니다.</block>
  <block id="eb7b93b4aadbfaf4b78c0c4bfe125171" category="paragraph">복구 단계를 계속 진행하려면 다음 필수 구성 요소가 완료된 것으로 가정합니다.</block>
  <block id="aca50891060f7ebe7be1192b4a8b78ad" category="list-text">Veeam Full Restore를 사용하여 Windows Server VM을 VMware Cloud SDDC로 복구했습니다.</block>
  <block id="9731e8839876f65368eab4ef1eecdc20" category="inline-link-macro">SnapCenter 백업 및 복원 프로세스 요약</block>
  <block id="fe51b70218e2191f0338d4bcb01eb4a7" category="list-text">보조 SnapCenter 서버가 설정되었고 섹션에 설명된 단계를 사용하여 SnapCenter 데이터베이스 복원 및 구성이 완료되었습니다 <block ref="f1b6dca3014749c436758b70cc0d8f7f" category="inline-link-macro-rx"></block></block>
  <block id="565a76f57020cb4db728d0a24384a0d9" category="section-title">VM: SQL Server VM에 대한 사후 복원 구성</block>
  <block id="eface2367b3de31eee3102f62de9295d" category="paragraph">VM 복원이 완료된 후 SnapCenter 내에서 호스트 VM을 재검색할 수 있도록 네트워킹 및 기타 항목을 구성해야 합니다.</block>
  <block id="0a64ec0b8b14816ed47650a0096fd3b3" category="list-text">관리 및 iSCSI 또는 NFS에 새 IP 주소를 할당합니다.</block>
  <block id="8ceacb8e6c12d270f190550e317ed5be" category="list-text">Windows 도메인에 호스트를 연결합니다.</block>
  <block id="612dbb7fb61a87afcf471d797448e487" category="list-text">DNS 또는 SnapCenter 서버의 호스트 파일에 호스트 이름을 추가합니다.</block>
  <block id="21b91bc158a5a6579966133ece84f927" category="admonition">SnapCenter 플러그인이 현재 도메인과 다른 도메인 자격 증명을 사용하여 배포된 경우 SQL Server VM의 Windows용 플러그인 서비스에 대한 로그온 계정을 변경해야 합니다. 로그온 계정을 변경한 후 SnapCenter SMCore, Windows용 플러그인 및 SQL Server 서비스용 플러그인을 다시 시작합니다.</block>
  <block id="0634c3a099feec2a74ff9c0751719ed6" category="admonition">SnapCenter에서 복원된 VM을 자동으로 다시 검색하려면 FQDN이 SnapCenter 온-프레미스에 원래 추가된 VM과 동일해야 합니다.</block>
  <block id="0d4bede73841f93a92c80d25b0194d1e" category="section-title">SQL Server 복구를 위한 FSx 스토리지를 구성합니다</block>
  <block id="1a87030fb5d5a31f7bcfdfa68ade9691" category="paragraph">SQL Server VM의 재해 복구 복원 프로세스를 수행하려면 FSx 클러스터에서 기존 SnapMirror 관계를 중단하고 볼륨에 대한 액세스를 부여해야 합니다. 이렇게 하려면 다음 단계를 완료하십시오.</block>
  <block id="4c9e09e4807ffb0a4456b29e6f9a4281" category="list-text">SQL Server 데이터베이스 및 로그 볼륨에 대한 기존 SnapMirror 관계를 해제하려면 FSx CLI에서 다음 명령을 실행합니다.</block>
  <block id="3d20282913974593577c784c3192e510" category="list-text">SQL Server Windows VM의 iSCSI IQN이 포함된 이니시에이터 그룹을 생성하여 LUN에 대한 액세스 권한 부여:</block>
  <block id="d287a88d877191e5695e6e46cde801a3" category="list-text">마지막으로 LUN을 방금 생성한 이니시에이터 그룹에 매핑합니다.</block>
  <block id="e47557c42d0af2df20a15a19f84795ee" category="list-text">경로 이름을 찾으려면 'lun show' 명령을 실행합니다.</block>
  <block id="c38f08ac05515c2b594fc836b22181e0" category="section-title">iSCSI 액세스를 위해 Windows VM을 설정하고 파일 시스템을 검색합니다</block>
  <block id="39eb9c3b6c8eb2106dcb06edfdbb6f65" category="list-text">SQL Server VM에서 iSCSI 네트워크 어댑터를 설정하여 FSx 인스턴스의 iSCSI 타겟 인터페이스에 대한 연결로 설정된 VMware 포트 그룹에서 통신합니다.</block>
  <block id="cf8c6b6b8c54ec784d05b5f092751a4d" category="list-text">iSCSI 초기자 등록 정보 유틸리티를 열고 검색, 즐겨찾기 대상 및 대상 탭에서 이전 연결 설정을 지웁니다.</block>
  <block id="1a2e1a79fa495e5f511838af9609be4f" category="list-text">FSx 인스턴스/클러스터에서 iSCSI 논리 인터페이스에 액세스하기 위한 IP 주소를 찾습니다. AWS 콘솔의 Amazon FSx &gt; ONTAP &gt; Storage Virtual Machines에서 찾을 수 있습니다.</block>
  <block id="d9401c99c6ddc6dbcd6070c357088cf5" category="paragraph"><block ref="d9401c99c6ddc6dbcd6070c357088cf5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba5037ceee608981a7684c3277ceca73" category="list-text">검색 탭에서 포털 검색 을 클릭하고 FSx iSCSI 대상의 IP 주소를 입력합니다.</block>
  <block id="49ba75dd04ab3da15488d6e271466575" category="paragraph"><block ref="49ba75dd04ab3da15488d6e271466575" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cd6bd08689af39f12a04ce95acbaa7df" category="paragraph"><block ref="cd6bd08689af39f12a04ce95acbaa7df" category="inline-image-macro-rx" type="image"></block></block>
  <block id="193f314b02dfe15e71a9ec5d16f5ce73" category="list-text">대상 탭에서 연결을 클릭하고 구성에 적합한 경우 다중 경로 사용을 선택한 다음 확인을 클릭하여 대상에 연결합니다.</block>
  <block id="8625607d58104640aa3cc3a687356560" category="paragraph"><block ref="8625607d58104640aa3cc3a687356560" category="inline-image-macro-rx" type="image"></block></block>
  <block id="907488914aeab882127886e6028b0ea0" category="list-text">컴퓨터 관리 유틸리티를 열고 디스크를 온라인 상태로 전환합니다. 이전에 사용했던 것과 동일한 드라이브 문자가 유지되는지 확인합니다.</block>
  <block id="885afbf2d17d52ec64abfd147535488e" category="paragraph"><block ref="885afbf2d17d52ec64abfd147535488e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4bc8ec032118740c31355c3345d62bf4" category="section-title">SQL Server 데이터베이스를 연결합니다</block>
  <block id="7f423619ca14c77f6b9db6f7bda8de76" category="list-text">SQL Server VM에서 Microsoft SQL Server Management Studio를 열고 연결 을 선택하여 데이터베이스에 연결하는 프로세스를 시작합니다.</block>
  <block id="fd43b9851dc24c4889086cdc9afd2a3a" category="paragraph"><block ref="fd43b9851dc24c4889086cdc9afd2a3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8bff2998bccc1ca5a6d707233af02c9" category="list-text">추가 를 클릭하고 SQL Server 기본 데이터베이스 파일이 들어 있는 폴더로 이동한 다음 해당 파일을 선택하고 확인 을 클릭합니다.</block>
  <block id="f700bbcedcee0092e600d8527c84b19f" category="paragraph"><block ref="f700bbcedcee0092e600d8527c84b19f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a827dff2feb3c6226fcac7b4b80a3cc8" category="list-text">트랜잭션 로그가 별도의 드라이브에 있는 경우 트랜잭션 로그가 포함된 폴더를 선택합니다.</block>
  <block id="f42947d249de7e97db085085f542e3c4" category="list-text">완료되면 확인 을 클릭하여 데이터베이스를 연결합니다.</block>
  <block id="74242a349c592d71e13c317715f21c6f" category="paragraph"><block ref="74242a349c592d71e13c317715f21c6f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3f8fd7fd0d8b19f4ee350fa3bfaca1ca" category="section-title">SQL Server 플러그인과 SnapCenter 통신을 확인합니다</block>
  <block id="b6c6326ece2d2042cc822762ac90932a" category="paragraph">SnapCenter 데이터베이스가 이전 상태로 복원되면 SQL Server 호스트가 자동으로 다시 검색됩니다. 이 작업이 올바르게 작동하려면 다음 필수 조건을 염두에 두십시오.</block>
  <block id="db44d05563a2083dddeaf5a8c08c36b8" category="list-text">SnapCenter를 재해 복구 모드로 전환해야 합니다. 이 작업은 Swagger API 또는 재해 복구의 글로벌 설정을 통해 수행할 수 있습니다.</block>
  <block id="f77564f6296c2b86366fa8c55cde3b3d" category="list-text">SQL Server의 FQDN은 온-프레미스 데이터 센터에서 실행 중인 인스턴스와 동일해야 합니다.</block>
  <block id="7effb9a6b0bfb89f35e1496a0b8ee21c" category="list-text">원래 SnapMirror 관계가 끊어야 합니다.</block>
  <block id="25c898cf2666acc247fd6eda6262658f" category="list-text">데이터베이스가 포함된 LUN은 SQL Server 인스턴스 및 연결된 데이터베이스에 마운트되어야 합니다.</block>
  <block id="9c7568e40b946736fc8b8e0b79f35603" category="paragraph">SnapCenter가 재해 복구 모드에 있는지 확인하려면 SnapCenter 웹 클라이언트 내에서 설정 으로 이동합니다. 글로벌 설정 탭으로 이동한 다음 재해 복구 를 클릭합니다. 재해 복구 활성화 확인란이 활성화되어 있는지 확인합니다.</block>
  <block id="fa26a16fa4868aed3c0c634a2d7a27a5" category="paragraph"><block ref="fa26a16fa4868aed3c0c634a2d7a27a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9ba3ddc84b2f59fd2a102309365db81a" category="doc">Veeam 전체 복원으로 애플리케이션 VM을 복원합니다</block>
  <block id="36dc3b29e336105b87846d5917f36466" category="section-title">백업 리포지토리를 생성하고 S3에서 백업을 가져옵니다</block>
  <block id="bfa510d8cc1cb8902740f538c9871cd5" category="paragraph">2차 Veeam 서버에서 S3 스토리지의 백업을 가져오고 SQL Server 및 Oracle VM을 VMware Cloud 클러스터로 복원합니다.</block>
  <block id="e2f3927605d5be5f9e2924c7578d06ab" category="paragraph">사내 스케일아웃 백업 리포지토리에 속하는 S3 오브젝트에서 백업을 가져오려면 다음 단계를 완료합니다.</block>
  <block id="04e06ef7f33197a158ddc19d53c0d1a5" category="list-text">백업 리포지토리 로 이동하고 상단 메뉴에서 리포지토리 추가 를 클릭하여 백업 리포지토리 추가 마법사를 시작합니다. 마법사의 첫 번째 페이지에서 백업 저장소 유형으로 오브젝트 스토리지 를 선택합니다.</block>
  <block id="6206d8a7c31f00a44ec41ebae87e8b6b" category="paragraph"><block ref="6206d8a7c31f00a44ec41ebae87e8b6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4fcfafe3d4baedadc9910b99baf527a" category="list-text">오브젝트 스토리지 유형으로 Amazon S3를 선택합니다.</block>
  <block id="293aed632d96ade5bfef832bcdc2cd1e" category="paragraph"><block ref="293aed632d96ade5bfef832bcdc2cd1e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="698ebee929c01fad4c318876313789ab" category="list-text">Amazon Cloud Storage Services 목록에서 Amazon S3를 선택합니다.</block>
  <block id="12cfad41ab613d7744d12d07d4a556d4" category="paragraph"><block ref="12cfad41ab613d7744d12d07d4a556d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2639f2cf7409eb24ed59c46794f26c33" category="list-text">드롭다운 목록에서 미리 입력한 자격 증명을 선택하거나 클라우드 스토리지 리소스에 액세스하기 위한 새 자격 증명을 추가합니다. 다음을 클릭하여 계속합니다.</block>
  <block id="ca271cf67d4c973e828e31689285727f" category="paragraph"><block ref="ca271cf67d4c973e828e31689285727f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d158a2a4f2b2c9b52c009bfbd87668a" category="list-text">버킷 페이지에서 데이터 센터, 버킷, 폴더 및 원하는 옵션을 입력합니다. 적용 을 클릭합니다.</block>
  <block id="cf2158b0a3f58d891bcbc6031fde92d4" category="paragraph"><block ref="cf2158b0a3f58d891bcbc6031fde92d4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5adae514074dc7c746819968e035e2a0" category="list-text">마지막으로 마침 을 선택하여 프로세스를 완료하고 리포지토리를 추가합니다.</block>
  <block id="076951b7756435f95654310ef960f866" category="section-title">S3 오브젝트 스토리지에서 백업을 가져옵니다</block>
  <block id="397f99a04387aed7bca366a20084083f" category="paragraph">이전 섹션에 추가된 S3 리포지토리에서 백업을 가져오려면 다음 단계를 완료합니다.</block>
  <block id="6add4097706ff1ee04793b80b99c3980" category="list-text">S3 백업 리포지토리에서 백업 가져오기 를 선택하여 백업 가져오기 마법사를 시작합니다.</block>
  <block id="d2e0dedfd0a67b45116f5c02f41dfad6" category="paragraph"><block ref="d2e0dedfd0a67b45116f5c02f41dfad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f08dd57757030d81cfcdd38f9c443e05" category="list-text">가져오기에 대한 데이터베이스 레코드가 생성된 후 요약 화면에서 다음 을 선택한 다음 마침 을 선택하여 가져오기 프로세스를 시작합니다.</block>
  <block id="dee3665bb9cd000955be1a118818554f" category="paragraph"><block ref="dee3665bb9cd000955be1a118818554f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4afd5477c1ce1473a255dee8ce524184" category="list-text">가져오기가 완료되면 VM을 VMware Cloud 클러스터로 복구할 수 있습니다.</block>
  <block id="8f2cd7b75623b2421c1eaadd379ca431" category="paragraph"><block ref="8f2cd7b75623b2421c1eaadd379ca431" category="inline-image-macro-rx" type="image"></block></block>
  <block id="73fee194f5e4e8ac33d750244fe7ebd5" category="section-title">Veeam을 사용하여 애플리케이션 VM을 VMware Cloud로 완벽하게 복구합니다</block>
  <block id="ec223385ec31537dfd3adc4f3f97735d" category="paragraph">SQL 및 Oracle 가상 머신을 AWS 워크로드 도메인/클러스터의 VMware Cloud로 복구하려면 다음 단계를 수행하십시오.</block>
  <block id="9085bbecf522e8f0cf0f7d5480dd7cd9" category="list-text">Veeam Home 페이지에서 가져온 백업이 포함된 객체 스토리지를 선택하고 복구할 VM을 선택한 다음 마우스 오른쪽 버튼을 클릭하고 Restore Entire VM을 선택합니다.</block>
  <block id="5320e29249c22b00240fc3df301d60a6" category="paragraph"><block ref="5320e29249c22b00240fc3df301d60a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8d53e507da99665f0cd76090f0c8b932" category="list-text">전체 VM 복원 마법사의 첫 페이지에서 원하는 경우 백업할 VM을 수정하고 다음을 선택합니다.</block>
  <block id="118ea730c6c794b12c6da0062216053b" category="paragraph"><block ref="118ea730c6c794b12c6da0062216053b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="93e4b62efeb3d091b37047e066e45da4" category="list-text">복원 모드 페이지에서 새 위치로 복원 또는 다른 설정으로 복원 을 선택합니다.</block>
  <block id="53ddd9505ead460715da91ab5ae479ae" category="paragraph"><block ref="53ddd9505ead460715da91ab5ae479ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="faca70e3cfbddf72933acf5dcbedf4ff" category="list-text">호스트 페이지에서 VM을 복구할 타겟 ESXi 호스트 또는 클러스터를 선택합니다.</block>
  <block id="5c468616bb48a8d3a72e2b3f20932126" category="paragraph"><block ref="5c468616bb48a8d3a72e2b3f20932126" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1ee5d8dddaf8720bc49f23dc8e19f11b" category="list-text">Datastores 페이지에서 구성 파일과 하드 디스크 모두에 대한 타겟 데이터 저장소 위치를 선택합니다.</block>
  <block id="ae5ebb3a87f25b2bf09c963a4029e53a" category="paragraph"><block ref="ae5ebb3a87f25b2bf09c963a4029e53a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48d9c25678124f335015d969c2c7645f" category="list-text">네트워크 페이지에서 VM의 원래 네트워크를 새 대상 위치의 네트워크에 매핑합니다.</block>
  <block id="b33233fb74ffe76bde21729b21fde02d" category="paragraph"><block ref="b33233fb74ffe76bde21729b21fde02d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b3d7fc3c9f85e5663d3361a9e999487c" category="paragraph"><block ref="b3d7fc3c9f85e5663d3361a9e999487c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="511bf18240f9f57b5658a22974a640f0" category="list-text">복원된 VM에서 맬웨어를 검사할지 여부를 선택하고 요약 페이지를 검토한 다음 마침 을 클릭하여 복원을 시작합니다.</block>
  <block id="0e966aefc6e57da3e61d08eb83f8f9b7" category="summary">SnapCenter는 장기간 아카이브 및 보존을 위해 운영 스토리지 시스템(운영 &gt; 미러) 및 보조 스토리지 시스템(운영 &gt; 소산) 내의 SnapMirror 관계를 업데이트할 수 있습니다. 이렇게 하려면 SnapMirror를 사용하여 대상 볼륨과 소스 볼륨 간의 데이터 복제 관계를 설정하고 초기화해야 합니다.</block>
  <block id="860d1fc24372044f6c88f15cea6b9155" category="doc">SnapMirror 관계 및 보존 일정을 구성합니다</block>
  <block id="1888797bfba812a31bad2548f183ffe6" category="paragraph">소스 및 타겟 ONTAP 시스템은 Amazon VPC 피어링, 전송 게이트웨이, AWS Direct Connect 또는 AWS VPN을 사용하여 피어링된 네트워크에 있어야 합니다.</block>
  <block id="aa318628cbf2869d724b704d547dc8f4" category="paragraph">온프레미스 ONTAP 시스템과 FSx ONTAP 간에 SnapMirror 관계를 설정하려면 다음 단계가 필요합니다.</block>
  <block id="fbfcc1aa520560c558b69fb448e3e601" category="inline-link">ONTAP용 FSX – ONTAP 사용 설명서</block>
  <block id="7ffc7a254a972aeb4df657be8d41c5a2" category="paragraph">을 참조하십시오<block ref="67cdb2cad717abb12c965d934ae13809" category="inline-link-rx"></block> FSx를 사용하여 SnapMirror 관계를 만드는 방법에 대한 자세한 내용은 를 참조하십시오.</block>
  <block id="cc9e567b33c3e82ac1b18f4780ca5f42" category="section-title">소스 및 대상 클러스터간 논리 인터페이스를 기록합니다</block>
  <block id="44c719fef7654c0f1aecbd77f14b9ab7" category="paragraph">사내에 상주하는 소스 ONTAP 시스템의 경우 System Manager 또는 CLI에서 클러스터 간 LIF 정보를 검색할 수 있습니다.</block>
  <block id="d3983f090ac28583ca4499e720c4cc25" category="list-text">ONTAP System Manager에서 네트워크 개요 페이지로 이동하여 FSx가 설치된 AWS VPC와 통신하도록 구성된 Type:Intercluster의 IP 주소를 검색합니다.</block>
  <block id="de45ac288e78c12d34318717ae7cacd8" category="paragraph"><block ref="de45ac288e78c12d34318717ae7cacd8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="94cf5d813faccf347c0faaab27941922" category="list-text">FSx의 Intercluster IP 주소를 검색하려면 CLI에 로그인하여 다음 명령을 실행합니다.</block>
  <block id="244c638485f1bcb26a0e966bd289e4a9" category="paragraph"><block ref="244c638485f1bcb26a0e966bd289e4a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ce2dabb10080d128fabb2edc80a417a" category="section-title">ONTAP와 FSx 간에 클러스터 피어링을 설정합니다</block>
  <block id="84c8209b0c6f3e5e18c66f9f45cf5358" category="paragraph">ONTAP 클러스터 간에 클러스터 피어링을 설정하려면 시작 ONTAP 클러스터에 입력된 고유한 암호가 다른 피어 클러스터에서 확인되어야 합니다.</block>
  <block id="085f57325580b1a203343baf39c910d1" category="list-text">'cluster peer create' 명령을 사용하여 대상 FSx 클러스터에서 피어링을 설정합니다. 메시지가 표시되면 소스 클러스터에서 나중에 사용되는 고유한 암호를 입력하여 생성 프로세스를 마칩니다.</block>
  <block id="475947ec353590c018e5b0d813538a84" category="list-text">소스 클러스터에서 ONTAP System Manager 또는 CLI를 사용하여 클러스터 피어 관계를 설정할 수 있습니다. ONTAP 시스템 관리자에서 보호 &gt; 개요 로 이동하고 피어 클러스터 를 선택합니다.</block>
  <block id="692ee36299ec8b049d7462a75dd1463a" category="paragraph"><block ref="692ee36299ec8b049d7462a75dd1463a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1aa5f33eeccc2dab1c1b6aba564ec238" category="list-text">피어 클러스터 대화 상자에서 필요한 정보를 입력합니다.</block>
  <block id="28b3f47a49c9a2fb506879e23a7b1723" category="list-text">대상 FSx 클러스터에서 피어 클러스터 관계를 설정하는 데 사용된 암호를 입력합니다.</block>
  <block id="157bacc8ed48f5dc430560300ef9f5a5" category="list-text">암호화된 관계를 설정하려면 Yes를 선택합니다.</block>
  <block id="70c324b6369e6cb6f4a8df99ac8b4b7e" category="list-text">대상 FSx 클러스터의 인터클러스터 LIF IP 주소를 입력합니다.</block>
  <block id="c9af913b694e4e4dcce39b7e3a2eabd2" category="list-text">클러스터 피어링 시작 을 클릭하여 프로세스를 마칩니다.</block>
  <block id="409a2deb1ca3f5fe6ad3f90977529965" category="paragraph"><block ref="409a2deb1ca3f5fe6ad3f90977529965" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2b39da3667dd0f4cab32a9027eeadf60" category="list-text">다음 명령을 사용하여 FSx 클러스터에서 클러스터 피어 관계의 상태를 확인합니다.</block>
  <block id="25ca322582650fd7d3732bea77176905" category="paragraph"><block ref="25ca322582650fd7d3732bea77176905" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdf4cefe90737a4248cd083c1a1d2e36" category="section-title">SVM 피어링 관계를 설정합니다</block>
  <block id="4f194687804b9dff8219b58d47dc2a69" category="paragraph">다음 단계는 SnapMirror 관계에 있는 볼륨을 포함하는 소스 스토리지 가상 시스템과 타겟 스토리지 가상 시스템 간에 SVM 관계를 설정하는 것입니다.</block>
  <block id="9bd0b716a7c6f7821d01f58d3576978d" category="list-text">소스 FSx 클러스터에서 CLI에서 다음 명령을 사용하여 SVM 피어 관계를 생성합니다.</block>
  <block id="1a82405201cf3be5b0f3f96ffb551406" category="list-text">소스 ONTAP 클러스터에서 ONTAP System Manager 또는 CLI와 피어링 관계를 수락합니다.</block>
  <block id="dd0f7f7da0626cbd138836fd072f65de" category="list-text">ONTAP 시스템 관리자에서 보호 &gt; 개요 로 이동하고 스토리지 VM 피어 아래에서 피어 스토리지 VM 을 선택합니다.</block>
  <block id="486b508476b1f8dff9a5314ac26e36e9" category="paragraph"><block ref="486b508476b1f8dff9a5314ac26e36e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8b0c3d15e3f1c8ecebfa725f753f98e7" category="list-text">피어 스토리지 VM 대화 상자에서 필수 필드를 입력합니다.</block>
  <block id="b980118a5ade1402e409e2354f286c60" category="list-text">소스 스토리지 VM입니다</block>
  <block id="2cb119a467d09216231bdf2ff83bfb5f" category="list-text">타겟 클러스터</block>
  <block id="1d1fa3ffdce0bd1d4a0faf3d15fb94f6" category="list-text">대상 스토리지 VM입니다</block>
  <block id="22a926c9631a59bce535d179c6f1f5ae" category="paragraph"><block ref="22a926c9631a59bce535d179c6f1f5ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52fee5b72c266bcf84963c260c8cf2ed" category="list-text">피어 스토리지 VM 을 클릭하여 SVM 피어링 프로세스를 완료합니다.</block>
  <block id="332a29af91768111608bcb6bf43107e7" category="section-title">스냅샷 보존 정책을 생성합니다</block>
  <block id="b2659ce2591907c1c9269d82e68d8109" category="paragraph">SnapCenter는 운영 스토리지 시스템에서 스냅샷 복사본으로 존재하는 백업의 보존 일정을 관리합니다. SnapCenter에서 정책을 생성할 때 설정됩니다. SnapCenter는 보조 스토리지 시스템에 보존되는 백업에 대한 보존 정책을 관리하지 않습니다. 이러한 정책은 보조 FSx 클러스터에서 생성되고 소스 볼륨과 SnapMirror 관계에 있는 대상 볼륨에 연결된 SnapMirror 정책을 통해 별도로 관리됩니다.</block>
  <block id="1d64d8f27569c9f8182a6c536add0069" category="paragraph">SnapCenter 정책을 생성할 때 SnapCenter 백업을 수행할 때 생성되는 각 스냅샷의 SnapMirror 레이블에 추가되는 2차 정책 레이블을 지정할 수 있습니다.</block>
  <block id="b3ca63efc1d304947f75061071da604c" category="admonition">보조 스토리지에서 이러한 레이블은 스냅샷 보존을 적용하기 위해 대상 볼륨과 관련된 정책 규칙과 일치합니다.</block>
  <block id="422f63101989fe9b50c840c82bb5fe9f" category="paragraph">다음 예제는 SQL Server 데이터베이스 및 로그 볼륨의 일일 백업에 사용되는 정책의 일부로 생성된 모든 스냅샷에 존재하는 SnapMirror 레이블을 보여줍니다.</block>
  <block id="5f70d8aa597c91ed28f7be347e2fac0a" category="paragraph"><block ref="5f70d8aa597c91ed28f7be347e2fac0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5c9b73d439aa92ef011ebf02237c888" category="inline-link">SnapCenter 설명서</block>
  <block id="2d0828fbc32c49aad5149bd71dd05ddf" category="paragraph">SQL Server 데이터베이스에 대한 SnapCenter 정책을 만드는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>.</block>
  <block id="f508c027fda31d58c4677043e1a3eaa8" category="paragraph">우선 유지할 스냅샷 복사본 수를 결정하는 규칙을 사용하여 SnapMirror 정책을 생성해야 합니다.</block>
  <block id="bb66348f31a358d5d6f969b7ab6ee82c" category="list-text">FSx 클러스터에서 SnapMirror 정책을 생성합니다.</block>
  <block id="e8d5c5ace79f3b8be2db75ba7135e0a8" category="list-text">SnapCenter 정책에 지정된 2차 정책 레이블과 일치하는 SnapMirror 레이블을 사용하여 정책에 규칙을 추가합니다.</block>
  <block id="5a3507b9cf4dd4a569d2ffe314e6b7eb" category="paragraph">다음 스크립트는 정책에 추가할 수 있는 규칙의 예를 제공합니다.</block>
  <block id="762402f82600698541f18b3a2f4ac8f4" category="admonition">각 SnapMirror 레이블과 유지할 스냅샷 수(보존 기간)에 대한 추가 규칙을 생성합니다.</block>
  <block id="2f061612da9689d76bf56673168e2297" category="section-title">대상 볼륨을 생성합니다</block>
  <block id="3c09a07bfb806c844317f3b57d93a884" category="paragraph">소스 볼륨에서 스냅샷 복사본을 받을 FSx에 대상 볼륨을 생성하려면 FSx ONTAP에서 다음 명령을 실행합니다.</block>
  <block id="9a9f4d5cf2f4ccad396091e224e45c7e" category="section-title">소스 볼륨과 타겟 볼륨 간의 SnapMirror 관계를 생성합니다</block>
  <block id="dfceac14afc666c56290006c22ba8a0a" category="paragraph">소스 볼륨과 타겟 볼륨 간에 SnapMirror 관계를 생성하려면 FSx ONTAP에서 다음 명령을 실행합니다.</block>
  <block id="e3a7ebd416df655cee455d58e86e8477" category="section-title">SnapMirror 관계 초기화</block>
  <block id="a457a30bf4ecea53998aa344bee4329a" category="paragraph">SnapMirror 관계를 초기화합니다. 이 프로세스에서는 소스 볼륨에서 생성된 새 스냅샷을 시작하여 타겟 볼륨에 복사합니다.</block>
  <block id="2cd2d537da5641f8e4fc5712872944c4" category="paragraph">볼륨을 생성하려면 FSx ONTAP에서 다음 명령을 실행합니다.</block>
  <block id="dcbabf28828ef9b03cf9856a74eedf64" category="summary">이 솔루션에서 SnapCenter는 SQL Server 및 Oracle 애플리케이션 데이터에 대해 애플리케이션 정합성이 보장되는 스냅샷을 제공합니다. 이 구성은 SnapMirror 기술과 함께 사내 AFF와 FSx ONTAP 클러스터 간에 고속 데이터 복제를 제공합니다. 또한 Veeam Backup &amp; Replication은 가상 머신에 백업 및 복원 기능을 제공합니다.</block>
  <block id="a7b22ebf343cad0f97e90df47a7d7f0c" category="paragraph">이 섹션에서는 백업 및 복원을 위한 SnapCenter, SnapMirror 및 Veeam의 구성에 대해 살펴봅니다.</block>
  <block id="66b3c7123c5d46e3d176f20cb0ede484" category="paragraph">다음 섹션에서는 보조 사이트에서 페일오버를 완료하는 데 필요한 구성 및 단계에 대해 설명합니다.</block>
  <block id="b33c39866fb3627a46e2d343e5fcdb1a" category="list-text">온-프레미스에서 Windows SnapCenter 서버를 배포하고 구성합니다.</block>
  <block id="498fdd311192093265ba745435fc1476" category="doc">Veeam Backup Server를 구축 및 구성합니다</block>
  <block id="48e37aaf43e2a1010e9e267340ce923e" category="inline-link">Veeam Help Center 기술 문서</block>
  <block id="9e67d6bed8c55a98c2cfe02531c07393" category="paragraph">Veeam 백업 및 복제 소프트웨어는 Veeam 스케일 아웃 백업 저장소(SOBR)를 사용하여 애플리케이션 가상 머신을 백업하고 백업 복사본을 Amazon S3 버킷에 아카이빙하는 데 사용됩니다. Veeam을 이 솔루션의 Windows 서버에 구축했습니다. Veeam 구축에 대한 자세한 지침은 를 참조하십시오<block ref="43bd82bcfa6fc650951eb1c3021cf923" category="inline-link-rx"></block>.</block>
  <block id="a2af8a9311b9c3a74f6418a81bb700d2" category="section-title">Veeam 스케일아웃 백업 저장소를 구성합니다</block>
  <block id="b61099b9ef1858547775741cc632226a" category="paragraph">소프트웨어를 배포하고 라이센스를 받은 후에는 백업 작업을 위한 타겟 스토리지로 SOBR(스케일 아웃 백업 저장소)을 생성할 수 있습니다. 재해 복구를 위해 VM 데이터를 오프 사이트로 백업하는 데에도 S3 버킷을 포함해야 합니다.</block>
  <block id="b2fe763ad14c7947f74a8693fa06bf2b" category="paragraph">시작하기 전에 다음 필수 구성 요소를 참조하십시오.</block>
  <block id="e787194bd6ef5154135951b4ab7f0317" category="list-text">백업을 위한 타겟 스토리지로 사내 ONTAP 시스템에 SMB 파일 공유를 생성합니다.</block>
  <block id="1c2ed63d64d034cdd6fe30f769495f52" category="list-text">SOBR에 포함할 Amazon S3 버킷을 생성합니다. 오프사이트 백업을 위한 저장소입니다.</block>
  <block id="e349d3884df12b302e0d564f4cf3dec4" category="section-title">Veeam에 ONTAP 스토리지를 추가합니다</block>
  <block id="3f71ccdf6fe8797ee5930ef4b5a0eaf1" category="paragraph">먼저, Veeam에서 ONTAP 스토리지 클러스터와 관련 SMB/NFS 파일 시스템을 스토리지 인프라로 추가합니다.</block>
  <block id="dc14600d8d3627181cbe1757142b1c03" category="list-text">Veeam 콘솔을 열고 로그인합니다. Storage Infrastructure로 이동한 다음 Add Storage를 선택합니다.</block>
  <block id="a55b866e82b1226d8874e7d53e6e50a9" category="paragraph"><block ref="a55b866e82b1226d8874e7d53e6e50a9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5bb1dc14738b469545970cd32668931f" category="list-text">스토리지 추가 마법사에서 NetApp을 스토리지 공급업체로 선택한 다음 Data ONTAP를 선택합니다.</block>
  <block id="391d2bf94e1387196a435da4f4f0af41" category="list-text">관리 IP 주소를 입력하고 NAS Filer 상자를 선택합니다. 다음 을 클릭합니다.</block>
  <block id="a8485af4e188b4009412f68ce18de31a" category="paragraph"><block ref="a8485af4e188b4009412f68ce18de31a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fab62b3f01af99a63f513f81f07f4c93" category="list-text">자격 증명을 추가하여 ONTAP 클러스터에 액세스합니다.</block>
  <block id="5e9ee6438a10072376c31e6014cef8c3" category="paragraph"><block ref="5e9ee6438a10072376c31e6014cef8c3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f55d6a23cbf126acc9c5ca42a97be0fc" category="list-text">NAS Filer 페이지에서 검사할 프로토콜을 선택하고 Next 를 선택합니다.</block>
  <block id="596ee09f3551be34368ba19aa36584cd" category="paragraph"><block ref="596ee09f3551be34368ba19aa36584cd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="674fb2409a1f0a9e628bebcb470960cf" category="list-text">마법사의 적용 및 요약 페이지를 완료하고 마침 을 클릭하여 스토리지 검색 프로세스를 시작합니다. 검사가 완료되면 ONTAP 클러스터가 NAS 파일러와 함께 사용 가능한 리소스로 추가됩니다.</block>
  <block id="dc2bb995c316bc90c4d3a169bbb877d5" category="paragraph"><block ref="dc2bb995c316bc90c4d3a169bbb877d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8f9b12801eaee10c32275f4ee61916aa" category="list-text">새로 검색된 NAS 공유를 사용하여 백업 리포지토리를 생성합니다. Backup Infrastructure에서 Backup Repositories를 선택하고 Add Repository 메뉴 항목을 클릭합니다.</block>
  <block id="621999df528dc938edd5a395cf0df8f3" category="paragraph"><block ref="621999df528dc938edd5a395cf0df8f3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="afc15a9e4c0cbbfa567d40414a9725a1" category="inline-link">Veeam 문서를 참조하십시오</block>
  <block id="218b99cee35d61ca3e9cb2d068673d9a" category="list-text">새 백업 저장소 마법사의 모든 단계를 수행하여 리포지토리를 생성합니다. Veeam Backup Repositories 생성에 대한 자세한 내용은 를 참조하십시오<block ref="3932357efba07e37ed76091ad3c0260c" category="inline-link-rx"></block>.</block>
  <block id="b56272bcb8aa2b6cb2998d01ed46d1f8" category="paragraph"><block ref="b56272bcb8aa2b6cb2998d01ed46d1f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6fdf6cc44242ceed0927b180d30e5e75" category="section-title">Amazon S3 버킷을 백업 저장소로 추가합니다</block>
  <block id="8c5c80325137d0f76fbe191272748ba6" category="paragraph">다음 단계는 Amazon S3 스토리지를 백업 저장소로 추가하는 것입니다.</block>
  <block id="6a1ed885510bb28a64f66f0870fbaa39" category="list-text">Backup Infrastructure &gt; Backup Repositories 로 이동합니다. 리포지토리 추가 를 클릭합니다.</block>
  <block id="bf510a56b5d84298de7541e645b836b7" category="paragraph"><block ref="bf510a56b5d84298de7541e645b836b7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="021391ea3955cab71330e7a32f03333f" category="list-text">백업 저장소 추가 마법사에서 오브젝트 스토리지 를 선택한 다음 Amazon S3를 선택합니다. 그러면 New Object Storage Repository 마법사가 시작됩니다.</block>
  <block id="c1f1ad1062498b5eeb9d31293b71343c" category="paragraph"><block ref="c1f1ad1062498b5eeb9d31293b71343c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d3a3eb593a619e4becab9e45b8f46652" category="list-text">오브젝트 스토리지 저장소의 이름을 입력하고 Next를 클릭합니다.</block>
  <block id="97f3c4606f2c2ebb0ffadd0616b76446" category="list-text">다음 섹션에서 자격 증명을 입력합니다. AWS 액세스 키와 비밀 키가 필요합니다.</block>
  <block id="e561e4c61aaefae45d0344b4ce87f23b" category="paragraph"><block ref="e561e4c61aaefae45d0344b4ce87f23b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="157669cd4d5a68c9ab9f3537a9e0ea33" category="list-text">Amazon 구성이 로드되면 데이터 센터, 버킷 및 폴더를 선택하고 적용 을 클릭합니다. 마지막으로 마침을 클릭하여 마법사를 닫습니다.</block>
  <block id="2e9f45d4556ef13d4724b6f93eea5fd3" category="section-title">스케일아웃 백업 저장소를 생성합니다</block>
  <block id="7d8f14e05d872984577255cdeb1f14ec" category="paragraph">이제 Veeam에 스토리지 저장소를 추가했으므로 재해 복구를 위해 SOBR을 생성하여 백업 복사본을 외부 Amazon S3 오브젝트 스토리지에 자동으로 계층화할 수 있습니다.</block>
  <block id="328e03460d532c3507b2a6ba6ce53438" category="list-text">백업 인프라 에서 스케일 아웃 리포지토리 를 선택한 다음 스케일 아웃 리포지토리 추가 메뉴 항목을 클릭합니다.</block>
  <block id="3ffac3b915968cb75860eac6dcb2255b" category="paragraph"><block ref="3ffac3b915968cb75860eac6dcb2255b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="582671a9090106ace80b09bb160558c6" category="list-text">새 스케일 아웃 백업 리포지토리에서 SOBR의 이름을 제공하고 다음을 클릭합니다.</block>
  <block id="8f7df3cc6ed6758328582e4972dcb532" category="list-text">성능 계층의 경우 로컬 ONTAP 클러스터에 상주하는 SMB 공유가 포함된 백업 저장소를 선택합니다.</block>
  <block id="2c4b66b86991d603fc9db639a47179f8" category="paragraph"><block ref="2c4b66b86991d603fc9db639a47179f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7362749638566881b7b5f8fe545c64e8" category="list-text">배치 정책의 경우 데이터 인접성 또는 요구 사항에 따른 성능 을 선택합니다. 다음을 선택합니다.</block>
  <block id="2d1b39bdffbca5df6978176960bb0148" category="list-text">용량 계층의 경우 Amazon S3 오브젝트 스토리지로 SOBR을 확장합니다. 재해 복구를 위해, 2차 백업을 적시에 제공할 수 있도록 백업이 생성되는 즉시 Copy Backups to Object Storage 를 선택합니다.</block>
  <block id="3a54badf400b7e061484dbadf3a19b19" category="paragraph"><block ref="3a54badf400b7e061484dbadf3a19b19" category="inline-image-macro-rx" type="image"></block></block>
  <block id="248e4221544eda567f1dd23b587cec68" category="list-text">마지막으로 적용 및 마침 을 선택하여 SOBR 생성을 마칩니다.</block>
  <block id="97f8173a9f8ac774dbbb04ad209a46ee" category="section-title">스케일아웃 백업 저장소 작업을 생성합니다</block>
  <block id="d7b3c8996a5cc044c6c1221d000a9d9b" category="inline-link">Veeam Help Center 기술 문서</block>
  <block id="2b6483678eaaf63094c195aa8a37e401" category="paragraph">Veeam을 구성하는 마지막 단계는 새로 생성한 SOBR을 백업 대상으로 사용하여 백업 작업을 생성하는 것입니다. 백업 작업 생성은 스토리지 관리자의 일반적인 일부이며 여기서는 자세한 단계를 다루지 않습니다. Veeam에서 백업 작업 생성에 대한 자세한 내용은 를 참조하십시오<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="3bd61e230841633b4a28f6d2f882d50e" category="summary">조직에서는 중대한 운영 중단이 발생할 경우 비즈니스 크리티컬 애플리케이션을 신속하게 복구할 수 있도록 검증된 DR(재해 복구) 환경과 계획을 반드시 수립해야 합니다. 이 솔루션은 사내 및 AWS 기반의 VMware Cloud 모두에서 VMware 및 NetApp 기술을 중심으로 DR 사용 사례를 시연하는 데 초점을 맞춥니다.</block>
  <block id="1ae55e7a3caf44baf5721cdf304e676d" category="doc">TR-4931: Amazon Web Services 및 Guest Connect에서 VMware Cloud를 사용한 재해 복구</block>
  <block id="5f3d0127b9424be374b1c1474deb2684" category="paragraph">NetApp은 오랫동안 VMware와 통합해왔습니다. 수만 명의 고객이 가상화 환경의 스토리지 파트너로 NetApp을 선택했다는 것이 증명되었습니다. 이러한 통합은 클라우드의 게스트 연결 옵션 및 최근 NFS 데이터 저장소와의 통합에서도 계속됩니다. 이 솔루션은 일반적으로 게스트 연결 스토리지라고 하는 사용 사례에 중점을 둡니다.</block>
  <block id="1134d985d8893464bee3d37e02a36402" category="paragraph">게스트 연결 스토리지에서 게스트 VMDK는 VMware 프로비저닝된 데이터 저장소에 구축되고 애플리케이션 데이터는 iSCSI 또는 NFS에 보관되며 VM에 직접 매핑됩니다. 다음 그림과 같이 Oracle 및 MS SQL 애플리케이션을 사용하여 DR 시나리오를 보여 줍니다.</block>
  <block id="50dd1256f4cf87b2fa70e300ade578e4" category="paragraph"><block ref="50dd1256f4cf87b2fa70e300ade578e4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a9a05fe4fa63215c3d368883b85e9312" category="summary">이 솔루션은 NetApp SnapCenter를 사용하여 SQL Server 및 Oracle 데이터베이스의 애플리케이션 정합성이 보장되는 백업을 수행합니다. Veeam Backup &amp; Replication을 사용하여 가상 머신의 VMDK를 백업하면 사내 및 클라우드 기반 데이터 센터를 위한 포괄적인 재해 복구 솔루션을 제공할 수 있습니다.</block>
  <block id="d312952f462ee1dc88347d6060c708da" category="section-title">Windows SnapCenter Server를 사내에 배포합니다</block>
  <block id="989d04f01dc04fe21c2b542b83a45a6b" category="inline-link">NetApp 문서 센터</block>
  <block id="5d15da138c85d083e6e6409b418b8411" category="paragraph">SnapCenter 소프트웨어는 NetApp Support 사이트에서 제공되며 도메인 또는 작업 그룹에 있는 Microsoft Windows 시스템에 설치할 수 있습니다. 자세한 계획 가이드 및 설치 지침은 에서 확인할 수 있습니다<block ref="c18608d8aa7f8cbafcf1d09b2fb01df0" category="inline-link-rx"></block>.</block>
  <block id="e6220e7462e6d815945c93dcd734235f" category="paragraph">SnapCenter 소프트웨어는 에서 얻을 수 있습니다<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="d2476cc18d417aa498cc7c32f99e980b" category="paragraph">설치가 완료되면 _\https://Virtual_Cluster_IP_or_FQDN:8146_ 를 사용하여 웹 브라우저에서 SnapCenter 콘솔에 액세스할 수 있습니다.</block>
  <block id="63b96bb46045042b50fd68d9b5a0f0ba" category="section-title">SnapCenter에 스토리지 컨트롤러를 추가합니다</block>
  <block id="8956d4de491225a4e6515ba0ad92fb30" category="paragraph">SnapCenter에 스토리지 컨트롤러를 추가하려면 다음 단계를 수행하십시오.</block>
  <block id="2ba7db7e99ccd03f69c81ce1f25330e6" category="list-text">왼쪽 메뉴에서 스토리지 시스템 을 선택한 다음 새로 만들기 를 클릭하여 스토리지 컨트롤러를 SnapCenter에 추가하는 프로세스를 시작합니다.</block>
  <block id="f1d609f44050cd3b443f66e474c3b93c" category="paragraph"><block ref="f1d609f44050cd3b443f66e474c3b93c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="48806d1941dc50dadf8bcd5d590511ab" category="list-text">스토리지 시스템 추가 대화 상자에서 로컬 온-프레미스 ONTAP 클러스터의 관리 IP 주소와 사용자 이름 및 암호를 추가합니다. 그런 다음 제출 을 클릭하여 스토리지 시스템 검색을 시작합니다.</block>
  <block id="7b7a93dac3e0141a111190c64a54a220" category="paragraph"><block ref="7b7a93dac3e0141a111190c64a54a220" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dc7b9fe54780f87aa8bdf884b95187c5" category="list-text">이 과정을 반복하여 FSx ONTAP 시스템을 SnapCenter에 추가합니다. 이 경우 Add Storage System 창의 아래쪽에 있는 More Options 를 선택하고 Secondary 의 확인란을 클릭하여 FSx 시스템을 SnapMirror 복사본 또는 기본 백업 스냅샷으로 업데이트된 보조 스토리지 시스템으로 지정합니다.</block>
  <block id="4a8fedebba8d5bd8e357863942b66b79" category="paragraph"><block ref="4a8fedebba8d5bd8e357863942b66b79" category="inline-image-macro-rx" type="image"></block></block>
  <block id="62104d735113c9c7e8a23cd031ca2004" category="paragraph">SnapCenter에 스토리지 시스템을 추가하는 방법에 대한 자세한 내용은 에서 설명서를 참조하십시오<block ref="05f72e618af68eda439c6d688692dcd6" category="inline-link-rx"></block>.</block>
  <block id="c81dcfed07648c407976127bb0bdbed2" category="section-title">SnapCenter에 호스트를 추가합니다</block>
  <block id="e796a589329333070ad568f533b21931" category="paragraph">다음 단계는 SnapCenter에 호스트 애플리케이션 서버를 추가하는 것입니다. 이 프로세스는 SQL Server와 Oracle에서 모두 비슷합니다.</block>
  <block id="6718a4b38f7a3df604d1fd6079decaae" category="list-text">왼쪽 메뉴에서 호스트 를 선택한 다음 추가 를 클릭하여 스토리지 컨트롤러를 SnapCenter에 추가하는 프로세스를 시작합니다.</block>
  <block id="4106a2178f1f526d51c57cb723e0f3ef" category="list-text">호스트 추가 창에서 호스트 유형, 호스트 이름 및 호스트 시스템 자격 증명을 추가합니다. 플러그인 유형을 선택합니다. SQL Server의 경우 Microsoft Windows 및 Microsoft SQL Server 플러그인을 선택합니다.</block>
  <block id="3eae7017924ae8e187a046e62f5c334e" category="paragraph"><block ref="3eae7017924ae8e187a046e62f5c334e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fdb2b840f37deff5210ef9f13e554fd5" category="list-text">Oracle의 경우 호스트 추가 대화 상자에서 필수 필드를 입력하고 Oracle Database 플러그인의 확인란을 선택합니다. 그런 다음 제출 을 클릭하여 검색 프로세스를 시작하고 호스트를 SnapCenter에 추가합니다.</block>
  <block id="6430fb639e6454a8e47d23925ec8f583" category="paragraph"><block ref="6430fb639e6454a8e47d23925ec8f583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7da39703d1c501afafc02c06d1c31788" category="section-title">SnapCenter 정책을 생성합니다</block>
  <block id="fa5cc6d015db1929ddc02765f2003a33" category="paragraph">정책은 백업 작업에 대해 따라야 할 특정 규칙을 설정합니다. 여기에는 백업 일정, 복제 유형 및 SnapCenter에서 트랜잭션 로그 백업 및 잘라내기를 처리하는 방식이 포함되며 이에 국한되지 않습니다.</block>
  <block id="817a33901829b57a630a499c24b4daf2" category="paragraph">SnapCenter 웹 클라이언트의 설정 섹션에서 정책에 액세스할 수 있습니다.</block>
  <block id="6ddda0770a816978059cd0702e0223d0" category="paragraph"><block ref="6ddda0770a816978059cd0702e0223d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9d91360f1fd4ad1abf6c445ec8ff103" category="paragraph">SQL Server 백업에 대한 정책을 생성하는 방법에 대한 자세한 내용은 를 참조하십시오<block ref="7f14e0044cbde8b494ce0e026c2561cf" category="inline-link-rx"></block>.</block>
  <block id="f079afadb233d404e335685a7b58c70e" category="paragraph">Oracle 백업에 대한 정책을 생성하는 방법에 대한 자세한 내용은 를 참조하십시오<block ref="be1c60aeb8bf91be9c4096428152eedc" category="inline-link-rx"></block>.</block>
  <block id="5847f474084786fc8a16763856c1b0da" category="list-text">정책 생성 마법사를 진행하는 동안 복제 섹션을 특별히 기록해 둡니다. 이 섹션에서는 백업 프로세스 중에 사용할 보조 SnapMirror 복사본의 유형을 설명합니다.</block>
  <block id="fc3c693a9b60faa4913d47e755b4cf34" category="list-text">“로컬 스냅샷 복사본을 생성한 후 SnapMirror 업데이트” 설정은 동일한 클러스터에 상주하는 두 스토리지 가상 시스템 사이에 SnapMirror 관계가 존재하는 경우 SnapMirror 관계를 업데이트하는 것을 의미합니다.</block>
  <block id="77bf66c8cee4cd2482095210be78e13a" category="list-text">“로컬 스냅샷 복사본을 만든 후 SnapVault 업데이트” 설정은 두 개의 개별 클러스터와 온-프레미스 ONTAP 시스템과 Cloud Volumes ONTAP 또는 FSxN 사이에 존재하는 SnapMirror 관계를 업데이트하는 데 사용됩니다.</block>
  <block id="824aec6074385910e619ac91969c68a3" category="paragraph">다음 이미지는 이전 옵션과 백업 정책 마법사에서 이러한 옵션이 표시되는 방식을 보여 줍니다.</block>
  <block id="89bace67b9ee8f5a253e88d282ceb63d" category="paragraph"><block ref="89bace67b9ee8f5a253e88d282ceb63d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e6bd8190e5c79ad5d86289d596dd8c16" category="section-title">SnapCenter 리소스 그룹을 생성합니다</block>
  <block id="2f15c296209e980cccf829b7e5c1bbca" category="paragraph">리소스 그룹을 사용하면 백업에 포함할 데이터베이스 리소스와 해당 리소스에 대해 수행한 정책을 선택할 수 있습니다.</block>
  <block id="e96fdebed13bd03c9e88f6cff2b7ed67" category="list-text">왼쪽 메뉴의 리소스 섹션으로 이동합니다.</block>
  <block id="8b5265ba89102ff3a5fd8b504ba85140" category="list-text">창 위쪽에서 작업할 리소스 유형(이 경우 Microsoft SQL Server)을 선택한 다음 새 리소스 그룹을 클릭합니다.</block>
  <block id="695c07b026f6602eff292288473cdc42" category="paragraph"><block ref="695c07b026f6602eff292288473cdc42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bad635c8aa26c147bd68eb7b700cabbe" category="paragraph">SnapCenter 설명서는 SQL Server 및 Oracle 데이터베이스 모두에 대한 리소스 그룹을 생성하는 단계별 세부 정보를 제공합니다.</block>
  <block id="6f9886092f343d1ecc5b676f4ca381c7" category="paragraph">SQL 리소스 백업의 경우 에 따릅니다<block ref="d0500a8d119256a2ca6775a9357c88fa" category="inline-link-rx"></block>.</block>
  <block id="ffbeca6b667809b446c63465c7ff671f" category="paragraph">Oracle 리소스 백업에 대해서는 을 참조하십시오<block ref="c6b13e1956473c7b22893d8b12c1b8be" category="inline-link-rx"></block>.</block>
  <block id="601c3055944b06a3d06d7da4128af752" category="summary">애플리케이션 VM 및 데이터베이스 볼륨을 AWS에서 실행되는 VMware Cloud Volume 서비스로 페일오버하려면 SnapCenter Server와 Veeam Backup and Replication Server의 실행 중인 인스턴스를 설치하고 구성해야 했습니다. 페일오버가 완료된 후 사내 데이터 센터에 대한 페일백이 계획 및 실행될 때까지 이러한 툴을 정상 백업 작업을 재개하도록 구성해야 합니다.</block>
  <block id="f93f90f32b570b5fbcc3458fb93a6ab2" category="doc">클라우드 백업 툴</block>
  <block id="4f31ced8146865d2c2823db3f623bf36" category="section-title">백업 툴 구축</block>
  <block id="4dad49c9583060929c06d355e24a683a" category="paragraph">SnapCenter 서버 및 Veeam Backup &amp; Replication Server를 VMware Cloud SDDC에 설치하거나 VPC에 상주하는 EC2 인스턴스에 설치할 수 있으며, VMware 클라우드 환경에 네트워크를 연결할 수 있습니다.</block>
  <block id="f709ed2f05802131924f53cb483d0216" category="section-title">SnapCenter 서버</block>
  <block id="257b2c5a413bf4e187ebd89c8a363827" category="inline-link-macro">NetApp 문서화 센터</block>
  <block id="2bd8e8f9848a7635d56bcd86b9ad4c8f" category="paragraph">SnapCenter 소프트웨어는 NetApp Support 사이트에서 제공되며 도메인 또는 작업 그룹에 상주하는 Microsoft Windows 시스템에 설치할 수 있습니다. 자세한 계획 가이드 및 설치 지침은 에서 확인할 수 있습니다 <block ref="a00f6e57d5c269a935cd1b0491cebb83" category="inline-link-macro-rx"></block>.</block>
  <block id="d099bc9c6d34500d99c2caac0e6df36c" category="paragraph">SnapCenter 소프트웨어는 에서 찾을 수 있습니다<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="5a8e524620f781b94c018014370aad68" category="paragraph">Veeam Backup &amp; Replication 서버를 AWS의 VMware Cloud 또는 EC2 인스턴스에 설치할 수 있습니다. 자세한 구현 지침은 를 참조하십시오<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="af7bd34681425c09ae0ef24381972fb5" category="section-title">백업 툴 및 구성</block>
  <block id="82634d63ab3a3344fb59974c50487bac" category="paragraph">설치 후 SnapCenter 및 Veeam Backup &amp; Replication이 AWS의 VMware Cloud에 데이터를 복원하는 데 필요한 작업을 수행하도록 구성되어 있어야 합니다.</block>
  <block id="4b152f4bba0a5ca6345daa47736e4622" category="section-title">SnapCenter 구성</block>
  <block id="411fce4d2b732a8bfda73c4f04da246c" category="paragraph">FSx ONTAP에 미러링된 응용 프로그램 데이터를 복원하려면 먼저 온-프레미스 SnapCenter 데이터베이스의 전체 복원을 수행해야 합니다. 이 프로세스가 완료되면 VM과의 통신이 다시 설정되고 FSx ONTAP를 기본 스토리지로 사용하여 응용 프로그램 백업을 다시 시작할 수 있습니다.</block>
  <block id="d307f68836099290d00bdc9341ec2be7" category="inline-link-macro">보조 Windows SnapCenter 서버를 배포합니다</block>
  <block id="520d23cd5df8582645ee42124b69ccae" category="paragraph">AWS에 있는 SnapCenter 서버에서 완료해야 하는 단계 목록은 섹션을 참조하십시오 <block ref="a29fcfa081b59708af69951be417dc25" category="inline-link-macro-rx"></block>.</block>
  <block id="50d8cb6b9ada9f3e6328cb534ed5773f" category="paragraph">Amazon S3 스토리지에 백업된 가상 머신을 복구하려면 Veeam Server를 Windows 서버에 설치하고 원래 백업 저장소가 포함된 VMware Cloud, FSx ONTAP 및 S3 버킷과 통신하도록 구성해야 합니다. 또한 VM이 복구된 후 새 백업을 수행하려면 FSx ONTAP에 새 백업 리포지토리가 구성되어 있어야 합니다.</block>
  <block id="845690e8aecca4f756b60cbd6c80c7f9" category="inline-link-macro">2차 Veeam Backup &amp; amp; Replication Server를 구축합니다</block>
  <block id="82a8a7d9b8f053ce73af1c1b5b8694ff" category="paragraph">애플리케이션 VM의 장애 조치를 완료하는 데 필요한 전체 단계 목록은 섹션을 참조하십시오 <block ref="83d03cb08c05a76f36dedd6b85344746" category="inline-link-macro-rx"></block>.</block>
  <block id="db4ff15d9c0c503103508af3dd860139" category="summary">NetApp AFF A-Series 시스템은 클라우드에서 다양한 엔터프라이즈 시나리오를 지원하는 유연한 데이터 관리 옵션을 갖춘 고성능 스토리지 인프라를 제공합니다. 이 솔루션에서는 ONTAP AFF A300을 기본 사내 스토리지 시스템으로 사용했습니다.</block>
  <block id="6e5148fc476ca76eb8c330524bc1064d" category="paragraph">이 솔루션에서 NetApp ONTAP를 VMware 및 SnapCenter용 ONTAP 툴과 함께 사용하여 VMware vSphere와 긴밀하게 통합된 포괄적인 관리 및 애플리케이션 백업 기능을 제공했습니다.</block>
  <block id="e64f2bbe0643eeea77fa30ad5e4bdbe4" category="paragraph">가상 머신 및 VMDK 파일을 호스팅하는 VMware 데이터 저장소에는 ONTAP 스토리지를 사용했습니다. VMware는 연결된 데이터 저장소에 대해 여러 스토리지 프로토콜을 지원하며, 이 솔루션에서는 ESXi 호스트의 데이터 저장소에 NFS 볼륨을 사용했습니다. 그러나 ONTAP 스토리지 시스템은 VMware에서 지원하는 모든 프로토콜을 지원합니다.</block>
  <block id="ba1139b1becb929a6ba79e930297c5b7" category="paragraph">다음 그림은 VMware 스토리지 옵션을 보여 줍니다.</block>
  <block id="6869f0a16b26f7047d40a5a9c5a0ccd4" category="paragraph"><block ref="6869f0a16b26f7047d40a5a9c5a0ccd4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aed995b63d54f1d314ad87fc5d16b69d" category="paragraph">ONTAP 볼륨은 애플리케이션 VM을 위한 iSCSI 및 NFS 게스트 연결 스토리지 모두에 사용되었습니다. 애플리케이션 데이터에 다음 스토리지 프로토콜을 사용했습니다.</block>
  <block id="c787b4233027288b06ace5dad3c0e461" category="list-text">게스트가 연결된 Oracle 데이터베이스 파일용 NFS 볼륨입니다.</block>
  <block id="6a13696c6a6b506058d391582e402c83" category="list-text">게스트 연결 Microsoft SQL Server 데이터베이스 및 트랜잭션 로그용 iSCSI LUN</block>
  <block id="6504ffb2b49026508f8d68a73a0893a1" category="cell">데이터베이스 유형입니다</block>
  <block id="9b8bdf7379e889d83ab24e782c87d2ac" category="cell">스토리지 프로토콜</block>
  <block id="0fc2cb6a177a3a14f31bd4810e09fa97" category="cell">볼륨 설명입니다</block>
  <block id="31f8757839909e87266f2b53482c86ef" category="cell">Windows Server 2019</block>
  <block id="e40ceeaead715c564e85bdc9b183e491" category="cell">SQL Server 2019</block>
  <block id="458648f675593beefe031e7b7ba9fcdd" category="cell">데이터베이스 파일</block>
  <block id="81fae4ea40cc442afa43dab4cc001004" category="cell">로그 파일</block>
  <block id="ed47cdd7d93d911c4e94fc2801456784" category="cell">Oracle Linux 8.5</block>
  <block id="e13e1c4f4700229b02ee474e7dda4ea2" category="cell">Oracle 19c</block>
  <block id="4659ac5526bf8dff13f1ec371e79b766" category="cell">Oracle 바이너리</block>
  <block id="f0a16b1024d40f006a15728ebd0e0f12" category="cell">Oracle 데이터</block>
  <block id="1d9c31e9be3c01076e13f0f4fa1c15ae" category="cell">Oracle 복구 파일</block>
  <block id="26f11a15ba5f458b3d86d9ecc01b56f3" category="paragraph">또한 Primary Veeam 백업 저장소에도 ONTAP 스토리지를 사용하고 SnapCenter 데이터베이스 백업의 백업 타겟에도 스토리지를 사용했습니다.</block>
  <block id="e8d719041d7958d85248e29684218330" category="list-text">Veeam 백업 리포지토리를 위한 SMB 공유입니다.</block>
  <block id="6005cf3be81f9c1a1908df0afb543b7d" category="list-text">SMB 공유는 SnapCenter 데이터베이스 백업의 타겟입니다.</block>
  <block id="6872c2b6282a1ff41523f7b84a51d4da" category="section-title">클라우드 스토리지</block>
  <block id="72cd2806db1eac2f04ef89c81542dd54" category="paragraph">이 솔루션에는 페일오버 프로세스의 일부로 복원되는 가상 머신을 호스팅하기 위한 AWS 기반 VMware Cloud가 포함되어 있습니다. 이 쓰기 작업을 통해 VMware는 VM 및 VMDK를 호스팅하는 데이터 저장소에 대해 vSAN 스토리지를 지원합니다.</block>
  <block id="501c11094fdd604514f321bced51fe82" category="paragraph">ONTAP용 FSX는 SnapCenter 및 SyncMirror를 사용하여 미러링되는 애플리케이션 데이터의 보조 스토리지로 사용됩니다. 페일오버 프로세스의 일환으로 ONTAP 클러스터용 FSx는 운영 스토리지로 변환되고 데이터베이스 애플리케이션은 FSx 스토리지 클러스터에서 실행되는 일반 기능을 재개할 수 있습니다.</block>
  <block id="2872e9fbf25a6695761c355a5170f21f" category="section-title">NetApp ONTAP용 Amazon FSx 설정</block>
  <block id="81d8366c2ec35340f9822e490b614b41" category="paragraph">Cloud Manager를 사용하여 NetApp ONTAP용 AWS FSx를 배포하려면 의 지침을 따르십시오<block ref="f938a02d8e5f1cc6cb4c026bb367a9b5" category="inline-link-rx"></block>.</block>
  <block id="e48c9f83aba7e50a34062296356c11da" category="paragraph">FSx ONTAP를 배포한 후 온-프레미스 ONTAP 인스턴스를 FSx ONTAP로 끌어서 놓아 볼륨의 복제 설정을 시작합니다.</block>
  <block id="bfeecfa1e5aafaba3386ba09221608e3" category="paragraph">다음 그림은 FSx ONTAP 환경을 보여 줍니다.</block>
  <block id="f0eabf6ad2404299416504a68c18c70b" category="paragraph"><block ref="f0eabf6ad2404299416504a68c18c70b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46fabc81c23066d3f0ef74556fc23d0d" category="section-title">네트워크 인터페이스가 생성되었습니다</block>
  <block id="cf36149275607710e0655ce5a52d4745" category="paragraph">NetApp ONTAP용 FSX에는 iSCSI, NFS, SMB 및 클러스터 간 네트워크에 사용할 수 있도록 미리 구성되고 준비된 네트워크 인터페이스가 있습니다.</block>
  <block id="a23141775a4b1f964c8a4c1335d366c7" category="section-title">VM 데이터 저장소 스토리지</block>
  <block id="60d2a0c028f1fc1db964ff9d52cfe139" category="paragraph">VMware Cloud SDDC에는 vsandatastore와 workloaddatastore라는 두 개의 VSAN 데이터 저장소가 있습니다. 클라우드 관리자 자격 증명에 대한 액세스가 제한된 관리 VM을 호스팅하기 위해 "vsandastore"를 사용했습니다. 워크로드의 경우 워크로드 데이터 저장소를 사용했습니다.</block>
  <block id="d4fab32948320ef14f4b14bb30559cd4" category="summary">이 솔루션을 사용하려면 NetApp SyncMirror 작업을 수행하기 위해 사내 ONTAP 클러스터에서 NetApp ONTAP 인터커넥트 클러스터 네트워크 주소용 AWS FSx와 성공적으로 통신해야 합니다. 또한 Veeam 백업 서버가 AWS S3 버킷에 액세스할 수 있어야 합니다. 인터넷 전송을 사용하는 대신 기존 VPN 또는 Direct Connect 링크를 S3 버킷에 대한 전용 링크로 사용할 수 있습니다.</block>
  <block id="c850af3ffbdd92ab67281dbdfeaf4e52" category="paragraph">ONTAP는 SAN 환경을 위한 iSCSI, FC(파이버 채널), FCoE(Fibre Channel over Ethernet) 또는 NVMe/FC(Non-Volatile Memory Express over Fibre Channel)를 비롯하여 가상화에 사용되는 모든 주요 스토리지 프로토콜을 지원합니다. ONTAP는 게스트 연결을 위해 NFS(v3 및 v4.1) 및 SMB 또는 S3를 지원합니다. 환경에 가장 적합한 프로토콜을 자유롭게 선택할 수 있으며, 필요에 따라 단일 시스템에서 프로토콜을 결합할 수 있습니다. 예를 들어, 몇 개의 iSCSI LUN 또는 게스트 공유로 NFS 데이터 저장소의 일반 사용을 늘릴 수 있습니다.</block>
  <block id="dc8286bc14e4eca04d5c8c3d3745e742" category="paragraph">이 솔루션은 게스트 VMDK의 경우 사내 데이터 저장소에 NFS 데이터 저장소를, 게스트 애플리케이션 데이터의 경우 iSCSI와 NFS를 모두 활용합니다.</block>
  <block id="89cf31d317f3100637041ccf296c3421" category="section-title">클라이언트 네트워크</block>
  <block id="d6c8c82593995a45499a762d317c04ec" category="paragraph">VMkernel 네트워크 포트 및 소프트웨어 정의 네트워킹은 ESXi 호스트에 대한 연결을 제공하므로 VMware 환경 외부의 요소와 통신할 수 있습니다. 접속은 사용되는 VMkernel 인터페이스 유형에 따라 달라집니다.</block>
  <block id="774cca28a02c25118dc9668598f65663" category="paragraph">이 솔루션에서는 다음과 같은 VMkernel 인터페이스가 구성되었습니다.</block>
  <block id="fe4dbcab9b910577e5035e97ac068dae" category="list-text">관리</block>
  <block id="31ce31cccd4aecd29ff8b40dd37b8305" category="section-title">스토리지 네트워크가 프로비저닝되었습니다</block>
  <block id="a09cf1d6ddb872a8c1ee517538a9373d" category="paragraph">LIF(논리 인터페이스)는 클러스터의 노드에 대한 네트워크 액세스 지점을 나타냅니다. 이렇게 하면 클라이언트가 액세스하는 데이터가 저장된 스토리지 가상 시스템과 통신할 수 있습니다. 클러스터가 네트워크를 통해 통신을 주고받는 포트에 LIF를 구성할 수 있습니다.</block>
  <block id="b976c5d6eaa4fa1f606cff663f77835f" category="paragraph">이 솔루션에서 LIF는 다음과 같은 스토리지 프로토콜에 대해 구성됩니다.</block>
  <block id="cfba851bf46ae36ca092575bba6c7289" category="section-title">클라우드 연결 옵션</block>
  <block id="466c519a74055fba20814454ab577c83" category="paragraph">고객은 사내 환경을 클라우드 리소스에 연결할 때 VPN 또는 Direct Connect 토폴로지 구축을 비롯한 다양한 옵션을 사용할 수 있습니다.</block>
  <block id="ce24b5f233dc29fc3614b2c7d961948b" category="section-title">VPN(가상 사설망)</block>
  <block id="55e6887f1e4e535089db85cbcae36acd" category="paragraph">VPN(가상 사설망)은 인터넷 기반 또는 사설 MPLS 네트워크를 통해 안전한 IPSec 터널을 만드는 데 주로 사용됩니다. VPN은 설치가 쉽지만 안정성(인터넷 기반) 및 속도가 부족합니다. 종료 지점은 AWS VPC 또는 VMware Cloud SDDC에서 종료할 수 있습니다. 이 재해 복구 솔루션을 위해 사내 네트워크에서 NetApp ONTAP용 AWS FSx에 대한 연결을 만들었습니다. NetApp ONTAP용 FSx가 연결되어 있는 AWS VPC(가상 프라이빗 게이트웨이 또는 전송 게이트웨이)에서 종료할 수 있습니다.</block>
  <block id="365e9311cae767fae52a5cdba7003f9a" category="paragraph">VPN 설정은 경로 기반 또는 정책 기반일 수 있습니다. 라우팅 기반 설정을 사용하면 끝점이 자동으로 라우트를 교환하며, 셋업은 새로 생성된 서브넷으로 가는 경로를 학습한다. 정책 기반 설정을 사용하면 로컬 및 원격 서브넷을 정의해야 하며, 새 서브넷이 추가되고 IPSec 터널에서 통신할 수 있게 되면 경로를 업데이트해야 합니다.</block>
  <block id="fb932a9cb1f7aff6a88af2645c80731e" category="admonition">IPSec VPN 터널이 기본 게이트웨이에 생성되지 않은 경우 원격 네트워크 라우트는 로컬 VPN 터널 끝점을 통해 라우팅 테이블에서 정의해야 합니다.</block>
  <block id="2dc9d6f2c2810edb190acfe717c84a68" category="paragraph">다음 그림에서는 일반적인 VPN 연결 옵션을 보여 줍니다.</block>
  <block id="d90d767da5b6da33c2785b3d3120c23f" category="paragraph"><block ref="d90d767da5b6da33c2785b3d3120c23f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac1fc9354c56b77f7143d2b6a7d185ad" category="section-title">직접 연결</block>
  <block id="4aa5340761d0794e8da7cfa5ead94eb3" category="paragraph">Direct Connect는 AWS 네트워크에 대한 전용 링크를 제공합니다. 전용 연결은 1Gbps, 10Gbps 또는 100Gbps 이더넷 포트를 사용하여 AWS에 대한 링크를 생성합니다. AWS Direct Connect 파트너는 자신과 AWS 간의 사전 설정된 네트워크 링크를 사용하여 호스팅된 연결을 제공하며, 50Mbps~10GBps까지 이용할 수 있습니다. 기본적으로 트래픽은 암호화되지 않습니다. 그러나 MACsec 또는 IPsec을 사용하여 트래픽을 보호하는 옵션을 사용할 수 있습니다. MACsec는 레이어 2 암호화를 제공하고 IPsec은 레이어 3 암호화를 제공합니다. MACsec은 통신 중인 장치를 은폐하여 보안을 강화합니다.</block>
  <block id="f41e1aa529328c6c391ee2bbb3e7b35f" category="paragraph">고객은 라우터 장비를 AWS Direct Connect 위치에 두어야 합니다. 이를 설정하기 위해 AWS APN(Partner Network)과 협력할 수 있습니다. 해당 라우터와 AWS 라우터 간에 물리적 연결이 이루어집니다. VPC에서 NetApp ONTAP용 FSx에 대한 액세스를 활성화하려면 전용 가상 인터페이스 또는 Direct Connect에서 VPC로 전송 가상 인터페이스가 있어야 합니다. 프라이빗 가상 인터페이스를 사용하는 경우 Direct Connect to VPC 연결 확장성이 제한됩니다.</block>
  <block id="aac639f893699a86dc44236deb8c2ff8" category="paragraph">다음 그림은 Direct Connect 인터페이스 옵션을 보여 줍니다.</block>
  <block id="65d0f01c0d2abb5df490f85de1a3c7f5" category="paragraph"><block ref="65d0f01c0d2abb5df490f85de1a3c7f5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a547cd01b7307bbc41da8aed4983dc1" category="section-title">전송 게이트웨이</block>
  <block id="5789b6855d128c642555ffa55396a65c" category="inline-link">AWS Direct Connect 설명서</block>
  <block id="3ae6c7e3aea4c72d9bf07244d7b959e6" category="paragraph">전송 게이트웨이는 지역 내 Direct Connect-to-VPC 연결의 확장성을 높일 수 있는 지역 수준 구조입니다. 교차 지역 연결이 필요한 경우 이동 게이트웨이를 피어링해야 합니다. 자세한 내용은 를 참조하십시오<block ref="9f2a100b6fab526146ca277977e4ef3a" category="inline-link-rx"></block>.</block>
  <block id="ac8979d211e20b50e94073d31f2e8d44" category="section-title">클라우드 네트워크 고려 사항</block>
  <block id="02c5109954e68b54548d5ef777afaf76" category="paragraph">클라우드에서 기본 네트워크 인프라는 클라우드 서비스 공급자가 관리하는 반면, 고객은 AWS에서 VPC 네트워크, 서브넷, 라우팅 테이블 등을 관리해야 합니다. 또한 컴퓨팅 엣지에서 NSX 네트워크 세그먼트를 관리해야 합니다. SDDC는 외부 VPC 및 Transit Connect에 대한 경로를 그룹화합니다.</block>
  <block id="ee94a9a0de351e37a54ce1fec2961c62" category="paragraph">Multi-AZ 가용성을 지원하는 NetApp ONTAP용 FSx가 VMware Cloud에 연결된 VPC에 배포되면 iSCSI 트래픽에서 필요한 라우트 테이블 업데이트를 수신하여 통신을 가능하게 합니다. 기본적으로 Multi-AZ 구축을 위해 연결된 VPC에서 VMware Cloud에서 FSx ONTAP NFS/SMB 서브넷으로 연결되는 라우트는 없습니다. 이 경로를 정의하기 위해 VMware에서 관리하는 전송 게이트웨이인 VMware Cloud SDDC 그룹을 사용하여 같은 지역의 VMware Cloud SDDC와 외부 VPC 및 기타 전송 게이트웨이 간에 통신을 허용했습니다.</block>
  <block id="7ee08649d3bd024352f28df7dabbb32f" category="admonition">전송 게이트웨이 사용과 관련된 데이터 전송 비용이 있습니다. 특정 지역의 비용 세부 정보는 를 참조하십시오<block ref="b6f8eb4f405293cd9bb0c07a2ec1b299" category="inline-link-rx"></block>.</block>
  <block id="68010b6bb26779cadbf96e9d04dad537" category="paragraph">VMware Cloud SDDC는 단일 데이터 센터를 갖는 것과 같은 단일 가용성 영역에 구축할 수 있습니다. 또한, 확장 클러스터 옵션을 사용할 수 있습니다. 이는 가용성 영역 장애 시 가용성을 높이고 다운타임을 줄일 수 있는 NetApp MetroCluster 솔루션과 유사합니다.</block>
  <block id="0d5aa9b9832dc4c044a656ccdd139dcf" category="paragraph">데이터 전송 비용을 최소화하려면 VMware Cloud SDDC 및 AWS 인스턴스 또는 서비스를 동일한 가용성 영역에 유지해야 합니다. AWS는 가용성 영역에 부하를 분산하기 위해 계정별 AZ 주문 목록을 제공하므로 이름이 아닌 가용성 영역 ID와 일치시키는 것이 좋습니다. 예를 들어 계정(US-East-1a)은 AZ ID 1을 가리키지만 다른 계정(US-East-1c)은 AZ ID 1을 가리킬 수 있습니다. 가용성 영역 ID는 여러 가지 방법으로 검색할 수 있습니다. 다음 예에서는 VPC 서브넷에서 AZ ID를 검색했습니다.</block>
  <block id="64c06e81643d1c8b6eba37a5343885ec" category="paragraph"><block ref="64c06e81643d1c8b6eba37a5343885ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="70cd8bfb8fd7a4082087201414ab2fe4" category="inline-link">VMware 설명서</block>
  <block id="8920393d6c2c8771eef99f947100b883" category="paragraph">VMware Cloud SDDC에서 네트워킹은 NSX를 통해 관리되며, 남북의 트래픽 업링크 포트를 처리하는 에지 게이트웨이(Tier-0 라우터)는 AWS VPC에 연결됩니다. 컴퓨팅 게이트웨이와 관리 게이트웨이(Tier-1 라우터)는 동서 트래픽을 처리합니다. 에지의 업링크 포트가 많이 사용되는 경우 트래픽 그룹을 생성하여 특정 호스트 IP 또는 서브넷과 연결할 수 있습니다. 트래픽 그룹을 생성하면 트래픽을 분리하기 위해 추가 에지 노드가 생성됩니다. 를 확인하십시오<block ref="616556354bfd279ba90d5c2485799af5" category="inline-link-rx"></block> 다중 에지 설정을 사용하는 데 필요한 최소 vSphere 호스트 수</block>
  <block id="e064913c9382e82051f900b9564779d5" category="paragraph">VMware Cloud SDDC를 프로비저닝할 경우 VMkernel 포트가 이미 구성되어 사용할 수 있습니다. VMware는 이러한 포트를 관리하며 업데이트할 필요가 없습니다.</block>
  <block id="edbc8b71394d65a981746a0ed9072b51" category="paragraph">다음 그림에서는 호스트 VMkernel 정보의 예를 보여 줍니다.</block>
  <block id="24d3a9af73ac14dc11a2d9a4745a77b0" category="paragraph"><block ref="24d3a9af73ac14dc11a2d9a4745a77b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1315738b589a4d2de3fd82a05b2d4e19" category="section-title">프로비저닝된 스토리지 네트워크(iSCSI, NFS)</block>
  <block id="1a6b4ca0fa5ca04588d2e2eac3bf0444" category="paragraph">VM 게스트 스토리지 네트워크의 경우 일반적으로 포트 그룹을 생성합니다. NSX를 사용하면 vCenter에서 포트 그룹으로 사용되는 세그먼트를 생성합니다. 스토리지 네트워크는 라우팅 가능한 서브넷에 있기 때문에 별도의 네트워크 세그먼트를 생성하지 않아도 기본 NIC를 사용하여 LUN에 액세스하거나 NFS 엑스포트를 마운트할 수 있습니다. 스토리지 트래픽을 분리하려면 추가 세그먼트를 생성하고 규칙을 정의하고 해당 세그먼트에서 MTU 크기를 제어할 수 있습니다. 내결함성을 제공하려면 스토리지 네트워크 전용으로 두 개 이상의 세그먼트를 사용하는 것이 좋습니다. 앞서 언급했듯이 업링크 대역폭이 문제가 되면 트래픽 그룹을 생성하고 IP 접두사와 게이트웨이를 할당하여 소스 기반 라우팅을 수행할 수 있습니다.</block>
  <block id="87e62e5f6f235efbfc557b0177d0e112" category="paragraph">DR SDDC의 세그먼트를 소스 환경과 일치시켜 페일오버 중에 네트워크 세그먼트를 매핑할 수 없도록 하는 것이 좋습니다.</block>
  <block id="9175bb34d0aede26315b313b9432bcbb" category="section-title">보안 그룹</block>
  <block id="7c9ffa8d590736372f008da84037edaa" category="paragraph">다양한 보안 옵션을 통해 AWS VPC 및 VMware Cloud SDDC 네트워크에 대한 보안 통신을 제공합니다. VMware Cloud SDDC 네트워크 내에서 NSX 추적 흐름을 사용하여 사용된 규칙을 포함한 경로를 식별할 수 있습니다. 그런 다음 VPC 네트워크에서 네트워크 분석기를 사용하여 흐름 중에 사용되는 경로 테이블, 보안 그룹 및 네트워크 액세스 제어 목록을 포함한 경로를 식별할 수 있습니다.</block>
  <block id="bd6d688efed13ace07c5656a3de04479" category="doc">개요 - AWS 게스트 연결 스토리지 재해 복구</block>
  <block id="67b5a180b1adfc09bd2752e51613fea5" category="paragraph">이 섹션에서는 사용자가 NetApp 및 VMware와 함께 사용할 온프레미스 및 클라우드 환경을 확인, 구성 및 검증하도록 지원하는 지침을 제공합니다. 특히, 이 솔루션은 ONTAP AFF 온-프레미스 및 VMware 클라우드 및 클라우드용 AWS FSx ONTAP와 함께 VMware 게스트 연결 사용 사례에 중점을 둡니다. 이 솔루션은 재해 복구 시나리오에서 Oracle과 MS SQL의 두 가지 애플리케이션으로 입증되었습니다.</block>
  <block id="d48ec23d0c00af2c45aa4b1c24b412d8" category="summary">운영 사내 데이터 센터에서 재해가 발생할 경우 당사의 시나리오에서는 AWS의 VMware Cloud를 사용하여 Amazon Web Services 인프라에 있는 2차 사이트로 페일오버합니다. 가상 시스템과 사내 ONTAP 클러스터에 더 이상 액세스할 수 없다고 가정합니다. 또한, SnapCenter 및 Veeam 가상 머신을 더 이상 액세스할 수 없으며 2차 사이트에서 다시 구축해야 합니다.</block>
  <block id="7388404ef116c3ff812bfd290b094d9e" category="doc">페일오버</block>
  <block id="03c450647cafbb7294b1d6fef9f2476f" category="section-title">운영 사이트에서 재해가 발생합니다</block>
  <block id="ff36edd2e7e49fd0a40827688d2f4d8c" category="paragraph">이 섹션에서는 클라우드 환경으로의 인프라 페일오버에 대해 다루며 다음 주제를 다룹니다.</block>
  <block id="9555d80191893a5b671187e1a859f379" category="list-text">SnapCenter 데이터베이스 복원 새 SnapCenter 서버가 설정된 후, 보조 FSx 스토리지가 기본 스토리지 장치가 될 수 있도록 MySQL 데이터베이스 및 구성 파일을 복원하고 데이터베이스를 재해 복구 모드로 전환합니다.</block>
  <block id="2f2ee1d320a4d17fae8f4228f0a0c17a" category="list-text">Veeam Backup &amp; Replication을 사용하여 애플리케이션 가상 머신을 복구합니다. VM 백업이 포함된 S3 스토리지를 연결하고 백업을 가져온 다음 AWS의 VMware Cloud로 복원합니다.</block>
  <block id="8509dc3cb04f91e9c6eb62971df36219" category="list-text">SnapCenter를 사용하여 SQL Server 응용 프로그램 데이터를 복원합니다.</block>
  <block id="81e920a3cfad3020139d281a7be1093a" category="list-text">SnapCenter를 사용하여 Oracle 애플리케이션 데이터를 복구합니다.</block>
  <block id="7c3080588178d0f5908a96d9e20be883" category="section-title">SnapCenter 데이터베이스 복원 프로세스</block>
  <block id="86c580a0ed766eb38c0ef43f08d425e5" category="paragraph">SnapCenter는 MySQL 데이터베이스 및 구성 파일의 백업 및 복원을 허용하여 재해 복구 시나리오를 지원합니다. 이를 통해 관리자는 사내 데이터 센터에서 SnapCenter 데이터베이스의 정기적인 백업을 유지하고 나중에 해당 데이터베이스를 보조 SnapCenter 데이터베이스로 복원할 수 있습니다.</block>
  <block id="ee1f8cb839e16951e7004e4047603101" category="paragraph">원격 SnapCenter 서버에서 SnapCenter 백업 파일에 액세스하려면 다음 단계를 수행하십시오.</block>
  <block id="0b5c65b05530328f42d8b65f68657302" category="list-text">FSx 클러스터에서 SnapMirror 관계를 중단하여 볼륨을 읽기/쓰기로 만듭니다.</block>
  <block id="dbfff075901e62d26ef1f316380d01f7" category="list-text">필요한 경우 CIFS 서버를 생성하고 복제된 볼륨의 연결 경로를 가리키는 CIFS 공유를 생성합니다.</block>
  <block id="26b0d9d510f38125c4de3a7b68569b29" category="list-text">xcopy를 사용하여 보조 SnapCenter 시스템의 로컬 디렉토리에 백업 파일을 복사합니다.</block>
  <block id="fa0138f778767381d2b0af9bdabad76e" category="list-text">SnapCenter v4.6을 설치합니다.</block>
  <block id="736c8557bca1ad901b82efb5e946a527" category="list-text">SnapCenter 서버의 FQDN이 원래 서버와 동일한지 확인합니다. 이 작업은 DB 복원이 성공하려면 필요합니다.</block>
  <block id="6f77488ce3ed6db6422cddaa1e4cbf8f" category="paragraph">복원 프로세스를 시작하려면 다음 단계를 수행하십시오.</block>
  <block id="7220866a3d1d3ba6c1aef39d02d64b1f" category="list-text">보조 SnapCenter 서버의 Swagger API 웹 페이지로 이동하고 이전 지침에 따라 인증 토큰을 얻습니다.</block>
  <block id="a5214e49691510795c98aad40874caa1" category="list-text">Swagger 페이지의 Disaster Recovery 섹션으로 이동하여 "/4.6/disasterrecovery/server/restore"를 선택하고 Try It Out을 클릭합니다.</block>
  <block id="3c235173c5db1037212eff5e3a152a26" category="paragraph"><block ref="3c235173c5db1037212eff5e3a152a26" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d76d7bbb789675126fd1e9a0bf929635" category="list-text">인증 토큰을 붙여 넣고 SmDRResterRequest 섹션에서 백업 이름과 보조 SnapCenter 서버의 로컬 디렉터리를 붙여 넣습니다.</block>
  <block id="34938ae261d31ae76af2e4369a2c8b0a" category="paragraph"><block ref="34938ae261d31ae76af2e4369a2c8b0a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4579e653c0e46ed15c466f496b60b0f3" category="list-text">실행 버튼을 선택하여 복원 프로세스를 시작합니다.</block>
  <block id="fcbb767c97ce18f6b82f09bf8ea9c993" category="list-text">SnapCenter에서 모니터 섹션으로 이동하여 복구 작업의 진행률을 확인합니다.</block>
  <block id="8fa0520efd67da15041467d3126133a7" category="paragraph"><block ref="8fa0520efd67da15041467d3126133a7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d67615193bee26cd99be6b7ea889f065" category="paragraph"><block ref="d67615193bee26cd99be6b7ea889f065" category="inline-image-macro-rx" type="image"></block></block>
  <block id="49b4fb23e31b4cd2d12434ce03b24134" category="list-text">보조 스토리지에서 SQL Server 복원을 사용하려면 SnapCenter 데이터베이스를 재해 복구 모드로 전환해야 합니다. 이 작업은 별도의 작업으로 수행되며 Swagger API 웹 페이지에서 시작됩니다.</block>
  <block id="35afa1a915c7752e139ef7b0362596a6" category="list-text">Disaster Recovery(재해 복구) 섹션으로 이동하여 '/4.6/Disasterrecovery/storage(4.6/Disasterrecovery/storage)'를 클릭합니다.</block>
  <block id="7633ff4043449878afbd5ca925faa5b1" category="list-text">사용자 인증 토큰을 붙여 넣습니다.</block>
  <block id="5fb3d7404a8cc43eb5e120b4e22fe16d" category="list-text">SmSetDisasterRecoverySettingsRequest 섹션에서 EnableDisasterRecover 를 true 로 변경합니다.</block>
  <block id="e7470af265e05d2efa8863c259541c2b" category="list-text">실행 을 클릭하여 SQL Server에 대한 재해 복구 모드를 활성화합니다.</block>
  <block id="8579e283f02173e29df7090294128589" category="paragraph"><block ref="8579e283f02173e29df7090294128589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4a08ff9e7fd1ec468bc55c7ba9df45" category="admonition">추가 절차에 대한 설명을 참조하십시오.</block>
  <block id="5b13229945c45439c072dc9c270e8177" category="inline-link-macro">AWS에서 VMC를 사용한 재해 복구(게스트 연결)</block>
  <block id="866b55fdae1463f1934c300853ecefe2" category="list-text"><block ref="866b55fdae1463f1934c300853ecefe2" category="inline-link-macro-rx"></block></block>
  <block id="38631d978812c49b6f395a78becd9750" category="summary">다음 프로세스에서는 사내 사이트가 작동 불가능한 재해 발생 시 AWS의 VMware Cloud Services에서 Oracle 애플리케이션 데이터를 복구하는 방법에 대한 지침을 제공합니다.</block>
  <block id="c8ae03dc8bb68d2ad3e63a9126f795e6" category="doc">Oracle 애플리케이션 데이터를 복구합니다</block>
  <block id="18ed07dc9f8533a3a2cf047292765486" category="paragraph">복구 단계를 계속하려면 다음 필수 구성 요소를 완료하십시오.</block>
  <block id="d55274d1968c306eb025dc5e6eca42b4" category="list-text">Veeam Full Restore를 사용하여 Oracle Linux 서버 VM을 VMware Cloud SDDC로 복구했습니다.</block>
  <block id="66d808fa42d45f6883d1a223ee26eb0c" category="list-text">보조 SnapCenter 서버가 설정되었으며 이 섹션에 설명된 단계를 사용하여 SnapCenter 데이터베이스 및 구성 파일이 복원되었습니다 <block ref="f1b6dca3014749c436758b70cc0d8f7f" category="inline-link-macro-rx"></block></block>
  <block id="b723df724fefe9f2021e7bb7bd8a57d0" category="section-title">Oracle 복원을 위해 FSx 구성 - SnapMirror 관계를 끊습니다</block>
  <block id="ab26994a6aef07f6a796a6109f921a28" category="paragraph">FSxN 인스턴스에서 호스팅되는 보조 스토리지 볼륨을 Oracle 서버에서 액세스할 수 있도록 하려면 먼저 기존 SnapMirror 관계를 해제해야 합니다.</block>
  <block id="d80c0676712ecc3e8d717347b9a0113a" category="list-text">FSx CLI에 로그인한 후 다음 명령을 실행하여 올바른 이름으로 필터링된 볼륨을 확인합니다.</block>
  <block id="c534b90634ff37c01e77b058859f2a29" category="paragraph"><block ref="c534b90634ff37c01e77b058859f2a29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="771b4d8e9d4a9f112068c45d013c2940" category="list-text">다음 명령을 실행하여 기존 SnapMirror 관계를 중단하십시오.</block>
  <block id="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="paragraph"><block ref="60c89c7c11b1e5d09c8f7d6fcf1b4255" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5a4480a103abe04e17eca64a771420a8" category="list-text">Amazon FSx 웹 클라이언트에서 junction-path를 업데이트합니다.</block>
  <block id="a3848e78db2c915e6ec7913bc0779a86" category="paragraph"><block ref="a3848e78db2c915e6ec7913bc0779a86" category="inline-image-macro-rx" type="image"></block></block>
  <block id="467332d89a649add4b0efb09dd2386c5" category="list-text">접합 경로 이름을 추가하고 업데이트 를 클릭합니다. Oracle 서버에서 NFS 볼륨을 마운트할 때 이 연결 경로를 지정합니다.</block>
  <block id="7a522c1cba5b4c9df88cb71a944d5efd" category="paragraph"><block ref="7a522c1cba5b4c9df88cb71a944d5efd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="974ee05a635ebfcae6d6f6aa6f5da0b9" category="section-title">Oracle Server에서 NFS 볼륨을 마운트합니다</block>
  <block id="f3677efe1cf868a895b6634743ae53cd" category="paragraph">Cloud Manager에서 Oracle 데이터베이스 파일 및 로그가 포함된 NFS 볼륨을 마운트하기 위한 올바른 NFS LIF IP 주소를 사용하여 마운트 명령을 얻을 수 있습니다.</block>
  <block id="5ecb7cb864e3f6e77b9ae7264115942e" category="list-text">Cloud Manager에서 FSx 클러스터의 볼륨 목록에 액세스합니다.</block>
  <block id="dc33973d3bef150b7e3be67c8acbde9a" category="paragraph"><block ref="dc33973d3bef150b7e3be67c8acbde9a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cf957a98bd60352ec8312937f87b49dc" category="list-text">작업 메뉴에서 마운트 명령을 선택하여 Oracle Linux 서버에서 사용할 마운트 명령을 보고 복사합니다.</block>
  <block id="42ae5bd08cec138b52386d868d92bcfe" category="paragraph"><block ref="42ae5bd08cec138b52386d868d92bcfe" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8026151c7c8dc5002a8652cdd0ac0610" category="paragraph"><block ref="8026151c7c8dc5002a8652cdd0ac0610" category="inline-image-macro-rx" type="image"></block></block>
  <block id="91d32453a4c3b285d62be2bc5eb3d24c" category="list-text">Oracle Linux Server에 NFS 파일 시스템을 마운트합니다. NFS 공유를 마운트하는 디렉토리가 Oracle Linux 호스트에 이미 있습니다.</block>
  <block id="3f7f1270061c2e231f722bfd466cec0d" category="list-text">Oracle Linux 서버에서 mount 명령을 사용하여 NFS 볼륨을 마운트합니다.</block>
  <block id="5cafad6c0970ad9fd32dd43eb98a7d6f" category="paragraph">Oracle 데이터베이스와 연결된 각 볼륨에 대해 이 단계를 반복합니다.</block>
  <block id="264225a103d86a5e552aebab3ee7dd3f" category="admonition">재부팅 시 NFS 마운트를 영구적으로 만들려면 '/etc/fstab' 파일을 편집하여 마운트 명령을 포함합니다.</block>
  <block id="2095b7305d1da91dff871c600b482eb9" category="list-text">Oracle 서버를 재부팅합니다. Oracle 데이터베이스는 정상적으로 시작되어 사용할 수 있어야 합니다.</block>
  <block id="997d17d93cccb6709985c79ccc870db0" category="doc">재해 복구를 위한 SnapCenter 데이터베이스 백업</block>
  <block id="9cb03f5cfb57a7f655c8a28ca64ae0d1" category="paragraph">SnapCenter를 사용하면 재해 발생 시 SnapCenter 서버를 복구하기 위해 기본 MySQL 데이터베이스와 구성 데이터를 백업 및 복구할 수 있습니다. 이 솔루션을 위해 VPC에 상주하는 AWS EC2 인스턴스에서 SnapCenter 데이터베이스 및 구성을 복구했습니다. 이 단계에 대한 자세한 내용은 을 참조하십시오<block ref="85e9a4a54f289ebdfa6c4169fb097d15" category="inline-link-rx"></block>.</block>
  <block id="46137d274838eaef40c110eac160dabc" category="section-title">SnapCenter 백업 사전 요구 사항</block>
  <block id="2fe071c4476effcd542a95a182832104" category="paragraph">SnapCenter 백업에 필요한 사전 요구 사항은 다음과 같습니다.</block>
  <block id="be2b68df1cb3db2a8f1393a8c89a5c30" category="list-text">백업된 데이터베이스 및 구성 파일을 찾기 위해 사내 ONTAP 시스템에서 생성된 볼륨 및 SMB 공유입니다.</block>
  <block id="1a9ee88991730f920252a1445a467c77" category="list-text">사내 ONTAP 시스템과 AWS 계정의 FSx 또는 CVO 간 SnapMirror 관계 이 관계는 백업된 SnapCenter 데이터베이스 및 구성 파일이 포함된 스냅샷을 전송하는 데 사용됩니다.</block>
  <block id="3c0e70fa217603c0388de21f978923f3" category="list-text">EC2 인스턴스 또는 VMware Cloud SDDC의 VM에 클라우드 계정에 설치된 Windows Server</block>
  <block id="328228524f87469e005c8944ad925402" category="list-text">VMware 클라우드의 Windows EC2 인스턴스 또는 VM에 설치된 SnapCenter</block>
  <block id="0038f6b75b40b9c37893544119ad7ca4" category="section-title">SnapCenter 백업 및 복원 프로세스 요약</block>
  <block id="f4644dc8d01e527218cd1fc0daa6af40" category="list-text">백업 db 및 config 파일을 호스팅하기 위해 사내 ONTAP 시스템에 볼륨을 생성합니다.</block>
  <block id="c4232930a0fc8d0f9a5e1a16db36a816" category="list-text">온프레미스와 FSx/CVO 간에 SnapMirror 관계를 설정합니다.</block>
  <block id="3e1461fe483fb58c7a6642074cb71d8d" category="list-text">SMB 공유를 마운트합니다.</block>
  <block id="dd5b017c2cafc1394e2d7ab7081652e3" category="list-text">API 작업을 수행하기 위한 Swagger 인증 토큰을 검색합니다.</block>
  <block id="51263d7f64b29b2b3bd6730068e64a27" category="list-text">DB 복구 프로세스를 시작합니다.</block>
  <block id="23011a36184705e18919c3e5560fd514" category="list-text">xcopy 유틸리티를 사용하여 db 및 config 파일 로컬 디렉토리를 SMB 공유에 복사합니다.</block>
  <block id="b84dd176bda6a6d30c5cb8901a8bf5b1" category="list-text">FSx에서 ONTAP 볼륨의 클론을 생성합니다(사내에서 SnapMirror를 통해 복사됨).</block>
  <block id="1a3f92b9c5623f19d294ef2907d98cc8" category="list-text">FSx에서 EC2/VMware Cloud로 SMB 공유를 마운트합니다.</block>
  <block id="87d37b3dfd2b98df04243247ebff4325" category="list-text">SMB 공유에서 로컬 디렉토리로 복구 디렉토리를 복사합니다.</block>
  <block id="fd516b8b37d528453c538c9022d6d9db" category="list-text">Swagger에서 SQL Server 복원 프로세스를 실행합니다.</block>
  <block id="63c6890e4065bde44f84394d274e05db" category="section-title">SnapCenter 데이터베이스 및 구성을 백업합니다</block>
  <block id="493aa18049179f21c66cc95e36c19670" category="paragraph">SnapCenter는 REST API 명령을 실행하기 위한 웹 클라이언트 인터페이스를 제공합니다. Swagger를 통해 REST API에 액세스하는 방법에 대한 자세한 내용은 에서 SnapCenter 설명서를 참조하십시오<block ref="2a9068db8cebf7672f374b2eb0a0c5ec" category="inline-link-rx"></block>.</block>
  <block id="911dd02ad9a62d89e83d996753811c7b" category="section-title">Swagger에 로그인하고 인증 토큰을 얻습니다</block>
  <block id="820336a66e164f408946dd8235833c07" category="paragraph">Swagger 페이지로 이동한 후 인증 토큰을 검색하여 데이터베이스 복원 프로세스를 시작해야 합니다.</block>
  <block id="99899958b071bcb677dc5a5b24f1b2a3" category="list-text">https://&lt;SnapCenter 서버 IP &gt;:8146/swagger/_에서 SnapCenter Swagger API 웹 페이지에 액세스합니다.</block>
  <block id="20f069ff72fb03614b867af722c7c40b" category="paragraph"><block ref="20f069ff72fb03614b867af722c7c40b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5ad3b9c1075f899242a74f969cbb12fa" category="list-text">인증 섹션을 확장하고 시험 사용 을 클릭합니다.</block>
  <block id="5ffa75198edfa553c162f3b9945a23a0" category="paragraph"><block ref="5ffa75198edfa553c162f3b9945a23a0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="41402cfc6490d3bf582b8a14ff8bfcbe" category="list-text">UserOperationContext 영역에서 SnapCenter 자격 증명 및 역할을 입력하고 실행 을 클릭합니다.</block>
  <block id="2e1aa1ca38ffa5e45db5da3276238eac" category="paragraph"><block ref="2e1aa1ca38ffa5e45db5da3276238eac" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18e649ac855810eb5b8a774b3fab5f5c" category="list-text">아래의 응답 본문에서 토큰을 볼 수 있습니다. 백업 프로세스를 실행할 때 인증을 위해 토큰 텍스트를 복사합니다.</block>
  <block id="32d5d8e51cafb2b4d387df356fe41955" category="paragraph"><block ref="32d5d8e51cafb2b4d387df356fe41955" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a1a34831e3e917e934e09eb9402b4d6" category="section-title">SnapCenter 데이터베이스 백업을 수행합니다</block>
  <block id="3d8b8b9e239f00e8fbddb0437a5c5659" category="paragraph">그런 다음 Swagger 페이지의 Disaster Recovery 영역으로 이동하여 SnapCenter 백업 프로세스를 시작합니다.</block>
  <block id="5fd8196e8aa6d444acf7a65f639a6085" category="list-text">재해 복구 영역을 클릭하여 확장합니다.</block>
  <block id="7ec34046162f53040f7ca7c8a78c4b17" category="paragraph"><block ref="7ec34046162f53040f7ca7c8a78c4b17" category="inline-image-macro-rx" type="image"></block></block>
  <block id="14245d6803dae3fc2cab0fe1fd18565e" category="list-text">'/4.6/disasterrecovery/server/backup' 섹션을 확장하고 try it을 클릭합니다.</block>
  <block id="b5f8e4e588ebd761591d02cb02f2a5dd" category="paragraph"><block ref="b5f8e4e588ebd761591d02cb02f2a5dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aad454707845382aef2a040acc30177a" category="list-text">SmDRBackupRequest 섹션에서 올바른 로컬 대상 경로를 추가하고 Execute 를 선택하여 SnapCenter 데이터베이스 및 구성의 백업을 시작합니다.</block>
  <block id="949b4a3f3887b0d48d721acc506fb82e" category="admonition">백업 프로세스에서는 NFS 또는 CIFS 파일 공유에 직접 백업할 수 없습니다.</block>
  <block id="ef97a1ec7f6c4c7d84f053938ce48398" category="paragraph"><block ref="ef97a1ec7f6c4c7d84f053938ce48398" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f638b2ae24161dbfa69705afbf177bd" category="section-title">SnapCenter에서 백업 작업을 모니터링합니다</block>
  <block id="03322e4ba2c5a628edfa27eb5a52741b" category="paragraph">데이터베이스 복원 프로세스를 시작할 때 SnapCenter에 로그인하여 로그 파일을 검토합니다. 모니터 섹션에서 SnapCenter 서버 재해 복구 백업의 세부 정보를 볼 수 있습니다.</block>
  <block id="82c39eed34769992987a93ed6b12a97f" category="paragraph"><block ref="82c39eed34769992987a93ed6b12a97f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ac753614a3d47f00caddc06fd2dc281f" category="section-title">XCOPY 유틸리티를 사용하여 SMB 공유에 데이터베이스 백업 파일을 복사합니다</block>
  <block id="d2a0be1c4b7f47c09b612fb78a28adee" category="paragraph">그런 다음 SnapCenter 서버의 로컬 드라이브에서 데이터를 SnapMirror로 복제하는 데 사용되는 CIFS 공유로 AWS의 FSx 인스턴스에 있는 보조 위치로 백업을 이동해야 합니다. 파일 권한을 유지하는 특정 옵션과 함께 xcopy를 사용합니다.</block>
  <block id="fa13c8e8caa807a78a4301f1cfa0ec2f" category="paragraph">관리자 권한으로 명령 프롬프트를 엽니다. 명령 프롬프트에서 다음 명령을 입력합니다.</block>
  <block id="0b55c8177ba39a322f35975c0c3bd3ba" category="section-title">기술 및 지식</block>
  <block id="b1adf7ef88c9564fb1f6c97bf42dca5c" category="paragraph">Cloud Volumes Service for AWS에 액세스하려면 다음 기술 및 정보가 필요합니다.</block>
  <block id="7b83d82f99126fdb6efaa234f31683f5" category="list-text">VMware 및 ONTAP 사내 환경에 대한 액세스 및 지식</block>
  <block id="39a8abb00c1f9d982e3a29b4baec67f2" category="list-text">VMware Cloud 및 AWS에 대한 지식 및 액세스</block>
  <block id="eaad72d3a50e4be3e11d36792eb96d62" category="list-text">AWS 및 Amazon FSx ONTAP에 대한 액세스 및 지식</block>
  <block id="25e65b652ca97821fa49aa9571b2b54a" category="list-text">SDDC 및 AWS 리소스에 대한 지식</block>
  <block id="18334368a9f4fce73ca297bdd4be123a" category="list-text">온프레미스 리소스와 클라우드 리소스 간의 네트워크 연결에 대한 지식</block>
  <block id="f917b7afd251e67bbdf50fa466a9918e" category="list-text">재해 복구 시나리오에 대한 작업 지식</block>
  <block id="77d0638c77df28bd77c058b3da580702" category="list-text">VMware에 구축된 애플리케이션에 대한 작업 지식</block>
  <block id="9ef15415f400d1d1a7b2c4d3e8879124" category="section-title">관리</block>
  <block id="99be46c7a7d783d36552f0f11df8cd5e" category="paragraph">온프레미스 또는 클라우드에서 리소스와 상호 작용하든, 사용자와 관리자는 자신의 권한에 따라 필요할 때 필요한 리소스를 프로비저닝할 수 있는 기능과 권한을 가지고 있어야 합니다. 성공적인 하이브리드 클라우드 구축을 위해서는 ONTAP, VMware를 비롯한 온프레미스 시스템과 VMware 클라우드 및 AWS를 포함한 클라우드 리소스에 대한 역할 및 사용 권한의 상호 작용이 무엇보다 중요합니다.</block>
  <block id="e5d4baff0167d033367d67396f5608f6" category="paragraph">VMware 및 ONTAP On-Premises와 VMware Cloud on AWS 및 FSx ONTAP를 사용하여 DR 솔루션을 구성하려면 다음 관리 작업이 필요합니다.</block>
  <block id="e6833d473d476a99c7ec8095a5bfe8df" category="list-text">다음을 프로비저닝할 수 있는 역할 및 계정:</block>
  <block id="297c8005623a7f22aad3d141e82fabb5" category="list-text">ONTAP 스토리지 리소스</block>
  <block id="864d5ea26def3831e53731dc58671672" category="list-text">VMware VM, 데이터 저장소 등</block>
  <block id="61b883742c54e0000affbbf61cecb00a" category="list-text">AWS VPC 및 보안 그룹</block>
  <block id="cae667335742a0f5e8a41bb0caa73e4c" category="list-text">사내 VMware 환경 및 ONTAP 프로비저닝</block>
  <block id="7098bf260c6533f1ebf70f5b9bb041b0" category="list-text">VMware 클라우드 환경</block>
  <block id="eca5f84e846df7323fccde83f4ff44d5" category="list-text">ONTAP 파일 시스템용 FSx에 대한 Amazon</block>
  <block id="29b34be64d30233d5ed6d4f314db7483" category="list-text">사내 환경과 AWS 간의 연결</block>
  <block id="c89c49a63ff46b95a3a1930093133477" category="list-text">AWS VPC 연결</block>
  <block id="9301a9f205ba883a750d8c90b33c2bbc" category="paragraph">VMware 가상 환경에는 다음 그림과 같이 ESXi 호스트, VMware vCenter Server, NSX 네트워킹 및 기타 구성 요소의 라이센스가 포함됩니다. 모든 구성 요소는 서로 다른 방식으로 라이센스가 부여되므로 기본 구성 요소가 사용 가능한 라이센스 용량을 어떻게 소비하는지 이해하는 것이 중요합니다.</block>
  <block id="42094e9e4a0f05012b8d6753300a1657" category="section-title">ESXi 호스트</block>
  <block id="1d50ac197ef032b2bc2e46d8e2e64598" category="paragraph">VMware 환경의 컴퓨팅 호스트는 ESXi와 함께 구축됩니다. 다양한 용량 계층에서 vSphere로 라이센스를 부여하면 가상 머신은 각 호스트의 물리적 CPU와 해당 기능을 활용할 수 있습니다.</block>
  <block id="43e02e05b2879c1406a010bf6a28f8f7" category="section-title">VMware vCenter를 참조하십시오</block>
  <block id="05f79f8867c02153173be8abc21ae61a" category="paragraph">ESXi 호스트 및 스토리지 관리는 vCenter Server를 사용하는 VMware 관리자가 사용할 수 있는 다양한 기능 중 하나입니다. VMware vCenter 7.0부터 VMware vCenter의 세 가지 에디션을 사용할 수 있습니다.</block>
  <block id="f958b6a3f3407168711a82d395fb4ac7" category="list-text">vCenter Server Essentials 를 참조하십시오</block>
  <block id="a0301fdeb61b558341af142a9f2dd3aa" category="list-text">vCenter Server Foundation을 참조하십시오</block>
  <block id="62a846eee92143dee42cae576208c443" category="list-text">vCenter Server Standard를 참조하십시오</block>
  <block id="e44df2b6e256fb033bf0234d942a29f3" category="paragraph">VMware NSX는 관리자에게 고급 기능을 활성화하는 데 필요한 유연성을 제공합니다. 기능은 라이센스가 부여된 NSX-T Edition 버전에 따라 활성화됩니다.</block>
  <block id="9e8b160226c9fe22a910c782ce5076e2" category="list-text">전문가입니다</block>
  <block id="9b6545e4cea9b4ad4979d41bb9170e2b" category="list-text">고급</block>
  <block id="1330271d87fae19afa4e7be5cd94b9f8" category="list-text">원격 사무소/지사</block>
  <block id="88793829da8796f676eaebd57e42009d" category="paragraph">NetApp ONTAP 라이센싱은 관리자가 NetApp 스토리지 내의 다양한 기능에 액세스하는 방법을 나타냅니다. 라이센스는 하나 이상의 소프트웨어 사용 권한의 기록입니다. 라이센스 코드라고도 하는 라이센스 키를 설치하면 스토리지 시스템에서 특정 기능 또는 서비스를 사용할 수 있습니다. 예를 들어, ONTAP는 모든 주요 업계 표준 클라이언트 프로토콜(NFS, SMB, FC, FCoE, iSCSI, NVMe/FC) 라이센스를 통해 제공됩니다.</block>
  <block id="90a29bf269cfe6c256d42b29776d14dd" category="paragraph">Data ONTAP 기능 라이센스는 여러 기능 또는 단일 기능을 포함하는 패키지로 발급됩니다. 패키지에는 라이센스 키가 필요하며, 키를 설치하면 패키지의 모든 기능에 액세스할 수 있습니다.</block>
  <block id="e4b843c32b9db50414c1dfbad0c4d1c0" category="paragraph">라이센스 유형은 다음과 같습니다.</block>
  <block id="0f00a6a817b378adf16de8d25fbf24fa" category="list-text">* 노드 잠김 라이센스. * 노드 잠김 라이센스를 설치하면 노드에 라이센스가 부여된 기능이 부여됩니다. 클러스터에 라이센스가 부여된 기능을 사용하려면 해당 기능에 대해 하나 이상의 노드에 라이센스가 있어야 합니다.</block>
  <block id="52db1a3edfedfc7015c35209e22f04c2" category="list-text">* 마스터/사이트 라이센스. * 마스터 또는 사이트 라이센스는 특정 시스템 일련 번호에 연결되지 않습니다. 사이트 라이센스를 설치하면 클러스터의 모든 노드에 라이센스가 부여된 기능이 부여됩니다.</block>
  <block id="b2aa6f86c442a3ce1bedb4a83498fcc6" category="list-text">* 데모/임시 사용권. * 데모 또는 임시 사용권은 일정 시간이 지나면 만료됩니다. 이 라이센스를 사용하면 사용 권한을 구입하지 않고도 특정 소프트웨어 기능을 사용할 수 있습니다.</block>
  <block id="c6009ee65fbe56a5eed91a0a06f3a1b5" category="list-text">* 용량 라이센스(ONTAP Select 및 FabricPool에만 해당). * ONTAP Select 인스턴스는 사용자가 관리하려는 데이터 양에 따라 라이센스가 부여됩니다. ONTAP 9.4부터 FabricPool를 사용하려면 타사 스토리지 계층(예: AWS)과 함께 용량 라이센스를 사용해야 합니다.</block>
  <block id="13b92bafad23a87622890420ed0b860b" category="paragraph">SnapCenter에서는 데이터 보호 작업을 위해 여러 개의 라이센스가 필요합니다. 설치하는 SnapCenter 라이센스 유형은 스토리지 환경과 사용하려는 기능에 따라 다릅니다. SnapCenter Standard 라이센스는 애플리케이션, 데이터베이스, 파일 시스템 및 가상 머신을 보호합니다. SnapCenter에 스토리지 시스템을 추가하기 전에 하나 이상의 SnapCenter 라이센스를 설치해야 합니다.</block>
  <block id="c2aa46e5e57aae7e4f4c969c417f1238" category="paragraph">애플리케이션, 데이터베이스, 파일 시스템 및 가상 머신을 보호하려면 FAS 또는 AFF 스토리지 시스템에 표준 컨트롤러 기반 라이센스가 설치되어 있거나 ONTAP Select 및 Cloud Volumes ONTAP 플랫폼에 표준 용량 기반 라이센스가 설치되어 있어야 합니다.</block>
  <block id="14c2700881a435ad41069af9e8ee6f85" category="paragraph">이 솔루션에 대한 다음 SnapCenter 백업 사전 요구 사항을 참조하십시오.</block>
  <block id="96b3493b2e1844322d28e845c314e10b" category="list-text">백업된 데이터베이스 및 구성 파일을 찾기 위해 사내 ONTAP 시스템에서 생성된 볼륨 및 SMB 공유입니다.</block>
  <block id="f39931d0fa94c8e0cb577222f77fb09d" category="list-text">사내 ONTAP 시스템과 AWS 계정의 FSx 또는 CVO 간 SnapMirror 관계 백업된 SnapCenter 데이터베이스 및 구성 파일이 포함된 스냅샷을 전송하는 데 사용됩니다.</block>
  <block id="d2727816fa1087ddac7dff69e35c5536" category="section-title">MS SQL</block>
  <block id="f9e005542c2e103eede9db2dfe82bdc7" category="paragraph">이 솔루션 검증의 일부로 MS SQL을 사용하여 재해 복구를 시연합니다.</block>
  <block id="ed94f710e6ae715e2f17c5670d6bf092" category="paragraph">MS SQL 및 NetApp ONTAP의 모범 사례에 대한 자세한 내용은 다음 웹 사이트를 참조하십시오<block ref="1ed6e40008e985821d1338a60f7ccab3" category="inline-link-rx"></block>.</block>
  <block id="877ee5bcf7f0335c93ce9f231f44f195" category="paragraph">이 솔루션 검증의 일환으로, NetApp은 Oracle을 사용하여 재해 복구를 시연합니다. Oracle 및 NetApp ONTAP 모범 사례에 대한 자세한 내용은 다음 웹 사이트를 참조하십시오<block ref="3b13b5361a3a7b7e48b79b29a907e9fc" category="inline-link-rx"></block>.</block>
  <block id="05241239c2e205951eabc51d0b39de96" category="section-title">Veeam을 선택합니다</block>
  <block id="cf575d98d37c3423857f91c318d883e7" category="paragraph">이 솔루션 검증의 일부로 Veeam을 사용하여 재해 복구를 시연합니다. Veeam 및 NetApp ONTAP의 모범 사례에 대한 자세한 내용은 를 참조하십시오<block ref="69659c9961c1e42b0f8742562f24fdfa" category="inline-link-rx"></block>.</block>
  <block id="59288c543af9b26fa84b24054d3be8dc" category="paragraph">다음 작업을 수행할 수 있어야 합니다.</block>
  <block id="f35a1ddfb2f9b2cac114bd32ce5bbbab" category="list-text">도메인 서비스 배포 및 구성</block>
  <block id="71877c1e84cfa72072c46494d86a8ee7" category="list-text">특정 VPC에 애플리케이션 요구 사항당 FSx ONTAP를 구축합니다.</block>
  <block id="9135a2c6ac5c27bd10c50337c5a89f26" category="list-text">FSx ONTAP의 트래픽을 허용하도록 AWS 컴퓨팅 게이트웨이에서 VMware 클라우드를 구성합니다.</block>
  <block id="8a401f5d4b33a44bd1812ff7ead2248d" category="list-text">AWS 서브넷의 VMware Cloud와 FSx ONTAP 서비스가 구축된 AWS VPC 서브넷 간의 통신을 허용하도록 AWS 보안 그룹을 구성합니다.</block>
  <block id="2e31cdf7daad1ca06d6642765fa13252" category="section-title">VMware 클라우드</block>
  <block id="f7f38aee276941a8501ab3a4788fb838" category="list-text">AWS SDDC에서 VMware Cloud를 구성합니다.</block>
  <block id="08aa379cc2bcb108397d323bd5732f6c" category="section-title">Cloud Manager 계정 검증</block>
  <block id="17d24c2f3d504e509ec34ba87bfea6a5" category="paragraph">NetApp Cloud Manager로 리소스를 구축할 수 있어야 합니다. 다음 작업을 완료할 수 있는지 확인합니다.</block>
  <block id="2ee5d6132c6433861745857e6af68778" category="inline-link">Cloud Central에 가입하십시오</block>
  <block id="604e59aa26a0b211909e4b9590685eb1" category="list-text"><block ref="35c2f2ba3f068c3df62b94b779d38cce" category="inline-link-rx"></block> 아직 없는 경우</block>
  <block id="e7ef0ccc08f963a97d6ab9c3aabc5081" category="inline-link">Cloud Manager에 로그인합니다</block>
  <block id="5ec677c5c014e60203e82de8cbed20e4" category="list-text"><block ref="77549d8461eff5ea7726f72f7e171b7c" category="inline-link-rx"></block>.</block>
  <block id="78e80a35b7d01f404398eea432dd9654" category="inline-link">작업 영역 및 사용자를 설정합니다</block>
  <block id="6693afd5aef7c87168fb40b34d61e795" category="list-text"><block ref="491866e862424f2a10f9441373484bc0" category="inline-link-rx"></block>.</block>
  <block id="e7a9cd1dc4bf0c230d0684e18369d70d" category="inline-link">커넥터를 작성합니다</block>
  <block id="821d88deb5e031a9587e5a8e00abe556" category="list-text"><block ref="b3797d3b448c35004d47db91b5cf65cf" category="inline-link-rx"></block>.</block>
  <block id="4c0f2b07e3034da6a2b901197cec7210" category="paragraph">AWS 계정이 있는 후에는 다음 작업을 수행할 수 있어야 합니다.</block>
  <block id="7d8207e3bfa061fd6c5b1389d79e23e4" category="list-text">NetApp ONTAP 파일 시스템에 Amazon FSx를 프로비저닝할 수 있는 IAM 관리 사용자를 생성합니다.</block>
  <block id="7984cdcb84b94f3ec5af3c2aa0bc9f9c" category="section-title">구성 사전 요구 사항</block>
  <block id="799b279302dc2106f49a0c61994a42a1" category="paragraph">고객이 사용하는 다양한 토폴로지를 고려할 때 이 섹션에서는 사내에서 클라우드 리소스로의 통신을 지원하는 데 필요한 포트를 중점적으로 다룹니다.</block>
  <block id="dee55c33a91e43d371aa8eab0ee8968e" category="section-title">필수 포트 및 방화벽 고려 사항</block>
  <block id="34e0f9db6d0a94f20e464420fb481570" category="paragraph">다음 표에는 인프라 전체에서 사용해야 하는 포트가 설명되어 있습니다.</block>
  <block id="28c5fdd36289c2258f08118f41c54729" category="paragraph">Veeam Backup &amp; Replication 소프트웨어에 필요한 포트의 전체 목록을 보려면 다음 단계를 따르십시오<block ref="2a9b4a1873abbc6819ad7073e9ebc1a5" category="inline-link-rx"></block>.</block>
  <block id="2a975bb27423e33e6c65cb2e2b14db28" category="paragraph">SnapCenter의 포트 요구 사항에 대한 보다 포괄적인 목록은 을 참조하십시오<block ref="4939c26301b3a22bfb3c0a6725311b88" category="inline-link-rx"></block>.</block>
  <block id="8a042a39d5b3b0e7e0554c5af7abd76b" category="paragraph">다음 표에는 Microsoft Windows Server에 대한 Veeam 포트 요구사항이 나와 있습니다.</block>
  <block id="5da618e8e4b89c66fe86e32cdafde142" category="cell">보낸 사람</block>
  <block id="e12167aa0a7698e6ebc92b4ce3909b53" category="cell">를 선택합니다</block>
  <block id="60aaf44d4b562252c04db7f98497e9aa" category="cell">포트</block>
  <block id="f4c6f851b00d5518bf888815de279aba" category="cell">참고</block>
  <block id="52045ab804b1b913874ef04c2c3a2f69" category="cell">백업 서버</block>
  <block id="de6900dd0f213be9d369252ce490a1df" category="cell">Microsoft Windows 서버</block>
  <block id="b136ef5f6a01d816991fe3cf7a6ac763" category="cell">TCP</block>
  <block id="67f7fb873eaf29526a11a9b7ac33bfac" category="cell">445</block>
  <block id="3f8c4ba1591441de01c30814d6be96cb" category="cell">Veeam Backup &amp; Replication 구성 요소를 구축하는 데 필요한 포트입니다.</block>
  <block id="a34fcb59deecb10582ae58c505df58ba" category="cell">백업 프록시</block>
  <block id="fa3060edb66e6ff4507886f9912e1ab9" category="cell">6160</block>
  <block id="a615435ab6eb1aac4a4b4c4ebe2a89e9" category="cell">Veeam Installer Service에서 사용되는 기본 포트입니다.</block>
  <block id="480ddf908a09bb49e2eb46b2293d83e0" category="cell">백업 저장소</block>
  <block id="84c456c47f1859be98a88fa53ffca994" category="cell">2500에서 3500까지</block>
  <block id="1622c3ddec12802a4bc6cbb96c7b1b49" category="cell">데이터 전송 채널 및 로그 파일 수집에 사용되는 기본 포트 범위</block>
  <block id="a31f402016255891ea5a6010567d0c28" category="cell">서버를 마운트합니다</block>
  <block id="6aaba9a124857622930ca4e50f5afed2" category="cell">6162</block>
  <block id="f36e2d75f4071e4e994fdbc77c14ddb0" category="cell">Veeam Data Mover에서 사용되는 기본 포트입니다.</block>
  <block id="510f315f3436af1e5ec4cb22dd263070" category="admonition">작업에서 사용하는 모든 TCP 연결에 대해 이 범위의 포트 하나가 할당됩니다.</block>
  <block id="655a5fe10451fb66645cbcdec5034698" category="paragraph">다음 표에는 Linux Server의 Veeam 포트 요구사항이 나와 있습니다.</block>
  <block id="b5d9f1a9fbf0fb75f6765f140eb5774f" category="cell">Linux 서버</block>
  <block id="28c991d1c426febedd1596fd29a3f864" category="cell">콘솔에서 대상 Linux 호스트로 제어 채널로 사용되는 포트입니다.</block>
  <block id="a4fda10bbaa8015596c2c1c1dd6f1a36" category="paragraph">다음 표에는 Veeam Backup Server 포트 요구사항이 나와 있습니다.</block>
  <block id="4197adf45342f775880cf0b40b2bebe4" category="cell">HTTPS, TCP</block>
  <block id="ff48f6174c8c54c3faa04ebcf25b720d" category="cell">vCenter Server에 연결하는 데 사용되는 기본 포트입니다. 콘솔에서 대상 Linux 호스트로 제어 채널로 사용되는 포트입니다.</block>
  <block id="dad95acf5318650271f0853ca3c36a1a" category="cell">Veeam Backup &amp; Replication 구성 데이터베이스를 호스팅하는 Microsoft SQL Server</block>
  <block id="8fb5f8be2aa9d6c64a04e3ab9f63feee" category="cell">1443</block>
  <block id="dc0848552680aa2839c317b54853b6c8" category="cell">Veeam Backup &amp; Replication 구성 데이터베이스가 구축된 Microsoft SQL Server와의 통신에 사용되는 포트입니다(Microsoft SQL Server 기본 인스턴스를 사용하는 경우).</block>
  <block id="1cdaa0286d1e5b2da16bb4a4d56030e5" category="cell">모든 백업 서버의 이름 확인이 있는 DNS 서버</block>
  <block id="8643c8e2107ba86c47371e037059c4b7" category="cell">3389</block>
  <block id="2914ea759530f85f84d8d97088f4c0fb" category="cell">DNS 서버와 통신하는 데 사용되는 포트입니다</block>
  <block id="462cb0982d9c6d8b64cd1a92197cad0e" category="admonition">vCloud Director를 사용하는 경우 기본 vCenter Server에서 포트 443을 열어야 합니다.</block>
  <block id="5fd55c0224ae845943b259eaa37fa9de" category="paragraph">다음 표에는 Veeam Backup Proxy 포트 요구 사항이 나와 있습니다.</block>
  <block id="e564618b1a0f9a0e5b043f63d43fc065" category="cell">6210</block>
  <block id="06c6eec6c18e0d75ea5c6853a2397d90" category="cell">SMB 파일 공유 백업 중에 VSS 스냅샷을 생성하기 위해 Veeam Backup VSS Integration Service에서 사용하는 기본 포트입니다.</block>
  <block id="dd46e35ec3bd7632e2b6924b4ace5592" category="cell">vCenter 설정에서 사용자 지정할 수 있는 기본 VMware 웹 서비스 포트입니다.</block>
  <block id="67f0bc6c760260e8ecb1e44fc5337bd6" category="paragraph">다음 표에는 SnapCenter 포트 요구 사항이 나와 있습니다.</block>
  <block id="bd9f125b279a19f0d5b7f09c7d793d35" category="cell">포트 유형</block>
  <block id="d7ca8612b857419959ee2c089e5be08c" category="cell">SnapCenter 관리 포트</block>
  <block id="0e8433f9a404f1f3ba601c14b026d321" category="cell">HTTPS</block>
  <block id="202ed3792e2cfa7318b12ead83763c37" category="cell">8146</block>
  <block id="a1a3a7ab0e2e0b654e17bb8a2e57e9e5" category="cell">이 포트는 SnapCenter 클라이언트(SnapCenter 사용자)와 SnapCenter 서버 간의 통신에 사용됩니다. 플러그인 호스트에서 SnapCenter 서버로의 통신에도 사용됩니다.</block>
  <block id="18622e175ff22b2375f9cbc2314b3285" category="cell">SnapCenter SMCore 통신 포트입니다</block>
  <block id="bb68b5529560433e58ff13eb45622724" category="cell">이 포트는 SnapCenter 서버와 SnapCenter 플러그인이 설치된 호스트 간의 통신에 사용됩니다.</block>
  <block id="f79093a340ccf8139d6e585381acc44c" category="cell">Windows 플러그인 호스트, 설치</block>
  <block id="a1639b6147c7f85402852464ce33b9ae" category="cell">135, 445</block>
  <block id="4b790f3dbcd2d867091d8fbf3b63026f" category="cell">이러한 포트는 SnapCenter 서버와 플러그인이 설치되는 호스트 간의 통신에 사용됩니다. 설치 후 포트를 닫을 수 있습니다. 또한 Windows Instrumentation Services는 열려 있어야 하는 49152 ~ 65535 포트를 검색합니다.</block>
  <block id="da8fa0760683502b8b15e2d8f992b780" category="cell">Linux 플러그인 호스트, 설치</block>
  <block id="765553e6c7ac8592c389acb9878a050a" category="cell">SSH를 클릭합니다</block>
  <block id="e541d805fe886aded7cfb18984fba335" category="cell">이러한 포트는 SnapCenter 서버와 플러그인이 설치되는 호스트 간의 통신에 사용됩니다. 이 포트는 SnapCenter에서 플러그인 패키지 바이너리를 Linux 플러그인 호스트에 복사하는 데 사용됩니다.</block>
  <block id="8ffa3ad47599004a1c67f905da7456c0" category="cell">Windows/Linux용 SnapCenter 플러그인 패키지</block>
  <block id="0c0cfd9478c6551fbfe74a7acb6fc037" category="cell">8145</block>
  <block id="9b52abdc2eaa620c3f1c7588679b8764" category="cell">이 포트는 SnapCenter 플러그인이 설치된 SMCore와 호스트 간의 통신에 사용됩니다.</block>
  <block id="7c1239972879fe0b69b4bb6d5c9a743e" category="cell">VMware vSphere vCenter Server 포트입니다</block>
  <block id="4047860556fa008e56adfadd36f5b7af" category="cell">이 포트는 VMware vSphere용 SnapCenter 플러그인과 vCenter Server 간의 통신에 사용됩니다.</block>
  <block id="87db2cdf992c6481194f67a3c24f2d31" category="cell">VMware vSphere 포트용 SnapCenter 플러그인</block>
  <block id="edf0320adc8658b25ca26be5351b6c4a" category="cell">8144</block>
  <block id="397d2ce87a0d127486b8fa20c5f3cdb9" category="cell">이 포트는 vCenter vSphere 웹 클라이언트 및 SnapCenter 서버로부터 통신하는 데 사용됩니다.</block>
  <block id="f201deaeba7cc565253f52d974008543" category="summary">애플리케이션 VM 및 데이터베이스 볼륨을 AWS에서 실행되는 VMware Cloud Volume 서비스로 페일오버하려면 SnapCenter Server와 Veeam Backup and Replication Server의 실행 중인 인스턴스를 설치 및 구성해야 합니다. 페일오버가 완료된 후 사내 데이터 센터에 대한 페일백이 계획 및 실행될 때까지 정상적인 백업 작업을 재개하도록 이러한 툴을 구성해야 합니다.</block>
  <block id="ee51a40e9d2538b4e33b441d66869c24" category="doc">클라우드 백업 툴 및 구성</block>
  <block id="a514f4da2fec40b52d89613d7b3854fa" category="section-title">보조 Windows SnapCenter 서버를 배포합니다</block>
  <block id="dba3e8475ef38dcd147447c5730c2f7c" category="paragraph">SnapCenter 서버는 VMware 클라우드 SDDC에 구축하거나 VMware 클라우드 환경에 대한 네트워크 연결을 통해 VPC에 상주하는 EC2 인스턴스에 설치됩니다.</block>
  <block id="1a297f32b70010f208d00a4f58855fec" category="paragraph">SnapCenter 소프트웨어는 NetApp Support 사이트에서 제공되며 도메인 또는 작업 그룹에 있는 Microsoft Windows 시스템에 설치할 수 있습니다. 자세한 계획 가이드 및 설치 지침은 에서 확인할 수 있습니다<block ref="92e6fa322f689d7da93690560d0b41bd" category="inline-link-rx"></block>.</block>
  <block id="4adffd967d9bbc0f71287e67a568e0ae" category="paragraph">SnapCenter 소프트웨어는 에서 찾을 수 있습니다<block ref="6c76039d71cd5c9473efac721f24ac89" category="inline-link-rx"></block>.</block>
  <block id="224efa116a105cfd586d82f09e7cd1fe" category="section-title">보조 Windows SnapCenter 서버를 구성합니다</block>
  <block id="9ec64430f94c7b2f3824857182b8ff9d" category="paragraph">FSx ONTAP에 미러링된 애플리케이션 데이터를 복구하려면 먼저 온-프레미스 SnapCenter 데이터베이스의 전체 복원을 수행해야 합니다. 이 프로세스가 완료되면 VM과의 통신이 다시 설정되고 FSx ONTAP를 기본 스토리지로 사용하여 응용 프로그램 백업을 다시 시작할 수 있습니다.</block>
  <block id="b502974234450ceabf2344f2a3e45f7a" category="paragraph">이를 위해서는 SnapCenter 서버에서 다음 항목을 완료해야 합니다.</block>
  <block id="13d56fa22f861d817f01e34bd0dff18d" category="list-text">원래 온-프레미스 SnapCenter 서버와 동일하게 컴퓨터 이름을 구성합니다.</block>
  <block id="87da734902f9a20ba518a732df6228fc" category="list-text">VMware 클라우드 및 FSx ONTAP 인스턴스와 통신하도록 네트워킹을 구성합니다.</block>
  <block id="7f2fdcaa4d368c36731db2bdf5eb79a9" category="list-text">SnapCenter 데이터베이스를 복원하는 절차를 완료합니다.</block>
  <block id="b9f6e6c037c51c372d51f5f4254d76cc" category="list-text">SnapCenter가 재해 복구 모드에 있는지 확인하여 이제 FSx가 백업용 기본 스토리지인지 확인합니다.</block>
  <block id="b8864a7697abc4d58d337a7803f7ca8e" category="list-text">복구된 가상 머신과 통신이 다시 설정되었는지 확인합니다.</block>
  <block id="6b9d280aee667ad2407fdb311dc034cb" category="inline-link-macro">SnapCenter 데이터베이스 복원 프로세스</block>
  <block id="4757e8da6d3b5465a3ae91d8390db6d9" category="paragraph">이러한 단계를 완료하는 방법에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="fe5a34b461345b6f910f9d5fd86fde40" category="inline-link-macro-rx"></block>.</block>
  <block id="b827704a3bb22b3992173e0581a1c28b" category="paragraph">Veeam Backup &amp; Replication 서버를 AWS의 VMware Cloud 또는 EC2 인스턴스에 설치할 수 있습니다. 자세한 구현 지침은 를 참조하십시오<block ref="1e2565ba3e6473b62b1909934037e810" category="inline-link-rx"></block>.</block>
  <block id="e271ecc9b2a2050b58d0914d62a2325b" category="paragraph">Amazon S3 스토리지에 백업된 가상 머신의 복구를 수행하려면 Veeam Server를 Windows 서버에 설치하고 원래 백업 저장소가 포함된 VMware Cloud, FSx ONTAP 및 S3 버킷과 통신하도록 구성해야 합니다. 또한 VM이 복구된 후 새 백업을 수행하려면 FSx ONTAP에 새 백업 리포지토리가 구성되어 있어야 합니다.</block>
  <block id="d569da58bc917eb906ada72f76bf1030" category="paragraph">이 프로세스를 수행하려면 다음 항목을 완료해야 합니다.</block>
  <block id="6443544e723bdb5a8e0b2e300ce4e821" category="list-text">네트워킹을 구성하여 원래 백업 저장소가 포함된 VMware Cloud, FSx ONTAP 및 S3 버킷과 통신합니다.</block>
  <block id="d19ea991ccb7ded9582c07fa062fb3b4" category="list-text">FSx ONTAP에서 SMB 공유를 새 백업 리포지토리로 구성합니다.</block>
  <block id="adf79b820407599132e907adb994746d" category="list-text">사내에서 스케일아웃 백업 저장소의 일부로 사용된 원래 S3 버킷을 마운트합니다.</block>
  <block id="a706ef66660617fcf4a5aeb2e6f6d76b" category="list-text">VM을 복구한 후 SQL 및 Oracle VM을 보호하기 위한 새로운 백업 작업을 설정합니다.</block>
  <block id="28850f35c95cf12d5e28a35c2fdd8e5d" category="inline-link-macro">Veeam Full Restore로 애플리케이션 VM을 복구합니다</block>
  <block id="5ad23c05d5054f7daf749b3a328903be" category="paragraph">Veeam을 사용하여 VM을 복원하는 방법에 대한 자세한 내용은 섹션을 참조하십시오 <block ref="145e19bb138e7c87e2d24d78a1c11e93" category="inline-link-macro-rx"></block>.</block>
  <block id="f377bdd54f0f567b139a5913567466f1" category="paragraph">* VMware Tanzu Kubernetes Grid(TKG) *</block>
  <block id="7a3368d887604b1812f8f796b668f0e7" category="paragraph">* VMware Tanzu Kubernetes Grid Service(TKGS) *</block>
  <block id="8da30835717bc9e00a9ea2b89d75d943" category="paragraph">* VMware Tanzu Kubernetes Grid Integrated(TKGI) *</block>
  <block id="22bd1c4adfe1c3f7d3dc00763a7a8d40" category="paragraph">* vSphere 및 Tanzu(vSphere Pod) *</block>
  <block id="4f50bac068dbe84c04d257f75bb42142" category="list-text">vSphere 기본 포드는 가상 하드웨어가 규정된 가상 계층으로 구성된 가상 광자 기반 계층에서 실행되어 완벽한 격리를 제공합니다.</block>
  <block id="c8cefb07aba3cc260670993281c9bef5" category="list-text">NSX-T가 필요하지만 Harbour 이미지 레지스트리와 같은 추가 기능을 지원할 수 있습니다.</block>
  <block id="b603aa094817eb0510887a841cc71df8" category="list-text">TKGS와 같은 가상 Supervisor 클러스터를 사용하여 vSphere 7.0U1 이상에서 구축 및 관리 ESXi 노드에서 직접 Pod를 실행합니다.</block>
  <block id="cf3b96589f75768a855cebe2679e5b8b" category="list-text">vSphere 관리를 통해 완벽하게 통합된 최고의 가시성과 제어 기능을 제공합니다.</block>
  <block id="3b050b735b1eb713cc1b3816851e3060" category="list-text">최고 수준의 보안을 제공하는 격리된 crX 기반 포드.</block>
  <block id="e7004adb0d2f74954305a1023249e642" category="list-text">영구 스토리지에 대한 vSphere CSI만 지원합니다. 타사 스토리지 오케스트레이터는 지원되지 않습니다.</block>
  <block id="90534ff553f8895d609b7e0cec5e7977" category="paragraph">Astra Trident는 VMware Tanzu를 비롯한 컨테이너 및 Kubernetes 배포를 위한 완전히 지원되는 오픈 소스 스토리지 오케스트레이터입니다.</block>
  <block id="25e19f6e213533d24e711ce5e6738fa9" category="paragraph">vSphere Pod라고도 하는 Tanzu를 지원하는 VMware vSphere를 사용하면 베어 메탈 Kubernetes 환경에서 VMware vSphere 환경의 ESXi 하이퍼바이저 노드를 작업자 노드로 사용할 수 있습니다.</block>
  <block id="c2556907e1f90b93c9c43e198113de8b" category="paragraph">가상화된 Supervisor Cluster는 Kubernetes를 위한 고가용성 제어 플레인을 제공하기 위해 생성되고, 사용자를 위한 리소스 격리를 보장하기 위해 각 애플리케이션에 대해 개별 네임스페이스는 생성됩니다.</block>
  <block id="9e2885b693a2045e931fda4aeb8bf28f" category="paragraph">Tanzu가 설치된 VMware vSphere가 활성화된 경우 각 ESXi 호스트에는 Spherelet 애플리케이션이 설치 및 구성되어 있습니다. 이를 통해 각 노드가 Kubernetes 구축 시 작업자 역할을 수행하고 각 노드에 구축된 Pod를 관리할 수 있습니다.</block>
  <block id="c44d7c5351501c027261c0480a658d6d" category="paragraph">현재 Tanzu 및 vSphere Pod를 사용하는 VMware vSphere는 로컬 vSphere CSI 드라이버만 지원합니다. 이 작업은 vSphere Client에서 관리자가 vSphere 데이터 저장소로 사용할 수 있는 스토리지 타겟 중에서 선택할 스토리지 정책을 생성하도록 하는 방식으로 수행할 수 있습니다. 이러한 정책은 컨테이너화된 애플리케이션을 위한 영구 볼륨을 생성하는 데 사용됩니다.</block>
  <block id="fe41e8fdcbc9d8447c9077fbd167fe8d" category="admonition">현재 NetApp Astra Trident CSI 드라이버는 외부 ONTAP 및 Element 스토리지 어레이에 직접 연결할 수 있도록 지원하지만, 이러한 NetApp 스토리지 시스템은 vSphere 환경의 기본 스토리지를 지원하는 데 주로 사용됩니다. 또한 NetApp 고급 데이터 관리 및 스토리지 효율성 툴을 이러한 방식으로 사용할 수 있습니다.</block>
  <block id="70aaffec040bcf9e5cf77c0ccabb8f11" category="paragraph">Tanzu를 사용하는 VMware vSphere에 대한 자세한 내용은 설명서를 참조하십시오 <block ref="0cdaad1423fdb034ad0ee788d57a7a82" category="inline-link-macro-rx"></block>.</block>
  <block id="5e86473217a757f4702d326176983651" category="cell">2022년 7월 28일</block>
  <block id="e325d40f0256e06aa0a0f1c795ea68ee" category="cell">SnapCenter와 Veeam으로 AWS/VMC(게스트 연결 스토리지)용 DR 솔루션 추가</block>
  <block id="af2a34190d0729a3b5a2ed9d50d9e399" category="cell">VMware 솔루션을 사용하는 하이브리드 멀티 클라우드의 체계적인 콘텐츠: 각 하이퍼스케일러의 랜딩 페이지 및 사용 가능한 솔루션(사용 사례) 콘텐츠 포함</block>
  <block id="9c00744e128712d7626e5c00edcfeaa1" category="cell">VMware를 통해 가상화 및 하이브리드 멀티 클라우드를 위한 콘텐츠를 효율적으로 구성하기 위한 랜딩 페이지를 만들었습니다</block>
  <block id="5424d7e641fa7962888e16022445e1ae" category="cell">가상화 환경 및 게스트 연결 스토리지 옵션을 위한 VMware 콘텐츠를 포함하는 하이브리드 멀티 클라우드 생성</block>
  <block id="e307db07b3975fef922a80d07455ee5e" category="cell">데이터베이스</block>
  <block id="6c6fb0f7e5fe3a7242028f22d2792fca" category="cell">NetApp 솔루션 타일에 엔터프라이즈 애플리케이션 및 데이터베이스용 블로그 섹션이 추가되었습니다. 데이터베이스 블로그에 두 개의 블로그를 추가했습니다.</block>
  <block id="c99ec32d06b1f19699d82b1b34a80ca0" category="paragraph"><block ref="c99ec32d06b1f19699d82b1b34a80ca0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="58098d451cf2728b0542acd542f9000b" category="cell">* 보조 NFS 데이터 저장소 *</block>
  <block id="51b0e38e5ec7edbe37b6672987ce5f2e" category="paragraph">NetApp이 게스트 연결 스토리지 장치로 NetApp에서 제공하는 3가지 운영 하이퍼스케일러 또는 보조 NFS 데이터 저장소를 마이그레이션 워크플로우에 전환하여 클라우드, 백업/복원 및 재해 복구를 확장/버스팅 하는 기능에 대해 자세히 알아보십시오.</block>
  <block id="ccb4d111a650d51ca9a8feb2542610be" category="paragraph">NetApp 스토리지는 세 가지 주요 하이퍼 스케일러 내에서 각각 연결된 추측이나 보조 NFS 데이터 저장소로 활용할 수 있습니다.</block>
  <block id="d22e98327d29984cdf19ebfeeb53bd99" category="paragraph">NetApp이 AWS VMware 클라우드(VMC)에 제공하는 기능에 대해 자세히 알아보십시오. NetApp은 게스트 연결 스토리지 장치로, 보충 NFS 데이터 저장소에서 마이그레이션 워크플로우에 전환하여 클라우드, 백업/복원 및 재해 복구를 확대/급증할 수 있습니다.</block>
  <block id="e3dea11e8144be98f637687e2a2cf316" category="paragraph">AWS VMC에서 NetApp 스토리지를 guess connected 또는 보완 NFS 데이터 저장소로 여러 가지 방법으로 활용할 수 있습니다.</block>
  <block id="206616b83a19162051802c3823da0f7c" category="paragraph">또한 NetApp은 게스트 내(게스트 연결) 스토리지로서 프로비저닝되거나 각 하이퍼스케일러에서 보조 NFS 데이터 저장소로 제공하는 솔루션을 제공합니다. 모든 솔루션은 클라우드 워크로드의 VMware 분류와 함께 분류됩니다. 이러한 분류에는 다음이 포함됩니다.</block>
  <block id="04e248dee456b1f3910d53450d745125" category="list-text">클라우드 보완 기술을 활용하여 앱 현대화</block>
  <block id="77d50dd2ce4e2531e14f13434a560e7d" category="section-title">보충 NFS 스토리지 옵션의 중요성 이해</block>
  <block id="de8529127f85189767876e4d9a97427c" category="paragraph">클라우드에 구축된 VMware는 모든 고객에게 고유한 하이브리드 기능을 제공하지만, 제한된 보조 NFS 스토리지 옵션으로 스토리지 집약적인 워크로드를 사용하는 조직에는 유용성이 제한됩니다. 스토리지는 호스트에 직접 연결되므로 스토리지를 확장하는 유일한 방법은 호스트를 추가하는 것입니다. 이렇게 하면 스토리지 집약적인 워크로드의 비용이 35-40% 이상 증가할 수 있습니다. 이러한 워크로드는 추가 마력이 아닌 추가 스토리지만 필요합니다. 하지만 이는 추가 호스트에 대한 비용을 지불하는 것을 의미합니다.</block>
  <block id="af68f7a1e7ca322318bf949baba2129e" category="inline-link-macro">ANF 및 Jetstream을 사용한 재해 복구(보조 NFS 데이터 저장소)</block>
  <block id="73c807da78ef06fdb99e2307b5d8cb57" category="list-text"><block ref="73c807da78ef06fdb99e2307b5d8cb57" category="inline-link-macro-rx"></block></block>
  <block id="f93c390413608eaad8cc43b29f8073d0" category="inline-link-macro">ANF 및 CVO(게스트 연결 스토리지)를 사용한 재해 복구</block>
  <block id="233b8f979ad627e56656fbdd647fdc2b" category="list-text"><block ref="233b8f979ad627e56656fbdd647fdc2b" category="inline-link-macro-rx"></block></block>
  <block id="5f2df3110b7088a1c8d1659ffb728f46" category="doc">CVO 및 AVS(게스트 연결 스토리지)를 통한 재해 복구</block>
  <block id="9a130cd816dc8be85c4f198310f16e4c" category="paragraph">NetApp이 AVS(Azure VMware Solution)에 제공하는 기능에 대해 자세히 알아보십시오. NetApp은 게스트 연결 스토리지 장치로, 보충 NFS 데이터 저장소에서 마이그레이션 워크플로우에 전환, 클라우드로 확장/버스팅, 백업/복원, 재해 복구까지 지원합니다.</block>
  <block id="465fe02ad52f12cc5844200de029e385" category="paragraph">NetApp 스토리지는 Azure AVS에서 guess Connected 또는 보충 NFS 데이터 저장소로 여러 가지 방법으로 활용할 수 있습니다.</block>
  <block id="827f15aa97cbfccd71eb2ba3ac7d4eac" category="doc">Azure의 보조 NFS 데이터 저장소 옵션</block>
  <block id="d6e093aa5c1e7500fe79b8732c410c91" category="paragraph">또한 Azure NetApp Files를 사용하면 여러 데이터 저장소를 배포할 수 있습니다. 이 데이터 저장소는 가상 머신을 적절한 데이터 저장소에 배치하고 워크로드 성능 요구 사항을 충족하는 데 필요한 서비스 수준을 할당하여 온-프레미스 구축 모델을 모방하는 데 도움이 됩니다. 멀티 프로토콜 지원의 고유한 기능을 통해 게스트 스토리지는 SQL 및 Oracle과 같은 데이터베이스 워크로드를 위한 추가 옵션일 뿐만 아니라 보충 NFS 데이터 저장소 기능을 사용하여 나머지 VMDK를 저장합니다. 이와 별도로 네이티브 스냅샷 기능을 사용하여 신속한 백업 및 세분화된 복원을 수행할 수 있습니다.</block>
  <block id="402936a0724fed1eeed39a4791eae422" category="paragraph">개략적으로 보면, 이 아키텍처는 온프레미스 환경과 Azure에서 하이브리드 클라우드 연결 및 애플리케이션 이동성을 달성하는 방법을 설명합니다. 또한 Azure NetApp Files를 보조 NFS 데이터 저장소로 사용하거나 Azure VMware 솔루션에서 호스팅되는 게스트 가상 머신을 위한 게스트 내 스토리지 옵션으로 사용하는 방법에 대해서도 설명합니다.</block>
  <block id="66433e0e715221ebed495642af8005b7" category="doc">NetApp의 GCP용 보조 NFS 데이터 저장소 옵션</block>
  <block id="ce2d3ab910808452912b4cae1adc8bd7" category="paragraph">NetApp이 GCP(Google Cloud Platform) GCVE(Google Cloud Virtualization Engine)에 제공하는 기능에 대해 자세히 알아보십시오. NetApp은 게스트 연결 스토리지 장치로, 또는 NFS 데이터 저장소를 보완하여 워크플로우를 마이그레이션하고, 클라우드로 확장/버스팅, 백업/복원, 재해 복구를 수행합니다.</block>
  <block id="275ed895f3f409270670131f7369b1ac" category="paragraph">NetApp 스토리지는 GCP GCVE 내에서 guess Connected 또는 보충 NFS 데이터 저장소로 여러 가지 방법으로 활용할 수 있습니다.</block>
  <block id="55b61b011b735ba396a8dbd7e3f95f20" category="cell">2022년 8월 5일</block>
  <block id="678582eb0cbbe0e063e618d230b63223" category="cell">* 호스트 설정 *</block>
  <block id="dfe49b73bd7e747701b49f9ed21ea2d6" category="cell">* NetApp 권장 가치 *</block>
  <block id="edceae57d92287f4f6200f94d3259cd0" category="cell">* 재부팅 필요 *</block>
  <block id="dc3a6955a23583876d020db0f6b80d4d" category="cell">* ESXi 고급 구성 *</block>
  <block id="5fffea5cb752d304de420a5efa158e13" category="cell">설정된 상태로 유지(VMware 기본값은 1)</block>
  <block id="5d1b81f1885499e392018ebd7124ad37" category="inline-link-macro">VMware KB 2007427</block>
  <block id="36478566e3585eb8ea863e941dcb967a" category="cell">설정된 상태로 둡니다(VMware 기본값은 0이지만 VMFS6에는 필요하지 않음). 자세한 내용은 을 참조하십시오 <block ref="68c2cf0ecb6a1c6abaf6e56c035d5866" category="inline-link-macro-rx"></block></block>
  <block id="875f6b98e20edfecb56f9013d00987f6" category="cell">vSphere 6.0 이상, 32로 설정. 다른 모든 NFS 구성은 30으로 설정합니다</block>
  <block id="a8af33a99dd728969fd947da27a2f69f" category="cell">대부분의 vSphere 6.X 릴리즈에서는 512MB로 설정합니다. 6.5U3, 6.7U3 및 7.0 이상의 경우 1024MB로 설정합니다.</block>
  <block id="e787d5b0d643685421632a1af3914963" category="cell">vSphere 6.0 이상으로, 다른 모든 NFS 구성을 256으로 설정하고 64로 설정합니다.</block>
  <block id="e18600af98c17fae10fdba0dc89979ed" category="cell">NFS.MaxQueueDepth^1^</block>
  <block id="be7707fa525d0124489c9fe3072f78de" category="cell">vSphere 6.0 이상으로, 128로 설정합니다</block>
  <block id="138989cbe5dd3a4997662e0f65c17878" category="cell">모든 NFS 구성에 대해 10으로 설정합니다</block>
  <block id="7ea6e8664542e3beb1aea10425efb4db" category="cell">모든 NFS 구성에 대해 12로 설정합니다</block>
  <block id="fb62337a3ef32f4701b639339a4ceb33" category="cell">ALUA를 사용하는 FC 경로를 사용할 때 RR(라운드 로빈)으로 설정합니다. 다른 모든 설정에 대해 고정으로 설정합니다. 이 값을 RR로 설정하면 모든 활성/최적화 경로에서 로드 밸런싱을 제공하는 데 도움이 됩니다. 고정 값은 이전 비 ALUA 구성에 대한 값이며 프록시 I/O를 방지하는 데 도움이 됩니다 다시 말해, 7-Mode에서 Data ONTAP를 실행하는 환경에서 I/O가 고가용성(HA) 쌍의 다른 노드로 이동하는 것을 돕니다</block>
  <block id="0e82e1f81de2159b0e9bee0b7be00dc9" category="cell">모든 설정에 대해 32로 설정합니다. 이 값을 설정하면 I/O 오류가 방지됩니다.</block>
  <block id="bdd8c1d08eabb5e1923ed8f0c4b10ba4" category="cell">모든 설정에 대해 8로 설정합니다. 이 값을 설정하면 I/O 오류가 방지됩니다.</block>
  <block id="2aa077454308383f1e82025427cd7362" category="cell">모든 iSCSI 경로에 대해 RR(라운드 로빈)으로 설정합니다. 이 값을 RR로 설정하면 모든 활성/최적화 경로에서 로드 밸런싱을 제공하는 데 도움이 됩니다.</block>
  <block id="0340eb1bcbfc6cd3c62b8a878d8d643b" category="cell">모든 설정에 대해 32로 설정합니다. 이 값을 설정하면 I/O 오류가 방지됩니다</block>
  <block id="891c10448731ad57490b9a932dabfff8" category="inline-link-macro">VMware KB 86331</block>
  <block id="2c572e3c397fe100b075a09359c9cc23" category="admonition">1-NFS 고급 구성 옵션 MaxQueueDepth는 VMware vSphere ESXi 7.0.1 및 VMware vSphere ESXi 7.0.2를 사용할 때 의도한 대로 작동하지 않을 수 있습니다. 참조하십시오 <block ref="861055760f3cd527823fd34a49459992" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="3f7502a5f109d7a73706aba1c0741a4b" category="cell">* ONTAP 도구 *</block>
  <block id="485577e97e8efcd504fc8e8b13e613f1" category="cell">* 기본 설정 *</block>
  <block id="f639f9fbf0a0ec97e697dc20f2dec14f" category="sidebar">보충 NFS 데이터 저장소 옵션</block>
  <block id="015a03470e91621621a76f7a4e3dc56e" category="sidebar">보조 NFS 데이터 저장소로서의 ANF: 개요</block>
  <block id="5a9500ea180d9aa487f8a027550c1888" category="sidebar">보충 NFS 데이터 저장소 개요</block>
  <block id="5cc354638211ca59bc561a960afa71f9" category="sidebar">보조 NFS 데이터 저장소 - Public Preview(Microsoft)</block>
  <block id="95fd29d87d2c7d3100a5198bc7067e95" category="sidebar">AVS용 보조 NFS 데이터 저장소입니다</block>
  <block id="e7e97f343a76aab098fd05b8953ee1a5" category="list-text">Azure NetApp Files 데이터 저장소를 Azure VMware 솔루션 호스트에 연결(Preview)</block>
  <block id="1838681ebe885a1a1e886cdf7e263065" category="inline-link"><block ref="1838681ebe885a1a1e886cdf7e263065" category="inline-link-rx"></block></block>
  <block id="2361f6fabb02c6060c638b5f1780cda2" category="paragraph"><block ref="2361f6fabb02c6060c638b5f1780cda2" category="inline-link-rx"></block></block>
  <block id="bcd4c93e63ff96ec357bc67c62874e0c" category="cell">2022년 8월 23일</block>
  <block id="10daf0bb04814721080056526de2b200" category="cell">모든 보조 NFS 데이터 저장소 옵션의 최신 지역 가용성을 업데이트했습니다</block>
  <block id="9e779086e93810f8495caf5b07f578cd" category="paragraph">Azure/AVS에서 보조 NFS 데이터 저장소의 가용성은 Microsoft에서 정의합니다. 먼저 AVS와 ANF를 특정 지역에서 모두 사용할 수 있는지 확인해야 합니다. 그런 다음 해당 지역에서 ANF 보조 NFS 데이터 저장소가 지원되는지 여부를 확인해야 합니다.</block>
  <block id="8ff7e1fad21e60bbdef17593aae83ff6" category="list-text">AVS 및 ANF의 가용성을 확인하십시오 <block ref="757f75bead0b939967621d226ba54faa" category="inline-link-macro-rx"></block>.</block>
  <block id="2f53a51554f6e0b66622228f3db68361" category="list-text">ANF 보조 NFS 데이터 저장소의 가용성을 확인합니다 <block ref="02ba6bc5fe71be0f7426aedd427de443" category="inline-link-macro-rx"></block>.</block>
  <block id="926f20c82f92e797825f3ddf31c8d15b" category="paragraph">GCP/GCVE에서 보조 NFS 데이터 저장소의 가용성은 Google에서 정의합니다. 먼저 특정 지역에서 GCVE 및 CVS를 모두 사용할 수 있는지 확인해야 합니다. 그런 다음 해당 지역에서 CVS 보조 NFS 데이터 저장소가 지원되는지 여부를 확인해야 합니다.</block>
  <block id="0970f21d33cd70a68d82d99f1d6abd42" category="list-text">GCVE 및 CVS의 가용성을 확인합니다 <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>.</block>
  <block id="52d36923e6e7f21dede2a88e87bd5528" category="list-text">CVS 보조 NFS 데이터 저장소의 가용성을 확인합니다 <block ref="007e08d33d89c24a1316c16966bb4055" category="inline-link-macro-rx"></block>.</block>
  <block id="46c2094fdbb2fbdc301a330fb7419074" category="paragraph">AWS/VMC에서 보조 NFS 데이터 저장소를 사용할 수 있는 가용성은 Amazon에서 정의합니다. 먼저, VMC와 FSxN을 모두 지정된 지역에서 사용할 수 있는지 확인해야 합니다. 그런 다음 해당 지역에서 FSxN 보조 NFS 데이터 저장소가 지원되는지 여부를 확인해야 합니다.</block>
  <block id="c10e413ea65850b7369ee5ae6f60b460" category="list-text">VMC에 대한 FSxN 보조 NFS 데이터 저장소의 가용성이 곧 제공될 예정입니다.</block>
  <block id="a1838a4ac0f386c517d82fae26f2372e" category="paragraph">정보가 아직 릴리즈되는 동안 다음 차트는 VMC, FSxN 및 FSxN에 대한 현재 지원을 보조 NFS 데이터 저장소로 식별합니다.</block>
  <block id="97be15a34c6b82b6177132129dd0b293" category="doc">지역 가용성 – VMC용 보조 NFS 데이터 저장소</block>
  <block id="0b6b52ed7135814c4a167640dee306f2" category="doc">지역 가용성 – Google Cloud Platform(GCP)용 보조 NFS 데이터 저장소</block>
  <block id="e78040a1599894c3db7423e479a1f7d1" category="summary">클라우드로 재해 복구는 랜섬웨어 등 사이트 운영 중단 및 데이터 손상 이벤트로부터 워크로드를 보호하는 복원력이 있는 비용 효율적인 방법입니다. NetApp SnapMirror를 사용하면 게스트 연결 스토리지를 사용하는 사내 VMware 워크로드를 Google Cloud에서 실행 중인 NetApp Cloud Volumes ONTAP로 복제할 수 있습니다.</block>
  <block id="58997b61f0fc8812c9977a9dd3d181c5" category="doc">SnapCenter, Cloud Volumes ONTAP, Veeam 복제를 통한 애플리케이션 재해 복구</block>
  <block id="0fa916b50826c2fab3e504331d6b8ad1" category="paragraph">저자: NetApp Suesh Thoppay</block>
  <block id="366fe59477118cc36e7ef7936cc04771" category="paragraph">클라우드로 재해 복구는 랜섬웨어 등 사이트 운영 중단 및 데이터 손상 이벤트로부터 워크로드를 보호하는 복원력이 있는 비용 효율적인 방법입니다. NetApp SnapMirror를 사용하면 게스트 연결 스토리지를 사용하는 사내 VMware 워크로드를 Google Cloud에서 실행 중인 NetApp Cloud Volumes ONTAP로 복제할 수 있습니다. 여기에는 애플리케이션 데이터가 포함됩니다. 하지만 실제 VM 자체는 어떻습니까? 재해 복구는 가상 머신, VMDK, 애플리케이션 데이터 등을 비롯한 모든 종속 구성 요소를 포함해야 합니다. 이를 위해 Veeam과 함께 SnapMirror를 사용하여 VM VMDK에 vSAN 스토리지를 사용하면서 사내에서 Cloud Volumes ONTAP로 복제된 워크로드를 원활하게 복구할 수 있습니다.</block>
  <block id="93fb0db9f34ab708d4c3e5d233e4d97f" category="paragraph">이 문서에서는 NetApp SnapMirror, Veeam 및 Google Cloud VMware Engine(GCVE)을 사용하는 재해 복구를 설정하고 수행하기 위한 단계별 접근 방식을 제공합니다.</block>
  <block id="669129cbcdc854bf23fe7e672be9c44c" category="paragraph"><block ref="669129cbcdc854bf23fe7e672be9c44c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c611c3f34a5f506ad20f441b78810981" category="paragraph">온프레미스 환경과 Google Cloud 네트워크 간의 연결을 위해 전용 상호 연결 또는 Cloud VPN과 같은 연결 옵션을 사용합니다. 세그먼트는 사내 VLAN 설계를 기반으로 생성해야 합니다.</block>
  <block id="b62c675a3e45635be4cc5a65dde4c55c" category="admonition">온프레미스 데이터 센터를 Google Cloud에 연결하는 옵션에는 여러 가지가 있으며, 이로 인해 NetApp에서 이 문서의 특정 워크플로우를 개괄적으로 설명하지 못하게 됩니다. 적절한 온프레미스-Google 연결 방법은 Google Cloud 설명서를 참조하십시오.</block>
  <block id="5e345ef39956138694764fce9921e498" category="list-text">Veeam 소프트웨어를 설치하고 Google Cloud VMware Engine 인스턴스에 가상 머신 복제를 시작합니다.</block>
  <block id="7c6d17fe855de9f3821d0cead78f4d26" category="list-text">재해 발생 시 Cloud Manager를 사용하여 SnapMirror 관계를 맺고 Veeam으로 가상 시스템의 페일오버를 트리거하십시오.</block>
  <block id="e36e9213012a15c95ec5048a09f751b0" category="list-text">애플리케이션을 온라인으로 전환합니다.</block>
  <block id="820f3ffde5403dbc2ca3d17b511f569e" category="example-title">Google Cloud에서 CVO를 구성하고 볼륨을 CVO로 복제합니다</block>
  <block id="6765d7341fa9566a047031c62d2040b8" category="inline-link">CVO</block>
  <block id="14cdb7188d3a5edcc69cb9fe2ebf708b" category="paragraph">첫 번째 단계는 Google Cloud에서 Cloud Volumes ONTAP를 구성하는 것입니다 <block ref="21dbe7906aa79142ad8a44237d3d84a5" category="inline-link-rx"></block>)를 사용하여 원하는 볼륨을 Cloud Volumes ONTAP에 복제하고 원하는 빈도와 스냅샷 보존 기능을 사용할 수 있습니다.</block>
  <block id="1b6eb09708583df3feb79dd7e7b9ed2a" category="paragraph"><block ref="1b6eb09708583df3feb79dd7e7b9ed2a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b67ee8de7f0f6f1b68e41ce4be6b4a0b" category="inline-link">SnapCenter를 사용하여 복제를 설정합니다</block>
  <block id="8064e6b40ef12da2c44763dcfe735ae8" category="paragraph">SnapCenter 설정 및 데이터 복제에 대한 단계별 지침은 을 참조하십시오<block ref="68793c30d3c5e8a024de6c79bc478fe1" category="inline-link-rx"></block></block>
  <block id="5a101eac27a34cdc3b06c105760d0cee" category="example-title">GCVE 호스트 및 CVO 데이터 액세스를 구성합니다</block>
  <block id="1fe9f40218e52161bc5e31e2cd383a0b" category="paragraph">SDDC를 배포할 때 고려해야 할 두 가지 중요한 요소는 GCVE 솔루션의 SDDC 클러스터의 크기와 SDDC를 사용할 수 있는 기간 입니다. 재해 복구 솔루션의 두 가지 주요 고려 사항은 전체 운영 비용을 절감하는 데 도움이 됩니다. SDDC는 최대 3개의 호스트까지 구성할 수 있으며, 전체 구축 환경에서 다중 호스트 클러스터까지 가능합니다.</block>
  <block id="4f7b492a9eedf950f4dbd01357b22979" category="paragraph">모든 VPC 및 GCVE에 Cloud Volumes ONTAP를 구축할 수 있습니다. VM이 iSCSI LUN에 접속하려면 해당 VPC에 대한 전용 연결이 있어야 합니다.</block>
  <block id="727eadb1fcad984cfa778a04f2181408" category="paragraph">GCVE SDDC를 구성하려면 를 참조하십시오<block ref="06e1fa19855b73b0e800850663f265a2" category="inline-link-rx"></block>. 사전 요구 사항으로, 연결이 설정된 후 GCVE 호스트에 상주하는 게스트 VM이 Cloud Volumes ONTAP의 데이터를 사용할 수 있는지 확인합니다.</block>
  <block id="fb75a211e033fa96e7f692258221c1da" category="paragraph">Cloud Volumes ONTAP 및 GCVE가 올바르게 구성된 후에는 Veeam 복제 기능을 사용하고 Cloud Volumes ONTAP에 애플리케이션 볼륨 복사본에 SnapMirror를 활용하여 사내 워크로드(게스트 내 스토리지가 있는 애플리케이션 VMDK 및 VM이 있는 VM)를 GCVE로 자동 복구하도록 Veeam 구성을 시작하십시오.</block>
  <block id="87e3cc18e14b0d78c8c46e3ed343fca7" category="example-title">Veeam 구성 요소를 설치합니다</block>
  <block id="60fec867397af265e1e757d06135859e" category="example-title">Veeam으로 VM 복제를 설정합니다</block>
  <block id="d81c3dfdfda7fb8581660b5d218c6a3a" category="inline-link">vSphere VM 복제 작업을 설정합니다</block>
  <block id="6a67b79523a52a3a2b4e485485456565" category="paragraph">사내 vCenter와 GCVE vCenter를 모두 Veeam에 등록해야 합니다.<block ref="9af60ccd7c779b77ba6ce43ae96a95f6" category="inline-link-rx"></block> 마법사의 게스트 처리 단계에서 애플리케이션 인식 백업 및 복구를 위해 SnapCenter를 활용할 예정이므로 애플리케이션 처리 비활성화 를 선택합니다.</block>
  <block id="34510608302d692ff6f3936359703d26" category="example-title">Microsoft SQL Server VM의 페일오버</block>
  <block id="ce137de4140fd114a7fb3fcb057328fa" category="list-text">Veeam Replication을 사용하면 DR 사이트에서 VM IP 주소를 변경할 수 있습니다.</block>
  <block id="dee7570423fb41bfa5f00fd539ed91da" category="doc">지역 가용성 – ANF용 보조 NFS 데이터 저장소</block>
  <block id="9e289e2a1ce460725108e7241e19b575" category="doc">AWS, Azure 및 GCP에서 보조 NFS 데이터 저장소를 위한 지역 가용성</block>
  <block id="3ce209dcd58ed0c7d8cf39f37f2b1557" category="paragraph">AWS, Azure 및 Google Cloud Platform(GCP)에서 NFS 데이터 저장소를 추가로 지원하는 글로벌 지역에 대해 자세히 알아보십시오.</block>
  <block id="f22705ef66107a528d4982aa8fdd463d" category="list-text"><block ref="f22705ef66107a528d4982aa8fdd463d" category="inline-link-macro-rx"></block></block>
  <block id="e9063f3c3631446cbaeef19e7965f491" category="sidebar">SnapCenter, CVO, Veeam 복제를 통한 애플리케이션 재해 복구</block>
  <block id="d15aa19396a83c3c15a1fb8ba83efda1" category="cell">2022년 8월 25일</block>
  <block id="56991209ac6bc77f76e9e1828103cdfc" category="cell">블로그 추가 - Amazon FSx 스토리지를 사용하여 하이브리드 클라우드에서 Oracle 데이터베이스 운영을 현대화하십시오</block>
  <block id="f37741764b2517136f3747b14ec803a0" category="cell">새로운 솔루션: NetApp 및 VMware를 사용하는 NVIDIA AI Enterprise</block>
  <block id="9f65880e605551f01ff1d2c03d3fa4c6" category="cell">2022년 6월 29일</block>
  <block id="304bc05c6debf3075c4f25dcffcf50bd" category="cell">WP-7357 추가: EC2/FSx Best Practices에 Oracle Database 구축</block>
  <block id="69e8c6aef5e50150d499e7fa39f846ed" category="summary">NVIDIA AI Enterprise는 모든 조직이 AI를 성공적으로 활용할 수 있도록 최적화된 엔드 투 엔드 클라우드 네이티브 AI 및 데이터 분석 소프트웨어 제품군입니다.</block>
  <block id="68cdb7bf3dabd26e338e1ba72b549c69" category="doc">NetApp 및 VMware를 사용하는 NVIDIA AI Enterprise</block>
  <block id="61cb0c1b4a32d4815eb2a785c0c84cb8" category="paragraph">IT 설계자 및 관리자의 경우 AI 툴링은 복잡하고 익숙하지 않을 수 있습니다. 또한 많은 AI 플랫폼은 엔터프라이즈급이 아닙니다. NetApp과 VMware이 지원하는 NVIDIA AI Enterprise는 간소화된 엔터프라이즈급 AI 아키텍처를 제공하도록 제작되었습니다.</block>
  <block id="65590ec18b850984cfb8bbe6ba35fe7d" category="paragraph">NVIDIA AI Enterprise는 NVIDIA 인증 시스템과 함께 VMware vSphere에서 실행하도록 NVIDIA에서 최적화, 인증 및 지원하는 엔드 투 엔드 클라우드 네이티브 AI 및 데이터 분석 소프트웨어 제품군입니다. 이 소프트웨어를 사용하면 최신 하이브리드 클라우드 환경에서 AI 워크로드를 쉽고 빠르게 구축, 관리, 확장할 수 있습니다. NetApp 및 VMware를 기반으로 하는 NVIDIA AI Enterprise는 단순하고 친숙한 패키지로 엔터프라이즈급 AI 워크로드 및 데이터 관리를 제공합니다.</block>
  <block id="24c4078c95e6e2df55bd1d251c11f4aa" category="paragraph"><block ref="24c4078c95e6e2df55bd1d251c11f4aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7d92209f7d0eac282a9a26e642c20a91" category="inline-link-macro">다음: 기술 개요.</block>
  <block id="51624dfcafe192d37d40a363ccfa4260" category="paragraph"><block ref="51624dfcafe192d37d40a363ccfa4260" category="inline-link-macro-rx"></block></block>
  <block id="f0de4adaf6568678921cef0d0e69b81f" category="summary">NetApp 및 VMware를 사용하는 NVIDIA AI Enterprise - 기술 개요</block>
  <block id="bdab293b91374abd32d30076de9d29b9" category="paragraph"><block ref="bdab293b91374abd32d30076de9d29b9" category="inline-link-macro-rx"></block></block>
  <block id="51ab86189ca8b1d1a08ac2970d39f90c" category="section-title">NVIDIA AI 엔터프라이즈</block>
  <block id="0719941ec04c59670033b3b1f0e3c239" category="paragraph">NVIDIA AI Enterprise는 NVIDIA 인증 시스템과 함께 VMware vSphere에서 실행하도록 NVIDIA에서 최적화, 인증 및 지원하는 엔드 투 엔드 클라우드 네이티브 AI 및 데이터 분석 소프트웨어 제품군입니다. 이 소프트웨어를 사용하면 최신 하이브리드 클라우드 환경에서 AI 워크로드를 쉽고 빠르게 구축, 관리, 확장할 수 있습니다.</block>
  <block id="cbd4c44d2b7fc45943b834d2a03f2a63" category="paragraph">NVIDIA NGC는 AI 전문가가 AI 솔루션을 개발할 수 있도록 GPU 최적화 소프트웨어 카탈로그를 호스팅합니다. 또한 모델 훈련을 위한 NVIDIA Base Command, 모델을 배포 및 모니터링하는 NVIDIA Fleet Command, 독점 AI 소프트웨어에 안전하게 액세스하고 관리하기 위한 NGC 프라이빗 레지스트리 등 다양한 AI 서비스에 대한 액세스를 제공합니다. 또한, NVIDIA AI 엔터프라이즈 고객은 NGC 포털을 통해 지원을 요청할 수 있습니다.</block>
  <block id="7ee50a783ac86f99c7b7db29b77e7a2a" category="paragraph">VMware vSphere는 데이터 센터를 CPU, 스토리지 및 네트워킹 리소스를 포함하는 집계된 컴퓨팅 인프라로 변환하는 VMware의 가상화 플랫폼입니다. vSphere는 이러한 인프라스트럭처를 통합 운영 환경으로 관리하고 관리자에게 해당 환경에 참여하는 데이터 센터를 관리할 수 있는 툴을 제공합니다.</block>
  <block id="a8b821c11b6c83cd7165137d4f68a45b" category="paragraph">vSphere의 두 가지 핵심 구성 요소는 ESXi와 vCenter Server입니다. ESXi는 관리자가 가상 머신 및 가상 어플라이언스를 생성 및 실행하는 가상화 플랫폼입니다. vCenter Server는 관리자가 네트워크 및 풀 호스트 리소스에 연결된 여러 호스트를 관리하는 서비스입니다.</block>
  <block id="f45c2aa2e74e3412ee9883eb28b7549e" category="paragraph">NetApp의 최신 세대 스토리지 관리 소프트웨어인 ONTAP 9는 기업이 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있도록 지원합니다. ONTAP는 업계 최고 수준의 데이터 관리 기능을 활용하여 데이터가 상주하는 위치와 상관없이 단일 툴셋으로 데이터를 관리하고 보호할 수 있습니다. 필요에 따라 에지, 코어, 클라우드 등 어느 위치로도 데이터를 자유롭게 이동할 수 있습니다. ONTAP 9에는 데이터 관리를 단순화하고, 중요 데이터를 더 빨리 처리하고, 보호하며, 하이브리드 클라우드 아키텍처 전체에서 차세대 인프라 기능을 지원하는 다양한 기능이 포함되어 있습니다.</block>
  <block id="7cc4f632835e2377fd90f38601a3e0eb" category="paragraph">NetApp DataOps 툴킷은 고성능 스케일아웃 NetApp 스토리지가 지원하는 개발/교육 작업 공간 및 추론 서버의 관리를 단순화하는 Python 기반 툴입니다. 주요 기능은 다음과 같습니다.</block>
  <block id="f9e55f3095ff79acd2c7f6315222ba4a" category="list-text">고성능 스케일아웃 NetApp 스토리지를 기반으로 하는 새로운 고용량 JupyterLab 작업 공간을 빠르게 프로비저닝합니다.</block>
  <block id="a9e4b1a2cc4b445907d2b986ab2f3515" category="list-text">엔터프라이즈급 NetApp 스토리지를 통해 지원되는 새로운 NVIDIA Triton Inference Server 인스턴스를 빠르게 프로비저닝합니다.</block>
  <block id="23b97f551923a166ae2d3223b0ed84cc" category="list-text">실험 또는 신속한 반복을 위해 고용량 JupyterLab 작업 공간을 거의 동시에 복제합니다.</block>
  <block id="27c7d5bdafd6a9d64ad337b08e104c87" category="list-text">백업 및/또는 추적 가능성/베이스라인 기능을 위해 고용량 JupyterLab 작업 공간의 스냅샷을 거의 동시에 저장합니다.</block>
  <block id="86f28dd8fdffc90314bf94c94e1b3c1c" category="list-text">대용량 고성능 데이터 볼륨을 거의 동시에 프로비저닝, 복제 및 스냅샷으로 제공합니다.</block>
  <block id="263db194560bc66bd5de27c72f9b7923" category="paragraph"><block ref="263db194560bc66bd5de27c72f9b7923" category="inline-link-macro-rx"></block></block>
  <block id="d8299632c247aca8f771d7368ee36f9d" category="summary">NetApp 및 VMware-Architecture를 지원하는 NVIDIA AI Enterprise</block>
  <block id="9ca68ac69c80fa519c5ead343d865ce4" category="inline-link-macro">이전: 기술 개요.</block>
  <block id="ab7d7704700b22bf8dd4ce26b09e2562" category="paragraph"><block ref="ab7d7704700b22bf8dd4ce26b09e2562" category="inline-link-macro-rx"></block></block>
  <block id="37810ec69b6e321b4b377d835e7d84ac" category="paragraph">이 솔루션은 NetApp, VMware 및 NVIDIA 인증 시스템을 갖춘, 그 우수성이 입증된 친숙한 아키텍처를 기반으로 구축되었습니다. 자세한 내용은 다음 표를 참조하십시오.</block>
  <block id="95a502ec0ddaf3352c2540e3e9f65a1b" category="cell">AI 및 데이터 분석 소프트웨어</block>
  <block id="61da586210da33a8abab150a7d7d0972" category="inline-link-macro">VMware용 NVIDIA AI Enterprise</block>
  <block id="7865e440c1b499e7942ca9b659d737d6" category="cell"><block ref="7865e440c1b499e7942ca9b659d737d6" category="inline-link-macro-rx"></block></block>
  <block id="102995a1cdd2c719d7d0aa4d888fa019" category="cell">가상화 플랫폼</block>
  <block id="4ce5f3794d6e351daaaaa4f211e419ee" category="cell"><block ref="4ce5f3794d6e351daaaaa4f211e419ee" category="inline-link-macro-rx"></block></block>
  <block id="8cf5fbd26a1d5d924600d38015860908" category="cell">컴퓨팅 플랫폼</block>
  <block id="aee87e9fe5cc4cf9193cd27c74a0a6e7" category="inline-link-macro">NVIDIA 인증 시스템</block>
  <block id="b3cdb2e0e953c1639ad63fe06b8c7a37" category="cell"><block ref="b3cdb2e0e953c1639ad63fe06b8c7a37" category="inline-link-macro-rx"></block></block>
  <block id="ddca712fc3b0dad3d85e423eb97d58ea" category="cell">데이터 관리 플랫폼</block>
  <block id="1c317db419d669c4b6473c6d462e881e" category="cell"><block ref="1c317db419d669c4b6473c6d462e881e" category="inline-link-macro-rx"></block></block>
  <block id="121c96ce43abda774fe95c1ccde1603e" category="paragraph"><block ref="121c96ce43abda774fe95c1ccde1603e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23a5db9f9241f7132df83ceacee13eb5" category="inline-link-macro">다음: 초기 설정.</block>
  <block id="65ee66895a5d90d6bde80ce787a7e3b7" category="paragraph"><block ref="65ee66895a5d90d6bde80ce787a7e3b7" category="inline-link-macro-rx"></block></block>
  <block id="922b9696b39b06f6a4d313569231a446" category="summary">NVIDIA AI Enterprise with NetApp and VMware - Where to Find Additional Information(NetApp 및 VMware - 추가 정보를 찾을 수 있는 위치)</block>
  <block id="77b8a01d0d63ff78898858cf688363c3" category="inline-link-macro">이전: 사용 사례 예 - TensorFlow 교육 작업</block>
  <block id="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="paragraph"><block ref="14b2e29c23cc5c2fbf0ecfe2c97d9919" category="inline-link-macro-rx"></block></block>
  <block id="913e298a14c5b49185ced898ccea22bd" category="list-text">NVIDIA AI Enterprise 및 VMware</block>
  <block id="5fad8e8f46a27398d761d66b0cb3f138" category="paragraph"><block ref="b79ccae54733d96b388303db61e85c7c" category="inline-link-rx"></block>]</block>
  <block id="c85cb3eda6d429393778efbed7420a50" category="list-text">Bobby Oommen, 선임 NetApp 선임 관리자</block>
  <block id="c4321e9f60724f09a097b4d8b79c6e7b" category="list-text">Ramesh Isaac, NetApp 시스템 관리자</block>
  <block id="cf4995eac87d7ce5351e1043fe85683c" category="list-text">Ronney Daniel, NetApp 기술 마케팅 엔지니어</block>
  <block id="ffdaf4e44bdc58181aaa1fb09d821794" category="summary">NetApp 및 VMware를 사용하는 NVIDIA AI 엔터프라이즈 - NVIDIA NGC 소프트웨어 활용</block>
  <block id="a99b0f81ba7eb4c3316c034815d10d6f" category="doc">NVIDIA NGC 소프트웨어를 활용합니다</block>
  <block id="c9af43d59068b9518707160eb6b96225" category="inline-link-macro">이전: 초기 설정.</block>
  <block id="594eb3d3a076d44ee9951aa997704c5a" category="paragraph"><block ref="594eb3d3a076d44ee9951aa997704c5a" category="inline-link-macro-rx"></block></block>
  <block id="4161955dbf0998e264bc502f3cedc932" category="paragraph">이 섹션에서는 NVIDIA AI 엔터프라이즈 환경에서 NVIDIA NGC 엔터프라이즈 소프트웨어를 활용하기 위해 수행해야 하는 작업에 대해 설명합니다.</block>
  <block id="cdc25880ca2e070e7e8937596a923a72" category="inline-link-macro">다음: 설정.</block>
  <block id="990700dce54370c3a1bca7246dfa67a2" category="paragraph"><block ref="990700dce54370c3a1bca7246dfa67a2" category="inline-link-macro-rx"></block></block>
  <block id="d6b1f830356956d1f4b73438f8604232" category="summary">NetApp 및 VMware를 사용하는 NVIDIA AI 엔터프라이즈 - NVIDIA NGC 소프트웨어 활용 - 설정</block>
  <block id="d0dad2e446397223579c27c4071bd112" category="inline-link-macro">이전: NVIDIA NGC 소프트웨어를 활용합니다.</block>
  <block id="149dec50621ec3639bea5fc28effa6cf" category="paragraph"><block ref="149dec50621ec3639bea5fc28effa6cf" category="inline-link-macro-rx"></block></block>
  <block id="7bb37c1d3fb64e908e6704f53b5fe4a8" category="paragraph">이 섹션에서는 NVIDIA AI Enterprise 환경에서 NVIDIA NGC 엔터프라이즈 소프트웨어를 활용하기 위해 수행해야 하는 초기 설정 작업에 대해 설명합니다.</block>
  <block id="6641666d7bc2748bab0ac80cdec3a2a3" category="inline-link-macro">초기 설정</block>
  <block id="512338e48541699ec73dae999f67080a" category="paragraph">이 섹션에 요약된 단계를 수행하기 전에 에 나와 있는 지침에 따라 NVIDIA AI Entprise 호스트 소프트웨어를 이미 구축했다고 가정합니다 <block ref="a8e4d2617194ed990c0124f2cc8aee91" category="inline-link-macro-rx"></block> 페이지.</block>
  <block id="c23799b3650257af14b8af5acb107354" category="section-title">vGPU를 사용하여 Ubuntu 게스트 VM을 생성합니다</block>
  <block id="0271f6ade1f60c92c6548f0e5c440e4e" category="inline-link-macro">NVIDIA AI Enterprise 구축 가이드 를 참조하십시오</block>
  <block id="1d7d5c692ef1d70e3217e93bb16af99e" category="paragraph">먼저 vGPU를 사용하여 Ubuntu 20.04 게스트 VM을 만들어야 합니다. vGPU를 사용하여 Ubuntu 20.04 게스트 VM을 생성하려면 의 지침 개요를 따르십시오 <block ref="f5168fb76d8813fb2707289c4637d2ea" category="inline-link-macro-rx"></block>.</block>
  <block id="70c95294a49e1475adbde86d8eae754e" category="section-title">NVIDIA 게스트 소프트웨어를 다운로드하고 설치합니다</block>
  <block id="6148d2809a69d7225df7c6dcc1b5f94f" category="inline-link-macro">NVIDIA AI Enterprise 빠른 시작 가이드 를 참조하십시오</block>
  <block id="8f3d19df984dedd40b9998136343e036" category="paragraph">그런 다음 이전 단계에서 생성한 게스트 VM 내에 필요한 NVIDIA 게스트 소프트웨어를 설치해야 합니다. 게스트 VM 내에서 필요한 NVIDIA 게스트 소프트웨어를 다운로드하여 설치하려면 의 섹션 5.1-5.4에 설명된 지침을 따르십시오 <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>.</block>
  <block id="15186686bd7e9c36683658388b6865b0" category="admonition">섹션 5.4에 설명된 검증 작업을 수행할 때, 가이드를 작성한 후 CUDA 컨테이너 이미지가 업데이트되었으므로 다른 CUDA 컨테이너 이미지 버전 태그를 사용해야 할 수 있습니다. 검증을 위해 'NVIDIA/CUDA:11.0.3-BASE-uubu20.04'를 사용했습니다.</block>
  <block id="f43e7f8a79b8984748fff81eeb0f8c5f" category="section-title">AI/분석 프레임워크 컨테이너 다운로드</block>
  <block id="12a93794571377dc80b4be8c2f22349c" category="paragraph">그런 다음, 게스트 VM 내에서 사용할 수 있도록 NVIDIA NGC에서 필요한 AI 또는 분석 프레임워크 컨테이너 이미지를 다운로드해야 합니다. 게스트 VM 내에서 프레임워크 컨테이너를 다운로드하려면 에 설명된 지침을 따르십시오 <block ref="26bd3715eff2817a0154bee58d883e27" category="inline-link-macro-rx"></block>.</block>
  <block id="5a8b2b886d790892b5beca474e789276" category="section-title">NetApp DataOps 툴킷을 설치하고 구성합니다</block>
  <block id="a225239f36328db667324928281cd834" category="paragraph">그런 다음 게스트 VM 내에 기존 환경을 위한 NetApp DataOps 툴킷을 설치해야 합니다. NetApp DataOps 툴킷은 게스트 VM 내의 터미널에서 ONTAP 시스템의 스케일아웃 데이터 볼륨을 직접 관리하는 데 사용할 수 있습니다. 게스트 VM에 NetApp DataOps 툴킷을 설치하려면 다음 작업을 수행하십시오.</block>
  <block id="e0288a23fbe1bfdb5f5b06d39e315992" category="list-text">PIP를 설치합니다.</block>
  <block id="bb5f723fd408b79a93de1e726de66dd1" category="list-text">게스트 VM 터미널에서 로그아웃한 후 다시 로그인합니다.</block>
  <block id="c456f18c285a54b87c3bc96f0ee32ebb" category="list-text">NetApp DataOps 툴킷을 구성합니다. 이 단계를 완료하려면 ONTAP 시스템에 대한 API 액세스 세부 정보가 필요합니다. 스토리지 관리자로부터 이러한 정보를 얻어야 할 수 있습니다.</block>
  <block id="defe5f6be79f86b85d956d3e53c7ac4d" category="section-title">게스트 VM 템플릿을 생성합니다</block>
  <block id="d5d979be97f5a76cf2676ef5a9c7f071" category="paragraph">마지막으로, 게스트 VM을 기반으로 VM 템플릿을 생성해야 합니다. 이 템플릿을 사용하여 NVIDIA NGC 소프트웨어를 사용하기 위한 게스트 VM을 빠르게 생성할 수 있습니다.</block>
  <block id="fec1fe0b41ba3927cfb9ac7c0507a1f5" category="paragraph">게스트 VM을 기반으로 VM 템플릿을 생성하려면 VMware vSphere에 로그인하고 게스트 VM 이름을 마우스 오른쪽 단추로 클릭한 다음 '클론'을 선택하고 '템플릿으로 클론 복제...'를 선택한 다음 마법사를 따릅니다.</block>
  <block id="05e042a4870614727b5012704b95e5ec" category="paragraph"><block ref="05e042a4870614727b5012704b95e5ec" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0ad90a409faffb6ba8eef6ec1658543c" category="inline-link-macro">다음: 사용 사례 예 - TensorFlow 교육 작업</block>
  <block id="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="paragraph"><block ref="2dbc93dcf9e19b9e4c3cdac9786d0d7d" category="inline-link-macro-rx"></block></block>
  <block id="e4f8ad54c095217d5da72f9ba2ad87d4" category="summary">NetApp 및 VMware를 사용하는 NVIDIA AI 엔터프라이즈 - NVIDIA NGC 소프트웨어 활용 - 사용 사례 - TensorFlow 교육 작업</block>
  <block id="b26247c1865d93ea590ef10d1150c2ae" category="doc">사용 사례 - TensorFlow 교육 작업 예</block>
  <block id="9e4efb6787f44fcab6b00e2afd36fcee" category="inline-link-macro">이전: 설정.</block>
  <block id="fd157334647c1bdd933147dbf284f59e" category="paragraph"><block ref="fd157334647c1bdd933147dbf284f59e" category="inline-link-macro-rx"></block></block>
  <block id="ff35b7c65e31b6103dee61bd8d89ee4f" category="paragraph">이 섹션에서는 NVIDIA AI Enterprise 환경 내에서 TensorFlow 교육 작업을 실행하기 위해 수행해야 하는 작업에 대해 설명합니다.</block>
  <block id="cd33d31cec93ae54705bbc90e8ffbc09" category="paragraph">이 섹션에 설명된 단계를 수행하기 전에 에 설명된 지침에 따라 게스트 VM 템플릿을 이미 생성했다고 가정합니다 <block ref="8c165f1fe6ca595dd726d3af3dcdf541" category="inline-link-macro-rx"></block> 페이지.</block>
  <block id="c8281ef65e7f967dfd74821eada0aed1" category="section-title">템플릿에서 게스트 VM을 생성합니다</block>
  <block id="8f195db6a3d092a2d990de535475fb82" category="paragraph">먼저 이전 섹션에서 생성한 템플릿에서 새 게스트 VM을 생성해야 합니다. 템플릿에서 새 게스트 VM을 생성하려면 VMware vSphere에 로그인하고 템플릿 이름을 마우스 오른쪽 단추로 클릭한 다음 '이 템플릿에서 새 VM...'을 선택하고 마법사를 따릅니다.</block>
  <block id="9739d298a43441a49ece0169468d720e" category="paragraph"><block ref="9739d298a43441a49ece0169468d720e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="229fea3a8aa56b262dc3dbb996d81052" category="section-title">데이터 볼륨 생성 및 마운트</block>
  <block id="bbdc3bf8e16f6c828df2941c605e4ef3" category="paragraph">그런 다음, 교육 데이터 세트를 저장할 새 데이터 볼륨을 생성해야 합니다. NetApp DataOps 툴킷을 사용하여 새 데이터 볼륨을 빠르게 생성할 수 있습니다. 다음 예제 명령은 용량이 2TB인 'imagenet'이라는 이름의 볼륨을 생성하는 방법을 보여 줍니다.</block>
  <block id="bed0c39c2a853526e026bbd1d13b0a29" category="paragraph">데이터 볼륨을 데이터로 채우기 전에 게스트 VM 내에 마운트해야 합니다. NetApp DataOps 툴킷을 사용하여 데이터 볼륨을 빠르게 마운트할 수 있습니다. 다음 예제 명령은 이전 단계에서 생성한 볼륨의 모팅을 보여 줍니다.</block>
  <block id="3418ebfa9c3ff38c1bfcd27521d4e641" category="section-title">데이터 볼륨을 채웁니다</block>
  <block id="ec123d1ef57b0ab158b8c891c6b936da" category="paragraph">새 볼륨을 프로비저닝하고 마운트한 후에는 소스 위치에서 교육 데이터 세트를 가져와서 새 볼륨에 배치할 수 있습니다. 일반적으로 이 작업은 S3 또는 Hadoop 데이터 레이크에서 데이터를 가져오는 작업을 수반하며, 경우에 따라 데이터 엔지니어의 도움을 받게 됩니다.</block>
  <block id="d3e84e47f561be23742b30b8c3dd7d10" category="section-title">TensorFlow 교육 작업을 실행합니다</block>
  <block id="f6a0596efc5c96edbcbffd2d19e48f41" category="paragraph">이제 TensorFlow 교육 작업을 실행할 준비가 되었습니다. TensorFlow 교육 작업을 실행하려면 다음 작업을 수행하십시오.</block>
  <block id="83c4072e784e0048974a7fbaef9e7567" category="list-text">NVIDIA NGC 엔터프라이즈 TensorFlow 컨테이너 이미지를 가져옵니다.</block>
  <block id="26857c717c90aa9ca7c999304a47e6ad" category="list-text">NVIDIA NGC 엔터프라이즈 TensorFlow 컨테이너의 인스턴스를 시작합니다. '-v' 옵션을 사용하여 데이터 볼륨을 컨테이너에 연결합니다.</block>
  <block id="c8dc137f2972d72ed031b7e9000c2b58" category="list-text">컨테이너 내에서 TensorFlow 교육 프로그램을 실행합니다. 다음 예제 명령은 컨테이너 이미지에 포함된 ResNet-50 훈련 프로그램의 예를 보여 줍니다.</block>
  <block id="5a71d5119829b5c78d377ad1aa8a90a8" category="inline-link-macro">다음: 추가 정보를 찾을 위치.</block>
  <block id="d5ca60148a0675b3abb83565cbf886d7" category="paragraph"><block ref="d5ca60148a0675b3abb83565cbf886d7" category="inline-link-macro-rx"></block></block>
  <block id="54d7050762b4d8c4af04f27ce33f1f9b" category="summary">NetApp 및 VMware를 사용하는 NVIDIA AI Enterprise - 초기 설정</block>
  <block id="232b44c6dbb39fe55ed3d2ae7953c0ce" category="paragraph"><block ref="232b44c6dbb39fe55ed3d2ae7953c0ce" category="inline-link-macro-rx"></block></block>
  <block id="cb8b0bf52601ee3b7c48b31850f1a45a" category="paragraph">이 섹션에서는 NetApp 및 VMware에서 NVIDIA AI Enterprise를 활용하기 위해 수행해야 하는 초기 설정 작업에 대해 설명합니다.</block>
  <block id="5600e01753ba1c962c6d52ee6f0bdc72" category="inline-link-macro">NVIDIA AI 엔터프라이즈 제품 지원 매트릭스</block>
  <block id="b46df8af05863c37f3cd1fd611e5d2d9" category="inline-link-macro">NetApp 및 VMware 솔루션 설명서</block>
  <block id="bf44a799ea99e6a60d34e10561a03e4e" category="paragraph">이 섹션에 요약된 단계를 수행하기 전에 이미 VMware vSphere 및 NetApp ONTAP를 구축했다고 가정합니다. 을 참조하십시오 <block ref="7fc42871bfcfe7310a97a725dca473d8" category="inline-link-macro-rx"></block> 지원되는 vSphere 버전에 대한 자세한 내용은 를 참조하십시오. 을 참조하십시오 <block ref="627bf2e2dbf74de3f0be812563fb3ec4" category="inline-link-macro-rx"></block> NetApp ONTAP와 함께 VMware vSphere를 구축하는 방법에 대한 자세한 내용은 를 참조하십시오.</block>
  <block id="a067b320746c7952a2b152f5a3af42b4" category="section-title">NVIDIA AI Enterprise Host Software를 설치합니다</block>
  <block id="ee9d732a57ce821e52e753e2b4bd4a84" category="paragraph">NVIDIA AI Entraprise 호스트 소프트웨어를 설치하려면 의 섹션 1-4에 설명된 지침을 따르십시오 <block ref="d00914f6db2027b3a594dc7a64e68b3c" category="inline-link-macro-rx"></block>.</block>
  <block id="cd110cdaa9b8e3838ddcbc34234a5317" category="inline-link-macro">다음: NVIDIA NGC 소프트웨어를 활용합니다.</block>
  <block id="4a2f52c7b89633749f7644b851cb7bc6" category="paragraph"><block ref="4a2f52c7b89633749f7644b851cb7bc6" category="inline-link-macro-rx"></block></block>
  <block id="befb671d4726ae8f3ef8dab781033dcc" category="inline-link-macro">스토리지 스냅샷을 사용하는 Oracle 멀티 테넌트 플러그형 데이터베이스 클론</block>
  <block id="9e2a9bc8a2f8e27bba893554318c300a" category="paragraph">리포지토리의 모든 주요 변경 사항(새로운 솔루션, 주요 업데이트, 새로운 비디오/데모 등)은 에서 추적됩니다 <block ref="62716531525ec9f2f5022745ce51b3a4" category="inline-link-macro-rx"></block>.</block>
  <block id="aeb79a141f3c3f603cee05dfa64277aa" category="inline-link-macro">Amazon FSx 스토리지를 사용하여 하이브리드 클라우드에서 Oracle 데이터베이스 운영을 현대화하십시오</block>
  <block id="a35641294527bf47526671d78d910a7e" category="list-text"><block ref="a35641294527bf47526671d78d910a7e" category="inline-link-macro-rx"></block></block>
  <block id="958dc0e3d1fcb4de4e8d506927ac81d3" category="sidebar">EC2/FSx 모범 사례에 기반한 Oracle 데이터베이스 구축</block>
  <block id="4d6f369fd362693ff1e7c02749ce60d9" category="example-title">구내 Jetstream DR을 설치하는 방법</block>
  <block id="91a827791bf5a23c98b3d5c7a69fe4ac" category="example-title">프라이빗 클라우드에 AVS용 Jetstream DR을 설치하는 방법</block>
  <block id="60e3a8b4e353d775c34a7d4d16b3d797" category="example-title">페일오버/페일백 수행 방법</block>
  <block id="a401c5c75859d12743686229123750bc" category="cell">2022년 9월 14일</block>
  <block id="1063ab954566d1fe67239a1e96653a34" category="cell">AWS/VMC에 대한 보충 NFS 데이터 저장소 옵션이 추가되었습니다</block>
  <block id="b7331610ced5770e91945f51e7656fcf" category="cell">권장 ESXi 및 ONTAP 설정에 대한 "재부팅 필요" 정보가 추가되었습니다</block>
  <block id="b6f0b1a9bd2c9c15cf02f97ead58d81f" category="list-text">FSX ONTAP는 보조 NFS 데이터 저장소입니다</block>
  <block id="aa98d71f784cc09bb41639407a3263d5" category="inline-link-macro">VMC에 대한 보조 NFS 데이터 저장소 옵션</block>
  <block id="d1a83ba46ad33cdd3fc8bd7a4e73176d" category="paragraph">자세한 내용을 확인하십시오 <block ref="faae832115390401ac20af18b263017a" category="inline-link-macro-rx"></block>. 자세한 내용을 확인하십시오 <block ref="5f92906354f0392b0588cf1731a5faf9" category="inline-link-macro-rx"></block>.</block>
  <block id="7bf09ad035c9bf793d2fa043537aefb5" category="paragraph">자세한 내용을 확인하십시오 <block ref="cfba6c34c6cd33cf1694f8b48900db44" category="inline-link-macro-rx"></block>. 자세한 내용을 확인하십시오 <block ref="a17693751f1eec7b9dedb49cf6a85cf2" category="inline-link-macro-rx"></block>.</block>
  <block id="483a9a3bc528f4d194f9f8f3d2a8411a" category="inline-link-macro">AVS용 보조 NFS 데이터 저장소 옵션</block>
  <block id="7772cfe9c74977a26d43cfda8576ff1a" category="paragraph">자세한 내용을 확인하십시오 <block ref="b477b575563628f6202758f8f4d6ef57" category="inline-link-macro-rx"></block>. 자세한 내용을 확인하십시오 <block ref="e443f734d29f2f5bbba9449696a3f3f6" category="inline-link-macro-rx"></block>.</block>
  <block id="026198900efc3d72ea20d8258c67523f" category="paragraph">자세한 내용을 확인하십시오 <block ref="c21bcdb7b1f85738a3211dff01d327ef" category="inline-link-macro-rx"></block>. 자세한 내용을 확인하십시오 <block ref="266132cd9b913032bfeaea66cd238ea6" category="inline-link-macro-rx"></block>.</block>
  <block id="110493136fe9c9cec7895d42493cf949" category="doc">TR-4938: AWS에서 VMware Cloud를 사용하여 ONTAP용 Amazon FSx를 NFS 데이터 저장소로 마운트합니다</block>
  <block id="fac58d9bf77947f6384b904919414388" category="paragraph">성공적인 모든 조직은 혁신과 현대화의 길을 따라 있습니다. 이 프로세스의 일환으로, 기업은 일반적으로 기존 VMware 투자를 사용하여 클라우드의 이점을 활용하고 가능한 한 원활하게 프로세스에 대한 재해 복구를 마이그레이션, 버스트, 확장 및 제공하는 방법을 모색합니다. 클라우드로 마이그레이션하는 고객은 탄력성 및 폭발적 사용 사례, 데이터 센터 종료, 데이터 센터 통합, 수명 종료 시나리오, 인수 합병 인수 합병 등</block>
  <block id="040632d7dc15d3ff95c3010b585c825d" category="inline-link">최신 통합</block>
  <block id="d790d297409e3864a7ea5e89c42f2281" category="paragraph">대부분의 고객은 VMware Cloud on AWS를 통해 고유한 하이브리드 기능을 제공할 수 있기 때문에 이 옵션을 선호하지만, 제한된 기본 스토리지 옵션으로 인해 스토리지 집약적인 워크로드를 사용하는 조직에는 유용성이 제한되었습니다. 스토리지가 호스트에 직접 연결되어 있으므로 스토리지를 확장하는 유일한 방법은 호스트를 추가하는 것입니다. 이렇게 하면 스토리지 집약적인 워크로드에서 비용이 35-40% 이상 증가할 수 있습니다. 이러한 워크로드는 추가 성능이 아닌 추가 스토리지 및 분리된 성능을 필요로 하며, 이는 추가 호스트에 대한 비용을 지불한다는 것을 의미합니다. 이 부분에서 가 사용됩니다<block ref="ce6e0c0e7e2ab2c5f159e9999125a0f1" category="inline-link-rx"></block> ONTAP용 FSx는 AWS 기반의 VMware Cloud를 통해 스토리지 및 성능 집약적인 워크로드에 매우 유용합니다.</block>
  <block id="419a1659c567e39948d6e6e837c207d8" category="paragraph">다음과 같은 시나리오를 생각해 보겠습니다. 고객은 마력(vCPU/vmem)을 위해 8개의 호스트를 필요로 하지만 스토리지에 대한 요구 사항도 상당히 있습니다. 평가를 기준으로 이 고객은 스토리지 요구사항을 충족하기 위해 16개의 호스트를 필요로 합니다. 이렇게 하면 실제로 필요한 모든 것이 더 많은 스토리지일 때 마력을 추가로 구입해야 하기 때문에 전체 TCO가 증가합니다. 마이그레이션, 재해 복구, 사용 급증, 개발/테스트, 등.</block>
  <block id="477aa009d1d8f0ca50a38092473e92c8" category="paragraph">이 문서에서는 ONTAP용 FSx를 AWS의 VMware Cloud용 NFS 데이터 저장소로 프로비저닝하고 연결하는 데 필요한 단계를 안내합니다.</block>
  <block id="dfc876546f6dc1183356f103bca8c9bf" category="section-title">연결 옵션</block>
  <block id="96ebe87ba2bf6e2436936fad5261faee" category="paragraph">이 섹션에서는 고속 접속 아키텍처와 추가 호스트 추가 없이 SDDC 클러스터의 스토리지를 확장하는 솔루션을 구축하는 데 필요한 단계에 대해 설명합니다.</block>
  <block id="373604cc33724c808b5ea035d2c5d911" category="paragraph">NetApp ONTAP용 Amazon FSx는 널리 사용되는 NetApp ONTAP 파일 시스템에 구축된 매우 안정적이고 확장 가능하며 고성능의 풍부한 기능 파일 스토리지를 제공하는 완전 관리형 서비스입니다. Amazon FSx for NetApp ONTAP(Multi-AZ)는 가용성 영역 수준 장애 발생 시 NAS 트래픽에 페일오버 기능을 지원하는 부동 IP 주소를 사용합니다. 이 IP 주소는 VPC CIDR 주소 공간 외부에 있으므로 ENI를 통해 SDDC로 라우팅할 수 없습니다. 따라서 VMware Transit Connect를 사용하여 NAS 인터페이스의 부동 IP 주소에 연결해야 합니다.</block>
  <block id="f86935ff4bae98bba5454898ea941c13" category="paragraph"><block ref="f86935ff4bae98bba5454898ea941c13" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b5dfb62423539055e813d9c1ad0de5ec" category="paragraph">고급 배포 단계는 다음과 같습니다.</block>
  <block id="a7e048390e1de16427d130135387bbfa" category="list-text">새로 지정된 VPC에서 ONTAP용 Amazon FSx를 생성합니다.</block>
  <block id="1f950f8c314491fa3429d8c2b47b567d" category="list-text">SDDC 그룹을 만듭니다.</block>
  <block id="564e0792e18e12a265348716dc476e35" category="list-text">VMware Transit Connect 및 TGW 접속 장치를 생성합니다.</block>
  <block id="6618150a8dc116ed81a57b9c0241d023" category="list-text">라우팅(AWS VPC 및 SDDC) 및 보안 그룹을 구성합니다.</block>
  <block id="657ef96833b0b326d08849a14b70424f" category="list-text">NFS 볼륨을 SDDC 클러스터에 데이터 저장소로 연결합니다.</block>
  <block id="4950c77542ffaf6f7c4295f413cd34bf" category="inline-link-macro">AWS 기반 VMware Cloud 시작하기</block>
  <block id="38cb82c3cccc048a7afcc98467fce2aa" category="paragraph">ONTAP용 FSx를 NFS 데이터 저장소로 프로비저닝하고 연결하려면 먼저 클라우드 SDDC 환경에서 VMware를 설정하거나 기존 SDDC를 v1.20 이상으로 업그레이드해야 합니다. 자세한 내용은 를 참조하십시오 <block ref="8f2441f58c4fdf4959e58cb9afc7d8c0" category="inline-link-macro-rx"></block>.</block>
  <block id="fcb9956e91549e3dd62d5abdb369413b" category="admonition">ONTAP용 FSX는 현재 확장 클러스터에서 지원되지 않습니다.</block>
  <block id="ee377d68ed297e79a44797bf1a95c224" category="paragraph">이 문서에서는 AWS에서 VMware 클라우드를 사용하여 ONTAP용 Amazon FSx를 구성하는 데 필요한 단계를 설명합니다. ONTAP용 Amazon FSx는 파일 서비스와 함께 애플리케이션 워크로드를 배포 및 관리하는 탁월한 옵션을 제공하는 동시에 애플리케이션 계층에 대한 데이터 요구 사항을 원활하게 만들어 TCO를 절감합니다. 어떤 사용 사례에서든 AWS 기반 VMware Cloud와 Amazon FSx for ONTAP를 함께 사용하여 클라우드의 이점, 일관된 인프라, 그리고 사내 스토리지에서 AWS로 이르는 운영, 워크로드의 양방향 이동성, 엔터프라이즈급 용량 및 성능을 빠르게 실현할 수 있습니다. 스토리지 연결에 사용되는 것과 동일한 친숙한 프로세스 및 절차입니다. 이는 새로운 이름과 함께 변경된 데이터의 위치일 뿐입니다. 도구와 프로세스는 모두 동일하며 ONTAP용 Amazon FSx는 전체 구축을 최적화하는 데 도움이 됩니다.</block>
  <block id="0f7e01a8024cd158b945c34799508470" category="paragraph">이 프로세스에 대해 자세히 알아보려면 자세한 단계별 안내 비디오를 참조하십시오.</block>
  <block id="e4d49e783d07283d117d34b32c4415cd" category="doc">AWS의 보충 NFS 데이터 저장소 옵션</block>
  <block id="b2e86378d41d58201dddc613a82c81e2" category="paragraph">VMware Cloud를 AWS VPC에 연결하여 사용할 준비가 되면 NetApp ONTAP용 Amazon FSx를 원래 연결되거나 기존 기본 VPC가 아닌 새로 지정된 VPC에 구축해야 합니다.</block>
  <block id="b96e49fe229de5c473c616c913f822c8" category="inline-link">VMware Cloud에서 SDDC 그룹 구성</block>
  <block id="ff5a4226923e95cf43bd31559660d1c8" category="paragraph">먼저 SDDC가 있는 지역과 가용성 영역에 VPC를 추가로 구축한 다음, NetApp ONTAP용 Amazon FSx를 새 VPC에 구축합니다.<block ref="5be76f2b0a93cb7fee056cbead96da1a" category="inline-link-rx"></block> 콘솔은 ONTAP용 FSx를 구축할 새로 지정된 VPC에 연결하는 데 필요한 네트워킹 구성 옵션을 활성화합니다.</block>
  <block id="61a4d8e132eda51933073e665a4eac93" category="admonition">AWS SDDC 기반 VMware Cloud와 동일한 가용성 영역에 ONTAP용 FSx를 구축합니다.</block>
  <block id="55304a7521acfdd7143fb9cdb66a6344" category="paragraph">NetApp ONTAP 파일 시스템용 Amazon FSx를 생성하고 마운트하려면 다음 단계를 완료하십시오.</block>
  <block id="1a8a81e4c4d14a95fc47e07b614950b5" category="list-text">https://console.aws.amazon.com/fsx/` 에서 Amazon FSx 콘솔을 열고 * 파일 시스템 생성 * 을 선택하여 * 파일 시스템 생성 * 마법사를 시작합니다.</block>
  <block id="ffd72149dd51740fcd4d150cabc5561f" category="list-text">파일 시스템 유형 선택 페이지에서 * ONTAP * 용 Amazon FSx 를 선택한 후 * 다음 * 을 클릭합니다. 파일 시스템 생성 * 페이지가 나타납니다.</block>
  <block id="e71747de43d70e18285f2764e5a036a6" category="paragraph"><block ref="e71747de43d70e18285f2764e5a036a6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f4817656b0e2a8e3ebdf2bd3377b2456" category="list-text">생성 방법의 경우 * 표준 생성 * 을 선택합니다.</block>
  <block id="35eb19b4c782b6a9c50e35b42f8c1f8c" category="paragraph"><block ref="35eb19b4c782b6a9c50e35b42f8c1f8c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5f47a2dd0d360703b1b45075c63cff1b" category="paragraph"><block ref="5f47a2dd0d360703b1b45075c63cff1b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="11dd82404551d7373785e4fcbc9b1005" category="list-text">VPC(Virtual Private Cloud)용 * 네트워킹 * 섹션에서 경로 테이블과 함께 적절한 VPC 및 기본 서브넷을 선택합니다. 이 경우 드롭다운 메뉴에서 Demo-FSxforONTAP-VPC를 선택합니다.</block>
  <block id="a9bc1797cfb722fb8dbfec3b16f44cb9" category="paragraph"><block ref="a9bc1797cfb722fb8dbfec3b16f44cb9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a560e434862aec182aa626e0de6ca3a" category="list-text">암호화 키의 * 보안 및 암호화 * 섹션에서 저장된 파일 시스템의 데이터를 보호하는 AWS KMS(Key Management Service) 암호화 키를 선택합니다. 파일 시스템 관리 암호 * 의 경우 fsxadmin 사용자의 보안 암호를 입력합니다.</block>
  <block id="9626f8b41e6908a3873b72869026a9da" category="paragraph"><block ref="9626f8b41e6908a3873b72869026a9da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="75f7834ca5cbd9bf6c7a2b2e5073b427" category="list-text">기본 스토리지 가상 시스템 구성 * 섹션에서 SVM의 이름을 지정합니다.</block>
  <block id="7c32cf52ace07fb1672e72defde4ac61" category="admonition">GA 시점에는 4개의 NFS 데이터 저장소가 지원됩니다.</block>
  <block id="5c732cc058a6b6d4676b55223bf85f5f" category="paragraph"><block ref="5c732cc058a6b6d4676b55223bf85f5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="51ac4bf63a0c6a9cefa7ba69b4154ef1" category="cell">설정</block>
  <block id="9f1ef07877f9d85a82bd500f408b4814" category="cell">0%</block>
  <block id="a85c04491cb5bbcb534dc50b65b97530" category="cell">자동 삭제</block>
  <block id="4ec86a7059e3d1002a06c51cbec9ad47" category="cell">Volume/OLDEST_FIRST(볼륨/가장 오래된</block>
  <block id="5987147997d274c5292cab0b0006bef1" category="cell">볼륨 계층화 정책</block>
  <block id="902c737cbaa1a86889c41fec210c805f" category="cell">먼저 시도하십시오</block>
  <block id="f4c25546f220bb5d07f94244c9303967" category="cell">자동 확장</block>
  <block id="4c0abf2d4c54820b8d33061abaf30759" category="cell">스냅샷 정책</block>
  <block id="7c031a8d1af863155f52c6a16c34e0c1" category="paragraph"><block ref="7c031a8d1af863155f52c6a16c34e0c1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3216fa1649258260fcc7fb0c291ff2fb" category="paragraph"><block ref="3216fa1649258260fcc7fb0c291ff2fb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b2d2529841aebb478d3748c5528b4696" category="list-text">파일 시스템 생성 * 페이지에 표시된 파일 시스템 구성을 검토합니다.</block>
  <block id="a7f848b3fa508f3850a768505d8de438" category="list-text">Create File System * 을 클릭합니다.</block>
  <block id="8c63e014bdbc571ce93e6b93d628d4e2" category="paragraph"><block ref="8c63e014bdbc571ce93e6b93d628d4e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef936ea5a977520b22368e3dbad83818" category="paragraph"><block ref="ef936ea5a977520b22368e3dbad83818" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f36688b56a320d6a48574b6092329e26" category="paragraph">ONTAP용 Amazon FSx 성능에 대한 자세한 내용은 를 참조하십시오<block ref="45a884cbefaf34ae6fd7defa1c6be8c3" category="inline-link-rx"></block>.</block>
  <block id="6d3e0252631c98651b062c2fc85ad936" category="example-title">2단계: SDDC 그룹 만들기</block>
  <block id="82fd9df68bd32ff1e24a66dc98b1e237" category="paragraph">파일 시스템 및 SVM을 생성한 후 VMware Console을 사용하여 SDDC 그룹을 생성하고 VMware Transit Connect를 구성합니다. 이렇게 하려면 다음 단계를 완료하고 VMware Cloud Console과 AWS 콘솔 간에 이동해야 합니다.</block>
  <block id="cfdf8bfdb817c09bbd04bc1f8aec640d" category="list-text">VMC 콘솔('https://vmc.vmware.com` )에 로그인합니다.</block>
  <block id="7959effd33c50a6257362d30f57326de" category="list-text">Inventory * 페이지에서 * SDDC Groups * 를 클릭합니다.</block>
  <block id="b8f684e055bd625606633c09969e9540" category="list-text">SDDC Groups * 탭에서 * Actions * 를 클릭하고 * Create SDDC Group * 을 선택합니다. 데모 목적으로 SDDC 그룹을 FSxONTAPDatastoreGrp라고 합니다.</block>
  <block id="ab3ee4623c465cb9edfbfeccc6ca86ba" category="list-text">구성원 자격 그리드에서 그룹 구성원으로 포함할 DC를 선택합니다.</block>
  <block id="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="paragraph"><block ref="7e52f6f87b99cfdf5ba2a85e9fe2e795" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ef4fa61cc3be19123a586bd1f8e29e6e" category="list-text">"그룹에 대한 VMware Transit Connect 구성 시 첨부 파일 및 데이터 전송당 비용이 청구되는지" 여부를 확인한 다음 * 그룹 생성 * 을 선택합니다. 이 프로세스를 완료하는 데 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="a3f9cb9f805a5c5abc39008c09a7f2b1" category="paragraph"><block ref="a3f9cb9f805a5c5abc39008c09a7f2b1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b17d6992e86eba9b41dc8a123e6e8fb" category="example-title">3단계: VMware Transit 접속 구성</block>
  <block id="dde50926302f7ec2015681d9c6a96817" category="inline-link">그룹에 외부 VPC를 연결하는 지침</block>
  <block id="8ebb2eb5630a76b1fe25c564158f80f6" category="list-text">새로 생성된 지정된 VPC를 SDDC 그룹에 연결합니다. External VPC * 탭을 선택하고 를 따릅니다<block ref="b29559f9008e4efd51a29ebaa2e02912" category="inline-link-rx"></block>. 이 프로세스를 완료하는 데 10-15분 정도 걸릴 수 있습니다.</block>
  <block id="ac3defa2f0f4566a77fa8a1608c03c29" category="paragraph"><block ref="ac3defa2f0f4566a77fa8a1608c03c29" category="inline-image-macro-rx" type="image"></block></block>
  <block id="633bd88abb0a911cad29e551387946b8" category="list-text">계정 추가 * 를 클릭합니다.</block>
  <block id="cec0191b59ccf1e88591a2c33ced8c4b" category="list-text">ONTAP 파일 시스템용 FSx를 프로비저닝하는 데 사용된 AWS 계정을 제공합니다.</block>
  <block id="7dee7e783d13b6d5d415926ce0bfc306" category="list-text">추가 * 를 클릭합니다.</block>
  <block id="6a61e881b78352ae03c966d62ea1556d" category="list-text">AWS 콘솔로 돌아가서 동일한 AWS 계정에 로그인하고 * Resource Access Manager * 서비스 페이지로 이동합니다. 리소스 공유를 수락할 수 있는 버튼이 있습니다.</block>
  <block id="8fd6a12de6d9f24e91a89e003fe58ccd" category="paragraph"><block ref="8fd6a12de6d9f24e91a89e003fe58ccd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b5910ab3c7395246baf35589ead376f" category="admonition">외부 VPC 프로세스의 일부로, 리소스 액세스 관리자를 통해 AWS 콘솔을 통해 새 공유 리소스에 대한 메시지가 표시됩니다. 공유 리소스는 VMware Transit Connect에서 관리하는 AWS Transit Gateway입니다.</block>
  <block id="48fb6ee0dcc903c5fcfb9d1b15f2e3ad" category="list-text">자원 공유 동의 * 를 클릭합니다.</block>
  <block id="333af8dd6d2cdd37922abf85ebd7179a" category="paragraph"><block ref="333af8dd6d2cdd37922abf85ebd7179a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4e8fd48c7d02ab11c26a3e1882fd465a" category="list-text">VMC 콘솔로 돌아가면 외부 VPC가 연결된 상태에 있음을 알 수 있습니다. 이 작업은 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="49ba8c3245c3d07a0ed6167e466b43e1" category="example-title">4단계: 전송 게이트웨이 접속 장치를 작성합니다</block>
  <block id="9db03aae4c3c9b489ffa8fc51242bb7e" category="list-text">AWS 콘솔에서 VPC 서비스 페이지로 이동하여 FSx 파일 시스템 프로비저닝에 사용된 VPC로 이동합니다. 여기에서 오른쪽의 탐색 창에 있는 * Transit Gateway Attachment * 를 클릭하여 전송 게이트웨이 첨부 파일을 만듭니다.</block>
  <block id="6d37c5b21f24bcca6d12fc5042185d45" category="list-text">VPC Attachment * 에서 DNS 지원 이 선택되어 있는지 확인하고 ONTAP용 FSx가 배포된 VPC를 선택합니다.</block>
  <block id="1dcf4f0eabbad36654447dfb34f237b4" category="paragraph"><block ref="1dcf4f0eabbad36654447dfb34f237b4" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc8975fcad9c69f295fb15e5a13f2e40" category="list-text">Create * * * TRANSIT Gateway Attachment * 를 클릭합니다.</block>
  <block id="89483e202d4e3f304f821390c4a7a7cc" category="paragraph"><block ref="89483e202d4e3f304f821390c4a7a7cc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d2e46cdc573277625faad22330cf154f" category="list-text">VMware Cloud Console로 돌아가 SDDC 그룹 &gt; 외부 VPC 탭으로 다시 이동합니다. FSx에 사용되는 AWS 계정 ID를 선택하고 VPC를 클릭한 다음 * Accept * 를 클릭합니다.</block>
  <block id="36fdbe9831a4d114b9917bcd89fac4c2" category="paragraph"><block ref="36fdbe9831a4d114b9917bcd89fac4c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c3d94f2f6e446adaf149684973d365ee" category="paragraph"><block ref="c3d94f2f6e446adaf149684973d365ee" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a81e35637833161072f4311f3cb32ac5" category="admonition">이 옵션은 몇 분 정도 걸릴 수 있습니다.</block>
  <block id="08783cc975c3897f2fbd3671f2f82620" category="list-text">그런 다음 * Routes * 열의 * External VPC * 탭에서 * Add Routes * 옵션을 클릭하고 필요한 경로를 추가합니다.</block>
  <block id="028ce3dd99b949a311e20d5403f17103" category="list-text">NetApp ONTAP 부동 IP용 Amazon FSx의 부동 IP 범위에 대한 경로입니다.</block>
  <block id="40fd62af6ee711539f271fc7513146a5" category="paragraph"><block ref="40fd62af6ee711539f271fc7513146a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e007562e54d1b070168e2b77a1766fdc" category="paragraph"><block ref="e007562e54d1b070168e2b77a1766fdc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="937e96f27b1c5759ad7123b60f3775db" category="example-title">5단계: 라우팅(AWS VPC 및 SDDC) 및 보안 그룹을 구성합니다</block>
  <block id="b484a2377e56c4c768b99fa1ba1b950a" category="list-text">AWS 콘솔에서 VPC 서비스 페이지에서 VPC를 찾아 SDDC로 돌아가는 경로를 생성하고 VPC에 대한 * main * route 테이블을 선택합니다.</block>
  <block id="a563a48fad77850ec5058bda722b322a" category="list-text">하단 패널에서 라우팅 테이블을 찾아 * 라우트 편집 * 을 클릭합니다.</block>
  <block id="85f3b67e1c98b7869b12f779e5f02b51" category="paragraph"><block ref="85f3b67e1c98b7869b12f779e5f02b51" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fb26d090b870823ae62ed28050e3aa89" category="list-text">Edit route * 패널에서 * Add route * 를 클릭하고 * Transit Gateway * 와 관련 TGW ID 를 선택하여 SDDC 인프라스트럭처의 CIDR을 입력합니다. 변경 내용 저장 * 을 클릭합니다.</block>
  <block id="99388849296a3bbf649a9a953c7ce7d5" category="paragraph"><block ref="99388849296a3bbf649a9a953c7ce7d5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="74b3770eecc791f1748634fe7f30e559" category="paragraph"><block ref="74b3770eecc791f1748634fe7f30e559" category="inline-image-macro-rx" type="image"></block></block>
  <block id="358c085fce4b273ef954f6147feeb2c8" category="admonition">인바운드 규칙을 SDDC 인프라스트럭처의 CIDR 블록으로 업데이트합니다.</block>
  <block id="268ce11e03f9defefab0c436b3818aab" category="admonition">연결 문제를 방지하기 위해 VPC(ONTAP용 FSx가 있는 경우) 경로 테이블이 업데이트되었는지 확인합니다.</block>
  <block id="a3debdddc4080cea8851b37aee79d278" category="admonition">NFS 트래픽을 허용하도록 보안 그룹을 업데이트합니다.</block>
  <block id="492fa7be92a68b15ae3479a6542a7774" category="example-title">6단계: NFS 볼륨을 SDDC 클러스터에 데이터 저장소로 연결합니다</block>
  <block id="e91ba866f25c52426b4d551f9fa981ef" category="paragraph">파일 시스템이 프로비저닝되고 접속이 완료되면 VMware Cloud Console에 액세스하여 NFS 데이터 저장소를 마운트합니다.</block>
  <block id="3c4c5dd0c54ac8e289c4fb955dfe019e" category="list-text">VMC 콘솔에서 SDDC의 * Storage * 탭을 엽니다.</block>
  <block id="b953143972b1f780c4334b7673a4c696" category="paragraph"><block ref="b953143972b1f780c4334b7673a4c696" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5b525bd0f1409ea87d946684edb92331" category="list-text">ATTACH DataStore * 를 클릭하고 필요한 값을 입력합니다.</block>
  <block id="ad7075e284143c915d4b8c07e499daa4" category="admonition">NFS 서버 주소는 FSx &gt; Storage virtual machines 탭 &gt; Endpoints within AWS console 아래에서 찾을 수 있는 NFS IP 주소입니다.</block>
  <block id="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="paragraph"><block ref="98c1a8bf80cc3d0fcacfd52aeb1ac321" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d13c0b52cc34c4f5571b5ea17a13e01" category="list-text">데이터 저장소 연결 * 을 클릭하여 데이터 저장소를 클러스터에 연결합니다.</block>
  <block id="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="paragraph"><block ref="3d8b70e4499f2e2dd0c18b8b7f29eff9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ea3387672e6f02f40253d603226e4fd8" category="list-text">아래와 같이 vCenter에 액세스하여 NFS 데이터 저장소를 검증합니다.</block>
  <block id="30880d4531deb5f77cf22e65ed7f3bc8" category="paragraph"><block ref="30880d4531deb5f77cf22e65ed7f3bc8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ff56eef7a458cc9250ee84cb0b8b3752" category="cell">FSX ONTAP<block ref="b9210f6aa16b7e370d59e02bd5b54f88" category="inline-link-macro-rx"></block></block>
  <block id="b2859c129ed9d2683658aaef48d31759" category="doc">솔루션 이름&gt;</block>
  <block id="4845fee41e2c9edce3bd46094fdb57a2" category="paragraph">작성자:&lt;이름&gt;, &lt;제목&gt;, &lt;회사&gt;</block>
  <block id="ef1e6887c579ba81dcedc3f4e3793cd2" category="section-title">대상</block>
  <block id="46c04e63acdf5955295f68d8a963bfbd" category="paragraph">이 솔루션은 &lt;GOAL&gt;에 관심이 있는 &lt;ROLE&gt;을(를) 위한 것입니다.</block>
  <block id="1d00e7dce692e8dc3f6877f035e3a616" category="paragraph">또는</block>
  <block id="b98cf6de800fd94a50eaa1fff8bfd974" category="section-title">솔루션 테스트/검증 환경</block>
  <block id="aca7234abb238eb8646973440eb294d3" category="paragraph">이 솔루션의 테스트/검증은 최종 배포 환경과 일치하거나 일치하지 않을 수 있는 랩에서 수행되었습니다. 자세한 내용은 다음 섹션을 참조하십시오.</block>
  <block id="bb46e30937334302b789ae4644fdc412" category="image-alt">솔루션 아키텍처 다이어그램</block>
  <block id="39f3ba4cf87d6a47181e787c275344e5" category="section-title">하드웨어/소프트웨어 구성 요소</block>
  <block id="958c530ea1ae0e18b942f8784148734c" category="cell">* 하드웨어 *</block>
  <block id="619d009ae026df3741648cc5d1d82614" category="cell">하드웨어 이름&gt;</block>
  <block id="295146e011d375f76fc8093d2a5f746a" category="cell">모델/버전&gt;</block>
  <block id="18206c5add24b8898426959c811b779b" category="cell">추가 정보</block>
  <block id="7eef23b11d6e87eee968a9bef33fd707" category="cell">* 소프트웨어 *</block>
  <block id="b8b4ca3eb830ebaf39f536d59b342a79" category="cell">소프트웨어 이름&gt;</block>
  <block id="192dcc5c64e1f37fd6c9e50a1b157443" category="cell">버전&gt;</block>
  <block id="94f04537971d7a4a561c607ec55952a2" category="section-title">추가 참고 사항</block>
  <block id="5f8c710bd804698095dac1f01702f2dc" category="list-text">참고 1</block>
  <block id="b5be88cc2b21098a0407835f4cf72ead" category="list-text">참고 n</block>
  <block id="dd1d4adbfe73c3cd87fc248a003b05a0" category="section-title">솔루션 구축</block>
  <block id="335680aa8906e185cbdaebb23568afb0" category="example-title">단계 1:&amp;lt; 설명 단계 이름 &amp;GT;</block>
  <block id="8368bea2982e0341bdf3dd2e21ae59ba" category="list-text">과제 1</block>
  <block id="246b81c0be9905296fd43f043d65acf9" category="list-text">작업 n</block>
  <block id="dc84800e606f171d76211870801056d9" category="example-title">단계 2:&amp;lt; 설명 단계 이름 &amp;GT;</block>
  <block id="1361b538eba6bc2813d883fde1eaa379" category="example-title">단계 n:&amp;lt; 설명 단계 이름 &amp;GT;</block>
  <block id="b57b7771f6b9c2ff769c133b18814390" category="section-title">기타 구축 옵션</block>
  <block id="43437c4ac7246d8571bf69d647faab0e" category="inline-link-macro">문서에 대한 설명입니다</block>
  <block id="0da1d1196a3aec2a948937502374b5bb" category="list-text"><block ref="0da1d1196a3aec2a948937502374b5bb" category="inline-link-macro-rx"></block></block>
  <block id="71214e9c5af2e86babf8e62565a8dda2" category="inline-link-macro">다른 문서에 대한 설명입니다</block>
  <block id="2757c805d63f926c06b19e462b16de69" category="list-text"><block ref="2757c805d63f926c06b19e462b16de69" category="inline-link-macro-rx"></block></block>
  <block id="2f9ce81cf9e5f73733bacd731daaedbc" category="sidebar">보충 NFS 데이터 저장소: 개요</block>
  <block id="cd9738c68373595541959c8e55ede29e" category="sidebar">보충 NFS 데이터 저장소: 옵션</block>
  <block id="00ec4042cd11b865f5a96645c8f6abca" category="sidebar">보충 NFS 데이터 저장소로서의 FSX ONTAP: 개요</block>
  <block id="74fed8860f1d0399cb4c6a16b2510cd1" category="sidebar">VMC용 보조 NFS 데이터 저장소입니다</block>
  <block id="d251fcb24842564580e4c994b283538e" category="cell">FSxN/VMC 및 ANF/AVS용 TCO 계산기 및 시뮬레이터에 대한 링크가 추가되었습니다</block>
  <block id="8625e1de7be14c39b1d14dc03d822497" category="sidebar">도구</block>
  <block id="e5365f39437feb49b24eddfa73253c24" category="sidebar">ONTAP+ VMC TCO 계산기에 대한 FSX</block>
  <block id="4856ec39dcc21fb53484ef230701e66b" category="sidebar">ONTAP + VMC 시뮬레이터의 FSX</block>
  <block id="67c988a2e4a11132f6866cf0aff95568" category="sidebar">ANF + AVS TCO 계산기</block>
  <block id="faeff2a13624e3552e026ffcba1c35dc" category="sidebar">ANF + AVS 시뮬레이터</block>
  <block id="71b51633ceea83cdf1136196fce39901" category="admonition">게스트 내 스토리지는 Cloud Volumes ONTAP을 AWS VMC에 연결하는 유일한 지원 방법입니다.</block>
  <block id="9761d5208d76a88ba5a08152c4431c2f" category="admonition">게스트 내 스토리지는 Cloud Volumes ONTAP를 Azure VMware 솔루션에 연결하는 유일한 지원 방법입니다.</block>
  <block id="bb19e956b854f8e209f51237a29feb31" category="admonition">현재 CVO(Cloud Volumes ONTAP)를 AWS VMC에 연결하는 유일한 방법은 게스트 내 스토리지 뿐입니다.</block>
  <block id="714163a53d8c9c62964e7d6931c1c9ec" category="admonition">연결된 VPC에는 ONTAP용 FSx를 배포할 수 없습니다. 대신 새로 지정된 VPC에 구축한 다음 SDDC 그룹을 통해 VPC를 vTGW(VMware Managed Transit Gateway)에 연결해야 합니다.</block>
  <block id="d7641cecb55db2651063f3be07278b31" category="example-title">1단계: 새로 지정된 VPC에서 ONTAP용 Amazon FSx를 생성합니다</block>
  <block id="4e0c93d8fb3b7cedc4f8d92d8d692e85" category="admonition">데이터 저장소 크기는 고객마다 조금씩 다릅니다. NFS 데이터 저장소당 권장되는 가상 머신 수는 주관적이지만, 많은 요소가 각 데이터 저장소에 배치할 수 있는 최적의 VM 수를 결정합니다. 대부분의 관리자가 용량만 고려하지만 VMDK에 전송되는 동시 I/O의 양은 전체 성능을 위한 가장 중요한 요소 중 하나입니다. 온프레미스에서 성능 통계를 사용하여 데이터 저장소 볼륨을 적절하게 사이징합니다.</block>
  <block id="2f0865bd1a50874390d074524829bfc4" category="admonition">연결된 VPC가 아닌 새 지정 VPC를 사용해야 합니다.</block>
  <block id="55431364d6f307d0c1adb83c07425d6c" category="admonition">기본적으로 ONTAP용 FSx는 파일 시스템의 기본 엔드포인트 IP 주소 범위로 198.19.0.0/16 을 사용합니다. 엔드포인트 IP 주소 범위가 AWS SDDC, 관련 VPC 서브넷 및 사내 인프라에서 VMC와 충돌하지 않는지 확인합니다. 확실하지 않은 경우 충돌하지 않는 겹치지 않는 범위를 사용하십시오.</block>
  <block id="505582b625e19e5637e0557ad61b581e" category="list-text">기본 볼륨 구성 * 섹션에서 데이터 저장소에 필요한 볼륨 이름과 크기를 지정하고 * 다음 * 을 클릭합니다. NFSv3 볼륨이어야 합니다. 스토리지 효율성 * 을 사용하려면 * Enabled * 를 선택하여 ONTAP 스토리지 효율성 기능(압축, 중복제거, 컴팩션)을 켜십시오. 생성 후 셸을 사용하여 *_volume modify_ * 를 사용하여 다음과 같이 볼륨 매개 변수를 수정합니다.</block>
  <block id="9fdea1f4f5c62c2485312ab231c865ee" category="cell">볼륨 보장(공간 보장 스타일)</block>
  <block id="bd03fce695997bf49af026bcb349a578" category="cell">없음(씬 프로비저닝됨) – 기본적으로 설정됩니다</block>
  <block id="9399f3b9e96901f84ac3bd68deec8850" category="cell">fractional_reserve(분할 예약)</block>
  <block id="6b3edd41659df403c04fb39ee40b0b0a" category="cell">0% – 기본적으로 설정됩니다</block>
  <block id="dfa2ec9e60d8028b01d021f862fb77da" category="cell">snap_reserve(percent-snapshot-space)</block>
  <block id="80c2511d74ccaf27c63f1b6c3aafb2dc" category="cell">자동 크기 조정(자동 크기 조정 모드)</block>
  <block id="535a7e7f6a8dd82fa6603e44982e0525" category="cell">Enabled(사용) – 기본적으로 설정됩니다</block>
  <block id="df370ff95c6787552e774c17a2878b11" category="cell">스냅샷 전용 – 기본적으로 설정됩니다</block>
  <block id="f072855ce664b2c9dd19371c8f451e72" category="paragraph">다음 SSH 명령을 사용하여 볼륨을 생성하고 수정합니다.</block>
  <block id="82bf57f964fd07a578454495c4ae3a34" category="paragraph">* 셸에서 새 데이터 저장소 볼륨을 생성하려면 * 명령을 사용합니다</block>
  <block id="3fe80d288dea7b9265abdfe33f302a9a" category="paragraph">* 참고: * 쉘을 통해 생성된 볼륨이 AWS 콘솔에 표시되려면 몇 분 정도 걸립니다.</block>
  <block id="34b5a79399461f15942cc2bbb68ddb58" category="paragraph">* 기본적으로 설정되지 않은 볼륨 매개 변수를 수정하는 명령입니다. *</block>
  <block id="8f2384de60fd85d0b57b92b82a7b1835" category="admonition">초기 마이그레이션 시나리오 중에 기본 스냅샷 정책으로 인해 데이터 저장소 용량 꽉 참 문제가 발생할 수 있습니다. 이 문제를 해결하려면 필요에 맞게 스냅샷 정책을 수정하십시오.</block>
  <block id="a19c957e90534613b36e90008ac1736c" category="admonition">이전 단계를 반복하여 용량 및 성능 요구 사항에 따라 더 많은 스토리지 가상 머신 또는 파일 시스템과 데이터 저장소 볼륨을 생성합니다.</block>
  <block id="5659fbd7d9a7a1963d1f57717f874bcb" category="list-text">다음 단계는 관련 VPC의 보안 그룹이 SDDC 그룹 CIDR에 대한 올바른 인바운드 규칙으로 업데이트되었는지 확인하는 것입니다.</block>
  <block id="381318b231b70d3c81a3bb05e8912be3" category="paragraph">이 단계는 적절한 SDDC에 대한 연결을 준비하는 마지막 단계입니다. 파일 시스템이 구성되고 경로가 추가되고 보안 그룹이 업데이트되면 데이터 저장소를 마운트할 때입니다.</block>
  <block id="36c48411397a73fcbe7ccac93862641b" category="admonition">이 문서가 작성된 시점에서 게스트 내 저장소가 유일하게 사용 가능한 옵션이었습니다. 보충 NFS 데이터 저장소 지원이 제공되면 추가 설명서를 사용할 수 있습니다 <block ref="2feee9d08b57f121d415095bba26ae78" category="inline-link-macro-rx"></block>.</block>
  <block id="e60de72a8067fd05498b03b24d9f93e7" category="paragraph">이 솔루션은 다음과 같은 사용 사례를 해결합니다.</block>
  <block id="50f68cc3bee11411ba8ee639a7ed59d7" category="list-text">사용 사례 1&gt;</block>
  <block id="bfbe592724efe7b70f86b50a78741381" category="list-text">사용 사례 n&gt;</block>
  <block id="732f94f3061dc1751b3c7e3ea8566239" category="paragraph">이 솔루션은 다음을 위한 것입니다.</block>
  <block id="dab739113e8cfebbcfcfaea1515c0bcf" category="list-text">역할&gt;, &lt;목표&gt;에 관심이 있는 사용자,</block>
  <block id="7367185552beb127edfea2f14982e67f" category="list-text">역할&gt;, &lt;목표&gt;에 관심이 있는 사용자.</block>
  <block id="44db359cccfc9a14e67b800f405a2078" category="sidebar">자동화 환경 설정</block>
  <block id="1c08b76510a159f0dcb62c62d5584a78" category="paragraph"><block ref="1c08b76510a159f0dcb62c62d5584a78" category="inline-link-macro-rx"></block></block>
  <block id="b5062caa115b4047ecd2ef0d7177923b" category="paragraph">이 TR에 사용된 참조 자료는 다음과 같습니다.</block>
  <block id="7a5b516d0c7b523466aabf4d65c5920e" category="list-text">Apache Spark 아키텍처 및 구성 요소</block>
  <block id="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link"><block ref="71792c2d1ea80e0e082f8dc3cbdabfdd" category="inline-link-rx"></block></block>
  <block id="e37c2ea27f7286c4bd6a5fda415b8de8" category="paragraph"><block ref="e37c2ea27f7286c4bd6a5fda415b8de8" category="inline-link-rx"></block></block>
  <block id="63e2d6091a94e7952a98f50aab0149ce" category="list-text">Apache Spark 사용 사례</block>
  <block id="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link"><block ref="f2b9f91de80e495bcbc6169f57a4bd2d" category="inline-link-rx"></block></block>
  <block id="7bc4162d3088ec5f539bb8bccd911d30" category="paragraph"><block ref="7bc4162d3088ec5f539bb8bccd911d30" category="inline-link-rx"></block></block>
  <block id="506326e78695dcca6de9cbc14a77c5b7" category="list-text">Apache 당면 과제</block>
  <block id="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link"><block ref="6f8995e5d73fedcfa04d4c714e6f7a46" category="inline-link-rx"></block></block>
  <block id="a4047ab5c68e6bd8f8ad5dfc79e46847" category="paragraph"><block ref="a4047ab5c68e6bd8f8ad5dfc79e46847" category="inline-link-rx"></block></block>
  <block id="635dbe8a61ae76776533cf731db5ca3d" category="list-text">스파크 NLP</block>
  <block id="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link"><block ref="164b938eda63c6ce2631a3fcf3f37e5f" category="inline-link-rx"></block></block>
  <block id="4f2faa20c7d825b4d0501e1086305aac" category="paragraph"><block ref="4f2faa20c7d825b4d0501e1086305aac" category="inline-link-rx"></block></block>
  <block id="94f39b7b282094c13473d8b26a45d1f1" category="inline-link"><block ref="94f39b7b282094c13473d8b26a45d1f1" category="inline-link-rx"></block></block>
  <block id="aff4ff24147d7c4a2645c7781e081f7f" category="paragraph"><block ref="aff4ff24147d7c4a2645c7781e081f7f" category="inline-link-rx"></block></block>
  <block id="b507f78e88e67a8302f19d731bc75b06" category="list-text">Deep and Cross Network for Ad Predictions를 클릭합니다</block>
  <block id="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link"><block ref="8ebbe970a3e3c77f7c8e00655ce2e505" category="inline-link-rx"></block></block>
  <block id="ae454d032cd3c53237c03ee439566905" category="paragraph"><block ref="ae454d032cd3c53237c03ee439566905" category="inline-link-rx"></block></block>
  <block id="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link"><block ref="4a695ebb62ee4f32f7dd893fa1e282f9" category="inline-link-rx"></block></block>
  <block id="c0ce2c750c3848619c847bc001ba66be" category="paragraph"><block ref="c0ce2c750c3848619c847bc001ba66be" category="inline-link-rx"></block></block>
  <block id="becd6832ca6f3b6680d480b5802d1435" category="list-text">스트리밍 ETL</block>
  <block id="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link"><block ref="b5924cfbbd0aa8b99cd3b6953ae625a3" category="inline-link-rx"></block></block>
  <block id="8d325f57229e685a7ad47c71dd567604" category="paragraph"><block ref="8d325f57229e685a7ad47c71dd567604" category="inline-link-rx"></block></block>
  <block id="31a31ad34b829349beab62dc154bb53c" category="list-text">Hadoop용 NetApp E-Series 솔루션</block>
  <block id="7cc9f35180bb40054e46d3046347f4fd" category="inline-link"><block ref="7cc9f35180bb40054e46d3046347f4fd" category="inline-link-rx"></block></block>
  <block id="ea07fc98557e1b8c5b675972fe1621da" category="paragraph"><block ref="ea07fc98557e1b8c5b675972fe1621da" category="inline-link-rx"></block></block>
  <block id="6e1ead71812900db964474f24a84ff5e" category="list-text">NetApp AI와 고객 커뮤니케이션을 통한 감정 분석</block>
  <block id="270a8289ec3296709282f87be3043182" category="inline-link"><block ref="270a8289ec3296709282f87be3043182" category="inline-link-rx"></block></block>
  <block id="5d6e0d6396516ff7be3c4a58b49ef3a7" category="paragraph"><block ref="5d6e0d6396516ff7be3c4a58b49ef3a7" category="inline-link-rx"></block></block>
  <block id="a435d889d8c30f88d959b581e585cb98" category="inline-link"><block ref="a435d889d8c30f88d959b581e585cb98" category="inline-link-rx"></block></block>
  <block id="2e0db0f40c94a679b5a5692c131d03f4" category="paragraph"><block ref="2e0db0f40c94a679b5a5692c131d03f4" category="inline-link-rx"></block></block>
  <block id="794cb725c5631ad99b5b7c000307f0df" category="list-text">SnapMirror를 참조하십시오</block>
  <block id="c932e562e101240deed6e4be0656dfd6" category="inline-link"><block ref="c932e562e101240deed6e4be0656dfd6" category="inline-link-rx"></block></block>
  <block id="750daab11890513d7529766b651ae531" category="paragraph"><block ref="750daab11890513d7529766b651ae531" category="inline-link-rx"></block></block>
  <block id="a7ac1d2e69b9bbb9a2accb2ec30a1d69" category="list-text">xCP</block>
  <block id="e7d54d48522774aa8774f3733414d084" category="inline-link"><block ref="f575d0e12f7a285daadcaf60a35e305e" category="inline-link-rx"></block></block>
  <block id="a0b810672fcf48d5064bdbf73f520d55" category="paragraph"><block ref="d41dfcb87efb2171f45941c801c9f5cc" category="inline-link-rx"></block></block>
  <block id="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link"><block ref="90a11f9647f9e3f6cfead9fdd4f0789d" category="inline-link-rx"></block></block>
  <block id="b8cfbcc5c9748a8f12142a1b9aae0e67" category="paragraph"><block ref="b8cfbcc5c9748a8f12142a1b9aae0e67" category="inline-link-rx"></block></block>
  <block id="ce9b5cd96205262213c417b501e9ed55" category="list-text">DataOps 툴킷</block>
  <block id="90f0f970ed32524c528ba2778079d485" category="summary">NetApp은 FAS/AFF, E-Series, Cloud Volumes ONTAP의 3가지 스토리지 포트폴리오를 보유하고 있습니다. Apache Spark를 지원하는 Hadoop 솔루션을 위한 ONTAP 스토리지 시스템을 통해 AFF 및 E-Series를 검증했습니다. NetApp이 제공하는 Data Fabric은 데이터 액세스, 제어, 보호 및 보안을 위해 데이터 관리 서비스와 애플리케이션(구성 요소)을 통합합니다.</block>
  <block id="12a9f57585cd6b3b985dd451bf552845" category="doc">NetApp Spark 솔루션 개요</block>
  <block id="255ce02d0613433bc0a7c76f4afde71e" category="inline-link-macro">이전: 솔루션 기술.</block>
  <block id="dd12a34c3b567f24a9da980ebdd52821" category="paragraph"><block ref="dd12a34c3b567f24a9da980ebdd52821" category="inline-link-macro-rx"></block></block>
  <block id="5e1c0d548834c9871fb6687dd0f1adab" category="paragraph">NetApp은 FAS/AFF, E-Series, Cloud Volumes ONTAP의 3가지 스토리지 포트폴리오를 보유하고 있습니다. Apache Spark를 지원하는 Hadoop 솔루션을 위한 ONTAP 스토리지 시스템을 통해 AFF 및 E-Series를 검증했습니다. NetApp 기반의 Data Fabric은 아래 그림과 같이 데이터 액세스, 제어, 보호 및 보안을 위한 데이터 관리 서비스와 애플리케이션(구성 요소)을 통합합니다.</block>
  <block id="710b54a5dd637d8e21574c4fb3eea545" category="inline-image-macro">Data Fabric은 데이터 관리 서비스 및 애플리케이션을 제공합니다.</block>
  <block id="84996abc8bbc3c77ef59d8a39c852d30" category="paragraph"><block ref="84996abc8bbc3c77ef59d8a39c852d30" category="inline-image-macro-rx" type="image"></block></block>
  <block id="829a597c83ae2b02e991f062bb891ace" category="list-text">* NetApp NFS 직접 액세스 * 는 추가 소프트웨어 또는 드라이버 요구사항 없이 최신 Hadoop 및 Spark 클러스터를 NetApp NFS 볼륨에 직접 액세스할 수 있도록 지원합니다.</block>
  <block id="d075304bce816c2722d405cac9bf4877" category="list-text">* NetApp SnapMirror 기술. * 사내 및 ONTAP 클라우드 또는 NPS 인스턴스 간에 데이터 보호 기능을 제공합니다.</block>
  <block id="bd162abba0390e6a6e2e2581d449bf77" category="paragraph">다음 그림은 NetApp 스토리지를 포함한 Spark 솔루션을 보여 줍니다.</block>
  <block id="0ec1ecf37e474c5f4116ab4ae95e84d9" category="inline-image-macro">NetApp 스토리지로 솔루션 스파크</block>
  <block id="0847e549ec9fd7e676ad66196c4210a2" category="paragraph"><block ref="0847e549ec9fd7e676ad66196c4210a2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc4d71ccd96e1b29bc3437c1cb6a245e" category="paragraph">ONTAP Spark 솔루션은 NetApp NFS 직접 액세스 프로토콜을 사용하여 기존 운영 데이터에 대한 액세스를 통해 데이터 이동 없이 분석 및 AI, ML 및 DL 워크플로우를 지원합니다. Hadoop 노드에 사용 가능한 운영 데이터를 내보내 데이터 이동 없이 분석 및 AI, ML, DL 작업을 수행합니다. Hadoop 노드에서 처리하는 데이터에 NetApp NFS 직접 액세스 또는 사용하지 않고 액세스할 수 있습니다. 독립 실행형 또는 'YARN' 클러스터 관리자를 사용하여 Spark에서 ' 을 사용하여 NFS 볼륨을 구성할 수 있습니다<block ref="7667eac59549f5d64cbcc9214ea613f8" category="inline-link-rx"></block>. 서로 다른 데이터 세트를 사용하여 세 가지 사용 사례를 검증했습니다. 이러한 검증에 대한 자세한 내용은 "테스트 결과" 섹션에 나와 있습니다. (Xref)</block>
  <block id="955ae639ea2500f38215e8263610b119" category="paragraph">다음 그림은 NetApp Apache Spark/Hadoop 스토리지 포지셔닝을 보여줍니다.</block>
  <block id="78157b6c5aece6e0b7b7ea998dce3a8a" category="inline-image-macro">NetApp Apache Spark/Hadoop 스토리지 포지셔닝</block>
  <block id="5af92584fa4ab2b78abca73f9bbdcf42" category="paragraph"><block ref="5af92584fa4ab2b78abca73f9bbdcf42" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3cf3adbf38f17f8e0c86c8531fc379b7" category="paragraph">E-Series Spark 솔루션, AFF/FAS ONTAP Spark 솔루션 및 StorageGRID Spark 솔루션의 고유한 기능을 식별하고 자세한 검증 및 테스트를 수행했습니다. 관찰 결과에 따라, NetApp은 E-Series 솔루션을 그린필드 설치 및 새로운 확장 가능한 구축에 사용하고, 기존 NFS 데이터를 사용하는 데이터 이동 없는 분석, AI, ML, DL 워크로드, 오브젝트 스토리지가 필요할 경우 StorageGRID for AI, ML, DL 및 최신 데이터 분석을 지원하는 AFF/FAS 솔루션을 권장합니다.</block>
  <block id="675ed5324aa6eda280e015498c583161" category="inline-image-macro">Spark에 권장되는 NetApp 솔루션:</block>
  <block id="d3deaa8bf3eb6619cb86d00d661a22e9" category="paragraph"><block ref="d3deaa8bf3eb6619cb86d00d661a22e9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="aa7b20f32446fa30f765cd0b1ca93739" category="paragraph">데이터 레이크는 분석, AI, ML 및 DL 작업에 사용할 수 있는 기본 형식의 대규모 데이터 세트를 위한 스토리지 리포지토리입니다. E-Series, AFF/FAS, StorageGRID SG6060 Spark 솔루션을 위한 데이터 레이크 저장소를 구축했습니다. E-Series 시스템은 HDFS에 Hadoop Spark 클러스터에 액세스할 수 있는 반면, 기존 운영 데이터는 NFS 직접 액세스 프로토콜을 통해 Hadoop 클러스터에 액세스할 수 있습니다. 오브젝트 스토리지에 상주하는 데이터 세트의 경우 NetApp StorageGRID를 통해 S3 및 S3a의 안전한 액세스를 제공합니다.</block>
  <block id="22ad538f7c0e01603f9410a9bdc10d04" category="inline-link-macro">다음: 사용 사례 요약</block>
  <block id="5de3601bc15319fca36066c272d6321d" category="paragraph"><block ref="5de3601bc15319fca36066c272d6321d" category="inline-link-macro-rx"></block></block>
  <block id="fd79b6614eaf33c0131b98cf6d33aef4" category="summary">이 페이지에서는 주요 AI, ML 및 DL 사용 사례 및 아키텍처에 대해 자세히 설명합니다.</block>
  <block id="029e93fe56123e362c90a853d36c91c9" category="doc">주요 AI, ML 및 DL 사용 사례 및 아키텍처</block>
  <block id="4204e74b027f3052d00f7e876556fd90" category="inline-link-macro">이전: 사용 사례 요약</block>
  <block id="8fc7ffb01920f82159e7c7fc73617df5" category="paragraph"><block ref="8fc7ffb01920f82159e7c7fc73617df5" category="inline-link-macro-rx"></block></block>
  <block id="38fe3ee7a8452539638ebb43094bf303" category="paragraph">주요 AI, ML 및 DL 사용 사례 및 방법론을 다음 절로 나눌 수 있습니다.</block>
  <block id="28ab286fd15a84ffcfa82ffe262b2d07" category="section-title">NLP 파이프라인 및 TensorFlow 분산 추론을 스파크합니다</block>
  <block id="b66d8859b0ca8adab0c5459ef44ed90c" category="paragraph">다음 목록에는 데이터 과학 커뮤니티가 다양한 개발 수준에서 채택한 가장 널리 사용되는 오픈 소스 NLP 라이브러리가 포함되어 있습니다.</block>
  <block id="357d19386660ae0694f2fa195678b61a" category="inline-link">자연어 도구 키트(NLTK)</block>
  <block id="b7c0dd146600af70e881dce2c233cdb9" category="list-text"><block ref="202d1986e5208977bf54b6b767767c39" category="inline-link-rx"></block>. 모든 NLP 기술에 대한 완벽한 도구 키트. 2000년대 초반부터 유지되었습니다.</block>
  <block id="76e3c26aea345cd63928dae30c7683b8" category="inline-link">텍스트 부분</block>
  <block id="9733a294c2e8cbac3f50f2b1c6165ac9" category="list-text"><block ref="29dbbb204c6bb7c5433e577a001773ba" category="inline-link-rx"></block>. NLTK 및 패턴 위에 구축된 사용하기 쉬운 NLP 도구 Python API.</block>
  <block id="b8dc45aaa0db9ddabebf51171beed13a" category="inline-link">스탠포드 코어 NLP</block>
  <block id="e566a3c30415cf2003b1ae965e897b0c" category="list-text"><block ref="3aea58940b1efe70ecaf2254ccc89f1e" category="inline-link-rx"></block>. 스탠포드 NLP Group이 개발한 Java의 NLP 서비스 및 패키지.</block>
  <block id="7013def92af3dd7db98d1285170b5c5a" category="inline-link">젠심</block>
  <block id="f669b3f1322541dcae0edc94f45435ac" category="list-text"><block ref="7b679f834cae0cff7425a8dc62e2ec2e" category="inline-link-rx"></block>. 인간을 위한 주제 모델링은 체코 디지털 수학 라이브러리 프로젝트를 위한 Python 스크립트의 모음으로 시작되었습니다.</block>
  <block id="2840ef6b507856e3306a32ffe28a8886" category="inline-link">스파이</block>
  <block id="418cc23cee80079d8aa2ccd37169bfc0" category="list-text"><block ref="bc5121a0541ff390725a7d480b19b87f" category="inline-link-rx"></block>. 트랜스포머용 GPU 가속 기능을 갖춘 Python 및 Cython을 사용한 엔드 투 엔드 산업용 NLP 워크플로.</block>
  <block id="e0b205fce51b69be7136044a22a371ab" category="inline-link">빠른 텍스트</block>
  <block id="07ad1b642fbcf4cbc6f67e8f5b7ce593" category="list-text"><block ref="53fd0bea11d98e3b7893bc4fbf501c85" category="inline-link-rx"></block>. Facebook의 AI 연구(Fair) 연구소에서 만든 단어 인식 및 문장 분류용 무료 경량 오픈 소스 NLP 라이브러리.</block>
  <block id="12680128425c827ef65d76f354329e97" category="inline-link">스파크 ML</block>
  <block id="27e7661d3fd9daf238bb981e30734c3c" category="paragraph">SPARK NLP는 모든 NLP 작업 및 요구 사항을 충족하는 단일 통합 솔루션으로, 실제 생산 사용 사례에 맞게 확장 가능하고 성능이 뛰어나며 정확도가 높은 NLP 기반 소프트웨어를 지원합니다. 이 제품은 전송 학습을 활용하고 연구 및 산업 전반에 걸쳐 최신 최신 알고리즘 및 모델을 구현합니다. Spark는 위의 라이브러리에 대한 완벽한 지원이 부족하기 때문에 Spark NLP를 기반으로 구축되었습니다<block ref="3b3cfa486b6d50798f20e9b1ded08f31" category="inline-link-rx"></block> Spark의 범용 인메모리 분산 데이터 처리 엔진을 미션 크리티컬 프로덕션 워크플로우를 위한 엔터프라이즈급 NLP 라이브러리로 활용하십시오. 주석 달기 는 규칙 기반 알고리즘, 머신 러닝 및 TensorFlow를 활용하여 딥 러닝 구현을 지원합니다. 여기에는 토큰화, 레몬화, 스테밍, 부분 음성 태깅, 명명된 엔터티 인식 등을 포함한 일반적인 NLP 작업이 포함됩니다. 맞춤법 검사 및 정서 분석.</block>
  <block id="5f29df192bff436cf72d454f30a968c1" category="paragraph">Transformers(BERT)의 양방향 인코더 표현은 NLP를 위한 변압기 기반 기계 학습 기술입니다. 사전 교육과 미세 조정 개념을 대중화했습니다. BERT의 변압기 아키텍처는 재발성 신경망(RNN) 기반 언어 모델보다 장기적인 종속성을 더 잘 모델링하는 기계 번역에서 비롯되었습니다. 또한 MLM(Masked Language Modeling) 작업도 도입되었으며, 이 작업에서는 모든 토큰의 임의 15%가 마스킹되고 모델이 이를 예측하여 진정한 방향성을 가능하게 합니다.</block>
  <block id="8f1fadc17d848b3be53c2009f5f9070a" category="inline-link">핀베르트</block>
  <block id="f12fa7d8a39cc8394ad5dfb1afe14bee" category="inline-link">로이터 TRC2</block>
  <block id="3795ebdf5b8232c65a11ceced659b1d5" category="inline-link">금융 서비스 은행</block>
  <block id="575e9b077146ddbbac786ed0a40a1a21" category="inline-link">금융 뉴스를 위한 감정 분석</block>
  <block id="189f0cc22e5920c5fbe48e7f7a384fa4" category="inline-link">문서 DL을 설명합니다</block>
  <block id="8171f59448f55698ad8ecd07ce1633b6" category="paragraph">전문 언어와 해당 영역에 레이블이 지정된 데이터가 없기 때문에 재무 감정의 분석은 어렵습니다.<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>사전 훈련된 BERT에 기반한 언어 모델은 도메인 적용에 적합합니다<block ref="a21d1b93ad8a312fcc9c56c81567ecca" category="inline-link-rx"></block>, 재정 문제, 라벨이 붙은 데이터(<block ref="14fa31c8eadcc29b01046706cfe3add5" category="inline-link-rx"></block>)를 참조하십시오. 연구원들은 재무 용어로 뉴스 기사에서 4개, 500개 문장을 추출했습니다. 그때 16명의 전문가들과 재정 배경을 가진 대학생들은 그 문장을 긍정적이고 중립적이며 부정적으로 표시했다. 2016년부터 2020년까지 FinBERT와 사전 교육 받은 두 개의 다른 파이프라인을 사용하여 상위 10개 NASDAQ 회사 수익 통화 녹취록의 정서를 분석하기 위해 Spark 워크플로를 구축했습니다<block ref="6d4ea12c876c5a993aa1b5d0f03f167f" category="inline-link-rx"></block>,<block ref="520f5e4ba9970dad735654cb1f0d1138" category="inline-link-rx"></block>) Spark NLP에서.</block>
  <block id="026dcbbbfad27f6209a41e9dab2f3aed" category="paragraph">Spark NLP를 위한 기본 딥 러닝 엔진은 손쉬운 모델 구축, 어디서나 강력한 ML 생산, 연구를 위한 강력한 실험을 지원하는 기계 학습용 엔드 투 엔드 오픈 소스 플랫폼인 TensorFlow입니다. 따라서 Spark 'YARN 클러스터' 모드에서 파이프라인을 실행할 때 기본적으로 하나의 마스터 노드와 여러 작업자 노드 및 클러스터에 마운트된 네트워크 연결 스토리지에서 데이터와 모델 병렬화를 통해 분산된 TensorFlow를 실행하고 있었습니다.</block>
  <block id="159bdf3f5d37e56033c6c1736f86b085" category="section-title">Horovod의 분산 훈련</block>
  <block id="ba6c44669e2888938a004611469c95dc" category="inline-link">TR-3969: Hadoop용 NetApp 솔루션</block>
  <block id="6f5ab42847eab5c573282c94e51100a9" category="paragraph">MapReduce 관련 성능을 위한 핵심 Hadoop 검증은 TeraGen, TeraSort, TeraValidate 및 DFSIO(읽기 및 쓰기)를 통해 수행됩니다. TeraGen 및 TeraSort 검증 결과는 에 나와 있습니다<block ref="c56c49d0c7359320f900743306997a3c" category="inline-link-rx"></block> E-Series의 경우 및 AFF의 경우 "스토리지 계층화"(xref) 섹션</block>
  <block id="2c41734dc7928bdea8c2eab845ad7074" category="inline-link">Spark의 Hoborod</block>
  <block id="7509c08cb8b336b99de5f0cd33f545fd" category="paragraph">고객의 요청에 따라 Spark와 함께 분산된 교육을 다양한 사용 사례 중 가장 중요한 것으로 간주합니다. 이 문서에서는 을 사용했습니다<block ref="e46884ff7ae14dc4a4c2907aa0145199" category="inline-link-rx"></block> AFF(All Flash FAS) 스토리지 컨트롤러, Azure NetApp Files 및 StorageGRID를 사용하여 NetApp 사내, 클라우드 네이티브 및 하이브리드 클라우드 솔루션을 통해 Spark 성능을 검증합니다.</block>
  <block id="57b5eacba6da62ec21ea18f95421ef6b" category="paragraph">Horovod on Spark 패키지는 Spark 클러스터에서 분산된 훈련 워크로드를 간단하게 실행할 수 있도록 Horovod를 둘러싸는 편리한 래퍼를 제공합니다. 따라서 훈련 및 추론 데이터가 상주하는 Spark에서 데이터 처리, 모델 훈련 및 모델 평가를 모두 수행하는 엄격한 모델 설계 루프를 사용할 수 있습니다.</block>
  <block id="e556cc2b256f6dd2bbe1cdfdb528c858" category="inline-link">Kaggle Rossmann 매장 판매</block>
  <block id="f2280eb8ac361218b35f9fc97d4027b4" category="paragraph">Spark에서 Horovod를 실행하기 위한 두 가지 API(고급 추정기 API 및 하위 수준의 Run API)가 있습니다. 둘 다 동일한 기본 메커니즘을 사용하여 Spark 실행기에서 Horovod를 실행하지만 Estimator API는 데이터 처리, 모델 훈련 루프, 모델 체크포인트, 메트릭 수집 및 분산 교육을 추상화합니다. Horovod Spark Estimators, TensorFlow 및 Keras를 사용하여 에 기반한 엔드 투 엔드 데이터 준비 및 분산 교육 워크플로를 사용했습니다<block ref="d30b6f4a07a765f48b43dd15bf3bc8ea" category="inline-link-rx"></block> 경쟁업체.</block>
  <block id="fa3406903536d0cf09bf8e66ae33aebf" category="inline-link-macro">주요 활용 사례별로 Python 스크립트</block>
  <block id="94f33f4ba60c5f66bf0c60c3e391a81b" category="paragraph">'keras_spark_horovod_rossmann_estimator.py' 스크립트는 섹션에서 찾을 수 있습니다 <block ref="9843d2ebe8b4d4385946214b6f8e40b8" category="inline-link-macro-rx"></block> 여기에는 다음 세 가지 부분이 포함됩니다.</block>
  <block id="1e0ac520c0a0627793f8b0ca3703e8e1" category="list-text">첫 번째 부분은 Kaggle이 제공하고 커뮤니티에서 수집한 초기 CSV 파일 세트에 대해 다양한 데이터 전처리 단계를 수행합니다. 입력 데이터는 '검증' 하위 세트와 테스트 데이터 세트가 있는 교육 세트로 구분됩니다.</block>
  <block id="80ee77d4db5b8f731e911e7c47803afa" category="list-text">두 번째 부분은 로그 시그마리드 활성화 기능과 ADAM 옵티마이저가 있는 Keras Deep Neural Network(DNN) 모델을 정의하고 Spark On을 사용하여 모델 분산 훈련을 수행합니다.</block>
  <block id="6c32e5a10a8b9f7e225e92b30c4eb494" category="list-text">세 번째 부분은 검증 세트의 전체 평균 절대 오류를 최소화하는 최상의 모델을 사용하여 테스트 데이터 세트에 대한 예측을 수행합니다. 그런 다음 출력 CSV 파일을 만듭니다.</block>
  <block id="ca1ff924f88675800b52c7c1b223b4a2" category="inline-link-macro">“머신 러닝”</block>
  <block id="a67083c66285446e108268f795b72b24" category="paragraph">섹션을 참조하십시오 <block ref="65cdc2076a502903b78fb8128fc1a214" category="inline-link-macro-rx"></block> 다양한 런타임 비교 결과.</block>
  <block id="840da3122eba37f84480a8dc769a8cc3" category="section-title">CTR 예측에 Keras를 사용한 다중 작업자 딥 러닝</block>
  <block id="4debf96216c552af520b74d3d0d2f2dc" category="paragraph">최근 ML 플랫폼 및 애플리케이션의 발전으로 이제 대규모 학습에 많은 관심이 집중되고 있습니다. 클릭 비율(CTR)은 온라인 광고 노출 100회 당 평균 클릭 수(백분율로 표시)로 정의됩니다. 디지털 마케팅, 소매, 전자 상거래 및 서비스 공급자를 포함한 다양한 산업 및 사용 사례에서 핵심 메트릭으로 널리 채택되고 있습니다. 자세한 내용은 를 참조하십시오<block ref="5e9febd4c244550b32d7bb781b595741" category="inline-link-rx"></block> CTR 및 Kubernetes를 통한 엔드 투 엔드 클라우드 AI 워크플로우 구현, 분산된 데이터 ETL, Dask 및 CUDA ML을 사용한 모델 교육에 대한 자세한 내용을 확인하십시오.</block>
  <block id="45c832c8d01426bfb65d74b7c547ad0c" category="inline-link">Criteo Terabyte Click Logs 데이터 세트</block>
  <block id="be1115ec919e48805da898209ea2c15a" category="paragraph">이 기술 보고서에서는 의 변형을 사용했습니다<block ref="1a19f40e7660b78c77663f74c89e1e7b" category="inline-link-rx"></block> (TR-4904 참조) Keras를 사용하여 여러 작업자가 딥 및 크로스 네트워크(DCN) 모델로 Spark 워크플로를 구축하여 로그 손실 오류 기능과 기준 Spark ML 회귀 모델의 성능을 비교한 딥 러닝(Deep and Cross Network) 모델에 대해 알아보십시오. DCN은 경계가 지정된 수준의 효과적인 기능 상호 작용을 효율적으로 캡처하고, 고도의 비선형 상호 작용을 학습하며, 수동 기능 엔지니어링 또는 철저한 검색이 필요하지 않으며, 계산 비용이 낮습니다.</block>
  <block id="71b755d753dcdba2aeca91b65c167330" category="paragraph">웹 스케일 추천 시스템을 위한 데이터는 대부분 불연속적이고 범주적이며, 이는 기능 탐색이 어려운 크고 부족한 기능 공간으로 이어집니다. 이는 대부분의 대규모 시스템을 물류 회귀와 같은 선형 모델로 제한합니다. 그러나 자주 예측 가능한 기능을 식별하고 보이지 않거나 희귀한 크로스 기능을 탐색하는 것은 좋은 예측을 위한 열쇠입니다. 선형 모델은 단순하고, 해석 가능하며, 확장이 쉽지만 표현 능력이 제한적입니다.</block>
  <block id="793743a945a26aaa07de844420d013af" category="paragraph">반면 크로스 기능은 모델의 표현 능력을 향상시키는 데 중요한 것으로 나타났습니다. 하지만 이러한 기능을 식별하려면 수동 기능 엔지니어링이나 철저한 검색이 필요한 경우가 많습니다. 보이지 않는 피처 상호작용에 일반화하기는 어려운 경우가 많습니다. DCN과 같은 교차 신경망(cross neural network)을 사용하면 자동 방식으로 기능적으로 명시적으로 교차하여 작업별 기능별 엔지니어링을 피할 수 있습니다. 크로스 네트워크는 다중 계층으로 구성되어 있으며, 이 경우 가장 높은 수준의 상호 작용이 레이어 깊이에 따라 결정될 수 있습니다. 각 계층은 기존 레이어를 기반으로 보다 높은 수준의 상호 작용을 생성하고 이전 레이어의 상호 작용을 유지합니다.</block>
  <block id="70725839e7d887ef6f8c815f325d4592" category="paragraph">DNN(Deep Neural Network)은 여러 기능에서 매우 복잡한 상호 작용을 포착할 수 있는 가능성을 가지고 있습니다. 그러나 DCN과 비교할 때 거의 많은 매개변수가 필요하며, 상호 기능을 명시적으로 구성할 수 없으며, 일부 유형의 기능 상호 작용을 효율적으로 학습하지 못할 수 있습니다. 크로스 네트워크는 메모리 효율적이고 구현하기 쉽습니다. 상호 및 DNN 구성 요소를 공동으로 교육하여 예측 가능한 기능 상호 작용을 효율적으로 캡처하고 Critio CTR 데이터 세트에 대한 최첨단 성능을 제공합니다.</block>
  <block id="9830e1f81f623b33106acc186b93374e" category="inline-link">ML</block>
  <block id="fefc70efb4580c1020c62303f76330f7" category="inline-link">mllib를 참조하십시오</block>
  <block id="2c9e5f067c0c14c56aa757d792108648" category="inline-link">DeepCTR</block>
  <block id="75e8e622ae2ef0cb646ef505a0b3f7be" category="paragraph">DCN 모델은 포매 및 스태킹 계층, 크로스 네트워크 및 딥 네트워크를 병렬로 사용하여 시작합니다. 두 네트워크의 출력을 결합하는 최종 조합 계층이 이어집니다. 입력 데이터는 희소 및 고밀도 피처를 가진 벡터가 될 수 있습니다. Spark에서는 두 가지 모두 가능합니다<block ref="e0c7aa0ef7a63ea331cba99be2697841" category="inline-link-rx"></block> 및<block ref="495fc8cfd173be827e5c6c8258a34e04" category="inline-link-rx"></block> 라이브러리에는 'parseVector' 형식이 포함됩니다. 따라서 사용자는 두 가지 기능을 구분할 수 있어야 하며 각 함수와 메서드를 호출할 때 유의해야 합니다. CTR 예측과 같은 웹 스케일 추천 시스템에서 입력은 주로 범주적인 기능(예: ``country=USA’)입니다. 이러한 기능은 `[0,1,0,…]’’와 같은 하나의 인기 벡터로 인코딩되는 경우가 많습니다. 'ParseVector'를 사용한 단일 핫 인코딩(OHE)은 끊임없이 변화하고 성장하는 어휘를 사용하여 실제 데이터세트를 처리할 때 유용합니다. 에서 예제를 수정했습니다<block ref="0be922124247f224cab64b030781eed7" category="inline-link-rx"></block> 대용량 어휘를 처리하기 위해 DCN의 포매 및 스태킹 계층에 포매 벡터를 만듭니다.</block>
  <block id="565d2d07d9c220babb78adab27c2243a" category="inline-link">Criteo Display Ads 데이터 세트</block>
  <block id="d05de658e793ee731e5a3782c453caa6" category="paragraph">를 클릭합니다<block ref="8cb83117ecfa6e6678785dbda34d1999" category="inline-link-rx"></block> 광고 클릭률을 예측합니다. 13개의 정수 기능과 각 범주에 높은 카디널리티가 있는 26개의 범주 기능이 있습니다. 이 데이터 세트의 경우 입력 크기가 커서 로그손실이 0.001로 향상되는 것이 실질적으로 중요합니다. 대규모 사용자 기반의 예측 정확도가 약간 개선되는 경우 회사의 수익이 크게 증가할 수 있습니다. 데이터 세트에는 7일 동안 11GB의 사용자 로그가 포함되어 있으며, 이는 약 4100만 개의 레코드에 해당합니다. Spark dataFrame.RandomSplit() 기능을 사용하여 교육(80%), 교차 검증(10%) 및 나머지 10%의 테스트 데이터를 무작위로 분할했습니다.</block>
  <block id="e871e132ed2e9c6d6213da57972adec1" category="paragraph">DCN은 Keras를 통해 TensorFlow에 구현되었습니다. DCN을 통해 모델 교육 프로세스를 구현하는 주요 구성 요소는 다음과 같습니다.</block>
  <block id="18aca2eb061782e34fcc772d780e4327" category="list-text">* 데이터 처리 및 포함. * 실제 가치가 있는 기능은 로그 변환을 적용하여 정규화됩니다. 카테고리 피처의 경우, 치수 6 × (카테고리 카디널리티) 1/4의 고밀도 벡터에 피처를 포함시킵니다. 모든 임베디드 디딩을 연결하면 치수 1026의 벡터가 됩니다.</block>
  <block id="190befa8188b0e07126d23d7488e79e7" category="list-text">최적화. * ADAM 옵티마이저를 사용하여 미니 배치 확률적 최적화를 적용했습니다. 배치 크기가 512로 설정되었습니다. 배치 정규화가 딥 네트워크에 적용되고 그레이디언트 클립 표준은 100으로 설정되었습니다.</block>
  <block id="023b8b252258fa415118862dec994bbf" category="list-text">"규칙화." 우리는 L2 규칙화 또는 중도탈락이 효과가 없는 것으로 확인됨에 따라 조기 정지에 사용했습니다.</block>
  <block id="5f7ce3c44b690052b88504fd4c0ff7bb" category="list-text">* Hyperparameters. * 숨겨진 계층 수, 숨겨진 계층 크기, 초기 학습 속도 및 교차 계층 수에 대한 그리드 검색을 기반으로 결과를 보고합니다. 숨겨진 레이어의 수는 2-5개까지이며 숨겨진 레이어 크기는 32-1024입니다. DCN의 경우 교차 계층 수는 1에서 6까지 있었습니다. 초기 학습 속도는 0.0001에서 0.0001로 조정되었으며 0.0001씩 증가하였습니다. 모든 실험은 훈련 단계 150,000에 일찍 멈추어 적용되었고, 그 이후에는 과다 피팅이 발생하기 시작했습니다.</block>
  <block id="a5203fd5d2ee4a156e177b2b5b5ecb45" category="inline-link">DeepFM</block>
  <block id="ca099c15c1ba89f9956f37979064b6ea" category="inline-link">xDeepFM</block>
  <block id="43d5f147547ecf24ebc038feb06a8312" category="inline-link">자동 내부</block>
  <block id="79249d5f44965bf593f3105190bac784" category="inline-link">DCN v2</block>
  <block id="ebca0d5eb18ce917a3f0d2d49746eb3d" category="paragraph">DCN 외에도 CTR 예측을 위해 기타 인기 있는 딥 러닝 모델도 테스트했습니다(예<block ref="256b68047e4850e72fc6a1a263d88e86" category="inline-link-rx"></block>,<block ref="dc65ad48383bc08407486976f4411f66" category="inline-link-rx"></block>,<block ref="a61c3ddacc920697ed1145d7ed359d25" category="inline-link-rx"></block>, 및<block ref="8b59d0e884bf752e43135b866516c089" category="inline-link-rx"></block>.</block>
  <block id="408be753ce98edae615db82036085d63" category="section-title">검증에 사용된 아키텍처</block>
  <block id="2150013c97241fde077622292dd996b4" category="paragraph">이 검증을 위해 4개의 작업자 노드와 AFF-A800 HA 쌍의 1개의 마스터 노드를 사용했습니다. 모든 클러스터 구성원이 10GbE 네트워크 스위치를 통해 연결되었습니다.</block>
  <block id="de404d7688ac5c78348bfea711a12792" category="paragraph">이러한 NetApp Spark 솔루션 검증을 위해 E5760, E5724, AFF-A800의 3가지 스토리지 컨트롤러를 사용했습니다. E-Series 스토리지 컨트롤러는 12Gbps SAS로 연결된 5개의 데이터 노드에 연결되었습니다. AFF HA 쌍 스토리지 컨트롤러는 10GbE 연결을 통해 Hadoop 작업자 노드에 내보낸 NFS 볼륨을 제공합니다. Hadoop 클러스터 멤버는 E-Series, AFF 및 StorageGRID 하둡 솔루션에서 10GbE 연결을 통해 연결했습니다.</block>
  <block id="f3952bdea9a512245a3b2e368bdd17a4" category="inline-image-macro">검증에 사용된 아키텍처</block>
  <block id="2f2f17293788ab5e5b754a35afe8b3b5" category="paragraph"><block ref="2f2f17293788ab5e5b754a35afe8b3b5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d69bb7b5d4a03684a8454a168278a99a" category="inline-link-macro">다음: 테스트 결과.</block>
  <block id="8e32abf231872a250f5352294ee7f66d" category="paragraph"><block ref="8e32abf231872a250f5352294ee7f66d" category="inline-link-macro-rx"></block></block>
  <block id="ca052b24845534e817869836d49d519a" category="summary">이 문서에서는 Apache Spark 아키텍처, 고객 사용 사례 및 빅데이터 분석 및 인공 지능과 관련된 NetApp 스토리지 포트폴리오에 대해 중점적으로 소개합니다. 또한 적절한 Spark 솔루션을 선택할 수 있도록 업계 표준 AI, 머신 러닝 및 딥 러닝 툴을 일반적인 Hadoop 시스템과 비교하여 다양한 테스트 결과를 제공합니다.</block>
  <block id="58b2293adcda372fb415412d23f01a8e" category="doc">TR-4570: Apache Spark용 NetApp 스토리지 솔루션: 아키텍처, 사용 사례 및 성능 결과</block>
  <block id="057e5f9ddc5d049ab86855dceffd6d14" category="paragraph">Rick Huang, Karthikeyan Nagalingam, NetApp</block>
  <block id="550fd771b94cb8eb3739d16af31243f3" category="paragraph">이 문서에서는 Apache Spark 아키텍처, 고객 사용 사례 및 빅데이터 분석 및 인공 지능(AI)과 관련된 NetApp 스토리지 포트폴리오에 대해 중점적으로 소개합니다. 또한 적절한 Spark 솔루션을 선택할 수 있도록 업계 표준 AI, 머신 러닝(ML) 및 딥 러닝(DL) 툴을 일반적인 Hadoop 시스템과 비교하여 다양한 테스트 결과를 제공합니다. 시작하려면 Spark 아키텍처, 적절한 구성 요소 및 두 가지 배포 모드(클러스터 및 클라이언트)가 필요합니다.</block>
  <block id="9e19cfda234e917201ce19469f25275b" category="paragraph">또한 이 문서는 구성 문제를 해결하기 위한 고객 사용 사례를 제공하며 빅데이터 분석 및 AI, ML, Spark를 지원하는 DL과 관련된 NetApp 스토리지 포트폴리오의 개요를 설명합니다. 그런 다음 Spark 관련 사용 사례 및 NetApp Spark 솔루션 포트폴리오의 테스트 결과를 마무리합니다.</block>
  <block id="ce663ffc6a85b2c97e60368b5a9c76e3" category="paragraph">이 섹션에서는 소매, 디지털 마케팅, 은행, 이산 제조, 프로세스 제조 등 데이터 성장 산업에서 빅데이터 분석 및 AI/ML/DL과 관련된 고객 과제에 대해 정부 및 전문 서비스.</block>
  <block id="8a5bab0d8f4c0d1b73de5ada6b1c91e6" category="section-title">성능을 예측할 수 없습니다</block>
  <block id="9790dc49aa09b4759e4c6ebc65fb4c42" category="paragraph">기존 Hadoop 구축에는 일반적으로 일반 하드웨어가 사용됩니다. 성능을 향상시키려면 네트워크, 운영 체제, Hadoop 클러스터, Spark와 같은 에코시스템 구성 요소 및 하드웨어를 조정해야 합니다. 각 계층을 튜닝하더라도 Hadoop은 사용자 환경에서 고성능을 발휘하도록 설계되지 않은 상용 하드웨어에서 실행되기 때문에 원하는 성능 수준을 달성하는 것이 어려울 수 있습니다.</block>
  <block id="b496a0269649d7b570c2052646fd23b6" category="section-title">미디어 및 노드 장애</block>
  <block id="21af95409591262fb36555acb96262d8" category="paragraph">정상적인 조건에서 상용 하드웨어는 장애가 발생하기 쉽습니다. 데이터 노드의 한 디스크에 장애가 발생하면 기본적으로 Hadoop 마스터는 해당 노드가 정상 상태가 아닌 것으로 간주합니다. 그런 다음 네트워크를 통해 해당 노드의 특정 데이터를 복제본에서 정상 노드로 복제합니다. 이 프로세스는 모든 Hadoop 작업에 대한 네트워크 패킷의 속도를 늦춥니다. 그런 다음, 정상적인 상태가 아닌 노드가 정상 상태가 될 때 클러스터가 데이터를 다시 복제하고 초과 복제된 데이터를 제거해야 합니다.</block>
  <block id="03d4836e0d1deb07679d400b8c88a880" category="section-title">Hadoop 공급업체에 종속</block>
  <block id="bb33286c56b053ae85ab21a377bd4347" category="paragraph">Hadoop 총판은 자체 버전 관리 기능을 통해 Hadoop을 직접 배포하며, 고객은 이 버전을 통해 해당 배포판에 종속됩니다. 그러나 많은 고객들은 특정 Hadoop 배포와 고객을 연계하지 않는 인메모리 분석에 대한 지원을 필요로 합니다. 따라서 고객이 원하는 대로 배포를 변경하고 분석을 실행할 수 있어야 합니다.</block>
  <block id="a940c960f38c44b75bf1da78215690c2" category="section-title">둘 이상의 언어를 지원하지 않습니다</block>
  <block id="65a27ee7da3f8c68004d31f60ab65e55" category="paragraph">고객은 업무를 실행하기 위해 MapReduce Java 프로그램 외에 여러 언어에 대한 지원을 필요로 하는 경우가 많습니다. SQL 및 스크립트와 같은 옵션을 사용하면 답변을 보다 유연하게 얻고, 데이터를 구성 및 검색하는 더 많은 옵션을 사용할 수 있으며, 데이터를 분석 프레임워크로 신속하게 이동할 수 있습니다.</block>
  <block id="f3e2f69098f73bd8bb3cf61330433955" category="section-title">사용의 어려움</block>
  <block id="e2bdfb6bb3e956b38b6aacde957996df" category="paragraph">Hadoop을 사용하기 어렵다고 불만을 토로하는 사람들이 있습니다. 새로운 버전이 출시될 때마다 Hadoop이 더욱 단순해지고 강력해지기는 했지만 이러한 비판은 지속되었습니다. Hadoop을 사용하려면 Java 및 MapReduce 프로그래밍 패턴을 이해해야 합니다. 이는 데이터베이스 관리자와 기존 스크립팅 기술을 사용하는 사람들에게 어려운 과제입니다.</block>
  <block id="5f5f8f99cf4c6ebc0b81445be5328bf6" category="section-title">복잡한 프레임워크 및 도구</block>
  <block id="74faacaf156cd022099bed5469595b3e" category="paragraph">엔터프라이즈 AI 팀은 여러 가지 과제에 직면합니다. 전문 데이터 과학 지식을 갖추고 있더라도 다양한 구축 에코시스템과 애플리케이션을 위한 툴과 프레임워크에서 다른 에코시스템으로 변환되지 않을 수 있습니다. 데이터 과학 플랫폼은 Spark 기반의 해당 빅 데이터 플랫폼과 원활하게 통합되어야 하며, 간편한 데이터 이동, 재사용 가능 모델, 즉시 사용 가능한 코드, 프로토타입 제작, 검증, 버전 관리, 공유, 재사용, 운영 환경에 모델을 빠르게 구축할 수 있습니다.</block>
  <block id="067be0651f3de8fd60ec45827a4078ed" category="section-title">NetApp을 선택해야 하는 이유</block>
  <block id="8ff43bcedde084850831da9cdcc5a43a" category="paragraph">NetApp은 다음과 같은 방법으로 Spark 경험을 개선할 수 있습니다.</block>
  <block id="dc5106ccf618944587be46565f5585cd" category="list-text">NetApp NFS 직접 액세스(아래 그림에 표시)를 사용하면 데이터를 이동하거나 복사하지 않고도 기존 또는 새로운 NFSv3 또는 NFSv4 데이터에 대해 빅데이터 분석 작업을 실행할 수 있습니다. 여러 데이터 복제본을 방지하고 소스와 데이터를 동기화할 필요가 없습니다.</block>
  <block id="38bc62edaebd471500fa64a4758f7f04" category="list-text">스토리지 효율성 향상 및 서버 복제 감소 예를 들어, NetApp E-Series Hadoop 솔루션은 3개의 데이터 복제본이 아닌 2개의 복제본을 필요로 하며 FAS Hadoop 솔루션은 데이터 소스만 필요로 하지만 데이터의 복제 또는 복제본은 필요로 하지 않습니다. NetApp 스토리지 솔루션은 또한 서버 간 트래픽을 줄여 줍니다.</block>
  <block id="2fc945668748ad0173e63b5db34773e7" category="list-text">드라이브 및 노드 장애 시 Hadoop 작업 및 클러스터 동작이 향상됩니다.</block>
  <block id="343500ea6d724fe727d127f6409b86c2" category="list-text">더 나은 데이터 수집 성능:</block>
  <block id="109f256618c8d9037bb2cd6cc28f5959" category="inline-image-macro">대체 Apache Spark 구성</block>
  <block id="ce1f5d61aacdba15be898e2d6408542f" category="paragraph"><block ref="ce1f5d61aacdba15be898e2d6408542f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="40771867b1bf0db74b9505757197a17a" category="paragraph">예를 들어, 금융 및 의료 부문에서 데이터를 한 위치에서 다른 위치로 이동하는 것은 쉬운 일이 아닌 법적 의무를 준수해야 합니다. 이 시나리오에서는 NetApp NFS 직접 액세스가 원래의 위치에서 재무 및 의료 데이터를 분석합니다. 또 다른 주요 이점은 NetApp NFS 직접 액세스를 통해 기본 Hadoop 명령을 사용하여 Hadoop 데이터를 간편하게 보호하고 NetApp의 강력한 데이터 관리 포트폴리오를 통해 데이터 보호 워크플로우를 구축할 수 있다는 것입니다.</block>
  <block id="a9e81b3240a7c1ae64fc23e96c84f4ea" category="paragraph">NetApp NFS 직접 액세스는 Hadoop/Spark 클러스터에 대한 두 가지 유형의 구축 옵션을 제공합니다.</block>
  <block id="4e8fe573a9fe74b6429508c87337b99b" category="list-text">기본적으로 Hadoop 또는 Spark 클러스터는 데이터 스토리지와 기본 파일 시스템에 HDFS(Hadoop Distributed File System)를 사용합니다. NetApp NFS 직접 액세스는 기본 HDFS를 NFS 스토리지로 대체하여 NFS 데이터에 대한 직접 분석을 지원합니다.</block>
  <block id="071998ed00d39b3ff27f5410b196f9cc" category="list-text">다른 구축 옵션에서 NetApp NFS 직접 액세스는 NFS를 단일 Hadoop 또는 Spark 클러스터의 HDFS와 함께 추가 스토리지로 구성할 수 있도록 지원합니다. 이 경우 고객은 NFS 내보내기를 통해 데이터를 공유하고 HDFS 데이터와 함께 동일한 클러스터에서 데이터를 액세스할 수 있습니다.</block>
  <block id="c1923befca33cfe6cc9ace80af8580b6" category="paragraph">NetApp NFS 직접 액세스를 사용할 때의 주요 이점은 다음과 같습니다.</block>
  <block id="91221d408b0c171556751f29fb9d8071" category="list-text">현재 위치에서 데이터를 분석하면 분석 데이터를 HDFS와 같은 Hadoop 인프라스트럭처로 이동하는 데 시간과 성능 소모가 큰 작업이 발생하지 않습니다.</block>
  <block id="1675635f440b61b7219bf7ed2bb2ed27" category="list-text">복제본 수를 3개부터 1개로 축소</block>
  <block id="16f81b84f137a7a52da9ba8d798af622" category="list-text">사용자가 컴퓨팅과 스토리지를 분리하여 독립적으로 확장할 수 있도록 지원</block>
  <block id="71946d3c421aea3a8238a481bebe1919" category="list-text">ONTAP의 강력한 데이터 관리 기능을 활용하여 엔터프라이즈 데이터 보호 제공</block>
  <block id="abebb9b977d736f599ab76c517961b24" category="list-text">Hortonworks 데이터 플랫폼을 사용한 인증</block>
  <block id="3c41c2d3511fa95c83687fae6fb57754" category="list-text">하이브리드 데이터 분석을 구축할 수 있습니다.</block>
  <block id="05550a44691e53e07f81616af5d58e20" category="list-text">동적 다중 스레드 기능을 활용하여 백업 시간 단축</block>
  <block id="009b0bd3acc58fbc1c3db15692583fa9" category="paragraph">을 참조하십시오<block ref="217abb9bc41aa22d30da41b7958b4152" category="inline-link-rx"></block> Hadoop 데이터, 클라우드에서 사내로 백업 및 재해 복구, 기존 Hadoop 데이터에 대한 DevTest, 데이터 보호 및 멀티 클라우드 연결, 분석 워크로드 가속화 등을 지원합니다.</block>
  <block id="3100ca44a05fa97ed5f07875f442084e" category="paragraph">다음 섹션에서는 Spark 고객에게 중요한 스토리지 기능에 대해 설명합니다.</block>
  <block id="da2518ef48c60077e2b2c0be7fed7193" category="section-title">스토리지 계층화</block>
  <block id="d9a83ca3a623dce37a2f84027f1495ce" category="paragraph">Hadoop 스토리지 계층화를 사용하면 스토리지 정책에 따라 다양한 스토리지 유형의 파일을 저장할 수 있습니다. 스토리지 유형으로는 핫, 콜드, 웜, 올 SSD, 원 SSD 등이 있습니다. 그리고 게으른 유영이 있습니다.</block>
  <block id="36edc8f5974bdf6ad51a220254b99dfb" category="paragraph">다음 그림은 Hadoop SSD를 위한 NetApp 솔루션의 성능을 보여줍니다.</block>
  <block id="d09520ed9b4a17ada38e70314907675f" category="inline-image-macro">1TB의 데이터를 정렬할 시간입니다.</block>
  <block id="55fdf8b2dd620bd73dcd37db50e0f0e5" category="paragraph"><block ref="55fdf8b2dd620bd73dcd37db50e0f0e5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c2f530d95c6332b106d86a53b41e4a36" category="inline-link">TR-3969 Hadoop용 NetApp E-Series 솔루션</block>
  <block id="8cdadd1c9614abebd1b476daba691f36" category="list-text">기본 NL-SAS 구성에는 8개의 컴퓨팅 노드와 96개의 NL-SAS 드라이브가 사용되었습니다. 이 구성에서는 4분 38초 내에 1TB의 데이터가 생성되었습니다. 을 참조하십시오<block ref="f08cd7da48b5d74d9eaab10199016f47" category="inline-link-rx"></block> 클러스터 및 스토리지 구성에 대한 자세한 내용은 를 참조하십시오.</block>
  <block id="f895fa75cdc40f4e672bba6f7a873e25" category="list-text">TeraGen을 사용하면 SSD 구성에서 NL-SAS 구성보다 1TB의 데이터가 15.66x 더 빠르게 생성됩니다. 또한 SSD 구성에서는 컴퓨팅 노드 수의 절반과 디스크 드라이브 수의 절반을 사용했습니다(총 24개의 SSD 드라이브). 작업 완료 시간을 기준으로 할 때 NL-SAS 구성의 속도는 약 2배였습니다.</block>
  <block id="c13c2e056adb51078f3067ba570d2780" category="section-title">성능 확장 - 스케일아웃</block>
  <block id="beb08cca1e99e0bdbf11c74ebb62d5ea" category="paragraph">AFF 솔루션에서 Hadoop 클러스터의 컴퓨팅 성능이 더 많이 필요한 경우 적절한 수의 스토리지 컨트롤러를 사용하여 데이터 노드를 추가할 수 있습니다. 스토리지 컨트롤러 어레이당 4개의 데이터 노드로 시작하고 워크로드 특성에 따라 스토리지 컨트롤러당 8개의 데이터 노드로 숫자를 늘리는 것이 좋습니다.</block>
  <block id="431bd1a68814e184bc49ff7231450049" category="paragraph">AFF와 FAS는 데이터 이동 없는 분석에 적합합니다. 계산 요구사항에 따라 노드 관리자를 추가할 수 있으며 무중단 운영을 통해 다운타임 없이 스토리지 컨트롤러를 온디맨드 방식으로 추가할 수 있습니다. NetApp은 AFF NVMe 미디어 지원, 효율성 보장, 데이터 축소, QoS, 예측 분석, FAS 클라우드 계층화, 복제, 클라우드 구축, 보안 고객의 요구사항을 충족할 수 있도록 NetApp에서는 추가 라이센스 비용 없이 파일 시스템 분석, 할당량, 온박스 로드 밸런싱과 같은 기능을 제공합니다. NetApp은 동시 작업 수, 낮은 지연 시간, 단순한 운영, 경쟁업체보다 더 높은 초당 처리 성능 등의 이점을 제공합니다. 또한 NetApp Cloud Volumes ONTAP은 3가지 주요 클라우드 공급자 모두에서 실행됩니다.</block>
  <block id="ccfed4ad520d8db8b13dc91438d30680" category="section-title">성능 확장 - 스케일업</block>
  <block id="9341bdabe891be81d2be3440a4c413b5" category="paragraph">스케일업 기능을 사용하면 스토리지 용량이 더 필요할 때 AFF, FAS, E-Series 시스템에 디스크 드라이브를 추가할 수 있습니다. Cloud Volumes ONTAP를 사용하면 자주 사용되지 않는 데이터를 블록 스토리지의 오브젝트 스토리지로 계층화하고, 추가 컴퓨팅 없이 Cloud Volumes ONTAP 라이센스를 스태킹하는 두 가지 요소의 조합으로 스토리지를 PB 수준으로 확장할 수 있습니다.</block>
  <block id="1a4f71bef2c7cfcc6846e82e9e0e0331" category="section-title">다중 프로토콜</block>
  <block id="11d6ae97757031ae53e1437c9c9b61bd" category="paragraph">NetApp 시스템은 SAS, iSCSI, FCP, InfiniBand를 비롯한 대부분의 Hadoop 구현 프로토콜을 및 NFS 로 이동합니다.</block>
  <block id="98ed4f29e9a08c43fe10dda6782e567e" category="section-title">운영 및 지원 솔루션</block>
  <block id="dc15faa991f0a6740734b42c6e08c347" category="inline-link">MapR</block>
  <block id="464e596f1568de8e5f19e16e09beaaa8" category="inline-link">Hortonworks의</block>
  <block id="f1fd1913c968a1c383c88631e335a7ca" category="inline-link">인증</block>
  <block id="7454739e907f5595ae61d84b8547f574" category="inline-link">파트너</block>
  <block id="b1202a92f536818c64c3005cf78d8e35" category="paragraph">이 문서에 설명된 Hadoop 솔루션은 NetApp에서 지원됩니다. 또한 이러한 솔루션은 주요 Hadoop 총판에서도 인증되었습니다. 자세한 내용은 를 참조하십시오<block ref="cc609e66e0173716d91f0397bfa09e1b" category="inline-link-rx"></block> 사이트<block ref="030fa12946d3d4653223853ac09b7183" category="inline-link-rx"></block> 사이트 및 Cloudera<block ref="110185abc20d52e7eb83135b84742416" category="inline-link-rx"></block> 및<block ref="a573734769be98dedf1aa2242c0eb40c" category="inline-link-rx"></block> 있습니다.</block>
  <block id="7a2a776baec23a88727e6039089b8193" category="inline-link-macro">다음: 대상.</block>
  <block id="e8020665ce34622c78e50d808e554235" category="paragraph"><block ref="e8020665ce34622c78e50d808e554235" category="inline-link-macro-rx"></block></block>
  <block id="49c9a66d1f76b5f264fea5d54130b82a" category="summary">TeraGen 벤치마킹 툴에서 TeraSort 및 TeraValidate 스크립트를 사용하여 E5760, E5724 및 AFF-A800 구성을 사용하여 Spark 성능 검증을 측정했습니다. 또한 세 가지 주요 사용 사례를 테스트했습니다. Spark NLP 파이프라인 및 TensorFlow 분산 교육, Horovod 분산 교육, DeepFM으로 Keras for CTR Prediction을 사용한 다중 작업자 딥 러닝.</block>
  <block id="41be8de44faa8ba43210d7494ee095d2" category="doc">테스트 결과</block>
  <block id="0daa7dd4f2822f3e63bdac1bd5870a75" category="inline-link-macro">이전: 주요 AI, ML 및 DL 사용 사례 및 아키텍처</block>
  <block id="26d27784aaeb94a4670d31f46185d57d" category="paragraph"><block ref="26d27784aaeb94a4670d31f46185d57d" category="inline-link-macro-rx"></block></block>
  <block id="60637296d8b6dcd84aaff3afc778241d" category="paragraph">TeraGen 벤치마킹 툴에서 TeraSort 및 TeraValidate 스크립트를 사용하여 E5760, E5724 및 AFF-A800 구성을 사용하여 Spark 성능 검증을 측정했습니다. 또한, Spark NLP 파이프라인 및 TensorFlow 배포 교육, Horovod 분산 교육, DeepFM을 통한 CTR 예측에 Keras를 사용한 다중 작업자 딥 러닝 등 3가지 주요 사용 사례를 테스트했습니다.</block>
  <block id="653a9ba51c0af0c11aab6af3ecfdc8c6" category="paragraph">E-Series와 StorageGRID 검증 모두에 Hadoop 복제 계수 2를 사용했습니다. AFF 검증에서는 하나의 데이터 소스만 사용했습니다.</block>
  <block id="6cdf0c4c6177a49f44f3688dd2a5b9ad" category="paragraph">다음 표에는 Spark 성능 검증을 위한 하드웨어 구성이 나와 있습니다.</block>
  <block id="00e536f9715964bf964b4961d7287f95" category="cell">Hadoop 작업자 노드</block>
  <block id="ce1dc110e77caccbe12e51dce2d1c9b7" category="cell">드라이브 유형입니다</block>
  <block id="c8fafade5cff4119459018fc205beed1" category="cell">노드당 드라이브 수</block>
  <block id="bb43878952414106e66a5d3e8902dd46" category="cell">스토리지 컨트롤러</block>
  <block id="2db46c628cfb3bd1545d3b5a14b4a9c5" category="cell">SAS를 참조하십시오</block>
  <block id="d748fcab9e84c60a5a7b1e5ed2d052c8" category="cell">단일 고가용성(HA) 쌍</block>
  <block id="fb5e436e0878dfd2227011932c4eb93c" category="cell">E5760에서</block>
  <block id="072b030ba126b2f4b2374f342be9ed44" category="cell">60</block>
  <block id="6303aa59a000812ac121a6f5238d6c2c" category="cell">단일 HA 쌍</block>
  <block id="83ac07c2ad3d90f5c6608cfaa2eec573" category="cell">E5724)를 참조하십시오</block>
  <block id="26b9fff68b23131979be5c2d9a456454" category="cell">AFF800</block>
  <block id="bddda15d92b567df6d8aa197c281ddc4" category="paragraph">다음 표에는 소프트웨어 요구 사항이 나와 있습니다.</block>
  <block id="8b6f93f33bce541c7f50f8aff637e2e1" category="cell">RHEL을 참조하십시오</block>
  <block id="299e5505ce975112afaefec130cc83e0" category="cell">7.9</block>
  <block id="bedb19167c4cde670f36a4985efbadd2" category="cell">OpenJDK 런타임 환경</block>
  <block id="4fda350b2148254bcd9e67bbdbecdc93" category="cell">1.8.0</block>
  <block id="b185818332a596af6cda9cae4dc594f6" category="cell">OpenJDK 64비트 서버 VM</block>
  <block id="681eea6b2a996d12035edc50dc4cb4c2" category="cell">25.302</block>
  <block id="30a2ec41610037af662087fe85d19a4d" category="cell">2.24.1</block>
  <block id="87f16b82c65c9274a67305d08b5dfecb" category="cell">GCC/G++</block>
  <block id="b87ed8b82b1cf2cb4e4ddaa75ec9e0e4" category="cell">11.2.1</block>
  <block id="8cde774d6f7333752ed72cacddb05126" category="cell">스파크</block>
  <block id="f2f87b58be0d57ecf71ada8df361a2d9" category="cell">3.2.1</block>
  <block id="17e918efeeeb8f100c695e284d5c0a08" category="cell">피스파크</block>
  <block id="1f4e00506ff9fb5fe179f2ba1c60ff61" category="cell">3.1.2</block>
  <block id="401534b4a193f467279a370076ccb955" category="cell">스파르크LP</block>
  <block id="de8a4e99bb5f22ded6d686cfd948274b" category="cell">3.4.2</block>
  <block id="074dd699710da0ec1eb45f13b31788e3" category="cell">TensorFlow를 참조하십시오</block>
  <block id="7fee7bb66f4294c3e32783efa7d9bafc" category="cell">Keras</block>
  <block id="35a0c5fdc22109515a67a96e5e7fb914" category="cell">0.24.3</block>
  <block id="14bdb1335d2386afb42f726416a2a83b" category="section-title">재무 정서 분석</block>
  <block id="559cf37b505e9001d46e6d6bd73e746c" category="inline-link">NVIDIA Riva SDK를 참조하십시오</block>
  <block id="e65b49198d65919095402991b0cf5624" category="inline-link">Tao 프레임워크</block>
  <block id="3f57666cb1b915db482629c0554b2d92" category="paragraph">발표했습니다<block ref="36713788fc49ad5281ee4a8956df0b3b" category="inline-link-rx"></block>즉, 포괄적인 대화형 AI 파이프라인은 를 사용하여 구축되었습니다<block ref="5d9fb1d86d92052bc5dca8ba91d13ff2" category="inline-link-rx"></block>, AFF 스토리지 및 NVIDIA DGX 시스템. 파이프라인은 DataOps 툴킷을 활용하여 배치 오디오 신호 처리, 자동 음성 인식(ASR), 전송 학습 및 정서 분석을 수행합니다.<block ref="8702bd0254f484bdfe9f1ec1c2a853b1" category="inline-link-rx"></block>, 및<block ref="bba656873bd8ccd45c0c4fc908390474" category="inline-link-rx"></block>. 정서 분석 활용 사례를 금융 서비스 산업으로 확대하면서 스파르크LP 워크플로를 구축하고, 명명된 엔터티 인식 등의 다양한 NLP 작업을 위한 BERT 모델을 3개 로드했으며, NASDAQ 상위 10개 기업의 분기별 수익 통화에 대해 문장 수준의 감정을 얻었습니다.</block>
  <block id="ffeb7ccd27ad1e7d783757733dadec57" category="paragraph">다음 스크립트의 entiment_analysis_spark. py는 다음 표와 같이 FinBERT 모델을 사용하여 HDFS에서 전사체를 처리하고 양의, 중성적이고, 부정적인 정서 수를 산출합니다.</block>
  <block id="077259b584adffb379f7f2638be91edc" category="paragraph">다음 표에는 2016년부터 2020년까지 NASDAQ 상위 10대 기업에 대한 순익금 및 문장 수준의 정서 분석이 나와 있습니다.</block>
  <block id="30702e828192097c5634358e6047d0cf" category="cell">정서 수와 백분율</block>
  <block id="7838fb6ed7918fca8c7797b3b68952d2" category="cell">10개 회사 모두</block>
  <block id="8b10e4ae9eeb5684921a9ab27e4d87aa" category="cell">AAPL</block>
  <block id="48af4341f745163f945fa838eeabb062" category="cell">AMD</block>
  <block id="261fd26b0151a81370d097e4ed4c6505" category="cell">AMZN</block>
  <block id="85fd1bb0e226da6a33e9b5dc1a4952f1" category="cell">CSCO</block>
  <block id="e15ce71ff533c9125f11a46c09e2412b" category="cell">GOOGL</block>
  <block id="fc39dab34bbe435680d30933db783ba0" category="cell">아이NTC</block>
  <block id="b004b3ecde24c85e32c1923f10d3fb62" category="cell">MSFT</block>
  <block id="7f5f6a07b14840f4d8a22caa3df2aed0" category="cell">NVDA</block>
  <block id="4f65a47dc5d0d8a27379f2b1b4d9281b" category="cell">양수입니다</block>
  <block id="9e6adb1432c4a75a33d48693328e4159" category="cell">7447</block>
  <block id="18d10dc6e666eab6de9215ae5b3d54df" category="cell">1567</block>
  <block id="5c572eca050594c7bc3c36e7e8ab9550" category="cell">743</block>
  <block id="f90f2aca5c640289d0a29417bcb63a37" category="cell">290</block>
  <block id="08d98638c6fcd194a4b1e6992063e944" category="cell">682를 참조하십시오</block>
  <block id="795c7a7a5ec6b460ec00c5841019b9e9" category="cell">826</block>
  <block id="677e09724f0e2df9b6c000b75b5da10d" category="cell">824</block>
  <block id="f47d0ad31c4c49061b9e505593e3db98" category="cell">904</block>
  <block id="41ae36ecb9b3eee609d05b90c14222fb" category="cell">417</block>
  <block id="be201b8b1b0b81005e46d49fd301124c" category="cell">중립 카운트</block>
  <block id="1ab0418ab8dc5325176cd1e26660234f" category="cell">64067</block>
  <block id="34ad9bc83e3c72c62281cb2c744ac966" category="cell">6856)을 참조하십시오</block>
  <block id="1796a48fa1968edd5c5d10d42c7b1813" category="cell">7596</block>
  <block id="71e63ef5b7249cfc60852f0e0f5bf4c8" category="cell">5086</block>
  <block id="126c2da128e5b044dc53405c25b4d8de" category="cell">6650</block>
  <block id="dd5bfdeb57f7c75d400de61e99d78e2e" category="cell">5914</block>
  <block id="80c0e8c4457441901351e4abbcf8c75c" category="cell">6099</block>
  <block id="6e4243f5511fd6ef0f03e9f386d54403" category="cell">5715)를 참조하십시오</block>
  <block id="67ba02d73c54f0b83c05507b7fb7267f" category="cell">6189</block>
  <block id="e65849536f4b2170d6b42c8309222fac" category="cell">음의 카운트</block>
  <block id="d860bd12ce9c026814bbdfc1c573f0f5" category="cell">1787</block>
  <block id="c24cd76e1ce41366a4bbe8a49b02a028" category="cell">253</block>
  <block id="979d472a84804b9f647bc185a877a8b5" category="cell">213</block>
  <block id="68d30a9594728bc39aa24be94b319d21" category="cell">84</block>
  <block id="a2557a7b2e94197ff767970b67041697" category="cell">189</block>
  <block id="e2ef524fbf3d9fe611d5a8e90fefdc9c" category="cell">97</block>
  <block id="6a9aeddfc689c1d0e3b9ccc3ab651bc5" category="cell">282</block>
  <block id="7647966b7343c29048673252e490f736" category="cell">89</block>
  <block id="691ec36991472d115c60f32cd84bfc5b" category="cell">분류되지 않은 카운트</block>
  <block id="084b6fbb10729ed4da8c3d3f5a3ae7c9" category="cell">196</block>
  <block id="fbd7939d674997cdb4692d34de8633c4" category="cell">76</block>
  <block id="2706e1e04688749582425d394866306e" category="cell">(총 카운트)</block>
  <block id="b72e37e992d9e460ce2a491a974d13b5" category="cell">73497</block>
  <block id="9f6f2381bc56ef668e94f6d1fb4f6309" category="cell">8676)을 참조하십시오</block>
  <block id="a563b6d5abbf137175059d6bb14672cc" category="cell">8552</block>
  <block id="1134ac57b5b1d38b7d70c1b6feaa28cf" category="cell">5536</block>
  <block id="e1e1f667ce4596e5644be6fab627c226" category="cell">7521</block>
  <block id="176bf6219855a6eb1f3a30903e34b6fb" category="cell">6837</block>
  <block id="75da5036f659fe64b53f3d9b39412967" category="cell">7205</block>
  <block id="e6be4c22a5963ab00dfe8f3b695b5332" category="cell">6822</block>
  <block id="2ea1202aed1e0ce30d41be4919b0cc99" category="cell">6695)를 참조하십시오</block>
  <block id="14d1ed13bbef7783a73cfb9346480ce2" category="paragraph">백분율의 경우 CEO와 CFO가 말하는 대부분의 문장이 사실에 근거해 중립적인 감정을 가지고 있습니다. 수익 통화 중에 분석가들은 긍정적이거나 부정적인 감정을 전달할 수 있는 질문을 합니다. 이에 따라 내당일 또는 다음 날 주가가 음성이나 양성으로 어떻게 영향을 미치는지를 정량적으로 조사할 필요가 있다.</block>
  <block id="3957e5ecad1215aa086504cf2c9ba9cc" category="paragraph">다음 표에는 NASDAQ 상위 10대 기업에 대한 문장 수준의 감정 분석이 백분율로 나와 있습니다.</block>
  <block id="e8a6f3527192d64ba338192ce83f6283" category="cell">정서 백분율</block>
  <block id="3289297424e01eda5b788c083bbf3147" category="cell">긍정적</block>
  <block id="3e263985564016f5774bfb75e31efb0d" category="paragraph">10.13%</block>
  <block id="d983b23f5dc08dfb28a31a898b6fbb6a" category="cell">18.06%</block>
  <block id="ed5f9ec0b398f0f53408828898412855" category="cell">8.69%</block>
  <block id="4d8e8cc0a97724584c1cd94c9485d555" category="cell">5.24%</block>
  <block id="d43cdfa633a84f9ca5043f4eb9363a38" category="cell">9.07%</block>
  <block id="a134c476ebd0c219b3cc879185d436ce" category="cell">12.08%</block>
  <block id="27cd80a0bdc79a724fdc31fa8841e19b" category="cell">11.44%</block>
  <block id="e954976d9376dfe5860acd553772a6df" category="cell">13.25%</block>
  <block id="d30929e6786318e19a22c88447dcc97c" category="cell">6.23%</block>
  <block id="e9bb5320b3890b6747c91b5a71ae5a01" category="cell">중립</block>
  <block id="6c3d5ec0fc8197d1a8f8366e142e37aa" category="cell">87.17%</block>
  <block id="578429551436bef848f19eccdd93fb73" category="cell">79.02%</block>
  <block id="bd443bde0360eb444a5906bea9d081b0" category="cell">88.82%</block>
  <block id="97840fcb1a1f07bef3a12ef2d7975f09" category="cell">91.87%</block>
  <block id="32edca53c1f1f00d865543b435d4ce3a" category="cell">88.42%</block>
  <block id="407967ec786c26ce4ee7608c076fa6d7" category="cell">86.50%</block>
  <block id="9784395b081e78ec535161a5ba0ffd1e" category="cell">84.65%</block>
  <block id="5d4b03024bcea7385ffc5808dd9c3b74" category="cell">83.77%</block>
  <block id="b73c3663139621b36cfdafbeab44fae9" category="cell">92.44%</block>
  <block id="ffb9356ff2b7da85c75c92fa7ea03b8b" category="cell">네거티브</block>
  <block id="672484e7c4fb5894b2ec75fd7e277fe4" category="cell">2.43%</block>
  <block id="c1fbc8ff600d3f571e0c440833db1a10" category="cell">2.92%</block>
  <block id="161a790eac04cd27fc3e4ffd23ba452d" category="cell">2.49%</block>
  <block id="5fd44dd7fb1198b1903141531424bb54" category="cell">1.52%</block>
  <block id="6916237a9f5c4ed45ddfff6fe37f45e7" category="cell">2.51%</block>
  <block id="43045dfce9b4c190cfa4dad2e4bf9457" category="cell">1.42%</block>
  <block id="248199b9ac50bd355476016ad093ac09" category="cell">3.91%</block>
  <block id="1cdf97682ca1bcd645e8dbcebb105529" category="cell">2.96%</block>
  <block id="8098f29a2cea86e839d8ca03f50d52ce" category="cell">1.33%</block>
  <block id="0d015d96f63a8c12d96b8399482b593f" category="cell">분류되지 않았습니다</block>
  <block id="1291f0b93a9f9d5a7e7391a09b5ec0cc" category="cell">0.27%</block>
  <block id="6a040d1ee7200a1dc349a598a163cc38" category="cell">1.37%</block>
  <block id="d9fd62085e1ade721df051f8bc4c320d" category="cell">0.01%</block>
  <block id="28bf86a8e29245437d4ad59ea6e80962" category="paragraph">워크플로우 런타임 측면에서 HDFS의 로컬 모드에서 분산 환경으로 4.78배, NFS를 활용하여 0.14% 향상되었습니다.</block>
  <block id="87509d62c8804cdab48bea9e54013be4" category="paragraph">다음 그림에서 볼 수 있듯이 데이터 및 모델 병렬 처리를 통해 데이터 처리 및 분산 TensorFlow 모델 추론 속도가 향상되었습니다. NFS의 데이터 위치는 워크플로우 병목 현상이 사전 교육 모델을 다운로드하는 것이기 때문에 런타임 성능이 약간 향상되었습니다. 전사체 데이터 세트 크기를 늘릴 경우 NFS의 장점은 더욱 명확합니다.</block>
  <block id="493d0790c882abcf160f461d269c7ec5" category="inline-image-macro">SPARK NLP 정서 분석 종단간 워크플로 런타임.</block>
  <block id="bb9cd55aa92ceddf07506d9a2aaaa151" category="paragraph"><block ref="bb9cd55aa92ceddf07506d9a2aaaa151" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3484d035679c83a95496eb633ffde0d3" category="section-title">Horovod 성과를 통한 분산 훈련</block>
  <block id="319e0ff7f30f4729140562f5e123c5cb" category="inline-link-macro">“주요 활용 사례별로 Python 스크립트”</block>
  <block id="e37af8307fb97140dbcc0c8e2293d58f" category="paragraph">다음 명령을 실행하면 코어 1개가 포함된 160개의 실행자가 있는 단일 마스터 노드를 사용하여 Spark 클러스터에서 런타임 정보와 로그 파일이 생성되었습니다. 메모리 부족 오류가 발생하지 않도록 executor 메모리가 5GB로 제한되었습니다. 섹션을 참조하십시오 <block ref="033a864c436cdbcbe38983e75952a07f" category="inline-link-macro-rx"></block> 'keras_spark_horovod_rossmann_estimator.py'의 데이터 처리, 모델 훈련 및 모델 정확도 계산에 대한 자세한 내용</block>
  <block id="6281f693bbc375a45312622b626d3bcd" category="paragraph">10번의 교육 Epoch를 사용한 결과 런타임은 다음과 같습니다.</block>
  <block id="842bc4f8403cd2df9f22939e3df59aee" category="paragraph">입력 데이터를 처리하고, DNN 모델을 교육하고, 정확도를 계산하고, 예측 결과를 위한 TensorFlow 체크포인트와 CSV 파일을 생성하는 데 43분 이상이 걸렸습니다. 교육 Epoch의 수를 10개로 제한했습니다. 실제로 만족스러운 모델 정확도를 보장하기 위해 대개 100으로 설정되어 있습니다. 일반적으로 교육 시간은 Epoch 수에 비례하여 확장됩니다.</block>
  <block id="1e580bbdb11118035631867d15ad9f25" category="paragraph">다음으로 클러스터에서 사용할 수 있는 4개의 작업자 노드를 사용하고 HDFS에서 데이터와 함께 'YARN' 모드로 동일한 스크립트를 실행했습니다.</block>
  <block id="3661bcf870f3d2b11b0489ed7f0585a7" category="paragraph">결과 런타임은 다음과 같이 개선되었습니다.</block>
  <block id="206c83ab2ec1ea280656b18c0e2dc4dd" category="paragraph">Spark의 Horovod 모델과 데이터 병렬화를 통해 10번의 교육 Epoch로 "원사"와 "로컬" 모드의 실행 속도가 5.29배 빨라졌습니다. 이 그림은 다음 그림과 같이 전설적인 HDFS와 Local로 표시됩니다. 기본 TensorFlow DNN 모델 교육은 GPU를 사용하여 더 가속화될 수 있습니다. NetApp은 이 테스트를 수행하고 결과를 향후 기술 보고서에 게시할 계획입니다.</block>
  <block id="216851565edc166c4409515484cac08b" category="paragraph">다음 테스트에서는 NFS에 상주하는 입력 데이터와 HDFS를 비교하여 실행 시간을 비교했습니다. AFF A800의 NFS 볼륨은 Spark 클러스터의 5개 노드(마스터 1개, 작업자 4명)에 걸쳐 '/Spkdemo/horovod'에 마운트되었습니다. NFS 마운트를 가리키는 '--data-dir' 매개 변수를 사용하여 이전 테스트와 비슷한 명령을 실행했습니다.</block>
  <block id="3ba4d622f15813cc383c433722b46d27" category="paragraph">NFS의 결과 런타임은 다음과 같습니다.</block>
  <block id="7e1d2a49ae0a0e06a39a62e2c7c74877" category="paragraph">다음 그림과 같이 속도가 1.43배 더 향상되었습니다. 따라서 고객은 클러스터에 연결된 NetApp All-Flash 스토리지를 통해 Horovod Spark 워크플로우에서 빠른 데이터 전송 및 배포의 이점을 누리고 단일 노드에서 실행되는 것에 비해 7.55배 더 빠른 속도를 달성할 수 있습니다.</block>
  <block id="88caa92ecc3ebb345f81205aa696e3ac" category="inline-image-macro">Horovod Spark 워크플로 런타임.</block>
  <block id="56085b16b09d835f05c89b29473a0e73" category="paragraph"><block ref="56085b16b09d835f05c89b29473a0e73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b32c8309a0c0ca3edc35cb1597b9182c" category="section-title">CTR 예측 성능을 위한 딥 러닝 모델</block>
  <block id="6ff877f80b732c197c0a432029ad1920" category="paragraph">CTR을 최대화하도록 설계된 추천 시스템의 경우 낮은 순서에서 높은 순서로 수학적으로 계산할 수 있는 사용자 행동 뒤에 정교한 기능 상호 작용을 학습해야 합니다. 낮은 순서의 기능과 높은 순서의 기능 상호 작용은 둘 중 하나를 편향하지 않고 우수한 딥 러닝 모델에 똑같이 중요합니다. 인수 기계 기반 신경 네트워크인 DeepFM(Deep Factorization Machine)은 새로운 신경망 아키텍처에서 기능 학습을 위한 권장 사항과 딥 러닝을 위한 인수 기계(factorization Machine)를 결합합니다.</block>
  <block id="a22645195470eca2abbe24e7d40cde8e" category="inline-link">와이드 &amp; 앰프, 딥 모델</block>
  <block id="4028a7777950de6e915d72e379bde75d" category="paragraph">기존의 공장 인수 기계는 쌍 단위 기능 상호 작용을 기능 간의 잠재적 벡터의 내부 제품으로 모델링하고 이론적으로 높은 순서 정보를 캡처할 수 있지만, 실제로 머신 러닝 실무자는 높은 계산 및 스토리지 복잡성으로 인해 일반적으로 2차 기능 상호 작용만 사용합니다. Google과 같은 딥 뉴럴 네트워크 변형<block ref="6c51a2ff49c9929908a73e863a1421f0" category="inline-link-rx"></block> 반면, 선형 와이드 모델과 딥 모델을 결합하여 하이브리드 네트워크 구조에서 정교한 기능 상호 작용을 학습합니다.</block>
  <block id="a22f6dcc8bc499f7332ab04cdb36fcf9" category="paragraph">이 Wide &amp; Deep Model에는 기본 와이드 모델과 딥 모델에 대한 두 가지 입력이 있으며, 그 중 후자는 여전히 전문적인 피처 엔지니어링을 필요로 하므로 다른 영역에 대해 일반화할 수 없는 기술을 렌더링합니다. 광각 및 딥 모델과 달리, DeepFM은 넓은 부분과 깊은 부분이 동일한 입력 및 포함 벡터를 공유하기 때문에 기능 엔지니어링 없이 RAW 기능으로 효율적으로 교육을 받을 수 있습니다.</block>
  <block id="03eaefcaa3f1aca8b4ffa8b95a4798b9" category="inline-link-macro">“각 주요 활용 사례에 대한 Python 스크립트”</block>
  <block id="105a0d9d76e001ecdab02b77ca3a98ae" category="paragraph">먼저 Criteo '기차.txt'(11GB) 파일을 NFS 마운트에 저장된 CTR_트레인.csv라는 CSV 파일로 처리했습니다. /spclassification_criteo_spark.py라는 섹션을 사용하여 /spkdemo/TR-4570-data로 처리했습니다 <block ref="43e008bfee5963b21d09b0af490bfdd7" category="inline-link-macro-rx"></block> 이 스크립트에서 함수 "process_input_file"은 여러 문자열 메소드를 수행하여 탭을 제거하고 구분 기호로 ",", 줄 바꿈으로 "\n""를 삽입합니다. 코드 블록이 주석으로 표시되도록 원래 기차 .txt만 처리하면 됩니다.</block>
  <block id="c960954a8d119eab5ff32a80d7fcc8e8" category="paragraph">다음 DL 모델 테스트를 위해 입력 파일로 CTR_트레인.csv를 사용했습니다. 후속 테스트 실행에서 입력 CSV 파일은 "'레이블'', 정수 밀도 기능 "['I1', 'I2', 'i3',…, 'I13']" 필드가 포함된 스키마가 있는 Spark DataFrame으로 읽혀졌습니다. 그리고 스파스 피처 "['C1','C2','C3',...,'C26']". 다음 'park-submit' 명령은 입력 CSV에서 수행하고 교차 검증을 위해 20% 분할로 DeepFM 모델을 교육하고 10번의 교육 Epoch 후에 최적의 모델을 선택하여 테스트 세트의 예측 정확도를 계산합니다.</block>
  <block id="52703dd8fd8c710b0aed616d19ddc0fb" category="paragraph">데이터 파일 'CTR_트레인.csv'가 11GB를 초과하므로 오류를 방지하려면 데이터 세트 크기보다 충분한 spark.driver.maxResultSize를 설정해야 합니다.</block>
  <block id="650f108a9978f10b1e3b0a8cbdcd6ac1" category="inline-link">Apache 화살표</block>
  <block id="caa01fc7f9a1a61f1bc803760af8e97f" category="paragraph">위 'parkSession.builder' 설정에서도 활성화했다<block ref="d19d750623d06d371730c4055a0fbbbf" category="inline-link-rx"></block>이는 Df. toPandas() 메소드를 사용하여 Spark DataFrame을 Pandas DataFrame으로 변환합니다.</block>
  <block id="e20380d4fed48eae6cd24a0df1477ba7" category="paragraph">무작위 분할 후, 교육 데이터 세트에 36M 행이 넘고 테스트 세트에 9M 샘플이 있습니다.</block>
  <block id="e6219a2eedbe95f3aa16ed53c4733845" category="paragraph">이 기술 보고서는 GPU를 사용하지 않고 CPU 테스트에 집중되므로 적절한 컴파일러 플래그를 사용하여 TensorFlow를 구축하는 것이 중요합니다. 이 단계는 GPU 가속 라이브러리를 호출하지 않고 TensorFlow의 AVX(Advanced Vector Extensions) 및 AVX2 명령을 최대한 활용합니다. 이러한 기능은 벡터화된 추가, 피드 포워드 내부의 행렬 다중화 또는 역전파 DNN 교육과 같은 선형 대수 계산에 맞게 설계되었습니다. 256비트 부동 소수점(FP) 레지스터를 사용하는 AVX2에서 사용할 수 있는 FMA(Fused Multiply Add) 명령은 정수 코드 및 데이터 형식에 적합하며 최대 2배의 속도를 제공합니다. FP 코드 및 데이터 유형의 경우 AVX2는 AVX에 비해 8% 빠른 속도를 제공합니다.</block>
  <block id="6c396013ff0ebff6a2a96cdc20a4ba4c" category="inline-link">Bazel</block>
  <block id="97139e366bae36e316c93ce5b5e7e10b" category="paragraph">소스에서 TensorFlow를 빌드하려면 사용을 권장합니다<block ref="0bf1f7ee55f693a3c117cb75493ba615" category="inline-link-rx"></block>. 우리는 현재 환경에 대해 셸 프롬프트에서 다음 명령을 실행하여 df, df-plugins, Bazel을 설치합니다.</block>
  <block id="29fe549665f940a68b9303eae3e3a61e" category="paragraph">빌드 프로세스 중에 C++ 17 기능을 사용하려면 GCC 5 이상을 활성화해야 합니다. 이 기능은 RHEL에서 SCL(Software Collections Library)과 함께 제공합니다. 다음 명령은 RHEL 7.9 클러스터에 devt툴셋 및 GCC 11.2.1을 설치합니다.</block>
  <block id="92a2b5cb9c6906035c2864fa225e1940" category="inline-link">기사</block>
  <block id="d4b82f54dfee1e5c527d0d5f8cb0d7aa" category="paragraph">마지막 두 명령은 /opt/rh/dev툴셋 -11/root/usr/bin/gcc(GCC 11.2.1)를 사용하는 dev툴셋 -11을 활성화합니다. 또한 git 버전이 1.8.3 이상인지 확인하십시오(RHEL 7.9와 함께 제공됨). 이를 참조하십시오<block ref="7d93914bddb4046675adee0145ba45bd" category="inline-link-rx"></block> git를 2.24.1로 업데이트하는 경우.</block>
  <block id="dc06a2e6ab4959266b8e70b6a4ecc45c" category="inline-link-macro">“주요 활용 사례별로 Python 스크립트,”</block>
  <block id="c55692ca5ecd175c73f55ba5b9319688" category="paragraph">최신 TensorFlow 마스터 저장소 를 이미 복제했다고 가정합니다. 그런 다음 "작업 공간" 파일을 사용하여 "작업 공간" 디렉토리를 만들어 AVX, AVX2 및 FMA를 사용하여 소스에서 TensorFlow를 구축합니다. '설정' 파일을 실행하고 올바른 Python 바이너리 위치를 지정합니다.<block ref="be1c72ed18fb5f637a2d34d959decb73" category="inline-link-rx"></block> GPU를 사용하지 않았기 때문에 테스트에 사용할 수 없습니다. 설정에 따라 '.bazelrc' 파일이 생성됩니다. 또한 파일을 편집하고 "build--define=no_hdfs_support=false"를 설정하여 HDFS 지원을 활성화했습니다. 절의 '.bazelrc'를 참조하십시오 <block ref="2aec9284f17908b1690444cda81e493c" category="inline-link-macro-rx"></block> 설정 및 플래그의 전체 목록을 표시합니다.</block>
  <block id="8329b0f29ec7368fd026b86d981f9dc7" category="paragraph">올바른 플래그를 사용하여 TensorFlow를 빌드한 후 다음 스크립트를 실행하여 Critio Display Ads 데이터 세트를 처리하고 DeepFM 모델을 교육하고 예측 점수의 Receiver Operating Characteristic Curve(ROC AUC) 아래에 있는 영역을 계산합니다.</block>
  <block id="d5a94c8db568912353007fdff822667e" category="paragraph">10번의 교육 Epoch 후에 테스트 데이터 세트에 AUC 점수를 얻었습니다.</block>
  <block id="e3c9ed451390735cd8c4f8e5eb0e31f5" category="paragraph">이전 사용 사례와 비슷한 방식으로 Spark 워크플로우 런타임을 다른 위치에 있는 데이터와 비교했습니다. 다음 그림은 Spark 워크플로 런타임에 대한 딥 러닝 CTR 예측을 비교한 것입니다.</block>
  <block id="3737826be0460f743becdc4c64050946" category="inline-image-macro">Spark 워크플로 런타임에 대한 딥 러닝 CTR 예측 비교</block>
  <block id="d27b678d975cf1fb0769c3e664f4f2dd" category="paragraph"><block ref="d27b678d975cf1fb0769c3e664f4f2dd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f7eb641fcfa1ced825edab271ee870e9" category="inline-link-macro">다음: 하이브리드 클라우드 솔루션</block>
  <block id="3f5dc233ecdfc868e2a067d1eb7d8811" category="paragraph"><block ref="3f5dc233ecdfc868e2a067d1eb7d8811" category="inline-link-macro-rx"></block></block>
  <block id="bd8f37587e7778e9d19d350dd4bd6d3a" category="summary">이 섹션에서는 이 솔루션의 내용에 관심이 있는 사용자를 설명합니다.</block>
  <block id="c1416f7786ac2faa1173c4336b6eb03e" category="paragraph"><block ref="c1416f7786ac2faa1173c4336b6eb03e" category="inline-link-macro-rx"></block></block>
  <block id="49997701037fef2c24b57a2e7186d0ab" category="paragraph">분석 및 데이터 과학의 세계는 IT와 비즈니스의 여러 분야를 아우릅니다.</block>
  <block id="529ac4605b034914d0e8b489a81e45e0" category="list-text">DevOps 엔지니어는 새로운 AI 및 ML 애플리케이션을 CI 및 CD 파이프라인에 통합하는 툴을 필요로 합니다.</block>
  <block id="090e55ccd8633a454f9d471ca3ed004d" category="list-text">클라우드 관리자와 설계자는 하이브리드 클라우드 리소스를 설정하고 관리할 수 있어야 합니다.</block>
  <block id="3cb782c6019ddcbb4e7f6bf8ae154d40" category="list-text">비즈니스 사용자는 분석, AI, ML 및 DL 애플리케이션에 액세스해야 합니다.</block>
  <block id="3dfd24951a51ec1661b0294f59bea86e" category="paragraph">이 기술 보고서에서는 NetApp AFF, E-Series, StorageGRID, NFS 직접 액세스, Apache Spark가 어떤 식으로 Horovod와 Keras는 이러한 각 역할이 비즈니스에 가치를 제공하는 데 도움을 줍니다.</block>
  <block id="1f3c9b64432ff113f81d3897c98ed74b" category="inline-link-macro">다음은 솔루션 기술입니다.</block>
  <block id="fdd31e37014fd5b0f491f1d30b29c4c3" category="paragraph"><block ref="fdd31e37014fd5b0f491f1d30b29c4c3" category="inline-link-macro-rx"></block></block>
  <block id="727c63651b565bca2eb7d8a48e0fefd9" category="summary">이 섹션에서는 Apache Spark용 NetApp 스토리지 솔루션에 관해 이 문서를 요약합니다.</block>
  <block id="265d8449fb55764666dffa0a87f0c3fc" category="inline-link-macro">이전: 주요 활용 사례별로 Python 스크립트</block>
  <block id="7fc4ed21f18b26424c49779d455d4f51" category="paragraph"><block ref="7fc4ed21f18b26424c49779d455d4f51" category="inline-link-macro-rx"></block></block>
  <block id="900200cfc3f2577215c327d16f34840a" category="paragraph">이 문서에서는 Apache Spark 아키텍처, 고객 사용 사례 및 빅데이터, 최신 분석, AI, ML 및 DL과 관련된 NetApp 스토리지 포트폴리오에 대해 설명합니다. 업계 표준 벤치마킹 툴 및 고객 요구사항을 기반으로 한 성능 검증 테스트에서 NetApp Spark 솔루션은 네이티브 Hadoop 시스템에 비해 뛰어난 성능을 입증했습니다. 이 보고서에 제공된 고객 사용 사례 및 성능 결과를 조합하여 배포할 적절한 Spark 솔루션을 선택할 수 있습니다.</block>
  <block id="7772bd81086ccf1a440798ec74c6c795" category="paragraph"><block ref="7772bd81086ccf1a440798ec74c6c795" category="inline-link-macro-rx"></block></block>
  <block id="dce4db89f623baec1071c07c6784f4b1" category="summary">최신 엔터프라이즈 데이터 센터는 지속적인 데이터 관리 계층을 통해 여러 분산 인프라 환경을 연결하여 온프레미스 및/또는 멀티 퍼블릭 클라우드의 일관된 운영 모델을 유지하는 하이브리드 클라우드입니다. 하이브리드 클라우드를 최대한 활용하려면 데이터 변환 또는 애플리케이션 리팩토링 없이 사내 환경과 멀티 클라우드 환경 간에 데이터를 원활하게 이동할 수 있어야 합니다.</block>
  <block id="e27d277adca53504bfe79d8a5e7c2084" category="doc">하이브리드 클라우드 솔루션</block>
  <block id="bbbb8f5ce180b59d7cf72bfd9ff78bf6" category="inline-link-macro">이전: 테스트 결과.</block>
  <block id="e8be57661ebf09e93d86ee83e74adbc3" category="paragraph"><block ref="e8be57661ebf09e93d86ee83e74adbc3" category="inline-link-macro-rx"></block></block>
  <block id="9cf7905c60934870d86a546076b272e4" category="paragraph">고객은 2차 스토리지를 클라우드로 이동하여 데이터 보호와 같은 사용 사례를 활용하거나 애플리케이션 개발, DevOps 등과 같은 비즈니스 크리티컬 워크로드를 클라우드로 이전함으로써 하이브리드 클라우드 여정을 시작한다고 했습니다. 그런 다음 더 중요한 워크로드로 이동합니다. 웹 및 콘텐츠 호스팅, DevOps 및 애플리케이션 개발, 데이터베이스, 분석, 컨테이너 앱 등이 가장 인기 있는 하이브리드 클라우드 워크로드 중 하나입니다. 엔터프라이즈 AI 프로젝트의 복잡성, 비용, 위험은 기존에 AI 채택의 실험 단계에서 운영 단계로 넘어왔던 것입니다.</block>
  <block id="38ddba87301d0e027f020fd24b8a5ade" category="paragraph">NetApp 하이브리드 클라우드 솔루션을 사용하는 고객은 통합 보안, 데이터 거버넌스, 규정 준수 툴을 활용하여 분산 환경에서 데이터 및 워크플로우를 단일 제어판에서 관리할 수 있으며, 사용에 따른 총 소유 비용을 최적화할 수 있습니다. 다음 그림은 고객의 빅데이터 분석 데이터를 위한 멀티 클라우드 연결을 제공하는 클라우드 서비스 파트너의 예입니다.</block>
  <block id="10ebc90118ac5ab60f289bf34b75d978" category="inline-image-macro">클라우드 서비스 파트너의 예시 솔루션</block>
  <block id="ad71e01672e98de491e72d22ba403059" category="paragraph"><block ref="ad71e01672e98de491e72d22ba403059" category="inline-image-macro-rx" type="image"></block></block>
  <block id="207f35bf95973770d860aeee0abe32a2" category="paragraph">이 시나리오에서는 여러 소스에서 AWS로 수신된 IoT 데이터가 NPS(NetApp 프라이빗 스토리지)의 중앙 위치에 저장됩니다. NPS 스토리지는 AWS와 Azure에 위치한 Spark 또는 Hadoop 클러스터에 연결되어 여러 클라우드에서 실행되는 빅데이터 분석 애플리케이션이 동일한 데이터에 액세스할 수 있도록 지원합니다. 이 활용 사례의 주요 요구사항과 과제는 다음과 같습니다.</block>
  <block id="bf871745f8e53cd8c13aca4c2ae67522" category="list-text">다양한 센서와 허브를 통해 사내 환경, 클라우드 환경과 같은 다양한 소스로부터 데이터를 받아야 합니다.</block>
  <block id="cb1726ae6d68d40c3bc9861c2b26a1a0" category="list-text">솔루션은 효율적이고 비용 효율적이어야 합니다.</block>
  <block id="6dc7db5e9c1da14f7d61e2a7f4428219" category="list-text">주된 과제는 서로 다른 사내 및 클라우드 환경 간에 하이브리드 분석 서비스를 제공하는 비용 효율적이고 효율적인 솔루션을 구축하는 것입니다.</block>
  <block id="cc4772ffa75dd53e0fb87df4b15528cd" category="paragraph">NetApp의 데이터 보호 및 멀티 클라우드 연결 솔루션은 여러 하이퍼스케일러에 클라우드 분석 애플리케이션이 있다는 문제를 해결합니다. 위 그림과 같이 센서의 데이터가 스트리밍되어 Kafka를 통해 AWS Spark 클러스터로 수집됩니다. 이 데이터는 Equinix 데이터 센터 내의 클라우드 공급자 외부에 있는 NPS에 있는 NFS 공유에 저장됩니다.</block>
  <block id="88971c24837a2734fa58ba8805336328" category="paragraph">NetApp NPS는 각각 Direct Connect와 Express Route 연결을 통해 Amazon AWS 및 Microsoft Azure에 연결되므로, 고객은 데이터 이동 없는 분석 모듈을 활용하여 Amazon 및 AWS 분석 클러스터 모두에서 데이터에 액세스할 수 있습니다. 따라서 사내 스토리지와 NPS 스토리지 모두 ONTAP 소프트웨어를 실행하기 때문에<block ref="fcca72a796080b3a5e2b7b1394bd00ad" category="inline-link-rx"></block> NPS 데이터를 사내 클러스터에 미러링하여 사내 및 여러 클라우드 전반에 하이브리드 클라우드 분석 기능을 제공할 수 있습니다.</block>
  <block id="6e53d162faf0b7bc51e81ca980f05f86" category="paragraph">최적의 성능을 위해 일반적으로 여러 네트워크 인터페이스 및 직접 연결 또는 빠른 경로를 사용하여 클라우드 인스턴스의 데이터에 액세스하는 것이 좋습니다. NetApp은 다음을 비롯한 다른 Data Mover 솔루션을 보유하고 있습니다<block ref="0adb843c17d646acd72646e9688dde2b" category="inline-link-rx"></block> 및<block ref="4c1cade27212922d2ee7525beab5b4a9" category="inline-link-rx"></block> 고객이 애플리케이션 인식, 보안 및 비용 효율적인 하이브리드 클라우드 스파크 클러스터를 구축할 수 있도록 지원합니다.</block>
  <block id="1e73bec6e2f584224cb16d4550039696" category="inline-link-macro">다음: 주요 활용 사례별로 Python 스크립트</block>
  <block id="cf6b62d678290b47b2c7abc2f11eb6d5" category="paragraph"><block ref="cf6b62d678290b47b2c7abc2f11eb6d5" category="inline-link-macro-rx"></block></block>
  <block id="edeeafbd44ff39ea2ff14f5de4488b69" category="summary">이 페이지에서는 이 솔루션을 사용할 수 있는 다양한 영역에 대해 설명합니다.</block>
  <block id="bf9bdab57c82171f2cc9bcebdc37b2c2" category="doc">사용 사례 요약</block>
  <block id="2a4bf885433f99fb55281d25340cf2b5" category="inline-link-macro">이전: NetApp Spark 솔루션 개요</block>
  <block id="105ad1f4294f02452bad1ed7ad67aa5d" category="paragraph"><block ref="105ad1f4294f02452bad1ed7ad67aa5d" category="inline-link-macro-rx"></block></block>
  <block id="badfbf9255d6b555592b41ab34e4efc6" category="section-title">스트리밍 데이터</block>
  <block id="4cc7dbb8e0e56a0e190e0ad588a8ba78" category="paragraph">Apache Spark는 스트리밍 추출, 변환 및 로드(ETL) 프로세스, 데이터 보강, 이벤트 감지 트리거 및 복잡한 세션 분석에 사용되는 스트리밍 데이터를 처리할 수 있습니다.</block>
  <block id="35658693f34a1c5dc8b752f79caeb198" category="list-text">* Streaming ETL. * 데이터가 데이터 저장소로 푸시되기 전에 지속적으로 정리 및 집계됩니다. Netflix는 Kafka 및 Spark 스트리밍을 사용하여 다양한 데이터 소스에서 매일 수십억 개의 이벤트를 처리할 수 있는 실시간 온라인 영화 추천 및 데이터 모니터링 솔루션을 구축합니다. 그러나 일괄 처리를 위한 기존 ETL은 다르게 처리됩니다. 이 데이터를 먼저 읽은 다음 데이터베이스에 쓰기 전에 데이터베이스 형식으로 변환됩니다.</block>
  <block id="1e8d9d663f583499f32f92ca2486e7df" category="list-text">* 데이터 보강. * Spark 스트리밍은 라이브 데이터를 정적 데이터로 보강하여 보다 실시간 데이터 분석을 가능하게 합니다. 예를 들어, 온라인 광고주는 고객 행동에 대한 정보를 바탕으로 맞춤화된 맞춤형 광고를 제공할 수 있습니다.</block>
  <block id="e3c0d503686e9ab8960903bc80d3f700" category="list-text">* 이벤트 감지 트리거 * 스파크 스트리밍을 사용하면 잠재적으로 심각한 문제를 나타낼 수 있는 비정상적인 동작을 신속하게 감지하고 대응할 수 있습니다. 예를 들어, 금융 기관은 사기 거래를 탐지 및 중지하는 트리거를 사용하며 병원에서는 환자의 바이탈 사인에 감지된 위험한 건강 변화를 감지하기 위해 트리거를 사용합니다.</block>
  <block id="af8f12b6a4cff696802c46442e36e264" category="list-text">* 복잡한 세션 분석. * Spark 스트리밍은 웹 사이트나 응용 프로그램에 로그인한 후 사용자 활동과 같은 이벤트를 수집하여 그룹화하고 분석합니다. 예를 들어 Netflix는 이 기능을 사용하여 실시간 영화 권장 사항을 제공합니다.</block>
  <block id="61fb23ef88a4d1404b2410cf94238fb5" category="paragraph">스트리밍 데이터 구성, Confluent Kafka 검증 및 성능 테스트에 대한 자세한 내용은 을 참조하십시오<block ref="10063fdbf72f58440f18bb49eb2309fe" category="inline-link-rx"></block>.</block>
  <block id="2a80513f40f0c2a9c11009fa83049bd9" category="section-title">머신 러닝</block>
  <block id="c2e9a1abebd45c1d446eb49fb690afd7" category="paragraph">Spark 통합 프레임워크는 MLlib(Machine Learning Library)를 사용하여 데이터 세트에서 반복되는 쿼리를 실행할 수 있도록 도와줍니다. MLlib는 예측 인텔리전스, 마케팅 목적으로 고객 세분화, 감정 분석과 같은 일반적인 빅 데이터 기능의 클러스터링, 분류 및 차원 감소 등의 영역에서 사용됩니다. MLlib는 네트워크 보안에 사용되어 데이터 패킷의 실시간 검사를 수행하여 악의적인 활동의 징후를 파악합니다. 이 솔루션은 보안 제공업체가 새로운 위협에 대해 학습하고 해커보다 앞서나가는 동시에 클라이언트를 실시간으로 보호할 수 있도록 도와줍니다.</block>
  <block id="03d3e10f072ae25d491b55767b4fc37e" category="section-title">딥 러닝</block>
  <block id="b45690b6bb62bd55da7e1911ed880ec6" category="paragraph">TensorFlow는 업계 전반에 걸쳐 사용되는 인기 있는 딥 러닝 프레임워크입니다. TensorFlow는 CPU 또는 GPU 클러스터에 대한 분산 교육을 지원합니다. 이렇게 분산된 교육을 통해 사용자는 많은 양의 데이터에서도 딥 레이어가 많이 포함된 상태로 데이터를 실행할 수 있습니다.</block>
  <block id="9981faa66d13ca7ba415a6c70dc52893" category="paragraph">얼마 전까지만 해도 TensorFlow에 Apache Spark를 사용하려면 PySpark에서 TensorFlow에 필요한 ETL을 수행한 다음 중간 스토리지에 데이터를 써야 했습니다. 그런 다음 실제 훈련 프로세스를 위해 TensorFlow 클러스터에 데이터를 로드합니다. 이 워크플로우에서는 사용자가 ETL용 클러스터와 TensorFlow의 분산 교육용으로 각각 하나씩, 두 개의 서로 다른 클러스터를 유지해야 했습니다. 여러 클러스터를 실행하고 유지하는 일은 일반적으로 지루하고 시간이 오래 걸립니다.</block>
  <block id="082ad29f115c5cd4ab167c596b90688c" category="paragraph">이전 Spark 버전의 DataFrames 및 RDD는 랜덤 액세스가 제한되었기 때문에 딥 러닝에 적합하지 않았습니다. 프로젝트 수소가 포함된 Spark 3.0에서는 딥 러닝 프레임워크에 대한 기본 지원이 추가됩니다. 이 접근 방식을 사용하면 Spark 클러스터에서 MapReduce를 기반으로 하지 않는 일정을 수행할 수 있습니다.</block>
  <block id="44cd5d1ec9ffc51f82d838faf685ef6e" category="section-title">대화형 분석</block>
  <block id="11bb4412e7e82514a739cb60053e30df" category="paragraph">Apache Spark는 SQL, R, Python 등 Spark 이외의 개발 언어를 사용하여 샘플링하지 않고 탐색 쿼리를 수행할 수 있을 만큼 빠릅니다. Spark는 시각화 도구를 사용하여 복잡한 데이터를 처리하고 대화형으로 시각화합니다. Spark with 구조화된 스트리밍은 웹 분석의 라이브 데이터에 대한 대화형 쿼리를 수행하여 웹 방문자의 현재 세션에 대해 대화형 쿼리를 실행할 수 있도록 합니다.</block>
  <block id="d89f01bf7c0ceacaf30849bab08e0939" category="section-title">추천 시스템</block>
  <block id="38c79706797b854a06f30876828ee766" category="paragraph">기업과 소비자가 온라인 쇼핑, 온라인 엔터테인먼트 및 기타 다양한 산업의 급격한 변화에 대응함에 따라, 지난 몇 년 동안 추천 시스템은 우리의 삶에 엄청난 변화를 가져왔습니다. 실제로 이러한 시스템은 생산 과정에서 AI의 가장 확실한 성공 사례 중 하나입니다. 많은 실제 사용 사례에서 추천 시스템은 NLP 백엔드와 상호 작용 AI 또는 챗봇과 결합되어 관련 정보를 얻고 유용한 추론을 생성합니다.</block>
  <block id="6346d11f3fda24eb2d12fa4ac478fe3b" category="paragraph">오늘날, 많은 소매업체들은 온라인 구매 및 매장에서 픽업, 큐브사이드 픽업, 셀프 체크아웃, 스캔 및 이동 등 새로운 비즈니스 모델을 채택하고 있습니다. COVID-19가 범세계적으로 확산되고 있는 가운데, 이러한 모델은 더욱 안전하고 편리한 쇼핑을 통해 뚜렷하게 부각되고 있습니다. AI는 소비자 행동의 영향을 받는 디지털 트렌드에 있어 매우 중요합니다. 고객의 증가하는 요구사항을 충족하고, 고객 경험을 보강하고, 운영 효율성을 개선하고, 수익을 증대하기 위해 NetApp은 엔터프라이즈 고객과 기업이 머신 러닝 및 딥 러닝 알고리즘을 사용하여 더 빠르고 정확한 추천 시스템을 설계할 수 있도록 지원합니다.</block>
  <block id="b32f1d719ba1fea2cad3538a4795c552" category="paragraph">협업 필터링, 콘텐츠 기반 시스템, 딥 러닝 추천 모델(DLRM), 하이브리드 기술 등 권장 사항을 제공하는 데 사용되는 몇 가지 기술이 있습니다. 고객은 이전에 PySpark를 사용하여 권장 시스템 생성을 위한 협업 필터링을 구현했습니다. Spark MLlib는 DLRM이 등장하기 전에 엔터프라이즈 사이에서 매우 널리 사용되는 알고리즘인 협업 필터링을 위해 교류 최소 사각형(ALS)을 구현합니다.</block>
  <block id="9389b39b238fbd5ad61de2fea371853d" category="section-title">자연어 처리</block>
  <block id="18bfab6309a4addeb7e1dae07d2a4b89" category="inline-link">Gartner</block>
  <block id="47fa981bf7641c90f0ce83a88c21234e" category="paragraph">자연어 처리(NLP)로 가능해진 대화형 AI는 컴퓨터가 인간과 통신할 수 있도록 지원하는 AI의 지점입니다. NLP는 스마트 비서 및 챗봇에서 Google 검색 및 예측 텍스트에 이르기까지 모든 업계 수직 및 다양한 사용 사례에서 널리 사용되고 있습니다. 에 따르면<block ref="be3a50ddc5683c6936ee69409b86e212" category="inline-link-rx"></block> 2022년까지 70%의 사용자가 매일 대화형 AI 플랫폼과 상호 작용할 것으로 예측 인간과 기계 사이의 고품질 대화를 위해서는 신속하고 지능적이며 자연스러운 대화가 이루어져야 합니다.</block>
  <block id="9cac4209da8ee0481a45fa299b66e587" category="paragraph">고객은 NLP 및 ASR(자동 음성 인식) 모델을 처리하고 교육하기 위해 대량의 데이터가 필요합니다. 또한 에지, 코어, 클라우드 전반에서 데이터를 이동해야 하며, 인류와 자연적 통신을 위해 수 밀리초 내에 추론을 수행할 수 있는 기능이 필요합니다. NetApp AI 및 Apache Spark는 컴퓨팅, 스토리지, 데이터 처리, 모델 교육, 미세 조정, 있습니다.</block>
  <block id="33984e410ab674dcea1f21af4c5db4ec" category="paragraph">정서 분석은 NLP에서 텍스트에서 긍정적, 부정적 또는 중립적 감정을 추출하는 연구 분야입니다. 고객 의견 분석에는 지원 센터 직원의 성과 파악부터 적절한 자동 챗봇 응답 제공에 이르기까지 다양한 활용 사례가 있습니다. 또한 분기별 수익 통화 시 기업 담당자와 대상 간의 상호 작용을 기반으로 회사의 주가를 예측하기도 했습니다. 또한, 감정 분석을 사용하여 브랜드가 제공하는 제품, 서비스 또는 지원에 대한 고객의 관점을 결정할 수 있습니다.</block>
  <block id="511405f2428e9a6a71530b7f2cdcbc21" category="inline-link">John Snow Labs를 참조하십시오</block>
  <block id="351594930581e8fa82cf694de7562fd2" category="inline-link">금융 뉴스 정서</block>
  <block id="322f98ff217f4c12ea8f1b3ea41f4024" category="paragraph">을 사용했습니다<block ref="0f17ea1334fb20ed83c3ab03268616d7" category="inline-link-rx"></block> 라이브러리 시작<block ref="22825786ea861b373c2a5fdda9f62d81" category="inline-link-rx"></block> 를 포함하여 Transformers(BERT) 모델의 사전 교육 파이프라인 및 양방향 인코더 표현을 로드합니다<block ref="25bfdf207733b5ead40d4d36ea328e85" category="inline-link-rx"></block> 및<block ref="9c44f0ce83f7021f3ece2b04fda553fb" category="inline-link-rx"></block>즉, 토큰화, 명명된 엔터티 인식, 모델 교육, 피팅 및 정서 분석을 대규모로 수행합니다. Spark NLP는 BERT, Albert, Electra, XLNet, DistillBERT 등의 최첨단 변압기(transformer)를 제공하는 유일한 오픈 소스 NLP 라이브러리입니다. Roberta, DeBERTa, XLM-Roberta, Longrofer, Elmo, Universal 문장 인코더, Google T5, MarianMT 및 GPT2. 이 라이브러리는 Python 및 R 뿐만 아니라 Apache Spark를 기본적으로 확장하여 JVM 에코시스템(Java, Scala, Kotlin)에서도 사용할 수 있습니다.</block>
  <block id="e4f0ac4ff07b9b5031299d0b3702fedb" category="inline-link-macro">다음: 주요 AI, ML 및 DL 사용 사례 및 아키텍처</block>
  <block id="84fcdcaf39dee89e28f1b44c28ad46ef" category="paragraph"><block ref="84fcdcaf39dee89e28f1b44c28ad46ef" category="inline-link-macro-rx"></block></block>
  <block id="7e838102a13e780977b21c90f648a5d0" category="summary">이 섹션에서는 Apache Spark의 특성 및 구성 요소와 이러한 구성 요소가 이 솔루션에 어떻게 기여하는지 설명합니다.</block>
  <block id="b47e85e30f997f214c7850de9dd795da" category="inline-link-macro">이전: 대상 청중.</block>
  <block id="9e972d78946023378ffbea0f999c2d03" category="paragraph"><block ref="9e972d78946023378ffbea0f999c2d03" category="inline-link-macro-rx"></block></block>
  <block id="f4387c90411f7b92618497bc53b16256" category="paragraph">Apache Spark는 HDFS(Hadoop Distributed File System)와 직접 연동되는 Hadoop 애플리케이션을 작성하기 위한 인기 있는 프로그래밍 프레임워크입니다. Spark는 프로덕션을 지원하며 스트리밍 데이터의 처리를 지원하며 MapReduce보다 빠릅니다. Spark는 효율적인 반복을 위해 메모리 내 데이터 캐싱을 구성할 수 있으며 Spark 셸은 데이터를 학습하고 탐색하는 대화형 기능을 제공합니다. Spark를 사용하면 Python, Scala 또는 Java로 애플리케이션을 만들 수 있습니다. SPARK 응용 프로그램은 하나 이상의 작업이 있는 하나 이상의 작업으로 구성됩니다.</block>
  <block id="6a696023a577a0d26763ef9c382b4b1f" category="paragraph">모든 Spark 응용 프로그램에는 Spark 드라이버가 있습니다. YARN-Client 모드에서 드라이버는 클라이언트에서 로컬로 실행됩니다. YARN-Cluster 모드에서는 드라이버가 애플리케이션 마스터의 클러스터에서 실행됩니다. 클러스터 모드에서는 클라이언트의 연결이 끊기더라도 애플리케이션이 계속 실행됩니다.</block>
  <block id="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="paragraph"><block ref="fed4e6478ab0d82b2e98b4f5bd62f0e2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6feb0bd2b4db4693572a9fc2e517e888" category="paragraph">세 가지 클러스터 관리자가 있습니다.</block>
  <block id="4c79d7007667a60b712836e2f93d6bfc" category="list-text">* 독립 실행형. * 이 매니저는 Spark의 일부이며, 클러스터를 쉽게 설정할 수 있습니다.</block>
  <block id="c0a5bce529ff277ee2735538a7b43913" category="list-text">* Apache Mesos. * MapReduce 및 기타 애플리케이션도 실행하는 일반 클러스터 관리자입니다.</block>
  <block id="24683e4dfc33dc5b20a0d9a75c0ff150" category="list-text">* Hadoop YARN. * Hadoop 3의 리소스 관리자입니다.</block>
  <block id="569531fd384ec251943946598eb00dcb" category="paragraph">탄력적인 분산 데이터 세트(RDD)는 Spark의 주요 구성 요소입니다. RDD는 클러스터의 메모리에 저장된 데이터에서 손실되거나 누락된 데이터를 재생성하고 파일에서 나오거나 프로그래밍 방식으로 생성된 초기 데이터를 저장합니다. RDD는 파일, 메모리에 있는 데이터 또는 다른 RDD에서 생성됩니다. SPARK 프로그래밍은 변환과 동작이라는 두 가지 작업을 수행합니다. 변환은 기존 RDD를 기반으로 새 RDD를 생성합니다. 작업은 RDD에서 값을 반환합니다.</block>
  <block id="06b482c7bd2522ec4a62ccc70b71c37e" category="paragraph">변환 및 작업은 Spark 데이터 집합 및 DataFrames에도 적용됩니다. 데이터 세트는 분산 데이터 모음으로서 Spark SQL의 최적화된 실행 엔진의 이점과 함께 RDD(강력한 타이핑, 람다 함수 사용)의 이점을 제공합니다. 데이터세트는 JVM 객체에서 생성한 다음 기능 변환(맵, 평면 맵, 필터 등)을 사용하여 조작할 수 있습니다. DataFrame 은 명명된 열로 구성된 데이터 집합입니다. 개념적으로 관계형 데이터베이스의 테이블 또는 R/Python의 데이터 프레임에 해당합니다. DataFrames는 정형 데이터 파일, Hive/HBase의 테이블, 사내 또는 클라우드의 외부 데이터베이스 또는 기존 RDD와 같은 다양한 소스에서 구성할 수 있습니다.</block>
  <block id="89d836212e4c5086ebcd9e5fbd6a4b37" category="paragraph">스파크 응용 프로그램에는 하나 이상의 스파크 작업이 포함됩니다. 작업은 실행기에서 작업을 실행하고 실행자는 YARN 컨테이너에서 실행됩니다. 각 실행자는 단일 컨테이너에서 실행되며 실행자는 응용 프로그램 수명 내내 존재합니다. 응용 프로그램이 시작된 후 실행자가 수정되고 YARN은 이미 할당된 컨테이너의 크기를 조정하지 않습니다. 집행자는 인메모리 데이터에 대해 작업을 동시에 실행할 수 있습니다.</block>
  <block id="93b777568c6fc956b8dcbf6cb778cf8e" category="inline-link-macro">다음은 NetApp Spark 솔루션 개요입니다.</block>
  <block id="2e9d493fc7f04097c722ddfd7bf4cba7" category="paragraph"><block ref="2e9d493fc7f04097c722ddfd7bf4cba7" category="inline-link-macro-rx"></block></block>
  <block id="43fc68a998702bc80e46c46de6c28621" category="doc">주요 활용 사례별로 Python 스크립트</block>
  <block id="6af3c467ec5223400f1d1e91f69cb12b" category="inline-link-macro">이전: 하이브리드 클라우드 솔루션</block>
  <block id="45d040833437bf9dd9f64d4dfa4981c4" category="paragraph"><block ref="45d040833437bf9dd9f64d4dfa4981c4" category="inline-link-macro-rx"></block></block>
  <block id="cfb5f1c014066f18d7979fa1d35a934d" category="paragraph">다음 세 가지 Python 스크립트는 테스트를 거친 세 가지 주요 사용 사례에 해당합니다. 첫 번째는 'sentiment_analysis_sparklp.py'입니다.</block>
  <block id="d3abf6f12cafa2cc1b795b31cd547c75" category="paragraph">두 번째 스크립트는 keras_spark_horovod_rossmann_estimator.py입니다.</block>
  <block id="6e9120b39f924b2eed528e3bcdd009ac" category="paragraph">세 번째 스크립트는 run_classification_criteo_spark.py입니다.</block>
  <block id="be0ba1bf6a99c201834567c4d58fc40e" category="paragraph"><block ref="be0ba1bf6a99c201834567c4d58fc40e" category="inline-link-macro-rx"></block></block>
  <block id="2ce0710320aace7b17c3af20eaac2918" category="sidebar">사용 사례 요약</block>
  <block id="7a28dc06a92c8c13aba4217cc065d556" category="list-text">사용 사례 2&gt;...</block>
  <block id="e71faea04999fd95e327c2ae1b14b591" category="list-text">참고 2...</block>
  <block id="39a42e9bc59c02bbbf3ed4eb16b1cca4" category="paragraph">이 솔루션의 배포를 완료할 수 있습니다.</block>
  <block id="7300ce5706dee36f69c820d38d478b65" category="list-text">스크린샷과 함께 제공되는 자세한 지침을 수동으로 따릅니다.</block>
  <block id="8412750c53dfad13bb8a2baccb69df63" category="list-text">실행할 단계를 보여 주는 비디오와 함께 수동으로 또는 를 수행합니다</block>
  <block id="ec325ca23fb4f2a557b0efcf8667bf31" category="list-text">자동화 섹션에 제공된 지침을 자동으로 따릅니다.</block>
  <block id="d22702677ec3ab6384e6dae329022796" category="open-title">자세한 지침</block>
  <block id="233777e8b1ab8b0114d7518acdbd2377" category="list-text">과제 2...</block>
  <block id="2f43b42fd833d1e77420a8dae7419000" category="paragraph">...</block>
  <block id="a0c7049fba5354f8f1711e379e6f4201" category="open-title">비디오 연습</block>
  <block id="c6388aefff17f19b12b255766fe6b6fe" category="paragraph">여기에 비디오 세부 정보 포함&gt;</block>
  <block id="f674169036173cc4a9f01e223c275c8d" category="open-title">자동화된 배포</block>
  <block id="b9e9e9354502c35dc60d3744fb1506e6" category="paragraph">여기에 자동화된 단계/프로세스/비디오 포함&gt;</block>
  <block id="bbc8a731eb9387bfdc71e5f35721af4c" category="example-title">lt; 옵션 1 및 GT 설명;</block>
  <block id="e83c35e6afea2838c146155292120e3a" category="paragraph">여기에 옵션의 세부 정보를 입력하십시오&gt;</block>
  <block id="a8ec4bf9dc004e6dc4ec8c7c8cb307a3" category="example-title">lt; 옵션 2 및 GT 설명;</block>
  <block id="13e60333560bb11c5611ca7faa0dff3b" category="example-title">lt; 옵션 설명 n&amp;gt;</block>
  <block id="329ecbed66c88e6c0c049d051ad6aa9a" category="paragraph">David Arnette 및 Sung-Han Lin, NetApp</block>
  <block id="d940dfad6ae514d8235749f5f5bf92ed" category="paragraph">NVA-1151-design은 NetApp AFF A800 스토리지 시스템, NVIDIA DGX A100 시스템 및 NVIDIA Mellanox 네트워크 스위치를 사용하는 머신 러닝 및 인공 지능 워크로드를 위한 NetApp 검증 아키텍처를 설명합니다. 또한 구현된 아키텍처의 벤치마크 테스트 결과도 포함되어 있습니다.</block>
  <block id="16550c71fdf2102ec8face86a5d82746" category="cell">2022년 9월 30일</block>
  <block id="8485ff07404cda7656a72c1d11b2e278" category="cell">VMware HCX를 사용하여 워크로드를 FSxN 데이터 저장소로 마이그레이션하기 위한 솔루션을 추가했습니다</block>
  <block id="bee0d36d9b0ec64a15bf59019a6ec2e2" category="cell">2022년 9월 29일</block>
  <block id="b6942044de91f49e700f684f12314907" category="cell">VMware HCX를 사용하여 ANF 데이터 저장소로 워크로드를 마이그레이션하기 위한 솔루션이 추가되었습니다</block>
  <block id="fa3811ba5828de9b5ce35701ec38d154" category="list-text">VMC의 가용성을 확인합니다 <block ref="bd516ef46cad23535fac2e4d7f54defe" category="inline-link-macro-rx"></block>.</block>
  <block id="0ecaf171a89c41ea509c3f45896220b8" category="list-text">아마존의 가격 책정 가이드에서는 FSxN(FSx ONTAP)을 사용할 수 있는 위치에 대한 정보를 제공합니다. 해당 정보를 찾을 수 있습니다 <block ref="2d4b4b449ef448fbb3000f58e542f4ee" category="inline-link-macro-rx"></block>.</block>
  <block id="4573434025dab87886cfb0b766c70cb1" category="paragraph">마지막 업데이트: 2022년 9월 28일.</block>
  <block id="d8cefe0428d28368238dbbeabef9c83f" category="open-title">하이브리드 멀티 클라우드(HMC)</block>
  <block id="493f775d3c83d2c658056477b1d58f74" category="paragraph">[underline]# * AWS/VMC * #에 대한 동영상</block>
  <block id="638eb9310db06d086fac0c3c069669af" category="video-title">NetApp ONTAP용 Amazon FSx를 사용하는 AWS 보조 데이터 저장소의 VMware Cloud</block>
  <block id="6f605e77e59dfe45ae918965ba0bd336" category="video-title">NetApp ONTAP용 Amazon FSx를 통해 AWS에서 VMware Cloud를 TCO로 절감할 수 있습니다</block>
  <block id="d7d56735bb43053ca43b2d9698b2623c" category="video-title">VMC를 위한 VMware HCX 구축 및 구성 설정</block>
  <block id="c6434a9743fb403cd78cd2d3a42d9683" category="video-title">VMC 및 FSxN에 대한 VMware HCX와 vMotion 데모</block>
  <block id="e906083dc0b31806eab68df2c340504f" category="video-title">VMC 및 FSxN용 VMware HCX와 함께 콜드 마이그레이션 데모</block>
  <block id="62184265581f788d642b26b13c273b93" category="paragraph">[underline]# * Azure/AVS * 용 동영상 #</block>
  <block id="62766d3266d403114a010bc02e7b4004" category="video-title">Azure VMware 솔루션 Azure NetApp Files의 데이터 저장소 보충 개요</block>
  <block id="4864ff1c07b9b500fd46c4a1c5918fd8" category="video-title">Cloud Volumes ONTAP, SnapCenter 및 Jetstream을 사용한 Azure VMware 솔루션 DR</block>
  <block id="8eb2fa7c0d2a676485a155077b770fdd" category="video-title">VMware HCX for AVS 및 ANF와 함께 콜드 마이그레이션 데모</block>
  <block id="664115ac899ebaf481e2b75540d5c56c" category="video-title">VMware HCX와 함께 AVS 및 ANF용 vMotion 데모</block>
  <block id="914c1d4cdf840b7b030978f1b07915d8" category="video-title">VMware HCX for AVS 및 ANF와 함께 대량 마이그레이션 데모</block>
  <block id="1709b8b454125c7d55fd44e302c8aee3" category="example-title">FSxN, VMware HCX와 함께 AWS 기반의 VMware Cloud 마이그레이션</block>
  <block id="9de15a07d3a8b75e451c50d7fa64fae9" category="example-title">ANF(Azure NetApp Files)가 있는 Azure 기반 Azure VMware 서비스</block>
  <block id="875970986c8d6a0d19f47ed744bf33e1" category="example-title">Azure VMware Solution Migrate with ANF, VMware HCX</block>
  <block id="04a1b40e30ee3bddef53c85ca68c8b36" category="inline-link-macro">VMware HCX를 사용하여 워크로드를 Azure NetApp Files 데이터 저장소로 마이그레이션합니다</block>
  <block id="edf47ba9dc6467e3104102f10bafe323" category="list-text"><block ref="edf47ba9dc6467e3104102f10bafe323" category="inline-link-macro-rx"></block></block>
  <block id="668f202e4850de68f941501493126dea" category="doc">TR-4940: VMware HCX-Quickstart 가이드를 사용하여 워크로드를 Azure NetApp Files 데이터 저장소로 마이그레이션합니다</block>
  <block id="ddfd90f2a10c16cbd6548844b07532c2" category="paragraph">저자: NetApp 솔루션 엔지니어링</block>
  <block id="e5baae71bfede792aee5ab0c09fbcd23" category="section-title">개요: VMware HCX, Azure NetApp Files 데이터 저장소 및 Azure VMware 솔루션을 사용하여 가상 시스템 마이그레이션</block>
  <block id="45c532c5535fe16cf9a5868bbd9a3fcd" category="paragraph">Azure VMware 솔루션 및 Azure NetApp Files 데이터 저장소의 가장 일반적인 사용 사례 중 하나는 VMware 워크로드 마이그레이션입니다. VMware HCX가 선호되는 옵션이며, 온프레미스 VM(가상 머신)과 데이터를 Azure NetApp Files 데이터 저장소로 이동하는 다양한 마이그레이션 메커니즘을 제공합니다.</block>
  <block id="a2ee24315378af7416f8fef29e0f0efa" category="paragraph">VMware HCX는 주로 클라우드 전반에서 애플리케이션 마이그레이션, 워크로드 재조정 및 비즈니스 연속성을 간소화하도록 설계된 마이그레이션 플랫폼입니다. Azure VMware Solution 프라이빗 클라우드의 일부로 포함되어 있으며 다양한 방법으로 워크로드를 마이그레이션하여 DR(재해 복구) 작업에 사용할 수 있습니다.</block>
  <block id="227830ba037f63bb97cffeeb98e3a13e" category="paragraph">이 문서에서는 Azure NetApp Files 데이터 저장소를 프로비저닝한 후 VMware HCX를 다운로드, 구축 및 구성하기 위한 단계별 지침을 제공하며, 여기에는 다양한 VM 마이그레이션 메커니즘을 지원하는 상호 연결, 네트워크 확장, WAN 최적화를 비롯한 온프레미스 및 Azure VMware 솔루션 측의 모든 주요 구성 요소가 포함됩니다.</block>
  <block id="a7441e9f968c9ea792320876fd73622a" category="admonition">VMware HCX는 마이그레이션이 VM 레벨에 있으므로 모든 데이터 저장소 유형과 함께 작동합니다. 따라서 이 문서는 비용 효율적인 VMware 클라우드 구축을 위해 Azure VMware 솔루션을 포함한 Azure NetApp Files를 구축하려는 기존 NetApp 고객 및 타사 고객에게 적용됩니다.</block>
  <block id="0ba40ecb813b20bd8c3277c4afcbd451" category="example-title">높은 수준의 단계</block>
  <block id="9a40c0b2781fd2a3a99aa2a6c0c4616e" category="paragraph">이 목록은 Azure 클라우드 측에서 HCX Cloud Manager를 설치 및 구성하고 HCX Connector를 온프레미스에 설치하는 데 필요한 높은 수준의 단계를 제공합니다.</block>
  <block id="d7bfcf4345887ee24f2c3083038c6327" category="list-text">Azure 포털을 통해 HCX를 설치합니다.</block>
  <block id="ea0d203a776b5c56ae3ed2c61269d2a9" category="list-text">사내 VMware vCenter Server에서 HCX Connector OVA(Open Virtualization Appliance) 설치 프로그램을 다운로드하여 구축합니다.</block>
  <block id="2be88e0d3f6d4e20f4bf2bcca7895d7b" category="list-text">라이센스 키를 사용하여 HCX를 활성화합니다.</block>
  <block id="6a0721ebaaff6c0b1564863ac23c2509" category="list-text">온프레미스 VMware HCX Connector를 Azure VMware Solution HCX Cloud Manager와 페어링합니다.</block>
  <block id="612a4c795715d17bfff4e0ba3a8f66d1" category="list-text">네트워크 프로파일, 컴퓨팅 프로파일 및 서비스 메시를 구성합니다.</block>
  <block id="81feabec43f9f1bcb7230fd62f89fb76" category="list-text">(선택 사항) 마이그레이션 중에 재IP를 방지하기 위해 네트워크 확장을 수행합니다.</block>
  <block id="dbed86346a8d7cb3692ba413f7e14f56" category="list-text">어플라이언스 상태를 확인하고 마이그레이션이 가능한지 확인합니다.</block>
  <block id="2f2c97fb0d914a7fc7bcb2c8fad16868" category="list-text">VM 워크로드를 마이그레이션합니다.</block>
  <block id="f2f281974ab353b606093268f9d5335e" category="paragraph">시작하기 전에 다음 필수 구성 요소가 충족되었는지 확인하십시오. 자세한 내용은 다음을 참조하십시오<block ref="88354f8e41d1a2e6cea84b3d932b3286" category="inline-link-rx"></block>. 연결을 포함한 필수 구성 요소가 구축된 후에는 Azure VMware Solution 포털에서 라이센스 키를 생성하여 HCX를 구성하고 활성화합니다. OVA 설치 프로그램을 다운로드한 후 아래 설명된 대로 설치 프로세스를 진행합니다.</block>
  <block id="f52b030029e78590ca66fbf452dfcb14" category="admonition">HCX Advanced가 기본 옵션이며 VMware HCX Enterprise Edition도 지원 티켓을 통해 제공되며 추가 비용 없이 지원됩니다.</block>
  <block id="67863abb3ec8a28f54adf852298b392b" category="inline-link">NetApp 링크</block>
  <block id="d2a5cfbad293008f62b5d4e58457a6d1" category="inline-link">Microsoft 링크</block>
  <block id="1ed491d88e9198d83430469156bf2665" category="list-text">기존 Azure VMware 솔루션 SDDC(소프트웨어 정의 데이터 센터)를 사용하거나 이를 사용하여 프라이빗 클라우드를 생성합니다<block ref="db330bdc7708ed0196dccd83d189a8ae" category="inline-link-rx"></block> 또는 이<block ref="5633c6477a16a80a8050560dab9783c9" category="inline-link-rx"></block>.</block>
  <block id="e265f4db94070f55784ef698e7f4f29b" category="inline-link">사이트 간 VPN 또는 Express 라우트 전역 연결 연결을 설정합니다</block>
  <block id="bb764f1df90a85d77eec079e03bd9764" category="list-text">사내 VMware vSphere 지원 데이터 센터에서 VM 및 관련 데이터를 마이그레이션하려면 데이터 센터에서 SDDC 환경으로 네트워크를 연결해야 합니다. 워크로드를 마이그레이션하기 전에<block ref="31180ecf5c9f25ba891b891b395a9305" category="inline-link-rx"></block> 데이터 관리 및 보호</block>
  <block id="d08fd3825f77e870dd8e93463aea245d" category="list-text">사내 VMware vCenter Server 환경에서 Azure VMware Solution 프라이빗 클라우드로 가는 네트워크 경로는 vMotion을 사용하여 VM 마이그레이션을 지원해야 합니다.</block>
  <block id="f3b5e5598d4c0c196bd2fd79b000637f" category="inline-link">방화벽 규칙 및 포트</block>
  <block id="e1be03b35dc8e9fb114970b06dcd6c18" category="list-text">필수 를 확인하십시오<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> 온-프레미스 vCenter Server와 SDDC vCenter 간에 vMotion 트래픽이 허용됩니다. 프라이빗 클라우드에서 vMotion 네트워크의 라우팅은 기본적으로 구성됩니다.</block>
  <block id="444617dcfe0d17ad386105e865d21113" category="list-text">Azure NetApp Files NFS 볼륨은 Azure VMware 솔루션에서 데이터 저장소로 마운트되어야 합니다. 이에 설명된 단계를 따릅니다<block ref="1b959b45bbb3571141089802677ad765" category="inline-link-rx"></block> Azure NetApp Files 데이터 저장소를 Azure VMware 솔루션 호스트에 연결합니다.</block>
  <block id="2f660e9fff52e5ac1b7818a029d3b447" category="example-title">고급 아키텍처</block>
  <block id="0048e42e38e4c6f587f210afe26fcb4a" category="inline-image-macro">이 이미지는 이 솔루션에 사용된 고급 아키텍처를 보여 줍니다.</block>
  <block id="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="paragraph"><block ref="39fc1d64ec4b3a4ff5306e55bdaf2c0f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d84f7e9d42c2c0ee4f87ddeaa2e09bb2" category="paragraph">이 솔루션의 배포를 완료하려면 다음 단계를 따르십시오.</block>
  <block id="4c8f77e6ab4a9e453faf4063978f94d5" category="example-title">1단계: 추가 기능 옵션을 사용하여 Azure Portal을 통해 HCX를 설치합니다</block>
  <block id="f4ca86f94d0e12644ce102e7c48d6030" category="paragraph">설치를 수행하려면 다음 단계를 수행하십시오.</block>
  <block id="7d4c34e9f83446ef58ad083cd2c29580" category="list-text">Azure Portal에 로그인하여 Azure VMware Solution 프라이빗 클라우드에 액세스합니다.</block>
  <block id="16671eada5939f5c2129db7e8f9522a0" category="list-text">적절한 프라이빗 클라우드를 선택하고 애드온 에 액세스합니다. 이 작업은 * 관리 &gt; 추가 기능 * 으로 이동하여 수행할 수 있습니다.</block>
  <block id="de23e32bd14f5f77d4178bb7d56c2eb0" category="list-text">HCX 워크로드 이동성 섹션에서 * 시작하기 * 를 클릭합니다.</block>
  <block id="239ba3d7293041d0d4dcb4c5b538ea74" category="inline-image-macro">HCX 워크로드 이동성 섹션의 스크린샷.</block>
  <block id="91a36107da2b4f5cbc4963027f871289" category="paragraph"><block ref="91a36107da2b4f5cbc4963027f871289" category="inline-image-macro-rx" type="image"></block></block>
  <block id="de66be71be828600d682c9f0bdb03a18" category="list-text">이용 약관에 동의함 * 옵션을 선택하고 * 사용 및 배포 * 를 클릭합니다.</block>
  <block id="e26184583d86572b90efcca3db66731e" category="admonition">기본 배포는 HCX Advanced입니다. Enterprise 버전을 사용하도록 지원 요청을 엽니다.</block>
  <block id="adafe418547291754cadbfc0d2c5c1dc" category="admonition">배포에는 약 25~30분이 소요됩니다.</block>
  <block id="e39769185df95d6577314b0c683cf848" category="inline-image-macro">HCX 워크로드 이동성 섹션의 완료 스크린샷</block>
  <block id="6df468c8490be1137779d8811f53bddb" category="paragraph"><block ref="6df468c8490be1137779d8811f53bddb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ae33ed8b7695cc113850f5a13bab6e56" category="example-title">2단계: 온-프레미스 vCenter Server에 설치 관리자 OVA를 구축합니다</block>
  <block id="e957ef97a04368fda5e2652e51c19d1d" category="paragraph">온프레미스 커넥터가 Azure VMware 솔루션의 HCX Manager에 연결하려면 적절한 방화벽 포트가 온-프레미스 환경에서 열려 있어야 합니다.</block>
  <block id="0c216cee9411e03f1127e6ffc2bf025d" category="paragraph">온-프레미스 vCenter Server에서 HCX Connector를 다운로드하여 설치하려면 다음 단계를 수행하십시오.</block>
  <block id="c28009ba42c1703c33046d99285a0a10" category="list-text">Azure 포털에서 Azure VMware 솔루션으로 이동하여 프라이빗 클라우드를 선택한 다음 * 관리 &gt; 추가 기능 &gt; HCX를 사용한 마이그레이션 * 을 선택하고 HCX Cloud Manager 포털을 복사하여 OVA 파일을 다운로드합니다.</block>
  <block id="3a858d6f55c84c77db797aafa874a8a5" category="admonition">기본 CloudAdmin 사용자 자격 증명을 사용하여 HCX 포털에 액세스합니다.</block>
  <block id="7efdfa090ad75b0c0f02e115ab8e56bd" category="inline-image-macro">HCX OVA 파일을 다운로드하기 위한 Azure 포털의 스크린샷</block>
  <block id="ab9fbdf98484d630980bec96dac55284" category="paragraph"><block ref="ab9fbdf98484d630980bec96dac55284" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69d5565b77c91d5d6d289858e4d7ea91" category="list-text">jumphost를 사용하여 mailto:cloudadmin@vsphere.loca l[cloudadmin@vsphere.loca l^]으로 HCX 포털에 액세스한 후 * 관리 &gt; 시스템 업데이트 * 로 이동하여 * 다운로드 링크 요청 * 을 클릭합니다.</block>
  <block id="f6b26e036b373b18f11dc0da33ef5268" category="admonition">OVA에 대한 링크를 다운로드하거나 복사하여 브라우저에 붙여 넣으면 온-프레미스 vCenter Server에 구축할 VMware HCX Connector OVA 파일의 다운로드 프로세스가 시작됩니다.</block>
  <block id="894d2481892f65fcae6dfc0ac7b9ec0d" category="inline-image-macro">오류: OVA 다운로드 링크의 스크린샷</block>
  <block id="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="paragraph"><block ref="2a8ced383f2ab7fb9d4a69fc8d344b0e" category="inline-image-macro-rx" type="image"></block></block>
  <block id="12e1c817f24a0aa94d2ae26ea6535479" category="list-text">OVA를 다운로드한 후 * Deploy OVF Template * 옵션을 사용하여 온프레미스 VMware vSphere 환경에 구축합니다.</block>
  <block id="fc1a0933af5c68cc43dbb90b50c1b0d3" category="inline-image-macro">오류: 올바른 OVA 템플릿을 선택하기 위한 스크린샷.</block>
  <block id="d36fa73d8072d1ab34f185f12d5fede5" category="paragraph"><block ref="d36fa73d8072d1ab34f185f12d5fede5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8ba87ef75729cfcffc74d93e0a0852a1" category="list-text">OVA 배포에 필요한 모든 정보를 입력하고 * Next * 를 클릭한 다음 * Finish * 를 클릭하여 VMware HCX 커넥터 OVA를 배포합니다.</block>
  <block id="ed1aadd2fcd5906dd58f9a89179a638e" category="admonition">가상 어플라이언스의 전원을 수동으로 켭니다.</block>
  <block id="dca749083ce6c763573225ed6a46a64e" category="inline-link">VMware HCX 사용자 가이드</block>
  <block id="e10fbd147d2ee50fbbb460ad2f18fa14" category="paragraph">단계별 지침은 를 참조하십시오<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>.</block>
  <block id="6897bb7015f874baf69560eef515010c" category="example-title">3단계: 라이센스 키로 HCX 커넥터를 활성화합니다</block>
  <block id="4aa14207b82768ed77473306cc7a65c2" category="paragraph">VMware HCX 커넥터 OVA를 온-프레미스로 배포하고 어플라이언스를 시작한 후 다음 단계를 수행하여 HCX 커넥터를 활성화하십시오. Azure VMware Solution 포털에서 라이센스 키를 생성하고 VMware HCX Manager에서 활성화합니다.</block>
  <block id="3535419e37127ca2de6abd9538414466" category="list-text">Azure 포털에서 Azure VMware 솔루션으로 이동하여 프라이빗 클라우드를 선택하고 * 관리 &gt; 추가 기능 &gt; HCX * 를 사용한 마이그레이션 을 선택합니다.</block>
  <block id="436402d536d27aaa2091a54751a60036" category="list-text">HCX 키를 사용하여 온-프레미스로 연결 * 에서 * 추가 * 를 클릭하고 활성화 키를 복사합니다.</block>
  <block id="0b053e667d8c9baa8cbb4a5402fe69e1" category="inline-image-macro">HCX 키 추가 스크린샷.</block>
  <block id="5d9de146e997662a8510bd175e5c593a" category="paragraph"><block ref="5d9de146e997662a8510bd175e5c593a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03fc385dd3b54c80a78341c5aa2189a3" category="admonition">배포된 각 온프레미스 HCX Connector에는 별도의 키가 필요합니다.</block>
  <block id="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link"><block ref="e8edfbded2eb5193c58170d5f9073d7d" category="inline-link-rx"></block></block>
  <block id="b6d4af6a25f46f3687120681e525d833" category="list-text">사내 VMware HCX Manager()에 로그인합니다<block ref="f9ac10929d1e2f12c4fea5c57d73b3eb" category="inline-link-rx"></block> 관리자 자격 증명을 사용합니다.</block>
  <block id="b2719f92794cef282f9cd7684baca4c4" category="admonition">OVA 배포 중에 정의된 암호를 사용합니다.</block>
  <block id="a864855f2120d5c8d4793a4866b6a7bb" category="list-text">라이센스에서 3단계에서 복사한 키를 입력하고 * Activate * 를 클릭합니다.</block>
  <block id="e5c8d88f2fa7af9f1a719e04c4b17740" category="admonition">온프레미스 HCX 커넥터는 인터넷에 연결되어 있어야 합니다.</block>
  <block id="ee746d79ab481579a8c0202a94e8d378" category="list-text">데이터 센터 위치 * 에서 VMware HCX Manager를 사내에 설치할 수 있는 가장 가까운 위치를 제공합니다. 계속 * 을 클릭합니다.</block>
  <block id="c72431b355c96ffdfb7baece307881f0" category="list-text">시스템 이름 * 에서 이름을 업데이트하고 * 계속 * 을 클릭합니다.</block>
  <block id="030627b8e0e3f6ba69c6a9e524d8e9c0" category="list-text">예, 계속 * 을 클릭합니다.</block>
  <block id="05399e57e0b2a25ce8cef32f3628b2e3" category="list-text">vCenter * 연결 아래에서 vCenter Server의 FQDN(정규화된 도메인 이름) 또는 IP 주소와 해당 자격 증명을 입력하고 * 계속 * 을 클릭합니다.</block>
  <block id="96b1cf77a862dc0408a3e2e9678b2165" category="admonition">나중에 연결 문제를 방지하려면 FQDN을 사용합니다.</block>
  <block id="390f6c76fee2d7fb6d09bcedc3622467" category="list-text">SSO/PSC * 구성 아래에서 플랫폼 서비스 컨트롤러의 FQDN 또는 IP 주소를 입력하고 * 계속 * 을 클릭합니다.</block>
  <block id="b070c615098fb975bc2bc3a9f6c67b3e" category="admonition">VMware vCenter Server FQDN 또는 IP 주소를 입력합니다.</block>
  <block id="f4bb2b9a4de7e44c942457943977fd34" category="list-text">입력한 정보가 올바른지 확인하고 * Restart * (재시작 *)를 클릭합니다.</block>
  <block id="a565e4f9db7c03385f61c3bdb0f4b806" category="list-text">서비스를 다시 시작하면 표시되는 페이지에 vCenter Server가 녹색으로 표시됩니다. vCenter Server와 SSO 모두 적절한 구성 매개 변수를 가져야 하며, 이는 이전 페이지와 동일해야 합니다.</block>
  <block id="457446477fbd3326ba80d1248eaca490" category="admonition">이 프로세스는 약 10~20분 정도 소요되며 플러그인이 vCenter Server에 추가되어야 합니다.</block>
  <block id="1181827ced4ce13f7bd91097d9b10dac" category="inline-image-macro">완료된 프로세스를 보여 주는 스크린샷</block>
  <block id="534d4f43f7a513cf2f2152686da775ae" category="paragraph"><block ref="534d4f43f7a513cf2f2152686da775ae" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0b94fcafcd5f76f4f84be761263d657" category="example-title">4단계: 온프레미스 VMware HCX Connector를 Azure VMware Solution HCX Cloud Manager와 페어링합니다</block>
  <block id="ae37843769e741d076e2422772db5395" category="paragraph">HCX Connector를 온프레미스 및 Azure VMware 솔루션에 설치한 후 페어링을 추가하여 온프레미스 VMware HCX Connector for Azure VMware Solution 프라이빗 클라우드를 구성합니다. 사이트 페어링을 구성하려면 다음 단계를 수행하십시오.</block>
  <block id="28b0363954066139335c413f28022037" category="list-text">온-프레미스 vCenter 환경과 Azure VMware Solution SDDC 간에 사이트 쌍을 생성하려면 온-프레미스 vCenter Server에 로그인하고 새 HCX vSphere Web Client 플러그인에 액세스합니다.</block>
  <block id="f4f57342a1f5bfd667f7d19048c4aa85" category="inline-image-macro">HCX vSphere Web Client 플러그인의 스크린샷</block>
  <block id="1ecb33e8c47a03470ff03bb6c09a1d87" category="paragraph"><block ref="1ecb33e8c47a03470ff03bb6c09a1d87" category="inline-image-macro-rx" type="image"></block></block>
  <block id="302ca8cbe91eb456c9defb6fe514b81e" category="list-text">인프라 에서 * 사이트 페어링 추가 * 를 클릭합니다.</block>
  <block id="cd6182a85ca09ca99bda2787165407d9" category="admonition">Azure VMware 솔루션 HCX Cloud Manager URL 또는 IP 주소와 프라이빗 클라우드에 액세스하기 위한 CloudAdmin 역할의 자격 증명을 입력합니다.</block>
  <block id="407d1d705e5bdedf2e1c5e9257c0c1ef" category="inline-image-macro">CloudAdmin 역할의 스크린샷 URL 또는 IP 주소 및 자격 증명.</block>
  <block id="6e861dfeca468a35e2aa6f6a42b2ad5f" category="paragraph"><block ref="6e861dfeca468a35e2aa6f6a42b2ad5f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9bccd838ddedeb361e65189136ac5c0f" category="list-text">연결 * 을 클릭합니다.</block>
  <block id="7630a70e4d4511de5ac0f8ce18edd594" category="admonition">VMware HCX Connector는 포트 443을 통해 HCX Cloud Manager IP로 라우팅할 수 있어야 합니다.</block>
  <block id="ddea1cbf444f5d4e69d68b23eb0b4b59" category="list-text">페어링이 생성된 후에는 새로 구성된 사이트 페어링을 HCX 대시보드에서 사용할 수 있습니다.</block>
  <block id="8cdce778f46399f121d65006767f466a" category="inline-image-macro">HCX 대시보드의 완료된 프로세스 스크린샷</block>
  <block id="a71387f99ef8fc06b56323de8e6a67e6" category="paragraph"><block ref="a71387f99ef8fc06b56323de8e6a67e6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="38bca9c1088c36da27f6910232836b09" category="example-title">5단계: 네트워크 프로파일, 컴퓨팅 프로파일 및 서비스 메시를 구성합니다</block>
  <block id="a030f25f2e21cc0db80d6a88646adb63" category="paragraph">VMware HCX Interconnect 서비스 어플라이언스는 인터넷을 통해 복제 및 vMotion 기반 마이그레이션 기능과 타겟 사이트에 대한 프라이빗 연결을 제공합니다. 상호 연결은 암호화, 트래픽 엔지니어링 및 VM 이동성을 제공합니다. 상호 연결 서비스 어플라이언스를 생성하려면 다음 단계를 수행하십시오.</block>
  <block id="efb9332572aac00947298fc1ed65c0da" category="list-text">인프라 아래에서 * 상호 연결 &gt; 멀티 사이트 서비스 메시 &gt; 컴퓨팅 프로파일 &gt; 컴퓨팅 프로파일 생성 * 을 선택합니다.</block>
  <block id="96e78a381f203820b7fb0d823994f764" category="admonition">컴퓨팅 프로필은 구축된 어플라이언스와 HCX 서비스에서 액세스할 수 있는 VMware 데이터 센터 부분을 포함하여 구축 매개 변수를 정의합니다.</block>
  <block id="df03fa88f502c44f3476981d50c25ae4" category="inline-image-macro">vSphere Client Interconnect 페이지의 스크린샷.</block>
  <block id="0f7d2c9383c1f40641b39e9f65126dcf" category="paragraph"><block ref="0f7d2c9383c1f40641b39e9f65126dcf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ba9d884b8a48f110e052a2644f36c6bb" category="list-text">컴퓨팅 프로파일을 만든 후 * 다중 사이트 서비스 메시 &gt; 네트워크 프로파일 &gt; 네트워크 프로파일 만들기 * 를 선택하여 네트워크 프로파일을 만듭니다.</block>
  <block id="7e461f559c367396eca97f75c2262003" category="paragraph">네트워크 프로파일은 HCX가 가상 어플라이언스에 사용하는 IP 주소 및 네트워크의 범위를 정의합니다.</block>
  <block id="12618dff60108a0e440afb082e782c71" category="admonition">이 단계에서는 두 개 이상의 IP 주소가 필요합니다. 이러한 IP 주소는 관리 네트워크에서 상호 연결 어플라이언스로 할당됩니다.</block>
  <block id="9f137734809298c4fa85b07a7ddb6c5f" category="inline-image-macro">vSphere Client Interconnect 페이지에 IP 주소를 추가하는 스크린샷</block>
  <block id="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="paragraph"><block ref="c1fdcb13f1a622ccbe4f21a52d31bcb1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9f78591a00b39059d077f422f8695286" category="list-text">현재 컴퓨팅 및 네트워크 프로파일이 성공적으로 생성되었습니다.</block>
  <block id="5e8122825414e5afe12c228e3afb9f77" category="list-text">Interconnect * 옵션 내에서 * Service Mesh * 탭을 선택하고 온프레미스 및 Azure SDDC 사이트를 선택하여 Service Mesh를 생성합니다.</block>
  <block id="efe6cc3fe15f7c67781cd956f1aa3b8e" category="list-text">서비스 메시는 로컬 및 원격 계산 및 네트워크 프로파일 쌍을 지정합니다.</block>
  <block id="292b454f1874f04a4b6f9258b5f933e4" category="admonition">이 프로세스의 일환으로 안전한 전송 패브릭을 생성하기 위해 소스 사이트와 타겟 사이트 모두에 HCX 어플라이언스를 구축하고 자동으로 구성합니다.</block>
  <block id="0433a192b31baf05b1deba1471c492ff" category="inline-image-macro">vSphere Client Interconnect 페이지의 Service Mesh 탭 스크린샷</block>
  <block id="55551523a891564fc7b09d6dec2fe75f" category="paragraph"><block ref="55551523a891564fc7b09d6dec2fe75f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9df03f8fa3fc5e40e9100c8ebbd3a2ad" category="list-text">이 단계는 구성의 마지막 단계입니다. 구축을 완료하는 데 약 30분이 소요됩니다. 서비스 메시가 구성된 후 작업 부하 VM을 마이그레이션하도록 IPsec 터널이 성공적으로 생성된 환경이 준비됩니다.</block>
  <block id="532b4e992bd2794e777d1c1320e94f98" category="inline-image-macro">vSphere Client Interconnect 페이지에 완료된 프로세스의 스크린샷</block>
  <block id="9158466ef9c7277d9287f86080b2c362" category="paragraph"><block ref="9158466ef9c7277d9287f86080b2c362" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e0e8a1058909962c26cdead8b3fab020" category="example-title">6단계: 워크로드 마이그레이션</block>
  <block id="80ea378666ca268305d30933ca376035" category="paragraph">다양한 VMware HCX 마이그레이션 기술을 사용하여 온프레미스 및 Azure SDDC 간에 워크로드를 양방향으로 마이그레이션할 수 있습니다. VM은 HCX 대량 마이그레이션, HCX vMotion, HCX 콜드 마이그레이션, HCX Replication Assisted vMotion(HCX Enterprise Edition에서 사용 가능) 및 HCX OS 지원 마이그레이션(HCX Enterprise Edition에서 사용 가능)과 같은 여러 마이그레이션 기술을 사용하여 VMware HCX 활성 엔터티로 또는 VMware에서 이동할 수 있습니다.</block>
  <block id="94638809b72d557d4335dfce65f69e35" category="inline-link">VMware HCX 마이그레이션 유형</block>
  <block id="aa52e427086548446f11ad8e43c6e998" category="paragraph">다양한 HCX 마이그레이션 메커니즘에 대한 자세한 내용은 을 참조하십시오<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block>.</block>
  <block id="998d1ed8e82c8145e094c99bf11f8408" category="paragraph">* 대량 마이그레이션 *</block>
  <block id="15a3af99dcf6c8651b8f168e13625c61" category="paragraph">이 섹션에서는 대량 마이그레이션 메커니즘에 대해 자세히 설명합니다. 대량 마이그레이션 중에 HCX의 대량 마이그레이션 기능은 vSphere Replication을 사용하여 디스크 파일을 마이그레이션하는 동시에 대상 vSphere HCX 인스턴스에서 VM을 다시 생성합니다.</block>
  <block id="181b4946601ef2026e3d3ca16145a722" category="paragraph">대량 VM 마이그레이션을 시작하려면 다음 단계를 수행하십시오.</block>
  <block id="76b01c506c1450a5b0ff6dccaeb0e9b7" category="list-text">서비스 &gt; 마이그레이션 * 에서 * 마이그레이션 * 탭에 액세스합니다.</block>
  <block id="bdfca72da9e5f7e7bfcd81aa9844aa45" category="inline-image-macro">vSphere Client의 마이그레이션 섹션 스크린샷</block>
  <block id="005bf2b00a4806639f3ea37ea4509f6b" category="paragraph"><block ref="005bf2b00a4806639f3ea37ea4509f6b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cc18384d5bbc3aa89ffea93d51abc451" category="list-text">원격 사이트 연결 * 에서 원격 사이트 연결을 선택하고 소스 및 대상을 선택합니다. 이 예에서 대상은 Azure VMware Solution SDDC HCX 엔드포인트입니다.</block>
  <block id="251b1066293b131079328f5d09e33aca" category="list-text">마이그레이션을 위한 VM 선택 * 을 클릭합니다. 이 목록에는 모든 온-프레미스 VM 목록이 표시됩니다. match:value 식을 기준으로 VM을 선택하고 * Add * 를 클릭합니다.</block>
  <block id="70dc92c7c0c3752e5757560b72fa8f04" category="list-text">Transfer and Placement * 섹션에서 마이그레이션 프로파일을 포함하여 필수 필드(* Cluster *, * Storage *, * Destination * 및 * Network *)를 업데이트하고 * Validate * 를 클릭합니다.</block>
  <block id="009e0b54f8062ebadb85388889541f12" category="inline-image-macro">vSphere Client의 Transfer and Placement 섹션 스크린샷</block>
  <block id="e5cde894c26fccdfef420936d570829b" category="paragraph"><block ref="e5cde894c26fccdfef420936d570829b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7599f8a3668b692ca7501152d4682c07" category="list-text">유효성 검사가 완료된 후 * GO * 를 클릭하여 마이그레이션을 시작합니다.</block>
  <block id="79af22f136dbfe3d3bf950a72f2c5f5b" category="inline-image-macro">마이그레이션 시작 스크린샷.</block>
  <block id="c40f6796f391e80926e1a459f389859b" category="paragraph"><block ref="c40f6796f391e80926e1a459f389859b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c1969ef22141ce348651d2b0f4eb5dd8" category="admonition">이 마이그레이션 중에 소스 VM 디스크의 데이터를 자리 표시자 디스크로 복제할 수 있도록 대상 vCenter 내의 지정된 Azure NetApp Files 데이터 저장소에 자리 표시자 디스크가 생성됩니다. HBR은 타겟에 대한 전체 동기화를 위해 트리거되며, 기준선이 완료되면 RPO(복구 시점 목표) 주기에 따라 증가분 동기화가 수행됩니다. 전체/증분 동기화가 완료되면 특정 일정이 설정되지 않으면 전환이 자동으로 트리거됩니다.</block>
  <block id="c0b39ee3609ffbaf676e9119dd912e9b" category="list-text">마이그레이션이 완료된 후 대상 SDDC vCenter에 액세스하여 동일한 검증을 수행합니다.</block>
  <block id="5d882ffc756bfb07c0785abe30634c3c" category="paragraph"><block ref="5d882ffc756bfb07c0785abe30634c3c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0d785f8302edf28ffd50ba9bd9a1e3e5" category="paragraph">다양한 마이그레이션 옵션과 HCX를 사용하여 워크로드를 온프레미스에서 Azure VMware 솔루션으로 마이그레이션하는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>.</block>
  <block id="73e6478a04a38e6c1af3fd112abd351f" category="paragraph">이 프로세스에 대해 자세히 알아보려면 자세한 단계별 안내 비디오를 참조하십시오.</block>
  <block id="128dd96b5323b02401db618a27f67394" category="paragraph">다음은 HCX vMotion 옵션의 스크린샷입니다.</block>
  <block id="d77e1c6edbcf98bc28017153ba737ae7" category="paragraph"><block ref="d77e1c6edbcf98bc28017153ba737ae7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="efb5f7e867e5fc98adcdcb1d219cdd4a" category="admonition">마이그레이션을 처리할 수 있는 대역폭이 충분한지 확인합니다.</block>
  <block id="6147587d84b933dcb429334a5e2594f9" category="admonition">타겟 ANF 데이터 저장소에 마이그레이션을 처리할 충분한 공간이 있어야 합니다.</block>
  <block id="d7372a0d2d0e1ec31f9e1d607d52e246" category="paragraph">Azure NetApp Files와 HCX는 사내 모든 유형/공급업체 스토리지에 상주하는 모든 클라우드 또는 하이브리드 클라우드 및 데이터를 대상으로 애플리케이션 워크로드에 대한 데이터 요구 사항을 애플리케이션 계층에 원활하게 제공함으로써 TCO를 절감하는 동시에 애플리케이션 워크로드를 배포 및 마이그레이션할 수 있는 탁월한 옵션을 제공합니다. 어떤 사용 사례에서든 Azure NetApp Files와 함께 Azure VMware 솔루션을 선택하면 클라우드의 이점, 일관된 인프라, 사내 및 멀티 클라우드 전반의 운영, 워크로드의 양방향 이동성, 엔터프라이즈급 용량 및 성능을 빠르게 실현할 수 있습니다. VMware vSphere Replication, VMware vMotion 또는 NFC(네트워크 파일 복사)를 사용하여 스토리지를 연결하고 VM을 마이그레이션하는 데 사용되는 익숙한 프로세스와 절차가 동일합니다.</block>
  <block id="7a7f4f94771d5c3f94a76599dcacb0cf" category="list-text">이제 Azure NetApp Files를 Azure VMware 솔루션 SDDC에서 데이터 저장소로 사용할 수 있습니다.</block>
  <block id="44b43fa706a816b30490196d187959c4" category="list-text">사내의 데이터를 Azure NetApp Files 데이터 저장소로 손쉽게 마이그레이션할 수 있습니다.</block>
  <block id="bc6808bfb84f0a05f9640103114929fa" category="list-text">마이그레이션 작업 중에 용량 및 성능 요구 사항을 충족하도록 Azure NetApp Files 데이터 저장소를 쉽게 확장 및 축소할 수 있습니다.</block>
  <block id="61af664797ae795435faba35dd141335" category="inline-link"><block ref="61af664797ae795435faba35dd141335" category="inline-link-rx"></block></block>
  <block id="ab19b6733f7a9500ff9d392433071ef2" category="paragraph"><block ref="ab19b6733f7a9500ff9d392433071ef2" category="inline-link-rx"></block></block>
  <block id="7c5ba33b986ba469d277c4ca9f906e55" category="inline-link-macro">VMware HCX를 사용하여 워크로드를 FSxN 데이터 저장소로 마이그레이션합니다</block>
  <block id="c037991d132128e15cdbfefe3ac8e997" category="list-text"><block ref="c037991d132128e15cdbfefe3ac8e997" category="inline-link-macro-rx"></block></block>
  <block id="086d898e7d4a481c2147d4eb71dff1f6" category="section-title">개요: VMware HCX, FSx ONTAP 보조 데이터 저장소 및 VMware Cloud를 사용하여 가상 시스템 마이그레이션</block>
  <block id="82778188ea3c0ca7871389afec5bfd03" category="paragraph">AWS(Amazon Web Services)의 VMware 클라우드(VMC)에 대한 일반적인 사용 사례로서, NetApp ONTAP용 Amazon FSx의 보조 NFS 데이터 저장소가 포함된 VMware 워크로드를 마이그레이션합니다. VMware HCX가 선호되는 옵션이며, VMware에서 지원하는 모든 데이터 저장소에서 실행되는 사내 VM(가상 머신)과 해당 데이터를 ONTAP용 FSx의 보조 NFS 데이터 저장소를 포함하는 VMC 데이터 저장소로 이동하는 다양한 마이그레이션 방법을 제공합니다.</block>
  <block id="2fbfc2601ddccd56b7728df6f0a658e1" category="paragraph">VMware HCX는 주로 클라우드 전반에서 워크로드 마이그레이션, 워크로드 재조정 및 비즈니스 연속성을 간소화하도록 설계된 모바일 플랫폼입니다. 이 제품은 AWS 기반 VMware Cloud의 일부로 포함되어 있으며 워크로드를 다양한 방법으로 마이그레이션하여 DR(재해 복구) 작업에 사용할 수 있습니다.</block>
  <block id="aabc04eb6cd0b22670013ea8212b7a4f" category="paragraph">이 문서에서는 모든 주요 구성 요소, 온프레미스 및 클라우드 데이터 센터 측 등 다양한 VM 마이그레이션 메커니즘을 지원하는 VMware HCX를 구축 및 구성하기 위한 단계별 지침을 제공합니다.</block>
  <block id="d493b7ce0e1cf6434fdce9bd4fa1c847" category="inline-link">HCX 구축 소개</block>
  <block id="274e6762dc6bf155637729306a74154b" category="inline-link">AWS SDDC 대상 환경에서 VMware 클라우드를 사용하여 체크리스트 B-HCX를 설치합니다</block>
  <block id="1db2f90540d47d2fe14bfc6cad01537a" category="paragraph">자세한 내용은 을 참조하십시오<block ref="871067259283ae637dd3ddcf90a49e5d" category="inline-link-rx"></block> 및<block ref="b5449e907f27219538721e57c42a92c0" category="inline-link-rx"></block>.</block>
  <block id="18ad70c16d20c99de2753c4da7fb1291" category="paragraph">이 목록에는 VMware HCX를 설치하고 구성하는 단계가 수록되어 있습니다.</block>
  <block id="b9b7e6b65417eaac8eeb13d3f809942d" category="list-text">VMware Cloud Services Console을 통해 VMC SDDC(소프트웨어 정의 데이터 센터)에 대한 HCX를 활성화합니다.</block>
  <block id="76f775a9fe0b12df87ae0ad6b34efdd9" category="list-text">온-프레미스 vCenter Server에서 HCX Connector OVA 설치 프로그램을 다운로드하여 구축합니다.</block>
  <block id="f970657dc986e56f66a60a02b1210c43" category="list-text">라이센스 키를 사용하여 HCX를 활성화합니다.</block>
  <block id="2d7e8f746bd165e0f342b659b51cff2c" category="list-text">온프레미스 VMware HCX Connector를 VMC HCX Cloud Manager와 페어링합니다.</block>
  <block id="a9f9ba84cb2c76d9b8033c6f9ad14642" category="list-text">(선택 사항) 네트워크 확장을 수행하여 네트워크를 확장하고 재IP를 방지합니다.</block>
  <block id="f5633594a47ccbe1e89229d43cbce0ec" category="inline-link">HCX 설치 준비 중</block>
  <block id="ecdf05ad108113e6a7e36c14f4d8e596" category="paragraph">시작하기 전에 다음 필수 구성 요소가 충족되었는지 확인하십시오. 자세한 내용은 을 참조하십시오<block ref="c59343d9a8c2798bf6815397e3f08bd3" category="inline-link-rx"></block>. 연결을 포함하여 사전 요구 사항이 충족되면 VMC의 VMware HCX 콘솔에서 라이센스 키를 생성하여 HCX를 구성하고 활성화합니다. HCX가 활성화되면 vCenter 플러그인이 구축되며 관리를 위해 vCenter 콘솔을 사용하여 액세스할 수 있습니다.</block>
  <block id="f0983a6fa9c97fbc87ff3ad43495e008" category="paragraph">HCX 활성화 및 배포를 진행하기 전에 다음 설치 단계를 완료해야 합니다.</block>
  <block id="dba413fdbeffb35a4459e9d3f45be3bd" category="inline-link">VMware 링크</block>
  <block id="b390c6b07bec05579868558e66fda8e2" category="list-text">기존 VMC SDDC를 사용하거나 다음 새 SDDC를 생성합니다<block ref="11000cc7aedbe4805fa20a67d23d81ac" category="inline-link-rx"></block> 또는 이<block ref="5f912d133d878a69c5af374752da199e" category="inline-link-rx"></block>.</block>
  <block id="67cff13cad47354f1f51ce3ef47c6ddc" category="list-text">사내 vCenter 환경에서 VMC SDDC로의 네트워크 경로는 vMotion을 사용하여 VM 마이그레이션을 지원해야 합니다.</block>
  <block id="c9f9609ee5731fe3777e57937464dc54" category="list-text">필수 를 확인하십시오<block ref="69c9d7a74dad51c1c47ea8141c218514" category="inline-link-rx"></block> 온-프레미스 vCenter Server와 SDDC vCenter 간에 vMotion 트래픽이 허용됩니다.</block>
  <block id="aa8db0799849f7e0b11c7c3594394423" category="list-text">ONTAP NFS 볼륨용 FSx는 VMC SDDC에 보조 데이터 저장소로 마운트되어야 합니다. NFS 데이터 저장소를 적절한 클러스터에 연결하려면 여기에 설명된 단계를 따르십시오<block ref="2d161daeb93489b09b5e8bcd39dbc4b1" category="inline-link-rx"></block> 또는 이<block ref="6eb21d78e613b27f69be6d996a6367b3" category="inline-link-rx"></block>.</block>
  <block id="915747189317f7496ecb2bcdc22e83b5" category="paragraph">테스트 목적으로, 이 검증에 사용된 온프레미스 랩 환경은 사이트 간 VPN을 통해 AWS VPC에 연결되었으며, 외부 전송 게이트웨이를 통해 AWS와 VMware 클라우드 SDDC에 사내 연결을 가능하게 했습니다. HCX 마이그레이션 및 네트워크 확장 트래픽은 온프레미스 및 VMware 클라우드 대상 SDDC 사이에서 인터넷을 통해 흐릅니다. Direct Connect 프라이빗 가상 인터페이스를 사용하도록 이 아키텍처를 수정할 수 있습니다.</block>
  <block id="20c789c477f416c40ed37a0a96f352d5" category="paragraph">다음 이미지는 높은 수준의 아키텍처를 보여 줍니다.</block>
  <block id="9f4db1da9d84fe1111fd9ae7c377f786" category="paragraph"><block ref="9f4db1da9d84fe1111fd9ae7c377f786" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5189f076565998395f00538902b201d3" category="example-title">1단계: 애드온 옵션을 사용하여 VMC SDDC를 통해 HCX를 활성화합니다</block>
  <block id="84d84827fbe9c4b33c9c3b806b314d3f" category="inline-link">vmc.vmware.com</block>
  <block id="db44791d0479a0d2c9f5549eac8850ad" category="list-text">에서 VMC 콘솔에 로그인합니다<block ref="98f8f917cb7f10ee415fb6ce242d9349" category="inline-link-rx"></block> 재고 에 액세스할 수 있습니다.</block>
  <block id="049aac4163d4ee979d2ebd21434216a2" category="list-text">적절한 SDDC를 선택하고 Add-On에 액세스하려면 SDDC에서 View Details를 클릭하고 Add On 탭을 선택합니다.</block>
  <block id="933c74bf858432dc81f521597cffbfbb" category="list-text">VMware HCX에 대해 활성화 를 클릭합니다.</block>
  <block id="7335132a517aad5765c48773404c2687" category="admonition">이 단계를 완료하는 데 최대 25분이 소요됩니다.</block>
  <block id="be7b0f3d5e22843c4a2107342b36330b" category="paragraph"><block ref="be7b0f3d5e22843c4a2107342b36330b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fcf3d539a908f48f7d82acf7470675f7" category="list-text">구축이 완료되면 vCenter Console에서 HCX Manager 및 관련 플러그인을 사용할 수 있는지 확인하여 구축을 검증합니다.</block>
  <block id="8c0cff0c106bc3f5a4dd79c01c3de7a9" category="list-text">적절한 관리 게이트웨이 방화벽을 만들어 HCX Cloud Manager에 액세스하는 데 필요한 포트를 엽니다. 이제 HCX Cloud Manager가 HCX 작업을 수행할 준비가 되었습니다.</block>
  <block id="6eac4c95d8f88bfb601f7b87770513ab" category="paragraph">온프레미스 커넥터가 VMC의 HCX Manager와 통신하려면 적절한 방화벽 포트가 온-프레미스 환경에서 열려 있는지 확인합니다.</block>
  <block id="185b9319145cb225cdb1256b494e0595" category="list-text">VMC 콘솔에서 HCX 대시보드로 이동하고 관리 로 이동한 다음 시스템 업데이트 탭을 선택합니다. HCX 커넥터 OVA 이미지에 대한 다운로드 링크 요청 을 클릭합니다.</block>
  <block id="039b399de18508b9f1029358886fea99" category="list-text">HCX Connector를 다운로드한 후 온-프레미스 vCenter Server에 OVA를 구축합니다. vSphere Cluster를 마우스 오른쪽 버튼으로 클릭하고 Deploy OVF Template 옵션을 선택합니다.</block>
  <block id="bd18e96a29eec74967666d876a146937" category="paragraph"><block ref="bd18e96a29eec74967666d876a146937" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e8df6b0257b180b48db7d56e06e4da54" category="list-text">Deploy OVF Template 마법사에 필요한 정보를 입력하고 Next를 클릭한 다음 Finish를 클릭하여 VMware HCX Connector OVA를 구축합니다.</block>
  <block id="8925cbdefd949dca662858e368d4ccfb" category="list-text">가상 어플라이언스의 전원을 수동으로 켭니다. 단계별 지침을 보려면 로 이동하십시오<block ref="856d054195f2a40a0c4a2869d5895904" category="inline-link-rx"></block>.</block>
  <block id="fab9859fcf95f41f7bb654e91e6876b4" category="paragraph">VMware HCX 커넥터 OVA를 온-프레미스로 배포하고 어플라이언스를 시작한 후 다음 단계를 수행하여 HCX 커넥터를 활성화하십시오. VMC의 VMware HCX 콘솔에서 라이센스 키를 생성하고 VMware HCX Connector 설정 중에 라이센스를 입력합니다.</block>
  <block id="fddda62632eb91015346909c9da3cf70" category="list-text">VMware Cloud Console에서 Inventory로 이동하여 SDDC를 선택하고 View Details를 클릭합니다. 추가 기능 탭의 VMware HCX 타일에서 Open HCX를 클릭합니다.</block>
  <block id="51e51578490c90a69c673d41361b0070" category="list-text">활성화 키 탭에서 활성화 키 생성 을 클릭합니다. 시스템 유형을 HCX 커넥터로 선택하고 확인을 클릭하여 키를 생성합니다. 활성화 키를 복사합니다.</block>
  <block id="e30847f53a6e375f1da81f871c44e963" category="paragraph"><block ref="e30847f53a6e375f1da81f871c44e963" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c410deb9d7b04917aff523f97f944894" category="admonition">사내에 구축된 각 HCX Connector에는 별도의 키가 필요합니다.</block>
  <block id="1111fa8f5187058abdce3daca03b7e32" category="inline-link"><block ref="1111fa8f5187058abdce3daca03b7e32" category="inline-link-rx"></block></block>
  <block id="d9432955aa7705a1f97c9e94c730fdc9" category="list-text">사내 VMware HCX Connector 에 로그인합니다<block ref="ece20a9f7dc6720cdeb30c7e7733cd22" category="inline-link-rx"></block> 관리자 자격 증명을 사용합니다.</block>
  <block id="f5f8371708aa6ae3ddb84d1f4d9b5d17" category="list-text">Licensing 섹션에서 2단계에서 복사한 활성화 키를 입력하고 Activate를 클릭합니다.</block>
  <block id="404a7c7a7d73b870628663e76e974d09" category="admonition">활성화를 성공적으로 완료하려면 온-프레미스 HCX 커넥터에 인터넷 액세스가 있어야 합니다.</block>
  <block id="564ed09bba79e1d4262e37fc94987fbe" category="list-text">Datacenter Location(데이터 센터 위치) 에서 VMware HCX Manager를 설치할 위치를 지정합니다. 계속 을 클릭합니다.</block>
  <block id="61ce05ace76ff1424841e5e551873a97" category="list-text">시스템 이름 에서 이름을 업데이트하고 계속 을 클릭합니다.</block>
  <block id="4bc852451f43c4b3df306f35e67e4178" category="list-text">예 를 선택한 다음 계속 을 선택합니다.</block>
  <block id="7eefbebbdefe472b13ce5d0bce410737" category="list-text">vCenter 연결 에서 vCenter Server에 대한 IP 주소 또는 FQDN(정규화된 도메인 이름) 및 자격 증명을 제공하고 계속 을 클릭합니다.</block>
  <block id="47a7ea3464363cf9baa528c91d3aa4dc" category="admonition">나중에 통신 문제를 방지하려면 FQDN을 사용합니다.</block>
  <block id="eb7e70dd1954a71454c2e6a0cb9ed5f8" category="list-text">SSO/PSC 구성에서 플랫폼 서비스 컨트롤러의 FQDN 또는 IP 주소를 제공하고 계속을 클릭합니다.</block>
  <block id="1f2f2ed2ec24b1f1ab37799a6f27fa40" category="admonition">vCenter Server의 IP 주소 또는 FQDN을 입력합니다.</block>
  <block id="24b993e60859697b0875bc838cfe12aa" category="list-text">정보가 올바르게 입력되었는지 확인하고 다시 시작 을 클릭합니다.</block>
  <block id="b0fca3e3f2889bbec562577014fafd9a" category="list-text">완료되면 vCenter Server가 녹색으로 표시됩니다. vCenter Server와 SSO 모두 올바른 구성 매개 변수를 가져야 하며, 이는 이전 페이지와 동일해야 합니다.</block>
  <block id="8463d9f0fc95490bc0c65d3ba9063dea" category="admonition">이 프로세스는 약 10~20분 정도 소요되며 플러그인이 vCenter Server에 추가되어야 합니다.</block>
  <block id="a56ac8f65b53b91dba588aafc428f8b2" category="paragraph"><block ref="a56ac8f65b53b91dba588aafc428f8b2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="65d6e263d26134bb05aeec17adc73a06" category="example-title">4단계: 사내 VMware HCX Connector와 VMC HCX Cloud Manager를 페어링합니다</block>
  <block id="f68b6001164eba9a9e765e551c59a3c1" category="list-text">온-프레미스 vCenter Server와 VMC SDDC 간에 사이트 쌍을 생성하려면 온-프레미스 vCenter Server에 로그인하고 HCX vSphere Web Client 플러그인에 액세스합니다.</block>
  <block id="10f9af0781b3c0a9d621bac0b8719365" category="paragraph"><block ref="10f9af0781b3c0a9d621bac0b8719365" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1af79e59a8d820cc101f77efa75cb01d" category="list-text">인프라 에서 사이트 페어링 추가 를 클릭합니다. 원격 사이트를 인증하려면 VMC HCX Cloud Manager URL 또는 IP 주소와 CloudAdmin 역할의 자격 증명을 입력합니다.</block>
  <block id="1b49b2932a225dd49cc6f5298ad6cc8f" category="paragraph"><block ref="1b49b2932a225dd49cc6f5298ad6cc8f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2a7c72a1b7e925abd687d2c7a4ac5a2f" category="admonition">HCX 정보는 SDDC 설정 페이지에서 검색할 수 있습니다.</block>
  <block id="1272226ee970b8e49c49d25af6f4b6b8" category="paragraph"><block ref="1272226ee970b8e49c49d25af6f4b6b8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="838d70471e28171464ffd4fed8d9df3a" category="paragraph"><block ref="838d70471e28171464ffd4fed8d9df3a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dbcfb2058c277401b0872487463fe313" category="list-text">사이트 페어링을 시작하려면 연결 을 클릭합니다.</block>
  <block id="2147cde45e80d7c6a5db679f7180eab4" category="admonition">VMware HCX Connector는 포트 443을 통해 HCX Cloud Manager IP와 통신할 수 있어야 합니다.</block>
  <block id="618a4f677a45dc2b53f7c464b5598c28" category="paragraph">VMware HCX-IX(HCX Interconnect) 어플라이언스는 인터넷을 통해 보안 터널 기능을 제공하고 타겟 사이트에 대한 프라이빗 연결을 통해 복제 및 vMotion 기반 기능을 지원합니다. 상호 연결은 암호화, 트래픽 엔지니어링 및 SD-WAN을 제공합니다. HCI-IX 상호 연결 어플라이언스를 생성하려면 다음 단계를 수행하십시오.</block>
  <block id="f32fcca3303979d42a8f0be055fc36dd" category="list-text">인프라 에서 상호 연결 &gt; 다중 사이트 서비스 메시 &gt; 컴퓨팅 프로파일 &gt; 컴퓨팅 프로파일 생성 을 선택합니다.</block>
  <block id="46c0e6a1b2dbd6331bcea8e4726de843" category="admonition">컴퓨팅 프로파일에는 상호 연결 가상 어플라이언스를 구축하는 데 필요한 컴퓨팅, 스토리지 및 네트워크 구축 매개 변수가 포함됩니다. 또한 VMware 데이터 센터의 어떤 부분을 HCX 서비스에 액세스할 수 있는지도 지정합니다.</block>
  <block id="46a447d35c4917802c9d612dd8ede3b5" category="inline-link">컴퓨팅 프로파일 생성</block>
  <block id="9fc475734bed02e370e17ea150a74fd3" category="paragraph">자세한 지침은 을 참조하십시오<block ref="3e2a71be9bcd47a34446e38d1b8f4987" category="inline-link-rx"></block>.</block>
  <block id="648388c6923f0b4fc45138b46fb56158" category="paragraph"><block ref="648388c6923f0b4fc45138b46fb56158" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ad3c8534d57516f63a1f263c7e4a4c7a" category="list-text">컴퓨팅 프로파일을 만든 후 다중 사이트 서비스 메시 &gt; 네트워크 프로파일 &gt; 네트워크 프로파일 만들기를 선택하여 네트워크 프로파일을 만듭니다.</block>
  <block id="52d18a4f9043fce9a1e9d57e92fc77a4" category="list-text">네트워크 프로파일은 HCX가 가상 어플라이언스에 사용할 IP 주소 및 네트워크의 범위를 정의합니다.</block>
  <block id="2565e95c468130be3fbdbb45da6cadeb" category="admonition">이 경우 두 개 이상의 IP 주소가 필요합니다. 이러한 IP 주소는 관리 네트워크에서 가상 어플라이언스로 할당됩니다.</block>
  <block id="f62f78e1c7b4b764032cbdad0c61a6d0" category="paragraph"><block ref="f62f78e1c7b4b764032cbdad0c61a6d0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d9fad750cff1511b959d686e3a0829f0" category="inline-link">네트워크 프로파일 만들기</block>
  <block id="51cbf458571723275b781ce4b3fec323" category="paragraph">자세한 지침은 을 참조하십시오<block ref="fb1b37f7979e3209d40171b59e47f33b" category="inline-link-rx"></block>.</block>
  <block id="784e6023ad40986353535651f974e468" category="admonition">인터넷을 통해 SD-WAN에 연결하는 경우 네트워킹 및 보안 섹션에서 공용 IP를 예약해야 합니다.</block>
  <block id="c1b5864550e5f67407a0efd2cbe55b67" category="list-text">서비스 메시를 생성하려면 상호 연결 옵션에서 서비스 메시 탭을 선택하고 온-프레미스 및 VMC SDDC 사이트를 선택합니다.</block>
  <block id="295ecbce57290e03752d2e06d4575fff" category="paragraph">서비스 메시는 로컬 및 원격 계산 및 네트워크 프로파일 쌍을 설정합니다.</block>
  <block id="1e21db3cc04207cfb46fd912cdfef571" category="paragraph"><block ref="1e21db3cc04207cfb46fd912cdfef571" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dba94996b6f6f31ef7ea483dc8f0046c" category="admonition">이 프로세스의 일환으로 소스 사이트와 타겟 사이트 모두에서 자동으로 구성되는 HCX 어플라이언스를 구축하여 안전한 전송 패브릭을 생성합니다.</block>
  <block id="b7e93bb3e8f576437ca086d1702a7994" category="list-text">소스 및 원격 컴퓨팅 프로파일을 선택하고 계속을 클릭합니다.</block>
  <block id="ef7ca07b9da6362e4aa341061333a66c" category="paragraph"><block ref="ef7ca07b9da6362e4aa341061333a66c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e42fcfe670e1a9e7a259fb3c9d3dad87" category="list-text">활성화할 서비스를 선택하고 계속 을 클릭합니다.</block>
  <block id="ff89555f65d5e42967fac9abcecb74c8" category="paragraph"><block ref="ff89555f65d5e42967fac9abcecb74c8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f8438ec331921e82a31eaa97deb5f8c0" category="admonition">Replication Assisted vMotion 마이그레이션, SRM 통합 및 OS 지원 마이그레이션에는 HCX Enterprise 라이센스가 필요합니다.</block>
  <block id="9a44378d7dd14730acf075e18d7d8c29" category="list-text">서비스 메시의 이름을 작성하고 마침을 클릭하여 작성 프로세스를 시작합니다. 배포를 완료하는 데 약 30분이 소요됩니다. 서비스 메시를 구성한 후 워크로드 VM을 마이그레이션하는 데 필요한 가상 인프라 및 네트워킹이 생성되었습니다.</block>
  <block id="725a12cf06f45e850e7588b816663c20" category="paragraph"><block ref="725a12cf06f45e850e7588b816663c20" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d0de3992884fcc0e48531f19cce447e7" category="example-title">6단계: 워크로드 마이그레이션</block>
  <block id="af65fc6bdee93e32363bfe5c2cf8ee3a" category="paragraph">HCX는 사내 및 VMC SDDC와 같은 둘 이상의 서로 다른 환경 간에 양방향 마이그레이션 서비스를 제공합니다. HCX 대량 마이그레이션, HCX vMotion, HCX 콜드 마이그레이션, HCX Replication Assisted vMotion(HCX Enterprise Edition에서 사용 가능) 및 HCX OS 지원 마이그레이션(HCX Enterprise Edition에서 사용 가능)과 같은 다양한 마이그레이션 기술을 사용하여 HCX 활성 사이트로 애플리케이션 워크로드를 마이그레이션할 수 있습니다.</block>
  <block id="0afeac0ffbe358cc58864e34fc54c9b2" category="paragraph">사용 가능한 HCX 마이그레이션 기술에 대한 자세한 내용은 을 참조하십시오<block ref="17989ba7d4a97ba4d6ebb072be2dc216" category="inline-link-rx"></block></block>
  <block id="97957dd6d4c5d792035241d68a97795e" category="paragraph">HCX-IX 어플라이언스는 Mobility Agent 서비스를 사용하여 vMotion, Cold 및 RAV(Replication Assisted vMotion) 마이그레이션을 수행합니다.</block>
  <block id="2234ed56b9cbb2a083fd5fe49a89bce1" category="admonition">HCX-IX 어플라이언스는 vCenter Server에서 Mobility Agent 서비스를 호스트 개체로 추가합니다. 이 개체에 표시되는 프로세서, 메모리, 스토리지 및 네트워킹 리소스는 IX 어플라이언스를 호스팅하는 물리적 하이퍼바이저의 실제 소비량을 나타내지 않습니다.</block>
  <block id="c3735752087d3a11c85329680057de55" category="paragraph"><block ref="c3735752087d3a11c85329680057de55" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5c14d0d24d8dccac2ac3ca3ddacf8ba8" category="example-title">VMware HCX vMotion</block>
  <block id="8f2dbd716f60bbee8012a3f0e361fc65" category="paragraph">이 섹션에서는 HCX vMotion 메커니즘을 설명합니다. 이 마이그레이션 기술은 VMware vMotion 프로토콜을 사용하여 VM을 VMC SDDC로 마이그레이션합니다. vMotion 마이그레이션 옵션은 한 번에 하나의 VM의 VM 상태를 마이그레이션하는 데 사용됩니다. 이 마이그레이션 방법 중에는 서비스가 중단되지 않습니다.</block>
  <block id="0c1394a246edcdcb98e3c5fe3cedabbb" category="admonition">IP 주소를 변경할 필요 없이 VM을 마이그레이션하려면 네트워크 확장이 있어야 합니다(VM이 연결된 포트 그룹의 경우).</block>
  <block id="896f227a656a8b0f4a64aa3e12b2506e" category="list-text">온-프레미스 vSphere Client에서 Inventory로 이동하여 마이그레이션할 VM을 마우스 오른쪽 버튼으로 클릭하고 HCX Actions &gt; Migrate to HCX Target Site를 선택합니다.</block>
  <block id="d683c9596c42727fea13c654874f39be" category="paragraph"><block ref="d683c9596c42727fea13c654874f39be" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d4479366aca979ecb9be874cab7bc543" category="list-text">가상 시스템 마이그레이션 마법사에서 원격 사이트 연결(타겟 VMC SDDC)을 선택합니다.</block>
  <block id="09ca4fea7b9ff384e38622ce7cc20a9c" category="paragraph"><block ref="09ca4fea7b9ff384e38622ce7cc20a9c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67358e55b470861e1e14c63c30156dd4" category="list-text">그룹 이름을 추가하고 전송 및 배치에서 필수 필드(클러스터, 스토리지 및 대상 네트워크)를 업데이트한 후 유효성 검사를 클릭합니다.</block>
  <block id="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="paragraph"><block ref="1ce9ff194ee5bdbf4df7b739baf9b3d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a961199f9300128fcaa431e9245ac13" category="list-text">유효성 검사가 완료된 후 이동을 클릭하여 마이그레이션을 시작합니다.</block>
  <block id="f3d5cf5ffd51c9062748a6a292f749f7" category="inline-link">VMware HCX vMotion 및 콜드 마이그레이션 이해</block>
  <block id="136739244c82e4bdcdb6a1b1c3712d3b" category="admonition">vMotion 전송은 VM 활성 메모리, 실행 상태, IP 주소 및 MAC 주소를 캡처합니다. HCX vMotion의 요구 사항 및 제한 사항에 대한 자세한 내용은 을 참조하십시오<block ref="011541f11351d17074bdfa0823ec743b" category="inline-link-rx"></block>.</block>
  <block id="f2ca81fdc3e7326c354dc180a98c7ef2" category="list-text">HCX &gt; 마이그레이션 대시보드에서 vMotion의 진행 상황과 완료 상태를 모니터링할 수 있습니다.</block>
  <block id="b41362505f00e258d5e04636a0edaf7c" category="paragraph"><block ref="b41362505f00e258d5e04636a0edaf7c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1e4900648931ee918be9251a268e792c" category="example-title">VMware Replication Assisted vMotion을 참조하십시오</block>
  <block id="3bb995dd361711179fda278eb498a385" category="paragraph">VMware 문서에서 이미 알아보았듯이 VMware HCX RAV(Replication Assisted vMotion)는 대량 마이그레이션과 vMotion의 이점을 결합합니다. 대량 마이그레이션에서는 vSphere Replication을 사용하여 여러 VM을 병렬로 마이그레이션합니다. 전환 중에 VM이 재부팅됩니다. HCX vMotion은 다운타임 없이 마이그레이션되지만 복제 그룹에서 한 번에 한 VM에 대해 순차적으로 수행됩니다. RAV는 VM을 병렬로 복제하며 절체 윈도우가 될 때까지 동기화 상태를 유지합니다. 전환 프로세스 중에 VM의 다운타임 없이 한 번에 하나의 VM을 마이그레이션합니다.</block>
  <block id="93e2f4753a86232a37f8bd57209f626d" category="paragraph">다음 스크린샷은 마이그레이션 프로필을 Replication Assisted vMotion으로 보여 줍니다.</block>
  <block id="7c12abc7edfaeb45279b8ee126759269" category="paragraph"><block ref="7c12abc7edfaeb45279b8ee126759269" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a740a2796b321475f6bd003fafa67e5b" category="paragraph">복제 기간은 소수의 VM의 vMotion에 비해 더 길어질 수 있습니다. RAV에서는 델타만 동기화하고 메모리 내용을 포함시키십시오. 다음은 마이그레이션 상태의 스크린샷입니다. 이 스크린샷은 마이그레이션의 시작 시간이 동일하고 각 VM에 대한 종료 시간이 어떻게 다른지 보여 줍니다.</block>
  <block id="27e8bd561ebb9d9ee4d23860c10a3883" category="paragraph"><block ref="27e8bd561ebb9d9ee4d23860c10a3883" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e61c2a41cf1924a0a1e3d5217e16a084" category="paragraph">HCX 마이그레이션 옵션 및 HCX를 사용하여 워크로드를 온프레미스에서 VMware Cloud on AWS로 마이그레이션하는 방법에 대한 자세한 내용은 를 참조하십시오<block ref="15dbc17e63bae3f57dd4aa8612bacb9d" category="inline-link-rx"></block>.</block>
  <block id="f261622b527cc27756d5ba83c22662f8" category="admonition">VMware HCX vMotion에는 100Mbps 이상의 처리량 기능이 필요합니다.</block>
  <block id="60bd242580d7de82c0a2e6eee14d2f50" category="admonition">ONTAP 데이터 저장소용 타겟 VMC FSx에 마이그레이션을 수용할 수 있는 충분한 공간이 있어야 합니다.</block>
  <block id="17e30673228b69814c7132c287c12ecb" category="paragraph">사내 모든 유형/공급업체 스토리지에 상주하는 데이터를 클라우드 또는 하이브리드 클라우드에 배치하든, AWS ONTAP용 Amazon FSx와 HCX는 애플리케이션 계층에 대한 데이터 요구 사항을 원활하게 만들어 워크로드를 구축 및 마이그레이션하는 동시에 TCO를 절감하는 탁월한 옵션을 제공합니다. 어떤 사용 사례에서든 VMC와 FSx for ONTAP 데이터 저장소를 함께 사용하여 사내 및 멀티 클라우드 전체의 클라우드 이점, 일관된 인프라 및 운영을 빠르게 실현하고, 워크로드의 양방향 이동성을 실현하며, 엔터프라이즈급 용량과 성능을 실현할 수 있습니다. VMware vSphere 복제, VMware vMotion 또는 NFC 복사를 사용하여 스토리지를 연결하고 VM을 마이그레이션하는 데 사용되는 익숙한 프로세스와 절차가 동일합니다.</block>
  <block id="273435500e4b837aea488094a233f579" category="list-text">이제 Amazon FSx ONTAP를 VMC SDDC의 데이터 저장소로 사용할 수 있습니다.</block>
  <block id="cbbc4fc2bc12f5fd25f84b44f93fd5f3" category="list-text">모든 사내 데이터 센터에서 FSx for ONTAP 데이터 저장소를 사용하여 실행 중인 VMC로 데이터를 쉽게 마이그레이션할 수 있습니다</block>
  <block id="9004e09f6485129980daf3188affad35" category="list-text">마이그레이션 작업 중에 용량 및 성능 요구 사항을 충족하도록 FSx ONTAP 데이터 저장소를 쉽게 확장 및 축소할 수 있습니다.</block>
  <block id="34e948a9d10cb991d2da187e3e54caef" category="list-text">VMware 클라우드 설명서</block>
  <block id="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link"><block ref="56f2ce0be9d32c6c0e3c983d011be4d7" category="inline-link-rx"></block></block>
  <block id="1427dee608f6801474787ea58df57a2c" category="paragraph"><block ref="1427dee608f6801474787ea58df57a2c" category="inline-link-rx"></block></block>
  <block id="cc788b7e72b2a734dd0985bd1e0e9fe3" category="list-text">NetApp ONTAP용 Amazon FSx 문서</block>
  <block id="9c7174d13497f84bdd0b3e21af13794d" category="inline-link"><block ref="9c7174d13497f84bdd0b3e21af13794d" category="inline-link-rx"></block></block>
  <block id="05c89cf5b898c5c58986dac08f22a2a1" category="paragraph"><block ref="05c89cf5b898c5c58986dac08f22a2a1" category="inline-link-rx"></block></block>
  <block id="33efddb311b6c85bba97e5349040815f" category="sidebar">워크로드 마이그레이션 솔루션</block>
  <block id="e946411f5b47d53428345ae0e0e5f5fd" category="sidebar">워크로드를 마이그레이션 중입니다</block>
  <block id="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="list-text"><block ref="b0d7b47f43a6efe75ff49bfd5e21f6fd" category="inline-link-macro-rx"></block></block>
  <block id="90e97692c42b1eb0ec22c639049d78a1" category="list-text"><block ref="90e97692c42b1eb0ec22c639049d78a1" category="inline-link-macro-rx"></block></block>
  <block id="6ff1dafebf930a9c5fef12bf43046987" category="example-title">엔터프라이즈 애플리케이션 및 데이터베이스</block>
  <block id="98e44b407e40d6f57f90877a1960efae" category="list-text"><block ref="98e44b407e40d6f57f90877a1960efae" category="inline-link-macro-rx"></block></block>
  <block id="e2cd0f8dc5281c13263991c6973df405" category="list-text"><block ref="e2cd0f8dc5281c13263991c6973df405" category="inline-link-macro-rx"></block></block>
  <block id="bf49d74794280c8a3a207a97d6447db7" category="list-text"><block ref="bf49d74794280c8a3a207a97d6447db7" category="inline-link-macro-rx"></block></block>
  <block id="4efd965058c15f138d2c4d43454c3012" category="list-text"><block ref="4efd965058c15f138d2c4d43454c3012" category="inline-link-macro-rx"></block></block>
  <block id="5bfc3700f5feddf9397449627edbbdb9" category="example-title">컨테이너/Kubernetes</block>
  <block id="665b01682714e51e25b232a31a06b70e" category="inline-link-macro">NetApp 및 Google Anthos 비디오</block>
  <block id="810afd9a3a1d12fd9dd41977c9ed1781" category="list-text"><block ref="810afd9a3a1d12fd9dd41977c9ed1781" category="inline-link-macro-rx"></block></block>
  <block id="668ed010c67826eb36328daf61db1909" category="inline-link-macro">NetApp with VMware Tanzu 비디오</block>
  <block id="f05d310ffaf62c6645cbc528c52f46e1" category="list-text"><block ref="f05d310ffaf62c6645cbc528c52f46e1" category="inline-link-macro-rx"></block></block>
  <block id="19ec96fa965825479da361c5626b34f0" category="inline-link-macro">NetApp for DevOps 비디오</block>
  <block id="f1afd91555fd6fb162a6343cf91fdc05" category="list-text"><block ref="f1afd91555fd6fb162a6343cf91fdc05" category="inline-link-macro-rx"></block></block>
  <block id="70fc473134508f4cbdb235049ab72bc6" category="inline-link-macro">NetApp 및 Red Hat OpenShift 비디오</block>
  <block id="f86f2e66a68f28ad563c787ff0145ba4" category="list-text"><block ref="f86f2e66a68f28ad563c787ff0145ba4" category="inline-link-macro-rx"></block></block>
  <block id="c9fee86e220b694a9ca26cb5d3943276" category="summary">이 문서에서는 계층형 스토리지 벤치마킹 키트를 사용하여 NetApp ONTAP에 대해 Confluent 플랫폼의 성능 벤치마크를 설명합니다.</block>
  <block id="5514e652e396365ccb56f1b2b5371569" category="doc">TR-4941: NetApp ONTAP 스토리지 컨트롤러에 대해 잘 알고 있습니다</block>
  <block id="1e0e02def11263577d232ee8ce69c727" category="paragraph">Karthikeyan Nagalingam, Joe Scott, NetApp Rankesh Kumar, Confluent</block>
  <block id="f79dab50e0f9664c4b4d604319a8cbbe" category="paragraph">Confluent Platform의 확장성과 탄력성을 크게 확보하려면 IT에서 워크로드를 매우 빠르게 확장하고 균형을 맞출 수 있어야 합니다. 계층형 스토리지를 사용하면 운영 부담을 줄여 대량의 데이터를 유창한 관리 방식으로 저장할 수 있습니다. 기본 개념은 데이터 스토리지와 데이터 처리를 분리하여 각각을 독립적으로 쉽게 확장할 수 있도록 하는 것입니다.</block>
  <block id="44f523cee834fac14fc6966d940c5e92" category="paragraph">업계 최고의 혁신 기술을 갖춘 NetApp ONTAP 데이터 관리 소프트웨어는 데이터가 어디에 있든 다양한 이점을 유창하게 제공합니다.</block>
  <block id="ff221b4a7c17defefb1a32cf9136086d" category="inline-link-macro">다음: 해결책.</block>
  <block id="700a1e72f5247529520dfae6b0d991e3" category="paragraph"><block ref="700a1e72f5247529520dfae6b0d991e3" category="inline-link-macro-rx"></block></block>
  <block id="b7d338a537a3a1d0186080c4c4ba47eb" category="summary">이 페이지에서는 이 솔루션에 사용된 기술에 대해 설명합니다.</block>
  <block id="1ac2a5604ed02bc66c4d6241b534d13b" category="inline-link-macro">이전: 해결책.</block>
  <block id="9ec2e79862a05fa25e8c20aa973e0d4b" category="paragraph"><block ref="9ec2e79862a05fa25e8c20aa973e0d4b" category="inline-link-macro-rx"></block></block>
  <block id="7f1512274139985d5f21a72e13808522" category="section-title">NetApp ONTAP 스토리지 컨트롤러</block>
  <block id="b691cb82ce5ecb3d94f82b73ef3c2219" category="paragraph">NetApp ONTAP는 고성능 엔터프라이즈급 스토리지 운영 체제입니다.</block>
  <block id="f8b80927eb906c831742041c4c139be1" category="paragraph">NetApp ONTAP 9.8은 Amazon S3(Simple Storage Service) API를 지원합니다. ONTAP은 AWS(Amazon Web Services) S3 API 작업의 서브셋을 지원하며 클라우드 공급자(AWS, Azure 및 GCP) 및 온프레미스 전반에서 데이터를 ONTAP 기반 시스템에서 오브젝트로 나타낼 수 있습니다.</block>
  <block id="9496ba5a97ab04d734dc449f86646ffe" category="paragraph">NetApp StorageGRID 소프트웨어는 오브젝트 스토리지를 위한 NetApp의 대표적인 솔루션입니다. ONTAP은 오브젝트 데이터를 위해 NetApp에서 제공하는 Data Fabric을 확장하고 NetApp 제품 포트폴리오의 가치를 높여 에지에서 수집 및 사전 처리 지점을 제공함으로써 StorageGRID를 보완합니다.</block>
  <block id="d6e8f345bdd21d285f35171c2da8cd3a" category="paragraph">S3 버킷에 대한 액세스는 인증된 사용자 및 클라이언트 애플리케이션을 통해 제공됩니다. 다음 다이어그램에서는 S3 버킷에 액세스하는 애플리케이션을 보여 줍니다.</block>
  <block id="a38dfb3b286ff4854c6f5d67ebc15e13" category="inline-image-macro">이 그래픽은 S3 버킷에 액세스하는 애플리케이션을 보여 줍니다.</block>
  <block id="6090835a60a6e1de5e0c995ca8c5e5f8" category="paragraph"><block ref="6090835a60a6e1de5e0c995ca8c5e5f8" category="inline-image-macro-rx" type="image"></block></block>
  <block id="d5088428c842a8d5e45f2e6597af4138" category="section-title">주요 사용 사례</block>
  <block id="5c2f4a513e63ae351e5dc0b7412a43c2" category="paragraph">S3 API를 지원하는 주된 목적은 ONTAP에서 오브젝트 액세스를 제공하는 것입니다. ONTAP 유니파이드 스토리지 아키텍처는 이제 파일(NFS 및 SMB), 블록(FC 및 iSCSI), 오브젝트(S3)를 지원합니다.</block>
  <block id="1af2e65957e458000d1181bb9eba2517" category="section-title">네이티브 S3 애플리케이션</block>
  <block id="c0889d6b193afe7d0069e3d99bc5f310" category="paragraph">점점 더 많은 애플리케이션에서 S3를 사용하여 오브젝트 액세스에 ONTAP 지원을 활용할 수 있습니다. 고용량 아카이브 워크로드에 적합하지만 네이티브 S3 애플리케이션에서 고성능을 필요로 하는 것은 다음과 같습니다.</block>
  <block id="a768caa988605a2846599cf7e2d0c26a" category="list-text">분석</block>
  <block id="9d0996a44c6d51cf223e833dceecb286" category="list-text">인공 지능</block>
  <block id="1669cbc398e4228e7e05d6b2e030cbe7" category="list-text">엣지-코어 수집</block>
  <block id="bd1a4166acf45c62946d7592a64ad52d" category="paragraph">고객은 이제 ONTAP System Manager와 같은 익숙한 관리 효율 툴을 사용하여 ONTAP의 개발 및 운영에 필요한 고성능 오브젝트 스토리지를 신속하게 프로비저닝할 수 있습니다. 또한 ONTAP 스토리지 효율성 및 보안을 활용할 수 있습니다.</block>
  <block id="50472ac5cace1b7798b3f92db5c3049e" category="section-title">FabricPool 엔드포인트</block>
  <block id="5050f2389b47df5462550d8e11451e9d" category="paragraph">ONTAP 9.8부터 FabricPool는 ONTAP의 버킷 계층화를 지원하므로 ONTAP에서 ONTAP로 계층화할 수 있습니다. 이 옵션은 기존 FAS 인프라를 오브젝트 저장소 엔드포인트로 용도 변경하고자 하는 고객에게 적합합니다.</block>
  <block id="10beb552e5ed01d5c890a260a1d6af16" category="paragraph">FabricPool는 다음 두 가지 방법으로 ONTAP에 대한 계층화를 지원합니다.</block>
  <block id="1e53159984d41f5ea848cdf412430a06" category="list-text">* 로컬 클러스터 계층화. * 비활성 데이터는 클러스터 LIF를 사용하여 로컬 클러스터에 있는 버킷으로 계층화합니다.</block>
  <block id="08be0ca0511f2294cbbaf9d92327996b" category="list-text">* 원격 클러스터 계층화. * 비활성 데이터는 FabricPool 클라이언트의 IC LIF와 ONTAP 오브젝트 저장소의 데이터 LIF를 사용하여 기존 FabricPool 클라우드 계층과 비슷한 방식으로 원격 클러스터에 있는 버킷으로 계층화합니다.</block>
  <block id="bda29d8d2c5de29e5ec15858a0f72c79" category="paragraph">ONTAP S3는 추가 하드웨어 및 관리 없이 기존 클러스터에서 S3 기능을 원하는 경우에 적합합니다. 300TB 이상의 배포를 위해 NetApp StorageGRID 소프트웨어는 계속해서 오브젝트 스토리지를 위한 주력 NetApp 솔루션으로 부상하고 있습니다. ONTAP 또는 StorageGRID를 클라우드 계층으로 사용할 때는 FabricPool 라이센스가 필요하지 않습니다.</block>
  <block id="5a7adb78ef640711a870d82123f00775" category="section-title">Confluent 계층형 스토리지를 위한 NetApp ONTAP</block>
  <block id="9a5bc88300f877a695de175398887e0e" category="paragraph">모든 데이터 센터는 비즈니스 크리티컬 애플리케이션을 계속 실행하고 중요한 데이터를 안전하게 사용할 수 있어야 합니다. 새로운 NetApp AFF A900 시스템은 ONTAP 엔터프라이즈 에디션 소프트웨어와 복원력이 뛰어난 설계를 기반으로 합니다. NetApp의 새로운 초고속 NVMe 스토리지 시스템은 미션 크리티컬 운영의 중단을 제거하고, 성능 조정을 최소화하고, 랜섬웨어 공격으로부터 데이터를 보호합니다.</block>
  <block id="42dfa85904e1fd1b7fb41d4278c38047" category="paragraph">초기 구축부터 Confluent 클러스터의 확장까지, 귀사의 환경에서는 비즈니스 크리티컬 애플리케이션의 중단 없는 변화에 빠르게 적응해야 합니다. ONTAP 엔터프라이즈 데이터 관리, 서비스 품질(QoS) 및 성능 을 통해 고객 환경을 계획 및 조정할 수 있습니다.</block>
  <block id="36509bd95b243830a012c72c8a2d5844" category="paragraph">NetApp ONTAP와 Confluent Tiered Storage를 함께 사용하면 ONTAP를 스케일아웃 스토리지 대상으로 활용하여 Apache Kafka 클러스터의 관리를 단순화하고 컴퓨팅 및 스토리지 리소스를 Confluent로 독립적으로 확장할 수 있습니다.</block>
  <block id="e09818a7d7d98185cdb0309cf3aca8f5" category="paragraph">ONTAP S3 서버는 ONTAP의 성숙한 스케일아웃 스토리지 기능을 기반으로 구축되었습니다. ONTAP 클러스터는 S3 버킷을 확장하여 ONTAP 클러스터에 새로 추가된 노드를 사용함으로써 원활하게 확장할 수 있습니다.</block>
  <block id="1ccfe00aee80492f09968d6b208801d5" category="section-title">ONTAP 시스템 관리자를 사용하여 간단하게 관리할 수 있습니다</block>
  <block id="4fdad8328864e9de2db5338bb25291fc" category="paragraph">ONTAP System Manager는 브라우저 기반의 그래픽 인터페이스로, 단일 창에서 전 세계에 분산된 위치에서 ONTAP 스토리지 컨트롤러를 구성, 관리, 모니터링할 수 있습니다.</block>
  <block id="c99eb67a4e6cbe9ba119a72c95161fab" category="inline-image-macro">이 그림은 ONTAP System Manager 작업 공간을 보여줍니다.</block>
  <block id="45e8e67e3e5407c5dc518dd00eb8249b" category="paragraph"><block ref="45e8e67e3e5407c5dc518dd00eb8249b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="783157c9c38b4e88d7eefffe21cd97d3" category="paragraph">System Manager 및 ONTAP CLI를 사용하여 ONTAP S3를 구성 및 관리할 수 있습니다. System Manager를 사용하여 S3를 활성화하고 버킷을 생성할 때 ONTAP은 단순한 구성에 대한 모범 사례 기본값을 제공합니다. CLI에서 S3 서버 및 버킷을 구성할 경우에도 원하는 경우 System Manager로 관리하거나 그 반대로 구성할 수 있습니다.</block>
  <block id="d1623a9fec2de2642847391236e62e9b" category="paragraph">System Manager를 사용하여 S3 버킷을 생성하는 경우, ONTAP은 시스템에서 가장 가용성이 높은 기본 성능 서비스 수준을 구성합니다. 예를 들어 AFF 시스템에서 기본 설정은 Extreme입니다. 성능 서비스 수준은 사전 정의된 적응형 QoS 정책 그룹입니다. 기본 서비스 수준 대신 사용자 지정 QoS 정책 그룹 또는 정책 그룹을 지정할 수 있습니다.</block>
  <block id="bbcb9e2700fba39c3b7b7fd438155100" category="paragraph">사전 정의된 적응형 QoS 정책 그룹은 다음과 같습니다.</block>
  <block id="f1ec0b0c482a42bad395f01e7f2b6c1d" category="list-text">* Extreme. * 가장 짧은 지연 시간과 최고의 성능이 필요한 애플리케이션에 사용됩니다.</block>
  <block id="06e90efc82fff7e3090ba9ff1a3bd2a3" category="list-text">성능. * 적절한 성능 요구사항과 지연 시간이 필요한 애플리케이션에 사용됩니다.</block>
  <block id="7aa0f5702784b1be0a3c5ed9e6f3df8e" category="list-text">* 값. * 처리량과 용량이 지연 시간보다 더 중요한 애플리케이션에 사용됩니다.</block>
  <block id="113d20f8cc4d864cdfea1b0f611cbb0a" category="list-text">* 사용자 정의. * 사용자 정의 QoS 정책을 지정하거나 QoS 정책을 지정하지 않습니다.</block>
  <block id="42cc32e2c7857ba980019c70438e92ed" category="paragraph">계층화에 * 사용을 선택하면 성능 서비스 수준이 선택되지 않으며 시스템은 계층형 데이터에 대해 최적의 성능을 갖춘 저비용 미디어를 선택합니다.</block>
  <block id="5cc287af927b81043d030fc6a1ece879" category="paragraph">ONTAP는 가장 적합한 디스크가 있는 로컬 계층에서 이 버킷을 프로비저닝하려고 시도하여 선택한 서비스 수준을 충족시킵니다. 그러나 버킷에 포함할 디스크를 지정해야 하는 경우 로컬 계층(애그리게이트)을 지정하여 CLI에서 S3 오브젝트 스토리지를 구성하는 것이 좋습니다. CLI에서 S3 서버를 구성할 경우에도 원할 경우 System Manager로 관리할 수 있습니다.</block>
  <block id="74869eb3dfe4756dab5491da2a3de2ad" category="paragraph">버킷에 사용할 애그리게이트를 지정할 수 있는 기능은 CLI를 통해서만 지정할 수 있습니다.</block>
  <block id="0c0e3a803cf68a8772ebf58a68b20124" category="paragraph">Confluent Platform은 지속적인 실시간 스트림으로 데이터에 쉽게 액세스, 저장 및 관리할 수 있는 포괄적인 데이터 스트리밍 플랫폼입니다. Apache Kafka를 처음 개발한 Confluent는 Kafka 관리 또는 모니터링의 부담을 덜면서 엔터프라이즈급 기능을 통해 Kafka의 이점을 확장해 줍니다. 현재 Fortune 100대 기업 중 80% 이상이 데이터 스트리밍 기술을 사용하고 있으며 대부분 Confluent를 사용하고 있습니다.</block>
  <block id="d3c11d67f567698de4c90210b84c554d" category="paragraph">Confluent Platform을 사용하면 데이터가 다른 시스템 간에 어떻게 전송 또는 통합되는지 등의 기본 메커니즘을 걱정하지 않고 데이터에서 비즈니스 가치를 창출하는 방법에 집중할 수 있습니다. 특히 Confluent Platform은 데이터 소스를 Kafka에 연결하고 스트리밍 애플리케이션을 구축하며 Kafka 인프라의 보안, 모니터링 및 관리를 간소화합니다. 현재 Confluent Platform은 금융 서비스, 옴니채널 소매, 자율 자동차, 사기 탐지, 마이크로서비스, IoT 등 다양한 산업 전반의 다양한 사용 사례에 사용됩니다.</block>
  <block id="870b2318ccfd123ac0f7e9ef1396d49d" category="paragraph">다음 그림에서는 Confluent 플랫폼의 구성 요소를 보여 줍니다.</block>
  <block id="9d880468cb22c04bd894fc612814dbab" category="inline-image-macro">이 그래픽은 Confluent 플랫폼의 구성 요소를 보여 줍니다.</block>
  <block id="f64c3e5205853c0df35b5f05dcb208a1" category="paragraph"><block ref="f64c3e5205853c0df35b5f05dcb208a1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="05fafb4336e843d4634bd9ac122177c8" category="section-title">Confluent 이벤트 스트리밍 기술 개요</block>
  <block id="51be25b0145a0beca811de24a62b5cb4" category="inline-link">카프카</block>
  <block id="0139d991fe55319f2e19e039da969fcf" category="paragraph">Confluent Platform의 핵심은 입니다<block ref="66a1a9ec54e6ef0a1c109ad94b972ac9" category="inline-link-rx"></block>가장 인기 있는 오픈 소스 분산 스트리밍 플랫폼입니다. Kafka의 주요 기능은 다음과 같습니다.</block>
  <block id="82ff0b3d0476bb8ca2283ff06c017658" category="section-title">Confluent 플랫폼 엔터프라이즈 기능 개요</block>
  <block id="ed2c640e88db15d474de830703c8783b" category="list-text">* Confluent Control Center. * Kafka 관리 및 모니터링을 위한 UI 기반 시스템. Kafka Connect를 쉽게 관리하고 다른 시스템에 대한 연결을 생성, 편집 및 관리할 수 있습니다.</block>
  <block id="d63f46631d40c1c76b1a1a46445584aa" category="list-text">* Kafka 연결 커넥터 * 커넥터는 Kafka Connect API를 사용하여 Kafka를 데이터베이스, 키 값 저장소, 검색 인덱스 및 파일 시스템 등의 다른 시스템에 연결합니다. Confluorent Hub에는 가장 널리 사용되는 데이터 소스 및 싱크에 대한 다운로드 가능한 커넥터가 있습니다. 여기에는 Confluorent Platform이 포함된 이러한 커넥터의 전체 테스트 및 지원 버전이 포함됩니다. 자세한 내용은 을 참조하십시오<block ref="2f0cdf69523bef6b3b17324f38f83353" category="inline-link-rx"></block>.</block>
  <block id="9103a2961d6b4c593517d3d641763e5c" category="list-text">* 자체 밸런싱 클러스터 * 는 자동화된 로드 밸런싱, 장애 감지 및 자동 복구를 제공합니다. 또한 수동 조정 없이 필요에 따라 브로커를 추가하거나 해체할 수 있도록 지원합니다.</block>
  <block id="c1712fa040f6accce664a82ba6d58b94" category="list-text">* Confluorent auto data balancer. * 브로커 수, 파티션 크기, 파티션 수 및 클러스터 내의 리더 수에 대한 클러스터를 모니터링합니다. 균형 조정을 통해 트래픽을 재조정함으로써 운영 워크로드에 미치는 영향을 최소화하면서 클러스터 전체에서 짝수 워크로드를 생성할 수 있습니다.</block>
  <block id="0265b0b07689b6439fc600eec3164763" category="inline-link-macro">다음: Confluent Performance validation.</block>
  <block id="7d58203770f3360011c58049bd5dc048" category="paragraph"><block ref="7d58203770f3360011c58049bd5dc048" category="inline-link-macro-rx"></block></block>
  <block id="dbb940c31f0b7d7563745993661f70d4" category="summary">AFF A900 HA 쌍 NetApp 스토리지 컨트롤러 1개를 사용하여 농작물 사용 워크로드 중 5개 또는 8개의 브로커 노드로 계층형 스토리지 테스트를 수행했습니다. 테스트에 따르면 AFF A900 리소스 활용률이 100%에 이를 때까지 브로커 노드의 수에 따라 완료 시간과 성능 결과가 확장되었습니다. ONTAP 스토리지 컨트롤러를 설치하려면 최소 하나의 HA 쌍이 필요했습니다.</block>
  <block id="91e1cb9730965860cb465802520e6a45" category="doc">농작물 사용 워크로드 생성기를 사용한 성능 테스트</block>
  <block id="3daa014912cbb3dddcdeae426aea8652" category="inline-link-macro">이전: Confluent Performance validation.</block>
  <block id="262b5107278b398d0de9b7ef6b52e5d0" category="paragraph"><block ref="262b5107278b398d0de9b7ef6b52e5d0" category="inline-link-macro-rx"></block></block>
  <block id="b15c40872cdd0b1e0a152907f2194e69" category="paragraph">S3 검색 작업에 대한 성능은 Confluent 브로커 노드의 수에 따라 선형으로 향상되었습니다. ONTAP 스토리지 컨트롤러는 단일 배포에서 최대 12개의 HA 쌍을 지원합니다.</block>
  <block id="ec043d5e2714e1035038cbeb1aa3cba8" category="paragraph">다음 그래프에는 브로커 노드 5개 또는 8개가 결합된 S3 계층화 트래픽이 나와 있습니다. AFF A900 단일 HA Pair 성능을 극대화했습니다.</block>
  <block id="ffff2891cfdd07445c4e1e5261739c68" category="inline-image-macro">이 데이터 그래프는 5개 또는 8개의 브로커 노드와 결합된 S3 계층화 트래픽을 보여 줍니다.</block>
  <block id="388c51cbcac77b72c2e68dc334f9cf73" category="paragraph"><block ref="388c51cbcac77b72c2e68dc334f9cf73" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1efe906cedfd00618bda4d39b41a52fd" category="paragraph">다음 그래프는 약 31.74GBps의 Kafka 처리량을 보여 줍니다.</block>
  <block id="e7aff80741661a5eb60f57649077f9c5" category="inline-image-macro">이 데이터 그래프는 약 31.74GBps의 Kafka 처리량을 보여 줍니다.</block>
  <block id="1dc39288e0903ff9947d26bba4d46cef" category="paragraph"><block ref="1dc39288e0903ff9947d26bba4d46cef" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bc6821411dfc3b7f483da21b37082dfc" category="paragraph">또한 ONTAP 스토리지 컨트롤러 'perfstat' 보고서에서 유사한 처리량도 관찰되었습니다.</block>
  <block id="12521f8f565efeb65b076c8966841804" category="inline-link-macro">다음은 성능 모범 사례 지침입니다.</block>
  <block id="4d8306a1e68c76874ac5d8c93a819977" category="paragraph"><block ref="4d8306a1e68c76874ac5d8c93a819977" category="inline-link-macro-rx"></block></block>
  <block id="4ea8220421596c898f8150bfebdf4ccb" category="summary">이 검증 테스트는 NetApp ONTAP 스토리지 컨트롤러를 사용하는 Confluent에서 31.74GBps의 계층화 처리량에 도달했습니다.</block>
  <block id="f86bb9f7d3cb6d2f8473494c8bd135ec" category="inline-link-macro">이전: 성능 모범 사례 지침.</block>
  <block id="65b905a56baa366aa274945ca5b7cad4" category="paragraph"><block ref="65b905a56baa366aa274945ca5b7cad4" category="inline-link-macro-rx"></block></block>
  <block id="93a10982e8e304323ad8af9a9387d775" category="paragraph">이 검증 테스트는 NetApp ONTAP 스토리지 컨트롤러에 유창한 confluent에서 31.74GBps의 계층화 처리량에 도달했습니다.</block>
  <block id="0f2f674cce6910ae97ee7ecc7bd9de18" category="list-text">Confluent란 무엇입니까?</block>
  <block id="e6deab0ab2821160c056af4c7766624c" category="inline-link"><block ref="e6deab0ab2821160c056af4c7766624c" category="inline-link-rx"></block></block>
  <block id="ce3026317a00b57c81627bd64a1b3311" category="paragraph"><block ref="ce3026317a00b57c81627bd64a1b3311" category="inline-link-rx"></block></block>
  <block id="58a229be829dc9196abdaff6a4a26864" category="list-text">S3 in ONTAP 모범 사례</block>
  <block id="f47b79954bb4ad3165d7f99db02fe933" category="inline-link"><block ref="f47b79954bb4ad3165d7f99db02fe933" category="inline-link-rx"></block></block>
  <block id="e98b34b649783312d3b317c7441a20a5" category="paragraph"><block ref="e98b34b649783312d3b317c7441a20a5" category="inline-link-rx"></block></block>
  <block id="3075344c29b864c90ae1411c1db26e87" category="list-text">S3 오브젝트 스토리지 관리</block>
  <block id="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link"><block ref="cdc54c0262b6c0a6146ee416a9ca2113" category="inline-link-rx"></block></block>
  <block id="8a93310a8dd4b405a8711f82adeb3c23" category="paragraph"><block ref="8a93310a8dd4b405a8711f82adeb3c23" category="inline-link-rx"></block></block>
  <block id="1b70ac0a972fddf1e1a33e6ed9df49c7" category="cell">2022년 9월</block>
  <block id="331c0d2ba7a09b3ae7f6fac4652625da" category="summary">이 페이지에서는 이 솔루션의 성능을 개선하기 위한 모범 사례를 설명합니다.</block>
  <block id="69cefd131c612b28f058caddd20f5cac" category="doc">성능 모범 사례 지침</block>
  <block id="25075404ed18180817b5ff523b98b3ea" category="inline-link-macro">이전: 생산물을 사용한 성능 테스트 - 워크로드 생성기 사용</block>
  <block id="78f6cc0a5eeea34ea4a6b6d750751008" category="paragraph"><block ref="78f6cc0a5eeea34ea4a6b6d750751008" category="inline-link-macro-rx"></block></block>
  <block id="21414169b395738292b2ac2fd8ca50a9" category="list-text">ONTAP의 경우 가능하면 GET SIZE &gt;= 1MB 를 사용합니다.</block>
  <block id="ce2e9b8aaceb2d2993c90188d874af95" category="list-text">브로커 노드의 erver.properties` 에서 num.network.threads` 및 num.io.threads를 증가시키면 계층화 작업이 S3 계층으로 증가하게 됩니다. 이러한 결과는 num.network.threads` 및 num.io.threads가 32로 설정된 것입니다.</block>
  <block id="1a48e01d01924d18e32943982eb6d924" category="list-text">S3 버킷은 구성원 애그리게이트당 8개의 구성요소를 목표로 해야 합니다.</block>
  <block id="b5a9dc3c7ec54467d103e00eaa0efb21" category="list-text">S3 트래픽을 구동하는 이더넷 링크는 스토리지와 클라이언트 모두에서 가능하면 MTU 9k 를 사용해야 합니다.</block>
  <block id="9a2dcec18734a6b09898eef44edd5f9a" category="paragraph"><block ref="9a2dcec18734a6b09898eef44edd5f9a" category="inline-link-macro-rx"></block></block>
  <block id="614eb548d72efbb3690b5c131745db1b" category="summary">이 페이지에서는 이 솔루션의 매개 변수 내에서 Confluent의 성능 검증을 설명합니다.</block>
  <block id="28052d386826afbb88768d0629570b19" category="doc">Confluent 성능 검증</block>
  <block id="e0c5d30e7d8ab807973bb9e8800f9f30" category="paragraph"><block ref="e0c5d30e7d8ab807973bb9e8800f9f30" category="inline-link-macro-rx"></block></block>
  <block id="3ec7b1ca1aaf25c9bbca707f1ca8e466" category="paragraph">NetApp ONTAP의 계층형 스토리지를 위한 Confluent Platform을 사용하여 검증을 수행했습니다. NetApp과 Confluent 팀은 이 검증을 함께 수행하여 IT에 필요한 테스트 사례를 실행했습니다.</block>
  <block id="1f567e45477749710cbc14cf6b10afc4" category="section-title">Confluent 설정</block>
  <block id="99b45ae42dbbf816c910ba27197525dc" category="paragraph">설치를 위해 256GB RAM과 16개의 CPU를 갖춘 3대의 zookeepers, 5개의 브로커, 5대의 테스트 서버를 사용했습니다. NetApp 스토리지의 경우 ONTAP와 AFF A900 HA 쌍을 사용했습니다. 스토리지와 브로커는 100GbE 연결을 통해 연결되었습니다.</block>
  <block id="77727c2ca2ac5beb0de2853929b43367" category="paragraph">다음 그림에서는 계층형 스토리지 검증에 사용된 구성의 네트워크 토폴로지를 보여 줍니다.</block>
  <block id="57e8d3257fec5774d2e8d38588771a69" category="inline-image-macro">이 그래픽은 계층형 스토리지 검증에 사용된 구성의 네트워크 토폴로지를 보여 줍니다.</block>
  <block id="e1265b0a6795e57b3d1df5094ecde2bb" category="paragraph"><block ref="e1265b0a6795e57b3d1df5094ecde2bb" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1d9b75f4efe285b9777255f14c81323b" category="paragraph">도구 서버는 Confluent 노드로 이벤트를 보내거나 받는 응용 프로그램 클라이언트로 작동합니다.</block>
  <block id="1068af448bd05a968329fd2341036bfb" category="paragraph">다음과 같은 테스트 매개 변수를 사용했습니다.</block>
  <block id="3bfb3f2755d25ed45d39dad8b3ed3008" category="paragraph">검증을 위해 HTTP 프로토콜과 함께 ONTAP를 사용했지만 HTTPS도 작동했습니다. 액세스 키와 비밀 키는 confluent.tier.s3.cred.file.path 매개 변수에 제공된 파일 이름에 저장됩니다.</block>
  <block id="86d7ae5e1e87e4958b4fafcbca603956" category="section-title">NetApp 스토리지 컨트롤러 – ONTAP</block>
  <block id="b915ce35d395a0d68a794b87705f95fa" category="paragraph">검증을 위해 ONTAP에서 단일 HA 쌍 구성을 구성했습니다.</block>
  <block id="b9d2b35b3cfffa153fd4ed3401cb9dd9" category="inline-image-macro">이 그래픽은 환경이 검증을 위한 단일 HA 쌍으로 구성된 방식을 보여 줍니다.</block>
  <block id="0ccd17060e15591b9c8588dc7d974ecd" category="paragraph"><block ref="0ccd17060e15591b9c8588dc7d974ecd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7069b530e46a91698a16159b7d083019" category="section-title">확인 결과</block>
  <block id="3af1efc909fae49a716fe2d22ba24290" category="paragraph">검증을 위해 다음 5가지 테스트 사례를 완료했습니다. 첫 번째 두 테스트는 기능 테스트이고 나머지 세 가지는 성능 테스트입니다.</block>
  <block id="09da8339466c8b6111e4f310f1b78cb5" category="paragraph">이 테스트는 API 호출을 사용하여 계층형 스토리지에 사용되는 객체 저장소에서 GET, PUT 및 DELETE 등의 기본 작업을 수행합니다.</block>
  <block id="622ce818e2b8228cee071a827a43e1b2" category="paragraph">이 테스트에서는 오브젝트 스토리지의 엔드 투 엔드 기능을 검사합니다. 토픽을 생성하고, 새로 생성된 토픽에 대한 이벤트 스트림을 생성하고, 브로커가 세그먼트를 오브젝트 스토리지에 아카이브하고, 이벤트 스트림을 소비하며, 소비된 스트림이 생성된 스트림과 일치하는지 확인합니다. 객체 저장소 결함 주입 여부와 관계없이 이 테스트를 수행했습니다. ONTAP의 노드 중 하나에서 서비스 관리자 서비스를 중지하고 엔드 투 엔드 기능이 오브젝트 스토리지에서 작동하는지 확인하여 노드 장애를 시뮬레이션했습니다.</block>
  <block id="2712a580ff4c3586c7ba3534b78aad18" category="section-title">생산 - 워크로드 생성기 사용</block>
  <block id="0c22172129c2d0d58a5685fa1094fca0" category="paragraph">이 테스트에서는 세그먼트 아카이브를 통해 오브젝트 저장소에서 쓰기 워크로드를 간접적으로 생성합니다. 소비자 그룹이 세그먼트를 가져올 때 객체 스토리지에서 읽기 워크로드(세그먼트 읽기)가 생성되었습니다. 이 워크로드는 TOCC 스크립트에 의해 생성되었습니다. 이 테스트에서는 오브젝트 저장소에서 병렬 스레드의 읽기 및 쓰기 성능을 확인했습니다. 계층화 기능 정확도 테스트에서 보았듯이, 객체 저장소 결함 주입을 사용하여 테스트했으며 포함하지 않았습니다.</block>
  <block id="2a7273e52c0214e6f0b27bf1e870960e" category="section-title">보존 워크로드 생성기</block>
  <block id="48771387cb6a84889bc1db951598f78c" category="paragraph">이 테스트에서는 무거운 주제 보존 워크로드에서 오브젝트 스토리지의 삭제 성능을 검사했습니다. 보존 워크로드는 테스트 주제와 동시에 많은 메시지를 생성하는 TOCC 스크립트를 사용하여 생성되었습니다. 테스트 주제는 공격적인 크기 기반 및 시간 기반 보존 설정으로 구성되었으며, 이로 인해 이벤트 스트림이 개체 저장소에서 지속적으로 제거됩니다. 그런 다음 세그먼트가 아카이브되었습니다. 이로 인해 오브젝트 저장소 삭제 작업의 브로커링 및 컬렉션에 의해 오브젝트 스토리지가 많이 삭제되었습니다.</block>
  <block id="047fb529cf71ef63efe04d4185302684" category="paragraph">검증 세부 정보는 를 참조하십시오<block ref="86830f666762f920df1dddf1c71e6509" category="inline-link-rx"></block> 웹 사이트.</block>
  <block id="0e20876ceb73ae36999db9f6c412bdc5" category="inline-link-macro">다음: 생산 방식의 성능 테스트 - 워크로드 생성기 소비</block>
  <block id="ab82cfabb720bf1d31365b6ce33825f9" category="paragraph"><block ref="ab82cfabb720bf1d31365b6ce33825f9" category="inline-link-macro-rx"></block></block>
  <block id="b0c400a1c1ac5de2cbdc877645b349a0" category="summary">이 섹션에서는 계층형 스토리지를 위한 NetApp ONTAP를 사용하여 Confluent Platform 배포에서 성능을 검증하는 데 사용되는 하드웨어 및 소프트웨어에 대해 설명합니다. 다음 표에서는 솔루션 아키텍처와 기본 구성 요소에 대해 설명합니다.</block>
  <block id="5197b1c9433e86b5ed33786625f77786" category="paragraph">ONTAP 기반 Confluent 및 NetApp AFF A900 스토리지 컨트롤러는 데이터 스트림을 위해 설계된 분산 시스템입니다. 두 가지 모두 수평적으로 확장 가능하고 내결함성이 있으며 부하 상태에서 뛰어난 성능을 제공합니다. 데이터 공간을 최소화하는 데이터 축소 기술로 분산된 데이터 스트리밍 및 스트림 처리에서 서로 보완하여 스토리지 비용을 절감합니다. AFF A900 스토리지 컨트롤러는 뛰어난 성능을 제공하는 동시에 컴퓨팅과 데이터 스토리지 리소스를 분리할 수 있도록 합니다. 따라서 시스템 관리가 단순화되고 리소스를 독립적으로 확장할 수 있습니다.</block>
  <block id="8ebef54f33ae0fdc7c4dcb83539b6eac" category="inline-image-macro">솔루션 개요를 보여 주는 이미지입니다.</block>
  <block id="52dff9f6353660d69eddc1e9fdee4a83" category="paragraph"><block ref="52dff9f6353660d69eddc1e9fdee4a83" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7a785978a6b38bb45ae8786c30a1781e" category="cell">플랫폼 구성 요소</block>
  <block id="c704d8c873b1a8d5d0243075656aa1f5" category="cell">환경 구성</block>
  <block id="f75094292f4afb812bc29237348d9948" category="cell">Confluent 플랫폼 버전 6.2</block>
  <block id="5cc4fd015c7740c575d319eefacbce83" category="list-text">주키프 3개</block>
  <block id="8f6a506566bd03a47cafb69561bafe0f" category="list-text">브로커 서버 8대</block>
  <block id="aa76981d988c82fc8b387682968887e6" category="list-text">도구 서버 5대</block>
  <block id="b56d58a9a181bae1fa65f36407ea002c" category="list-text">Grafana 1개</block>
  <block id="4af3adf9207f6f8d2d6d9edda08f0638" category="list-text">제어 센터 1개</block>
  <block id="29c331c65dbb1c85faa29881b295fbfc" category="cell">모든 노드의 운영 체제</block>
  <block id="de4d788671df5cf79fda01236d8fc9a6" category="cell">웜 버킷용 NetApp ONTAP</block>
  <block id="37e0c77638b1388d83b997c8dffdb6d3" category="list-text">AFF A900 고가용성(HA) 쌍 1개</block>
  <block id="2e1c9b5ce764f890af0aebf38f1a500a" category="list-text">100GbE</block>
  <block id="983e16c42b860c2511053f17d60918c8" category="list-text">CPU 2개, 총 물리적 코어 16개</block>
  <block id="ce4750dd79017960eed95bd3b2677eb4" category="list-text">인텔 제온</block>
  <block id="01dcc4e221fc9ff7472c5102b082eaf4" category="list-text">256GB 물리적 메모리</block>
  <block id="433304c312dd41f05955324749c0a47f" category="list-text">100GbE 이중 포트</block>
  <block id="39bc57d27d632df4261bc60caf39a90c" category="paragraph"><block ref="39bc57d27d632df4261bc60caf39a90c" category="inline-link-macro-rx"></block></block>
  <block id="b98ea9630b58bea0f022799ecefe4062" category="sidebar">NetApp ONTAP 스토리지 컨트롤러를 사용하는 Confluent Kafka</block>
  <block id="875353af43abce06e81496931b9482ef" category="paragraph"><block ref="875353af43abce06e81496931b9482ef" category="inline-link-macro-rx"></block></block>
  <block id="93d153de96abb104b1cf0b56dddc7dfc" category="sidebar">VMware HCX를 사용하여 ANF 데이터 저장소로 워크로드를 마이그레이션합니다</block>
  <block id="9e925e9341b490bfd3b4c4ca3b0c1ef2" category="inline-link">여기</block>
  <block id="953fa9bc59561d97ed62ce854465ba35" category="paragraph">vSphere 5.5 이상에서는 "vmkfstools –y" 명령이 사용 가능한 블록 수를 지정하는 esxcli storage vmfs unmap" 명령으로 대체됩니다(VMware KB 참조)<block ref="1d61bd4e8925f7d5aac61e083b728439" category="inline-link-rx"></block> 참조). vSphere 6.5 이상에서는 VMFS 6을 사용할 때 공간이 자동으로 비동기적으로 재확보되어야 합니다(참조)<block ref="a9ae15a1c91a14939aefb313015202e6" category="inline-link-rx"></block> vSphere 설명서 참조), 필요한 경우 수동으로 실행할 수도 있습니다. 이 자동 UNMAP은 ONTAP에서 지원되며, VMware vSphere용 ONTAP 툴을 사용하면 우선 순위가 낮습니다. VMFS 데이터 저장소로 사용할 LUN을 프로비저닝할 때 LUN에서 공간 할당 옵션을 수동으로 설정해야 합니다. VMware vSphere용 ONTAP 툴을 사용하는 경우 LUN은 공간 반환을 지원하도록 자동으로 구성되며 추가 작업이 필요하지 않습니다. 을 참조하십시오<block ref="fca823934ad533ca13947daa01d8e441" category="inline-link-rx"></block> 자세한 내용은 기술 자료 문서를 참조하십시오.</block>
  <block id="b95b607ac94c4a8cb830243ecb537f59" category="cell">LDAP에서 사용하는 세션 보안 수준(서명, 봉인 또는 없음)을 정의합니다. LDAP 서명은 Active Directory에서 요청하는 경우 CVS - 성능에서 지원됩니다. CVS-SW는 LDAP 서명을 지원하지 않습니다. 두 서비스 유형 모두에서 봉인은 현재 지원되지 않습니다.</block>
  <block id="ce32836b59e052d959dee4d2358e5a21" category="paragraph">테스트 목적으로, 이 검증에 사용된 온프레미스 랩 환경은 Azure VMware 솔루션에 대한 온프레미스 연결을 허용하는 사이트 간 VPN을 통해 연결되었습니다.</block>
  <block id="0bcfdba2f090838df9da44d825fedc49" category="doc">TR 4942: VMware HCX를 사용하여 워크로드를 FSx ONTAP 데이터 저장소로 마이그레이션합니다</block>
  <block id="dd5244d49dea74bb9effd68426155ca2" category="sidebar">VMware HCX를 사용하여 워크로드를 ONTAP 데이터 저장소용 FSx로 마이그레이션</block>
  <block id="cdf4d8a8fa9326debf96606ee7177f41" category="doc">AsciiiDoc 코딩 및 출력 샘플</block>
  <block id="6c1cc46d8764b2147f50c80e336ab770" category="paragraph">이 문서에는 asciidoc 소스 및 결과 출력의 몇 가지 예가 포함되어 있습니다.</block>
  <block id="c252a357a127635943f82514442e62b3" category="section-title">제목 수준</block>
  <block id="8000c50cdc8b68dd9ea0d326040cbd63" category="paragraph">[파란색 밑줄] * 소스 AsciiiiDoc: *</block>
  <block id="3c2f44ba0863f4f0fcb5023aa4ee6ca2" category="paragraph">[파란색 밑줄] * 생성된 HTML: *</block>
  <block id="efea650a2edf10e173ba726fa4e90c5f" category="section-title">제목 수준 1(섹션 제목)</block>
  <block id="2b70e22920b3d78a96efdd65b4b37c1f" category="section-title">제목 수준 2(섹션 제목)</block>
  <block id="3742ded2a390654e38f763a70bd4e35a" category="section-title">제목 수준 3(섹션 제목)</block>
  <block id="4d1ebef97112908dabe0c9c786eaa7ba" category="section-title">제목 레벨 4(섹션 제목)</block>
  <block id="44e6fd3a1839882d90b6020944c4aeb1" category="section-title">제목 수준 5(섹션 제목)</block>
  <block id="691d1860ec58dd973e803e209697d065" category="section-title">목록</block>
  <block id="d3263947659da25e39643e07688fb919" category="paragraph">순서가 지정되지 않은 목록:</block>
  <block id="6e991c331de28266251c487c42df1f10" category="list-text">순서가 지정되지 않은 목록입니다</block>
  <block id="d1ad2884248be2067d5bc70a584eba6d" category="list-text">아직 순서가 지정되지 않은 목록입니다</block>
  <block id="b84268ab94bb6da5f97f344b7f78bf9f" category="list-text">순서가 지정되지 않은 목록의 하위 요소입니다</block>
  <block id="434aab8bf1245d04dc3e96af08e1842e" category="paragraph">정렬된 목록:</block>
  <block id="07628350d195b6ebaae83ec46df8e1c3" category="list-text">이 목록은 순서가 지정된 목록입니다</block>
  <block id="964f443f29145e9fa43a38671d07d447" category="list-text">이것은 여전히 순서가 지정된 목록입니다</block>
  <block id="239cecc0851db8990cd18461b6243348" category="list-text">이 요소는 정렬된 목록의 하위 요소입니다</block>
  <block id="fff0d600f8a0b5e19e88bfb821dd1157" category="section-title">이미지</block>
  <block id="340c4d7a25252d5807344db646713010" category="paragraph">리포지토리 내의 이미지 또는 웹 상의 어느 위치에나 연결할 수 있습니다. 리포지토리 내의 이미지의 경우, 이미지가 미디어 폴더에 배치되므로 ":imagesdir:./media/"가 적절하게 설정되어 있는지 확인해야 합니다.</block>
  <block id="13d002c81cf56705c2becc11e5ed9a4f" category="image-alt">리포지토리 내 이미지</block>
  <block id="43d8eb4fa9bb019f23b6835a3d3c93d7" category="image-alt">리포지토리 외부의 이미지</block>
  <block id="bd908db5ccb07777ced8023dffc802f4" category="section-title">링크</block>
  <block id="69faa60007e518154e5dfa6c7cb9606d" category="paragraph">이미지와 마찬가지로 링크는 리포지토리 내부 또는 웹 상의 모든 위치에서 문서를 참조할 수 있습니다. 내부 참조의 경우 링크 원본에 대한 경로가 "link:::" 문에 지정되었는지 확인하는 것이 중요합니다.</block>
  <block id="8cc0407dfab26edc02bac943afa1c50d" category="inline-link-macro">NetApp 솔루션 변경 로그(내부)</block>
  <block id="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="paragraph"><block ref="e5eddd5cb0a7a1048bd37c62e18ae2dd" category="inline-link-macro-rx"></block></block>
  <block id="4d9909e75daa4ee8685674e4136d2046" category="inline-link-macro">NetApp 솔루션 변경 로그(외부)</block>
  <block id="bc630a540bb452bb9f726ed7c7e14715" category="paragraph"><block ref="bc630a540bb452bb9f726ed7c7e14715" category="inline-link-macro-rx"></block></block>
  <block id="3bdabc119341b76ec34be01ada064a84" category="section-title">축소할 수 있는 콘텐츠(별칭 티시)</block>
  <block id="b78a3223503896721cca1303f776159b" category="example-title">제목</block>
  <block id="b66944886034ca73431f2e338216bd4b" category="paragraph">축소할 텍스트가 여기에 표시됩니다.</block>
  <block id="70f60b4a0e07b27ad4d42c2ede9220f3" category="admonition">"제목"을 클릭하여 확장된 콘텐츠를 봅니다</block>
  <block id="1cc54ce67047f47e6e0b998e4757610b" category="section-title">테이블 만들기</block>
  <block id="2e0fea6cc0d29edadf544e93bf56013c" category="cell">열 A</block>
  <block id="778c1ae51201605a08ca7745c8dd3856" category="cell">열 B</block>
  <block id="00862db58047a1191cc2f83e69ff9892" category="cell">열 C</block>
  <block id="19273115ac8897b4064a43ccf533c3ba" category="cell">A 열의 텍스트</block>
  <block id="9ed785bee043f58e69669715e38bfe2d" category="cell">B 열의 텍스트</block>
  <block id="ec7498417999a2d1bc9ab843b061d478" category="cell">C 열의 텍스트</block>
  <block id="19ffdf534588898ed43f67fde767f1fd" category="paragraph">다음은 한 행이 전체 테이블에 걸쳐 있고 다른 행에는 여러 열에 걸쳐 있는 데이터가 있는 또 다른 예입니다.</block>
  <block id="bf767d30d483b6701f943a456017bf9d" category="cell">머리글 열 1</block>
  <block id="6e3e0843cfe6ff00d3b74bf168580453" category="cell">머리글 열 2</block>
  <block id="a2fa10d34df17b106b689ca93f07c770" category="cell">머리글 열 3</block>
  <block id="61bd6ed3bebad9294ee30668abbeff3c" category="cell">머리글 열 4</block>
  <block id="1a168c8aca72f77bf84798bb31a4cb8c" category="cell">표의 4개 열 전체에 걸쳐 있는 매우 긴 행입니다. 이 행의 유일한 셀이며 빈 셀은 남겨 둘 수 없습니다.</block>
  <block id="4f14cfb44ee45b336256dd439e135021" category="cell">이 행은 표의 열 3개에 걸쳐 빈 셀 1개를 남겨 둔 긴 행입니다.</block>
  <block id="43eddd3ae82d79991b5cefa462bed9d7" category="cell">이 행은 두 개의 열에 걸쳐 있으며 두 개의 셀을 비워 둡니다.</block>
  <block id="77631ca4f0e08419b70726a447333ab6" category="cell">여기</block>
  <block id="f1965a857bc285d26fe22023aa5ab50d" category="cell">행</block>
  <block id="a2a551a6458a8de22446cc76d639a9e9" category="cell">있습니다</block>
  <block id="fea087517c26fadd409bd4b9dc642555" category="cell">정상</block>
  <block id="00a4cb60b0815316a1416dae59b77543" category="inline-link-macro">AsciiiDoc 문서</block>
  <block id="c784ba850708b73450bc80d79e01313e" category="admonition">표 레이아웃을 변경하도록 지정할 수 있는 여러 가지 옵션이 있습니다. 자세한 내용은 달성하려는 리포지토리(HTML 버전)에서 예제를 찾은 다음 Vscode로 이동하여 소스를 보거나 을 방문하십시오 <block ref="8ce64cdd9ff98df64c05c93fb30bd0b8" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="e2f7e3242523777351b6658f86564416" category="section-title">탭 블록</block>
  <block id="d6d281824a9f2f56cd13926cacd6f6c3" category="open-title">첫 번째 탭</block>
  <block id="a13c148381823333364efc7a66153681" category="paragraph">첫 번째 탭의 내용이 여기에 표시됩니다</block>
  <block id="99a1d6da572d7987b546c07b1053d7b0" category="open-title">두 번째 탭</block>
  <block id="d93aaa34fa764ccd0a071f1c256e0a6f" category="paragraph">두 번째 탭의 내용은 여기에 있습니다</block>
  <block id="3b04793c63a616fa65f54f1d98c263e1" category="admonition">해당 섹션의 내용을 보려면 "두 번째 탭"을 클릭하십시오.</block>
  <block id="c53dba1ad099d932b01eacd82bd500f2" category="doc">NVA-1155: FC-Design 및 구축 가이드를 통해 FlexPod 데이터 센터 및 Cisco UCS 및 NetApp AFF A800에 대한 Oracle 19c RAC 데이터베이스</block>
  <block id="547673676a9fdbc79f1364e749be4d0a" category="paragraph">NetApp, Allen Cao</block>
  <block id="6e170e4c0b9eb50546a09aafc90dc157" category="doc">TR-4794: NetApp EF-Series 기반의 Oracle 데이터베이스</block>
  <block id="9b6fc59469e9f5ee36cb85b08daacec3" category="paragraph">Mitch Blackburn, NetApp Ebin Kadavy</block>
  <block id="fa8b4902d0c1e464dcf9256a434920ba" category="paragraph">TR-4794는 스토리지 관리자와 데이터베이스 관리자가 NetApp EF-Series 스토리지에 Oracle을 성공적으로 구축할 수 있도록 설계되었습니다.</block>
  <block id="611a4a6b98272a717f8e1f6bf5ba787b" category="paragraph">Marco Schoen, NetApp을 참조하십시오</block>
  <block id="dbd408dfbba42c9529974244acc200aa" category="paragraph">TR-4467은 고객과 파트너에게 Windows 환경의 Microsoft SQL Server에서 실행되는 SAP Business Suite 솔루션을 지원하기 위해 clustered NetApp Data ONTAP을 구축하는 모범 사례를 제공합니다.</block>
  <block id="69015d285622bbd074d7bccf4ea12670" category="paragraph">사내 또는 클라우드에서 운영을 최적화하고 데이터의 파워를 최대한 활용하십시오.</block>
  <block id="a23b0f6840eece1bcfc1a2ce047e740e" category="doc">TR-3633: ONTAP 기반 Oracle 데이터베이스</block>
  <block id="3b1f454fff17aa123534722dc8b6870b" category="paragraph">Jeffrey Steiner, NetApp</block>
  <block id="bb00932088674136830625fe37741beb" category="paragraph">을 참조하십시오 <block ref="d0d24196afeacb93f8904954168bf8db" category="inline-link-macro-rx"></block> TR-3633에 지정된 환경, 구성 및 버전이 사용자 환경을 지원하는지 확인하려면</block>
  <block id="d9cd8ac988f5ea26e28a2da5f3485ff9" category="paragraph">Mitch Blackburn, Pat Sinth두산, NetApp</block>
  <block id="9db08b91ae68a77b71af230b40b31325" category="paragraph">이 모범 사례 가이드는 스토리지 관리자와 데이터베이스 관리자가 NetApp EF-Series 스토리지에 Microsoft SQL Server를 성공적으로 구축할 수 있도록 돕기 위해 제작되었습니다.</block>
  <block id="d5b9082efbf726d2e38c5042668ae4f0" category="doc">TR-4250: SAP with Oracle on UNIX 및 NFS with NetApp Clustered Data ONTAP and SnapManager for SAP 3.4</block>
  <block id="bb8cd3f7aec777de29cee988f4ade068" category="paragraph">NetApp, Nils Bauer</block>
  <block id="ea455e11718ea0bfb200c540f4e0c038" category="paragraph">TR-4250은 Oracle 데이터베이스를 사용하여 SAP 비즈니스 제품군 제품을 지원하는 스토리지 솔루션을 설계하는 데 따르는 문제를 해결합니다. 이 문서는 최신 SAP 솔루션을 사용하는 비즈니스 및 IT 리더가 직면한 일반적인 스토리지 인프라 설계, 구축, 운영 및 관리 문제를 중점적으로 다룹니다. 이 문서의 권장 사항은 일반적인 내용이며 SAP 애플리케이션 또는 SAP 구축 규모와 범위에 국한되지 않습니다. TR-4250은 독자가 NetApp 및 SAP 제품의 기술과 운영에 대해 기본적인 지식을 갖추고 있다고 가정합니다. TR-4250은 NetApp, SAP, Oracle, 고객 기술 직원의 상호 작용을 기반으로 개발되었습니다.</block>
  <block id="be52c99c6345cb49ab79a79b9565c737" category="doc">TR-4785: NetApp E-Series 및 BeeGFS를 통해 AI 구축</block>
  <block id="36f4667e440709d475f1c5db4ecae97e" category="paragraph">Nagalakshmi Raju, Daniel Landes, Nathan Swartz, amine Bennani, NetApp</block>
  <block id="c74f37bd5e8951b2feda7d19b03326e9" category="paragraph">인공 지능(AI), 머신 러닝(ML) 및 딥 러닝(DL) 애플리케이션에는 대규모 데이터 세트 및 고계산이 포함됩니다. 이러한 워크로드를 성공적으로 실행하려면 스토리지 및 컴퓨팅 노드를 원활하게 확장할 수 있는 민첩한 인프라가 필요합니다. 이 보고서에는 컴퓨팅 및 스토리지 노드를 원활하게 확장할 수 있는 AI 교육 모델을 분산 모드에서 실행하는 단계가 포함됩니다. 또한, 이 보고서에는 NetApp E-Series 스토리지를 BeeGFS 병렬 파일 시스템과 결합하여 AI 워크로드를 위한 유연하고 비용 효율적이며 단순한 솔루션을 제공하는 방법을 보여주는 다양한 성능 메트릭이 포함되어 있습니다.</block>
  <block id="4472645bc6fe350406624df126edf4ac" category="paragraph">Abdel Sadek, Tim Chau, Joe McCormick, David Arnette, NetApp</block>
  <block id="7d8f094cc030aec75a343f1baad8c19d" category="paragraph">이 문서에서는 NetApp EF600 NVMe 스토리지 시스템을 사용하는 머신 러닝(ML) 및 인공 지능(AI) 워크로드를 위한 NetApp 검증 아키텍처, ThinkParQ BeeGFS 병렬 파일 시스템, NVIDIA DGX A100 시스템 및 NVIDIA Mellanox Quantum QM8700 200Gbps InfiniBand(IB) 스위치에 대해 설명합니다. 또한 이 문서에는 배포가 완료된 후 검증 벤치마크 테스트를 실행하기 위한 지침도 포함되어 있습니다.</block>
  <block id="7bfbd6c5c294b7f81d430bd31f53aea3" category="paragraph">NVA-1153-design은 NetApp AFF A800 스토리지 시스템, NVIDIA DGX A100 시스템 및 NVIDIA Mellanox Spectrum SN3700V 200GB 이더넷 스위치를 사용하는 머신 러닝(ML) 및 인공 지능(AI) 워크로드를 위한 NetApp 검증 아키텍처를 설명합니다. 이 설계에서는 컴퓨팅 클러스터 인터커넥트 패브릭을 위한 RoCE(RDMA over Converged Ethernet)를 사용하여 고객에게 고성능 워크로드를 위한 완벽한 이더넷 기반 아키텍처를 제공합니다. 이 문서에는 구현된 아키텍처의 벤치마크 테스트 결과도 포함되어 있습니다.</block>
  <block id="981ed5a5ebc4fbc2a64f69a42d9ef36c" category="paragraph">David Arnette, NetApp</block>
  <block id="0e2b7ed1591c52ac15ea956ecb6a5701" category="paragraph">TR-4851은 머신 러닝(ML) 및 딥 러닝(DL) 소프트웨어 개발을 위한 데이터 저장소 및 관리 시스템으로 NetApp StorageGRID 오브젝트 스토리지를 사용하는 방법을 보여줍니다. 이 문서에서는 자율주행 차량 소프트웨어 개발의 데이터 흐름과 요구 사항과 데이터 라이프사이클을 간소화하는 StorageGRID 기능에 대해 설명합니다. 이 솔루션은 ML 및 DL 개발 프로세스에서 일반적인 모든 다단계 데이터 파이프라인 워크플로에 적용됩니다.</block>
  <block id="5ebb854a0e7b0964891f587bfc1d231a" category="paragraph">Karthikeyan Nagalingam, NetApp Miroslav Hodak, Lenovo</block>
  <block id="17f161066b709ea249da0f86319938b3" category="paragraph">TR-4810에서는 NetApp 스토리지 컨트롤러 및 Lenovo ThinkSystem 서버에 GPU 기반 인공 지능(AI) 교육을 구축하기 위한 비용 효율적인 엔트리 레벨 컴퓨팅 및 스토리지 아키텍처에 대해 설명합니다. 이 설정은 여러 교육 작업을 동시에 실행하는 중소 및 중견 팀을 위한 공유 리소스로 설계되었습니다.</block>
  <block id="290beddb4a567cd98ba4f9116eee11b4" category="paragraph">NVA-1151-deploy에는 NetApp AFF A800 스토리지 시스템, NVIDIA DGX A100 시스템 및 NVIDIA Mellanox 네트워크 스위치를 사용하는 머신 러닝(ML) 및 인공 지능(AI) 워크로드를 위한 NVA(NetApp Verified Architecture)에 대한 스토리지 시스템 구축 지침이 포함되어 있습니다. 또한 배포가 완료된 후 검증 벤치마크 테스트를 실행하기 위한 지침도 포함되어 있습니다.</block>
  <block id="806008ac96286a2e08058ba3a3daa601" category="paragraph">NetApp, Ryan Rodine</block>
  <block id="3e22ed7172d7770cfa1457b7e70b2b06" category="doc">TR-4915: AI 및 분석 워크플로우를 위해 E-Series 및 BeeGFS로 데이터 이동</block>
  <block id="b85127cc663f1e3f1a6a366bb2732406" category="paragraph">Cody Harryman과 NetApp의 Ryan Rodine이 함께 합니다</block>
  <block id="f75519c0654938719b5319e8d452e91a" category="paragraph">TR-4915 에서는 NetApp E-Series SAN 스토리지를 통해 데이터 저장소에서 BeeGFS 파일 시스템으로 데이터를 이동하는 방법에 대해 설명합니다. 고객은 인공 지능(AI) 및 머신 러닝(ML) 애플리케이션의 경우 모델 개발을 위해 페타바이트급 데이터가 넘는 대규모 데이터 세트를 BeeGFS 클러스터로 이동해야 할 수 있습니다. 이 문서에서는 NetApp XCP 및 NetApp Cloud Sync 툴을 사용하여 이러한 성과를 달성하는 방법에 대해 알아봅니다.</block>
  <block id="ff50db1ba0f8ba4a103a810e1ceb2afc" category="paragraph">Abdel Sadek, Tim Chau, Joe McCormick, David Arnette, NetApp</block>
  <block id="1d78c2c26f50714898cd986ca8147756" category="paragraph">NVA-1156-design은 NetApp EF600 NVMe 스토리지 시스템, BeeGFS 병렬 파일 시스템, NVIDIA DGX A100 시스템 및 NVIDIA Mellanox Quantum QM8700 200Gbps IB 스위치를 사용하는 머신 러닝(ML) 및 인공 지능(AI) 워크로드를 위한 NetApp 검증 아키텍처를 설명합니다. 이 설계는 스토리지 및 컴퓨팅 클러스터 인터커넥트 패브릭을 위한 200Gbps InfiniBand(IB)를 제공하여 고객에게 고성능 워크로드를 위한 완벽한 IB 기반 아키텍처를 제공합니다. 이 문서에는 구현된 아키텍처의 벤치마크 테스트 결과도 포함되어 있습니다.</block>
  <block id="eae34d8ef755492887b6a7aa4362588d" category="paragraph">Rick Huang, Sung-Han Lin, Sathish Thyagarajan, NetApp Jacci Cenci, NVIDIA</block>
  <block id="c92ae00fd88c8477c24628d0f17deceb" category="paragraph">이 참조 아키텍처는 NVIDIA DGX-2 시스템과 의료 사용 사례용 NetApp AFF 스토리지를 사용하는 인공 지능(AI) 인프라를 구축하는 고객을 위한 지침을 제공합니다. 이 영상에는 의료 진단 영상, 검증된 테스트 사례 및 결과를 위한 딥 러닝(DL) 모델 개발에 사용되는 고급 워크플로우에 대한 정보가 포함되어 있습니다. 또한 고객 구축을 위한 사이징 권장사항도 포함되어 있습니다.</block>
  <block id="5ee668b979e736471a8d46609abdc49b" category="paragraph">이 문서에서는 NetApp E-Series 스토리지 시스템을 사용하여 StorNext 병렬 파일 시스템 솔루션을 설계하는 방법에 대해 자세히 설명합니다. 이 솔루션은 NetApp EF280 All-Flash 어레이, NetApp EF300 All-Flash NVMe 어레이, EF600 All-Flash NVMe 어레이, NetApp E57760 하이브리드 시스템에 적용됩니다. 미디어 및 엔터테인먼트 업계에서 테스트에 널리 사용되는 도구인 프레임 벤치마킹(Frametest Benchmarking)을 기반으로 성능 특성을 제공합니다.</block>
  <block id="a8b8bcca1cc81c47655f69efaea66280" category="paragraph">Karthikeyan Nagalingam, Sung-Han Lin, NetApp Jacci Cenci, NVIDIA</block>
  <block id="5e01fc0ba3a2133ea5de509bf81e119d" category="paragraph">이 참조 아키텍처는 NVIDIA DGX-1 시스템과 NetApp AFF 스토리지를 사용하여 금융 부문 사용 사례를 위한 인공 지능 인프라를 구축하려는 고객을 위한 지침을 제공합니다. 여기에는 재무 서비스 테스트 사례 및 결과를 위한 딥 러닝 모델 개발에 사용되는 상위 레벨의 워크플로우에 대한 정보가 포함됩니다. 또한 고객 구축을 위한 사이징 권장사항도 포함되어 있습니다.</block>
  <block id="5f2ab39ba2f8133927b3b4608a712d5b" category="paragraph">David Arnette, NetApp Takashi Oishi, Fujitsu</block>
  <block id="62c32325e658b728843c4f250b5d1547" category="paragraph">이 솔루션은 NetApp 스토리지 시스템 및 Fujitsu 서버를 통해 인공 지능 시스템을 구축하는 스케일아웃 아키텍처에 중점을 둡니다. 이 솔루션은 Fujitsu GX2570 서버와 NetApp AFF A800 스토리지 시스템을 사용하는 MLperf v0.6 모델 교육 벤치마크에서 검증되었습니다.</block>
  <block id="7d8a7f37eb34080960253271b824ab2f" category="paragraph">Chris Seirer, NetApp</block>
  <block id="fdb4fdcbeafc3d334651614437516062" category="paragraph">TR-4859에서는 IBM의 Spectrum Scale 소프트웨어 스택을 기반으로 전체 병렬 파일 시스템 솔루션을 구축하는 프로세스를 설명합니다. TR-4859는 Spectrum Scale 설치, 인프라 검증, 구성 관리 방법에 대한 세부 정보를 제공하도록 설계되었습니다.</block>
  <block id="5f4c1dd940d24299c2c5a80211b1e330" category="paragraph">NVA-1153-deploy에는 NetApp AFF A800 스토리지 시스템, NVIDIA DGX A100 시스템 및 NVIDIA Mellanox Spectrum SN3700V 200GB 이더넷 스위치를 사용하는 머신 러닝(ML) 및 인공 지능(AI) 워크로드를 위한 NetApp 검증 아키텍처에 대한 스토리지 시스템 구축 지침이 포함되어 있습니다. 또한 배포가 완료된 후 검증 벤치마크 테스트를 실행하기 위한 지침도 포함되어 있습니다.</block>
  <block id="23b69f42a62554346d10d302e32866df" category="paragraph">Commvault, NetApp Girish Chanchlandi의 Akash Gupta</block>
  <block id="451f1cdad20049e4046b157a54826db1" category="paragraph">TR-4320에서는 Commvault Data Platform V11 환경에서 NetApp E-Series 스토리지를 사용할 때의 참조 아키텍처 및 모범 사례에 대해 간략하게 설명합니다. CommVault와 NetApp은 이 참조 아키텍처를 공동으로 개발하여 Commvault Data Platform V11 배포에 대한 지침을 제공하고 NetApp E-Series 스토리지를 활용해 이 솔루션의 애플리케이션 시간을 단축합니다.</block>
  <block id="d223d0d947999082ea93b57a68b3614b" category="paragraph">Akash Gupta와 Principled Technologies, NetApp</block>
  <block id="9c993f8d3d3aa7be9c86474635154c12" category="paragraph">TR-4704에서는 NetApp E-Series 스토리지에 Veritas NetBackup을 구축하는 방법을 설명합니다.</block>
  <block id="febdd047851001456a2f0c683cfcfd2b" category="paragraph">Akash Gupta, NetApp Shawn W대신하여(미주), Stefan Renner(EMEA), Michael Cade(성능), Veeam을 지원합니다</block>
  <block id="2de6bbd06654b0c6d7bd5a6f2bb218f8" category="paragraph">Arvind Ramakrishnan, Abhinav Singh, NetApp</block>
  <block id="6fdf0a62913845390e552b0f7d42cbf7" category="paragraph">NVA-1143은 NetApp HCI를 설계하고 구축하여 NIST(National Institute of Standards and Technology) SP 800-53 Revision 4 보안 및 개인 정보 보호 제어를 충족하는 방법을 설명합니다. 이 기능은 프라이빗 클라우드 인프라 및 멀티테넌트 구축에 매우 중요합니다.</block>
  <block id="404af9ebdf8554a92ea8d3dde06945b4" category="doc">TR-4623: NetApp E-Series E5700 및 Splunk Enterprise</block>
  <block id="1dcb8fb2d6ad519f4a7ecd244f9c7c76" category="paragraph">Mitch Blackburn, NetApp</block>
  <block id="6a67053961e2b9d7e16bf757a5bea347" category="doc">최신 데이터 분석 - 다양한 분석 전략을 위한 다양한 솔루션</block>
  <block id="8e1e8679efe4694874eb9820dff26af8" category="paragraph">이 백서에서는 NetApp의 최신 데이터 분석 솔루션 전략을 설명합니다. 비즈니스 성과, 고객 과제, 기술 동향, 경쟁 레거시 아키텍처, 최신 워크플로우, 사용 사례, 산업, 클라우드, 기술 파트너, Data Mover, NetApp Active IQ, NetApp DataOps 툴킷, Hadoop~Spark, NetApp Astra Control, 컨테이너, 엔터프라이즈 데이터 관리, 아카이빙, 계층화를 지원하는 소프트웨어 정의 스토리지, AI 및 분석 목표를 달성하는 방법, NetApp과 고객이 함께 데이터 아키텍처를 현대화하는 방법을 알아봅니다.</block>
  <block id="4eb5c705ea54813c084d88a3d5a668f0" category="admonition">문서당 문서 제목(수준 0)은 하나만 있어야 하며 섹션 제목은 건너뛸 수 없습니다(섹션 하위 제목은 섹션 아래의 다음 제목 수준이어야 함). 따라서 처리 중에 빌드 오류가 발생하지 않도록 출력에 샘플이 표시되지 않습니다.</block>
  <block id="9b6f25534617a536120885c9ce2bf30b" category="inline-link">설치 절차는 Veeam 설명서를 참조하십시오</block>
  <block id="51c7ff4d9c3185f2df469eed762010d5" category="inline-link-macro">VMware 클라우드 기술 영역</block>
  <block id="baab3b6c6024ccda908423e27d1a7d5b" category="admonition">이 솔루션은 VMware에서도 사용할 수 있습니다. 를 방문하십시오 <block ref="e4f8fde8ba3579a04642cf870e6e362f" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="dc32da64b7845bbbf4827a1513cd8daa" category="inline-link-macro">VMware HCX를 사용하여 NetApp ONTAP용 FSx 및 AWS SDDC 기반 VMware 클라우드를 구성할 수 있습니다</block>
  <block id="e51f186f2c7dd10d7f4c1196ab269d7c" category="list-text"><block ref="e51f186f2c7dd10d7f4c1196ab269d7c" category="inline-link-macro-rx"></block></block>
  <block id="3cf6cddd26350e6a84e8bef869102647" category="cell">2022년 10월 25일</block>
  <block id="80d05b7bca341d02b41c7f6cb32ad23b" category="cell">FSx ONTAP에 대한 VMware 문서 링크를 NFS 데이터 저장소로 추가했습니다</block>
  <block id="2937ec3775c4b0354bf359a5892c53f7" category="cell">VMware HCX를 사용하여 AWS SDDC에서 FSx ONTAP 및 VMC를 사용하여 하이브리드 클라우드를 구성하기 위한 블로그에 대한 참조가 추가되었습니다</block>
  <block id="0676783b7d49061bfb23deb83b2d2f82" category="paragraph">* 작업 템플릿을 구성하고 시작합니다. *</block>
  <block id="544348a8f04b16faced725115db5b6f3" category="section-title">환경에 대한 인벤토리, 그룹, 호스트 및 자격 증명을 생성합니다</block>
  <block id="be86ca474df5e14056bc0f20d2cdb767" category="section-title">프로젝트를 만듭니다</block>
  <block id="d02a79fb6f05358e16f9d9cf02288ac3" category="section-title">글로벌 변수를 설정합니다</block>
  <block id="3506caa5fe966a4676faac2993bc1431" category="section-title">자동화 플레이북</block>
  <block id="ba985cf3c812e3ba064fedc7353bbb77" category="section-title">Oracle 데이터베이스 복구 중</block>
  <block id="fb467c38c5af2ca41ea3f09fe535144d" category="list-text">* RO/RW 액세스 규칙 * 내보내기에 대한 액세스 수준을 제어하려면 읽기/쓰기 또는 읽기 전용 을 선택합니다. CVS - 성능은 다음 옵션을 제공합니다.</block>
  <block id="b42b7de139bf4398a5d4b048ecf30c9f" category="paragraph">또한 Cloud Volumes Service는 지원되는 최대 그룹을 32개까지 확장할 수 있도록 확장된 그룹 지원을 제공합니다. 이를 위해서는 유효한 UNIX 사용자 및 그룹 ID가 포함된 LDAP 서버에 대한 LDAP 연결이 필요합니다. 이 구성을 구성하는 방법에 대한 자세한 내용은 을 참조하십시오<block ref="744e76592290230cb7381c9b8a5414da" category="inline-link-rx"></block> Google 문서.</block>
  <block id="73867c3747b10f9f7b4b54a4597ff38b" category="paragraph">IAM은 Cloud Volumes Service에 대한 세분화된 기본 권한을 제공합니다. 를 찾을 수 있습니다<block ref="fefbe49b0be12af5b957eff3a3dc2826" category="inline-link-rx"></block>.</block>
  <block id="00aa2e143f3d3b00e94456b23d239a8d" category="paragraph">을 참조하십시오<block ref="5d862676de2107050ea35e71368d2326" category="inline-link-rx"></block> 자세한 내용은 Google 클라우드 설명서를 참조하십시오.</block>
  <block id="4a0d70491e56eae6b1e0743d9c3a3777" category="paragraph">Cloud Volumes Service API는 HTTPS(TLSv1.2)를 기본 네트워크 전송으로 사용하여 REST 기반 API를 사용합니다. 최신 API 정의를 찾을 수 있습니다<block ref="d30245d84ac801bb5beeb0b65de1621d" category="inline-link-rx"></block> 및 에서 API 사용 방법에 대한 정보를 참조하십시오<block ref="00c944b7c7739b905457d5d21be6a7ef" category="inline-link-rx"></block>.</block>
  <block id="f84137720cfd9533352746a01677a6b2" category="paragraph">CloudSQL, GCVE(Google Cloud VMware Engine) 및 파일 저장소와 같은 다른 Google Cloud 네이티브 서비스와 유사한 방식으로 Cloud Volumes Service는 을 사용합니다<block ref="0f93a99b9e468a051182b66dabbf3bed" category="inline-link-rx"></block> 서비스를 제공합니다. PSA에서는 서비스를 사용하는 서비스 프로듀서 프로젝트에 내장하고 있습니다<block ref="2d8d4488e7ed7b53a7aafab379ba8587" category="inline-link-rx"></block> 서비스 소비자에 연결합니다. 서비스 생산자는 NetApp에서 제공 및 운영하고, 서비스 소비자는 고객 프로젝트에서 VPC로, Cloud Volumes Service 파일 공유에 액세스하려는 클라이언트를 호스팅합니다.</block>
  <block id="9448d83a67980a22f2db155347fa277c" category="paragraph">에서 참조하는 다음 그림<block ref="6a8b5039754626811ee5b8fe5289e273" category="inline-link-rx"></block> 에서는 Cloud Volumes Service 설명서의 개략적인 보기를 보여 줍니다.</block>
  <block id="a436da0007911ed6531e093688e82535" category="paragraph">공유 VPC를 사용하는 경우 NFS Kerberos 및/또는 를 사용하여 전송 중 암호화 <block ref="639817e82862065dd236f0597e0b07ea" category="inline-link-macro-rx"></block> 트레이스에서 얻은 정보의 대부분을 가릴 수 있습니다. 그러나 일부 트래픽은 과 같은 일반 텍스트로 계속 전송됩니다 <block ref="c2e2f225386e22bd13a8b4b174f478da" category="inline-link-macro-rx"></block> 및 <block ref="86c1c13023c15e9d9a6317a0b69e7ce3" category="inline-link-macro-rx"></block>. 다음 그림에서는 Cloud Volumes Service에서 생성된 일반 텍스트 LDAP 쿼리 및 노출된 잠재적 식별 정보의 패킷 캡처를 보여 줍니다. Cloud Volumes Service의 LDAP 쿼리는 현재 SSL을 통한 암호화 또는 LDAP를 지원하지 않습니다. Active Directory에서 요청하는 경우 CVS - 성능은 LDAP 서명을 지원합니다. CVS-SW는 LDAP 서명을 지원하지 않습니다.</block>
  <block id="75956b9ee748b806549eeec3c9a81192" category="inline-link"><block ref="75956b9ee748b806549eeec3c9a81192" category="inline-link-rx"></block></block>
  <block id="6c84917a571a2282fd9fb2a6f058a11e" category="paragraph"><block ref="6c84917a571a2282fd9fb2a6f058a11e" category="inline-link-rx"></block></block>
  <block id="5bcf8cb715ebf788ba3e70915f4256c2" category="paragraph">지역당 하나의 Active Directory 연결만 허용됩니다.</block>
  <block id="00d6cadb7a586713782bbffe59d5bc21" category="paragraph">Cloud Volumes Service는 서로 다른 엔드포인트에 걸쳐 서비스 관리(컨트롤 플레인)와 데이터 액세스(데이터 플레인)를 세분화하여 Google Cloud의 보안 아키텍처를 제공하므로 다른 엔드포인트에 영향을 미치지 않습니다(섹션 참조) <block ref="d861c2ffd2960acc200167f08fd40005" category="inline-link-macro-rx"></block>)를 클릭합니다. Google을 사용합니다<block ref="1ac65cff0d913f26dd36736caeefd5b7" category="inline-link-rx"></block> (PSA) 프레임워크를 사용하여 서비스를 제공합니다. 이 프레임워크는 NetApp에서 제공하고 운영하는 서비스 생산자와 고객 프로젝트에서 VPC(가상 프라이빗 클라우드)인 서비스 소비자 간의 차이를 구별하며, Cloud Volumes Service 파일 공유에 액세스할 클라이언트를 호스팅합니다.</block>
  <block id="1e21a0f8a8012a10d3db8d473ba52502" category="paragraph">LDAP 및 Kerberos를 사용하는 경우 이러한 서비스에서 사용 중인 네트워크 포트를 확인해야 합니다. 에서 Cloud Volumes Service에서 사용 중인 포트의 전체 목록을 찾을 수 있습니다<block ref="0dc8f2243f86f97f7b6af9378a496f93" category="inline-link-rx"></block>.</block>
  <block id="811bec2d7b00d479640fbf3259346fe6" category="paragraph">CVS용 KMS 구성 - 성능에 대한 자세한 내용은 을 참조하십시오<block ref="a0d8b07d63b271255da3bba6f51651a4" category="inline-link-rx"></block>.</block>
  <block id="c56328227fc3affbe6ed0ef4ba04f494" category="list-text"><block ref="c56328227fc3affbe6ed0ef4ba04f494" category="inline-link-rx"></block></block>
  <block id="c6563340810489dd712f25c2644eaed8" category="list-text"><block ref="c6563340810489dd712f25c2644eaed8" category="inline-link-rx"></block></block>
  <block id="150a343c955aa3114dca2e9c39571ad8" category="paragraph">또한 Kerberos를 비롯한 LDAP를 지원하는 SMB, NFS 및 이중 프로토콜 구성을 사용하려면 Windows Active Directory 도메인에 대한 액세스가 필요합니다. Active Directory 연결은 이어야 합니다<block ref="10ec0b3d8ec2c3b73be0dd7483e61c9e" category="inline-link-rx"></block> 지역별로 제공됩니다. Active Directory 도메인 컨트롤러(DC)는 를 사용하여 식별합니다<block ref="821541d595f9fee8c67d91aa5da861b4" category="inline-link-rx"></block> 지정된 DNS 서버를 사용합니다. 반환된 DC 중 하나가 사용됩니다. Active Directory 사이트를 지정하면 자격 있는 DC 목록을 제한할 수 있습니다.</block>
  <block id="7a9b1188e66f0581af9bc76ec3099a55" category="paragraph">Cloud Volumes Service는 와 함께 할당된 CIDR 범위의 IP 주소를 사용하여 에 도달합니다<block ref="3102e8199e828cb030b6f0ade5fc2cec" prefix=" " category="inline-code"></block> 명령을 실행하는 동안<block ref="e8e0c669039859d9678de67879e03e1d" category="inline-link-rx"></block>. 이 CIDR을 소스 주소로 사용하여 Active Directory 도메인 컨트롤러에 대한 인바운드 방화벽을 구성할 수 있습니다.</block>
  <block id="60bb23c83a123fdd2c99980eb34c8f80" category="paragraph">Active Directory 도메인 컨트롤러가 필요합니다<block ref="7b35a292c67c7ee0f89d3dd389e188e4" category="inline-link-rx"></block>.</block>
  <block id="fd313eaaaadfe56df9ec88896284165d" category="paragraph">CVS용 KMS 구성 방법에 대한 자세한 내용은<block ref="905a3b34ffbfe930acdbf23dd47d698f" category="inline-link-rx"></block>.</block>
  <block id="9fd9d0ecc58c5d26f4934bc140ac2a41" category="list-text">CVS - 성능은 다른 CVS - 성능 볼륨에 대한 교차 지역 볼륨 복제를 제공합니다. 자세한 내용은 을 참조하십시오<block ref="ec408a29560fd662bec08bf50f9ff3d6" category="inline-link-rx"></block> Cloud Volumes Service 설명서를 참조하십시오.</block>
  <block id="6a7870f99b17bbb49636a1e7be9d4be1" category="list-text">CVS-SW는 서비스 네이티브 볼륨 백업/복원 기능을 제공합니다. 자세한 내용은 을 참조하십시오<block ref="2377dc7e4548195ed704b70f3ce6250c" category="inline-link-rx"></block> Cloud Volumes Service 설명서를 참조하십시오.</block>
  <block id="344c8cea0d31ef9e8c7c56863c714a04" category="paragraph">또한 Google Cloud에서 CRR(Cross-Region Replication) 관리를 통해 볼륨 삭제, 스냅샷 삭제 또는 스냅샷 스케줄 변경과 같은 악의적인 관리 작업을 방지할 수 있습니다. 이 작업은 볼륨 관리자를 분리하는 사용자 지정 역할을 생성하여 수행합니다. 볼륨 관리자는 소스 볼륨을 삭제할 수는 있지만 미러를 중단할 수는 없으므로 볼륨 작업을 수행할 수 없는 CRR 관리자로부터 대상 볼륨을 삭제할 수 없습니다. 을 참조하십시오<block ref="bf2a9ccb864ad3a1fa1ddc1fec02a961" category="inline-link-rx"></block> 각 관리자 그룹이 허용하는 권한에 대한 Cloud Volumes Service 문서</block>
  <block id="99144970696c7e366271871a0e83b6cd" category="paragraph">이러한 모든 이유로 NetApp Cloud Volumes Service은 를 통해 백업 서비스를 제공합니다<block ref="253601e5d476a508040b734cbc7b3164" category="inline-link-rx"></block>.</block>
  <block id="57e8b261ab803839f73416e368f552bc" category="paragraph">Cloud Volumes Service 백업은 Cloud Volumes Service에 옵션으로 내장되어 있습니다. 사용자는 볼륨별로 Cloud Volumes Service 백업을 활성화하여 보호할 볼륨을 결정할 수 있습니다. 를 참조하십시오<block ref="218d9dd384a48541f627c5084c286ade" category="inline-link-rx"></block> 백업에 대한 자세한 내용은 를 참조하십시오<block ref="d724a11e2928bd8489b8ad8fe1eac94b" category="inline-link-rx"></block>, 스케줄링 및 을 참조하십시오<block ref="31e05107512c82ef17df4f5c4b3fe0bd" category="inline-link-rx"></block>.</block>
  <block id="de8a90c8653195ed30cc4920de8c7921" category="paragraph">Cloud Volumes Service 백업(백업 생성, 삭제 및 복원)을 관리하려면 사용자에게 이 있어야 합니다<block ref="595f329bf934dbc7996bb735e9664896" category="inline-link-rx"></block> 역할.</block>
  <block id="6640e7cef3ca860543c49a5125ba4c5a" category="list-text">파일 개수가 많은 워크로드에 대해 NFSv4.x를 사용할 경우 krb5p보다 성능이 더 우수합니다.</block>
  <block id="11eb332ab75184a78c40c9174e16f520" category="paragraph-title">NetApp과 VMware: 더 나은 협력</block>
  <block id="58eaebf972358f1cf03d386a4ade1a0f" category="section-title">다음 단계</block>
  <block id="3603e14740d8edd319e72186341cb0af" category="cell">2022년 12월 6일</block>
  <block id="48461fa824ae344e0934144c7523c3f6" category="cell">Amazon FSx 스토리지를 사용한 하이브리드 클라우드에서 Oracle 데이터베이스 현대화를 위한 7개의 비디오가 추가되었습니다</block>
  <block id="954a2b08ded0ca2c881930f5ebeee24a" category="example-title">인공 지능(AI) 및 최신 데이터 분석</block>
  <block id="672d7bebe35b300386767050d4222453" category="paragraph">[underline] # * AWS 및 FSx *#의 하이브리드 클라우드를 통한 Oracle 현대화에 대한 동영상</block>
  <block id="deb1d0bb3f3f4ef0121635c0f832a3bf" category="video-title">1부 - 사용 사례 및 솔루션 아키텍처</block>
  <block id="369b9aec1beb25441dc7c7fb46bc0fc6" category="video-title">2a부 - 최대의 가용성과 자동화된 PDB 재배치를 사용하여 사내에서 AWS로 데이터베이스 마이그레이션</block>
  <block id="2edb94ef9695015c5cd01fec59bcc782" category="video-title">파트 2b - SnapMirror를 통해 BlueXP 콘솔을 사용하여 사내에서 AWS로 데이터베이스 마이그레이션</block>
  <block id="59fa2b2110d3350efd262bd841c10975" category="video-title">3부 - 자동화된 데이터베이스 HA/DR 복제 설정, 페일오버, 재동기화</block>
  <block id="938d46c61cee67ddb1711167aba9f463" category="video-title">파트 4a - 복제된 대기 복제본에서 SnapCenter UI를 사용하여 개발/테스트용 데이터베이스 클론</block>
  <block id="09b285fbf39efff75f085bbadedde45e" category="video-title">파트 4b - 데이터베이스 백업, 복원, SnapCenter UI를 사용한 클론</block>
  <block id="45885d9d91879afc9c37a8b3e046aac4" category="video-title">파트 4c - BlueXP SaaS 애플리케이션 백업 및 복구를 통한 데이터베이스 백업 및 복구</block>
  <block id="fe86efdcec6e779b5ef15f62d8f2bc90" category="paragraph-title">AWS에 NetApp CVO(단일 노드 인스턴스)를 구축하기 위한 Terraform 구성 파일</block>
  <block id="8c4271e6faf2cea4cfc8e5b7108d8ee9" category="paragraph-title">절차를 참조하십시오</block>
  <block id="4e91e39d32f2399e7c90059f4eea5684" category="paragraph-title">수취인:</block>
  <block id="93726ca0be25ac3bef0f54da1e20751c" category="paragraph-title">AWS에서 NetApp CVO(HA 쌍)를 구축하기 위한 Terraform 구성 파일</block>
  <block id="99661bfb937ca0c49c78878d8d2b0e77" category="paragraph-title">AWS에 NetApp ONTAP FSx 구축을 위한 Terraform 구성 파일</block>
  <block id="1538b268d8f3b010dea63370c1a65935" category="paragraph-title">레시피:</block>
  <block id="107933ea485144e916f16cd69884fea6" category="paragraph-title">Azure에서 ANF 볼륨 배포를 위한 Terraform 구성 파일</block>
  <block id="c2d6144ea47815bb9e1c4e09c0918486" category="paragraph-title">Azure에서 데이터 보호를 사용하여 ANF 볼륨 배포를 위한 Terraform 구성 파일</block>
  <block id="1ed1215fce9948e3bee78c99bf12de8d" category="paragraph-title">Azure에서 이중 프로토콜을 사용하는 ANF 볼륨 배포를 위한 Terraform 구성 파일</block>
  <block id="15b915279743f1a43ce2c0f10062e69e" category="paragraph-title">Azure의 Snapshot에서 ANF 볼륨을 배포하기 위한 Terraform 구성 파일</block>
  <block id="664b1f8a02a683b16bb76004afb03be2" category="paragraph-title">Azure에서 단일 노드 CVO를 구축하기 위한 Terraform 구성 파일</block>
  <block id="f06bfa867f111b72b9e71b8a75d661da" category="paragraph-title">Azure에서 CVO HA를 구축하기 위한 Terraform 구성 파일</block>
  <block id="e10db5a03ff1c5409d1b9ef0cf32ae11" category="paragraph-title">GCP에 NetApp CVO(단일 노드 인스턴스)를 구축하기 위한 Terraform 구성 파일</block>
  <block id="1e95e8962dbf55d78e03e8da38f9f408" category="paragraph-title">GCP에 NetApp CVO(HA 쌍)를 구축하기 위한 Terraform 구성 파일</block>
  <block id="f39b5c8ffff4c5fccbc9ca01bf3bacf8" category="paragraph-title">GCP 기반 NetApp CVS 볼륨 구축을 위한 Terraform 구성 파일</block>
  <block id="934282d2b6cc731f63bcc3cdfbba32a1" category="paragraph">Veeam 백업 서버, 백업 저장소 및 구축해야 하는 백업 프록시가 구축 시나리오에 기반을 두고 있습니다. 이 경우 Veeam 및 스케일아웃 저장소에도 오브젝트 저장소를 구축할 필요가 없습니다.<block ref="3798d8f6f1f14581181abe3a5ef34dc1" category="inline-link-rx"></block></block>
  <block id="a94f1b9cbc89a005a38096b1750f907f" category="cell">2022년 12월 15일</block>
  <block id="754451201969a73231c286ef8f4b2fd6" category="cell">NetApp ONTAP용 Amazon FSx를 사용하여 AWS EC2에 TR-4923:SQL Server 추가</block>
  <block id="f53cfd73e0994740413d578c9dd6b36e" category="doc">TR-4923: NetApp ONTAP용 Amazon FSx를 사용하는 AWS EC2의 SQL Server</block>
  <block id="9aeea85747c176482897f26600d172d0" category="paragraph">저자: Pat Sinth두산, Niyaz Mohamed, NetApp</block>
  <block id="8bd093418d226733e085e856bd9165c8" category="paragraph">사내 스토리지 시스템 및 클라우드 스토리지 서비스에서 제공하는 기능 차이로 인해 사내 애플리케이션을 클라우드로 마이그레이션하려는 많은 회사가 이러한 노력에 어려움을 겪고 있습니다. 이러한 격차로 인해 Microsoft SQL Server와 같은 엔터프라이즈 애플리케이션을 마이그레이션하는 데 훨씬 더 많은 문제가 있었습니다. 특히, 강력한 스냅샷, 스토리지 효율성 기능, 고가용성, 안정성, 일관된 성능 등과 같은 엔터프라이즈 애플리케이션을 실행하는 데 필요한 서비스 간의 격차를 좁히기 위해 고객은 설계 트레이드오프나 forgo 애플리케이션 마이그레이션을 수행할 수밖에 없었습니다. NetApp ONTAP용 FSx를 사용하면 고객은 더 이상 타협할 필요가 없습니다. NetApp ONTAP용 FSX는 AWS에서 판매, 지원, 청구 및 완벽하게 관리되는 네이티브 AWS 서비스입니다. NetApp ONTAP의 강력한 기능을 사용하여 NetApp에서 30년 동안 사내에 제공해온 엔터프라이즈급 스토리지 및 데이터 관리 기능을 관리형 서비스로 제공합니다.</block>
  <block id="f3eec26de1c09022af7c97255f0dfee6" category="inline-link">AWS FSx ONTAP</block>
  <block id="a2f7f68476a76b6aa359589e4d201707" category="paragraph">데이터베이스 관리자는 EC2 인스턴스에서 SQL Server를 사용하여 데이터베이스 환경과 기본 운영 체제에 액세스하고 사용자 지정할 수 있습니다. 와 함께 EC2 인스턴스의 SQL Server<block ref="3f737fd84a60fb425fdcdb5cf9a593da" category="inline-link-rx"></block> 데이터베이스 파일을 저장하려면, 블록 레벨 복제를 사용하여 고성능, 데이터 관리 및 간단하고 쉬운 마이그레이션 경로를 설정합니다. 따라서 간단한 인양이동 접근 방식, 클릭 수 감소, 스키마 변환 없이 AWS VPC에서 복잡한 데이터베이스를 실행할 수 있습니다.</block>
  <block id="cf79d59896c29cc7579cf75220c25c95" category="section-title">Amazon FSx for NetApp ONTAP with SQL Server의 이점</block>
  <block id="8908df00453997edbfc759829ecdf0d8" category="paragraph">NetApp ONTAP용 Amazon FSx는 AWS의 SQL Server 구축에 이상적인 파일 스토리지입니다. 다음과 같은 이점을 제공합니다.</block>
  <block id="7b699f0e1a60e419ed7d9173339aa3f5" category="list-text">짧은 지연 시간과 일관된 고성능 및 높은 처리량</block>
  <block id="8a34b0f2109dd0aad0c0c9976717cdd3" category="list-text">NVMe 캐시를 이용한 지능형 캐싱으로 성능 향상</block>
  <block id="b10e27f9d68e001b8aa9369c8d308a8c" category="list-text">용량, 처리량, IOP를 즉시 늘리거나 줄일 수 있는 유연한 사이징</block>
  <block id="169fee7c17564fc51aa8d2e77bcc1ce0" category="list-text">사내-AWS 블록 간 효율적인 복제</block>
  <block id="fd140f04c5bc5f51aff3ea5e1619abaf" category="list-text">데이터베이스 환경에서 잘 알려진 프로토콜인 iSCSI를 사용합니다</block>
  <block id="e2c00a563e0219fd93fa6f24606dee33" category="list-text">씬 프로비저닝, 설치 공간 제로 클론 복제 등의 스토리지 효율성 기능</block>
  <block id="4ac0316f1ba409d5cd9684222f9f8ada" category="list-text">백업 시간이 몇 시간에서 몇 분으로 단축되어 RTO가 감소합니다</block>
  <block id="e3168d8a4383357a37460afad2f8878d" category="list-text">직관적인 NetApp SnapCenter UI를 사용하여 SQL 데이터베이스의 세분화된 백업 및 복구</block>
  <block id="935da11069e36e124602b7e23a73ee06" category="list-text">실제 마이그레이션 전에 여러 번의 테스트 마이그레이션을 수행할 수 있습니다</block>
  <block id="15173984ed0ff615a3f0d55c8cd12291" category="list-text">마이그레이션 중 다운타임 단축 및 파일 레벨 또는 I/O 레벨 사본으로 마이그레이션 문제 해결</block>
  <block id="0de5f8d5cf18757efac074c02f16a0bb" category="list-text">주요 릴리스 또는 패치 업데이트 후 근본 원인을 찾아 MTTR 감소</block>
  <block id="1a8e2e4ef765d6c61c4652659fb151ac" category="paragraph">iSCSI 프로토콜을 사용하여 FSx ONTAP에 SQL Server 데이터베이스를 배포하면 일반적으로 사내에서 사용되는 것처럼 탁월한 성능, 스토리지 효율성 및 데이터 관리 기능을 갖춘 이상적인 데이터베이스 스토리지 환경을 제공합니다. 작업 세트 크기가 5%라고 가정하여 여러 iSCSI 세션을 사용하는 경우 Flash Cache를 fitting 하면 FSx ONTAP 서비스에 100K IOPS 이상이 제공됩니다. 이 구성을 통해 가장 까다로운 애플리케이션의 성능을 완벽하게 제어할 수 있습니다. ONTAP용 FSx에 연결된 더 작은 EC2 인스턴스에서 실행되는 SQL Server는 ONTAP용 FSx에 네트워크 대역폭 제한만 적용되므로 훨씬 더 큰 EC2 인스턴스에서 실행되는 SQL Server와 동일한 성능을 수행할 수 있습니다. 또한 인스턴스 크기를 줄이면 컴퓨팅 비용도 절감되므로 TCO에 최적화된 구축이 가능합니다. ONTAP용 FSx에서 iSCSI를 사용하는 SQL, SMB3.0과 다채널, 지속적인 가용성 공유를 조합하면 SQL 작업 부하에 큰 이점을 얻을 수 있습니다.</block>
  <block id="135b308ed83c53f1516b7c754566d1c4" category="section-title">시작하기 전에</block>
  <block id="365a329d23604298414064b1bd2dba2f" category="paragraph">Amazon FSx for NetApp ONTAP 및 EC2 인스턴스에 SQL Server를 함께 사용하면 가장 까다로운 애플리케이션 요구사항을 충족하는 엔터프라이즈급 데이터베이스 스토리지 설계를 생성할 수 있습니다. 두 기술을 모두 최적화하려면 SQL Server I/O 패턴과 특성을 이해하는 것이 중요합니다. SQL Server 데이터베이스를 위해 잘 설계된 스토리지 레이아웃은 SQL Server의 성능과 SQL Server 인프라의 관리를 지원합니다. 또한 우수한 스토리지 레이아웃을 통해 초기 구축을 성공적으로 수행하고 비즈니스 성장에 따라 시간이 지남에 따라 환경을 원활하게 확장할 수 있습니다.</block>
  <block id="800d285a5a8ca10451f7ace50ac40de5" category="paragraph">이 문서의 단계를 완료하기 전에 다음과 같은 전제 조건이 충족되어야 합니다.</block>
  <block id="69a7abd5a400936f0e1a89910dfa0ba1" category="list-text">AWS 계정</block>
  <block id="bfa061c0e7fe048c571ab15bc8d211a4" category="list-text">ONTAP용 EC2 및 FSx를 프로비저닝하기 위한 적절한 IAM 역할</block>
  <block id="a76b04166db341ceee35b584673698e9" category="list-text">EC2의 Windows Active Directory 도메인</block>
  <block id="3084927119ae63d45676d527dfb4a882" category="list-text">모든 SQL Server 노드는 서로 통신할 수 있어야 합니다</block>
  <block id="b1ada0ca0559fff335d482de393b4c70" category="list-text">DNS 확인이 작동하고 호스트 이름을 확인할 수 있는지 확인합니다. 그렇지 않은 경우 호스트 파일 항목을 사용합니다.</block>
  <block id="8413178222467ef68eb68a0644f11c42" category="list-text">SQL Server 설치에 대한 일반적인 지식</block>
  <block id="9c69c1668eca3541f0576cdc7fc730f0" category="paragraph">또한 최적의 스토리지 구성을 보장하기 위해 SQL Server 환경에 대한 NetApp 모범 사례 를 참조하십시오.</block>
  <block id="49c805233b94175c188c58ebf681a2b9" category="example-title">EC2의 SQL Server 환경에 대한 모범 사례 구성</block>
  <block id="d1d9da06ca1cde6106fef737b522df6e" category="paragraph">FSx ONTAP를 사용하면 스토리지를 조달하는 것이 가장 쉬우므로 파일 시스템을 업데이트하여 수행할 수 있습니다. 이 간단한 프로세스를 통해 필요에 따라 동적인 비용 및 성능 최적화를 수행할 수 있으며, SQL 워크로드의 균형을 유지하는 데 도움이 되며, 씬 프로비저닝을 위한 훌륭한 원동력이기도 합니다. FSX ONTAP 씬 프로비저닝은 SQL Server를 실행하는 EC2 인스턴스에 파일 시스템에서 프로비저닝되는 것보다 더 많은 논리적 스토리지를 제공하도록 설계되었습니다. 공간을 미리 할당하는 대신 데이터가 기록될 때 스토리지 공간이 각 볼륨 또는 LUN에 동적으로 할당됩니다. 대부분의 구성에서는 볼륨 또는 LUN의 데이터가 삭제되고 스냅샷 복사본이 보류되지 않는 경우에도 사용 가능한 공간이 다시 해제됩니다. 다음 표에는 스토리지를 동적으로 할당할 수 있는 구성 설정이 나와 있습니다.</block>
  <block id="db1bfba30dab4f1ed4a13cc586837f1b" category="cell">없음(기본값으로 설정)</block>
  <block id="f6445fd89b0b2c67f0304765c4c9a760" category="cell">LUN 예약입니다</block>
  <block id="f1e0735081bab920eff76b08a4600c76" category="cell">fractional_reserve</block>
  <block id="856ee920f3261cadbc1c3fc52171d071" category="cell">0%(기본값으로 설정)</block>
  <block id="99c0f62171e34b4ab6a79265f038e3af" category="cell">snap_reserve</block>
  <block id="7c68df7d17c446f99304ee1dc1498bfc" category="cell">자동 크기 조정</block>
  <block id="521c36a31c2762741cf0f8890cbe05e3" category="cell">켜짐</block>
  <block id="43c4c1dbc452be91829f25ee32c2a956" category="cell">볼륨 계층화 정책</block>
  <block id="6d576caa9862f6db0177dfaff7abb095" category="cell">스냅샷만</block>
  <block id="e08a486f204620eff1a08fc926316c68" category="paragraph">이 구성에서는 볼륨의 총 크기가 파일 시스템에서 사용 가능한 실제 스토리지보다 클 수 있습니다. LUN 또는 스냅샷 복사본에 볼륨에서 사용 가능한 공간보다 더 많은 공간이 필요한 경우 볼륨은 자동으로 확장되므로 포함된 파일 시스템에서 더 많은 공간을 차지합니다. 자동 확장 기능을 사용하면 FSx ONTAP에서 미리 결정한 최대 크기까지 볼륨 크기를 자동으로 늘릴 수 있습니다. 볼륨의 자동 증가를 지원하려면 포함하는 파일 시스템에 사용 가능한 공간이 있어야 합니다. 따라서 자동 확장 기능이 설정된 경우 포함된 파일 시스템의 사용 가능한 공간을 모니터링하고 필요할 때 파일 시스템을 업데이트해야 합니다.</block>
  <block id="82373a2016779f9c20fdc0d8b48101a7" category="inline-link">공간 할당</block>
  <block id="0126eb1acda2ac795726d8bc5fe76a98" category="paragraph">이와 함께 를 설정합니다<block ref="9d6ca3a9a42127525354c85d54adc465" category="inline-link-rx"></block> LUN의 옵션을 Enabled로 설정하면, FSx ONTAP는 볼륨의 공간이 부족하고 볼륨의 LUN이 쓰기를 수락할 수 없을 때 EC2 호스트에 알립니다. 또한 이 옵션을 사용하면 EC2 호스트의 SQL Server가 데이터를 삭제할 때 ONTAP용 FSx가 공간을 자동으로 재확보할 수 있습니다. 공간 할당 옵션은 기본적으로 사용하지 않도록 설정됩니다.</block>
  <block id="afa7be61df3527a5c4b5b7369729dfbc" category="admonition">공간 예약 LUN이 NONE-Guaranteed 볼륨에 생성된 경우 LUN은 공간이 예약되지 않은 LUN과 동일하게 작동합니다. 이는 보장된 볼륨 중 어느 것도 LUN에 할당할 공간이 없기 때문입니다. 볼륨 자체는 이 볼륨에 쓸 때만 공간을 할당할 수 있습니다. 이 경우 보장이 없기 때문입니다.</block>
  <block id="cf18df2432b44bda18f67ef6fc93e36f" category="paragraph">이 구성을 사용하면 FSx ONTAP 관리자는 일반적으로 호스트 측 및 파일 시스템의 LUN에서 사용된 공간을 관리 및 모니터링해야 하는 볼륨 크기를 조정할 수 있습니다.</block>
  <block id="3e5fc395bc0727ee4a5d50bf7852e11e" category="admonition">SQL Server 워크로드에 별도의 파일 시스템을 사용하는 것이 좋습니다. 파일 시스템이 여러 애플리케이션에 사용되는 경우 파일 시스템 및 파일 시스템 내의 볼륨 모두의 공간 사용량을 모니터링하여 볼륨이 사용 가능한 공간에 대해 경합하지 않는지 확인합니다.</block>
  <block id="9bc03cfd47c7deb1375b7e700fba9c1a" category="admonition">FlexClone 볼륨을 생성하는 데 사용되는 스냅샷 복사본은 자동 삭제 옵션에 의해 삭제되지 않습니다.</block>
  <block id="20292bb9591bce95b16e6ee1415023d3" category="admonition">SQL Server와 같은 미션 크리티컬 애플리케이션에 대해 스토리지 구매의사를 신중하게 고려하고 관리해야 하며, 운영 중단을 최소화해서는 안 됩니다. 이런 경우 스토리지 소비 추세를 모니터링하여 어느 정도의 구매량(있는 경우)을 허용할 수 있는지 확인하는 것이 좋습니다.</block>
  <block id="d846da4dd06c448920cac63b79adc614" category="list-text">최적의 스토리지 성능을 위해 파일 시스템 용량을 총 데이터베이스 사용 크기의 1.5배 크기로 프로비저닝합니다.</block>
  <block id="e2ec94309dce197f199c6e60cd3070eb" category="list-text">애플리케이션 다운타임을 방지하기 위해 씬 프로비저닝을 사용할 때는 효과적인 작업 계획과 함께 적절한 모니터링이 필요합니다.</block>
  <block id="d7fbab8fe0fe681c9e815507bcdf85c8" category="list-text">스토리지가 가득 찰 때 사람들이 연락할 수 있는 충분한 시간이 확보되도록 Cloudwatch 및 기타 모니터링 툴 알림을 설정해야 합니다.</block>
  <block id="626a89ea253e84625436538e7249e94d" category="section-title">SQL Server용 스토리지를 구성하고 백업, 복원 및 클론 작업을 위해 SnapCenter를 구축합니다</block>
  <block id="0a1c2236044192334a3fb3bbc0ab0dcd" category="paragraph">SnapCenter를 사용하여 SQL Server 작업을 수행하려면 먼저 SQL Server용 볼륨 및 LUN을 생성해야 합니다.</block>
  <block id="0cf06bf086c162ff9027bab7f6f36c93" category="example-title">SQL Server용 볼륨 및 LUN을 생성합니다</block>
  <block id="ff6ef44023084895f5f22aaf568ee0e3" category="paragraph">SQL Server용 볼륨 및 LUN을 생성하려면 다음 단계를 수행하십시오.</block>
  <block id="0165fcfd32879eacf541aadf086338d2" category="list-text">에서 Amazon FSx 콘솔을 엽니다<block ref="977f5adc4374191d0e48b9c0a8830158" category="inline-link-rx"></block></block>
  <block id="1e33ad7579c798ce6033c144ac99b840" category="list-text">생성 방법 아래의 표준 생성 옵션을 사용하여 NetApp ONTAP 파일 시스템에 대한 Amazon FSx를 생성합니다. 이를 통해 FSxadmin 및 vsadmin 자격 증명을 정의할 수 있습니다.</block>
  <block id="a83755c47ff9159637d0666c65d8c544" category="paragraph"><block ref="a83755c47ff9159637d0666c65d8c544" category="inline-image-macro-rx" type="image"></block></block>
  <block id="269452df07db5e5d5fb10125ef2dfc42" category="list-text">fsxadmin의 암호를 지정합니다.</block>
  <block id="0939c7e9185662b3e54503cb12415c7a" category="paragraph"><block ref="0939c7e9185662b3e54503cb12415c7a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="dea5db34596930d023317e03284777e1" category="list-text">SVM에 대한 암호를 지정합니다.</block>
  <block id="d2b251088e201058dd19119478e04523" category="paragraph"><block ref="d2b251088e201058dd19119478e04523" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e5a504f8d9fd87dc54c0f8a370eed579" category="inline-link">NetApp ONTAP용 FSx에서 볼륨 생성</block>
  <block id="d0ff5f8be38ac60d217f9c007a52da0e" category="list-text">에 나와 있는 단계에 따라 볼륨을 생성합니다<block ref="1146addad8000a8f0f70de9ea1e5f637" category="inline-link-rx"></block>.</block>
  <block id="17288ccd1a2a55fccc24e084bec74a89" category="list-text">스토리지 Snapshot 복사본 일정 및 보존 정책을 사용하지 않도록 설정합니다. 대신 NetApp SnapCenter를 사용하여 SQL Server 데이터 및 로그 볼륨의 스냅샷 복사본을 조정합니다.</block>
  <block id="c5023b4b04bc0ddc3d77e81fee7d99bb" category="list-text">개별 볼륨의 개별 LUN에서 데이터베이스를 구성하여 빠르고 세분화된 복원 기능을 활용할 수 있습니다.</block>
  <block id="6cb174042332f6d15cedab79c1f88bac" category="list-text">사용자 데이터 파일(.mdf)은 랜덤 읽기/쓰기 워크로드이므로 별도의 볼륨에 배치하십시오. 일반적으로 트랜잭션 로그 백업은 데이터베이스 백업보다 더 자주 생성됩니다. 따라서 트랜잭션 로그 파일(.ldf)을 데이터 파일과 별도의 볼륨에 배치하여 각 볼륨에 대해 독립적인 백업 일정을 생성할 수 있습니다. 또한 이 분리 방식은 로그 파일의 순차적 쓰기 I/O를 데이터 파일의 랜덤 읽기/쓰기 I/O에서 격리하고 SQL Server 성능을 크게 향상시킵니다.</block>
  <block id="0588cef8958d83f61aed452f853f5852" category="list-text">tempdb는 Microsoft SQL Server가 임시 작업 공간으로 사용하는 시스템 데이터베이스로, 특히 I/O 집약적인 DBCC CHECKDB 작업에 사용됩니다. 따라서 이 데이터베이스를 전용 볼륨에 배치합니다. 볼륨 수가 문제가 되는 대규모 환경에서는 신중하게 계획을 수립한 후 tempdb를 더 적은 볼륨으로 통합하고 동일한 볼륨에 저장할 수 있습니다. Microsoft SQL Server를 다시 시작할 때마다 이 데이터베이스가 다시 생성되므로 tempdb에 대한 데이터 보호는 높은 우선 순위가 아닙니다.</block>
  <block id="0f33b537ada1b2dcb95880741120d7b6" category="list-text">다음 SSH 명령을 사용하여 볼륨을 생성합니다.</block>
  <block id="4272c7e0323a62da36a59d8db2457c11" category="list-text">Windows Server에서 상승된 권한을 사용하여 PowerShell로 iSCSI 서비스를 시작합니다.</block>
  <block id="91d0d079f1c5a2183c1012cd2c2e59ab" category="list-text">Windows Server에서 상승된 권한을 사용하여 PowerShell로 Multipath-IO를 설치합니다.</block>
  <block id="4dee8d84e86540a5c4c302b3d75c32bc" category="list-text">Windows Server에서 상승된 권한을 사용하여 PowerShell을 사용하는 Windows 이니시에이터 이름을 찾습니다.</block>
  <block id="13aca4cbeddb191f6e28fc3dc5b50aca" category="paragraph"><block ref="13aca4cbeddb191f6e28fc3dc5b50aca" category="inline-image-macro-rx" type="image"></block></block>
  <block id="1fcce0650c7bce1532fc57b6af299dba" category="list-text">putty를 사용하여 SVM(스토리지 가상 시스템)에 연결하고 iGroup을 생성합니다.</block>
  <block id="a260444f9f7265e7da0cffa861246e93" category="list-text">다음 SSH 명령을 사용하여 LUN을 생성합니다.</block>
  <block id="0bf39861d87235a7c094d3de2e3a8840" category="paragraph"><block ref="0bf39861d87235a7c094d3de2e3a8840" category="inline-image-macro-rx" type="image"></block></block>
  <block id="52f5ef787d84b4ec1b5183cffdef5b56" category="list-text">OS 파티셔닝 스키마와 입출력 정렬을 달성하려면 Windows_2008을 권장되는 LUN 유형으로 사용합니다. 을 참조하십시오<block ref="ff5fd3b71f5cd8b1a4e2fe23ad6d92ae" category="inline-link-rx"></block> 자세한 내용은 를 참조하십시오.</block>
  <block id="4f10474fd5677d7f5caee5944cfd1a79" category="list-text">다음 SSH 명령을 사용하여 방금 생성한 LUN에 igroup을 매핑합니다.</block>
  <block id="e9cb77a7f24ef618789f32ace120d069" category="paragraph"><block ref="e9cb77a7f24ef618789f32ace120d069" category="inline-image-macro-rx" type="image"></block></block>
  <block id="0108f548c7bfba3ca19e227db2ad81d9" category="list-text">Windows 페일오버 클러스터를 사용하는 공유 디스크의 경우 SSH 명령을 실행하여 Windows 페일오버 클러스터에 참여하는 모든 서버에 속한 igroup에 동일한 LUN을 매핑합니다.</block>
  <block id="88c4f29ad54bd37fb1b7a1491b7af990" category="list-text">Windows Server를 iSCSI Target을 사용하여 SVM에 연결합니다. AWS Portal에서 타겟 IP 주소를 찾습니다.</block>
  <block id="547003177db44afb512e9939c282d6c9" category="paragraph"><block ref="547003177db44afb512e9939c282d6c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="df9eaa73034109b21c143e8c209823c2" category="list-text">서버 관리자 및 도구 메뉴에서 iSCSI 초기자를 선택합니다. 검색 탭을 선택한 다음 포털 검색 을 선택합니다. 이전 단계의 iSCSI IP 주소를 제공하고 고급을 선택합니다. 로컬 어댑터 에서 Microsoft iSCSI 초기자 를 선택합니다. 이니시에이터 IP에서 서버의 IP를 선택합니다. 그런 다음 확인 을 선택하여 모든 창을 닫습니다.</block>
  <block id="076e00306637258d0363c74566eb915d" category="paragraph"><block ref="076e00306637258d0363c74566eb915d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="8bd432f2fc3bb1fab0023bf42f7b4108" category="list-text">SVM에서 두 번째 iSCSI IP에 대해 12단계를 반복합니다.</block>
  <block id="5648333e8838336553b385e488639863" category="list-text">Targets * 탭을 선택하고 * Connect * 를 선택한 다음 * Enable Muti-path * 를 선택합니다.</block>
  <block id="4bff8ed7bd736139029b8aa4f639ccd9" category="paragraph"><block ref="4bff8ed7bd736139029b8aa4f639ccd9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f94de8933712f5d52ca62caf7fef6eb5" category="list-text">최상의 성능을 얻으려면 세션을 더 추가하고 5개의 iSCSI 세션을 생성하는 것이 좋습니다. 속성 * &gt; * 세션 추가 * &gt; * 고급 * 을 선택하고 12단계를 반복합니다.</block>
  <block id="5636fa6e8685f1da20bf9489bcadc782" category="paragraph"><block ref="5636fa6e8685f1da20bf9489bcadc782" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c762aaec425b12667f2a575012e48905" category="list-text">최적의 성능을 위해 타겟 인터페이스당 5개의 iSCSI 세션을 구성합니다.</block>
  <block id="72a53f90bcbaa031cad1c79575c53094" category="list-text">최상의 전체 iSCSI 성능을 위해 라운드 로빈 정책을 구성합니다.</block>
  <block id="168b03d713c83578e3c90be8e0a76a8e" category="list-text">LUN을 포맷할 때 할당 유닛 크기가 파티션의 64K로 설정되어 있는지 확인합니다</block>
  <block id="a196b0bfd5261a81ff3d40a2043f792c" category="list-text">다음 PowerShell 명령을 실행하여 iSCSI 세션이 유지되는지 확인합니다.</block>
  <block id="58fbf35d4173787943d2fe31aed43341" category="paragraph"><block ref="58fbf35d4173787943d2fe31aed43341" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22ae84abced8e9e1236160d982616772" category="list-text">다음 PowerShell 명령으로 디스크를 초기화합니다.</block>
  <block id="ac47df449db0c31d1ba6117a1dd19765" category="paragraph"><block ref="ac47df449db0c31d1ba6117a1dd19765" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b1e9edc2d6e907049df14a10a6fcc404" category="list-text">PowerShell을 사용하여 Create Partition 및 Format Disk 명령을 실행합니다.</block>
  <block id="79484e9f2e5f0589c78f273edd80759f" category="paragraph">부록 B의 PowerShell 스크립트를 사용하여 볼륨 및 LUN 생성을 자동화할 수 있습니다 SnapCenter를 사용하여 LUN을 생성할 수도 있습니다.</block>
  <block id="d05ae24753b4098046ae8369c5618b97" category="paragraph">볼륨 및 LUN을 정의한 후에는 SnapCenter를 설정하여 데이터베이스 작업을 수행할 수 있어야 합니다.</block>
  <block id="6309043436d4e7e5bad9a81c89ff15e4" category="example-title">SnapCenter 개요</block>
  <block id="419a08c6fdce80a29b8f8aeb7524f0e2" category="paragraph">NetApp SnapCenter는 계층 1 엔터프라이즈 애플리케이션을 위한 차세대 데이터 보호 소프트웨어입니다. SnapCenter는 단일 창 방식의 관리 인터페이스를 통해, 여러 데이터베이스와 기타 애플리케이션 워크로드의 백업, 복구 및 클론 복제와 관련된 시간 소모적이고 복잡한 수동 프로세스를 자동화 및 단순화합니다. SnapCenter는 NetApp Snapshot, NetApp SnapMirror, SnapRestore 및 NetApp FlexClone을 비롯한 NetApp 기술을 활용합니다. 이와 같은 통합을 통해 IT 조직은 스토리지 인프라를 확장하고, 점점 엄격해지는 SLA 규정을 충족하고, 기업 전체에서 관리자의 생산성을 향상시킬 수 있습니다.</block>
  <block id="aa7c84b8a1ac7c27cbd3e14740e96214" category="example-title">SnapCenter 서버 요구 사항</block>
  <block id="4ee08603c9fd8ece4f670310954cdde6" category="paragraph">다음 표에는 Microsoft Windows Server에 SnapCenter Server 및 플러그인을 설치하기 위한 최소 요구 사항이 나열되어 있습니다.</block>
  <block id="05bbb43b3d923283e0b6ffafd088f41f" category="cell">구성 요소</block>
  <block id="9b97b7bd5e0a87be7bf218224ada83cf" category="cell">요구 사항</block>
  <block id="44e5a606cb3fbfaed79ce8eb853ed886" category="paragraph">최소 CPU 수입니다</block>
  <block id="ea54f01387bc5362f6e287ba66d656a8" category="paragraph">코어/vCPU 4개</block>
  <block id="99880291d6a6b72b928a1847a6135c88" category="paragraph">최소 8GB 권장: 32GB</block>
  <block id="96e1506a8b72a455b990ffe403eea2cf" category="paragraph">저장 공간</block>
  <block id="39b4c2fc16a74430850f1b767f816bdd" category="paragraph">최소 설치 공간: 10GB의 리포지토리 최소 공간: 10GB</block>
  <block id="2e71b3fb71d89f18906d4807a6011e20" category="cell">지원되는 운영 체제</block>
  <block id="00aae0645113cb861020a7a42ded48c2" category="list-text">Windows Server 2012 를 참조하십시오</block>
  <block id="96bc7f42979153694e05a6a2b867772e" category="list-text">Windows Server 2012 R2</block>
  <block id="ed590cb2453f0683b64cb528f78610a2" category="list-text">Windows Server 2016</block>
  <block id="7c01fa88a74580e7e4f62ca6bfe7ee83" category="cell">소프트웨어 패키지</block>
  <block id="aab81d3c2e898a19cf0f270cdb285a21" category="list-text">NET 4.5.2 이상</block>
  <block id="43de0ba571a51d1adc60e6d05ecf8d70" category="list-text">WMF(Windows Management Framework) 4.0 이상</block>
  <block id="fd6133b32592ca288e63c1b1257f656d" category="list-text">PowerShell 4.0 이상</block>
  <block id="427d30c4045ae36c0130a14658100185" category="paragraph">자세한 내용은 공간 및 사이징 요구 사항을 참조하십시오 <block ref="bcc48263fbca83f546b0bc02edad3f56" category="inline-link-rx"></block></block>
  <block id="a19fb58a9ea7e8409b13e971960fdbf8" category="paragraph">버전 호환성은 를 참조하십시오<block ref="b7322bec4509d45107de6de43ca1f517" category="inline-link-rx"></block>.</block>
  <block id="00324c8ea6b2abc68414748e587e15ec" category="example-title">데이터베이스 스토리지 레이아웃</block>
  <block id="a02dce187534c84aa16d8849406a60eb" category="paragraph">다음 그림에서는 SnapCenter를 사용하여 백업할 때 Microsoft SQL Server 데이터베이스 스토리지 레이아웃을 생성할 때 고려해야 할 몇 가지 사항을 보여 줍니다.</block>
  <block id="4c246b141980a6574bc7f111fe7abef7" category="paragraph"><block ref="4c246b141980a6574bc7f111fe7abef7" category="inline-image-macro-rx" type="image"></block></block>
  <block id="ebfae4b9e090c4988616a73ffc71415e" category="list-text">데이터베이스를 I/O 집약적 쿼리로 배치하거나 데이터베이스 크기가 큰(예: 500GB 이상) 데이터베이스를 별도의 볼륨에 배치하여 복구 속도를 높입니다. 이 볼륨은 별도의 작업으로 백업되어야 합니다.</block>
  <block id="4916b57b0128fd5a0a4300f0a8763292" category="list-text">중요도가 덜하거나 I/O 요구사항이 적은 중소 규모의 데이터베이스를 단일 볼륨에 통합합니다. 동일한 볼륨에 상주하는 많은 데이터베이스를 백업하면 유지해야 하는 Snapshot 복사본이 줄어듭니다. 또한 Microsoft SQL Server 인스턴스를 통합하여 동일한 볼륨을 사용하여 생성한 백업 Snapshot 복사본 수를 제어하는 것이 모범 사례입니다.</block>
  <block id="8db6b23eddd61aa572ca93a39703d4a8" category="list-text">전체 텍스트 관련 파일 및 파일 스트리밍 관련 파일을 저장할 별도의 LUN을 생성합니다.</block>
  <block id="cb11fd215e0c541cb65535e582b9b273" category="list-text">Microsoft SQL Server 로그 백업을 저장할 호스트당 별도의 LUN을 할당합니다.</block>
  <block id="48b8325fd70d83c2d4e99987e23b07ef" category="list-text">데이터베이스 서버 메타데이터 구성 및 작업 세부 정보를 저장하는 시스템 데이터베이스는 자주 업데이트되지 않습니다. 시스템 데이터베이스/tempdb를 별도의 드라이브 또는 LUN에 배치합니다. 사용자 데이터베이스와 동일한 볼륨에 시스템 데이터베이스를 배치하지 마십시오. 사용자 데이터베이스는 다른 백업 정책을 가지고 있으며 사용자 데이터베이스 백업 빈도는 시스템 데이터베이스에 대해 동일하지 않습니다.</block>
  <block id="1be01a12dc77b3099b16d258c12db3f9" category="list-text">Microsoft SQL Server Availability Group 설정의 경우 복제본의 데이터 및 로그 파일을 모든 노드의 동일한 폴더 구조에 배치합니다.</block>
  <block id="a586cfc38b79b6539a9723b4d2f5af66" category="paragraph">사용자 데이터베이스 레이아웃을 서로 다른 볼륨으로 분리함으로써 얻을 수 있는 성능 이점 외에도 데이터베이스가 백업 및 복구에 필요한 시간에 큰 영향을 미칩니다. 데이터 및 로그 파일을 위한 별도의 볼륨을 가지고 있으면 여러 사용자 데이터 파일을 호스팅하는 볼륨에 비해 복원 시간이 크게 향상됩니다. 마찬가지로, I/O 집약적인 애플리케이션이 있는 사용자 데이터베이스는 백업 시간이 증가하기 쉽습니다. 백업 및 복원 방법에 대한 자세한 설명은 이 문서의 뒷부분에 나와 있습니다.</block>
  <block id="7f3611c256fabe67e4d74a6c70cfe9c5" category="admonition">SQL Server 2012(11.x), 시스템 데이터베이스(Master, Model, msdb 및 TempDB)부터 데이터베이스 엔진 사용자 데이터베이스는 SMB 파일 서버와 함께 스토리지 옵션으로 설치할 수 있습니다. 이는 독립 실행형 SQL Server 및 SQL Server 장애 조치 클러스터 설치 모두에 적용됩니다. 이를 통해 ONTAP용 FSx를 볼륨 용량, 성능 확장성 및 데이터 보호 기능 등 SQL Server가 활용할 수 있는 모든 성능 및 데이터 관리 기능과 함께 사용할 수 있습니다. 응용 프로그램 서버에서 사용하는 공유는 지속적으로 사용 가능한 속성 집합을 사용하여 구성해야 하며 볼륨은 NTFS 보안 스타일로 만들어야 합니다. ONTAP용 FSx에서 SMB 공유에 배치된 데이터베이스는 NetApp SnapCenter에서 사용할 수 없습니다.</block>
  <block id="9e45010900186b3cbbe04f954a6f3562" category="admonition">SnapCenter를 사용하여 백업을 수행하지 않는 SQL Server 데이터베이스의 경우 데이터와 로그 파일을 별도의 드라이브에 배치하는 것이 좋습니다. 데이터를 동시에 업데이트하고 요청하는 응용 프로그램의 경우 로그 파일은 쓰기 작업이 많고 데이터 파일(응용 프로그램에 따라 다름)은 읽기/쓰기 작업이 많이 사용됩니다. 데이터 검색을 위해 로그 파일이 필요하지 않습니다. 따라서 자체 드라이브에 있는 데이터 파일에서 데이터 요청을 처리할 수 있습니다.</block>
  <block id="41a264a984b034248073a80093913e60" category="admonition">새 데이터베이스를 만들 때는 데이터와 로그에 대해 별도의 드라이브를 지정하는 것이 좋습니다. 데이터베이스를 만든 후 파일을 이동하려면 데이터베이스를 오프라인으로 전환해야 합니다. Microsoft 권장 사항에 대한 자세한 내용은 별도의 드라이브에 데이터 및 로그 파일 배치 를 참조하십시오.</block>
  <block id="f4ea2029dd0e694cde33838315883930" category="example-title">SnapCenter 설치 및 설정</block>
  <block id="d39d360863f3fda3c5d615dc978e14ae" category="inline-link">SnapCenter 서버를 설치합니다</block>
  <block id="1155d165aa176b6275b67036497cd8e6" category="inline-link">Microsoft SQL Server용 SnapCenter 플러그인 설치</block>
  <block id="067f687182a68fccec4a3840e67fc889" category="paragraph">를 따릅니다<block ref="4144149cc24a91f915be2d3b14f23c22" category="inline-link-rx"></block> 및<block ref="7e24f6ba39e2c63512c07f20cb1a71c0" category="inline-link-rx"></block> SnapCenter를 설치하고 설정합니다.</block>
  <block id="3ab2ad2898088a813669db2948590562" category="paragraph">SnapCenter를 설치한 후 다음 단계를 수행하여 설정합니다.</block>
  <block id="dd0c654d5a8ede80984b9526335bddc9" category="list-text">자격 증명을 설정하려면 * 설정 * &gt; * 새로 만들기 * 를 선택한 다음 자격 증명 정보를 입력합니다.</block>
  <block id="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="paragraph"><block ref="ffe0bbfc2c08a0b0e98b92bee5d7a653" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c790771cb60de4cb4a7212e8db25bf3c" category="list-text">스토리지 시스템 &gt; 새로 만들기를 선택하여 스토리지 시스템을 추가하고 에서 ONTAP 스토리지 정보에 대해 적절한 FSx를 제공합니다.</block>
  <block id="28e78cc4b0ec3be7790fc763323de0f6" category="paragraph"><block ref="28e78cc4b0ec3be7790fc763323de0f6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c0e0b904d3c7826b806c48118543142c" category="list-text">호스트 * &gt; * 추가 * 를 선택하여 호스트를 추가한 다음 호스트 정보를 제공합니다. SnapCenter는 Windows 및 SQL Server 플러그인을 자동으로 설치합니다. 이 프로세스에는 시간이 다소 걸릴 수 있습니다.</block>
  <block id="0f2c351522362209f5160c4794708c97" category="paragraph"><block ref="0f2c351522362209f5160c4794708c97" category="inline-image-macro-rx" type="image"></block></block>
  <block id="23dd2805cf2d7b26334d0678ab4e99b4" category="paragraph">모든 플러그인을 설치한 후에는 로그 디렉토리를 구성해야 합니다. 트랜잭션 로그 백업이 상주하는 위치입니다. 호스트를 선택한 다음 로그 디렉토리 구성을 선택하여 로그 디렉토리를 구성할 수 있습니다.</block>
  <block id="5c5fb88ff793d01c8b1a283f1ee88749" category="admonition">SnapCenter는 호스트 로그 디렉토리를 사용하여 트랜잭션 로그 백업 데이터를 저장합니다. 호스트 및 인스턴스 레벨에 있습니다. SnapCenter에서 사용하는 각 SQL Server 호스트에는 로그 백업을 수행하도록 구성된 호스트 로그 디렉토리가 있어야 합니다. SnapCenter에는 데이터베이스 저장소가 있으므로 백업, 복원 또는 클론 복제 작업과 관련된 메타데이터가 중앙 데이터베이스 저장소에 저장됩니다.</block>
  <block id="0fc057cb39ba1a444dbc365c0161d31f" category="paragraph">호스트 로그 디렉토리의 크기는 다음과 같이 계산됩니다.</block>
  <block id="e067558831f8381f0970051292e0a02a" category="paragraph">호스트 로그 디렉토리의 크기 = ((시스템 데이터베이스 크기 + (최대 DB LDF 크기 × 일일 로그 변경률 %)) × (스냅샷 복사본 보존) ÷ (1 – LUN 오버헤드 공간 %)</block>
  <block id="1b5bc043867e6da78577571c1070e56a" category="paragraph">호스트 로그 디렉토리 사이징 공식은 다음을 가정합니다.</block>
  <block id="fa7afec3a90f55ad9aea3b76f336302f" category="list-text">tempdb 데이터베이스를 포함하지 않는 시스템 데이터베이스 백업입니다</block>
  <block id="f550013c290c4a21af7974f7440d758a" category="list-text">10% LUN 오버헤드 공간 전용 볼륨 또는 LUN에 호스트 로그 디렉토리를 저장합니다. 호스트 로그 디렉토리의 데이터 양은 백업 크기 및 백업 보존 일수에 따라 달라집니다.</block>
  <block id="83924e370463c681c401f53e2b4b3f2d" category="paragraph"><block ref="83924e370463c681c401f53e2b4b3f2d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="bd9dfb7fc6f502e70f86a8c1f2d66aa1" category="paragraph">LUN이 이미 용량 할당된 경우 호스트 로그 디렉토리를 나타내는 마운트 지점을 선택할 수 있습니다.</block>
  <block id="db38f16eb9374dba4590f05c202fa4a5" category="paragraph"><block ref="db38f16eb9374dba4590f05c202fa4a5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9a708f2af7ec6f7c7ae489cca832c811" category="paragraph">이제 SQL Server에 대한 백업, 복원 및 클론 작업을 수행할 준비가 되었습니다.</block>
  <block id="7bfeafaf85908b711b618c069c66e99c" category="example-title">SnapCenter를 사용하여 데이터베이스를 백업합니다</block>
  <block id="fc197cb26aec21d091eb6791c0d7cbff" category="paragraph">데이터베이스와 로그 파일을 FSx ONTAP LUN에 배치한 후 SnapCenter를 사용하여 데이터베이스를 백업할 수 있습니다. 다음 프로세스를 사용하여 전체 백업을 생성합니다.</block>
  <block id="f52f437d3282493fd1855bba366c482a" category="list-text">SnapCenter의 경우 RPO를 백업 빈도로 식별할 수 있습니다. 예를 들어, 데이터 손실을 최대 몇 분 이내로 줄이기 위해 백업 스케줄을 얼마나 자주 지정할지 알 수 있습니다. SnapCenter를 사용하면 5분마다 백업을 예약할 수 있습니다. 그러나 최대 트랜잭션 시간 동안 5분 내에 백업을 완료하지 못하거나 지정된 시간 내에 데이터 변화율이 더 높은 경우가 있을 수 있습니다. 가장 좋은 방법은 전체 백업 대신 빈번한 트랜잭션 로그 백업을 예약하는 것입니다.</block>
  <block id="7b99ea666dfc26516833c088400741e6" category="list-text">RPO 및 RTO를 처리하는 방법은 여러 가지가 있습니다. 이 백업 방식을 대체하는 방법 중 하나는 데이터 및 로그에 대해 서로 다른 간격을 두고 별도의 백업 정책을 사용하는 것입니다. 예를 들어, SnapCenter에서 로그 백업을 15분 간격으로 예약하고 데이터 백업을 6시간 간격으로 예약하는 경우가 있습니다.</block>
  <block id="14b0febccc904523871b9498c72ab705" category="list-text">스냅샷 최적화 및 관리할 작업 수를 위한 백업 구성에 리소스 그룹을 사용합니다.</block>
  <block id="45be64dc5372d4c03684e301633c794c" category="list-text">Resources * 를 선택한 다음 왼쪽 상단의 드롭다운 메뉴에서 * Microsoft SQL Server * 를 선택합니다. 리소스 새로 고침 * 을 선택합니다.</block>
  <block id="94cc612f3fcbd977b78ea3b7a422c531" category="paragraph"><block ref="94cc612f3fcbd977b78ea3b7a422c531" category="inline-image-macro-rx" type="image"></block></block>
  <block id="3b8d60492f611ef339bf79fdbeb56dda" category="list-text">백업할 데이터베이스를 선택한 다음 * Next * (다음 *) 및 (*+ *)를 선택하여 정책이 생성되지 않은 경우 추가합니다. 새 SQL Server 백업 정책 * 에 따라 새 정책을 만듭니다.</block>
  <block id="d99e4391045a563d9d1d2d78ddd2417a" category="paragraph"><block ref="d99e4391045a563d9d1d2d78ddd2417a" category="inline-image-macro-rx" type="image"></block></block>
  <block id="89f2e11b6c9317605c01622834d4853d" category="list-text">필요한 경우 검증 서버를 선택합니다. 이 서버는 전체 백업이 생성된 후 SnapCenter가 DBCC CHECKDB를 실행하는 서버입니다. 알림을 보려면 * 다음 * 을 클릭하고 검토하려면 * 요약 * 을 선택합니다. 검토 후 * 마침 * 을 클릭합니다.</block>
  <block id="fc2d6f88564b6e12fc40b19f28b7420d" category="paragraph"><block ref="fc2d6f88564b6e12fc40b19f28b7420d" category="inline-image-macro-rx" type="image"></block></block>
  <block id="919295932fd1084fb39c4a1be23b37ed" category="list-text">백업을 테스트하려면 * 지금 백업 * 을 클릭합니다. 팝업 창에서 * 백업 * 을 선택합니다.</block>
  <block id="93598d1ad688123817fda7d22fa0ac82" category="paragraph"><block ref="93598d1ad688123817fda7d22fa0ac82" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9c738a74e68034a98f4a38a1b41ef2d4" category="list-text">백업이 완료되었는지 확인하려면 * Monitor * 를 선택합니다.</block>
  <block id="710fa04917c218b834664e1f0d37a48c" category="paragraph"><block ref="710fa04917c218b834664e1f0d37a48c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="67459542a38abe56e00d4512bb475f05" category="list-text">SnapCenter에서 트랜잭션 로그 백업을 백업하면 복원 프로세스 중에 SnapCenter가 모든 백업 파일을 읽고 순서대로 자동으로 복원할 수 있습니다.</block>
  <block id="54d8d459dfb725a307f3bb54495de3e3" category="list-text">타사 제품을 백업에 사용하는 경우 SnapCenter에서 백업 복사를 선택하여 로그 시퀀스 문제를 방지하고 운영 환경으로 롤링하기 전에 복원 기능을 테스트합니다.</block>
  <block id="83b7215bcd7cc73d11f34b95b4026718" category="example-title">SnapCenter를 사용하여 데이터베이스를 복원합니다</block>
  <block id="7172cc34c1510c3891870c7c009c94e1" category="paragraph">EC2에서 FSx ONTAP와 SQL Server를 함께 사용할 경우 얻을 수 있는 주요 이점 중 하나는 각 데이터베이스 레벨에서 신속하고 세분화된 복원을 수행할 수 있다는 것입니다.</block>
  <block id="5afcacb3783eeead2b5317d1c455b3bc" category="paragraph">SnapCenter를 사용하여 개별 데이터베이스를 특정 시점 또는 최대 분으로 복원하려면 다음 단계를 완료하십시오.</block>
  <block id="a028f8b44f91b1338df98ed3237d093a" category="list-text">리소스 를 선택한 다음 복원할 데이터베이스를 선택합니다.</block>
  <block id="b5f8165159678d41fab115d5a8f013d2" category="paragraph"><block ref="b5f8165159678d41fab115d5a8f013d2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="eb395b310e199ca7ef6b36360302bc50" category="list-text">데이터베이스를 복원해야 하는 백업 이름을 선택한 다음 복원 을 선택합니다.</block>
  <block id="e99d25ac3998e8701f51a1990c8d8785" category="list-text">데이터베이스를 복원하려면 * 복원 * 팝업 창을 따르십시오.</block>
  <block id="8bdb6d6fe719d2506b9b5f86bda88b43" category="list-text">복구 프로세스가 성공적인지 확인하려면 * Monitor * 를 선택합니다.</block>
  <block id="e445e84ca78cd7f21cdd70356d211583" category="paragraph"><block ref="e445e84ca78cd7f21cdd70356d211583" category="inline-image-macro-rx" type="image"></block></block>
  <block id="459c0a4ca065bbbedc6304d4c6903cc5" category="example-title">크기가 작은 데이터베이스를 여러 개 사용하는 인스턴스에 대한 고려 사항입니다</block>
  <block id="0be8a2d7e2996a1641824fa4250d2fd3" category="paragraph">SnapCenter는 리소스 그룹 내의 인스턴스 또는 인스턴스 그룹에서 상당히 많은 수의 데이터베이스를 백업할 수 있습니다. 데이터베이스의 크기는 백업 시간의 주요 요인이 아닙니다. 백업 기간은 볼륨당 LUN 수, Microsoft SQL Server의 로드, 인스턴스당 총 데이터베이스 수, 특히 I/O 대역폭 및 사용량에 따라 달라질 수 있습니다. 인스턴스 또는 리소스 그룹에서 데이터베이스를 백업하도록 정책을 구성하는 동안에는 스냅샷 복사본당 백업된 최대 데이터베이스를 호스트당 100개로 제한하는 것이 좋습니다. 총 스냅샷 복사본 수가 1,023개 복사본 제한을 초과하지 않도록 해야 합니다.</block>
  <block id="33f3c567c61942e461392756abce64dc" category="paragraph">또한 각 데이터베이스 또는 인스턴스에 대해 여러 작업을 생성하는 대신 데이터베이스 수를 그룹화하여 병렬로 실행 중인 백업 작업을 제한하는 것이 좋습니다. 백업 기간의 성능을 최적화하려면 백업 작업 수를 한 번에 100개 이하의 데이터베이스를 백업할 수 있는 숫자로 줄입니다.</block>
  <block id="ea2e6af969539b040884e9a2ec1fcb49" category="paragraph">앞서 언급한 것처럼, I/O 사용은 백업 프로세스에서 중요한 요소입니다. 백업 프로세스는 데이터베이스에서 모든 I/O 작업이 완료될 때까지 일시 중지되도록 대기해야 합니다. I/O 작업이 매우 많은 데이터베이스는 다른 백업 시간으로 지연되거나 백업할 동일한 리소스 그룹 내의 다른 리소스에 영향을 주지 않도록 다른 백업 작업과 격리되어야 합니다.</block>
  <block id="e5ad8f936997e1328b1b169bf5c6cc8b" category="paragraph">호스트당 4개의 LUN과 생성된 볼륨당 1개의 LUN을 가정하여 인스턴스당 200개의 데이터베이스를 호스팅하는 Microsoft SQL Server 호스트가 6개 있는 환경의 경우 스냅샷 복사본당 백업된 최대 데이터베이스가 있는 전체 백업 정책을 100으로 설정합니다. 각 인스턴스에 200개의 데이터베이스가 2개의 LUN에 균등하게 분산되는 200개의 데이터 파일로 배치되고 200개의 로그 파일이 2개의 LUN에 균등하게 배포되며, 이는 볼륨당 100개의 파일입니다.</block>
  <block id="7804dbf4b7a37ec699db9a31f21bbea7" category="paragraph">세 개의 리소스 그룹을 생성하여 세 개의 백업 작업을 예약합니다. 각 그룹은 총 400개의 데이터베이스를 포함하는 두 인스턴스를 그룹화합니다.</block>
  <block id="e2ba702320599667af2b18f0fad307e0" category="paragraph">세 백업 작업을 모두 병렬로 실행하면 1,200개의 데이터베이스가 동시에 백업됩니다. 서버의 로드 및 I/O 사용량에 따라 각 인스턴스의 시작 및 종료 시간이 달라질 수 있습니다. 이 경우 총 24개의 스냅샷 복사본이 생성됩니다.</block>
  <block id="2d0d5c636161f9ca31c8ffbfa5ee5d7c" category="paragraph">전체 백업 외에도 중요 데이터베이스에 대한 트랜잭션 로그 백업을 구성하는 것이 좋습니다. 데이터베이스 속성이 전체 복구 모델로 설정되어 있는지 확인합니다.</block>
  <block id="aac1148375449745ddbbe1709a2375f5" category="list-text">백업에 포함된 데이터는 일시적이므로 백업에 tempdb 데이터베이스를 포함하지 마십시오. Snapshot 복제본이 생성되지 않는 스토리지 시스템 볼륨에 있는 LUN 또는 SMB 공유에 tempdb를 배치합니다.</block>
  <block id="16c5de1581b82a1f8657a3a98ac8fd34" category="list-text">I/O 집약적인 응용 프로그램이 있는 Microsoft SQL Server 인스턴스를 다른 백업 작업에서 격리하여 다른 리소스에 대한 전체 백업 시간을 줄여야 합니다.</block>
  <block id="a9a558ac49f24a2b078812205f07179c" category="list-text">동시에 백업할 데이터베이스 집합을 약 100개로 제한하고 나머지 데이터베이스 백업 집합을 스태그하여 동시 프로세스가 발생하지 않도록 합니다.</block>
  <block id="68086c26b8c1644dfe6ea7d6fb859641" category="list-text">Microsoft SQL Server 인스턴스에서 새 데이터베이스를 만들 때마다 SnapCenter에서는 자동으로 새 데이터베이스를 백업할 수 있도록 간주하므로 여러 데이터베이스 대신 리소스 그룹에서 Microsoft SQL Server 인스턴스 이름을 사용합니다.</block>
  <block id="5e5d80c17369e70061349fffb43b0aa8" category="list-text">데이터베이스 복구 모델을 전체 복구 모델로 변경하는 등 데이터베이스 구성을 변경하는 경우 즉시 백업을 수행하여 최신 복원 작업을 수행할 수 있습니다.</block>
  <block id="3dce7613a0d76dcf6fcb8e1daf396bbb" category="list-text">SnapCenter는 SnapCenter 외부에서 생성된 트랜잭션 로그 백업을 복원할 수 없습니다.</block>
  <block id="0007de7aba408b88984eb8eb18044303" category="list-text">FlexVol 볼륨을 클론 복제할 때 클론 메타데이터를 위한 충분한 공간이 있는지 확인합니다.</block>
  <block id="9416a94214ef699335d78087cd9f12c6" category="list-text">데이터베이스를 복원할 때 볼륨에서 충분한 공간을 사용할 수 있는지 확인합니다.</block>
  <block id="86e3f69ee9647210c14858984e2649ef" category="list-text">시스템 데이터베이스를 최소한 일주일에 한 번 관리하고 백업하기 위한 별도의 정책을 생성합니다.</block>
  <block id="330337562cd623f5deb5908d4e8af736" category="example-title">SnapCenter를 사용하여 데이터베이스 클론 생성</block>
  <block id="0a6bfc2082e52dc96430a6b7c0dfc7e7" category="paragraph">개발 또는 테스트 환경의 다른 위치로 데이터베이스를 복원하거나 비즈니스 분석을 위해 복사본을 생성하기 위해 NetApp 모범 사례는 클론 복제 방법을 활용하여 동일한 인스턴스 또는 대체 인스턴스에서 데이터베이스 복사본을 생성하는 것입니다.</block>
  <block id="0f462cc9e20017ed0597a6a199f57035" category="paragraph">ONTAP 환경의 FSx에서 호스팅되는 iSCSI 디스크에 500GB인 데이터베이스를 복제하는 데 일반적으로 5분도 걸리지 않습니다. 클론 생성이 완료되면 사용자는 클론 복제된 데이터베이스에서 필요한 모든 읽기/쓰기 작업을 수행할 수 있습니다. 대부분의 시간은 디스크 검사(diskpart)에 사용됩니다. NetApp 클론 복제 절차는 데이터베이스의 크기에 관계없이 일반적으로 2분 이내에 완료됩니다.</block>
  <block id="886ef20e3049a00bc0d9a1c734bb90da" category="paragraph">데이터베이스 클론 생성은 이중 방법으로 수행할 수 있습니다. 최신 백업에서 클론을 생성하거나 보조 인스턴스에서 최신 복사본을 사용할 수 있는 클론 라이프사이클 관리를 사용할 수 있습니다.</block>
  <block id="870999fc556eadefd7740857b96209c3" category="paragraph">SnapCenter를 사용하면 필요한 디스크에 클론 복제본을 마운트하여 보조 인스턴스에서 폴더 구조의 형식을 유지하고 백업 작업 스케줄을 계속 지정할 수 있습니다.</block>
  <block id="b2face8e1d4561b0ed5b594bfc4c0063" category="example-title">동일한 인스턴스에서 새 데이터베이스 이름으로 데이터베이스 클론 생성</block>
  <block id="4a3135e25926365f40a59fd88af69a44" category="paragraph">다음 단계를 사용하여 EC2에서 실행되는 동일한 SQL Server 인스턴스에서 데이터베이스를 새 데이터베이스 이름으로 복제할 수 있습니다.</block>
  <block id="4655b3c9fecfc4d22a59068929be2bec" category="list-text">리소스를 선택한 다음 클론을 생성해야 하는 데이터베이스를 선택합니다.</block>
  <block id="944b75c61851b0ebc427a8aedc83d6f3" category="list-text">클론 복제할 백업 이름을 선택하고 클론 을 선택합니다.</block>
  <block id="83d2194c2b06657769054af057f16b0a" category="list-text">백업 윈도우의 클론 지침에 따라 클론 프로세스를 완료합니다.</block>
  <block id="8fb624c33e03c9d016909a11c669125d" category="list-text">복제를 완료하려면 Monitor 를 선택합니다.</block>
  <block id="0b075fd84c4c4a47346b99d43f9260be" category="example-title">EC2에서 실행 중인 새 SQL Server 인스턴스로 데이터베이스 클론 생성</block>
  <block id="9451e65c3b1fc3fc6cf89a3fc9cf3cfd" category="paragraph">다음 단계는 EC2에서 실행되는 새 SQL Server 인스턴스에 데이터베이스를 복제하는 데 사용됩니다.</block>
  <block id="479cb4cd4ee76801e360aa03ddc20a3a" category="list-text">동일한 VPC에서 EC2에 새 SQL Server를 생성합니다.</block>
  <block id="163733cab5060ba4621bb642ba3870a0" category="list-text">iSCSI 프로토콜 및 MPIO를 활성화한 다음 "SQL Server용 볼륨 및 LUN 생성" 섹션의 3단계와 4단계에 따라 ONTAP용 FSx에 대한 iSCSI 연결을 설정합니다.</block>
  <block id="918269b8806c56ca4a0910482994e142" category="list-text">"SnapCenter 설치 및 설정" 섹션의 3단계를 따라 EC2의 새 SQL Server를 SnapCenter에 추가합니다.</block>
  <block id="e7130318e065eddd45ec86565b727731" category="list-text">리소스 &gt; 인스턴스 보기 를 선택한 다음 리소스 새로 고침 을 선택합니다.</block>
  <block id="8be42b1e845c00bcb04c11269072f895" category="list-text">리소스를 선택한 다음 복제할 데이터베이스를 선택합니다.</block>
  <block id="459801927d3c0bd5ddec9c1513f213ec" category="list-text">클론 복제할 백업 이름을 선택한 다음 클론 을 선택합니다.</block>
  <block id="030603235fe06c85ee75276379fe5baa" category="paragraph"><block ref="030603235fe06c85ee75276379fe5baa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45d50db35e68c1259b414779e24fdbf5" category="list-text">EC2 및 인스턴스 이름에 새 SQL Server 인스턴스를 제공하여 Clone from Backup 지침에 따라 클론 프로세스를 완료합니다.</block>
  <block id="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="paragraph"><block ref="78c549c0e0fcfc0dd6bb0c2e3a09a79f" category="inline-image-macro-rx" type="image"></block></block>
  <block id="20606e28a0d567be1dabd5cf50a2dc3b" category="section-title">부록</block>
  <block id="16dfbb688028526582ec31ab802b9589" category="example-title">부록 A: 클라우드 형성 템플릿에 사용할 YAML 파일</block>
  <block id="4c76ae47de51751cc57a4033d14f2f2a" category="paragraph">다음 .YAML 파일은 AWS 콘솔의 Cloud formation Template과 함께 사용할 수 있습니다.</block>
  <block id="76f249edcff2b74fcc17020455372f1b" category="inline-link"><block ref="76f249edcff2b74fcc17020455372f1b" category="inline-link-rx"></block></block>
  <block id="57ea11aec1064892e5db378204f829c4" category="list-text"><block ref="57ea11aec1064892e5db378204f829c4" category="inline-link-rx"></block></block>
  <block id="f6d8279768d195862ae69a3df8dd51ab" category="inline-link">이 GitHub 링크를 클릭합니다</block>
  <block id="4d39c6875a330594fc8521c48cadd7f6" category="paragraph">PowerShell을 사용하여 iSCSI LUN 생성 및 NetApp SnapCenter 설치를 자동화하려면 에서 리포를 클론 복제하십시오<block ref="445e758235a70998ddfcd1531f3ae35b" category="inline-link-rx"></block>.</block>
  <block id="00867e5f5ae22280c11a2626b65e657b" category="example-title">부록 B: 볼륨 및 LUN 프로비저닝을 위한 Powershell 스크립트</block>
  <block id="0826ee2b94a579e02e80bfcdf26c5648" category="paragraph">다음 스크립트는 볼륨 및 LUN을 프로비저닝하는 데 사용되며, 위에 제공된 지침에 따라 iSCSI를 설정하는 데도 사용됩니다. 두 개의 PowerShell 스크립트가 있습니다.</block>
  <block id="81e24f41fbaff249c9819985065173e3" category="list-text"><block ref="2a9a99327bbfb47d37ee76307e959506" prefix="" category="inline-code"></block></block>
  <block id="2ca8201f2a50e4aec0e5ba21f6afed4d" category="list-text"><block ref="d78c8f4fe63dbe3ffd666bbbaf054cd7" prefix="" category="inline-code"></block></block>
  <block id="6385631c0b330c166b540183cec5af78" category="paragraph">파일을 실행합니다<block ref="d2dd03515102971189549a37cb42eb14" prefix=" " category="inline-code"></block> 첫 번째 및 두 번째 스크립트는 서버가 재부팅된 후 자동으로 실행됩니다. 이러한 PowerShell 스크립트는 SVM에 대한 자격 증명 액세스로 인해 실행된 후에 제거할 수 있습니다.</block>
  <block id="d82c21a48349085e4fd93fb6712e3789" category="inline-link"><block ref="d82c21a48349085e4fd93fb6712e3789" category="inline-link-rx"></block></block>
  <block id="c745303ee8000be162517c239783af70" category="paragraph"><block ref="c745303ee8000be162517c239783af70" category="inline-link-rx"></block></block>
  <block id="c6e485d51bc9da63bcac29189dac0f3c" category="list-text">NetApp ONTAP용 FSx 시작하기</block>
  <block id="90572737558e59a2ecdd4618af07d6f3" category="inline-link"><block ref="90572737558e59a2ecdd4618af07d6f3" category="inline-link-rx"></block></block>
  <block id="7545caf3d97477d3c569d56c512074fa" category="paragraph"><block ref="7545caf3d97477d3c569d56c512074fa" category="inline-link-rx"></block></block>
  <block id="ad65cae8cf2bbd15ac77769974a440ce" category="list-text">SnapCenter 인터페이스의 개요입니다</block>
  <block id="59cbc11e5ccd87939e1b70af73ec1f01" category="inline-link"><block ref="c0a7623803fcfb4ac66342d4ae76ffff" category="inline-link-rx"></block></block>
  <block id="7ab2e91ecb30982855aa0dde8b78a361" category="paragraph"><block ref="89ba280df4e8c5cfd9bcd0f8c80d8ba5" category="inline-link-rx"></block></block>
  <block id="1bdf7559e69b81c007496a063e71bca0" category="list-text">SnapCenter 탐색 창 옵션을 둘러봅니다</block>
  <block id="6d5097a2c320359a8d212d07ea067dac" category="inline-link"><block ref="6d5097a2c320359a8d212d07ea067dac" category="inline-link-rx"></block></block>
  <block id="e0ae39eeb7c7d78d56a1292229d1277a" category="paragraph"><block ref="e0ae39eeb7c7d78d56a1292229d1277a" category="inline-link-rx"></block></block>
  <block id="d29a9430434c2654cce06036a4a478b2" category="list-text">SQL Server용 SnapCenter 4.0 플러그인을 설치합니다</block>
  <block id="520419781af4d13a8b33c054a304985b" category="inline-link"><block ref="520419781af4d13a8b33c054a304985b" category="inline-link-rx"></block></block>
  <block id="c2580a05e81a19c4b782e51932415e30" category="paragraph"><block ref="c2580a05e81a19c4b782e51932415e30" category="inline-link-rx"></block></block>
  <block id="f781a682aea107fb2cdda3a0c1fd3ac5" category="list-text">SnapCenter with SQL Server 플러그인을 사용하여 데이터베이스를 백업 및 복원하는 방법</block>
  <block id="285a27614fdeee7f22969646d33edc95" category="inline-link"><block ref="285a27614fdeee7f22969646d33edc95" category="inline-link-rx"></block></block>
  <block id="e1685ff793f13bbd2956f2156b0d5a67" category="paragraph"><block ref="e1685ff793f13bbd2956f2156b0d5a67" category="inline-link-rx"></block></block>
  <block id="c8e300ff66d94fe7668ff8d5d5e7f1c3" category="list-text">SnapCenter with SQL Server 플러그인을 사용하여 데이터베이스를 복제하는 방법</block>
  <block id="e482c7b116916a3d87aba2ab1365190b" category="inline-link"><block ref="e482c7b116916a3d87aba2ab1365190b" category="inline-link-rx"></block></block>
  <block id="b916fd292760d6ae01e337bf2a132edb" category="paragraph"><block ref="b916fd292760d6ae01e337bf2a132edb" category="inline-link-rx"></block></block>
  <block id="5d0dd45a93153403c2446a809dcb5fc3" category="sidebar">NetApp ONTAP용 Amazon FSx를 사용하는 AWS EC2의 SQL Server</block>
  <block id="dc406f8350f51d99347d8d026c0435a5" category="list-text">즉, 회전식 디스크에서 All-Flash로 전환하면 성능이 향상됩니다. 컴퓨팅 노드의 수는 병목 현상이 아니었습니다. NetApp All-Flash 스토리지를 사용하면 런타임 성능이 원활하게 확장됩니다.</block>
  <block id="67c8804409fa1f91b1b477b7c99d1d71" category="paragraph">저자: Chris Reno, Josh Powell, Suesh Thoppay - NetApp 솔루션 엔지니어링</block>
  <block id="37242160d8bbd9ad700322c3c2499272" category="section-title">가정, 전제 조건 및 구성 요소 개요</block>
  <block id="3ea8c755cca91dd6bbeec88e906263e9" category="paragraph">이 솔루션을 구축하기 전에 구성 요소 개요, 솔루션을 구축하는 데 필요한 전제 조건 및 이 솔루션을 문서화하는 데 필요한 가정을 검토하십시오.</block>
  <block id="7bcf43f481a8076036689561dce0e62d" category="inline-link-macro">DR 솔루션 요구 사항, 사전 요청 및 계획</block>
  <block id="684b2b80ca970225e77585d96775fc95" category="section-title">SnapCenter를 사용하여 DR 수행</block>
  <block id="782f10deb2809cc33e0082dbe9371f9b" category="paragraph">콘솔에 로그인한 후 백업 SQL Server 및 Oracle 데이터베이스에 대해 SnapCenter를 구성해야 합니다.</block>
  <block id="cf5c2d1e726e35ab57a75901cde43919" category="example-title">2차 Veeam Backup &amp; amp; Replication Server를 구축합니다</block>
  <block id="2b0e654aa884c8c50887b2eff59bc68f" category="example-title">Secondary Veeam Backup &amp; amp; Replication Server를 구성합니다</block>
  <block id="ed8b9b5c064b716d4c1d3f30a595410f" category="example-title">Veeam 백업 및 AMP, 복제</block>
  <block id="42c8c901c8d4c00c90f9f66d69df3cdb" category="example-title">Veeam Backup &amp; amp; 복제 서버입니다</block>
  <block id="17f0b02d31e76cb9b2878b4a08f19eb5" category="example-title">Veeam Backup &amp; amp; 복제 구성</block>
  <block id="53f8aa6361303e58854a4451a706df5e" category="doc">WP-7355: SnapCenter 플러그인 VMware vSphere - 제품 보안</block>
  <block id="ae9e79ac4b60eba67cf1c7508417b42c" category="paragraph">NetApp SnapCenter Plug-in for VMware vSphere 소프트웨어 엔지니어링은 다음과 같은 안전한 개발 활동을 사용합니다.</block>
  <block id="b25a1098aff7d0c5ee590f1e1a114bb9" category="list-text">* DAST(Dynamic Application Security Testing). * 실행 상태의 응용 프로그램에서 취약한 상태를 감지하도록 설계된 기술입니다. DAST는 웹 활성화 애플리케이션의 노출된 HTTP 및 HTML 인터페이스를 테스트합니다.</block>
  <block id="6cc1fee6b4fc48755d78e93170bbed93" category="list-text">* 타사 코드 통화. * 소프트웨어를 개발하고 오픈 소스 소프트웨어(OSS)를 사용하는 과정에서 제품에 통합된 OSS와 관련된 보안 취약점을 해결하는 것이 중요합니다. 이는 항상 OSS 구성 요소 버전에 새로 발견된 취약점이 보고될 수 있기 때문에 지속적으로 발생하는 것입니다.</block>
  <block id="87bd0fb9b4198f33535e0e1888a809f5" category="list-text">* 침투 테스트 * 침투 테스트는 시스템, 웹 응용 프로그램 또는 네트워크를 평가하여 공격자가 악용할 수 있는 보안 취약점을 찾는 프로세스입니다. NetApp의 침투 테스트(펜 테스트)는 승인되고 신뢰할 수 있는 타사 기업의 그룹에 의해 수행됩니다. 이러한 테스트 범위에는 정교한 악용 방법이나 도구를 사용하는 악의적인 침입자나 해커 같은 응용 프로그램 또는 소프트웨어에 대한 공격이 포함됩니다.</block>
  <block id="e3a3be4b4b04c5e0b6a5f1b5ea388380" category="list-text">제품 보안 문제의 대응 활동.* 보안 취약점은 회사 내외부에서 발견되며, 적절한 시기에 해결하지 못할 경우 NetApp의 평판에 심각한 위험을 초래할 수 있습니다. 이 프로세스를 용이하게 하기 위해 PSIRT(Product Security Incident Response Team)는 취약점을 보고 및 추적합니다.</block>
  <block id="e91db3b3278f7bd95cc704d74c5c9597" category="paragraph">VMware vSphere용 NetApp SnapCenter 플러그인에는 각 릴리즈마다 다음과 같은 보안 기능이 포함되어 있습니다.</block>
  <block id="4abd7d1d5d223683d3346671efb7e89c" category="list-text">* 제한된 셸 액세스. * SSH는 기본적으로 비활성화되어 있으며, VM 콘솔에서 활성화된 경우에만 1회 로그인이 허용됩니다.</block>
  <block id="8c264fa5ca2c588d960d98bd30cbc897" category="list-text">로그인 배너에 액세스 경고 * 로그인 프롬프트에 사용자 이름을 입력하면 다음 로그인 배너가 표시됩니다.</block>
  <block id="0d6633ada3a9803e206b2359d859e892" category="paragraph">사용자가 SSH 채널을 통해 로그인을 완료하면 다음 출력이 표시됩니다.</block>
  <block id="83e463bb73b12d9ca6e419327073c8a4" category="list-text">* 역할 기반 액세스 제어(RBAC). * 두 가지 유형의 RBAC 컨트롤이 NetApp ONTAP 도구에 연결되어 있습니다.</block>
  <block id="b883bf79639dfce77e395b8458ee69e4" category="list-text">기본 vCenter Server 권한</block>
  <block id="721796b1cb3468f0daf819180184d460" category="inline-link">역할 기반 액세스 제어(RBAC)</block>
  <block id="1d08c46b7567a29be0690a92b9722a58" category="list-text">VMware vCenter 플러그인별 권한 자세한 내용은 을 참조하십시오<block ref="f351263ad3706bd0a472039400dece78" category="inline-link-rx"></block>.</block>
  <block id="acab4c655c4a7b4db67fc07e22b86222" category="list-text">* 암호화된 통신 채널. * 모든 외부 통신은 TLS를 사용하여 HTTPS를 통해 이루어집니다.</block>
  <block id="47a37e2d5fc8b7c936ad9b2b7a569a08" category="paragraph">다음 표에는 열려 있는 포트 세부 정보가 나와 있습니다.</block>
  <block id="10bd16a816f831080065e807daa36a9a" category="cell">TCP v4/V6 포트 번호</block>
  <block id="d4a973e303ec37692cc8923e3148eef7" category="cell">8080</block>
  <block id="2c25c3d66f80eeaa8d6e5a144c6f942e" category="cell">OVA GUI에 대한 HTTPS 연결</block>
  <block id="14b3e670eec63cc0cc456fd904bbfbd9" category="cell">SSH(기본적으로 비활성화됨)</block>
  <block id="16fc18d787294ad5171100e33d05d4e2" category="cell">3306</block>
  <block id="4cbf9c234f6b34c242a110cb993252bd" category="cell">MySQL(내부 연결에만 해당, 외부 연결은 기본적으로 비활성화됨)</block>
  <block id="29ab4efbdb7c727c81ee1382593bc5e2" category="cell">Nginx(데이터 보호 서비스)</block>
  <block id="89f152cad33314315b4995ed1ca71535" category="inline-link">SSL 인증서를 생성 및/또는 VMware vSphere용 SnapCenter 플러그인(SCV)으로 가져오는 방법</block>
  <block id="450adc59e39f23172756ac9369494a2d" category="list-text">* CA(인증 기관) 서명 인증서 지원 * VMware vSphere용 SnapCenter 플러그인은 CA 서명 인증서의 기능을 지원합니다. 을 참조하십시오<block ref="9f83d87d5d9f604d96288df21d450fac" category="inline-link-rx"></block>.</block>
  <block id="05a1aa8021df4579874c4eeb8788e5c9" category="list-text">* 암호 정책 * 다음 암호 정책이 적용됩니다.</block>
  <block id="2c87609dbbc3630573c64e271de8207d" category="list-text">모든 자격 증명 정보는 SHA256 해싱을 사용하여 저장됩니다.</block>
  <block id="0f1a6fa0a65f9d5c3c4a16b070104d7a" category="list-text">*기본 운영 체제 이미지.* 이 제품은 제한된 액세스 및 쉘 액세스가 비활성화된 OVA용 Debian Base OS와 함께 제공됩니다. 이렇게 하면 공격 발생 가능성이 줄어듭니다. 모든 SnapCenter 릴리스 기본 운영 체제는 보안 범위를 극대화하기 위해 최신 보안 패치로 업데이트됩니다.</block>
  <block id="83cd5867ba912e517fa1100299fd1cf3" category="paragraph">NetApp은 VMware vSphere 어플라이언스인 SnapCenter 플러그인과 관련된 소프트웨어 기능 및 보안 패치를 개발한 다음 고객에게 번들 소프트웨어 플랫폼으로 배포합니다. 이러한 어플라이언스에는 특정 Linux 하위 운영 체제 종속성 및 NetApp의 독점 소프트웨어가 포함되어 있으므로 하위 운영 체제를 변경하지 않는 것이 좋습니다. 이 경우 NetApp 어플라이언스에 영향을 줄 가능성이 매우 높기 때문입니다. 이는 NetApp의 어플라이언스 지원 기능에 영향을 미칠 수 있습니다. 보안 관련 문제를 해결하기 위해 NetApp은 어플라이언스의 최신 코드 버전을 테스트하고 구축할 것을 권장합니다.</block>
  <block id="e50e258ecc9eaa88d6c653c3a24cb319" category="cell">2022년 3월</block>
  <block id="3107c066ea7eeb48bd5f87594a08fd7a" category="paragraph">&lt;&lt;&lt;&lt;&lt;&lt;&lt; head는 NetApp AFF 스토리지 컨트롤러에서 Hadoop 스토리지 계층화를 검증하고 SSD 및 SAS 드라이브를 사용하는 E-Series 스토리지 컨트롤러를 다양한 스토리지 정책으로 수행했습니다. AFF-A800의 Spark 클러스터에는 4개의 컴퓨팅 작업자 노드가 있는 반면 E-Series를 사용하는 클러스터는 8개의 노드를 가지고 있습니다. 주로 SSD(Solid-State Drive)와 HDD(하드 드라이브 디스크)의 성능을 비교합니다.</block>
  <block id="dba657bcaa661bcf5461e260c00e4f06" category="paragraph">NetApp AFF 스토리지 컨트롤러에서 Hadoop 스토리지 계층화를 검증하고 SSD 및 SAS 드라이브를 사용하는 E-Series 스토리지 컨트롤러를 다양한 스토리지 정책으로 수행했습니다. AFF-A800의 Spark 클러스터에는 4개의 컴퓨팅 작업자 노드가 있는 반면 E-Series를 사용하는 클러스터는 8개의 노드를 가지고 있습니다. 주로 SSD와 하드 드라이브 디스크의 성능을 비교하기 위해 이 작업을 수행하였습니다. &gt;&gt;&gt;&gt;&gt;&gt; a51c9ddf73ca69e1120ce05edc7b0b9607b96eae</block>
  <block id="f14f651fb8150de92c527d88344df494" category="list-text">TeraSort를 사용하면 SSD 구성에서 NL-SAS 구성에 비해 1TB의 데이터를 1138.36배 더 빠르게 정렬할 수 있습니다. 또한 SSD 구성에서는 컴퓨팅 노드 수의 절반과 디스크 드라이브 수의 절반을 사용했습니다(총 24개의 SSD 드라이브). 따라서 드라이브당 NL-SAS 구성보다 약 3배 빠른 속도를 제공합니다. &lt;&lt;&lt;&lt;&lt;&lt;&lt; 머리</block>
  <block id="52be2edb04819f386804af38bd53a55d" category="list-text">여기서 주목할 점은 회전식 디스크에서 All-Flash로 전환하여 성능을 향상할 수 있다는 것입니다. 컴퓨팅 노드의 수는 병목 현상이 아니었습니다. NetApp의 All-Flash 스토리지를 사용하면 런타임 성능이 원활하게 확장됩니다.</block>
  <block id="8cc25131075ed11b8263304fceebc5c6" category="list-text">NFS를 사용하면 데이터가 모두 함께 풀링되는 것과 기능적으로 동일하므로 워크로드에 따라 컴퓨팅 노드의 수를 줄일 수 있습니다. Apache Spark 클러스터 사용자는 컴퓨팅 노드의 수를 변경할 때 데이터를 수동으로 재조정할 필요가 없습니다.</block>
  <block id="6ed171c4fe1ca516676ea457d91105b1" category="list-text">NFS를 사용하면 데이터가 모두 함께 풀링되는 것과 기능적으로 동일하므로 워크로드에 따라 컴퓨팅 노드의 수를 줄일 수 있습니다. Apache Spark 클러스터 사용자는 컴퓨팅 노드 수를 변경할 때 데이터를 수동으로 재조정할 필요가 없습니다. &gt;&gt;&gt;&gt;&gt;&gt; a51c9ddf73ca69e1120ce05edc7b0b9607b96eae</block>
  <block id="2668a3fec665f31a26e9e428b4ee62a7" category="sidebar">SnapCenter 플러그인 VMware vSphere - 제품 보안</block>
  <block id="50b6e1c7f2e81842d993d8ce88acc979" category="summary">ONTAP는 SAN 환경을 위한 iSCSI, FC(파이버 채널), FCoE(Fibre Channel over Ethernet) 또는 NVMe/FC(Non-Volatile Memory Express over Fibre Channel)와 NFS(v3 및 v4.1), 게스트 연결을 위한 SMB 또는 S3와 같은 가상화에 사용되는 모든 주요 스토리지 프로토콜을 지원합니다. 고객은 자체 환경에 가장 적합한 프로토콜을 자유롭게 선택할 수 있으며 필요에 따라 단일 시스템에서 프로토콜을 결합할 수 있습니다.</block>
  <block id="d7a198a9254afae95101f5ba8a96e769" category="paragraph">ONTAP는 SAN 환경을 위한 iSCSI, FC(파이버 채널), FCoE(Fibre Channel over Ethernet) 또는 NVMe/FC(Non-Volatile Memory Express over Fibre Channel)와 NFS(v3 및 v4.1), 게스트 연결을 위한 SMB 또는 S3와 같은 가상화에 사용되는 모든 주요 스토리지 프로토콜을 지원합니다. 고객은 자체 환경에 가장 적합한 프로토콜을 자유롭게 선택할 수 있으며 필요에 따라 단일 시스템에서 프로토콜을 결합할 수 있습니다. 예를 들어, 소수의 iSCSI LUN 또는 게스트 공유로 NFS 데이터 저장소의 일반 사용을 늘릴 수 있습니다.</block>
  <block id="2df283d70436fd2d0a853af9fae00a91" category="list-text">* NetApp 스냅샷 복사본 * ONTAP은 스냅샷 복사본을 생성하거나 사용할 때 성능 저하 없이 VM 또는 데이터 저장소의 즉각적인 스냅샷 복사본을 제공합니다. 패치 적용 전 또는 간단한 데이터 보호를 위해 VM의 복원 지점을 만드는 데 사용할 수 있습니다. 이는 VMware(정합성 보장) 스냅샷과 다릅니다. ONTAP 스냅샷 복사본을 만드는 가장 쉬운 방법은 VMware vSphere용 SnapCenter 플러그인을 사용하여 VM 및 데이터 저장소를 백업하는 것입니다.</block>
  <block id="0fed44d392929d099987f70fe23074b4" category="list-text">* NetApp 볼륨 암호화 및 NetApp 애그리게이트 암호화. * NetApp 암호화 옵션은 유휴 데이터를 보호하기 위해 간편한 소프트웨어 기반 암호화를 제공합니다.</block>
  <block id="1a4c4db8b74f04b9da9ab150ff36e301" category="list-text">* REST 및 Ansible. * 사용<block ref="71191ff17e34498b2463e6167736896a" category="inline-link-rx"></block> 스토리지 및 데이터 관리를 자동화하고, 및 를 누릅니다<block ref="d4fc0de110866702e0b8608590b39b64" category="inline-link-rx"></block> ONTAP 시스템의 구성 관리를 위한 것입니다.</block>
  <block id="86544be11c52b782f03ad1ff879f872d" category="paragraph">일부 ONTAP 기능은 vSphere 워크로드에 적합하지 않습니다. 예를 들어, ONTAP 9.8 이전의 FlexGroup 기술은 전체 클론 복제를 지원하지 않았으며 vSphere에서 테스트되지 않았습니다(vSphere와 함께 사용하는 최신 정보는 FlexGroup 섹션 참조). FlexCache 기술은 읽기 작업이 많은 워크로드에 맞게 설계되었기 때문에 vSphere에도 적합하지 않습니다. 캐시가 오리진에서 분리되어 양쪽에서 NFS 데이터 저장소 오류가 발생하는 경우 쓰기에 문제가 발생할 수 있습니다.</block>
  <block id="f364e3337f5237c93d7b5439c82d444b" category="paragraph">VMware vSphere용 ONTAP 툴은 ONTAP 스토리지를 vSphere와 함께 사용하기 위한 일련의 툴입니다. 이전에 VSC(Virtual Storage Console)라고도 하는 vCenter 플러그인을 사용하면 SAN 또는 NAS를 사용하든지 스토리지 관리 및 효율성 기능을 단순화하고, 가용성을 향상하고, 스토리지 비용과 운영 오버헤드를 줄일 수 있습니다. Best Practice를 사용하여 데이터 저장소를 프로비저닝하고 NFS 및 블록 스토리지 환경에 대한 ESXi 호스트 설정을 최적화합니다. 이러한 모든 이점을 누리게 하려면 ONTAP 소프트웨어를 실행하는 시스템에서 vSphere를 사용할 때 이러한 ONTAP 툴을 모범 사례로 사용하는 것이 좋습니다. 여기에는 서버 어플라이언스, vCenter, VASA Provider 및 Storage Replication Adapter를 위한 사용자 인터페이스 확장이 포함됩니다. ONTAP 툴의 거의 모든 기능을 대부분의 최신 자동화 툴에서 사용 가능한 단순한 REST API를 사용하여 자동화할 수 있습니다.</block>
  <block id="0b266371a133b176a2ee883ccf72b46c" category="list-text">* vCenter UI 확장. * ONTAP 툴 UI 확장은 호스트 및 스토리지 관리, 정보 포틀릿 및 vCenter UI에서 직접 기본 경고 기능을 관리할 수 있는 사용이 간편한 컨텍스트 기반 메뉴를 횡령함으로써 운영 팀과 vCenter 관리자의 업무를 간소화합니다.</block>
  <block id="e08c666b5127e745f8aacbacfce37dcf" category="list-text">* VASA Provider for ONTAP. * VASA Provider for ONTAP는 VMware VASA(vStorage APIs for Storage Awareness) 프레임워크를 지원합니다. 이 제품은 구축 편의성을 위해 VMware vSphere용 ONTAP 툴의 일부로 단일 가상 어플라이언스로 제공됩니다. VASA Provider는 vCenter Server를 ONTAP와 연결하여 VM 스토리지를 프로비저닝하고 모니터링할 수 있도록 지원합니다. 이를 통해 VVol(VMware Virtual Volumes) 지원, 스토리지 기능 프로필 관리, 개별 VM VVol 성능, 용량 모니터링 및 프로파일 규정 준수에 대한 경보를 수행할 수 있습니다.</block>
  <block id="1c7bb8764fc089dda8481678ad1ea0b5" category="list-text">* 스토리지 복제 어댑터. * SRA는 VMware SRM(Site Recovery Manager)과 함께 사용되어 운영 사이트와 재해 복구 사이트 간의 데이터 복제를 관리하고 DR 복제본을 중단 없이 테스트합니다. 검색, 복구 및 재보호 작업을 자동화할 수 있습니다. Windows SRM 서버 및 SRM 어플라이언스에는 SRA 서버 어플라이언스와 SRA 어댑터가 모두 포함됩니다.</block>
  <block id="eff6699ec911b615a51eb7e9e0d89970" category="paragraph">VMware VAAI용 NetApp NFS 플러그인은 ESXi 호스트에서 ONTAP의 NFS 데이터 저장소와 함께 VAAI 기능을 사용할 수 있도록 지원하는 플러그인입니다. 클론 작업을 위한 복제 오프로드, 일반 가상 디스크 파일의 공간 예약, 스냅샷 복사본 오프로드를 지원합니다. 복사 작업을 스토리지로 오프로드하는 것이 반드시 완료되기만은 않습니다. 그러나 이 작업은 네트워크 대역폭 요구 사항을 줄이고 CPU 주기, 버퍼 및 큐와 같은 호스트 리소스를 오프로드합니다. VMware vSphere용 ONTAP 툴을 사용하여 ESXi 호스트 또는 지원되는 경우 VLCM(vSphere Lifecycle Manager)에 플러그인을 설치할 수 있습니다.</block>
  <block id="082e2767897584434269db14d4ceda54" category="sidebar">VMware 가상화를 위한 새로운 기능</block>
  <block id="839a1261c70db1f3c149f86d56e21d15" category="cell">2023년 1월 12일</block>
  <block id="70542da4927194cf41c777029ebe56be" category="cell">블로그 추가: NetApp ONTAP용 Amazon FSx와 NetApp SnapCenter를 사용하여 SQL Server 워크로드를 보호합니다</block>
  <block id="577322186c067590a18f8891be57e7e4" category="inline-link-macro">NetApp ONTAP용 Amazon FSx와 함께 NetApp SnapCenter를 사용하여 SQL Server 워크로드를 보호합니다</block>
  <block id="c1b7f59fc598d7a811682707bcd4eb40" category="list-text"><block ref="c1b7f59fc598d7a811682707bcd4eb40" category="inline-link-macro-rx"></block></block>
  <block id="af8dcb8c7a1e8b7e614e570806d8dcee" category="paragraph">7개의 프로토콜을 사용하여 ONTAP 소프트웨어를 실행하는 시스템의 데이터 저장소에 VMware vSphere를 연결합니다.</block>
  <block id="a7c815fafe60ae637d38216fa6300395" category="list-text">FCP</block>
  <block id="8b7c42123642e2e4ea7dd426aeb2de58" category="list-text">NVMe/TCP</block>
  <block id="f7d773fd2896401c143676940bc001fc" category="list-text">NFS v3</block>
  <block id="0b99b245267ef194ca3b9f6e694b0983" category="list-text">NFS v4.1</block>
  <block id="cfa070ed8af17c3125cfd1530fbd387a" category="paragraph">FCP, FCoE, NVMe/FC, NVMe/TCP 및 iSCSI는 vSphere VMFS(Virtual Machine File System)를 사용하여 ONTAP FlexVol 볼륨에 포함된 ONTAP LUN 또는 NVMe 네임스페이스 내에 VM을 저장하는 블록 프로토콜입니다. VMware는 vSphere 7.0부터 운영 환경에서는 더 이상 소프트웨어 FCoE를 지원하지 않습니다. NFS는 VMFS 없이 VM을 데이터 저장소(단순한 ONTAP 볼륨)에 배치하는 파일 프로토콜입니다. SMB(CIFS), iSCSI, NVMe/TCP 또는 NFS를 게스트 OS에서 ONTAP로 직접 사용할 수도 있습니다.</block>
  <block id="7469c178e150e10730dcab1094765f10" category="paragraph">다음 표에는 ONTAP에서 vSphere가 지원하는 기존 데이터 저장소 기능이 나와 있습니다. 이 정보는 VVOL 데이터 저장소에 적용되지 않지만 일반적으로 지원되는 ONTAP 릴리즈를 사용하는 vSphere 6.x 이상 릴리즈에 적용됩니다. 상담도 할 수 있습니다<block ref="26c5407c98ec413c85131fd8c0d178b4" category="inline-link-rx"></block> 특정 제한 사항을 확인하기 위한 특정 vSphere 릴리즈</block>
  <block id="6151632541dcd80356c6c76b34d69d0c" category="cell">NVMe - oF</block>
  <block id="18263a30df8afc60a733e59c60676ac0" category="cell">VMFS를 참조하십시오</block>
  <block id="aa23f9914ce1939ea7a4d479edfdc915" category="cell">호스트당 LUN 1024개</block>
  <block id="1af3b27207afc48a363629a315d76b59" category="cell">서버당 LUN 1024개</block>
  <block id="0705fd627c25b5fba17cd9a022ed7d72" category="cell">서버당 256개의 Names입니다</block>
  <block id="b4fb1d41fedaec79072964cbb4d16e3d" category="cell">최대 데이터 저장소 파일 크기입니다</block>
  <block id="fe299bb060ce245b8fe190de21d3978e" category="cell">대용량 파일이 활성화된 ONTAP 9.12.1RC1 이상 포함 16TB 또는 62TB</block>
  <block id="ca6e77250a239af7b4aed9a1ac058825" category="cell">자동 협상</block>
  <block id="bad19bc2587cd465cab5cec5a13aa306" category="cell">NFS.MaxQueueDepth in 을 참조하십시오<block ref="0391a4aaf03ed2bf80fb4efb215797d0" category="inline-link-rx"></block>.</block>
  <block id="d6407966cf588d8d78d4f7e65f1ea6fd" category="cell">V3만 해당**</block>
  <block id="50ed43e1a7a22335069a344bc706b600" category="cell">예, 새로운 HPP(High Performance Plugin) 사용</block>
  <block id="5663fa28fe2a703e07072185e3a90a94" category="paragraph">* NetApp은 VMFS 데이터 저장소에 다중 writer 지원 VMDK가 아닌 Microsoft 클러스터에 게스트 내 iSCSI를 사용할 것을 권장합니다. 이 접근 방식은 Microsoft 및 VMware에서 완벽하게 지원되며 ONTAP(사내 또는 클라우드의 ONTAP 시스템에 대한 SnapMirror)를 통해 뛰어난 유연성을 제공하고 쉽게 구성 및 자동화할 수 있으며 SnapCenter를 통해 보호할 수 있습니다. vSphere 7은 새로운 클러스터 VMDK 옵션을 추가합니다. 이는 클러스터 VMDK를 지원하는 FC 프로토콜을 통해 데이터 저장소를 제공해야 하는 멀티writer 지원 VMDK와 다릅니다. 기타 제한 사항이 적용됩니다. VMware 를 참조하십시오<block ref="b158594c147457b5b6417413cb30f800" category="inline-link-rx"></block> 구성 지침 설명서.</block>
  <block id="e2bd40041a6472b580305ce9017b0b2e" category="paragraph">** NVMe-oF 및 NFS v4.1을 사용하는 데이터 저장소에는 vSphere 복제가 필요합니다. 스토리지 기반 복제는 SRM에서 지원되지 않습니다.</block>
  <block id="b8c499c7b537f5bd4e51b0a6d6a1e9d0" category="list-text">ONTAP NFS 데이터 저장소를 사용하여 vSphere를 구축하면 관리가 용이한 고성능 구축이 가능하기 때문에 블록 기반 스토리지 프로토콜로는 얻을 수 없는 VM-데이터 저장소 비율을 제공할 수 있습니다. 이 아키텍처를 사용하면 데이터 저장소 밀도가 10배 증가하여 데이터 저장소 수가 서로 관련지어 줄어들 수 있습니다. 더 큰 데이터 저장소가 스토리지 효율성에 이점을 제공하고 운영 이점을 제공할 수 있지만, 하드웨어 리소스의 최대 성능을 얻기 위해 최소 4개의 데이터 저장소(FlexVol 볼륨)를 사용하여 VM을 단일 ONTAP 컨트롤러에 저장하는 것이 좋습니다. 이 방법을 사용하면 복구 정책이 서로 다른 데이터 저장소를 설정할 수도 있습니다. 비즈니스 요구 사항에 따라 다른 사람보다 더 자주 백업하거나 복제할 수 있는 경우도 있습니다. FlexGroup 볼륨은 설계상 확장되므로 성능을 위해 여러 데이터 저장소가 필요하지 않습니다.</block>
  <block id="241f8fed1e3a823fcd4d0c1eb705b1a2" category="list-text">FlexVol 볼륨은 ONTAP 9.8 FlexGroup 볼륨, NFS 데이터 저장소부터 사용하는 것이 좋습니다. qtree와 같은 다른 ONTAP 스토리지 컨테이너는 현재 VMware vSphere용 ONTAP 툴에서 지원되지 않으므로 일반적으로 권장되지 않습니다. 단일 볼륨에 여러 qtree로 데이터 저장소를 구축하면 데이터 저장소 수준 할당량 또는 VM 파일 클론의 이점을 누릴 수 있는 고도로 자동화된 환경에 유용할 수 있습니다.</block>
  <block id="964a81e46088ae1cc6306072464a9d73" category="list-text">또는 FC, iSCSI 또는 FCoE에서 액세스하는 LUN으로 VMFS 데이터 저장소를 구성할 수도 있습니다. VMFS를 사용하면 클러스터의 모든 ESX 서버에서 기존 LUN에 동시에 액세스할 수 있습니다. VMFS 데이터 저장소의 크기는 최대 64TB이고 최대 32개의 2TB LUN(VMFS 3) 또는 단일 64TB LUN(VMFS 5)으로 구성될 수 있습니다. ONTAP의 최대 LUN 크기는 대부분의 시스템에서 16TB이고, All-SAN 어레이 시스템에서 128TB입니다. 따라서 16TB LUN 4개를 사용하여 대부분의 ONTAP 시스템에서 VMFS 5 데이터 저장소의 최대 크기를 생성할 수 있습니다. 여러 LUN(하이엔드 FAS 또는 AFF 시스템 사용)을 사용하는 높은 I/O 워크로드에 성능 이점이 있을 수 있지만, 데이터 저장소 LUN을 생성, 관리 및 보호하고 가용성 위험을 높이는 관리 복잡성이 추가되어 이러한 이점을 얻을 수 있습니다. 일반적으로 각 데이터 저장소마다 큰 단일 LUN을 사용하는 것이 좋으며 16TB 데이터 저장소를 넘어서는 특별한 요구 사항이 있는 경우에만 확장할 것을 권장합니다. NFS와 마찬가지로, 단일 ONTAP 컨트롤러에서 성능을 최대화하기 위해 여러 데이터 저장소(볼륨)를 사용하는 것을 고려합니다.</block>
  <block id="040ffbbbbeda558bdae1e07f5371b4f5" category="list-text">Cisco의 vPC(Virtual PortChannel)와 같은 다중 섀시 링크 집선 그룹 접근 방식을 사용하여 두 개의 개별 스위치 섀시에서 포트의 링크 집계를 지원하는 스위치를 사용합니다.</block>
  <block id="19d137845c7f6687c99b386dfad0aa97" category="list-text">LACP가 구성된 dvSwitch 5.1 이상을 사용하지 않는 한 ESXi에 연결된 스위치 포트에 대해 LACP를 사용하지 않도록 설정합니다.</block>
  <block id="30254a2bb3e4b3b958b06d08c724e7db" category="list-text">LACP를 사용하여 IP 해시를 사용하는 동적 멀티모드 인터페이스 그룹을 통해 ONTAP 스토리지 시스템에 대한 링크 애그리게이트를 생성합니다.</block>
  <block id="d608421cceb8e4c584a2a32d9127879e" category="list-text">ESXi에서 IP 해시 팀 구성 정책을 사용합니다.</block>
  <block id="ba78d695573c8d4f1205452c675fa539" category="paragraph">* SVM LIF는 VLAN, MTU 및 기타 설정이 있는 포트, 인터페이스 그룹 또는 VLAN 인터페이스에 연결됩니다. 하지만 SVM 레벨에서 설정을 관리하지 않습니다.</block>
  <block id="631e164314a103fe3183b00b759057b2" category="paragraph">SLM은 특정 LUN에 경로를 알리는 노드를 제한합니다. NetApp 모범 사례로서, SVM당 노드당 하나 이상의 LIF를 가지고 SLM을 사용하여 LUN 및 HA 파트너를 호스팅하는 노드에 공고되는 경로를 제한하는 것입니다. 다른 경로는 있지만 기본적으로 광고되지 않습니다. SLM 내에서 ADD 및 REMOVE 노드 인수로 보급된 경로를 수정할 수 있습니다. 8.3 이전 릴리즈에서 생성된 LUN은 모든 경로를 광고하고 호스팅 HA 쌍의 경로만 광고하도록 수정해야 합니다. SLM에 대한 자세한 내용은 의 섹션 5.9를 참조하십시오<block ref="c6b12416d518b4689065ffe16afe88db" category="inline-link-rx"></block>. 이전 portset 방법을 사용하여 LUN에 사용 가능한 경로를 더 줄일 수도 있습니다. Portsets는 igroup의 이니시에이터가 LUN을 볼 수 있는 가시적인 경로의 수를 줄여 줍니다.</block>
  <block id="7b997b3be9c993d49799dd9d71d8c3f6" category="list-text">VMware는 VMware Infrastructure 3 이후 NFSv3을 지원했습니다. vSphere 6.0은 NFSv4.1에 대한 지원을 추가하여 Kerberos 보안과 같은 일부 고급 기능을 지원합니다. NFSv3에서는 클라이언트측 잠금을 사용하는 경우 NFSv4.1은 서버 측 잠금을 사용합니다. ONTAP 볼륨은 두 프로토콜을 통해 내보낼 수 있지만 ESXi는 하나의 프로토콜을 통해서만 마운트할 수 있습니다. 이 단일 프로토콜 마운트는 다른 ESXi 호스트가 다른 버전을 통해 동일한 데이터 저장소를 마운트하는 것을 배제하지 않습니다. 모든 호스트가 동일한 버전과 동일한 잠금 스타일을 사용하도록 마운트할 때 사용할 프로토콜 버전을 지정해야 합니다. 호스트 간에 NFS 버전을 혼합하지 마십시오. 가능한 경우 호스트 프로필을 사용하여 규정 준수 여부를 확인하십시오.</block>
  <block id="d8119941da55a672db49a624330ea7f0" category="list-text">NFS 내보내기 정책은 vSphere 호스트의 액세스를 제어하는 데 사용됩니다. 여러 볼륨(데이터 저장소)에 하나의 정책을 사용할 수 있습니다. NFSv3에서 ESXi는 sys(UNIX) 보안 스타일을 사용하며 VM을 실행하려면 루트 마운트 옵션이 필요합니다. ONTAP에서 이 옵션을 수퍼 유저라고 하며, 수퍼유저 옵션을 사용할 때 익명 사용자 ID를 지정할 필요가 없습니다. 에 대해 다른 값을 사용하여 정책 규칙을 내보냅니다<block ref="ea72d12ecaa06afdb0c8a3b15e485e95" prefix=" " category="inline-code"></block> 및<block ref="df809a941c1287d18c08bb5927b639dc" prefix=" " category="inline-code"></block> ONTAP 툴을 사용하여 SVM 검색 문제를 일으킬 수 있습니다. 샘플 정책은 다음과 같습니다.</block>
  <block id="0bbc71e6a4ea49af70dd616d3807e524" category="list-text">익명 UID</block>
  <block id="49bb4e84b97bfe104e9fe7eb7df07a38" category="list-text">NFS 데이터 저장소 볼륨은 SVM의 루트 볼륨에서 접합되므로 ESXi에서 루트 볼륨에 액세스하여 데이터 저장소 볼륨을 탐색하고 마운트해야 합니다. 루트 볼륨과 데이터 저장소 볼륨의 연결이 중첩된 다른 볼륨에 대한 내보내기 정책에는 읽기 전용 액세스를 허용하는 ESXi 서버에 대한 규칙 또는 규칙이 포함되어야 합니다. 다음은 VAAI 플러그인을 사용하는 루트 볼륨에 대한 샘플 정책입니다.</block>
  <block id="8c93fb3ff528165613797962f5a0ed9c" category="list-text">액세스 프로토콜: NFS(NFS3 및 nfs4 모두 포함)</block>
  <block id="80e6a4f964e826c69c1c62bd5ea67590" category="list-text">RW 액세스 규칙: 사용 안 함(루트 볼륨에 대한 최상의 보안)</block>
  <block id="f96625174b4a06d13267f9b0a5a96d59" category="list-text">슈퍼유저:sys(VAAI를 사용하는 루트 볼륨에도 필요)</block>
  <block id="23aa7b9aeed3fba2a1ec43e630313af7" category="list-text">플러그인을 사용하여 VMware 클러스터용 데이터 저장소를 생성할 때 단일 ESX Server가 아닌 클러스터를 선택합니다. 이 옵션을 선택하면 데이터 저장소가 클러스터의 모든 호스트에 자동으로 마운트됩니다.</block>
  <block id="1abaee3673de53b378351ee9dc679daa" category="list-text">VMware 및 NetApp은 현재 일반적인 다중 경로 네트워킹 접근 방식을 지원하지 않습니다. NFSv4.1에서는 NetApp이 pNFS를 지원하는 반면 VMware는 세션 트렁킹을 지원합니다. NFSv3은 볼륨에 대한 여러 물리적 경로를 지원하지 않습니다. ONTAP 9.8이 포함된 FlexGroup의 경우 간접 액세스의 영향은 일반적으로 최소(마이크로초)이므로 VMware vSphere용 ONTAP 툴을 단일 마운트로 설정하는 것이 좋습니다. 라운드 로빈 DNS를 사용하여 FlexGroup의 다른 노드에 있는 LIF에 ESXi 호스트를 배포할 수 있지만, 이 경우 VMware vSphere용 ONTAP 툴 없이 FlexGroup를 생성하고 마운트해야 합니다. 그러면 성능 관리 기능을 사용할 수 없습니다.</block>
  <block id="88ac8db9784908706c34feb6caee9044" category="paragraph"><block ref="88ac8db9784908706c34feb6caee9044" category="inline-link-macro-rx"></block></block>
  <block id="03b125f503e8b797be1fe5a21a10d220" category="summary">이 섹션에서는 azacsnap 도구와 스냅샷 백업, 복원 및 스냅샷을 사용하여 Azure BLOB로 Oracle 데이터베이스를 보호하는 방법에 대해 설명합니다.</block>
  <block id="b47faaf85acf415e557bd0b669342659" category="doc">Azure 클라우드에서 Oracle 데이터베이스를 보호합니다</block>
  <block id="cec4dbc9c066ab7b22ef743151be75eb" category="paragraph"><block ref="cec4dbc9c066ab7b22ef743151be75eb" category="inline-link-macro-rx"></block></block>
  <block id="06a2961d48a854a133ddfe05c7912732" category="section-title">AzAcSnap 툴을 사용하여 Oracle 데이터베이스를 스냅샷으로 백업합니다</block>
  <block id="30462dbcf926561966ea824afd44e355" category="paragraph">Azure Application-Consistent Snapshot Tool(AzAcSnap)은 스토리지 스냅샷을 생성하기 전에 애플리케이션 정합성 보장 상태로 전환하는 데 필요한 모든 오케스트레이션을 처리하여 타사 데이터베이스의 데이터를 보호하는 명령줄 도구입니다. 그런 다음 데이터베이스를 운영 상태로 되돌릴 수 있습니다.</block>
  <block id="07612935f16f2665ef52f490f9b1f43b" category="paragraph">Oracle의 경우 데이터베이스를 백업 모드로 전환하여 스냅샷을 생성한 다음 데이터베이스를 백업 모드에서 해제합니다.</block>
  <block id="070d0b63c9af5e43d43102c1869d4262" category="section-title">데이터 및 로그 볼륨을 백업합니다</block>
  <block id="7dd57abd8929da4f18cc94d1940161a1" category="paragraph">스냅샷 명령을 실행하는 단순 셸 스크립트를 사용하여 데이터베이스 서버 호스트에서 백업을 설정할 수 있습니다. 그런 다음 crontab에서 실행되도록 스크립트를 예약할 수 있습니다.</block>
  <block id="087916fda35dba838b68193ed8bc3aeb" category="paragraph">일반적으로 백업 빈도는 원하는 RTO 및 RPO에 따라 달라집니다. 스냅샷을 자주 생성하면 스토리지 공간이 더 많이 사용됩니다. 백업 빈도와 공간 소비 빈도는 서로 상충됩니다.</block>
  <block id="e2ece357797b760af1c814632edcf99d" category="paragraph">데이터 볼륨은 일반적으로 로그 볼륨보다 더 많은 스토리지 공간을 사용합니다. 따라서 데이터 볼륨에 대해 몇 시간마다 스냅샷을 생성하고 로그 볼륨에 대해 15-30분마다 더 자주 스냅샷을 생성할 수 있습니다.</block>
  <block id="2a2c2eb0d2bde8c24cc55a11862ca857" category="paragraph">백업 스크립트 및 스케줄링에 대한 다음 예를 참조하십시오.</block>
  <block id="e048ccd48425229cea678849ba68a190" category="paragraph">데이터 볼륨 스냅샷의 경우:</block>
  <block id="f0d6345b8e5345f55c21610283eaeedd" category="paragraph">로그 볼륨 스냅샷의 경우:</block>
  <block id="68b7e37ef318c0e56eabf3e1aded4216" category="paragraph">crontab 일정: 15,30,45 * * * * * * /home/azacsnap/snap_log.sh 0 * /2 * * * /home/azacsnap/snap_data.sh</block>
  <block id="adf4ba1e0f3190afb18557f038ae1ecf" category="admonition">백업 설정 시<block ref="8ed8c6bfea85d72bc4a36772490109c7" prefix=" " category="inline-code"></block> 구성 파일, 바이너리 볼륨을 포함한 모든 데이터 볼륨을 에 추가합니다<block ref="0fb9dff864caebba259b119756a2ce17" prefix=" " category="inline-code"></block> 및 모든 로그 볼륨을 에<block ref="5e5fb0a2540d102aeebc3dac60712494" prefix=" " category="inline-code"></block>. 스냅샷의 최대 보존은 250개입니다.</block>
  <block id="a93091ed018686dcf478589ba04fd6f6" category="section-title">스냅샷을 확인합니다</block>
  <block id="8a46f2968d5dc184634cff75cd1b8b8e" category="paragraph">Azure Portal &gt; Azure NetApp Files/volumes로 이동하여 스냅샷이 성공적으로 생성되었는지 확인합니다.</block>
  <block id="3542e11f657b779fcef8cc387987e9f2" category="inline-image-macro">이 스크린샷은 스냅샷 목록에 있는 두 개의 파일을 보여 줍니다.</block>
  <block id="c2dd243538b072e19882bdcd6ac2c6c9" category="inline-image-macro">이 스크린샷은 스냅샷 목록에 있는 8개의 파일을 보여 줍니다.</block>
  <block id="af143d815dcd69aae3ff8d8bdde9fd58" category="paragraph"><block ref="bf87ea8d7de67f1fdc628b6bb4b400e5" category="inline-image-macro-rx" type="image"></block>
<block ref="1d682e6513772285b95199f0646e28da" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7479b02641600cb6142d8594c1360d11" category="section-title">Oracle 로컬 백업에서 복원 및 복구</block>
  <block id="76265d8fce7f282b6ff5a8581df8879c" category="paragraph">스냅샷 백업의 주요 이점 중 하나는 소스 데이터베이스 볼륨과 함께 존재하고, 운영 데이터베이스 볼륨을 거의 즉시 롤백할 수 있다는 것입니다.</block>
  <block id="878609e3e12819fffdd7247406f655be" category="section-title">기본 서버에서 Oracle의 복원 및 복구</block>
  <block id="8733b7b64c8d2c32caa423c7eb2955fc" category="paragraph">다음 예에서는 동일한 Oracle 호스트의 Azure 대시보드 및 CLI에서 Oracle 데이터베이스를 복원 및 복구하는 방법을 보여 줍니다.</block>
  <block id="aa30a622663e0f34541394e008fe82cd" category="list-text">복원할 데이터베이스에 테스트 테이블을 만듭니다. [oracao-ora01~]$sqlplus/as sysdba</block>
  <block id="ea16560565f3889db4dabf938628b462" category="paragraph">SQL* Plus: 릴리즈 19.0.0.0.0 - 운영 날짜: 월 12:02:35 2022 버전 19.8.0.0.0</block>
  <block id="0409b2fce118cc126a532dea158d2943" category="paragraph">sql&gt; 테이블 testsnapshot(id integer, event varchar(100), dt timestamp) 생성</block>
  <block id="bec6da77877c0793c1d3eb6c6896e98e" category="paragraph">테이블이 생성되었습니다.</block>
  <block id="a5b83945adfd5370663cb2d9c4f31d09" category="paragraph">sql&gt; testsnapshot 값에 삽입(1, '스냅샷 복원을 검증하기 위한 데이터 마커 삽입', sysdate)</block>
  <block id="6ba18fa8fa7d170dfd8fc80f0f3d39f7" category="paragraph">1개의 행이 생성되었습니다.</block>
  <block id="d1d2dcb121f8bf8fd39724ea075c6409" category="paragraph">sql &gt; 커밋;</block>
  <block id="a92090dde5e820fde0a68705ee3f2bd0" category="paragraph">커밋이 완료되었습니다.</block>
  <block id="fd9736dfc88a182f9cb6e5f6a2b97487" category="paragraph">sql &gt; testsnapshot에서 * 선택;</block>
  <block id="2817b9cf9fc0cd0d8bf9fb03acbfc93f" category="list-text">스냅샷 백업 후에 테이블을 삭제합니다.</block>
  <block id="07b56c53a9fec8c477afb0cb5f2394af" category="paragraph">[oracao-ora01~]$sqlplus/as sysdba</block>
  <block id="dcd4d50ecf59b4752c161f0ddc44df44" category="paragraph">SQL* Plus: 릴리스 19.0.0.0.0 - 제품 릴리스 SEP 13 14:20:22 2022 버전 19.8.0.0.0</block>
  <block id="bee0f13528c2f6f5b67053dc1e942328" category="paragraph">sql &gt; drop table testsnapshot;</block>
  <block id="cd85f26775e453b2177d5fcc6265b31d" category="paragraph">테이블이 떨어졌습니다.</block>
  <block id="07e18ec921a195478cdbab47d8d68d89" category="paragraph">sql&gt; testsnapshot에서 * 를 선택합니다. testsnapshot * 오류에서 * 를 선택합니다. 1: ORA-00942: 테이블 또는 뷰가 없습니다</block>
  <block id="f06f4fbf6e3e0e45b0d4b241ceaf19c9" category="paragraph">sql&gt; shutdown immediate; Database closed. (즉시 종료 데이터베이스가 마운트 해제되었습니다. Oracle 인스턴스가 종료되었습니다. SQL&gt; 종료와 Oracle Database 19c Enterprise Edition 릴리스 19.0.0.0.0 - 프로덕션 버전 19.8.0.0.0의 연결이 끊겼습니다</block>
  <block id="09d4fe137595af1cc975247ba704462d" category="list-text">Azure NetApp Files 대시보드에서 로그 볼륨을 마지막으로 사용 가능한 스냅샷으로 복구합니다. 볼륨 되돌리기 * 를 선택합니다.</block>
  <block id="33ba8417b2640d4172513bbf9cbc3e55" category="inline-image-macro">이 스크린샷은 ANF 대시보드의 볼륨에 대한 스냅샷 재버전의 방법을 보여 줍니다.</block>
  <block id="546b967f1ce32832a90c77282f0cdf2b" category="paragraph"><block ref="546b967f1ce32832a90c77282f0cdf2b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="4b728fe18b10b9b611a1d3ab6acc0df9" category="list-text">되돌리기 볼륨을 확인하고 * Revert * 를 클릭하여 볼륨 재버전을 최신 사용 가능한 백업으로 완료합니다.</block>
  <block id="5c7deeb27ad1e0e4c1d6d52b2a2a1bfc" category="inline-image-macro">"이 작업을 수행하시겠습니까?" 페이지를 참조하십시오.</block>
  <block id="ef80226ab5a9d2865852e606297da2cf" category="paragraph"><block ref="ef80226ab5a9d2865852e606297da2cf" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18b9906dd2c95b12fdb987b7c2aa9917" category="list-text">데이터 볼륨에 대해 동일한 단계를 반복하고 백업에 복구할 테이블이 포함되어 있는지 확인합니다.</block>
  <block id="a38e609b2fd5c2dee1b4ccb1cbbac7d4" category="inline-image-macro">이 스크린샷은 ANF 대시보드의 데이터 볼륨에 대한 스냅샷 재버전의 방법을 보여줍니다.</block>
  <block id="f0d819988fad0119995986a2bdfd9ad6" category="paragraph"><block ref="f0d819988fad0119995986a2bdfd9ad6" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fc824d4f774a64498f954eb2ebbc093b" category="list-text">볼륨 버전을 다시 확인하고 "되돌리기"를 클릭합니다.</block>
  <block id="5e2296a09eabbd34b62da3492091ff33" category="inline-image-macro">"이 작업을 수행하시겠습니까?" 데이터 볼륨 스냅샷 재버전을 위한 페이지입니다.</block>
  <block id="af5f9a99ee2d86856d0e2477e417dc4c" category="paragraph"><block ref="af5f9a99ee2d86856d0e2477e417dc4c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="170b40e31285910539e0d464f2bf33a6" category="list-text">컨트롤 파일의 복제본이 여러 개 있는 경우 컨트롤 파일을 다시 동기화하고 이전 컨트롤 파일을 사용 가능한 최신 복제본으로 대체합니다.</block>
  <block id="952cd3804f479f3c31f123d064ccbdf5" category="paragraph">[Oracle@acao-ora01~]$mv/u02/oradata/ORATST/control01.ctl/u02/oradata/ORATST/control01.ctl[Oracle@acao-ora01~]$cp/u03/orareco/ORATactl/controltl/acutl.tl/attrl/a02</block>
  <block id="bd99bc18393147b05e3f350eb6a61f47" category="list-text">Oracle 서버 VM에 로그인하고 sqlplus를 사용하여 데이터베이스 복구를 실행합니다.</block>
  <block id="125ab5cbfb90c4a6d038bcca4da6fdc4" category="paragraph">SQL* Plus: 릴리스 19.0.0.0.0 - 제품 릴리스 SEP 13 15:10:17 2022 버전 19.8.0.0.0</block>
  <block id="010621501012cd31b6666d17dad683d2" category="paragraph">유휴 인스턴스에 연결되었습니다.</block>
  <block id="6bd3f70e5ab38ca26f8cabd390e15fc0" category="paragraph">sql&gt; 시작 마운트; Oracle 인스턴스가 시작되었습니다.</block>
  <block id="424459a4363a5afdd1e45d31fcd11efe" category="paragraph">전체 시스템 전역 영역 6442448984바이트 고정 크기 8910936바이트 가변 크기 1090519040바이트 데이터베이스 버퍼 5335154688바이트 다시 실행 버퍼 7864320바이트 데이터베이스가 마운트됨 sql&gt; 취소할 때까지 백업 제어 파일을 사용하여 데이터베이스 복구; ORA-00279: 변경 3188523 스레드 1에 대해 필요 ORA-00289: 제안: /u03/orareco/ORATST/archivelog/09_13/O1_mf_1_43_22rnj280 스레드 시퀀스에 대해 3188523</block>
  <block id="db9afd3f7adaff3fe1135208fa6b6a09" category="paragraph">로그 지정: {&lt;RET&gt;=Sugested|FileName|Auto|CANCEL}</block>
  <block id="abc467423916c8ee7c16f566b4ab4ca8" category="paragraph">ORA-00279: change 3188862가 2022-09:09:13 스레드 1에 대해 생성됨 10:01:20 필요 ORA-00289: 제안: /u03/orareco/ORATST/archivelog/2022_09_13/O1_mf_1_44_29f2lgb5_.arc_318280.torg.torg.log에서 더 이상 복구: /318928.torg.torg.2c.1c.2c.turg.2c.318-0028</block>
  <block id="479d2dfa77fdcde3bfd41fcdebbca1ff" category="paragraph">ORA-00279: change 3193117이 스레드 1에 대해 생성되었습니다. ORA-00289: 제안: /u03/orareco/ORATST/archivelog/2022_09_13/O1_mf_1_45__29h6qyw_.arc.00280.arc.org에서 더 이상 복구 필요.3800_3708.torg.torg.0_211_3708.torg.wa_3708.torg.tnd.wa_2nd.wa_2nd.toto.toto.toto.toto.toto.toto_3119에 대한 /3119에 대한 /u03_celo.w</block>
  <block id="c76ff2f7e10a42adf7faec8f9e6faeab" category="paragraph">Ora-00279: change 3193440이 2022-09에서 생성되었습니다. 12:01:20이 스레드 1에 필요합니다. ORA-00289: 제안: /u03/orareco/ORATST/archivelog/2022_09_13/O1_mf_1_46_%u_.arc ORA-00280: ORT445.RECOG.RECONO.THE_OVERYOVERYOMEO/O.45.A/TRACEMORA/TRACER.0.A/OVERYA/OTRACE.A.A.A.0.A/OVERYA/O.01.A/OTRACULLOG에 대해 더 긴 파일 필요.0.A/O.01_</block>
  <block id="0e98028493ec8c4a1d181c0d71c3ec7b" category="paragraph">로그 지정: {&lt;RET&gt;=Sugested|FileName|Auto|CANCEL} 미디어 복구가 취소되었습니다. sql &gt; alter database open resetlogs;</block>
  <block id="f6c9ea366c01da7d664a8c7c3813e0bd" category="paragraph">데이터베이스가 변경되었습니다.</block>
  <block id="8ad5254ade1fed8d3ccc482196b4c36c" category="paragraph">이 화면에서는 삭제된 테이블이 로컬 스냅샷 백업을 사용하여 복구되었음을 보여 줍니다.</block>
  <block id="34d73a671fa85d8d86ba1eff63b238d8" category="paragraph"><block ref="34d73a671fa85d8d86ba1eff63b238d8" category="inline-link-macro-rx"></block></block>
  <block id="0c55b956af322a2409f5dd75af116fee" category="doc">WP-7357: EC2 및 FSx Best Practices Introduction에서 Oracle Database Deployment를 참조하십시오</block>
  <block id="b985336298cf9391b91c898572090625" category="summary">이 섹션에서는 Azure 가상 머신 및 Azure NetApp Files 스토리지를 사용하는 Oracle 데이터베이스 구축 및 데이터 보호 솔루션 아키텍처에 대해 설명합니다.</block>
  <block id="fc6024ee9167308c3126789695e7353f" category="paragraph"><block ref="fc6024ee9167308c3126789695e7353f" category="inline-link-macro-rx"></block></block>
  <block id="91e17bfb5f535513b5320d68f6afe1fc" category="paragraph">다음 아키텍처 다이어그램은 Azure VM 인스턴스 및 Azure NetApp Files 스토리지에 가용성이 높은 Oracle 데이터베이스를 구축하는 방법을 보여 줍니다.</block>
  <block id="520c5c426000f1dbbd8ac385d5547603" category="paragraph">환경 내에서 Oracle 컴퓨팅 인스턴스는 Azure 서비스 VM 콘솔을 통해 구축됩니다. 콘솔에서 여러 Azure 인스턴스 유형을 사용할 수 있습니다. NetApp은 예상 워크로드를 충족하는 데이터베이스 기반의 Azure VM 인스턴스를 구축할 것을 권장합니다.</block>
  <block id="9e20ded809aa2fa1bd072f48ceacfdd8" category="paragraph">반면에 Oracle 데이터베이스 스토리지는 Azure 콘솔에서 사용 가능한 Azure NetApp Files 서비스와 함께 구축됩니다. 그런 다음 Oracle 바이너리, 데이터 또는 로그 볼륨이 제시되고 Azure VM 인스턴스 Linux 호스트에 마운트됩니다.</block>
  <block id="6b5cae77dbc9c4b759bf654b117eb10b" category="inline-image-macro">이 이미지는 기본 사이트, 대기 사이트 및 각 사이트의 VNET 피어링 간의 관계를 보여 줍니다. 이는 4개의 개별 가상 네트워크를 형성합니다.</block>
  <block id="2246b51fdf61c77213e0ce37d743cd03" category="paragraph"><block ref="2246b51fdf61c77213e0ce37d743cd03" category="inline-image-macro-rx" type="image"></block></block>
  <block id="03aa17a1290e1122adecd07d53463cde" category="paragraph">여러 측면에서 Azure 클라우드에 Azure NetApp Files를 구현하는 것은 RAID 및 이중 컨트롤러와 같은 다양한 내장 이중화 기능을 갖춘 사내 ONTAP 데이터 스토리지 아키텍처와 매우 유사합니다. 재해 복구의 경우 대기 사이트를 여러 지역에서 설정할 수 있으며 애플리케이션 수준 복제(예: Oracle Data Guard)를 사용하여 데이터베이스를 기본 사이트와 동기화할 수 있습니다.</block>
  <block id="6f1714a5ced243b141295d01d4038364" category="paragraph">Oracle 데이터베이스 구현 및 데이터 보호에 대한 테스트 검증에서 Oracle 데이터베이스는 다음 다이어그램에 표시된 대로 단일 Azure VM에 구축됩니다.</block>
  <block id="fef3344ae2f384e724a169b6e9d90be7" category="inline-image-macro">이 이미지는 VNET 피어링을 사용하는 단일 Azure VM의 구성을 보여 주어 두 개의 개별 가상 네트워크를 만듭니다.</block>
  <block id="f3699a22a9267b8e767816c81f821522" category="paragraph"><block ref="f3699a22a9267b8e767816c81f821522" category="inline-image-macro-rx" type="image"></block></block>
  <block id="69cf5342936c24c9fac1c6529c4f825f" category="paragraph">Azure Oracle 환경은 데이터베이스 구축, 백업, 복구 및 데이터베이스 마이그레이션을 위해 NetApp에서 제공하는 툴 키트를 사용하여 자동화를 위해 Ansible 컨트롤러 노드를 사용하여 관리할 수 있습니다. Oracle Azure VM 인스턴스 운영 체제 커널 또는 Oracle 패칭에 대한 모든 업데이트를 병렬로 수행하여 운영 및 대기 상태를 동기화할 수 있습니다. 실제로 초기 툴킷을 손쉽게 확장하여 필요한 경우 일상적인 Oracle 작업을 수행할 수 있습니다. CLI Ansible 컨트롤러를 설정하는 데 도움이 필요한 경우 을 참조하십시오 <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block> 시작하십시오.</block>
  <block id="149b87e0b981bcf1e3d652831c207e04" category="inline-link-macro">다음: 고려할 요인.</block>
  <block id="0a9d288b4b8679857f2d7e7f0d5a63f6" category="paragraph"><block ref="0a9d288b4b8679857f2d7e7f0d5a63f6" category="inline-link-macro-rx"></block></block>
  <block id="41f2543265fcbcf566ce925409c1bfbb" category="summary">이 섹션에서는 Oracle 데이터베이스를 사내에서 Azure NetApp Files로 또는 그 반대로 마이그레이션하는 방법에 대해 자세히 설명합니다.</block>
  <block id="3b99478aefcc6039ddcb29f19ce3f1ee" category="doc">사내에서 Azure 클라우드로 데이터베이스 마이그레이션</block>
  <block id="964310198f864c746c945ff1c6fffe3f" category="inline-link-macro">이전: 데이터베이스 보호.</block>
  <block id="413dcfd081f137889743981159ac9abe" category="paragraph"><block ref="413dcfd081f137889743981159ac9abe" category="inline-link-macro-rx"></block></block>
  <block id="3c2b924258f32094eb64883db57a778a" category="paragraph">Oracle이 단일 인스턴스 데이터베이스를 단계적으로 개발하기로 결정함에 따라 많은 조직에서 단일 인스턴스 Oracle 데이터베이스를 멀티 테넌트 컨테이너 데이터베이스로 전환했습니다. 이렇게 하면 최대 가용성 옵션을 사용하여 PDB라는 컨테이너 데이터베이스의 하위 집합을 클라우드로 손쉽게 재배치할 수 있으므로 마이그레이션 중에 가동 중지 시간이 최소화됩니다.</block>
  <block id="a221bb2d4b0b28bb7e9aa40527e36333" category="paragraph">그러나 여전히 Oracle 데이터베이스의 단일 인스턴스가 있는 경우 PDB 재배치를 시도하기 전에 먼저 Oracle 데이터베이스를 멀티 테넌트 컨테이너 데이터베이스로 변환할 수 있습니다.</block>
  <block id="3312d9383c6e42558bb6c7ffa86498b5" category="paragraph">다음 섹션에서는 어느 시나리오에서든 온프레미스 Oracle 데이터베이스를 Azure 클라우드로 마이그레이션하는 방법에 대해 자세히 설명합니다.</block>
  <block id="d7acbe14b605ece64e94636c2ac85151" category="section-title">멀티 테넌트 CDB에서 단일 인스턴스 비 CDB를 PDB로 변환합니다</block>
  <block id="b65ba7cc82289837e3a44b6025b8a104" category="paragraph">여전히 단일 인스턴스 Oracle 데이터베이스가 있는 경우 Oracle은 얼마 지나지 않아 단일 인스턴스 데이터베이스 지원을 중지하므로 클라우드로 마이그레이션할지 여부와 관계없이 멀티 테넌트 컨테이너 데이터베이스로 변환해야 합니다.</block>
  <block id="60a4157f0722b484d4ce9ec02662db31" category="paragraph">다음 절차에서는 단일 인스턴스 데이터베이스를 플러깅 지원 데이터베이스 또는 PDB로 컨테이너 데이터베이스에 연결합니다.</block>
  <block id="aefccbe3e9382cbdd83d84fee06a408d" category="list-text">단일 인스턴스 데이터베이스와 동일한 호스트에 별도의 셸 컨테이너 데이터베이스를 구축합니다<block ref="e1f651debac4f720c13ae930ff3ca14a" prefix=" " category="inline-code"></block>.</block>
  <block id="182e093a477c76844c12680be3deb7a4" category="list-text">단일 인스턴스 데이터베이스를 종료하고 읽기 전용 모드로 다시 시작합니다.</block>
  <block id="48270a516aeb2dd47c2b7f5d897c3182" category="list-text">를 실행합니다<block ref="707fc638546e97f4dca068fcf2fbe277" prefix=" " category="inline-code"></block> 데이터베이스 메타데이터를 생성하는 절차입니다.</block>
  <block id="61c2d2d903cc3e2bc374cc66b3a1572d" category="list-text">단일 인스턴스 데이터베이스를 종료합니다.</block>
  <block id="d0e90ac40083de7010746f1c7afa8680" category="list-text">컨테이너 데이터베이스를 시작합니다.</block>
  <block id="c9b14b140c5af8df85a71e71e823fcd9" category="list-text">를 실행합니다<block ref="6f6e7bfe46efb74f46338dcd4b8d7530" prefix=" " category="inline-code"></block> 비 CDB가 CDB와 호환되는지 여부를 확인하는 기능입니다.</block>
  <block id="b4579eff709cfd4a9e9d9b3c7823a470" category="paragraph">출력이 Yes인 경우 비 CDB가 호환되며 다음 단계를 계속 진행할 수 있습니다.</block>
  <block id="b788542aadbeda07cae67fad51f01ecf" category="paragraph">결과가 NO인 경우 비 CDB는 호환되지 않으며 를 확인할 수 있습니다<block ref="40bcd9431704d488bfba8de25bdd0469" prefix=" " category="inline-code"></block> 호환되지 않는 이유를 보려면 를 참조하십시오. 계속하기 전에 모든 위반 사항을 해결해야 합니다. 예를 들어, 업그레이드 또는 OPatch 유틸리티를 실행하여 모든 버전 또는 패치 불일치를 해결해야 합니다. 위반 사항을 수정한 후 를 실행합니다<block ref="6f6e7bfe46efb74f46338dcd4b8d7530" prefix=" " category="inline-code"></block> 비 CDB가 CDB와 호환되는지 확인하기 위해 다시 한 번 확인합니다.</block>
  <block id="3dc81f6d88ee2f38ca30676e4b371634" category="list-text">단일 인스턴스 비 CDB를 연결합니다.</block>
  <block id="10a9ce9a6e151e6ff04bee976e0cb1de" category="admonition">호스트에 공간이 충분하지 않으면 를 참조하십시오<block ref="4777c7eb130280b37f5b4b3abde7c586" prefix=" " category="inline-code"></block> 옵션을 사용하여 PDB를 생성할 수 있습니다. 이 경우 PDB에 원래 데이터 파일이 사용되었기 때문에 PDB로 플러그인을 연결한 후 단일 인스턴스 비 CDB를 사용할 수 없습니다. 변환 전에 백업을 생성하여 문제가 발생할 경우 다시 되돌릴 수 있도록 합니다.</block>
  <block id="03d9f2c68151dce9edd03b346e5b110c" category="list-text">소스 단일 인스턴스 비 CDB와 대상 CDB 간의 버전이 다른 경우 변환 후 PDB 업그레이드를 시작합니다. 동일한 버전 변환의 경우 이 단계를 건너뛸 수 있습니다.</block>
  <block id="81954d0087f2bc7590c39792b2d3ff79" category="paragraph">에서 업그레이드 로그 파일을 검토합니다<block ref="8940bd010306ed7bc730469a2815003c" prefix=" " category="inline-code"></block> 디렉토리.</block>
  <block id="65f9a981d9b9caaa37a227c9d787c280" category="list-text">플러그형 데이터베이스를 열고 PDB 플러그인 위반을 확인한 다음 잘못된 개체를 다시 컴파일합니다.</block>
  <block id="f4d5586e12195159e664b1f0a78cccd3" category="list-text">실행<block ref="30636d635a272a80dff68679e08f1c7a" prefix=" " category="inline-code"></block> 데이터 사전을 업데이트합니다.</block>
  <block id="182d7c995640cc8ef16b728a670fbe58" category="paragraph">컨테이너 DB를 종료하고 다시 시작합니다. ncdb가 제한된 모드에서 제외되었습니다.</block>
  <block id="d6af386b8be94481db3de6778b3fc24a" category="section-title">PDB 재배치를 통해 온프레미스 Oracle 데이터베이스를 Azure로 마이그레이션합니다</block>
  <block id="da5d44e97cbc406251573e1664b5e1f0" category="paragraph">Maximum-availability 옵션을 사용하는 Oracle PDB 재배치에서는 PDB 핫 클론 기술을 사용합니다. 이 기술을 사용하면 PDB가 타겟으로 복제되는 동안 소스 PDB를 사용할 수 있습니다. 전환 시 세션 및 연결이 대상 PDB로 자동으로 리디렉션됩니다. 따라서 재배치되는 PDB의 크기와 관계없이 가동 중지 시간이 최소화됩니다. NetApp은 마이그레이션 절차를 자동화하는 Ansible 기반 툴킷을 제공합니다.</block>
  <block id="a8efacce1c06e5f64504448dec25740a" category="list-text">동일한 버전 및 패치 수준을 가진 Azure VM의 Azure 퍼블릭 클라우드에서 CDB를 생성합니다.</block>
  <block id="0f09a4e81820f79a89d0b433bb0de6ca" category="list-text">Ansible 컨트롤러에서 자동화 툴킷 복사본을 복제합니다.</block>
  <block id="33abd0ac6a3fb7ef8c104725e8360e85" category="list-text">README 파일의 지침을 읽습니다.</block>
  <block id="59082266ab8171963eb8785041055ee1" category="list-text">이름 확인을 위해 소스 및 타겟 Oracle 서버와 DB 서버 호스트의 구성 파일 모두에 대해 Ansible 호스트 변수 파일을 구성합니다.</block>
  <block id="166811e58fa2fd17b3ab3305ca4b1948" category="list-text">Ansible 컨트롤러에 필수 구성 요소를 설치합니다.</block>
  <block id="e40dd1f176a77cef20eb421dee4fea9f" category="list-text">온프레미스 서버에 대해 마이그레이션 전 작업을 실행합니다.</block>
  <block id="aba7f3209eb8c49aca729c7368fb42fe" category="admonition">admin 사용자는 sudo 권한이 있는 온-프레미스 Oracle 서버 호스트의 관리 사용자입니다. admin 사용자는 암호로 인증됩니다.</block>
  <block id="a1da14dd2e192d36a7fe7bae327c2b23" category="list-text">온프레미스에서 대상 Azure Oracle 호스트로 Oracle PDB 재배치를 실행합니다.</block>
  <block id="39f1871870cabd138bd313c450662e67" category="admonition">Ansible 컨트롤러는 사내 또는 Azure 클라우드에 위치할 수 있습니다. 이 컨트롤러는 사내 Oracle 서버 호스트 및 Azure Oracle VM 호스트에 연결해야 합니다. Oracle 데이터베이스 포트(예: 1521)는 사내 Oracle 서버 호스트와 Azure Oracle VM 호스트 간에 열려 있습니다.</block>
  <block id="63a48a0f7ee4b39ef32c11b92acc2baa" category="section-title">추가 Oracle 데이터베이스 마이그레이션 옵션</block>
  <block id="7619081ba13aebf0c83d5660f9bf01bb" category="inline-link-macro">Oracle 데이터베이스 마이그레이션 결정 프로세스</block>
  <block id="0257ad9cf0c221fcf0c611f835c027ca" category="paragraph">추가 마이그레이션 옵션은 Microsoft 설명서를 참조하십시오. <block ref="421a85ebca6e289a6eff559e7e35faf8" category="inline-link-macro-rx"></block>.</block>
  <block id="a73e5c65844b18c49122a8a79ef3fa65" category="doc">Azure VM 및 Azure NetApp Files에 대한 단계별 Oracle 구축 절차</block>
  <block id="f8de11946f5850d6f1597a7cf5fc2234" category="inline-link-macro">이전: 고려할 요인.</block>
  <block id="e9704920b930163220a6e7564d7d680e" category="paragraph"><block ref="e9704920b930163220a6e7564d7d680e" category="inline-link-macro-rx"></block></block>
  <block id="cf2fb9f52eae11aaa1b6818cc22ade30" category="section-title">Azure 포털 콘솔을 통해 Oracle용 ANF와 Azure VM을 구축합니다</block>
  <block id="5e89dc82cb54763baa7cece42e7c3189" category="paragraph">Azure를 처음 사용하는 경우 먼저 Azure 계정 환경을 설정해야 합니다. 여기에는 Azure Active Directory를 사용하기 위한 조직 등록이 포함됩니다. 다음 섹션은 이러한 단계를 요약한 것입니다. 자세한 내용은 연결된 Azure 관련 설명서를 참조하십시오.</block>
  <block id="c743c9c56cd6cc2acf874405ef178af3" category="section-title">Azure 리소스를 생성하고 사용합니다</block>
  <block id="cc59653114a0ca329e90c87f8de8f2da" category="paragraph">Azure 환경을 설정하고 계정을 만들고 구독과 연결한 후 계정을 사용하여 Azure 포털에 로그인하여 Oracle을 실행하는 데 필요한 리소스를 생성할 수 있습니다.</block>
  <block id="4848dfd418cc69fdc8a92da472ac41b8" category="section-title">가상 네트워크 또는 VNET를 생성합니다</block>
  <block id="dd587303db328c6fc30f15fbf133eade" category="paragraph">Azure VNet(Virtual Network)은 Azure의 프라이빗 네트워크에 대한 기본 구성 요소입니다. VNET를 사용하면 Azure VM(가상 머신)과 같은 여러 유형의 Azure 리소스를 사용하여 서로, 인터넷 및 온프레미스 네트워크와 안전하게 통신할 수 있습니다. Azure VM을 프로비저닝하기 전에 먼저 VNet(VM이 배포된)을 구성해야 합니다.</block>
  <block id="2b9029fce84bbf7056c94e4b86015679" category="inline-link-macro">Azure 포털을 사용하여 가상 네트워크를 생성합니다</block>
  <block id="698a842fc17e080abbf6b6796628879b" category="paragraph">을 참조하십시오 <block ref="f497c9708f9505977884a23053323735" category="inline-link-macro-rx"></block> VNET를 생성합니다.</block>
  <block id="66d98f4e89afee6dc557332b0e9ebe43" category="section-title">ANF용 NetApp 스토리지 계정 및 용량 풀을 생성합니다</block>
  <block id="fecd60b0aedf111caefb4cf98b8d7be5" category="paragraph">이 구축 시나리오에서는 Azure VM OS가 일반 Azure 스토리지를 사용하여 프로비저닝되지만 ANF 볼륨은 NFS를 통해 Oracle 데이터베이스를 실행하도록 프로비저닝됩니다. 먼저 NetApp 스토리지 계정과 스토리지 볼륨을 호스팅할 용량 풀을 생성해야 합니다.</block>
  <block id="76dc01e3f39d83b88a3d3ad36c338654" category="inline-link-macro">Azure NetApp Files를 설정하고 NFS 볼륨을 생성합니다</block>
  <block id="8a57d5f988c678cd141c2f704e110472" category="paragraph">을 참조하십시오 <block ref="2337ae471c0cc5402cdba65ad3b4dc78" category="inline-link-macro-rx"></block> ANF 용량 풀을 설정하려면 다음을 수행합니다.</block>
  <block id="ed39ba49be7769bdf483ae876d88cdff" category="section-title">Oracle용 Azure VM을 프로비저닝합니다</block>
  <block id="acb4908e71af4ce0945c90f9039d0fc2" category="paragraph">워크로드를 기준으로 필요한 Azure VM 유형과 Oracle용 VM vCPU 및 RAM의 크기를 결정합니다. 그런 다음 Azure 콘솔에서 VM 아이콘을 클릭하여 VM 배포 워크플로를 시작합니다.</block>
  <block id="20d1e12ba2a72916f3917e44ff29b40a" category="list-text">Azure VM 페이지에서 * 생성 * 을 클릭한 다음 * Azure 가상 머신 * 을 선택합니다.</block>
  <block id="94f088d23454b3c408a17cfff3cb8989" category="inline-image-macro">이 스크린샷은 사용 가능한 Azure VM의 목록을 보여 줍니다.</block>
  <block id="e28fc410c2020dcbd93af60f3d700d99" category="paragraph"><block ref="e28fc410c2020dcbd93af60f3d700d99" category="inline-image-macro-rx" type="image"></block></block>
  <block id="78ba4b8df4acae5536f056217b16c353" category="list-text">배포에 대한 구독 ID를 선택한 다음 리소스 그룹, 영역, 호스트 이름, VM 이미지, 크기, 및 인증 방법을 참조하십시오. 디스크 페이지로 이동합니다.</block>
  <block id="cbbcba216ab68f94c8fab62d9c907a00" category="inline-image-macro">이 스크린샷은 Create a Virtual Machine 페이지의 입력 내용을 보여줍니다.</block>
  <block id="825d4c0973e48f04ab75cc30df85bbdc" category="inline-image-macro">이 스크린샷은 Create a Virtual Machine 페이지에 대한 추가 입력 정보를 보여 줍니다.</block>
  <block id="84982a7e7b9cc89bde9621d68800978e" category="paragraph"><block ref="a493253d19b28a6711494154a3160350" category="inline-image-macro-rx" type="image"></block>
<block ref="81b338659efc8df55ae98546f396c5b0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2c435f9a03a03e7cff44b06c9efafa31" category="list-text">OS 로컬 이중화를 위해 * 프리미엄 SSD * 를 선택하고 데이터 디스크가 ANF 스토리지에서 마운트되므로 데이터 디스크를 비워 둡니다. 네트워킹 페이지로 이동합니다.</block>
  <block id="04faa74bfe9ea34a9831d24d039dc159" category="inline-image-macro">이 스크린샷은 Create a Virtual Machine Disks(가상 머신 디스크 생성) 페이지에 대한 입력을 보여 줍니다.</block>
  <block id="2e21daafaa3607d62dda1a3411975b12" category="paragraph"><block ref="2e21daafaa3607d62dda1a3411975b12" category="inline-image-macro-rx" type="image"></block></block>
  <block id="f9c5742f2bffff7dd4a50e578bfb093b" category="list-text">VNET 및 서브넷을 선택합니다. 외부 VM 액세스를 위한 공용 IP를 할당합니다. 그런 다음 관리 페이지로 이동합니다.</block>
  <block id="0c0077e9a9d4700a64e70d30e9d110df" category="inline-image-macro">이 스크린샷은 Create a Virtual Machine 페이지에 대한 추가 입력을 보여 줍니다.</block>
  <block id="4aea6dbf72aa0b36bd98ced95acebcbd" category="paragraph"><block ref="4aea6dbf72aa0b36bd98ced95acebcbd" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6d5e4bb7568c6e8fb6a1f49aea08e975" category="list-text">관리에 대한 모든 기본값을 유지하고 고급 페이지로 이동합니다.</block>
  <block id="45291c6293e8de1084c3b8de71bfe120" category="inline-image-macro">이 스크린샷은 Create a Virtual Machine Management(가상 머신 관리 생성) 페이지에 대한 입력 내용을 보여 줍니다.</block>
  <block id="b031dac11379aafec2eb9832f71648ba" category="paragraph"><block ref="b031dac11379aafec2eb9832f71648ba" category="inline-image-macro-rx" type="image"></block></block>
  <block id="22b5d3beb0289dfe21618d5664538321" category="list-text">사용자 지정 스크립트를 사용하여 배포한 후 VM을 사용자 지정해야 하는 경우가 아니면 고급 페이지의 모든 기본값을 유지합니다. 그런 다음 태그 페이지로 이동합니다.</block>
  <block id="1a911a2f1237ad150a29236bcfe044a0" category="inline-image-macro">이 스크린샷은 Create a Virtual Machine Advanced 페이지에 대한 입력을 보여 줍니다.</block>
  <block id="00d8612fb98dc237476c6ecd9e0f52c9" category="paragraph"><block ref="00d8612fb98dc237476c6ecd9e0f52c9" category="inline-image-macro-rx" type="image"></block></block>
  <block id="46dfe2059392afeb84a872afb7cd09d5" category="list-text">필요한 경우 VM에 대한 태그를 추가합니다. 그런 다음 검토 + 만들기 페이지로 이동합니다.</block>
  <block id="85e3843de649be49b63e3b04c6887bcd" category="inline-image-macro">이 스크린샷은 Create a Virtual Machine Tags 페이지에 대한 입력 정보를 보여 줍니다.</block>
  <block id="ddeecdecd575fb71cf4e83d7f09717bc" category="paragraph"><block ref="ddeecdecd575fb71cf4e83d7f09717bc" category="inline-image-macro-rx" type="image"></block></block>
  <block id="57a6346e9ebfe8164361d5e2facffb62" category="list-text">배포 워크플로는 구성에 대한 유효성 검사를 실행하고 유효성 검사가 통과한 경우 * Create * 를 클릭하여 VM을 만듭니다.</block>
  <block id="dec1fd75845506029d8751bb7979c797" category="inline-image-macro">"이 스크린샷은 Create a Virtual Machine 검토 및 생성 페이지에 대한 입력 내용을 보여줍니다."</block>
  <block id="786b4cd98c208b72f71277850831c1aa" category="paragraph"><block ref="786b4cd98c208b72f71277850831c1aa" category="inline-image-macro-rx" type="image"></block></block>
  <block id="c18c3fe2e695bda0cb8b3e7ecccbdc4e" category="section-title">Oracle용 ANF 데이터베이스 볼륨 프로비저닝</block>
  <block id="f162c2b2b89920293c1f24ac435c520e" category="paragraph">Oracle 바이너리, 데이터 및 로그 볼륨에 대해 ANF 용량 풀에 대해 각각 3개의 NFS 볼륨을 생성해야 합니다.</block>
  <block id="09d8c19d5844128b31e1fa195808b215" category="list-text">Azure 콘솔의 Azure 서비스 목록에서 Azure NetApp Files 를 클릭하여 볼륨 생성 워크플로를 엽니다. ANF 스토리지 계정이 두 개 이상인 경우 볼륨을 프로비저닝할 계정을 클릭합니다.</block>
  <block id="733cf6b848c8e38a49b4b604225141a5" category="inline-image-macro">이 스크린샷은 ANF가 강조 표시된 Azure Services 페이지를 보여줍니다.</block>
  <block id="cc553796f259bc80d8c801687c0c1cd0" category="paragraph"><block ref="cc553796f259bc80d8c801687c0c1cd0" category="inline-image-macro-rx" type="image"></block></block>
  <block id="a8972cd5a80e6e385a27023ce45537a9" category="list-text">NetApp 스토리지 계정에서 * 볼륨 * 을 클릭한 다음 * 볼륨 추가 * 를 클릭하여 새 Oracle 볼륨을 만듭니다.</block>
  <block id="c8ce9170654447aba6747494e61bf3a2" category="inline-image-macro">이 스크린샷은 NetApp 스토리지 계정의 랜딩 화면을 보여줍니다.</block>
  <block id="b0d2d575f2aee1703b6e2896d43b72f9" category="inline-image-macro">이 스크린샷은 NetApp 스토리지 계정에서 사용할 수 있는 볼륨을 보여 줍니다.</block>
  <block id="3371cc932d04403ab2cd0788634d63e5" category="paragraph"><block ref="7266705f76a6cb3a106c34a6e8dc5540" category="inline-image-macro-rx" type="image"></block>
<block ref="f59831fbf7eaa0d216e8685698d0c55b" category="inline-image-macro-rx" type="image"></block></block>
  <block id="cbeaec71dc2b8275a14b23283d51cc04" category="list-text">VM 호스트 이름을 접두사로 사용하여 Oracle 볼륨을 식별한 다음 호스트에서 마운트 지점(예: Oracle 바이너리의 경우 u01, Oracle 데이터의 경우 u02, Oracle 로그의 경우 u03)을 확인합니다. VM과 동일한 VNet을 선택합니다. Next(다음): Protocol(프로토콜) &gt; * 를 클릭합니다.</block>
  <block id="ce4ff1bdb6d954e6967a7c241ff89518" category="inline-image-macro">볼륨 생성 화면</block>
  <block id="bacf4983022360caacd6f75352136f59" category="paragraph"><block ref="bacf4983022360caacd6f75352136f59" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b50bdcda066df8ed373847c60bc2f546" category="list-text">NFS 프로토콜을 선택하고 허용된 클라이언트에 Oracle 호스트 IP 주소를 추가한 다음 모든 IP 주소 0.0.0.0/0을 허용하는 기본 정책을 제거합니다. 그런 다음 * 다음: 태그 &gt; * 를 클릭합니다.</block>
  <block id="f8bc211f91c2b350b268959a57418393" category="inline-image-macro">Volume creation(볼륨 생성) 화면의 프로토콜 입력</block>
  <block id="8ac138d8c4a217ce018b45be622db1ed" category="paragraph"><block ref="8ac138d8c4a217ce018b45be622db1ed" category="inline-image-macro-rx" type="image"></block></block>
  <block id="fffcdc9cd5233d4718046c8f6d19c80b" category="list-text">필요한 경우 볼륨 태그를 추가합니다. 그런 다음 * 검토 + 생성 &gt; * 을 클릭합니다.</block>
  <block id="05864b350d713935d13966f3c8fcbcd7" category="inline-image-macro">Volume creation(볼륨 생성) 화면에 입력된 태그.</block>
  <block id="9bead8568a27fcf83faf41e77f52b246" category="paragraph"><block ref="9bead8568a27fcf83faf41e77f52b246" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6e574c0c875926f1fe654026995f3543" category="list-text">유효성 검사에 통과하면 * Create * 를 클릭하여 볼륨을 생성합니다.</block>
  <block id="4a585922412f050ac4a7fbcc34a2655b" category="inline-image-macro">Volume creation(볼륨 생성) 화면의 단계를 검토하고 생성합니다.</block>
  <block id="e9c713f1ad3a3f0b14801d722fb77f16" category="paragraph"><block ref="e9c713f1ad3a3f0b14801d722fb77f16" category="inline-image-macro-rx" type="image"></block></block>
  <block id="2d2dbc217706d8bb1248bc209e0ab9da" category="section-title">ANF가 있는 Azure VM에서 Oracle을 설치 및 구성합니다</block>
  <block id="7beaf3d9487c79b7245a1d9ae42d46aa" category="paragraph">NetApp 솔루션 팀은 Azure에서 Oracle을 원활하게 배포하는 데 도움이 되는 많은 Ansible 기반 자동화 툴킷을 만들었습니다. Azure VM에 Oracle을 구축하려면 다음 단계를 따르십시오.</block>
  <block id="0c782f45b1de4e6d016eafeeb60d286f" category="section-title">Ansible 컨트롤러 설정</block>
  <block id="58a105c56c05508f7233082bc282a654" category="paragraph">Ansible 컨트롤러를 설정하지 않은 경우 을 참조하십시오 <block ref="03bbd03f7d2552fa2076b42f86a04360" category="inline-link-macro-rx"></block>Ansible 컨트롤러를 설정하는 방법에 대한 자세한 지침이 포함되어 있습니다.</block>
  <block id="ce9ef6052d2c6ac4b97c01049ee4ec2b" category="section-title">Oracle 구축 자동화 툴킷을 제공합니다</block>
  <block id="52eae91ee8ea917bc73df6d9f1792469" category="paragraph">Ansible 컨트롤러에 로그인하는 데 사용하는 사용자 ID의 홈 디렉토리에 있는 Oracle 구축 툴킷 복사본을 복제합니다.</block>
  <block id="19cd6e3dfb797a7325548b346dc358f1" category="section-title">구성에 따라 툴킷을 실행합니다</block>
  <block id="aa98393908153ea46a2cef869e7dd100" category="paragraph">를 참조하십시오 <block ref="e7ab084e08308da08da1b2dd8151530b" category="inline-link-macro-rx"></block> CLI를 사용하여 플레이북을 실행합니다. CLI가 아닌 Azure 콘솔에서 데이터베이스 볼륨을 생성할 때 글로벌 VAR 파일의 변수 구성에서 ONTAP 부분을 무시할 수 있습니다.</block>
  <block id="24e16cc700e2ced028e529370af380e1" category="admonition">툴킷 기본값은 RU 19.8과 함께 Oracle 19c를 구축합니다. 경미한 기본 구성 변경 사항이 있는 다른 모든 패치 수준에 쉽게 적용할 수 있습니다. 또한 기본 시드 데이터베이스 활성 로그 파일이 데이터 볼륨에 배포됩니다. 로그 볼륨에 활성 로그 파일이 필요한 경우 초기 구축 후 해당 로그 파일을 재이동해야 합니다. 필요한 경우 NetApp 솔루션 팀에 도움을 요청하십시오.</block>
  <block id="dd52a71d2066e527d28efdbd46784e07" category="section-title">Oracle용 애플리케이션 정합성 보장 스냅샷을 위해 AzAcSnap 백업 툴을 설정합니다</block>
  <block id="211e60df4f320c617afaa9a96f62758f" category="paragraph">Azure Application-Consistent Snapshot Tool(AzAcSnap)은 스토리지 스냅샷을 생성하기 전에 애플리케이션 정합성 보장 상태로 전환하는 데 필요한 모든 오케스트레이션을 처리하여 타사 데이터베이스의 데이터를 보호할 수 있는 명령줄 툴입니다. 그런 다음 이러한 데이터베이스를 운영 상태로 되돌립니다. 데이터베이스 서버 호스트에 툴을 설치하는 것이 좋습니다. 다음 설치 및 구성 절차를 참조하십시오.</block>
  <block id="40390144ce134a2e38bfef9f590f867b" category="section-title">AzAcSnap 도구를 설치합니다</block>
  <block id="c2d834909e264a2f3bf3d3facd27740b" category="inline-link-macro">AzArcSnap 설치 프로그램</block>
  <block id="aed9be57adbc2906c27b7f325e1322aa" category="list-text">의 최신 버전을 가져옵니다 <block ref="696590d44d21e9b71649cae0895a0bca" category="inline-link-macro-rx"></block>.</block>
  <block id="243004130aa732bde904924170fa2e5c" category="list-text">다운로드한 자체 설치 프로그램을 대상 시스템에 복사합니다.</block>
  <block id="1aa45c54511185e4e2043ee91e8969bc" category="list-text">기본 설치 옵션을 사용하여 루트 사용자로 자체 설치 프로그램을 실행합니다. 필요한 경우 를 사용하여 파일을 실행 가능하게 만듭니다<block ref="48c01707d676030dd223de543c6beb09" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="483944250a0e1f955ad6fec7c6578bde" category="section-title">Oracle 접속 구성을 구성합니다</block>
  <block id="b6f7df8a3ada5b45cee3400740b83c9a" category="paragraph">스냅샷 도구는 Oracle 데이터베이스와 통신하며 백업 모드를 설정하거나 해제할 수 있는 적절한 권한이 있는 데이터베이스 사용자가 필요합니다.</block>
  <block id="6cd11918e51f60b6ce021e9d56c9e74a" category="section-title">AzAcSnap 데이터베이스 사용자를 설정합니다</block>
  <block id="84fe6666ea577b7ede5c61912d97705e" category="paragraph">다음 예에서는 Oracle 데이터베이스 사용자를 설정하고 sqlplus를 사용하여 Oracle 데이터베이스 통신을 보여 줍니다. 예제 명령은 Oracle 데이터베이스에 사용자(AZACSNAP)를 설정하고 IP 주소, 사용자 이름 및 암호를 적절하게 변경합니다.</block>
  <block id="342df2b2fb63c81cdd53e5e7bc5d00b9" category="list-text">Oracle 데이터베이스 설치에서 sqlplus를 실행하여 데이터베이스에 로그인합니다.</block>
  <block id="ab0840eee4ba613870ae404c907c1948" category="list-text">사용자를 생성합니다.</block>
  <block id="e90b9dc19df07f784e3fc408169077df" category="list-text">사용자 권한을 부여합니다. 이 예제에서는 데이터베이스를 백업 모드로 설정할 수 있도록 AZACSNAP 사용자에 대한 권한을 설정합니다.</block>
  <block id="f508d634fc1aa5df7fed84e6b58afce9" category="list-text">기본 사용자의 암호 만료 기간을 무제한으로 변경합니다.</block>
  <block id="bc5fff092e99ce3d1966b94061cb5953" category="list-text">데이터베이스에 대한 azacsnap 연결을 확인합니다.</block>
  <block id="8e0d0fb1cb3a50066ecd397700dfd22e" category="section-title">Oracle Wallet을 사용하여 DB 액세스를 위한 Linux-user azacsnap 구성</block>
  <block id="7140a904f4b795616fdc3c3efbdcd066" category="paragraph">AzAcSnap 기본 설치는 azacsnap OS 사용자를 생성합니다. Oracle Wallet에 저장된 암호를 사용하여 Oracle 데이터베이스 액세스를 위해 Bash 셸 환경을 구성해야 합니다.</block>
  <block id="c54cf7bb99b0e669ce6dc05ec8272470" category="list-text">루트 사용자로 를 실행합니다<block ref="760381f8107a856bc583301b7b272917" prefix=" " category="inline-code"></block> 호스트에서 ORACLE_HOME 및 ORACLE_SID 변수를 식별하는 명령입니다.</block>
  <block id="2a4941dc3f20c8f34a09b066691e66a5" category="list-text">azacsnap 사용자 bash 프로필에 oracle_home, oracle_SID, TNS_admin 및 경로 변수를 추가합니다. 필요에 따라 변수를 변경합니다.</block>
  <block id="e3c85fad3d30c470aac355430e98dc21" category="list-text">Linux 사용자 azacsnap로 전자지갑을 만듭니다. 전자지갑 암호를 묻는 메시지가 나타납니다.</block>
  <block id="83617bd12022f2dd9ba94816c7e56670" category="list-text">Oracle Wallet에 연결 문자열 자격 증명을 추가합니다. 다음 예제 명령에서 AZACSNAP는 AzAcSnap에서 사용할 ConnectString, azacsnap은 Oracle Database User, AzPasswd1은 Oracle User의 데이터베이스 암호입니다. 전자지갑 암호를 묻는 메시지가 다시 나타납니다.</block>
  <block id="02f08719de6240015b4e67725107792a" category="list-text">를 생성합니다<block ref="9de875b13677cf9b036a438bf9aedf5c" prefix=" " category="inline-code"></block> 파일. 다음 명령 예에서는 호스트를 Oracle Database의 IP 주소로 설정하고 서버 SID를 Oracle Database SID로 설정해야 합니다.</block>
  <block id="0eec77cc5ed96c42afb08c83ea3f1e3b" category="list-text">를 생성합니다<block ref="0501c2d94325e267bf15055591fb8157" prefix=" " category="inline-code"></block> 파일.</block>
  <block id="cafefcc0e796f3e73bc39de23dfc6b68" category="list-text">Wallet을 사용하여 Oracle 액세스를 테스트합니다.</block>
  <block id="8bf6bfb76bcf25b5e1bb9c1d4ede3d34" category="paragraph">명령 [azacsnap@acao-ora01~]$sqlplus/@AZNAP ACSAS SYSBACKUP에서 예상되는 출력입니다</block>
  <block id="9fac4799a7cb503012dac3d131cf3c15" category="paragraph">SQL* Plus: 릴리스 19.0.0.0.0 - 9월 8일 목요일 프로덕션 18:02:07 2022 버전 19.8.0.0.0</block>
  <block id="54eb020b97d7e8a9f56d67e93754e270" category="section-title">ANF 연결을 구성합니다</block>
  <block id="8c9356aaf30e863db064ba22b7d4b204" category="paragraph">이 섹션에서는 Azure NetApp Files(VM과 통신)와의 통신을 활성화하는 방법에 대해 설명합니다.</block>
  <block id="d78964ac0334c0f69ef24aada9864028" category="list-text">Azure Cloud Shell 세션 내에서 기본적으로 서비스 보안 주체와 연결할 구독에 로그인되어 있는지 확인합니다.</block>
  <block id="8611ff0fcccf2f05ff0dbde909379c14" category="list-text">가입이 올바르지 않으면 다음 명령을 사용합니다.</block>
  <block id="2d66e076b40e24c73ffa7a1704d985db" category="list-text">다음 예제와 같이 Azure CLI를 사용하여 서비스 보안 주체를 만듭니다.</block>
  <block id="707cc085819c641d15b9ea2b3b13cb53" category="paragraph">예상 출력:</block>
  <block id="e8e3af5b539b9415092afd10fc182ff7" category="paragraph">{"clientId":"00aa000a-aaaa-0000-00aa0-00aaaa000aaaa0a", "clientSecret":"00aaaa000a-aaaaaa-0000-00aaaaaaaaaaaaaaa000aaaaaaaaa-aaaaaaaaaaaaaaaaa000aaaaaaa-aaaaaaaaaa-aaaaaaaaaaaaaaaa-00a-aaaaaa <block ref="abe1a2134e98a87862a225c33f62cde4" category="inline-link-rx"></block>, "resourceManagerEndpointUrl": <block ref="5bbe1c35abcaa8749119f86fe8d12120" category="inline-link-rx"></block>, "activeDirectoryGraphResourceId": <block ref="91645ab7f47cce4ce23956a6c4c7df7c" category="inline-link-rx"></block>, "sqlManagementEndpointUrl": <block ref="2ce5923f710fffcd9fdcfffa2d0db664" category="inline-link-rx"></block>, "galleryEndpointUrl": <block ref="92fb62298a12469265ac683928098931" category="inline-link-rx"></block>, "managementEndpointUrl": <block ref="9a3197a885535f07c09e058a5f76aa0c" category="inline-link-rx"></block>}</block>
  <block id="c51a1e8c830ed4f63c489347dbcce1a7" category="list-text">출력 내용을 잘라내어 라는 파일에 붙여 넣습니다<block ref="b50999884a39c5efe8da46cd87acfeb2" prefix=" " category="inline-code"></block> Linux user azacsnap user bin 디렉토리에 저장되고 적절한 시스템 권한으로 파일을 보호합니다.</block>
  <block id="211f39ae9cd979a9f01bb800eca0b832" category="admonition">JSON 파일의 형식이 위에서 설명한 대로 정확하게 지정되었는지 확인하십시오. 특히 큰따옴표로 묶인 URL(")을 사용하십시오.</block>
  <block id="c1f6adfa882cba0dbd256d4909ac588c" category="section-title">AzAcSnap 도구 설정을 완료합니다</block>
  <block id="e0e7b63ff02eb3221940162934949dd0" category="paragraph">다음 단계에 따라 스냅샷 도구를 구성하고 테스트합니다. 테스트 성공 후 첫 번째 데이터베이스 정합성 보장 스토리지 스냅샷을 수행할 수 있습니다.</block>
  <block id="fe615094ac9bb468d26149280e3769d7" category="list-text">스냅샷 사용자 계정으로 변경합니다.</block>
  <block id="4ef9af49185e683998d060aa71c30e2b" category="list-text">명령 위치를 변경합니다.</block>
  <block id="412d274adbc3fc7cb51ab315d7a77f82" category="list-text">스토리지 백업 세부 정보 파일을 구성합니다. 이렇게 하면 가 생성됩니다<block ref="8ed8c6bfea85d72bc4a36772490109c7" prefix=" " category="inline-code"></block> 구성 파일.</block>
  <block id="d4c18f094b4959d27f52ee2a9709a6b9" category="paragraph">Oracle 볼륨 3개가 필요한 경우의 결과:</block>
  <block id="849abd2456a4bd2ccddb94a12dfcc37d" category="paragraph">[azacsnap@acao-ora01 bin]$azacsnap -c configure -- configuration new config file 구성 파일에 주석 추가(주석 추가를 종료하려면 빈 항목 추가): Oracle 스냅샷 백업 구성 파일에 주석 추가(주석 추가를 종료하려면 빈 항목 추가): 추가할 데이터베이스 유형, 'hana', 'oracle' 또는 'exit'(데이터베이스 없음)를 입력합니다. Oracle</block>
  <block id="fa7ad5b9d050b7a5baa27ffcd8863c42" category="paragraph">=== 추가 Oracle Database details === Oracle Database SID(예: CDB1): ORATST Database Server의 주소(호스트 이름 또는 IP 주소): 172.30.137.142 Oracle 연결 문자열(예: /@AZACSNAP):/@AZACSNAP</block>
  <block id="44b11046a63da89febd351b4213758cf" category="paragraph">=== Azure NetApp Files 스토리지 세부 정보 ===== 데이터베이스에 Azure NetApp Files를 사용하고 있습니까? (y/n) [n]: y -- 데이터 볼륨은 스냅샷이 되기 전에 애플리케이션이 정합성 보장 상태로 전환됨 -- 데이터베이스 구성의 데이터 볼륨 섹션에 Azure NetApp Files 리소스를 추가합니까? (y/n) [n]: y 전체 Azure NetApp Files 스토리지 볼륨 리소스 ID(예: /Subscriptions/.../resourceGroups/.../providers/Microsoft.NetApp/netAppAccounts/.../capacityPools/Premium/volumes/...):/Subscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourceGroups/ANFAVSRG/providers/Microsoft.NetApp/netAppAccounts/ANFAVSAcct/capacityPools/CapPool/volumes/acao-ora01-u01 서비스 보안 주체 인증 파일 이름 또는 Azure-auth.file<block ref="88c14b7c14e63dd3e0345f1f112a2bd3" category="inline-link-rx"></block> Oracle.json 데이터베이스 구성의 데이터 볼륨 섹션에 Azure NetApp Files 리소스를 추가합니까? (y/n) [n]: y 전체 Azure NetApp Files 스토리지 볼륨 리소스 ID(예: /Subscriptions/.../resourceGroups/.../providers/Microsoft.NetApp/netAppAccounts/.../capacityPools/Premium/volumes/...):/Subscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourceGroups/ANFAVSRG/providers/Microsoft.NetApp/netAppAccounts/ANFAVSAcct/capacityPools/CapPool/volumes/acao-ora01-u02 서비스 보안 주체 인증 파일 이름 또는 Azure-auth.file<block ref="88c14b7c14e63dd3e0345f1f112a2bd3" category="inline-link-rx"></block> Oracle.json 데이터베이스 구성의 데이터 볼륨 섹션에 Azure NetApp Files 리소스를 추가합니까? (y/n) [n]: n----- 다른 볼륨은 스냅샷을 위한 애플리케이션을 준비하지 않고 즉시 스냅샷임---- 데이터베이스 구성의 다른 볼륨에 Azure NetApp Files 리소스 추가? (y/n) [n]: y 전체 Azure NetApp Files 스토리지 볼륨 리소스 ID(예: /Subscriptions/.../resourceGroups/.../providers/Microsoft.NetApp/netAppAccounts/.../capacityPools/Premium/volumes/...):/Subscriptions/0efa2dfb-917c-4497-b56a-b3f4eadb8111/resourceGroups/ANFAVSRG/providers/Microsoft.NetApp/netAppAccounts/ANFAVSAcct/capacityPools/CapPool/volumes/acao-ora01-u03 서비스 보안 주체 인증 파일 이름 또는 Azure-auth.file<block ref="88c14b7c14e63dd3e0345f1f112a2bd3" category="inline-link-rx"></block> Oracle.json 데이터베이스 구성의 다른 볼륨 섹션에 Azure NetApp Files 리소스를 추가합니까? (y/n) [n]:n</block>
  <block id="e16c4d13d5c9c936ac3ca975a729784f" category="paragraph">==== Azure Managed Disk details ===== 데이터베이스에 Azure Managed Disks를 사용하고 있습니까? (y/n) [n]:n</block>
  <block id="e5e08e0b27271cd7952c3cd754436294" category="paragraph">==== Azure Large Instance (Bare Metal) Storage details ========== 데이터베이스에 Azure Large Instance (Bare Metal)를 사용하고 있습니까? (y/n) [n]:n</block>
  <block id="cec7485a9812da8e268c6d53917d0776" category="paragraph">추가할 데이터베이스 유형, 'HANA', 'Oracle' 또는 '종료'(데이터베이스 없음)를 입력합니다. 종료합니다</block>
  <block id="c63145a4ad8c93cb8bdff88f44cf483b" category="paragraph">'azacsnap.json'에 출력을 쓰는 중 구성 편집이 완료되었습니다.</block>
  <block id="72b0a1cda785576a979ca4ee2e3c8c62" category="list-text">azacsnap Linux 사용자로서, Oracle 백업에 대해 azacsnap 테스트 명령을 실행합니다.</block>
  <block id="ce9bfcddebc567805a4fdb6bcdf15515" category="paragraph">[azacsnap@acao-ora01 bin]$azacsnap -c test--test oracle--configfile azacsnap.json BEGIN:테스트 프로세스가 'oracle'에 대해 시작되었습니다. BEGIN:Oracle DB 테스트 통과: Oracle DB 버전 1908000000 END:Test process complete for 'oracle' [azacsnap@acao-ora01 bin]$</block>
  <block id="7be23e8f29bfc799fd8fbcdc55fe0e77" category="list-text">첫 번째 스냅샷 백업을 실행합니다.</block>
  <block id="42481f217667e9b11be3ea64c971056a" category="inline-link-macro">다음: 데이터베이스 보호.</block>
  <block id="d39c73ea41fa36408b518637e929e754" category="paragraph"><block ref="d39c73ea41fa36408b518637e929e754" category="inline-link-macro-rx"></block></block>
  <block id="87561d435f6cd79a59659b543d2991ca" category="summary">이 섹션에서는 맞춤형 Oracle RDS 및 FSx ONTAP 스토리지가 포함된 RDS Oracle 맞춤형 구축 솔루션 아키텍처를 보여 줍니다.</block>
  <block id="312f941d9e8f224f54ae372016e8f35a" category="paragraph">환경 내에서 Oracle 컴퓨팅 인스턴스는 AWS EC2 인스턴스 콘솔을 통해 구축됩니다. 콘솔에서 여러 EC2 인스턴스 유형을 사용할 수 있습니다. RedHat Enterprise Linux 8과 함께 M5 Ami 이미지와 같은 데이터베이스 기반 EC2 인스턴스 유형 및 최대 10Gbps의 네트워크 대역폭을 구축하는 것이 좋습니다.</block>
  <block id="830579b4d0c33e9e4fa1f11c61cb73a7" category="inline-image-macro">이 이미지는 운영 HA 클러스터, 즉 대기 HA 클러스터 관리 노드 및 관련 연결 노드를 포함한 샘플 아키텍처 다이어그램을 보여줍니다.</block>
  <block id="73793421735093db194ae82163f894b3" category="paragraph"><block ref="73793421735093db194ae82163f894b3" category="inline-image-macro-rx" type="image"></block></block>
  <block id="e3d0f7ae75ed6e0e3b522ecc7cac710b" category="paragraph">FSx 스토리지 클러스터는 기본 스토리지 클러스터와 대기 스토리지 클러스터가 모두 두 개의 서로 다른 가용성 영역에 구축되도록 이중 중복성으로 설계되었습니다. 데이터베이스 볼륨은 모든 Oracle 바이너리, 데이터 및 로그 볼륨에 대해 사용자가 구성할 수 있는 간격으로 기본 FSx 클러스터에서 대기 FSx 클러스터로 복제됩니다.</block>
  <block id="0008c12bed67fcf1f82ece8ff10b5c81" category="paragraph">이 고가용성 Oracle 환경은 Ansible 컨트롤러 노드와 SnapCenter 백업 서버 및 UI 툴을 사용하여 관리됩니다. Ansible 플레이북 기반 툴 키트를 사용하여 Oracle 설치, 구성, 복제를 자동화할 수 있습니다. Oracle EC2 인스턴스 커널 운영 체제 또는 Oracle 패칭에 대한 모든 업데이트를 병렬로 실행하여 운영 및 대기 상태를 동기화할 수 있습니다. 실제로 초기 자동화 설정을 쉽게 확장하여 필요한 경우 일상적인 Oracle 작업을 몇 가지 반복 수행할 수 있습니다.</block>
  <block id="1332f9ef53fc751a6087660a11f07ba6" category="paragraph"><block ref="1332f9ef53fc751a6087660a11f07ba6" category="inline-link-macro-rx"></block></block>
  <block id="1572d96530c843cddbe2d0a8b47abf8a" category="summary">이 모범 사례 가이드에서는 Azure NetApp 파일 스토리지 및 Azure VM에서 Oracle 데이터베이스를 구축하고 보호하기 위한 솔루션에 대해 자세히 설명합니다.</block>
  <block id="2e0520fcae6cb49914d2308fbaf4e1a8" category="doc">TR-4954: Azure NetApp Files에서 Oracle 데이터베이스 구축 및 보호</block>
  <block id="7e6f7643afec42d9c47efa933debef3e" category="paragraph">Allen Cao, Niyaz Mohamed, NetApp</block>
  <block id="b2bd5134cf9b573edd93cbfe6ee4559d" category="paragraph">많은 미션 크리티컬 Oracle 엔터프라이즈 데이터베이스가 여전히 사내에서 호스팅되며, 많은 기업에서 이러한 Oracle 데이터베이스를 퍼블릭 클라우드로 마이그레이션하려고 합니다. 종종 이러한 Oracle 데이터베이스는 애플리케이션 중심이므로 많은 서비스형 데이터베이스 퍼블릭 클라우드 오퍼링에서 누락되는 사용자별 구성이 필요합니다. 따라서 현재의 데이터베이스 환경에서는 고유한 요구 사항을 수용할 수 있는 고성능의 확장 가능한 컴퓨팅 및 스토리지 서비스를 통해 구축된 퍼블릭 클라우드 기반 Oracle 데이터베이스 솔루션이 필요합니다. Azure 가상 머신 컴퓨팅 인스턴스 및 Azure NetApp Files 스토리지 서비스는 미션 크리티컬 Oracle 데이터베이스 워크로드를 퍼블릭 클라우드로 구축 및 마이그레이션하는 데 활용할 수 있는 퍼즐의 누락된 조각일 수 있습니다.</block>
  <block id="a58dc8965e4de69beb97a33a5a1935ea" category="paragraph">Azure 가상 시스템은 Azure가 제공하는 여러 가지 유형의 온디맨드 확장 가능한 컴퓨팅 리소스 중 하나입니다. 일반적으로 다른 선택 사항보다 컴퓨팅 환경에 대한 제어 능력이 더 필요한 경우 가상 시스템을 선택합니다. Azure 가상 시스템은 컴퓨팅 또는 메모리 집약적인 워크로드에 관계없이 Oracle 데이터베이스를 실행하는 데 필요한 특정 구성으로 컴퓨터를 빠르고 쉽게 만들 수 있는 방법을 제공합니다. Azure 가상 네트워크의 가상 시스템은 보안 VPN 터널을 통해 조직의 네트워크에 쉽게 연결할 수 있습니다.</block>
  <block id="466d154dd31c873c4a2fd7113dc6b818" category="paragraph">Azure NetApp Files는 데이터베이스 워크로드를 이전보다 더 빠르고 안전하게 클라우드로 이전할 수 있는 완전 관리형 Microsoft 서비스입니다. 이 솔루션은 클라우드에서 Oracle 데이터베이스와 같은 고성능 워크로드를 실행하는 데 필요한 핵심 요구사항을 충족하도록 설계되었으며, 실제 IOPS 요구사항, 짧은 지연 시간, 고가용성, 높은 내구성, 대규모 관리 편의성을 반영하는 성능 계층을 제공합니다. 빠르고 효율적인 백업, 복구 및 클로닝에 활용할 수 있습니다. Azure NetApp Files는 Azure 데이터 센터 환경 내에서 실행되는 물리적 All-Flash NetApp ONTAP 시스템을 기반으로 하므로 이러한 기능이 가능합니다. Azure NetApp Files는 Azure DC 및 포털에 완벽하게 통합되어 있으며, 고객은 동일한 편안한 그래픽 인터페이스 및 API를 사용하여 다른 Azure 개체와 마찬가지로 공유 파일을 만들고 관리할 수 있습니다. Azure NetApp 파일을 사용하면 추가 위험, 비용 또는 시간 없이 Azure의 모든 기능을 활용할 수 있으며 Azure 네이티브 엔터프라이즈 파일 서비스만 믿고 사용할 수 있습니다.</block>
  <block id="30106aaa3e986f62cbb327f935569bca" category="inline-link-macro">Oracle Databases on Microsoft Azure 를 참조하십시오</block>
  <block id="bdb41d103336edebf957f48add0f3554" category="inline-link-macro">NetApp - 자동화</block>
  <block id="c2add34b573ef3798dd7c5b8972c008a" category="paragraph">이 문서에서는 온프레미스 시스템과 비슷한 성능과 내구성을 제공하는 Azure 가상 머신 및 Azure NetApp Files 스토리지 서비스를 사용하여 Oracle 데이터베이스를 구축, 구성 및 보호하는 방법에 대해 자세히 설명합니다. 모범 사례 지침은 TR-4780을 참조하십시오 <block ref="43d70d3cb7600babfb5820086b5480b6" category="inline-link-macro-rx"></block>. 더 중요한 것은 NetApp이 Azure 퍼블릭 클라우드에서 Oracle 데이터베이스 워크로드의 구현, 구성, 데이터 보호, 마이그레이션 및 관리에 필요한 대부분의 작업을 자동화하는 자동화 툴툴킷을 제공하는 것입니다. 자동화 툴킷을 NetApp 퍼블릭 GitHub 사이트에서 다운로드할 수 있습니다. <block ref="1b9adaed0e4ba13a6d8f6edc7ab8f2d8" category="inline-link-macro-rx"></block>.</block>
  <block id="3d7dbc3eeea5e87b5d14c9f00c66dd47" category="paragraph"><block ref="3d7dbc3eeea5e87b5d14c9f00c66dd47" category="inline-link-macro-rx"></block></block>
  <block id="cffc2899d8dda4926e6563cef4e76608" category="summary">이 섹션에서는 Azure 가상 머신 및 Azure NetApp Files 스토리지에 Oracle 데이터베이스를 구축할 때 고려해야 할 요소에 대해 자세히 설명합니다.</block>
  <block id="3cc4738ed2ec2e682ab2002688fa632b" category="paragraph"><block ref="3cc4738ed2ec2e682ab2002688fa632b" category="inline-link-macro-rx"></block></block>
  <block id="1a6a6241c0105da34f664d1e12534598" category="paragraph">다음 섹션에서는 Azure NetApp Files 스토리지를 사용하는 Azure 가상 머신 인스턴스의 Azure 퍼블릭 클라우드에서 Oracle 데이터베이스를 구축할 때의 주요 고려 사항에 대해 설명합니다.</block>
  <block id="c2b3b1e82aa97a133f0f6bbc12843085" category="section-title">VM 유형 및 사이징</block>
  <block id="4ca9712a9cd82ea80c8e225977fae1bb" category="inline-link-macro">Azure의 가상 머신 크기입니다</block>
  <block id="7c4a17715675ccfa7ce507eea6098318" category="paragraph">공용 클라우드에서 관계형 데이터베이스의 성능을 최적화하려면 올바른 VM 유형 및 크기를 선택하는 것이 중요합니다. Azure 가상 머신은 Oracle 데이터베이스 워크로드를 호스팅하는 데 사용할 수 있는 다양한 컴퓨팅 인스턴스를 제공합니다. Microsoft 설명서를 참조하십시오 <block ref="d854faa84ea41d8819c42ca3741a3561" category="inline-link-macro-rx"></block> 다양한 유형의 Azure 가상 머신 및 사이징 일반적으로, 중간 규모의 Oracle 데이터베이스를 구축할 때는 범용 Azure 가상 머신을 사용하는 것이 좋습니다. 대용량 Oracle 데이터베이스를 구축하는 경우 메모리에 최적화된 Azure VM이 적합합니다. RAM이 많을수록 더 큰 Oracle SGA 또는 스마트 플래시 캐시를 구성하여 물리적 I/O를 줄이고 데이터베이스 성능을 개선할 수 있습니다.</block>
  <block id="84942a15b69259aab0ff7c2620afcaf6" category="inline-link-macro">TR-4780: Microsoft Azure의 Oracle 데이터베이스</block>
  <block id="760a7b6c1bd4f6ebab6918d42feb4825" category="paragraph">Azure NetApp Files는 Azure 가상 머신에 연결된 NFS 마운트로 작동하여 처리량을 늘리고 로컬 스토리지로 스토리지 최적화된 VM 처리량 한도를 극복할 수 있습니다. 따라서 Azure NetApp Files에서 Oracle을 실행하면 라이센스 대상 Oracle CPU 코어 수 및 라이센스 비용을 줄일 수 있습니다. 을 참조하십시오 <block ref="b46cbe9b7b18b9ff8101a014c206465f" category="inline-link-macro-rx"></block>섹션 7 - Oracle 라이센스는 어떻게 작동합니까?</block>
  <block id="71b93ac808ac25bb511ebcbb028e32e8" category="paragraph">기타 고려해야 할 요소는 다음과 같습니다.</block>
  <block id="592bc946b588ad0e83c05f528895bcc8" category="list-text">워크로드 특성에 따라 올바른 vCPU 및 RAM 조합을 선택합니다. VM에서 RAM 크기가 증가하면 vCPU 코어 수도 증가합니다. vCPU 코어 수에 Oracle 라이센스 비용이 청구되므로 약간의 균형을 유지해야 합니다.</block>
  <block id="fb9844eb7ee0ff341d6f7066f78918ff" category="list-text">VM에 스왑 공간을 추가합니다. 기본 Azure VM 배포에서는 데이터베이스에 적합하지 않은 스왑 공간을 생성하지 않습니다.</block>
  <block id="81afc696937e3786d5701212de79c536" category="section-title">Azure NetApp Files 성능</block>
  <block id="c7bc5faed38f5284386f25a6fc3a5752" category="paragraph">Azure NetApp Files 볼륨은 용량 풀에서 할당되며 고객은 Azure NetApp Files 스토리지 계정에서 용량 할당을 수행해야 합니다. 각 용량 풀은 다음과 같이 할당됩니다.</block>
  <block id="3af20f4cec87eac026d0990a8a3f4169" category="list-text">전반적인 성능 기능을 정의하는 서비스 수준.</block>
  <block id="dd1fb66595c069d1b267fb8ca87e46eb" category="list-text">해당 용량 풀에 대해 초기에 프로비저닝된 스토리지 용량 또는 계층입니다. 프로비저닝된 공간에 대한 총 최대 처리량을 정의하는 서비스 품질(QoS) 수준입니다.</block>
  <block id="9dc50220b7e70511b5aeebb862346fad" category="paragraph">서비스 수준과 처음에 용량 할당된 스토리지 용량은 특정 Oracle 데이터베이스 볼륨의 성능 수준을 결정합니다.</block>
  <block id="59b8b6b998c3c0fcd2f1b107a68c290a" category="section-title">Azure NetApp Files에 대한 서비스 수준</block>
  <block id="f02ad1a8080bf1b50f8a15cb346ed483" category="paragraph">Azure NetApp Files는 Ultra, Premium 및 Standard의 세 가지 서비스 수준을 지원합니다.</block>
  <block id="3eec40f71dc46b07f32031c9703968ec" category="list-text">* Ultra 스토리지. * 이 계층은 할당된 1TiB 볼륨 할당량당 최대 128MiBps의 처리량을 제공합니다.</block>
  <block id="1b0fa75a1e8b815e03fb38f8a90d2a73" category="list-text">* 프리미엄 스토리지. * 이 계층은 할당된 1TiB 볼륨 할당량당 최대 64MiBps의 처리량을 제공합니다.</block>
  <block id="00792f6ec40d3e2833834d90802a7aa5" category="list-text">* 표준 스토리지. * 이 계층은 할당된 1TiB 볼륨 할당량당 최대 16MiBps의 처리량을 제공합니다.</block>
  <block id="7a720602d11a97fd37964c9979e2f1a5" category="section-title">용량 풀 및 서비스 품질</block>
  <block id="36ac84521252c58a4238292bf0c21d92" category="paragraph">원하는 서비스 수준마다 프로비저닝된 용량과 관련된 비용이 있으며 프로비저닝된 공간의 전체 최대 처리량을 정의하는 서비스 품질(QoS) 수준이 포함되어 있습니다.</block>
  <block id="7a93db9cf06fd65415faf241927e2087" category="paragraph">예를 들어, 프리미엄 서비스 수준이 포함된 10TiB 프로비저닝된 단일 용량 풀은 이 용량 풀 내의 모든 볼륨에 대해 1064MBps의 전체 가용 처리량을 제공하므로 40,000MBps(16K) IOPS 또는 80,000,000(8K) IOPS가 가능합니다.</block>
  <block id="18dc8b2cbfb938a0ba32c141664fba0e" category="paragraph">최소 용량 풀 크기는 4TiB입니다. 스토리지 요구사항 및 비용 관리를 위해 워크로드 요구사항의 변화에 따라 용량 풀 크기를 1TiB 단위로 변경할 수 있습니다.</block>
  <block id="8a26494cf7b0c3c3ca7cd38e89c068eb" category="section-title">데이터베이스 볼륨에서 서비스 수준을 계산합니다</block>
  <block id="9ce59559a0b99338ee0bad0c153c961a" category="paragraph">Oracle 데이터베이스 볼륨의 처리량 제한은 볼륨이 속한 용량 풀의 서비스 수준과 볼륨에 할당된 할당량의 조합에 의해 결정됩니다.</block>
  <block id="b87e1c6e437216fc2d3719c3dad93cb8" category="paragraph">다음 다이어그램은 Oracle 데이터베이스 볼륨의 처리량 한도를 계산하는 방법을 보여 줍니다.</block>
  <block id="1624b6f83446cd1719c94bae28cbbeb7" category="inline-image-macro">이 이미지는 총 처리량을 결정하기 위해 세 개의 용량 계층에 적용된 수식을 보여 줍니다.</block>
  <block id="4d06f88a6f007c9821ac2ea5741860c5" category="paragraph"><block ref="4d06f88a6f007c9821ac2ea5741860c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="7ce3321601c29c87cb29ae9817843b8d" category="paragraph">예제 1에서는 2TiB 할당량이 할당된 프리미엄 스토리지 계층이 있는 용량 풀의 볼륨에 128MiBps(2TiB * 64MiBps)의 처리량 제한이 할당됩니다. 이 시나리오는 용량 풀 크기 또는 실제 볼륨 소비에 관계없이 적용됩니다.</block>
  <block id="69da5d3e48cc26414a9177d843bd55d9" category="paragraph">예제 2에서는 100GiB가 할당된 프리미엄 스토리지 계층이 있는 용량 풀의 볼륨에 6.25MiBps(0.09765625TiB * 64MiBps)의 처리량 제한이 할당됩니다. 이 시나리오는 용량 풀 크기 또는 실제 볼륨 소비에 관계없이 적용됩니다.</block>
  <block id="def2c2ae4fa72ee296eada07b44a0cc9" category="paragraph">최소 볼륨 크기는 100GiB입니다.</block>
  <block id="78ad659ec79d8ee9e7432271167d18d3" category="list-text">소규모 데이터베이스의 경우 모든 Oracle 파일에 단일 볼륨 레이아웃을 사용합니다.</block>
  <block id="51672f1f7a65c28f28e5e113376309bd" category="inline-image-macro">이 이미지는 각각 데이터 파일, 재실행 로그, 아카이브 로그, 제어 파일이 포함된 세 개의 데이터베이스(DB1, DB2, DB3)를 단일 용량 풀 내에 보여 줍니다.</block>
  <block id="6dab61143f0fe37930fbd783e5c57c81" category="paragraph"><block ref="6dab61143f0fe37930fbd783e5c57c81" category="inline-image-macro-rx" type="image"></block></block>
  <block id="816445ad7ba016a8c0be293c985f068b" category="list-text">대규모 데이터베이스의 경우 여러 개의 볼륨 레이아웃이 권장됩니다. 하나는 Oracle 데이터, 중복 제어 파일, 다른 하나는 Oracle 액티브 로그, 아카이브 로그 및 제어 파일용입니다. 데이터베이스를 새 호스트에 재배치하고 신속하게 복구할 수 있도록 로컬 드라이브 대신 Oracle 바이너리에 대한 볼륨을 할당하는 것이 좋습니다.</block>
  <block id="955db4ecf8716abf17a3ea3f8e113671" category="inline-image-macro">이 이미지는 각각 두 개의 볼륨이 있는 두 개의 데이터베이스를 보여 줍니다. 첫 번째 볼륨에는 데이터 파일이 포함되어 있는 반면, 각 데이터베이스의 두 번째 볼륨에는 재실행 로그, 아카이브 로그, 제어 파일이 포함되어 있습니다. 모두 단일 용량 풀 내에 있습니다.</block>
  <block id="7432b939dcc290776a34b2e9610a2775" category="paragraph"><block ref="7432b939dcc290776a34b2e9610a2775" category="inline-image-macro-rx" type="image"></block></block>
  <block id="efeaafaa286e164985a0c325f0727cf1" category="paragraph">가장 일반적인 운영 체제인 Linux에는 네이티브 NFS 기능이 포함되어 있습니다. Oracle은 Oracle에 기본적으로 통합된 직접 NFS(dNFS) 클라이언트를 제공합니다. Oracle dNFS는 OS 캐시를 우회하고 병렬 처리를 가능하게 하여 데이터베이스 성능을 향상시킵니다. Oracle은 20년 이상 NFSv3을 지원해 왔으며 NFSv4는 Oracle 12.1.0.2 이상에서 지원됩니다.</block>
  <block id="be5ef2ba2540e077db09ca784b1ac18f" category="paragraph">dNFS(Oracle 11g 이후 사용 가능)를 사용하면 Azure Virtual Machine에서 실행되는 Oracle 데이터베이스가 네이티브 NFS 클라이언트보다 훨씬 더 많은 I/O를 구동할 수 있습니다. NetApp 자동화 툴킷을 사용하여 자동화된 Oracle 구축은 NFSv3에서 dNFS를 자동으로 구성합니다.</block>
  <block id="632bf0b812e05925eff22d7d0a7677c2" category="paragraph">다음 다이어그램은 Oracle dNFS를 사용하는 Azure NetApp Files의 SLOB 벤치마크를 보여줍니다.</block>
  <block id="08826656fd88155bdfaebbb292320e33" category="inline-image-macro">이 그래프는 dNFS가 KNFS를 통해 DB 순차 파일 지연 시간(ms)을 향상한다는 것을 극적으로 보여 줍니다.</block>
  <block id="258bafba486e8ac35578ed4c5fff8ab1" category="paragraph"><block ref="258bafba486e8ac35578ed4c5fff8ab1" category="inline-image-macro-rx" type="image"></block></block>
  <block id="24019b0d54b5da3a46b400c6a6dfee77" category="paragraph">최적의 성능을 제공하고 성능 문제를 방지하려면 TCP 슬롯 테이블을 제어하는 커널 매개 변수를 128로 조정합니다.</block>
  <block id="754e164c2de7ed1f02667d5f74297a0e" category="list-text">다음 표에는 Linux NFSv3의 단일 인스턴스에 대해 권장되는 NFS 마운트 옵션이 나와 있습니다.</block>
  <block id="fa7abb28d1b83f9ee23d95aff1d3123b" category="inline-image-macro">이 표에는 다음 파일 유형, 제어 파일, 데이터 파일, 재실행 로그, oracle_home, 및 oracle_base.</block>
  <block id="082aad17dee7d03a3d502a422c1a8c53" category="paragraph"><block ref="082aad17dee7d03a3d502a422c1a8c53" category="inline-image-macro-rx" type="image"></block></block>
  <block id="b71b592b003a6232eebe484a1736be7a" category="paragraph"><block ref="b71b592b003a6232eebe484a1736be7a" category="inline-link-macro-rx"></block></block>
  <block id="d0dfaca5f0573d672a0f4dc66997c002" category="doc">EC2 및 FSx Oracle 데이터베이스 관리</block>
  <block id="4020b36b638694a9834cb01b53b25ffe" category="doc">AWS EC2 및 FSx에서 Oracle Deployment Procedures를 단계별로 수행합니다</block>
  <block id="d842058c0e8814799a596324a98e5323" category="sidebar">AWS EC2 및 FSx Best Practices에 Oracle Database 구축</block>
  <block id="879f2366c198b1fc05740657cacebcc1" category="sidebar">Azure NetApp Files에서 Oracle 데이터베이스 구축 및 보호</block>
  <block id="fc305603a3cb90ea71cabdf327aaf437" category="sidebar">데이터베이스 보호</block>
  <block id="2ca630161d7251bb59a9e458ddef241c" category="paragraph"><block ref="2ca630161d7251bb59a9e458ddef241c" category="inline-link-macro-rx"></block></block>
  <block id="68a03283d8017637709e60ab77052710" category="paragraph"><block ref="68a03283d8017637709e60ab77052710" category="inline-link-macro-rx"></block></block>
  <block id="fb558936249b78a9b426ac6a575ece20" category="paragraph"><block ref="fb558936249b78a9b426ac6a575ece20" category="inline-link-macro-rx"></block></block>
  <block id="8b742cda768ff35bcc87798d5c8efcf1" category="paragraph"><block ref="8b742cda768ff35bcc87798d5c8efcf1" category="inline-link-macro-rx"></block></block>
  <block id="c6f1106d361e6595d08ff6340c004516" category="paragraph"><block ref="c6f1106d361e6595d08ff6340c004516" category="inline-link-macro-rx"></block></block>
  <block id="3b872d3a96131109e4700e3031e4b158" category="inline-link-macro">NVA-1155: FC를 통해 FlexPod 데이터 센터 및 Cisco UCS 및 NetApp AFF A800의 Oracle 19c RAC 데이터베이스</block>
  <block id="202f51b1cd08b9562681a95f87429702" category="paragraph"><block ref="202f51b1cd08b9562681a95f87429702" category="inline-link-macro-rx"></block></block>
  <block id="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="paragraph"><block ref="29f20bee1f160a8e20c6ef9d7ce1bfe2" category="inline-link-macro-rx"></block></block>
  <block id="9a13b1875b1cf906383834093477aa0b" category="paragraph"><block ref="9a13b1875b1cf906383834093477aa0b" category="inline-link-macro-rx"></block></block>
  <block id="b46d6d6e100776ecf2985ff50a451beb" category="cell">2023-02-07-02</block>
  <block id="6e6d4a2ed2ec59b98f8da1da20e890bb" category="cell">추가 블로그: Google Cloud VMware Engine에 대한 NetApp Cloud Volumes Service 데이터 저장소 지원의 일반적인 가용성을 소개합니다</block>
  <block id="7240c168839eaf56e1bc86326fb29d5b" category="cell">TR-4955 추가: ONTAP 및 VMC(AWS VMware Cloud)용 FSx를 통한 재해 복구</block>
  <block id="dd4fe8081ff6ae9c7e9975937aff6576" category="list-text">Azure NetApp Files(ANF)를 보조 NFS 데이터 저장소로 사용합니다</block>
  <block id="b2bf74ba9b2080c50a7214bcabdb670c" category="list-text">CVS(Cloud Volumes Service)를 보조 NFS 데이터 저장소로 사용</block>
  <block id="ef7615d9ff40c00e9893de8051347a72" category="cell">ANF<block ref="11e701f660af04a4005e56e6ac4b1c05" category="inline-link-macro-rx"></block></block>
  <block id="b577d5e5fe684be74c0fcbceb61e27d4" category="cell">CV<block ref="2bc02f38a6be3889a69283e362618186" category="inline-link-macro-rx"></block></block>
  <block id="d7fe32206230432c446b09e24ab3f41a" category="doc">TR-4955: ONTAP 및 VMC(AWS VMware Cloud)용 FSx를 통한 재해 복구</block>
  <block id="e99df6551992d3c39b8c5e87ee8a451f" category="paragraph">클라우드로 재해 복구는 사이트 운영 중단 및 데이터 손상 이벤트(예: 랜섬웨어)로부터 워크로드를 보호하는 복원력이 있고 비용 효율적인 방법입니다. NetApp SnapMirror 기술을 사용하면 사내 VMware 워크로드를 AWS에서 실행되는 ONTAP의 FSx에 복제할 수 있습니다.</block>
  <block id="c52f53db08961cb5fa061b55ca6812c7" category="paragraph">DRO(재해 복구 오케스트레이터, UI를 포함한 스크립팅된 솔루션)를 사용하여 사내에서 ONTAP용 FSx로 복제된 워크로드를 원활하게 복구할 수 있습니다. DRO는 VM 등록을 통해 SnapMirror 레벨에서 VMC로 복구를 자동화하고 NSX-T에서 직접 네트워크 매핑을 수행합니다 이 기능은 모든 VMC 환경에 포함되어 있습니다.</block>
  <block id="273c8112241e399eaf04dc840d119fb6" category="image-alt">이 그래픽은 사내 데이터 센터, AWS SDDC 기반 VMware 클라우드 인스턴스, NetApp ONTAP용 Amazon FSx 간의 구조 및 상호 연결을 보여 줍니다. 여기에는 SnapMirror 복제, DRaaS Ops 트래픽, 인터넷 또는 직접 연결, VMware Transit Connect가 포함됩니다.</block>
  <block id="246c1b44b3a8dc5d7fec2fdc031e49c5" category="section-title">AWS에서 VMware Cloud를 구축 및 구성합니다</block>
  <block id="f828dbeef2a459e165a6fbd33ccf4781" category="paragraph"><block ref="88a970f127e79f2a50f427561bb2a4f6" category="inline-link-macro-rx"></block> AWS 에코시스템의 VMware 기반 워크로드에 클라우드 네이티브 경험을 제공합니다. 각 VMware SDDC(소프트웨어 정의 데이터 센터)는 VPC(Amazon Virtual Private Cloud)에서 실행되며 전체 VMware 스택(vCenter Server 포함), NSX-T 소프트웨어 정의 네트워킹, vSAN 소프트웨어 정의 스토리지 및 워크로드에 컴퓨팅 및 스토리지 리소스를 제공하는 하나 이상의 ESXi 호스트를 제공합니다. AWS에서 VMC 환경을 구성하려면 다음 단계를 수행하십시오 <block ref="48c40480356563b3c93ca3177b91e728" category="inline-link-macro-rx"></block>. DR 목적으로도 파일럿 라이트 클러스터를 사용할 수 있습니다.</block>
  <block id="c3b336e3bd0ee5f4a24fd28ce72d7dea" category="admonition">최초 릴리즈에서 DRO는 기존의 파일럿 라이트 클러스터를 지원합니다. 온디맨드 SDDC 작성은 향후 릴리스에서 제공될 예정입니다.</block>
  <block id="09a69d8335838329a7615e73fa6b1fe0" category="section-title">ONTAP용 FSx를 프로비저닝하고 구성합니다</block>
  <block id="37973daf609f18c7a64511d10e65453e" category="paragraph">NetApp ONTAP용 Amazon FSx는 널리 사용되는 NetApp ONTAP 파일 시스템에 구축된 매우 안정적이고 확장 가능하며 고성능의 풍부한 기능 파일 스토리지를 제공하는 완전 관리형 서비스입니다. 이 단계를 따릅니다 <block ref="a5f36f80544ed8547e72f1f36fb2285b" category="inline-link-macro-rx"></block> ONTAP용 FSx를 프로비저닝하고 구성하려면 다음을 수행합니다.</block>
  <block id="7f38204cc308b0521e747e38f1cb0062" category="section-title">ONTAP용 FSx에 SnapMirror를 구축하고 구성합니다</block>
  <block id="4a6b91648345db53156af03bcc00bde8" category="paragraph">다음 단계는 NetApp BlueXP를 사용하고 AWS에서 ONTAP용 프로비저닝된 FSx 인스턴스를 검색하고 적절한 빈도와 NetApp 스냅샷 복사본 보존을 사용하여 원하는 데이터 저장소 볼륨을 사내 환경에서 ONTAP용 FSx로 복제하는 것입니다.</block>
  <block id="6a4903522028d4e4bd24b3880afcf49f" category="image-alt">이 그래픽은 활성화된 서비스 간의 다양한 상호 작용을 보여 주는 BlueXP Canvas 관계 맵을 보여 줍니다.</block>
  <block id="45568e41c66e2e325c210961987178e7" category="paragraph">이 링크의 단계에 따라 BlueXP를 구성합니다. NetApp ONTAP CLI를 사용하여 이 링크 이후의 복제를 예약할 수도 있습니다.</block>
  <block id="07f3fd5642ddcadbf716c250ccf987f0" category="admonition">SnapMirror 관계는 전제 조건이며 미리 만들어야 합니다.</block>
  <block id="8513f47f7075dac35da070dbceb25a2e" category="section-title">DRO 설치</block>
  <block id="9f8fa80dd85e2409bd0b4495b821f0f3" category="paragraph">DRO를 시작하려면 지정된 EC2 인스턴스 또는 가상 시스템에서 Ubuntu 운영 체제를 사용하여 필수 구성 요소를 충족하는지 확인합니다. 그런 다음 패키지를 설치합니다.</block>
  <block id="7bf01cb2204f9dd0fdff029933600264" category="list-text">소스 및 대상 vCenter 및 스토리지 시스템에 대한 접속이 있는지 확인합니다.</block>
  <block id="4c915967cda97460076cfdb71bc58421" category="list-text">DNS 이름을 사용하는 경우 DNS 확인이 필요합니다. 그렇지 않으면 vCenter 및 스토리지 시스템의 IP 주소를 사용해야 합니다.</block>
  <block id="3cfe50231d6e1ba1b199fc7421fb72e6" category="list-text">루트 권한이 있는 사용자를 생성합니다. EC2 인스턴스에서 sudo를 사용할 수도 있습니다.</block>
  <block id="6e968857b32243865ebf039c1facf6cf" category="section-title">OS 요구 사항</block>
  <block id="184e93a2064767475a538c600a47eb17" category="list-text">지정된 에이전트 VM에 다음 패키지를 설치해야 합니다.</block>
  <block id="1dfe00693fad27f5da719e6aeea58ef6" category="list-text">Docker-Compose</block>
  <block id="31b4674ec2f7760117c224c883183141" category="list-text">JQ</block>
  <block id="240f5270a2e18be8a75b0712b343d07a" category="paragraph">의 사용 권한을 변경합니다<block ref="b1360c159d030cf3e3075d3ec21faf46" prefix=" " category="inline-code"></block>:<block ref="e89a7e38128b2d546718b48d40d827f7" prefix=" " category="inline-code"></block>.</block>
  <block id="76af5eb969b6b58ab010f271730ae0ee" category="admonition">를 클릭합니다<block ref="60254338249f657a0a83f98258a56bfe" prefix=" " category="inline-code"></block> 스크립트는 필요한 모든 필수 구성 요소를 실행합니다.</block>
  <block id="478159949d5b4b537a6ca19613ae98bf" category="section-title">패키지를 설치합니다</block>
  <block id="54d75811a77a2a9b1526f372bc0a733e" category="list-text">지정된 가상 머신에 설치 패키지를 다운로드합니다.</block>
  <block id="97c5338b12461548bb0ceefccd562486" category="admonition">이 에이전트는 사내에 설치하거나 AWS VPC 내에 설치할 수 있습니다.</block>
  <block id="2d2a358ce62dfc056eddea09ea87d1d1" category="list-text">패키지의 압축을 풀고 배포 스크립트를 실행한 다음 호스트 IP(예: 10.10.10)를 입력합니다.</block>
  <block id="4e26021fda30753473246136bacc8094" category="list-text">디렉토리로 이동하고 다음과 같이 배포 스크립트를 실행합니다.</block>
  <block id="f1f49b31dc9a5d88e8029b9d361b9059" category="image-alt">재해 복구 오케스트레이터 로그인 화면</block>
  <block id="7b7ad84593d701138003778be3b6079f" category="section-title">DRO 구성</block>
  <block id="e9ff74e9030350261c678f0da3a354ee" category="paragraph">ONTAP 및 VMC용 FSx가 올바르게 구성된 후에는 ONTAP용 FSx에서 읽기 전용 SnapMirror 복사본을 사용하여 VMC로 온-프레미스 워크로드의 복구를 자동화하도록 DRO를 구성할 수 있습니다.</block>
  <block id="0a99b6b57603a6a9f7dc56799a0fdd8e" category="paragraph">ONTAP용 FSx가 구축된 AWS 및 동일한 VPC에 DRO 에이전트를 구축하는 것이 좋습니다(피어 연결도 가능). DRO 에이전트가 네트워크를 통해 온-프레미스 구성 요소와 ONTAP 및 VMC용 FSx 리소스와 통신할 수 있도록 합니다.</block>
  <block id="c7c5a0daa14b8062f69791fd594efd37" category="paragraph">첫 번째 단계는 온프레미스 및 클라우드 리소스(vCenter 및 스토리지 모두)를 DRO에 검색하고 추가하는 것입니다. 지원되는 브라우저에서 DRO를 열고 기본 사용자 이름 및 암호(admin/admin)와 사이트 추가를 사용합니다. 검색 옵션을 사용하여 사이트를 추가할 수도 있습니다. 다음 플랫폼을 추가합니다.</block>
  <block id="16ee49909b80df9050959890b8f578cb" category="list-text">사내 vCenter</block>
  <block id="e7aed9ec7e7600627310e041dbd517f7" category="list-text">ONTAP 스토리지 시스템</block>
  <block id="e3691c446d2915370eb25cbc68a6521a" category="list-text">VMC vCenter</block>
  <block id="36df1b975561708b246ef1801ea416e5" category="list-text">ONTAP용 FSX</block>
  <block id="c532da281c4c378954b0254be09c051b" category="image-alt">임시 자리 표시자 이미지 설명입니다.</block>
  <block id="3506b8840bdbadcda795249c636510c4" category="image-alt">소스 및 대상 사이트가 포함된 DRO 사이트 개요 페이지</block>
  <block id="cf5e0df8cb3adb3df51d336ec0b2211a" category="paragraph">추가된 DRO는 자동 검색을 수행하고 소스 스토리지에서 ONTAP용 FSx로 해당 SnapMirror 복제본이 있는 VM을 표시합니다. DRO는 VM에서 사용하는 네트워크 및 포트 그룹을 자동으로 감지하여 채웁니다.</block>
  <block id="abf7897bce5034c7714d0b7757ccac4c" category="image-alt">219개의 VM과 10개의 데이터 저장소가 포함된 자동 검색 화면</block>
  <block id="8ad855ec9cdd9c029c645af01c256999" category="paragraph">다음 단계는 필요한 VM을 기능 그룹으로 그룹화하여 리소스 그룹 역할을 하는 것입니다.</block>
  <block id="cdac0221d4dabd98123be4284952f872" category="section-title">리소스 그룹화</block>
  <block id="7546309b604714e5c864eef677efcd63" category="paragraph">플랫폼을 추가한 후 복구할 VM을 리소스 그룹으로 그룹화할 수 있습니다. DRO 리소스 그룹을 사용하면 종속 VM 집합을 부팅 순서, 부팅 지연 및 복구 시 실행할 수 있는 선택적 응용 프로그램 유효성 검사가 포함된 논리 그룹으로 그룹화할 수 있습니다.</block>
  <block id="265d81bb1af077020a501dcc75af41e1" category="paragraph">리소스 그룹 생성을 시작하려면 다음 단계를 수행하십시오.</block>
  <block id="a226ebee500532f5a9b1a5cbcb1db6d9" category="list-text">리소스 그룹 * 에 액세스하여 * 새 리소스 그룹 생성 * 을 클릭합니다.</block>
  <block id="cfc3c82954c855841a78a216dec1b32b" category="list-text">새 리소스 그룹 * 의 드롭다운에서 소스 사이트를 선택하고 * 만들기 * 를 클릭합니다.</block>
  <block id="c47c9ace957accd98c45c515282fb851" category="list-text">리소스 그룹 세부 정보 * 를 입력하고 * 계속 * 을 클릭합니다.</block>
  <block id="5e4c1f12f71cc535b41e76690fd718e3" category="list-text">검색 옵션을 사용하여 적절한 VM을 선택합니다.</block>
  <block id="de5c4b583db3aa4040c8d082ee2d1bcd" category="list-text">선택한 VM의 부팅 순서 및 부팅 지연(초)을 선택합니다. 각 VM을 선택하고 우선 순위를 설정하여 전원 켜기 순서의 순서를 설정합니다. 모든 VM의 기본값은 3입니다.</block>
  <block id="c32b3a0f06aa80c00476ddcabd88fde1" category="paragraph">옵션은 다음과 같습니다.</block>
  <block id="a89a043e6faeacde759612c6bfa5cc1c" category="paragraph">1 – 전원을 켤 첫 번째 가상 머신 3 – 기본값 5 – 전원을 켤 마지막 가상 머신</block>
  <block id="84a63bc4997af6ded1933281f4b8babb" category="list-text">리소스 그룹 만들기 * 를 클릭합니다.</block>
  <block id="0942dfbe3d3b0a1d41f357604f7e9fb2" category="image-alt">테스트 및 DemoRG1의 두 항목이 포함된 자원 그룹 목록의 스크린샷.</block>
  <block id="a8fc43ecd23ee9eb5e9efa5c60cb20b9" category="section-title">복제 계획</block>
  <block id="901831e404573eb9a2cc09f43d42e661" category="paragraph">재해가 발생할 경우 애플리케이션을 복구할 계획이 필요합니다. 드롭다운에서 소스 및 대상 vCenter 플랫폼을 선택하고 이 계획에 포함할 리소스 그룹을 선택하고, 애플리케이션 복구 및 전원 켜기 방법(예: 도메인 컨트롤러, 계층 1, 계층 2 등)을 그룹화합니다. 이러한 계획을 청사진이라고도 합니다. 복구 계획을 정의하려면 * Replication Plan * 탭으로 이동하여 * New Replication Plan * 을 클릭합니다.</block>
  <block id="f2e437ba3d91f90c4bd8d4b35ce32b78" category="paragraph">복제 계획 생성을 시작하려면 다음 단계를 수행하십시오.</block>
  <block id="7e2b1b88ae2fef26c3f9f94bc389f0d1" category="list-text">Replication Plans * 에 액세스하여 * Create New Replication Plan * 을 클릭합니다.</block>
  <block id="84ef8711a6a318c8bf4b8acfd4f1551c" category="image-alt">DemoRP라는 하나의 계획이 포함된 복제 계획 화면의 스크린샷</block>
  <block id="b9493784814dfebf88fc26091f72b601" category="list-text">새 복제 계획 * 에서 소스 사이트, 연결된 vCenter, 대상 사이트 및 연결된 vCenter를 선택하여 계획 이름을 제공하고 복구 매핑을 추가합니다.</block>
  <block id="88cedf638ed2d7e4779e1c47ee7c5ea1" category="image-alt">복구 매핑을 포함한 복제 계획 세부 정보의 스크린샷</block>
  <block id="d360387ddbca9636208f2b8a948f56b0" category="list-text">복구 매핑이 완료되면 클러스터 매핑을 선택합니다.</block>
  <block id="57e1d9c7da09c1484785ce5de748a5a4" category="list-text">리소스 그룹 세부 정보 * 를 선택하고 * 계속 * 을 클릭합니다.</block>
  <block id="28a5e1b451c50affbe5e71d787ef2818" category="list-text">리소스 그룹의 실행 순서를 설정합니다. 이 옵션을 사용하면 여러 리소스 그룹이 있을 때 작업 순서를 선택할 수 있습니다.</block>
  <block id="35e931afb6f8f9ea976030c41d20091d" category="list-text">작업을 완료한 후 해당 세그먼트에 대한 네트워크 매핑을 선택합니다. 세그먼트는 VMC 내에서 이미 프로비저닝되어야 하므로 VM을 매핑할 적절한 세그먼트를 선택하십시오.</block>
  <block id="4279ce58393302704e1d9f4ef8e18ca2" category="list-text">선택한 VM에 따라 데이터 저장소 매핑이 자동으로 선택됩니다.</block>
  <block id="920e197d79d1f4f66caaef11426066ba" category="admonition">SnapMirror가 볼륨 레벨에 있습니다. 따라서 모든 VM이 복제 대상에 복제됩니다. 데이터 저장소에 속한 모든 VM을 선택해야 합니다. 이 옵션을 선택하지 않으면 복제 계획에 포함된 VM만 처리됩니다.</block>
  <block id="76074b4a55fc86674d98cacd953dd720" category="list-text">VM 세부 정보 아래에서 VM의 CPU 및 RAM 매개 변수의 크기를 선택적으로 조정할 수 있습니다. 이는 대규모 환경을 소규모 타겟 클러스터로 복구하거나 일대일 물리적 VMware 인프라를 프로비저닝하지 않고도 DR 테스트를 수행할 때 매우 유용합니다. 또한 리소스 그룹에서 선택한 모든 VM에 대한 부팅 순서 및 부팅 지연(초)을 수정할 수 있습니다. 리소스 그룹 부팅 순서 선택 중에 선택한 변경 사항에서 필요한 변경 사항이 있는 경우 부팅 순서를 수정하는 추가 옵션이 있습니다. 기본적으로 리소스 그룹을 선택하는 동안 선택한 부팅 순서가 사용되지만 이 단계에서는 모든 수정 작업을 수행할 수 있습니다.</block>
  <block id="61b06cf38207274281ff2f90f66b49fa" category="list-text">Create Replication Plan * 을 클릭합니다.</block>
  <block id="8066d08fcf99bee6a3bb8bc060a5d031" category="paragraph">복제 계획이 생성되면 요구 사항에 따라 페일오버 옵션, 테스트 페일오버 옵션 또는 마이그레이션 옵션을 사용할 수 있습니다. 페일오버 및 테스트 페일오버 옵션 중에 최신 SnapMirror 스냅샷 복사본이 사용되거나, SnapMirror의 보존 정책에 따라 특정 시점의 Snapshot 복사본에서 특정 스냅샷 복사본을 선택할 수 있습니다. 가장 최근의 복제본이 이미 손상 또는 암호화된 상태에서 랜섬웨어와 같은 손상 이벤트가 발생할 경우 시점 옵션이 매우 유용할 수 있습니다. DRO는 사용 가능한 모든 시점을 표시합니다. 복제 계획에 지정된 구성으로 대체 작동을 트리거하거나 테스트 대체 작동을 트리거하려면 * 장애 조치 * 또는 * 테스트 대체 작동 * 을 클릭합니다.</block>
  <block id="9f6a9153365f1438c116145bc14ba9a9" category="image-alt">이 화면에서는 볼륨 스냅샷 세부 정보가 제공되며 최신 스냅샷을 사용하고 특정 스냅샷을 선택할 수 있습니다.</block>
  <block id="45c261be0b43693546955e87bd6ac10f" category="paragraph">복제 계획은 작업 메뉴에서 모니터링할 수 있습니다.</block>
  <block id="0225a4a711bba4eb595e835ad67356fc" category="image-alt">작업 메뉴에는 복제 계획에 대한 모든 작업 및 옵션이 표시되며 로그를 볼 수도 있습니다.</block>
  <block id="8d2831d40faa91653285bd44edc3917d" category="paragraph">페일오버가 트리거된 후 복구된 항목이 VMC vCenter(VM, 네트워크, 데이터 저장소)에서 표시될 수 있습니다. 기본적으로 VM은 Workload 폴더로 복구됩니다.</block>
  <block id="d45215d9339daaa38e8c825812d30a02" category="paragraph">페일백은 복제 계획 레벨에서 트리거될 수 있습니다. 테스트 페일오버의 경우 최분해 옵션을 사용하여 변경 사항을 롤백하고 FlexClone 관계를 제거할 수 있습니다. 페일오버와 관련된 페일백은 2단계 프로세스입니다. 복제 계획을 선택하고 * Reverse data sync * 를 선택합니다.</block>
  <block id="5f3ce61b7a4ffe23687402e421b81e18" category="image-alt">역방향 데이터 동기화 옵션이 포함된 드롭다운이 있는 복제 계획 개요 스크린샷</block>
  <block id="acd827a33a3e445ce9d2c9d94ff63886" category="paragraph">완료되면 페일백을 트리거하여 원래 운영 사이트로 다시 이동할 수 있습니다.</block>
  <block id="0c86039a87483290f146f9170e80b40b" category="image-alt">페일백 옵션이 포함된 드롭다운이 있는 복제 계획 개요 스크린샷</block>
  <block id="503c1e37074b31fdcd74fbffb13e3983" category="image-alt">원본 프로덕션 사이트가 가동되어 실행 중인 DRO 요약 페이지의 스크린샷.</block>
  <block id="0d95c1c8686951d59b82bdc816a93231" category="paragraph">NetApp BlueXP에서는 복제 상태가 적절한 볼륨(VMC에 읽기-쓰기 볼륨으로 매핑된 볼륨)에 대해 끊어지는 것을 볼 수 있습니다. 테스트 페일오버 중에 DRO는 대상 또는 복제본 볼륨을 매핑하지 않습니다. 대신 필요한 SnapMirror(또는 Snapshot) 인스턴스의 FlexClone 복사본을 만들고 FlexClone 인스턴스를 노출합니다. FlexClone 인스턴스는 ONTAP용 FSx의 추가 물리적 용량을 소비하지 않습니다. 이 프로세스를 통해 DR 테스트 또는 분류 워크플로우 중에도 볼륨을 수정하지 않고 복제 작업을 계속할 수 있습니다. 또한 이 프로세스를 통해 오류가 발생하거나 손상된 데이터가 복구되면 복제본을 제거할 위험 없이 복구를 정리할 수 있습니다.</block>
  <block id="648a04436d5621ca9c7c65c66c55cb79" category="section-title">랜섬웨어 복구</block>
  <block id="f1d63aa61bd9bd59550523eea84313e8" category="paragraph">랜섬웨어에서 복구하는 것은 매우 힘든 작업이 될 수 있습니다. 특히, IT 조직은 안전한 반환 지점이 어디인지 정확히 파악하기가 어려우며, 일단 결정된 후에는 침낭성 맬웨어 또는 취약한 응용 프로그램 등의 재발생 공격으로부터 복구된 워크로드를 보호하기가 어려울 수 있습니다.</block>
  <block id="c6ceeada99ad37301b94760e7f4bcab8" category="paragraph">DRO는 사용 가능한 모든 시점에서 시스템을 복구할 수 있도록 함으로써 이러한 문제를 해결합니다. 또한 작업 부하를 기능적이면서도 격리된 네트워크로 복구할 수 있으므로 응용 프로그램이 남북 트래픽에 노출되지 않은 위치에서 상호 작동하고 통신할 수 있습니다. 이를 통해 보안 팀은 법의학 조사를 안전하게 수행할 수 있으며, 숨겨진 악성 코드나 잠자는 맬웨어가 없는지 확인할 수 있습니다.</block>
  <block id="468a6beafe68b7f0e997ea3b22eaf021" category="list-text">효율적이고 복원력이 뛰어난 SnapMirror 복제 사용:</block>
  <block id="8dc2f1e4e39bbf8b271892846d90aee7" category="list-text">Snapshot 복사본 보존을 통해 사용 가능한 모든 시점으로 복구합니다.</block>
  <block id="6aaf12643047ec9787cc07db9f7e812a" category="list-text">스토리지, 컴퓨팅, 네트워크 및 애플리케이션 검증 단계에서 수백 또는 수천 개의 VM을 복구하는 데 필요한 모든 단계를 완벽하게 자동화</block>
  <block id="3067ce32bcf775ef4562f0900ee04ccf" category="list-text">ONTAP FlexClone 기술을 사용하여 복제된 볼륨을 변경하지 않는 방법으로 워크로드 복구</block>
  <block id="6359f2b426c28e13cbb7b8382496081c" category="list-text">볼륨 또는 스냅샷 복사본에 대한 데이터 손상 위험을 방지합니다.</block>
  <block id="cd08b15dd8bc6a19026ca47b4bcd618d" category="list-text">DevTest, 보안 테스트, 패치 또는 업그레이드 테스트, 수정 테스트 등과 같은 DR 이외의 다른 워크플로우에 클라우드 컴퓨팅 리소스를 사용하여 DR 데이터를 사용할 수 있습니다.</block>
  <block id="7d73fdff5300d11e557be0d55023b8e8" category="list-text">CPU 및 RAM 최적화를 통해 보다 작은 컴퓨팅 클러스터로 복구할 수 있으므로 클라우드 비용을 절감할 수 있습니다.</block>
  <block id="d923ff878d26dac68fc7ac0c94a428f0" category="inline-link-macro">ONTAP 및 VMC용 FSx를 통한 재해 복구(DRO</block>
  <block id="1ecab9e830a635b196a9f6c159eefe2c" category="list-text"><block ref="1ecab9e830a635b196a9f6c159eefe2c" category="inline-link-macro-rx"></block></block>
  <block id="46d1e37416bef4df8c1962b95c983bb0" category="sidebar">GCVE+ CVS TCO 계산기</block>
  <block id="15a2a7497ac6041e1b73d7cb41406245" category="doc">TR-4811: 의료 서비스를 위한 NetApp ONTAP AI 참조 아키텍처: 진단 이미징 - 솔루션 설계</block>
  <block id="5c6168ae6047f496e6903dde0fd3033c" category="paragraph"><block ref="5c6168ae6047f496e6903dde0fd3033c" category="inline-link-macro-rx"></block></block>
  <block id="4adfb8f589471885ed2256c4719146a6" category="doc">TR-4815: AI 및 ML 모델 훈련 워크로드용 NetApp AFF A800 및 Fujitsu Server PRIMERGY GX2570 M5</block>
  <block id="d6f6c54736f64c202c28a1736214c268" category="paragraph"><block ref="d6f6c54736f64c202c28a1736214c268" category="inline-link-macro-rx"></block></block>
  <block id="96f5c57f6fea73d6692c5f8c2703e9b9" category="doc">NVA-1150-design:Quantum StorNext with NetApp E-Series 시스템 설계 가이드</block>
  <block id="4f8b12df588cb1e82eb6d578f26c6c62" category="paragraph"><block ref="4f8b12df588cb1e82eb6d578f26c6c62" category="inline-link-macro-rx"></block></block>
  <block id="7054aac0ed39fa340a2d8034700f7366" category="doc">NVA-1151-design:NVIDIA DGX A100 시스템 설계 가이드를 지원하는 NetApp ONTAP AI</block>
  <block id="c3e7dfc3691f26701d35cccf4caf7151" category="paragraph"><block ref="c3e7dfc3691f26701d35cccf4caf7151" category="inline-link-macro-rx"></block></block>
  <block id="4357c1771697cec588056fc32ddcb708" category="doc">TR-4810: AI 및 ML 모델 교육 워크로드용 NetApp ONTAP 및 Lenovo ThinkSystem SR670</block>
  <block id="e0f6e346d478416affd57903ead08043" category="paragraph">TR-4810은 V100 GPU에 대한 TensorFlow를 통한 이미지 분류 교육을 평가하는 업계 표준 MLPerf 벤치마크에 대한 성능 데이터를 제공합니다. 성능을 측정하기 위해, ImageNet 데이터 세트, 배치 크기 512, 절반 정밀도, CUDA 및 cuDNN을 사용하여 ResNet50을 사용했습니다. 이 분석은 4개의 GPU SR670 서버와 엔트리 레벨 NetApp 스토리지 시스템을 사용하여 수행했습니다. 이 결과는 공유, 다중 사용자, 다중 작업 사례 등 여기에서 테스트한 여러 사용 사례에서 최대 4개의 서버로 확장 가능한 개별 작업 전체에서 매우 효율적인 성능을 보여줍니다. 대규모 스케일아웃 작업은 효율성이 낮지만 여전히 실현 가능합니다.</block>
  <block id="f19874be6cd1b381c570f4157608de5f" category="paragraph"><block ref="f19874be6cd1b381c570f4157608de5f" category="inline-link-macro-rx"></block></block>
  <block id="c95fe91ba2d256285401bdabdd666ca7" category="doc">NVA-1151 - 구축:NVIDIA DGX A100 시스템과 NetApp ONTAP AI</block>
  <block id="3f8a5951b902f50dcbc39690406ade15" category="paragraph"><block ref="3f8a5951b902f50dcbc39690406ade15" category="inline-link-macro-rx"></block></block>
  <block id="83c4efb371f86415987632c0baa2d086" category="doc">NVA-1156-설계: NVIDIA DGX A100 시스템 및 BeeGFS를 지원하는 NetApp EF-Series AI</block>
  <block id="2003f72965a4dbc9f31bdaa3da5deaa2" category="paragraph"><block ref="2003f72965a4dbc9f31bdaa3da5deaa2" category="inline-link-macro-rx"></block></block>
  <block id="716c8038f7ef1bc60bc3fe6c036e2d3b" category="doc">TR-4807: 금융 서비스 워크로드를 위한 NetApp ONTAP AI 참조 아키텍처 - 솔루션 설계</block>
  <block id="96ac76dbb46fec3f4db7ec194dc52d2a" category="paragraph"><block ref="96ac76dbb46fec3f4db7ec194dc52d2a" category="inline-link-macro-rx"></block></block>
  <block id="a5e99aa2ffae2218fdcf2038b1b3fd1b" category="doc">TR-4851: 자율 주행 워크로드를 위한 NetApp StorageGRID 데이터 레이크 - 솔루션 설계</block>
  <block id="ba9a0dcacc73fb54c527ad33eceb30c1" category="paragraph"><block ref="ba9a0dcacc73fb54c527ad33eceb30c1" category="inline-link-macro-rx"></block></block>
  <block id="fcf432f7f886df6aeafb1dec9357085d" category="doc">NVA-1150-Deploy:Quantum StorNext with NetApp E-Series 시스템 구축 가이드</block>
  <block id="74e37c842f0aa66d129305c85d5f458a" category="paragraph">이 문서에서는 NetApp E-Series 스토리지 시스템을 통해 StorNext 병렬 파일 시스템 솔루션을 구축하는 방법에 대해 자세히 설명합니다. 이 솔루션은 NetApp EF280 All-Flash 어레이, NetApp EF300 All-Flash NVMe 어레이, NetApp EF600 All-Flash NVMe 어레이, NetApp E57760 하이브리드 시스템에 적용됩니다. 미디어 및 엔터테인먼트 업계에서 테스트에 널리 사용되는 도구인 프레임 벤치마킹(Frametest Benchmarking)을 기반으로 성능 특성을 제공합니다.</block>
  <block id="a06fe4c2db4f7b09c705e4e8dafb5627" category="paragraph"><block ref="a06fe4c2db4f7b09c705e4e8dafb5627" category="inline-link-macro-rx"></block></block>
  <block id="837896d23c0eee81106906ab4cef7a6d" category="doc">TR-4799 - 설계: 자율 주행 워크로드를 위한 NetApp ONTAP AI 참조 아키텍처</block>
  <block id="63e3877ed0a830d2fb8beed8fffb2df4" category="paragraph">NVIDIA DGX 시스템 제품군은 엔터프라이즈 AI용으로 특별 제작된 세계 최초의 통합 인공 지능(AI) 플랫폼입니다. NetApp AFF 스토리지 시스템은 탁월한 성능과 업계 최고 수준의 하이브리드 클라우드 데이터 관리 기능을 제공합니다. NetApp과 NVIDIA는 협력 관계를 맺고 엔터프라이즈급 지원, 안정성 및 성능으로 AI 및 머신 러닝(ML) 워크로드를 지원하는 턴키 솔루션을 고객에게 제공할 수 있는 NetApp ONTAP AI 참조 아키텍처를 구축했습니다.</block>
  <block id="873b0fe1ee8adb4c5e6401e2fabf0734" category="paragraph"><block ref="873b0fe1ee8adb4c5e6401e2fabf0734" category="inline-link-macro-rx"></block></block>
  <block id="b7c82ef45da5d640a92ce6fb8fb757b7" category="doc">NVA-1153-design:NVIDIA DGX A100 시스템 및 Mellanox Spectrum 이더넷 스위치가 있는 NetApp ONTAP AI</block>
  <block id="3dbdc92d258dcfc8f4fb9e2723a77875" category="paragraph"><block ref="3dbdc92d258dcfc8f4fb9e2723a77875" category="inline-link-macro-rx"></block></block>
  <block id="bf6adc497a862180909278cf6ed029f1" category="doc">TR-4859: NetApp E-Series 스토리지를 통해 IBM 스펙트럼 확장 구축 - 설치 및 검증</block>
  <block id="6a51aeb3b4e11ee4436f8ad323e23c5a" category="paragraph"><block ref="6a51aeb3b4e11ee4436f8ad323e23c5a" category="inline-link-macro-rx"></block></block>
  <block id="9892437a073c63ca6232150c28b21c7b" category="doc">NVA-1156-구축:NVIDIA DGX A100 시스템 및 BeeGFS를 지원하는 NetApp EF-Series AI</block>
  <block id="ac6445146035971ff06dde08fd7cd295" category="paragraph"><block ref="ac6445146035971ff06dde08fd7cd295" category="inline-link-macro-rx"></block></block>
  <block id="9708ffc88c964c7e13b023f7eba9396b" category="doc">NVA-1153 - 구축: NVIDIA DGX A100 시스템 및 Mellanox Spectrum 이더넷 스위치가 포함된 NetApp ONTAP AI</block>
  <block id="50f2d8c31ffcba4aeffd6f55fd0f8bd2" category="paragraph"><block ref="50f2d8c31ffcba4aeffd6f55fd0f8bd2" category="inline-link-macro-rx"></block></block>
  <block id="3c2e1436532e8615aa8fdb7bb7432f80" category="paragraph">온프레미스 Oracle 데이터베이스가 ONTAP 스토리지 어레이에 있는 경우 AWS FSx ONTAP 스토리지에 내장된 NetApp SnapMirror 기술을 사용하여 데이터베이스 마이그레이션을 위한 복제를 쉽게 설정할 수 있습니다. NetApp BlueXP 콘솔을 사용하여 마이그레이션 프로세스를 조정할 수 있습니다.</block>
  <block id="ed7c233990ddaa2e7103a9f5b77ee3de" category="list-text">전환 시 운영 애플리케이션을 종료하여 모든 트랜잭션을 중지합니다. Oracle sqlplus CLI 인터페이스에서 Oracle 온라인 로그 스위치를 실행하고 SnapMirror 동기화가 타겟 볼륨에 마지막으로 아카이빙된 로그를 푸시하도록 허용합니다.</block>
  <block id="094ef1326e70f1212e06a1b5d65d2922" category="paragraph">다음 비디오에서는 NetApp BlueXP 콘솔 및 SnapMirror 복제를 사용하여 Oracle 데이터베이스를 사내에서 AWS FSx/EC2로 마이그레이션하는 방법을 보여줍니다.</block>
  <block id="0ed0689d68d30d32584025a19c85c9e1" category="inline-link-macro">SnapMirror 및 BlueXP를 통해 사내에서 FSx/EC2로 Oracle 데이터베이스 마이그레이션</block>
  <block id="bb74f90e0bd42cad827c08c3b5a1d1f8" category="paragraph"><block ref="bb74f90e0bd42cad827c08c3b5a1d1f8" category="inline-link-macro-rx"></block></block>
  <block id="e54801d4a4497c3566a98c0ef4ec6f18" category="section-title">최대한의 가용성과 함께 PDB 재배치를 사용하여 온프레미스 Oracle 데이터베이스를 AWS FSx/EC2로 마이그레이션합니다</block>
  <block id="16d584a60d17de3de7cd0dcc0828fee9" category="paragraph">이 마이그레이션 방식은 PDB/CDB 멀티 테넌트 모델에 이미 배포된 Oracle 데이터베이스에 가장 적합하며 ONTAP 스토리지는 온-프레미스에서 사용할 수 없습니다. PDB 재배치 방법은 Oracle PDB 핫 클론 기술을 활용하여 소스 CDB와 대상 CDB 간에 PDB를 이동하는 동시에 서비스 중단을 최소화합니다.</block>
  <block id="c5bd16be343bf2e5a3c081284c6c799b" category="paragraph">먼저, 사내에서 마이그레이션할 PDB를 호스팅할 충분한 스토리지를 가진 AWS FSx/EC2에서 CDB를 생성합니다. 여러 온프레미스 PDB를 한 번에 하나씩 재배치할 수 있습니다.</block>
  <block id="a6c9ea7b4477a21ac635b1db86abae5e" category="list-text">멀티 테넌트 PDB/CDB 모델이 아닌 단일 인스턴스에 온-프레미스 데이터베이스가 배포된 경우 의 지침을 따릅니다 <block ref="1a6a40cd2cc4844be72d5fbe9fd5f1e6" category="inline-link-macro-rx"></block> 단일 인스턴스를 멀티 테넌트 PDB/CDB로 변환합니다. 그런 다음 다음 다음 단계에 따라 변환된 PDB를 AWS FSx/EC2에서 CDB로 마이그레이션합니다.</block>
  <block id="92c29ab4b5bfbc6de30e29363bc9aea7" category="inline-link-macro">PDB 재배치를 통해 온프레미스 Oracle 데이터베이스를 클라우드로 마이그레이션합니다</block>
  <block id="522ca40aa0d528d119dec226eb9719b8" category="list-text">멀티 테넌트 PDB/CDB 모델에 온-프레미스 데이터베이스가 이미 배포된 경우 의 지침을 따릅니다 <block ref="02137814e079cdfea8552a492195c829" category="inline-link-macro-rx"></block> 마이그레이션을 수행합니다.</block>
  <block id="499d7c245aad786a568d21227b5b65d8" category="paragraph">다음 비디오에서는 최대 가용성과 함께 PDB 재배치를 사용하여 Oracle 데이터베이스(PDB)를 FSx/EC2로 마이그레이션하는 방법을 보여 줍니다.</block>
  <block id="c0d2cea4b49d55201605052121b68ca7" category="inline-link-macro">온프레미스 Oracle PDB를 최대 가용성으로 AWS CDB로 마이그레이션합니다</block>
  <block id="e3d2de69302b3f20931015cece4526e4" category="paragraph"><block ref="5deefe7b3e78f7f08541c2e7b5b56e54" category="inline-link-macro-rx"></block></block>
  <block id="5eae2f4290a9e1f77061f80c6c015bc6" category="admonition">1단계와 2단계의 지침이 Azure 퍼블릭 클라우드의 맥락에서 설명되지만 이 절차는 변경 없이 AWS 클라우드에 적용할 수 있습니다.</block>
  <block id="41099d15ad008ac11d04538ef8e57575" category="paragraph">NetApp 솔루션 자동화 팀에서는 사내에서 AWS 클라우드로 Oracle 데이터베이스를 쉽게 마이그레이션할 수 있는 마이그레이션 툴킷을 제공합니다. 다음 명령을 사용하여 PDB 재배치용 Oracle 데이터베이스 마이그레이션 툴킷을 다운로드합니다.</block>
  <block id="eef7539c8eab25bfe5c089aab85ec418" category="paragraph">솔루션 및 사용 사례에 대해 자세히 알아보려면 다음 개요 비디오 를 참조하십시오.</block>
  <block id="0df1fe5dfbca17caa87c91ffea49223a" category="inline-link-macro">AWS 및 FSx ONTAP, Part1 - 활용 사례 및 솔루션 아키텍처의 하이브리드 클라우드로 Oracle 데이터베이스를 현대화하십시오</block>
  <block id="adf8d1fc36b4704904a6251fde19535e" category="paragraph"><block ref="bab032e290776958656c886d774a2bf6" category="inline-link-macro-rx"></block></block>
  <block id="3282bd4b5c29b5e9be65469e592bba18" category="doc">Microsoft SQL Server 환경의 현대화</block>
  <block id="b5b095487ccabae138c7872353cadbe6" category="paragraph"><block ref="b5b095487ccabae138c7872353cadbe6" category="inline-link-macro-rx"></block></block>
  <block id="ebcadd0d5b1096e72d18133b1e0e3098" category="doc">TR-4467: Windows 기반 Microsoft SQL Server 기반 SAP - NetApp clustered Data ONTAP 및 SnapCenter 사용 모범 사례</block>
  <block id="d90b6dfa1c90883fc207f3309f98b1bf" category="paragraph"><block ref="d90b6dfa1c90883fc207f3309f98b1bf" category="inline-link-macro-rx"></block></block>
  <block id="046c9e52934c311f81497ca664d86a24" category="doc">TR-4764: NetApp EF-Series를 통한 Microsoft SQL Server의 모범 사례</block>
  <block id="730874cec0e792d7ebad5a796a90b3be" category="paragraph"><block ref="730874cec0e792d7ebad5a796a90b3be" category="inline-link-macro-rx"></block></block>
  <block id="ffaaa5a04a78a6ce5d807980dbf83e64" category="paragraph">FC를 통한 FlexPod 데이터 센터 및 Cisco UCS와 NetApp AFF A800의 Oracle 19c RAC 데이터베이스에 대한 이 설계 및 구축 가이드는 Oracle Linux 8.2를 사용하는 최신 FlexPod 데이터 센터 인프라에 Oracle RAC 데이터베이스를 호스팅하기 위한 단계별 구축 프로세스와 솔루션 설계에 대한 세부 정보를 제공합니다 운영 체제 및 Red Hat 호환 커널.</block>
  <block id="8c121c8c1e758ef244a52184e2d48c66" category="paragraph">TR-4623에서는 NetApp E-Series 및 Splunk 설계의 통합 아키텍처에 대해 설명합니다. 노드 스토리지의 균형, 안정성, 성능, 스토리지 용량, 밀도 및 이 설계에서는 Splunk clustered 인덱스 노드 모델을 채택하므로 확장성이 높고 TCO가 낮습니다. 스토리지를 컴퓨팅에서 분리하여 개별적으로 확장할 수 있으므로 오버프로비저닝 비용을 절감할 수 있습니다. 또한, 이 문서에는 Splunk 머신 로그 이벤트 시뮬레이션 툴에서 얻은 성능 테스트 결과가 요약되어 있습니다.</block>
  <block id="e2e44d09263d2131a3697ad71cadb51b" category="doc">NVA-1157 - 배포: NetApp 스토리지 솔루션을 사용한 Apache Spark 워크로드</block>
  <block id="ddf79baf38c476a90774aad122f73cb5" category="paragraph">NVA-1157-deploy는 NetApp NFS AFF 스토리지 시스템에서 Apache Spark SQL의 성능 및 기능 검증을 설명합니다. 다양한 시나리오를 기반으로 구성, 아키텍처, 성능 테스트를 검토하고 Spark with NetApp ONTAP 데이터 관리 소프트웨어 사용을 위한 권장사항을 살펴보십시오. 또한 JBOD(Just a Bunch of Disks) 와 NetApp AFF A800 스토리지 컨트롤러를 기반으로 한 테스트 결과에 대해서도 다룹니다.</block>
  <block id="39234cd00ad225afa457b33c5b2c5957" category="paragraph"><block ref="39234cd00ad225afa457b33c5b2c5957" category="inline-link-macro-rx"></block></block>
  <block id="2eded16d414f6935c27c95495a25eb53" category="cell">2023년 1월 24일</block>
  <block id="d75c9f4acb46fbd1cc7aeecbd376940e" category="cell">TR-4954 추가: Azure NetApp Files에서 Oracle 데이터베이스 구축 및 보호</block>
  <block id="f0a30c2a34036665913459cc735f4786" category="doc">TR-4704: NetApp E-Series 스토리지를 사용하여 Veritas NetBackup 구축</block>
  <block id="7ff53b7713dd7f38a4729f8a1a48f24e" category="paragraph"><block ref="7ff53b7713dd7f38a4729f8a1a48f24e" category="inline-link-macro-rx"></block></block>
  <block id="5e8c99d8eb1f9fde413c715abb6fa392" category="doc">TR-4320: NetApp E-Series 및 Commvault Data Platform V11 - 참조 아키텍처 및 스토리지 모범 사례</block>
  <block id="b5132c157b5da84909699e1aad5ea13d" category="inline-link-macro">TR-4320: NetApp E-Series 및 Commvault Data Platform V11 - 참조 아키텍처 및 스토리지 모범 사례</block>
  <block id="65c8e697e97b6ce1bd59d8334eaaab6f" category="paragraph"><block ref="65c8e697e97b6ce1bd59d8334eaaab6f" category="inline-link-macro-rx"></block></block>
  <block id="849bdf40e7fa0e2cab1cb845682e6f56" category="doc">TR-4471: Veeam Backup &amp; Replication 9.5의 E-Series 및 EF-Series 참조 아키텍처 및 스토리지 모범 사례</block>
  <block id="3bad2cd66e539f0136fbf484133914dd" category="paragraph">TR-4471에서는 Veeam Backup &amp; Replication 9.5 환경에서 NetApp E-Series 스토리지를 사용할 때의 참조 아키텍처 및 모범 사례에 대해 설명합니다.</block>
  <block id="f86686bed105d7053fbb06167a05f38e" category="inline-link-macro">TR-4471: Veeam Backup &amp; amp; Replication 9.5를 사용한 E-Series 및 EF-Series 참조 아키텍처 및 스토리지 모범 사례</block>
  <block id="8a9473d2b45da95a2d08524f5b182c4d" category="paragraph"><block ref="30941a222a593c860776bbf0831d36d0" category="inline-link-macro-rx"></block></block>
  <block id="97b39392e3b66691f26174f9392c96d0" category="doc">NVA-1143:NetApp HCI-NIST Security Controls for FISMA with HyTrust Infrastructure-NVA 설계 및 구축</block>
  <block id="86e20b04ba1f19de7a30d7843155e285" category="paragraph"><block ref="86e20b04ba1f19de7a30d7843155e285" category="inline-link-macro-rx"></block></block>
  <block id="7c3806f623157e3b19cc1801dd72a85d" category="inline-link-macro">Google Cloud VMware Engine(NetApp)에 대한 NetApp Cloud Volumes Service 데이터 저장소 지원</block>
  <block id="5e25da2b2b250c19fcd7efe36b782cc9" category="list-text"><block ref="5e25da2b2b250c19fcd7efe36b782cc9" category="inline-link-macro-rx"></block></block>
  <block id="c540d1dfacf4a64cc435acb640f4cbd4" category="inline-link-macro">NetApp CVS를 Google Cloud VMware Engine(Google)용 데이터 저장소로 사용하는 방법</block>
  <block id="4a8385e4a45d508eea692800bf2323d9" category="list-text"><block ref="4a8385e4a45d508eea692800bf2323d9" category="inline-link-macro-rx"></block></block>
  <block id="8031035e3922dbc188f876cc6fb8434d" category="inline-link-macro">Google Cloud VMware Engine에 대한 NetApp Cloud Volumes Service 데이터 저장소 지원(NetApp 블로그)</block>
  <block id="71f1bcf72187cb460ce8534fd5439962" category="inline-link-macro">NetApp CVS를 Google Cloud VMware Engine용 데이터 저장소로 사용하는 방법(Google 블로그)</block>
  <block id="5ca70e1272bcfe0644f6a52e2d971039" category="paragraph">에 대해 자세히 알아보십시오 <block ref="0d04aae7b3b1a3149a54ebc44d21fc72" category="inline-link-macro-rx"></block> 또는 <block ref="c1e740ec580b7430a1cc324eec4af172" category="inline-link-macro-rx"></block></block>
  <block id="2284540fd2f120164fbe2ca5d318f1f4" category="sidebar">NFS 데이터 저장소 보충 공지</block>
  <block id="92db868215c2d725770eeb14e1e377e1" category="sidebar">CVS: 보조 데이터 저장소로서(NetApp 블로그)</block>
  <block id="d99ca343caa90da336986677343c31fa" category="sidebar">보충 NFS 데이터 저장소 옵션 (NetApp 블로그)</block>
  <block id="b4fd1d48279ed0bed231fbd3b96a1e3a" category="list-text">최소 2GB 및 4개의 vCPU가 있는 Ubuntu 20.04(LTS</block>
  <block id="049e44fe327f7679318c6cf222207da7" category="list-text">다음을 사용하여 UI에 액세스합니다.</block>
  <block id="b7bd19f19df4ca5ef3102741951e7a1b" category="paragraph">다음 기본 자격 증명을 사용합니다.</block>
  <block id="d644796f5eb5712add7807df8829ee58" category="admonition">암호는 "암호 변경" 옵션을 사용하여 변경할 수 있습니다.</block>
  <block id="653a98af1c9a004c51b4e7358f06db9a" category="summary">이 솔루션은 PostgreSQL 데이터베이스 구축 및 HA/DR 설정, 페일오버, 재동기화를 위한 개요 및 세부 정보를 제공합니다. 이러한 기능은 AWS의 FSx ONTAP 스토리지 제품 및 NetApp Ansible 자동화 툴킷에 내장된 NetApp SnapMirror 기술을 기반으로 합니다.</block>
  <block id="e5f44d648a9d8c4db4e2b580d3370fbf" category="doc">TR-4956: AWS FSx/EC2에서 자동화된 PostgreSQL 고가용성 구축 및 재해 복구</block>
  <block id="03784a7c5600d29113972955e602a944" category="inline-link-macro">DB-엔진</block>
  <block id="1d8f1bdc206db1d9edd9fa46f02aa08c" category="paragraph">PostgreSQL은 에서 가장 많이 사용되는 데이터베이스 엔진 10개 중 4위에 해당하는 널리 사용되는 오픈 소스 데이터베이스입니다 <block ref="6e2d0e5987102894082cbdb135303e4d" category="inline-link-macro-rx"></block>. 반면 PostgreSQL은 라이선스 없는 오픈 소스 모델에서 고급 기능을 계속 사용하면서 인기를 얻고 있습니다. 반면, 오픈 소스가 되어 있기 때문에 고가용성 및 재해 복구(HA/DR) 영역, 특히 퍼블릭 클라우드에서 운영 수준의 데이터베이스 구축에 대한 자세한 지침은 부족한 실정입니다. 일반적으로 핫 스탠바이 및 웜 스탠바이, 스트리밍 복제 등을 사용하여 일반적인 PostgreSQL HA/DR 시스템을 설정하기 어려울 수 있습니다. 대기 사이트를 프로모션한 다음 운영 사이트로 다시 전환하여 HA/DR 환경을 테스트하는 경우 운영 중단이 발생할 수 있습니다. 읽기 워크로드가 스트리밍 핫 스탠바이에 배포되면 운영 환경에 잘 문서화된 성능 문제가 있습니다.</block>
  <block id="a685f8093823e999c5eaf32bef74906d" category="paragraph">이 문서에서는 애플리케이션 레벨 PostgreSQL 스트리밍 HA/DR 솔루션을 사용하지 않고 데이터베이스 파일 및 EC2 컴퓨팅 인스턴스(예: 데이터베이스 서버)를 위한 AWS FSx ONTAP 스토리지를 기반으로 PostgreSQL HA/DR 솔루션을 구축하는 방법을 설명합니다. 이 솔루션은 기존의 PostgreSQL 애플리케이션 레벨 스트리밍 복제(HA/DR)와 비교할 수 있는 보다 간편하고 유사한 시스템을 생성하고 그에 상응하는 결과를 제공합니다.</block>
  <block id="e2543d0568626be8ab6adad9d9a78652" category="paragraph">이 솔루션은 PostgreSQL HA/DR을 위한 AWS 네이티브 FSX ONTAP 클라우드 스토리지에서 사용할 수 있는 검증된 고급 NetApp SnapMirror 스토리지 레벨 복제 기술을 기반으로 구축되었습니다. NetApp 솔루션 팀이 제공하는 자동화 툴킷을 사용하면 간단하게 구축할 수 있습니다. 또한 유사한 기능을 제공하는 동시에 애플리케이션 레벨의 스트리밍 기반 HA/DR 솔루션을 통해 운영 사이트의 복잡성과 성능 저하를 방지합니다. 액티브 운영 사이트에 영향을 주지 않고 솔루션을 쉽게 구축 및 테스트할 수 있습니다.</block>
  <block id="f67bd3c0833b1d6bf90bb26a55f0a9ce" category="list-text">퍼블릭 AWS 클라우드에서 PostgreSQL을 위한 운영 등급 HA/DR 구축</block>
  <block id="420a5f3809172bb0dc9d501758fe94d2" category="list-text">퍼블릭 AWS 클라우드에서 PostgreSQL 워크로드 테스트 및 검증</block>
  <block id="c9d6a5076f52c5abce5f2003446ab211" category="list-text">NetApp SnapMirror 복제 기술을 기반으로 PostgreSQL HA/DR 전략 테스트 및 검증</block>
  <block id="82aa3e78c2089a2941fb745bb8c72f01" category="paragraph">이 솔루션은 다음과 같은 사용자를 대상으로 합니다.</block>
  <block id="4a7bde15fa2753ce507cef621fd789b2" category="list-text">퍼블릭 AWS 클라우드에 HA/DR로 PostgreSQL을 구축하려는 DBA</block>
  <block id="c5e04df584e0992a5dbdae10d89ded97" category="list-text">퍼블릭 AWS 클라우드에서 PostgreSQL 워크로드를 테스트하는 데 관심이 있는 데이터베이스 솔루션 설계자</block>
  <block id="ba083ee91407315383bac538162833ff" category="list-text">AWS FSx 스토리지에 배포된 PostgreSQL 인스턴스를 배포 및 관리하는 데 관심이 있는 스토리지 관리자</block>
  <block id="73ad058c671f3e1e105d92585f5ece7a" category="list-text">AWS FSx/EC2에서 PostgreSQL 환경을 구축하는 데 관심이 있는 애플리케이션 소유자입니다.</block>
  <block id="d17a638ff086388dc5bfbe98528ccfab" category="section-title">솔루션 테스트 및 검증 환경</block>
  <block id="863fb5b3a3b3b63b57a387bab70de0a9" category="paragraph">이 솔루션의 테스트 및 검증은 최종 구축 환경과 일치하지 않을 수 있는 AWS FSx 및 EC2 환경에서 수행되었습니다. 자세한 내용은 섹션을 참조하십시오 <block ref="8ea96e516bccf9a47ca2d74131eb7519" category="inline-xref-macro-rx"></block>.</block>
  <block id="bfa420253f0a67626a51ce1fa045944c" category="image-alt">이 이미지는 온프레미스 및 AWS 사이트를 비롯한 PostgreSQL 하이브리드 클라우드 솔루션의 구성에 대한 자세한 정보를 제공합니다.</block>
  <block id="34d0b9b49aa480630e91a3619ba7ffb2" category="section-title">하드웨어 및 소프트웨어 구성 요소</block>
  <block id="a09dc18a1bff4fa8388afca4627d0911" category="cell">FSX ONTAP 저장소</block>
  <block id="011fedf4050817b8826f95a53d9555b2" category="cell">현재 버전</block>
  <block id="0b70cdec9293f5625e5aaae9cdd38526" category="cell">동일한 VPC에 2개의 FSx HA 쌍, 운영 및 대기 HA 클러스터와 가용성 존</block>
  <block id="6a79356b19d3b59e92b358357c5b9053" category="cell">컴퓨팅용 EC2 인스턴스</block>
  <block id="cc4def82629f09f253176dba801a85f0" category="cell">T2.xLarge/4vCPU/16G</block>
  <block id="e3d6d4b94f9415561957f8c22f5fea2e" category="cell">2개의 EC2 T2 xLarge를 운영 및 대기 컴퓨팅 인스턴스로 설정합니다</block>
  <block id="3008feb4272787858d4d27f7e8acb08b" category="cell">Ansible 컨트롤러</block>
  <block id="26b9568eac10de69d574b84626735921" category="cell">온프레미스 CentOS VM/4vCPU/8G</block>
  <block id="7f151fffe66dad0021b1918085977654" category="cell">Ansible 자동화 컨트롤러를 온프레미스 또는 클라우드에서 호스팅하기 위한 VM</block>
  <block id="8b56d55f3caeb71ab2513c28fb1a52fc" category="cell">RedHat Linux</block>
  <block id="52359c9653f33c68cd1b454f7d05a27b" category="cell">RHEL-8.6.0_HVM-20220503-x86_64-2-Hourly2-GP2</block>
  <block id="fe6120dacb84838d71b1f43da1a3a514" category="cell">테스트를 위해 RedHat 서브스크립션을 배포했습니다</block>
  <block id="8003cafa06ec27e11cb235ec9544ef74" category="cell">CentOS Linux</block>
  <block id="04cd32c57cf3229ae9374fc80cd50d96" category="cell">CentOS Linux 릴리스 8.2.2004(코어)</block>
  <block id="63b6df5ba9d257bb0f6fbda5541d9171" category="cell">온프레미스 랩에 구축된 Ansible 컨트롤러를 호스팅</block>
  <block id="399bd1ee587245ecac6f39beaa99886f" category="cell">PostgreSQL</block>
  <block id="a3c20b719830dc5fda947c7b6f3e42be" category="cell">버전 14.5</block>
  <block id="f8c3d3a84c62eb07a1009aacdc46a50f" category="cell">Automation은 PostgreSQL.ora yum repo에서 사용 가능한 최신 버전의 PostgreSQL을 가져옵니다</block>
  <block id="202351f581b52c61061d29151c81d061" category="cell">버전 2.10.3</block>
  <block id="d222003898249e4a560d569acb0b5563" category="cell">요구 사항 플레이북과 함께 설치된 필수 컬렉션 및 라이브러리에 대한 사전 요구 사항</block>
  <block id="cd1aedf83959dd52fc058b9120f500e3" category="section-title">구축 시 고려해야 할 주요 요소</block>
  <block id="b062352f67359ac6729601c60a9a57a2" category="list-text">* PostgreSQL 데이터베이스 백업, 복원 및 복구. * PostgreSQL 데이터베이스는 pg_dump를 사용한 논리적 백업, pg_basebackup 또는 하위 수준의 OS 백업 명령을 사용한 물리적 온라인 백업, 스토리지 레벨 정합성 보장 스냅샷과 같은 다양한 백업 방법을 지원합니다. 이 솔루션은 PostgreSQL 데이터베이스 데이터에 NetApp 정합성 보장 그룹 스냅샷을 사용하고 대기 사이트에서 Wal 볼륨 백업, 복원 및 복구를 수행합니다. NetApp 정합성 보장 그룹 볼륨 스냅샷은 스토리지에 쓰일 때 입출력을 순차적으로 생성하고 데이터베이스 데이터 파일의 무결성을 보호합니다.</block>
  <block id="a28c157802547f294e145f164007d752" category="list-text">* EC2 컴퓨팅 인스턴스 * 이러한 테스트 및 검증에서는 PostgreSQL 데이터베이스 컴퓨팅 인스턴스에 대해 AWS EC2 T2.xLarge 인스턴스 유형을 사용했습니다. 데이터베이스 워크로드에 최적화되어 있으므로 배치 시 PostgreSQL용 컴퓨팅 인스턴스로 M5 유형 EC2 인스턴스를 사용하는 것이 좋습니다. 대기 컴퓨팅 인스턴스는 항상 FSx HA 클러스터용으로 구축된 패시브(대기) 파일 시스템과 동일한 존에 배포되어야 합니다.</block>
  <block id="d7aed04148f8b6ba1b91a7ed84d3fd10" category="list-text">* FSx 스토리지 HA 클러스터 단일 또는 다중 영역 배포. * 이러한 테스트 및 검증에서는 단일 AWS 가용성 영역에 FSx HA 클러스터를 구축했습니다. 프로덕션 배포를 위해 FSx HA 쌍을 두 가지 가용성 영역에 배포하는 것이 좋습니다. 운영 및 대기 간에 특정 거리가 필요한 경우 다른 지역에서 비즈니스 연속성을 위한 재해 복구 대기 HA 쌍을 설정할 수 있습니다. FSx HA 클러스터는 스토리지 레벨 이중화를 제공하기 위해 액티브-패시브 파일 시스템 쌍으로 미러링되는 HA 쌍으로 프로비저닝됩니다.</block>
  <block id="c6f1f46bc7e80b73e6d77a7f862e0625" category="list-text">* PostgreSQL 데이터 및 로그 배치 * 일반적인 PostgreSQL 배포는 데이터 및 로그 파일에 대해 동일한 루트 디렉토리 또는 볼륨을 공유합니다. 테스트 및 검증에서 PostgreSQL 데이터를 분리하고 성능을 위해 두 개의 개별 볼륨에 로그인합니다. 데이터 디렉토리에서 PostgreSQL Wal 로그 및 보관된 Wal 로그를 호스팅하는 로그 디렉토리 또는 볼륨을 가리키는 소프트 링크가 사용됩니다.</block>
  <block id="6e6dddb70c24cf218d0163faa3fb6a8f" category="list-text">* PostgreSQL 서비스 시작 지연 타이머 * 이 솔루션은 NFS 마운트 볼륨을 사용하여 PostgreSQL 데이터베이스 파일과 Wal 로그 파일을 저장합니다. 데이터베이스 호스트를 재부팅하는 동안 볼륨이 마운트되지 않은 상태에서 PostgreSQL 서비스가 시작하려고 할 수 있습니다. 이로 인해 데이터베이스 서비스 시작 오류가 발생합니다. PostgreSQL 데이터베이스를 올바르게 시작하려면 10 ~ 15초의 타이머 지연이 필요합니다.</block>
  <block id="ee79ca09fee704e63d972baa3c1319a2" category="list-text">비즈니스 연속성을 위한 * RPO/RTO. * DR을 위해 기본에서 대기로의 FSx 데이터 복제는 비동기를 기반으로 합니다. 즉, RPO는 Snapshot 백업 및 SnapMirror 복제 빈도에 따라 달라집니다. 스냅샷 복사본 및 SnapMirror 복제 빈도가 높아지면 RPO가 감소합니다. 따라서 재해 발생 시 잠재적인 데이터 손실과 스토리지 비용 증가 간에 균형을 유지할 수 있습니다. RPO에 대해 스냅샷 복사본과 SnapMirror 복제를 최소 5분 간격으로 구현할 수 있으며 PostgreSQL은 일반적으로 RTO에 대한 1분 이내에 DR 대기 사이트에서 복구할 수 있습니다.</block>
  <block id="cbeb123cc0c2c950a65a0c39f8412dc4" category="list-text">* 데이터베이스 백업. * PostgreSQL 데이터베이스가 구축되거나 On-Premrs 데이터 센터에서 AWS FSx 스토리지로 마이그레이션된 후 데이터를 보호하기 위해 FSx HA 쌍에서 자동 동기화됩니다. 재해 발생 시 복제된 대기 사이트로 데이터를 더욱 안전하게 보호할 수 있습니다. 장기 백업 보존 또는 데이터 보호를 위해 내장된 PostgreSQL pg_basebackup 유틸리티를 사용하여 S3 Blob 스토리지로 포팅할 수 있는 전체 데이터베이스 백업을 실행하는 것이 좋습니다.</block>
  <block id="d2598d7d09e212cad1231cd233c5f7dc" category="paragraph">이 솔루션 배포는 아래에 설명된 자세한 지침을 따라 NetApp Ansible 기반 자동화 툴킷을 사용하여 자동으로 완료할 수 있습니다.</block>
  <block id="7cfbd2a753781ece3080a48b0a56dad2" category="inline-link-macro">NA_PostgreSQL_AWS_Deploy_HADR</block>
  <block id="fce91619a13ef0fd71e3ffe1da6b5724" category="list-text">자동화 도구 키트 readme.md의 지침을 읽으십시오 <block ref="139722adb31b9bbcb8f923b221d78595" category="inline-link-macro-rx"></block>.</block>
  <block id="9a1c6815d4b1e7dc53acf5a926ab662e" category="list-text">다음 비디오 단계별 안내 를 시청하십시오.</block>
  <block id="c73ece4b7be6bb88143afe096ded59aa" category="list-text">필요한 매개 변수 파일을 구성합니다 <block ref="85cf4e6d42a71e693fd780c8b29accdd" prefix="(" category="inline-code"></block>,<block ref="0c83664bfb17d8d2c0bbc3551297e488" prefix=" " category="inline-code"></block>,<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block>)를 클릭합니다. 그런 다음 복사 버튼을 사용하여 Ansible 컨트롤러 호스트에 파일을 복사합니다.</block>
  <block id="00aaa5ff8fbd0841ab311f7d9b1e4e78" category="section-title">자동 배포를 위한 사전 요구 사항</block>
  <block id="fd10b9eacfe4eed8040bda8cae9ea050" category="paragraph">배포에는 다음과 같은 사전 요구 사항이 필요합니다.</block>
  <block id="e7491272f69c8efda69a595782f44d45" category="list-text">AWS 계정이 설정되었으며 AWS 계정 내에 필요한 VPC 및 네트워크 세그먼트가 생성되었습니다.</block>
  <block id="f71558e9ad22e37a70099d8b5d8ac06c" category="inline-link-macro">Linux 인스턴스에 대한 사용자 가이드</block>
  <block id="eb03aa8f939650517c1c56a6d0b9ad2f" category="list-text">AWS EC2 콘솔에서 2개의 EC2 Linux 인스턴스를 구축해야 합니다. 하나는 운영 사이트에, 다른 하나는 대기 DR 사이트에 운영 PostgreSQL DB 서버로 배포해야 합니다. 운영 및 대기 DR 사이트에서 컴퓨팅 이중화를 위해 2개의 추가 EC2 Linux 인스턴스를 대기 PostgreSQL DB 서버로 구축합니다. 환경 설정에 대한 자세한 내용은 이전 섹션의 아키텍처 다이어그램을 참조하십시오. 또한 를 검토합니다 <block ref="32934851360be4fd00506586c2cbc221" category="inline-link-macro-rx"></block> 를 참조하십시오.</block>
  <block id="933d3e5f984811b21da2922f3deb56c4" category="list-text">AWS EC2 콘솔에서 PostgreSQL 데이터베이스 볼륨을 호스팅하기 위해 두 개의 FSx ONTAP 스토리지 HA 클러스터를 구축합니다. FSx 저장소 배포에 익숙하지 않은 경우 설명서를 참조하십시오 <block ref="d73b8b529985c5c89147bd81cb29dbfb" category="inline-link-macro-rx"></block> 을 참조하십시오.</block>
  <block id="7053a216e34d0f83be18a65f22ce62ce" category="list-text">Ansible 컨트롤러를 호스팅할 CentOS Linux VM을 구축합니다. Ansible 컨트롤러는 사내 또는 AWS 클라우드에 위치할 수 있습니다. 사내에 있는 경우 VPC, EC2 Linux 인스턴스 및 FSx 스토리지 클러스터에 SSH를 연결해야 합니다.</block>
  <block id="d1186b859105640e1dc347ae7b714afa" category="list-text">리소스의 "RHEL/CentOS에서 CLI 배포를 위한 Ansible Control Node 설정" 섹션에 설명된 대로 Ansible 컨트롤러를 설정합니다 <block ref="a9149ecc8f33f363a4eae3089d5c6cb7" category="inline-link-macro-rx"></block>.</block>
  <block id="007fa0067fff9abdcd3e5b9ce9f20c06" category="list-text">공용 NetApp GitHub 사이트에서 자동화 툴킷 복사본을 복제합니다.</block>
  <block id="0ca21e6da2c89e765706d9a77f412898" category="list-text">툴킷 루트 디렉토리에서 필수 구성 요소 플레이북을 실행하여 Ansible 컨트롤러용 필수 컬렉션 및 라이브러리를 설치합니다.</block>
  <block id="df40cb16c4a24c991c143fbddeedd0bc" category="list-text">DB 호스트 변수 파일에 필요한 EC2 FSx 인스턴스 매개 변수를 검색합니다<block ref="ea858a411f1af6150f14b84176148712" prefix=" " category="inline-code"></block> 글로벌 변수 파일을 엽니다<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block> 구성.</block>
  <block id="57c7844b0a299340cf9b625ce4a0745a" category="section-title">호스트 파일을 구성합니다</block>
  <block id="ed578fbfbec5634c4fa508cde5bc4e85" category="paragraph">운영 FSx ONTAP 클러스터 관리 IP 및 EC2 인스턴스 호스트 이름을 HOSTS 파일에 입력합니다.</block>
  <block id="6ef214427ca7b42201d0b0508f56df98" category="section-title">host_name.yml 파일을 host_vars 폴더에 구성합니다</block>
  <block id="6967d323b85203ba993572c1cd814dc1" category="paragraph">밑줄이 그어진 파란색 필드에 시스템에 적절한 매개 변수를 입력한 다음 항목을 복사하여 에 붙여 넣습니다<block ref="caa6779553864dba00727ae27752b182" prefix=" " category="inline-code"></block> 파일을 Ansible 컨트롤러에 저장합니다<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> 폴더.</block>
  <block id="77ac1da2cd356e327eb4bfc4c5a21bcc" category="section-title">VAR 폴더에서 글로벌 FSX_VAR.yml 파일을 구성합니다</block>
  <block id="7876ddba2c3af67cbee2b37f64072428" category="paragraph">밑줄이 그어진 파란색 필드에 시스템에 적절한 매개 변수를 입력한 다음 항목을 복사하여 에 붙여 넣습니다<block ref="cb8e25d5e6251a20afadf4c5f4b626bb" prefix=" " category="inline-code"></block> 파일을 Ansible 컨트롤러 호스트에 저장합니다.</block>
  <block id="d56625a35762821798a2f3dd55ead05d" category="section-title">PostgreSQL 배포 및 HA/DR 설정</block>
  <block id="943a124028d8f011631df765453640dc" category="paragraph">다음 작업은 PostgreSQL DB 서버 서비스를 구축하고 운영 EC2 DB 서버 호스트의 운영 사이트에서 데이터베이스를 초기화합니다. 그런 다음 대기 운영 EC2 DB 서버 호스트가 대기 사이트에 설정됩니다. 마지막으로, 재해 복구를 위해 운영 사이트 FSx 클러스터에서 대기 사이트 FSx 클러스터로 DB 볼륨 복제가 설정됩니다.</block>
  <block id="08f6dd070ef1adfcbe3d7f3c70b08905" category="list-text">운영 FSx 클러스터에 DB 볼륨을 생성하고 운영 EC2 인스턴스 호스트에서 PostgreSQL을 설정합니다.</block>
  <block id="bf22091495c9a041dcbdba3a97795095" category="list-text">대기 DR EC2 인스턴스 호스트를 설정합니다.</block>
  <block id="f2dd18dfc82378171d01bdd3f956bc6f" category="list-text">FSx ONTAP 클러스터 피어링 및 데이터베이스 볼륨 복제를 설정합니다.</block>
  <block id="d681aef28cf1f863d0683a6896f12995" category="list-text">이전 단계를 단일 단계의 PostgreSQL 배포 및 HA/DR 설정에 통합합니다.</block>
  <block id="fe217a2e30a79cebc71db6d5cb676a71" category="list-text">기본 또는 대기 사이트에서 대기 PostgreSQL DB 호스트를 설정하려면 hosts file [DR_PostgreSQL] 섹션의 다른 모든 서버를 주석으로 추가한 다음 각 타겟 호스트(예: psql_01ps 또는 운영 사이트의 대기 EC2 컴퓨팅 인스턴스)와 함께 PostgreSQL_standby_setup.yml 플레이북을 실행합니다. 과 같은 호스트 매개 변수 파일이 있는지 확인합니다<block ref="7c0f59fa275836ef9c4f28bec839acca" prefix=" " category="inline-code"></block> 가 에 구성되어 있습니다<block ref="3342582e194d63e4c91b56623752c9c6" prefix=" " category="inline-code"></block> 디렉토리.</block>
  <block id="d3ecdce9695eacdb90ec80fa276865d4" category="section-title">PostgreSQL 데이터베이스 스냅샷 백업 및 대기 사이트로의 복제</block>
  <block id="3b320790a7f864b473e3baa86de785fe" category="paragraph">대기 사이트에 대한 PostgreSQL 데이터베이스 스냅샷 백업 및 복제는 사용자 정의 간격으로 Ansible 컨트롤러에서 제어 및 실행될 수 있습니다. 간격이 5분 정도일 수 있다는 것이 검증되었습니다. 따라서 운영 사이트에서 장애가 발생할 경우 예약된 다음 스냅샷 백업 바로 전에 장애가 발생할 경우 5분 내에 데이터가 손실될 수 있습니다.</block>
  <block id="421057a9fa982de2a1c1f79f5f03d750" category="section-title">DR을 위해 대기 사이트로 페일오버</block>
  <block id="6ddcc779c247e4adb5b5a56a34edd75d" category="paragraph">PostgreSQL HA/DR 시스템을 DR 실습으로 테스트하려면 다음 플레이북을 실행하여 대기 사이트의 운영 스탠바이 EC2 DB 인스턴스에서 페일오버 및 PostgreSQL 데이터베이스 복구를 실행합니다. 실제 DR 시나리오에서는 실제로 DR 사이트로 페일오버하는 경우에도 동일하게 실행합니다.</block>
  <block id="724a617bc1dcc9b26fedb732f63a569d" category="section-title">장애 조치 테스트 후 복제된 DB 볼륨을 다시 동기화합니다</block>
  <block id="6a08e960bd12a4fcddfd08082fbece4b" category="paragraph">페일오버 테스트 후 재동기화를 실행하여 데이터베이스 볼륨 SnapMirror 복제를 다시 설정합니다.</block>
  <block id="145966bc8e38b26c384abaf4e450f6a7" category="section-title">EC2 컴퓨팅 인스턴스 장애로 인해 운영 EC2 DB 서버에서 대기 EC2 DB 서버로 페일오버</block>
  <block id="bab50aeeeaabfc4e129f95b2d8d125e5" category="paragraph">라이센스가 필요할 수 있는 이미 잘 구축된 OS 클러스터 웨어에서 수동 페일오버를 실행하는 것이 좋습니다.</block>
  <block id="73bc97f640d8c1cae3fa624183216b41" category="inline-link-macro"><block ref="73bc97f640d8c1cae3fa624183216b41" category="inline-link-rx"></block></block>
  <block id="40285fa8e3dc4d66bfadb679f67dfde6" category="paragraph"><block ref="40285fa8e3dc4d66bfadb679f67dfde6" category="inline-link-macro-rx"></block></block>
  <block id="68253b5715937494905ba0cb9db91d2e" category="inline-link-macro"><block ref="be48c1546d351a5e48dcf4f28738754b" category="inline-link-rx"></block></block>
  <block id="6dcfba5adaa9302bd59dd5a601b947a2" category="paragraph"><block ref="95bfcff1050e9160bb2bd645993e8c18" category="inline-link-macro-rx"></block></block>
  <block id="6d183e6080727fa3b49f82e41b18c061" category="inline-link-macro"><block ref="6d183e6080727fa3b49f82e41b18c061" category="inline-link-rx"></block></block>
  <block id="8fb430b477f47c3062d0f4afb8a9195b" category="paragraph"><block ref="8fb430b477f47c3062d0f4afb8a9195b" category="inline-link-macro-rx"></block></block>
  <block id="031004dd1775e5fd9d35b534e33217ea" category="paragraph">[underline]# * 오픈 소스 데이터베이스용 동영상 * #</block>
  <block id="5b70a7f45ddd32cacfe28af238662d3d" category="video-title">PostgreSQL 자동 구축, HA/DR 복제 설정, 페일오버, 재동기화</block>
  <block id="61c8e892dd7e1908020eb0a312fd4bbb" category="cell">2023년 2월 15일</block>
  <block id="2ee6a0567aa163f6ace02183cb041cbd" category="cell">AWS FSx/EC2에서 PostgreSQL 고가용성 구축 및 재해 복구 추가</block>
  <block id="a54420e6e0f519f841f4280cf2545365" category="sidebar">오픈 소스 데이터베이스</block>
  <block id="67bb2ef7cf3c5ff59f35f28e513bfda3" category="sidebar">AWS FSx/EC2에서 PostgreSQL 고가용성 구축 및 재해 복구</block>
  <block id="1ae3eccde141a365ede8f18b188ae588" category="sidebar">AWS FSx/EC2에서 PostgreSQL HA 구축 및 DR 자동화</block>
  <block id="6fabfc29f0b3a196c8407c190bb67293" category="sidebar">데이터베이스용 SnapCenter</block>
  <block id="1f599c1b266e901a2c8d38e266e23c6f" category="summary">이 섹션에서는 자세한 테스트 절차 결과를 설명합니다.</block>
  <block id="c87fa6e515cf0976291b387e5a8ab6f6" category="doc">테스트 절차 및 자세한 결과</block>
  <block id="5a05f12c2c7f8b9ff569496691352e05" category="paragraph"><block ref="5a05f12c2c7f8b9ff569496691352e05" category="inline-link-macro-rx"></block></block>
  <block id="b70dd619781891706b7d2f44c418a2b5" category="section-title">ONTAP에서 ResNet를 사용한 이미지 인식 훈련</block>
  <block id="bf523bb892b07c71c90bd7ea34a091a9" category="paragraph">SR670 V2 서버 1대 및 2대를 사용하여 ResNet50 벤치마크를 실행했습니다. 이 테스트는 MXNet 22.04-py3 NGC 컨테이너를 사용하여 교육을 실시하였습니다.</block>
  <block id="a08c4eedb9047aae68f44b82037739b0" category="paragraph">이 검증에서 다음 테스트 절차를 사용했습니다.</block>
  <block id="df1a5f60f20e6aa3336812f58095e04f" category="list-text">스크립트를 실행하기 전에 호스트 캐시를 지웠습니다. 데이터가 이미 캐시되지 않았는지 확인해야 합니다.</block>
  <block id="ab93a65fabd2eaae21f5a6e097320730" category="list-text">서버 스토리지(로컬 SSD 스토리지)와 NetApp AFF 스토리지 시스템에서 ImageNet 데이터 세트를 사용하여 벤치마크 스크립트를 실행했습니다.</block>
  <block id="9f98453c4a6eede45b87d72527b49e7e" category="list-text">을 사용하여 네트워크 및 로컬 스토리지 성능을 검증했습니다<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> 명령.</block>
  <block id="47b048d9dcf1d84d76bddb033b842b3b" category="list-text">단일 노드 실행의 경우 다음 명령을 사용했습니다.</block>
  <block id="014e128029d9142b6957ca4f1b291090" category="list-text">분산 실행에서는 매개변수 서버의 병렬화 모델을 사용했습니다. 노드당 두 개의 매개 변수 서버를 사용했으며 단일 노드 실행과 같은 Epoch 수를 설정했습니다. 프로세스 간의 완벽한 동기화로 인해 분산된 교육에서 더 많은 Epoch를 사용하기 때문에 이 작업을 수행하였습니다. 여러 번의 Epoch가 단일 노드와 분산된 케이스 간의 비교 차이를 나타낼 수 있습니다.</block>
  <block id="8f74be345dbaeac65cc3a488503b2a1f" category="section-title">데이터 읽기 속도: 로컬 스토리지와 네트워크 스토리지</block>
  <block id="16d8fe364e1a7846c093983bec75e764" category="paragraph">읽기 속도는 을 사용하여 테스트했습니다<block ref="1aabac6d068eef6a7bad3fdf50a05cc8" prefix=" " category="inline-code"></block> ImageNet 데이터 세트에 대한 파일 중 하나에서 명령을 실행합니다. 특히, 로컬 및 네트워크 데이터에 대해 다음 명령을 실행했습니다.</block>
  <block id="c685a224eb9a88c5b7bd2be45fe5a128" category="paragraph">두 값은 모두 유사하며 네트워크 스토리지가 로컬 스토리지와 비슷한 속도로 데이터를 제공할 수 있음을 보여 줍니다.</block>
  <block id="aa613e8f689a1a64605aef401595bfd2" category="section-title">공유 활용 사례: 여러 개의 독립적인 동시 작업</block>
  <block id="7e4312d3e922a98bfc1dc4a84c80f12c" category="paragraph">이 테스트는 멀티 작업, 멀티 유저 AI 훈련과 같은 이 솔루션의 예상 사용 사례를 시뮬레이션했습니다. 각 노드는 공유 네트워크 스토리지를 사용하는 동안 자체 교육을 실행했습니다. 결과는 다음 그림에 표시되어 있습니다. 이는 솔루션 케이스가 개별 작업과 기본적으로 동일한 속도로 실행되는 모든 작업에서 탁월한 성능을 제공했음을 나타냅니다. 총 처리량은 노드 수에 비례하여 확장됩니다.</block>
  <block id="2b9215e7cc3c2422637b6f95b0d47d97" category="inline-image-macro">이 그림에서는 초당 집계 이미지를 보여 줍니다.</block>
  <block id="5224aacbc4b8472eb40ead3ee8856b90" category="paragraph"><block ref="5224aacbc4b8472eb40ead3ee8856b90" category="inline-image-macro-rx" type="image"></block></block>
  <block id="45f5fcaaad259a917b031b3169cd5ad4" category="inline-image-macro">이 그림에서는 몇 분 내에 런타임을 보여 줍니다.</block>
  <block id="8255e8c790967568129f1f898048f1c5" category="paragraph"><block ref="8255e8c790967568129f1f898048f1c5" category="inline-image-macro-rx" type="image"></block></block>
  <block id="289b386724c768cabf5ad786a3842335" category="paragraph">이 그래프는 동시 교육 모델과 단일 교육 모델을 결합하여 100GbE 클라이언트 네트워킹에서 각 서버의 8개 GPU를 사용한 컴퓨팅 노드의 런타임 및 초당 애그리게이트 이미지를 보여줍니다. 교육 모델의 평균 런타임은 35분 9초입니다. 개별 실행 시간은 34분 32초 36분 21초 34분 37초 35분 25초 34분 31초였습니다. 훈련 모델의 초당 평균 이미지는 2만573개, 초당 이미지 수는 2만1764개, 2만2438개, 2만2556개, 2만2564개, 2만547개.</block>
  <block id="ce47a442fe1dc7c09bf9a3ec5ed71236" category="paragraph">NetApp 검증 결과에 따라 NetApp 데이터 런타임을 포함하는 1개의 독립 교육 모델은 34분 54초와 22,231개의 이미지/초로 계산됩니다 로컬 데이터(DAS) 런타임을 포함하는 1개의 독립 교육 모델은 34분 21초, 22,102개의 이미지/초로 나타났습니다 실행 도중 NVIDIA-SMI에서 관찰된 평균 GPU 사용률은 96%였습니다. 이 평균에는 GPU를 사용하지 않는 테스트 단계가 포함되며, CPU 사용률은 mpstat로 측정한 40%입니다. 이는 각 경우에 데이터 전송 속도가 충분함을 나타냅니다.</block>
  <block id="f63534f8e2150e0624ee2af349f77999" category="inline-link-macro">다음: 아키텍처 조정.</block>
  <block id="92a7087794ac4c23f482ff2db8cf1742" category="paragraph"><block ref="92a7087794ac4c23f482ff2db8cf1742" category="inline-link-macro-rx"></block></block>
  <block id="686ebb62ce1be84dcfae0007fb84562d" category="summary">검증에 사용된 설정을 다른 사용 사례에 맞게 조정할 수 있습니다.</block>
  <block id="bf46169695d75ff844d955af09f33e75" category="doc">아키텍처 조정</block>
  <block id="747bf7dbe4329cb636a09e1a7e4b297b" category="inline-link-macro">이전: 테스트 절차 및 자세한 결과</block>
  <block id="61862ef71b0230e76d56381617d456b0" category="paragraph"><block ref="61862ef71b0230e76d56381617d456b0" category="inline-link-macro-rx"></block></block>
  <block id="1cf27bd587c6c632877c322cf42c0d97" category="paragraph">이 검증에 사용된 설정을 다른 사용 사례에 맞게 조정할 수 있습니다.</block>
  <block id="a752efb5fb2512dc99b2045f032779f7" category="section-title">CPU 조정</block>
  <block id="122acc941b98ef5a11208d23ed0a8090" category="paragraph">Lenovo에서 권장하는 대로 이 검증을 위해 Skylake Intel Xeon Platinum 8360Y 프로세서를 사용했습니다. 인텔 제온 골드 6330 프로세서인 Cascade Lake CPU는 이 작업 부하가 CPU가 부족하기 때문에 유사한 성능을 제공할 것으로 예상됩니다.</block>
  <block id="3cc37c167d58a1828b00c13cc6018ae8" category="section-title">스토리지 용량 증가</block>
  <block id="f40ff1aaa4f2e4ccd4189adfb3584e29" category="paragraph">추가 디스크 쉘프 및 컨트롤러 모델이 있다면 스토리지 용량 요구사항에 따라 필요 시 공유 스토리지(NFS 볼륨)를 늘릴 수 있습니다. 이 작업은 CLI 또는 스토리지 컨트롤러의 NetApp 웹 인터페이스에서 admin 사용자로 수행할 수 있습니다.</block>
  <block id="326221403d8b3298094c46f2012726ea" category="paragraph"><block ref="326221403d8b3298094c46f2012726ea" category="inline-link-macro-rx"></block></block>
  <block id="f737e7cc3d8aa89c5b49c4fe701e9e40" category="summary">이 검증에서는 MLPerf v2.0에 명시된 대로 이미지 인식 교육을 수행했습니다. 특히, ImageNet 데이터 세트를 사용하여 ResNet v2.0 모델을 교육했습니다. 주요 메트릭은 원하는 정확도에 도달하는 시간입니다. 또한 스케일 아웃 효율성을 더 잘 판단할 수 있도록 초당 이미지 단위의 교육 대역폭을 보고합니다.</block>
  <block id="813c7764ec170fb5498e50560d32a97f" category="paragraph"><block ref="813c7764ec170fb5498e50560d32a97f" category="inline-link-macro-rx"></block></block>
  <block id="0f25983094bc4cf5cea830260da8ee75" category="paragraph">이 검증에서는 MLPerf v2.0에 명시된 대로 이미지 인식 교육을 수행했습니다. 특히, 76.1%의 정확도에 도달할 때까지 ImageNet 데이터 세트를 사용하여 ResNet v2.0 모델을 훈련했습니다. 주요 메트릭은 원하는 정확도에 도달하는 시간입니다. 또한 스케일 아웃 효율성을 더 잘 판단할 수 있도록 초당 이미지 단위의 교육 대역폭을 보고합니다.</block>
  <block id="ac3e6a4fbe8e02d639c2defeebeac17f" category="paragraph">1차 테스트 사례에서는 동시에 실행되는 여러 개의 독립적인 교육 프로세스(노드당 1개)를 평가했습니다. 이는 여러 데이터 과학자가 사용하는 공유 시스템인 주요 사용 사례를 시뮬레이션합니다. 두 번째 테스트 사례에서는 스케일아웃 효율성을 평가했습니다.</block>
  <block id="e34017da9a1a8d672a4859eb7c75947a" category="paragraph"><block ref="e34017da9a1a8d672a4859eb7c75947a" category="inline-link-macro-rx"></block></block>
  <block id="1d126a9d86b70dcdbc0585754993a848" category="summary">이 솔루션은 인공 지능 워크로드에 최적화된 NetApp 스토리지와 Lenovo 서버를 사용하는 엔트리 레벨 및 미드레인지 클러스터 아키텍처에 중점을 둡니다. 대부분의 컴퓨팅 작업이 단일 노드(단일 또는 다중 GPU)이거나 몇 개의 컴퓨팅 노드로 분산된 중소 및 중견 팀을 위해 제공됩니다. 대부분의 일상적인 AI 교육 작업은 단일 노드이기 때문에 이것이 주요 제한 사항이 아닙니다.</block>
  <block id="119a956725a313a60a3ef97db900f9fa" category="doc">TR-4810: AI 및 ML 모델 교육을 위한 Lenovo ThinkSystem SR670 V2 기반 NetApp AFF A400</block>
  <block id="4bdd810ac842a2485ea52dbd42c4d5f8" category="paragraph">사티야라잔, 데이비드 아네트, NetApp Mircea Troaca, Lonovo</block>
  <block id="252875fbe73a0c4ecbd42a23cc730022" category="paragraph">이 솔루션은 인공 지능(AI) 워크로드에 최적화된 NetApp 스토리지와 Lenovo 서버를 사용하는 미드레인지 클러스터 아키텍처를 제공합니다. 대부분의 컴퓨팅 작업이 단일 노드(단일 또는 다중 GPU)이거나 몇 개의 컴퓨팅 노드로 분산된 중소 및 중견 기업에 적합합니다. 이 솔루션은 대부분의 비즈니스에서 일상적인 AI 교육 작업과 부합합니다.</block>
  <block id="2fd79dc2b0743358191fe41cd806d103" category="paragraph">이 문서에서는 8개의 GPU Lenovo SR670V2 서버, 미드레인지 NetApp AFF A400 스토리지 시스템 및 100GbE 인터커넥트 스위치로 구성된 컴퓨팅 및 스토리지 구성의 테스트 및 검증을 다룹니다. 성능을 측정하기 위해 ImageNet 데이터 세트, 배치 크기 408, 절반 정밀도, CUDA 및 cuDNN을 사용하여 ResNet50을 사용했습니다. 이 아키텍처는 NetApp ONTAP 클라우드 연결형 데이터 스토리지의 엔터프라이즈급 기능이 필요한 AI 이니셔티브부터 시작하여 중소 및 중견 기업을 위한 효율적이고 비용 효율적인 솔루션을 제공합니다.</block>
  <block id="a186cc4a556d59a6e7b787796afd96a6" category="list-text">AI 시스템의 데이터 과학자, 데이터 엔지니어, 데이터 관리자 및 개발자</block>
  <block id="9f16d751276619605acf16a23befe48e" category="list-text">AI 모델 개발을 위한 솔루션을 설계하는 엔터프라이즈 설계자</block>
  <block id="e8982c30a351cd862612b0062923a81e" category="list-text">딥 러닝(DL) 및 머신 러닝(ML) 개발 목표를 달성하는 효율적인 방법을 찾고 있는 데이터 과학자 및 데이터 엔지니어</block>
  <block id="ca84e34dfe1115f7b462050a20377876" category="list-text">AI 이니셔티브를 위한 출시 시기를 최대한 단축하려는 비즈니스 리더 및 OT/IT 의사 결정자</block>
  <block id="a2dac0ecb0b60ec2625d20a5003869fb" category="paragraph">Lenovo ThinkSystem 서버와 NetApp ONTAP with AFF 스토리지가 포함된 이 솔루션은 기존 CPU와 함께 GPU의 처리 능력을 사용하는 대규모 데이터 세트에 대한 AI 교육을 처리하도록 설계되었습니다. 이러한 검증 방식은 단일 NetApp AFF A400 스토리지 시스템과 함께 1, 2 또는 4대의 Lenovo SR670 V2 서버를 사용하는 스케일아웃 아키텍처를 통해 뛰어난 성능과 최적의 데이터 관리를 구현하는 것으로 입증되었습니다. 다음 그림에서는 아키텍처 개요를 제공합니다.</block>
  <block id="9eaa73568302c6f5b850762b65b3f334" category="inline-image-macro">이 이미지는 관리 서버에 둘러싸인 이더넷 스위치, 각각 8개의 GPU가 있는 SR670 V2s 4개 및 NetApp ONTAP 스토리지 시스템을 보여줍니다.</block>
  <block id="d0d5bc4c21e600127e347c093cc29e80" category="paragraph"><block ref="d0d5bc4c21e600127e347c093cc29e80" category="inline-image-macro-rx" type="image"></block></block>
  <block id="9336931f4103d973313cb8539e5c2613" category="list-text">여러 교육 작업을 동시에 실행할 때 매우 효율적이고 비용 효율적인 성능을 제공합니다</block>
  <block id="81c3992924ee5cdc4cb02692dcae98b4" category="list-text">다양한 수의 Lenovo 서버와 다양한 모델의 NetApp 스토리지 컨트롤러를 기반으로 한 확장 가능한 성능</block>
  <block id="bdcea52fecbcd9741f95a6bc0dbbde0f" category="list-text">데이터 손실 없이 낮은 RPO(복구 시점 목표) 및 RTO(복구 시간 목표)를 충족하는 강력한 데이터 보호</block>
  <block id="98393526d67c065feb588e5665301706" category="list-text">스냅샷 및 클론을 통해 데이터 관리를 최적화하여 개발 워크플로우를 간소화합니다</block>
  <block id="c8da2691d0a05080662301b92e048a74" category="paragraph"><block ref="c8da2691d0a05080662301b92e048a74" category="inline-link-macro-rx"></block></block>
  <block id="2d316c5d9e0cd748d1890ee69f57dc6c" category="summary">이 섹션에서는 이 솔루션의 테스트 결과를 요약합니다.</block>
  <block id="6385fabeefcfa0be0a013cdd61625e31" category="paragraph"><block ref="6385fabeefcfa0be0a013cdd61625e31" category="inline-link-macro-rx"></block></block>
  <block id="80b6b969d6707ba1b92d65466e8325f0" category="paragraph">다음 표에는 이 솔루션에 대해 수행된 모든 테스트의 결과가 요약되어 있습니다.</block>
  <block id="f5bc14ae022ba581c26f3bdb35badef1" category="cell">테스트 설명</block>
  <block id="34d8129946f1108a296f033dc66db266" category="cell">결과 요약</block>
  <block id="ab0d993807168c3a70cdd2952d4edfc0" category="cell">이미지 인식 교육: 여러 개의 동시 작업</block>
  <block id="290ba1c81812edd0651d8e18c5895054" category="cell">매우 효율적인 성능. 클러스터가 완전히 사용되었을 때에도 모든 작업이 최고 속도로 실행되었습니다. NetApp 스토리지 시스템은 로컬 SSD 스토리지와 유사한 교육 성능을 제공하는 동시에 서버 간에 데이터를 쉽게 공유할 수 있도록 지원합니다.</block>
  <block id="d58827ca3ccfccb5c83b1dc9c7e12289" category="cell">이미지 인식 교육: 스케일아웃</block>
  <block id="afb4fda11ecde317daa521e054df2bd4" category="cell">최대 4개 노드까지 매우 효율적으로 지원 이 시점에서는 스케일아웃이 효율적이지 못하지만 여전히 실현 가능했습니다. 고속 컴퓨팅 네트워크를 사용하면 확장성이 향상됩니다. NetApp 스토리지 시스템은 로컬 SSD 스토리지와 유사한 교육 성능을 제공하는 동시에 서버 간에 데이터를 쉽게 공유할 수 있도록 지원합니다.</block>
  <block id="09011e7c7cce04b0b96cec58ace75585" category="paragraph"><block ref="09011e7c7cce04b0b96cec58ace75585" category="inline-link-macro-rx"></block></block>
  <block id="bd7c9d63c88eb380170362e93db6ba46" category="summary">이 섹션에서는 테스트된 구성, 네트워크 인프라, SR670 V2 서버 및 스토리지 프로비저닝 세부 정보를 설명합니다.</block>
  <block id="86473a82da3bbf22df039db481fe256f" category="paragraph"><block ref="86473a82da3bbf22df039db481fe256f" category="inline-link-macro-rx"></block></block>
  <block id="a1052c50691421535c201fa50690a1ca" category="paragraph">이 섹션에서는 테스트를 거친 구성, 네트워크 인프라, SR670 V2 서버 및 NetApp 스토리지 프로비저닝 세부 정보에 대해 설명합니다.</block>
  <block id="7c8d74d4c719b2f2e30a143bb98717ad" category="paragraph">이 검증을 위해 다음 표에 나열된 솔루션 구성 요소를 사용했습니다.</block>
  <block id="35c99b744e4464f42b9b61595c1a1e79" category="list-text">각각 8개의 NVIDIA A100 80GB GPU 카드가 장착된 SR670 V2 서버 2대</block>
  <block id="222a9edda77d8676279c651c1b06d653" category="list-text">각 서버에는 2개의 Intel Xeon Platinum 8360Y CPU(28개의 물리적 코어)와 1TB RAM이 포함되어 있습니다</block>
  <block id="e18f1a9d73bf89b2b1245e5af1a99cf4" category="cell">Linux(Ubuntu – 20.04 및 CUDA 11.8)</block>
  <block id="2113187ee3a9451b60e960fdea11bbac" category="cell">NetApp AFF 스토리지 시스템(HA 쌍,</block>
  <block id="73b4d2da39f967445be9b79a6016c84c" category="list-text">NetApp ONTAP 9.10.1 소프트웨어</block>
  <block id="4028b206981977bc3aea334fd55f4cb9" category="list-text">마운트 지점에 대한 4개의 논리적 IP 주소를 사용하여 컨트롤러당 1개의 인터페이스 그룹(ifgrp</block>
  <block id="82693066c3bae0719e01ba8060494172" category="paragraph">이 검증에서는 MLPerf v2.0에서 지정한 ImageNet 기반으로 설정된 ResNet v2.0을 사용했습니다. 데이터 세트는 NFS 프로토콜을 통해 NetApp AFF 스토리지 시스템에 저장됩니다. SR670은 100GbE 스위치를 통해 NetApp AFF A400 스토리지 시스템에 연결했습니다.</block>
  <block id="e4869dda2a4e140bc138f43895626550" category="paragraph">ImageNet은 자주 사용되는 이미지 데이터 세트입니다. 총 144GB 크기의 거의 130만 개의 이미지가 포함되어 있습니다. 평균 이미지 크기는 108KB입니다.</block>
  <block id="3961f6874ee29dab2f4982bc3e0a1be5" category="paragraph">다음 그림은 테스트된 구성의 네트워크 토폴로지를 나타낸 것입니다.</block>
  <block id="d015822ec6fd4a7fc9867768f5a27898" category="inline-image-macro">이 그래픽은 컴퓨팅 계층, Lenovo ThinkSystem SR670 V2, 네트워크 계층, Lenovo 이더넷 스위치, 스토리지 계층, NetApp AFF A400 스토리지 컨트롤러를 보여줍니다. 모든 네트워크 연결이 포함됩니다.</block>
  <block id="1ee331a29f95ebce1684e5e998f3e70c" category="paragraph"><block ref="1ee331a29f95ebce1684e5e998f3e70c" category="inline-image-macro-rx" type="image"></block></block>
  <block id="18866bc1d6ba54b48522f7a219e02740" category="paragraph">다음 표에는 스토리지 구성이 나와 있습니다.</block>
  <block id="f64bc191156dac76ffce8622c16cb21d" category="cell">애그리게이트 크기</block>
  <block id="6bb41960470a19d97556b9240ac0b3ff" category="cell">볼륨 크기</block>
  <block id="abd2beb6abe5072ffab5f1aad1a8c27f" category="cell">운영 체제 마운트 지점</block>
  <block id="a38b6dcf7d1d2c2957803ba9a28b472e" category="cell">/a400-100g</block>
  <block id="43f5cd38d362fc55ace2f313e6b5cf09" category="cell">9.9TB</block>
  <block id="09808554056bf39d02319e3dbc2d6667" category="cell">19TB</block>
  <block id="a27053e11ec415312f3dc32f4e351b67" category="admonition">/a400-100g 폴더에는 ResNet 검증에 사용된 데이터 세트가 들어 있습니다.</block>
  <block id="1ea4953a2e32bbad1a47dd39cbfe929a" category="inline-link-macro">다음: 테스트 절차 및 자세한 결과</block>
  <block id="b20175407b354f0dfc3a4d6a98917f6f" category="paragraph"><block ref="b20175407b354f0dfc3a4d6a98917f6f" category="inline-link-macro-rx"></block></block>
  <block id="15977ebfd8c3685ca2d8911f74efcc2d" category="summary">이 NetApp 및 Lenovo 솔루션은 미드레인지 엔터프라이즈 AI에 적합한 유연한 스케일아웃 아키텍처입니다. NetApp 스토리지는 로컬 SSD 스토리지와 동일하거나 더 우수한 성능을 제공하며 데이터 과학자, 데이터 엔지니어 및 IT 의사 결정자에게 다음과 같은 이점을 제공합니다.</block>
  <block id="632d8fd87d5999301cfd5bd0c0f29b5f" category="inline-link-macro">이전: 아키텍처 조정.</block>
  <block id="b145bbef70e5528880cc5abbbe8575cd" category="paragraph"><block ref="b145bbef70e5528880cc5abbbe8575cd" category="inline-link-macro-rx"></block></block>
  <block id="aa91666790d55bdaa993592c884df440" category="paragraph">여기에서 검증된 NetApp 및 Lenovo 솔루션은 미드레인지 엔터프라이즈 AI에 적합한 유연한 스케일아웃 아키텍처입니다. NetApp 스토리지는 로컬 SSD 스토리지와 동일하거나 더 우수한 성능을 제공하며 데이터 과학자, 데이터 엔지니어 및 IT 의사 결정자에게 다음과 같은 이점을 제공합니다.</block>
  <block id="6127562591a3f60f8ac270d3967754dd" category="list-text">컴퓨팅과 스토리지를 독립적으로 확장 가능하므로 비용을 최소화하고 리소스 활용률을 높일 수 있습니다.</block>
  <block id="74902bcc2ed17395305301b925afee3f" category="list-text">즉각적이고 공간 효율적인 사용자 작업 공간, 통합 버전 제어 및 자동화된 구축을 위해 통합 스냅샷과 복제본을 사용하여 개발 및 구축 워크플로우를 간소화했습니다.</block>
  <block id="42e2aaa2f651d8ad800a51f65a258f1e" category="list-text">재해 복구 및 비즈니스 연속성을 위한 엔터프라이즈급 데이터 보호 기능</block>
  <block id="2ea563f362255807faae7242f06c9881" category="list-text">NetApp 기술 마케팅 엔지니어 Karthian Nagalingam</block>
  <block id="cccf21ceeae034a9e54b62eb00d9b6b3" category="list-text">Jarrett Upton, 관리자, AI Lab Systems, Lenovo</block>
  <block id="fdc944d7a0de8d8e3dfff03c6a0e03c6" category="list-text">NetApp All Flash 어레이 제품 페이지를 참조하십시오</block>
  <block id="d875955d78b62e4aff0847425410f79a" category="inline-link"><block ref="d875955d78b62e4aff0847425410f79a" category="inline-link-rx"></block></block>
  <block id="45f6f9585c85146b389a4f896653a5f9" category="paragraph"><block ref="45f6f9585c85146b389a4f896653a5f9" category="inline-link-rx"></block></block>
  <block id="ec5282877903d9d2aceb3db45b21da54" category="list-text">NetApp AFF A400 페이지</block>
  <block id="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link"><block ref="1f84bc4168c48270f2cc931b900d9eb4" category="inline-link-rx"></block></block>
  <block id="04438df627d0343d17b2f6f307b489ed" category="paragraph"><block ref="04438df627d0343d17b2f6f307b489ed" category="inline-link-rx"></block></block>
  <block id="9d92155996555576a58d20e697fc2bd6" category="list-text">NetApp ONTAP 데이터 관리 소프트웨어 제품 페이지</block>
  <block id="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link"><block ref="dae4be95628a9cc8cb5ecb4b90cd738e" category="inline-link-rx"></block></block>
  <block id="2f08744b4a39af375744e1fc4a15b53a" category="paragraph"><block ref="2f08744b4a39af375744e1fc4a15b53a" category="inline-link-rx"></block></block>
  <block id="45913847e0b47b72b60766711f7a8c21" category="inline-link"><block ref="45913847e0b47b72b60766711f7a8c21" category="inline-link-rx"></block></block>
  <block id="229469a202dbd3052c7b165bd55eda87" category="paragraph"><block ref="229469a202dbd3052c7b165bd55eda87" category="inline-link-rx"></block></block>
  <block id="dedba6b3261804ab1e5c2b75051c62ac" category="list-text">NVIDIA SMI(NVIDIA-SMI)</block>
  <block id="f5800a0bf7fbf711d11868c2913c218f" category="inline-link"><block ref="f5800a0bf7fbf711d11868c2913c218f" category="inline-link-rx"></block></block>
  <block id="41299b529a1014318d5e7776b9f92ad1" category="paragraph"><block ref="41299b529a1014318d5e7776b9f92ad1" category="inline-link-rx"></block></block>
  <block id="cf2dfa7ef96d78d1f3ec76316e1481d0" category="cell">2020년 2월</block>
  <block id="54858f2e7ecb57a17b7c0be2dedfcd7b" category="cell">최초 릴리스. SR670 및 AFF A220(TensorFlow 포함)에 대한 검증.</block>
  <block id="abb14d21829ba186172f6e1d0b64b55b" category="cell">2023년 1월</block>
  <block id="c04468d92a14823a475df983d69e5f9f" category="cell">업데이트된 릴리스. SR 670 V2 및 AFF A400(MXNet 포함) 검증</block>
  <block id="e59b92fc604ecde201ab865ddefca7c2" category="summary">이 섹션에서는 이 솔루션의 주요 구성 요소에 대해 자세히 설명합니다.</block>
  <block id="56cdae354d8e4efeaa936d576b919c49" category="paragraph"><block ref="56cdae354d8e4efeaa936d576b919c49" category="inline-link-macro-rx"></block></block>
  <block id="995049066ee0a46858d3a35e74f687fc" category="paragraph">NetApp AFF 스토리지 시스템을 사용하는 기업은 업계 최고의 성능, 탁월한 유연성, 클라우드 통합, 동급 최고의 데이터 관리 등을 통해 엔터프라이즈 스토리지 요구사항을 충족할 수 있습니다. 플래시 전용으로 설계된 AFF 시스템은 비즈니스 크리티컬 데이터를 더 빠르게 처리하고 관리, 보호할 수 있도록 지원합니다.</block>
  <block id="bd06e3e9a11cc16a8f389477f9ed6a95" category="paragraph">NetApp AFF A400은 FAS2650 하드웨어 및 SSD 플래시 미디어를 기반으로 하는 미드레인지 NVMe 플래시 스토리지 시스템입니다.</block>
  <block id="9cdcb25bd8b8e9dd029f0c58f1c1ce14" category="inline-image-macro">이 그림은 NetApp AFF A400 스토리지 컨트롤러의 앞면을 보여줍니다.</block>
  <block id="55f69aa150e5e2d9b4339594dbb70471" category="paragraph"><block ref="55f69aa150e5e2d9b4339594dbb70471" category="inline-image-macro-rx" type="image"></block></block>
  <block id="6a4c41eb7420fce0589579f0f045df87" category="inline-image-macro">이 그림은 NetApp AFF A400 스토리지 컨트롤러의 뒷면을 보여줍니다.</block>
  <block id="e83035ebe127e618e86974c913d42589" category="paragraph"><block ref="e83035ebe127e618e86974c913d42589" category="inline-image-macro-rx" type="image"></block></block>
  <block id="5062a65c6ae4cbe0c015396c4011a811" category="paragraph">NetApp AFF A400 미드레인지 스토리지 시스템의 기능은 다음과 같습니다.</block>
  <block id="722f61060a76e673835749dd7040109c" category="list-text">최대 유효 용량: 702.7PB</block>
  <block id="9b150a217729988c3dd54fdaf7b0f9b3" category="list-text">최대 스케일아웃: 2~24노드(12개의 HA 쌍)</block>
  <block id="ae3b033d221455bb2825ac51bee7200e" category="list-text">25GbE 및 16Gb FC 호스트 지원</block>
  <block id="e16f4e2b178ce47880c3556c501efea4" category="list-text">RoCE(100GbE RDMA over Converged Ethernet) 와 NVMe 확장 스토리지 쉘프 연결</block>
  <block id="2f5979909b8c4a0d58f13de4881feaf1" category="list-text">NVMe 쉘프가 연결되지 않은 경우 호스트 네트워크 연결용으로 100GbE RoCE 포트를 사용할 수 있습니다</block>
  <block id="dff1410020c1b676f56ee973acea57d3" category="list-text">전체 12GBps SAS 연결 확장 스토리지 쉘프</block>
  <block id="565637725a05c879995851c50d41275c" category="list-text">두 가지 구성으로 사용 가능:</block>
  <block id="8e707b713d26c4b020eda98a37207373" category="list-text">이더넷: 25Gb 이더넷(SFP28) 포트 4개</block>
  <block id="1d3c6ad9f15fc70a1cf63e449e90436a" category="list-text">파이버 채널: 16Gb FC(SFP+) 포트 4개</block>
  <block id="6a2a811bcec501901ab6f8f94694d1b2" category="list-text">100% 8KB 랜덤 읽기 @ .4 ms 400k IOPS</block>
  <block id="d3309961dfabc3043c3ea1878752450b" category="paragraph">엔트리 레벨 AI/ML 구축을 위한 NetApp AFF A250 기능은 다음과 같습니다.</block>
  <block id="68448ae40d26fce5bb74cd3bf75999c4" category="list-text">최대 실제 용량: 35PB</block>
  <block id="83fa45e9cc2def5751527547e3c57b61" category="list-text">최대 스케일아웃: 2~24노드(12개의 HA 쌍)</block>
  <block id="1283cfcd2651148a611c2c4b105458c3" category="list-text">최신 NetApp ONTAP 릴리스 ONTAP 9.8 이상을 기반으로 합니다</block>
  <block id="f31903137775862e1157677f447b0f52" category="list-text">HA 및 클러스터 인터커넥트용 25Gb 이더넷 포트 2개</block>
  <block id="f6c48fdc99c510156e0364e03a6fbd9e" category="paragraph">또한, NetApp은 대규모 AI/ML 구축을 위한 뛰어난 성능과 확장성을 제공하는 AFF A800 및 AFF A700과 같은 다른 스토리지 시스템을 제공합니다.</block>
  <block id="b2c0ed3ea756cb47f24ee9aef32e0f01" category="paragraph">NetApp의 최신 세대 스토리지 관리 소프트웨어인 ONTAP 9는 기업이 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있도록 지원합니다. ONTAP는 업계 최고 수준의 데이터 관리 기능을 활용하여 데이터가 상주하는 위치와 상관없이 단일 툴셋으로 데이터를 관리하고 보호할 수 있습니다. 필요에 따라 에지, 코어, 클라우드 등 어느 위치로도 데이터를 자유롭게 이동할 수 있습니다. ONTAP 9에는 데이터 관리를 단순화하고, 중요 데이터를 더 빨리 처리하고 보호하는 다수의 기능이 포함되어 있으며, 하이브리드 클라우드 아키텍처 전체에 미래 지향형 인프라를 제공합니다.</block>
  <block id="ddf38f965aeb6f6b5785254e6f143a09" category="list-text">* ONTAP FabricPool. * 이 기능은 콜드 데이터를 AWS(Amazon Web Services), Azure, NetApp StorageGRID 오브젝트 스토리지를 포함한 퍼블릭 및 프라이빗 클라우드 스토리지 옵션으로 자동 계층화합니다.</block>
  <block id="2a228ac6322b6d496b4cb0cf22cfbfe4" category="list-text">* 성능 및 낮은 지연 시간 * ONTAP는 가장 짧은 지연 시간으로 가장 높은 처리량을 제공합니다.</block>
  <block id="cf4d3359e3cce4324a54d8e1864d2647" category="paragraph">ONTAP 9은 지속적으로 변화하는 까다로운 요구사항을 충족할 수 있도록 지원합니다.</block>
  <block id="99f4fd3a9ea4a861a7095bfe26937f28" category="list-text">* 원활한 확장 및 무중단 운영 * ONTAP은 기존 컨트롤러 및 스케일아웃 클러스터에 용량을 무중단으로 추가할 수 있도록 지원합니다. 고객은 고비용이 따르는 데이터 마이그레이션이나 운영 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.</block>
  <block id="ba1e7aff40da44f3c5b86ba78a62e7d0" category="list-text">새로운 애플리케이션과의 통합 * ONTAP는 기존 엔터프라이즈 앱을 지원하는 인프라와 동일한 인프라를 사용하여 OpenStack, Hadoop, MongoDB와 같은 차세대 플랫폼 및 애플리케이션을 위한 엔터프라이즈급 데이터 서비스를 제공합니다.</block>
  <block id="0fdd508a09442b5caa00e47bc0563112" category="section-title">NetApp FlexGroup 볼륨</block>
  <block id="641653fdc449e0b1e30f3ee9d04182ab" category="paragraph">교육 데이터 세트는 일반적으로 수십억 개에 달하는 파일로 구성됩니다. 파일에는 텍스트, 오디오, 비디오 및 기타 형식의 비정형 데이터가 포함될 수 있으며, 이 데이터를 병렬로 읽고 저장해야 합니다. 스토리지 시스템은 수많은 작은 파일을 저장해야 하며 순차적 I/O 및 랜덤 I/O를 위해 병렬로 이들 파일을 읽어야 합니다</block>
  <block id="e6ad1152aea2aa4f79a47e3b80410fce" category="paragraph">FlexGroup 볼륨(다음 그림)은 여러 개의 구성 멤버 볼륨으로 이루어진 단일 네임스페이스이며, NetApp FlexVol 볼륨 스토리지와 같이 동작합니다. FlexGroup 볼륨의 파일은 개별 구성원 볼륨에 할당되며 볼륨 또는 노드에 스트라이핑되지 않습니다. 다음과 같은 기능을 지원합니다.</block>
  <block id="381a99cae8c29b3b8fd64a207b811935" category="list-text">메타데이터 워크로드에서 최대 20PB 용량 및 예측 가능한 짧은 지연 시간</block>
  <block id="b0e05251a53a0118d23cd469db4b1903" category="list-text">동일한 네임스페이스에서 최대 4천억 개의 파일 지원</block>
  <block id="4eb6665794643a2afabf63f90ddbe4da" category="list-text">CPU, 노드, 애그리게이트 및 구성 FlexVol 볼륨에서 NAS 워크로드에 병렬 작업을 수행합니다</block>
  <block id="19adba666d12642fc956c8a4c4607a66" category="inline-image-macro">"이 이미지는 FlexGroup 내의 기본 파일과 함께 많은 볼륨이 포함된 스토리지 컨트롤러의 HA 쌍을 보여줍니다.</block>
  <block id="67243c21916276b166b8cad21f937c57" category="paragraph"><block ref="3998ac0cd0b54d5528002049c9fb6e1f" category="inline-image-macro-rx" type="image"></block>"</block>
  <block id="f52dbcd9b43086f1d2957e6eb89f4113" category="section-title">Lenovo ThinkSystem 포트폴리오</block>
  <block id="c5ac419e5467e7539d60c18be3da4b99" category="paragraph">Lenovo ThinkSystem 서버 배포의 주요 이점은 다음과 같습니다.</block>
  <block id="c19629173ec04d03fae09e96ce30b98c" category="list-text">비즈니스 성장에 따라 확장 가능한 모듈식 설계</block>
  <block id="9ac34c98220e3dd285a7cd6c8679caeb" category="paragraph">AI 분야에서 Lenovo는 기업들이 워크로드에 대한 ML 및 AI의 이점을 이해하고 적용할 수 있도록 실질적인 접근 방식을 취하고 있습니다. Lenovo 고객은 Lenovo AI Innovation Center의 Lenovo AI 제품을 살펴보고 평가하여 해당 사용 사례의 가치를 완벽하게 파악할 수 있습니다. 가치 창출 시간을 단축하기 위해 이 고객 중심 접근 방식은 AI에 사용 가능하고 최적화된 솔루션 개발 플랫폼에 대한 고객 개념 증명을 제공합니다.</block>
  <block id="7cbc0e3d7cff391aa0e61b487dc29df1" category="section-title">Lenovo SR670 V2</block>
  <block id="5889950b76dcc45f10977523225c92a8" category="paragraph">Lenovo ThinkSystem SR670 V2 랙 서버는 가속화된 AI 및 고성능 컴퓨팅(HPC)을 위한 최적의 성능을 제공합니다. 최대 8개의 GPU를 지원하는 SR670 V2는 ML, DL 및 추론의 컴퓨팅 집약적인 워크로드 요구사항에 적합합니다.</block>
  <block id="327669874a587f6f9336f608f83d451d" category="inline-image-macro">이 이미지는 SR670 구성 3개를 보여 줍니다. 첫 번째 그림은 8개의 2.5인치 HS 드라이브와 2개의 PCIe I/O 슬롯이 있는 SXM GPU 4개를 보여 줍니다. 두 번째 그림은 4개의 이중 너비 또는 8개의 단일 와이드 GPU 슬롯과 8개의 2.5인치 또는 4개의 3.5인치 HS 드라이브가 있는 2개의 PCIe I/O 슬롯을 보여 줍니다. 세 번째 그림은 EDSFF HS 드라이브 6개와 PCIe I/O 슬롯 2개로 구성된 이중 와이드 GPU 슬롯 8개를 보여 줍니다.</block>
  <block id="f3ebf0cd9319acd4d10b09be0d9220c2" category="paragraph"><block ref="f3ebf0cd9319acd4d10b09be0d9220c2" category="inline-image-macro-rx" type="image"></block></block>
  <block id="85b1e2eb4bc61f3bdaea9a9f040eb3a0" category="paragraph">ThinkSystem SR670 V2는 하이엔드 GPU(NVIDIA A100 80GB PCIe 8x GPU 포함)를 지원하는 확장 가능한 최신 Intel Xeon CPU를 통해 AI 및 HPC 워크로드에 최적화된 가속 성능을 제공합니다.</block>
  <block id="d7ed5fdb2102567c3c051078e7c72e11" category="paragraph">가속기의 성능을 사용하는 워크로드가 증가할수록 GPU 밀도에 대한 수요도 증가합니다. 소매, 금융 서비스, 에너지, 의료 등의 산업에서 GPU를 사용하여 더 큰 통찰력을 얻고 ML, DL 및 추론 기술을 통해 혁신을 주도하고 있습니다.</block>
  <block id="89a846b0823ae167964c8a02382225cf" category="paragraph">ThinkSystem SR670 V2는 운영 환경에 가속화된 HPC 및 AI 워크로드를 배포할 수 있는 최적화된 엔터프라이즈급 솔루션으로, 차세대 플랫폼을 통해 슈퍼컴퓨팅 클러스터의 데이터 센터 밀도를 유지하는 동시에 시스템 성능을 극대화합니다.</block>
  <block id="9378d87a3787bb6ab3fe4605dd558aaf" category="paragraph">기타 기능은 다음과 같습니다.</block>
  <block id="fe62ffc0b0188329f10e2bfc0c560ece" category="list-text">고속 네트워크 어댑터가 GPU에 직접 연결되어 I/O 성능을 극대화하는 GPU 직접 RDMA I/O 지원</block>
  <block id="03e5fd8f257caa94eae847639e18b1a9" category="list-text">NVMe 드라이브가 GPU에 직접 연결된 GPU 직접 스토리지를 지원하여 스토리지 성능을 극대화합니다.</block>
  <block id="ad7857a40388167e99516cfe367478d5" category="paragraph">MLPerf는 AI 성능 평가를 위한 업계 최고의 벤치마크 제품군입니다. 이 검증에서는 가장 인기 있는 AI 프레임워크 중 하나인 MXNet과 함께 이미지 분류 벤치마크를 사용했습니다. MXNet_벤치마크 교육 스크립트는 AI 교육을 진행하는 데 사용되었습니다. 이 스크립트에는 널리 사용되는 여러 가지 기존 모델의 구현이 포함되어 있으며 가능한 한 빨리 구현되도록 설계되었습니다. 단일 시스템에서 실행하거나 여러 호스트에 걸쳐 분산 모드로 실행할 수 있습니다.</block>
  <block id="a29118c3c40b6309f6b6354a52631e91" category="paragraph"><block ref="a29118c3c40b6309f6b6354a52631e91" category="inline-link-macro-rx"></block></block>
  <block id="f0cbafc85a7a8d2836dd3a3d51266f61" category="sidebar">AI 및 ML 모델 교육을 위한 Lenovo ThinkSystem SR670 V2 기반 NetApp AFF A400</block>
</blocks>