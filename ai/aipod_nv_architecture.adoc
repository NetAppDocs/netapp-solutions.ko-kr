---
sidebar: sidebar 
permalink: ai/aipod_nv_architecture.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: NVIDIA DGX 시스템 기반 NetApp AI Pod - 아키텍처 
---
= NVIDIA DGX 시스템 기반 NetApp AI Pod - 아키텍처
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aipod_nv_sw_components.html["이전: ONTAP AI 소프트웨어 구성요소"]

이 레퍼런스 아키텍처는 컴퓨팅 클러스터 상호 연결 및 스토리지 액세스에 별도의 패브릭을 활용하며, 컴퓨팅 노드 간 NDR200 및 HDR200 Infiniband(IB) 연결 옵션을 제공합니다. DGX H100 시스템에는 NDR IB 연결을 위해 ConnectX-7 카드가 사전 설치되어 제공되며, DGX A100 시스템은 HDR 또는 NDR 연결에 ConnectX-6 또는 ConnectX-7 카드를 각각 사용할 수 있습니다.



== DGX H100 시스템을 사용하는 ONTAP AI

아래 그림은 ONTAP AI와 함께 DGX H100 시스템을 사용할 때의 전반적인 솔루션 토폴로지를 보여줍니다.

image:oai_H100_topo.png["오류: 그래픽 이미지가 없습니다"]

이 구성에서 컴퓨팅 클러스터 네트워크는 고가용성을 위해 함께 연결된 한 쌍의 QM9700 NDR IB 스위치를 사용합니다. 각 DGX H100 시스템은 8개의 NDR200 연결을 사용하여 스위치에 연결되며, 짝수 번호 포트는 하나의 스위치에 연결되고 홀수 번호 포트는 다른 스위치에 연결됩니다.

스토리지 시스템 액세스, 대역 내 관리 및 클라이언트 액세스의 경우 한 쌍의 SN4600 이더넷 스위치가 사용됩니다. 스위치는 스위치 간 링크로 연결되고 여러 VLAN으로 구성되어 다양한 트래픽 유형을 격리합니다. 대규모 배포의 경우 필요에 따라 스파인 및 리프를 위한 추가 스위치 쌍을 추가하여 이더넷 네트워크를 리프-스파인 구성으로 확장할 수 있습니다. 각 DGX A100 시스템은 이더넷 및 스토리지 트래픽을 위해 2개의 이중 포트 ConnectX-6 카드를 사용하여 프로비저닝되며, 이 솔루션의 경우 4개의 포트가 모두 200Gbps로 SN4600 이더넷 스위치에 연결됩니다. 각 카드의 포트 하나는 각 스위치에 연결된 1개의 포트를 가진 LACP MLAG 결합으로 구성되고, 대역 내 관리, 클라이언트 액세스 및 사용자 레벨 스토리지 액세스를 위한 VLAN이 이 결합에서 호스팅됩니다. 각 카드의 다른 포트는 AFF A800 스토리지 시스템에 연결하기 위해 별도의 전용 RoCE 스토리지 VLAN에서 독립적으로 사용됩니다. 이러한 포트는 NFS v3, pNFS용 NFSv4.x, RDMA over NFS를 통한 고성능 스토리지 액세스를 지원합니다.

컴퓨팅 상호 연결 및 고속 이더넷 네트워크 외에도 모든 물리적 장치가 대역 외 관리를 위해 하나 이상의 SN2201 이더넷 스위치에 연결됩니다.  DGX A100 시스템 연결에 대한 자세한 내용은 을 참조하십시오 link:https://nvdam.widen.net/s/nfnjflmzlj/nvidia-dgx-basepod-reference-architecture["NVIDIA BasePOD 설명서"].



== DGX A100 시스템을 사용하는 ONTAP AI

아래 그림은 DGX A100 시스템과 ONTAP AI에서 HDR 컴퓨팅 패브릭을 사용할 때의 전체 솔루션 토폴로지를 보여줍니다.

image:oai_A100_topo.png["오류: 그래픽 이미지가 없습니다"]

이 구성에서 컴퓨팅 클러스터 네트워크는 고가용성을 위해 함께 연결된 QM8700 HDR IB 스위치 쌍을 사용합니다. 각 DGX A100 시스템은 200Gbps 속도로 단일 포트 ConnectX-6 카드 4개를 사용하여 스위치에 연결되며, 짝수 포트가 하나의 스위치에 연결되고 홀수 번호 포트는 다른 스위치에 연결됩니다.

스토리지 시스템 액세스, 대역 내 관리 및 클라이언트 액세스의 경우 한 쌍의 SN4600 이더넷 스위치가 사용됩니다. 스위치는 스위치 간 링크로 연결되고 여러 VLAN으로 구성되어 다양한 트래픽 유형을 격리합니다. 대규모 배포의 경우 필요에 따라 스파인 및 리프를 위한 추가 스위치 쌍을 추가하여 이더넷 네트워크를 리프-스파인 구성으로 확장할 수 있습니다. 각 DGX A100 시스템은 이더넷 및 스토리지 트래픽을 위해 2개의 이중 포트 ConnectX-6 카드를 사용하여 프로비저닝되며, 이 솔루션의 경우 4개의 포트가 모두 200Gbps로 SN4600 이더넷 스위치에 연결됩니다. 각 카드의 포트 하나는 각 스위치에 연결된 1개의 포트를 가진 LACP MLAG 결합으로 구성되고, 대역 내 관리, 클라이언트 액세스 및 사용자 레벨 스토리지 액세스를 위한 VLAN이 이 결합에서 호스팅됩니다. 각 카드의 다른 포트는 AFF A800 스토리지 시스템에 연결하기 위해 별도의 전용 RoCE 스토리지 VLAN에서 독립적으로 사용됩니다. 이러한 포트는 NFS v3, pNFS용 NFSv4.x, RDMA over NFS를 통한 고성능 스토리지 액세스를 지원합니다.

컴퓨팅 상호 연결 및 고속 이더넷 네트워크 외에도 모든 물리적 장치가 대역 외 관리를 위해 하나 이상의 SN2201 이더넷 스위치에 연결됩니다.  DGX A100 시스템 연결에 대한 자세한 내용은 을 참조하십시오 link:https://nvdam.widen.net/s/nfnjflmzlj/nvidia-dgx-basepod-reference-architecture["NVIDIA BasePOD 설명서"].



== 관리 플레인 서버

이 레퍼런스 아키텍처에는 관리 플레인을 위한 5개의 CPU 기반 서버도 포함되어 있습니다. 이러한 시스템 중 두 개는 클러스터 구축 및 관리를 위한 Base Command Manager의 헤드 노드로 사용됩니다. 다른 3개의 시스템은 작업 예약을 위해 Slurm을 활용하는 구축에 Kubernetes 마스터 노드 또는 로그인 노드와 같은 추가 클러스터 서비스를 제공하는 데 사용됩니다. Kubernetes를 활용하는 구축에서는 NetApp Astra Trident CSI 드라이버를 활용하여 AFF A800 스토리지 시스템의 관리 및 AI 워크로드를 위한 영구 스토리지를 위한 자동 프로비저닝 및 데이터 서비스를 제공할 수 있습니다.

각 서버는 IB 스위치와 이더넷 스위치 모두에 물리적으로 연결되어 클러스터 배포 및 관리를 지원하며, 앞서 설명한 대로 클러스터 관리 아티팩트를 저장하기 위해 관리 SVM을 통해 스토리지 시스템에 NFS 마운트로 구성됩니다.

link:aipod_nv_storage.html["다음으로, NVIDIA DGX 시스템 지원 NetApp AI Pod - 스토리지 시스템 설계 및 사이징 지침"]
