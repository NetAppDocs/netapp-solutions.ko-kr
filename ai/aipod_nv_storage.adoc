---
sidebar: sidebar 
permalink: ai/aipod_nv_storage.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVIDIA BasePOD, NVIDIA DGX 
summary: NetApp AI Pod 및 NVIDIA DGX 시스템 - 스토리지 시스템 설계 및 사이징 지침 
---
= NetApp AI Pod 및 NVIDIA DGX 시스템 - 스토리지 시스템 설계 및 사이징 지침
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


link:aipod_nv_architecture.html["이전: NVIDIA DGX 시스템 기반 NetApp AI Pod - 아키텍처"]



== 스토리지 시스템 설계

각 AFF A800 스토리지 시스템은 각 컨트롤러에서 4개의 100GbE 포트를 사용하여 연결됩니다. 각 컨트롤러의 포트 2개는 DGX 시스템에서 워크로드 데이터에 액세스하는 데 사용되며, 각 컨트롤러의 포트 2개는 클러스터 관리 아티팩트 및 사용자 홈 디렉토리에 대한 관리 플레인 서버의 액세스를 지원하기 위해 LACP 인터페이스 그룹으로 구성됩니다. 스토리지 시스템에서 수행하는 데이터 액세스는 모두 NFS를 통해 제공되며, AI 워크로드 액세스 전용 SVM(Storage Virtual Machine) 및 클러스터 관리 전용 SVM은 별도로 제공됩니다.

워크로드 SVM은 스토리지 VLAN당 논리 인터페이스(LIF) 2개, 총 4개의 LIF로 구성됩니다. 각 물리적 포트는 2개의 LIF를 호스팅하므로, 각 컨트롤러의 VLAN당 2개의 LIF가 생성됩니다. 이렇게 구성하면 각 LIF가 동일한 컨트롤러의 다른 포트로 페일오버되는 방법과 최대 대역폭이 제공되므로, 네트워크 장애 발생 시 두 컨트롤러가 모두 활성 상태를 유지합니다. 이 구성은 GPUDirect Storage 액세스를 사용할 수 있도록 RDMA를 통한 NFS도 지원합니다. 스토리지 용량은 두 컨트롤러를 모두 아우르는 단일 대규모 FlexGroup 볼륨의 형태로 프로비저닝됩니다. 이 FlexGroup는 SVM의 모든 LIF에서 액세스할 수 있으며, DGX A100 시스템의 마운트 지점은 로드 밸런싱을 위해 사용 가능한 LIF로 분산됩니다.

관리 SVM에는 단일 LIF만 필요하며, 각 컨트롤러에 구성된 2포트 인터페이스 그룹에 호스팅됩니다. 다른 FlexGroup 볼륨은 관리 SVM에 프로비저닝되어 클러스터 노드 이미지, 시스템 모니터링 내역 데이터, 최종 사용자 홈 디렉토리 같은 클러스터 관리 아티팩트를 저장합니다. 아래 그림은 스토리지 시스템의 논리적 구성을 보여 줍니다.

image:oai_basepod1_logical.png["오류: 그래픽 이미지가 없습니다"]



== 스토리지 시스템의 사이징 지침

이 아키텍처는 NVIDIA DGX 시스템 및 NetApp AFF 스토리지 시스템으로 DL 인프라를 구축하려는 고객 및 파트너를 위한 참조용입니다. 아래 표는 각 AFF 모델에서 지원되는 A100 및 H100 GPU의 수를 대략적으로 보여줍니다.

image:oai_sizing.png["오류: 그래픽 이미지가 없습니다"]

에 나와 있는 대로 link:https://www.netapp.com/pdf.html?item=/media/21793-nva-1153-design.pdf["이 참조 아키텍처의 이전 버전입니다"], AFF A800 시스템은 8개 DGX A100 시스템에서 생성된 DL 교육 워크로드를 손쉽게 지원합니다. 위의 다른 스토리지 시스템에 대한 추정치는 이러한 결과를 기준으로 계산되었으며 H100 GPU의 추정치는 A100 시스템에 필요한 스토리지 처리량을 두 배로 높여 계산되었습니다.  스토리지 성능 요구사항이 더 높은 대규모 구축의 경우 단일 클러스터에서 최대 12개의 HA 쌍(24개 노드)까지 AFF 시스템을 NetApp ONTAP 클러스터에 추가할 수 있습니다. 이 솔루션에 설명된 FlexGroup 기술을 사용하여 24노드 클러스터는 단일 네임스페이스에서 40PB 이상의 처리량과 최대 300GBps 처리량을 제공할 수 있습니다. AFF A400, A250 및 C800 같은 다른 NetApp 스토리지 시스템은 낮은 비용으로 소규모 구축을 위한 낮은 성능 및/또는 더 높은 용량 옵션을 제공합니다. ONTAP 9에서 혼합 모델 클러스터가 지원되므로, 고객은 초기 설치 공간을 작게 시작한 후 용량 및 성능 요구사항이 증가함에 따라 클러스터에 규모가 더 큰 스토리지 시스템을 더 추가할 수 있습니다.
link:aipod_nv_conclusion.html["다음: NVIDIA DGX 시스템 기반 NetApp AI Pod - 결론"]
