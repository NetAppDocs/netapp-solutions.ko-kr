---
sidebar: sidebar 
permalink: ai/vector-database-performance-validation.html 
keywords: vector database 
summary: 벡터 데이터베이스 성능 검증 - NetApp용 벡터 데이터베이스 솔루션 
---
= Vector 데이터베이스 성능 검증
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
이 섹션에서는 벡터 데이터베이스에서 수행된 성능 검증을 중점적으로 소개합니다.



== 성능 검증

성능 검증은 벡터 데이터베이스와 스토리지 시스템 모두에서 중요한 역할을 하며 최적의 운영과 효율적인 리소스 활용도를 보장하는 핵심 요소로 작용합니다. 높은 차원 데이터를 처리하고 유사성 검색을 실행하는 것으로 알려진 벡터 데이터베이스는 복잡한 쿼리를 신속하고 정확하게 처리하기 위해 높은 성능 수준을 유지해야 합니다. 성능 검증은 병목 현상을 식별하고 구성을 세밀하게 조정하고 시스템이 서비스 성능 저하 없이 예상 로드를 처리할 수 있도록 하는 데 도움이 됩니다. 마찬가지로 스토리지 시스템에서 성능 검증은 전체 시스템 성능에 영향을 줄 수 있는 지연 시간 문제나 병목 현상 없이 데이터를 효율적으로 저장하고 검색하는 데 필수적입니다. 또한 정보에 근거하여 스토리지 인프라의 필요한 업그레이드 또는 변경 결정을 내릴 수 있도록 지원합니다. 따라서 성능 검증은 시스템 관리의 중요한 측면으로, 높은 서비스 품질, 운영 효율성 및 전반적인 시스템 안정성을 유지하는 데 크게 기여합니다.

이 섹션에서는 Milvus 및 pgvecto.RS와 같은 벡터 데이터베이스의 성능 검증을 자세히 살펴보고, LLM 수명주기 내의 RAG 및 추론 워크로드를 지원하는 I/O 프로필 및 NetApp 스토리지 컨트롤러 같은 스토리지 성능 특성에 초점을 맞추고자 합니다. 이들 데이터베이스가 ONTAP 스토리지 솔루션과 결합될 때 성능 차별화 요소를 평가하고 식별합니다. 당사의 분석은 QPS(초당 처리된 쿼리 수)와 같은 주요 성능 지표를 기반으로 합니다.

아래 Milvus에 사용되는 방법론과 진행 상황을 확인하십시오.

|===


| 세부 정보 | Milvus(독립 실행형 및 클러스터) | Postgres(pgvecto.rs) # 


| 버전 | 2.3.2 | 0.2.0 


| 파일 시스템 | iSCSI LUN의 XFS |  


| 워크로드 생성기 | link:https://github.com/zilliztech/VectorDBBench["벡터DB-벤치"] –v0.0.5 |  


| 데이터 세트 | LAION 데이터 세트
* 10,000,000개의 침구
* 768 치수
* ~ 300GB 데이터 세트 크기 |  


| 스토리지 컨트롤러 | AFF 800 * 버전 – 9.14.1 * 4 x 100GbE – Milvus용, postgres * iSCSI용 100GbE 2개 |  
|===


=== VectorDB - Milvus 독립 실행형 클러스터를 사용한 벤치

vectorDB-Bench를 사용하는 milvus 독립 실행형 클러스터에 대해 다음과 같은 성능 검증을 수행했습니다.
milvus 독립 실행형 클러스터의 네트워크 및 서버 연결은 다음과 같습니다.

image::perf_mivus_standalone.png[성능 mivus 독립 실행형]

이 섹션에서는 Milvus 독립 실행형 데이터베이스 테스트의 관찰 결과 및 결과를 공유합니다.
.	이러한 테스트의 인덱스 유형으로 DiskANN을 선택했습니다.
.	약 100GB의 데이터 세트에 대한 인덱스를 수집, 최적화 및 생성하는 데 약 5시간이 걸렸습니다. 대부분의 기간 동안 20개의 코어(하이퍼 스레딩을 사용할 경우 40개의 vCPU와 동일)를 장착한 Milvus 서버는 최대 CPU 용량인 100%에서 작동하고 있었습니다. DiskANN은 특히 시스템 메모리 크기를 초과하는 대규모 데이터세트에 매우 중요합니다.
.	조회 단계에서 0.9987을 리콜한 상태에서 QPS(Queries per second)가 10.93인 것을 확인했습니다. 쿼리의 99번째 백분위수 지연 시간은 708.2밀리초로 측정되었습니다.

스토리지 관점에서 볼 때 데이터베이스는 수집, 삽입 후 최적화, 인덱스 생성 단계에서 약 1,000 ops/sec를 기록했습니다. 쿼리 단계에서는 32,000 ops/초가 필요했습니다

다음 섹션에서는 스토리지 성능 메트릭에 대해 설명합니다.

|===
| 워크로드 단계 | 미터 | 값 


| 데이터 수집
및
삽입 후 최적화 | IOPS | 1,000명 이하 


|  | 지연 시간 | 400개 이상의 활용 


|  | 워크로드 | 읽기/쓰기 조합, 주로 쓰기입니다 


|  | IO 크기입니다 | 64KB 


| 쿼리 | IOPS | 32,000에서 최고치 


|  | 지연 시간 | 400개 이상의 활용 


|  | 워크로드 | 100% 캐시된 읽기 


|  | IO 크기입니다 | 주로 8KB 
|===
vectorDB-bench 결과는 다음과 같습니다.

image::vector_db_result_standalone.png[Vector db 결과 독립 실행형]

독립 실행형 Milvus 인스턴스의 성능 검증을 통해 현재 설정이 치수 1536의 5백만 벡터로 구성된 데이터 세트를 지원하기에는 불충분하다는 것을 알 수 있습니다. 스토리지에 적절한 리소스가 있으며 시스템에 병목 현상이 발생하지 않는 것으로 확인되었습니다.



=== VectorDB - 밀버스 클러스터를 사용한 벤치

이 섹션에서는 Kubernetes 환경 내에 Milvus 클러스터를 구축하는 방법에 대해 설명합니다. 이 Kubernetes 설정은 Kubernetes 마스터 및 작업자 노드를 호스팅하는 VMware vSphere 배포를 바탕으로 구성되었습니다.

VMware vSphere 및 Kubernetes 구축에 대한 자세한 내용은 다음 섹션에서 설명합니다.

image::milvus_vmware_perf.png[Milvus VMware 성능]

image::milvus_cluster_perf.png[Milvus 클러스터 성능]

이 섹션에서는 Milvus 데이터베이스 테스트에서 얻은 관찰 내용과 결과를 설명합니다.
*사용된 인덱스 유형은 DiskANN입니다.
*아래 표는 1536의 치수에서 5백만 벡터로 작업할 때 독립형 배포와 클러스터 배포를 비교한 것입니다. 우리는 데이터 수집 및 삽입 후 최적화에 걸리는 시간이 클러스터 구축에서 더 낮은 것으로 확인되었습니다. 독립 실행형 설정에 비해 클러스터 구축 시 쿼리의 99번째 백분위수 지연 시간이 6배 감소했습니다.
*클러스터 배포에서 QPS(Queries per Second) 비율이 높았지만 원하는 수준에서는 그렇지 않았습니다.

image::milvus_standalone_cluster_perf.png[Milvus 독립 실행형 클러스터 성능]

아래 이미지는 스토리지 클러스터 지연 시간 및 총 IOPS(초당 입출력 작업 수)를 포함한 다양한 스토리지 메트릭을 보여 줍니다.

image::storagecluster_latency_iops_milcus.png[스토리지lustr 지연 시간 IOPS milcus]

다음 섹션에서는 주요 스토리지 성능 메트릭에 대해 설명합니다.

|===
| 워크로드 단계 | 미터 | 값 


| 데이터 수집
및
삽입 후 최적화 | IOPS | 1,000명 이하 


|  | 지연 시간 | 400개 이상의 활용 


|  | 워크로드 | 읽기/쓰기 조합, 주로 쓰기입니다 


|  | IO 크기입니다 | 64KB 


| 쿼리 | IOPS | 147,000에서 최고점 


|  | 지연 시간 | 400개 이상의 활용 


|  | 워크로드 | 100% 캐시된 읽기 


|  | IO 크기입니다 | 주로 8KB 
|===
독립 실행형 Milvus 및 Milvus 클러스터의 성능 검증을 토대로 스토리지 I/O 프로필에 대한 세부 정보를 제공합니다.
* 독립 실행형 및 클러스터 구축 모두에서 I/O 프로필이 일관되게 유지되는 것을 확인했습니다.
* 피크 IOPS에서 관찰된 차이는 클러스터 구축 시 클라이언트 수가 많기 때문입니다.



=== Postgres가 있는 vectorDB-벤치(pgvecto.rs)

VectorDB-Bench를 사용하여 PostgreSQL(pgvecto.rs)에 대해 다음 작업을 수행했습니다.
PostgreSQL(특히 pgvecto.rs)의 네트워크 및 서버 연결에 대한 세부 정보는 다음과 같습니다.

image::pgvecto_perf_network_connectivity.png[pgvecto perf 네트워크 연결]

이 섹션에서는 특히 pgvecto.rs를 사용하여 PostgreSQL 데이터베이스를 테스트한 결과 및 관찰 결과를 공유합니다.
* 테스트 당시 DiskANN은 pgvecto.RS에 사용할 수 없었기 때문에 이러한 테스트의 인덱스 유형으로 HNSW를 선택했습니다.
* 데이터 수집 단계 동안, 우리는 768의 치수에서 천만 벡터로 구성된 COHERE 데이터세트를 로드했습니다. 이 과정은 약 4.5시간이 걸렸습니다.
* 쿼리 단계에서 0.6344를 리콜하여 1,068의 QPS(Queries per Second)를 확인했습니다. 쿼리의 99번째 백분위수 지연 시간은 20밀리초로 측정되었습니다. 대부분의 런타임 동안 클라이언트 CPU는 100% 용량으로 작동했습니다.

아래 이미지는 스토리지 클러스터 지연 시간 총 IOPS(초당 입출력 작업 수)를 포함한 다양한 스토리지 메트릭을 보여 줍니다.

image::pgvecto_storage_iops_latency.png[Pgvecto 스토리지 IOPS 지연 시간]

 The following section presents the key storage performance metrics.
image::pgvecto_storage_perf_metrics.png[pgvecto 스토리지 성능 메트릭]



=== 벡터 DB 벤치의 밀버스와 포스트그레스의 성능 비교

image::perf_comp_milvus_postgres.png[Perf comp milvus postgres의 약어입니다]

VectorDBBench를 사용한 Milvus 및 PostgreSQL의 성능 검증을 토대로 다음과 같은 점을 관찰했습니다.

* 인덱스 유형: HNSW
* 데이터 세트: 768차원으로 1,000만 벡터를 사용하는 COHERE


우리는 pgvecto.RS가 0.6344의 리콜로 1,068의 QPS(Queries per Second)를 달성했으며, Milvus는 0.9842의 리콜로 106의 QPS 속도를 달성했습니다.

쿼리의 높은 정밀도가 우선 순위인 경우 Milvus는 쿼리당 관련 항목의 비율이 더 높기 때문에 pgvecto.rs보다 성능이 뛰어납니다. 그러나 초당 쿼리 수가 더 중요한 요소인 경우 pgvecto.RS는 Milvus를 초과합니다. 하지만 pgvecto.rs를 통해 검색된 데이터의 품질이 낮고 검색 결과의 약 37%가 관련 없는 항목이라는 점을 유의해야 합니다.



=== 성능 검증에 따른 관찰:

성능 검증을 토대로 다음과 같이 관찰했습니다.

Milvus의 I/O 프로필은 Oracle SLOB에서 볼 수 있는 OLTP 워크로드와 비슷합니다. 벤치마크는 데이터 수집, 사후 최적화 및 쿼리의 세 단계로 구성됩니다. 초기 단계는 주로 64KB 쓰기 작업이 특징이며, 쿼리 단계에는 대개 8KB 읽기가 포함됩니다. ONTAP는 Milvus I/O 로드를 능숙하게 처리할 것으로 기대하고 있습니다.

PostgreSQL 입출력 프로파일은 까다로운 스토리지 워크로드를 제공하지 않습니다. 현재 인메모리 구현이 진행 중이라는 점을 감안할 때 쿼리 단계에서 디스크 입출력을 관찰하지 못했습니다.

DiskANN은 스토리지 차별화를 위한 중요한 기술로 등장했습니다. 시스템 메모리 경계를 넘어 벡터 DB 검색의 효율적인 확장을 지원합니다. 그러나 HNSW와 같은 인메모리 벡터 DB 인덱스와 스토리지 성능 차이를 구별할 가능성은 거의 없습니다.

또한 인덱스 유형이 RAG 애플리케이션을 지원하는 벡터 데이터베이스의 가장 중요한 작동 단계인 HSNW인 경우 쿼리 단계에서 스토리지가 중요한 역할을 수행하지 않는다는 점도 주목할 필요가 있습니다. 여기서 중요한 점은 스토리지 성능이 이러한 애플리케이션의 전체 성능에 크게 영향을 미치지 않는다는 것입니다.
