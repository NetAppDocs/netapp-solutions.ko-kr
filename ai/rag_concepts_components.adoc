---
sidebar: sidebar 
permalink: ai/rag_concepts_components.html 
keywords: RAG, Retrieval Augmented Generation, NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NeMo, NIM, NIMS, Hybrid, Hybrid Cloud, Hybrid Multicloud, NetApp ONTAP, FlexCache, SnapMirror, BlueXP 
summary: NetApp를 사용한 엔터프라이즈 RAG - 개념 및 구성 요소 
---
= 개념 및 구성 요소
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/




== 생성 가능한 AI

세대 AI와 같은 AI 시스템은 감독되지 않은 또는 자가 감독 머신 러닝을 대규모 데이터 세트에 적용하여 설계되었습니다. 특정 데이터 세트를 예측하는 기존의 머신 러닝 모델과 달리 생성 AI 모델은 사용자 프롬프트에 응답하여 텍스트, 코드, 이미지, 비디오 또는 오디오와 같은 새로운 콘텐츠를 생성할 수 있습니다. 이러한 이유로 생성 AI 시스템의 능력도 사용된 데이터의 형식이나 유형에 따라 분류된다. 이러한 옵션은 단일 모드 또는 다중 모드일 수 있습니다. 단일 모드 시스템은 한 가지 입력 유형(예: 텍스트 전용 또는 이미지 전용)을 사용하는 반면, 다중 모드 시스템은 둘 이상의 입력 유형(예: 텍스트, 이미지 및 오디오)를 사용하여 다양한 모달리티에 걸쳐 콘텐츠를 동시에 이해하고 생성할 수 있습니다. 본질적으로 세대 AI는 기업이 콘텐츠를 제작하고 새로운 설계 개념을 생성하며 기존 데이터에서 가치를 추출하는 방식을 바꾸고 있습니다.



=== 대형 언어 모델(LLM)

LLM은 방대한 양의 데이터에 대한 사전 교육을 받은 딥 러닝 모델로서, 다른 작업 중에서도 텍스트를 인식하고 생성할 수 있습니다. LLM은 주로 언어에 초점을 맞춘 세대 AI의 하위 집합으로 시작되었지만, 다중 모드 LLM이 계속 등장함에 따라 이러한 구분이 서서히 사라지고 있습니다. LLM의 기본 변압기는 RNN 또는 CNN 이외의 새로운 네트워크 아키텍처를 도입합니다. 인코더와 디코더로 구성된 신경망 세트가 있어 일련의 텍스트에서 의미를 추출하고 단어 사이의 관계를 이해하는 데 도움이 됩니다. LLM은 자연적인 언어에 대응하고 데이터 분석을 사용하여 비정형 질문에 답할 수 있습니다. 그러나 LLM은 수집하는 데이터만큼 신뢰할 수 있기 때문에 쓰레기 유입과 같은 난관에 기인하는 환각이 발생하기 쉽습니다. LLM에 잘못된 정보를 입력하면 사용자 쿼리에 응답하여 작성 중인 내러티브에 맞춰 부정확한 출력을 생성할 수 있습니다. 당사의 증거 기반 연구에 따르면 AI 엔지니어들은 이러한 환각에 대응하기 위해 다양한 방법을 사용하고 있습니다. 하나는 부정확한 결과를 제한하는 가드레일을 통해, 다른 하나는 RAG와 같은 기술을 통해 상황에 맞는 양질의 데이터로 미세 조정 및 학습을 전송한다는 것입니다.



=== 검색 증강 생성(RAG)

LLM은 대량의 데이터에 대해 교육을 받지만 데이터에 대해 훈련되지 않습니다. RAG는 LLM이 이미 액세스할 수 있는 데이터에 데이터를 추가하여 이 문제를 해결합니다. RAG를 통해 고객은 데이터에 대한 교육을 받은 LLM의 기능을 활용하여 정보를 검색하고 이를 사용하여 생성 AI 사용자를 위한 상황별 정보를 제공할 수 있습니다. RAG는 환각을 줄이고 LLM의 효능과 신뢰성을 개선하고 AI 애플리케이션의 개발을 가속화하며 엔터프라이즈 검색 환경을 강화하는 아키텍처 접근 방식인 머신 러닝 기술입니다.



=== 라가스

래그 파이프라인을 구축하는 데 도움이 되는 기존 도구와 프레임워크가 있지만 이를 평가하고 파이프라인 성과를 정량화하는 것은 어려울 수 있습니다. 바로 이 부분에서 Ragas(RAG Assessment)가 등장합니다. Ragas는 RAG 파이프라인을 평가하는 데 도움이 되는 프레임워크입니다. Ragas는 개방형 표준을 만들고자 하며, 개발자들에게 RAG 응용 프로그램에서 지속적인 학습을 활용할 수 있는 도구와 기술을 제공합니다. 자세한 내용은 을 참조하십시오 https://docs.ragas.io/en/stable/getstarted/index.html["Ragas 시작하기"^]



== 라마 3

디코더 전용 변압기 모델인 Meta의 Llama 3는 공개적으로 접근 가능한 사전 훈련된 LLM(Large Language Model)입니다. 15조 개 이상의 데이터 토큰에 대한 교육을 받은 Llama 3는 NLU(자연어 이해)의 게임 체인저입니다. 번역 및 대화 생성과 같은 복잡한 작업과 맥락을 이해하는 데 탁월합니다. Llama 3는 효율적인 배포 및 개발을 위한 8B, 대규모 AI 네이티브 애플리케이션을 위한 70B의 두 가지 크기로 제공됩니다. 고객은 Vertex AI를 통해 Google Cloud에 Llama 3 을 배포할 수 있습니다. Azure AI Studio를 통해 Azure에, Amazon Sagemaker를 통해 AWS에 배포할 수 있습니다.

이 검증에서는 NVIDIA A100 GPU로 가속화된 NVIDIA DGX 인스턴스 컴퓨팅에 Meta의 Llama 모델을 NVIDIA Nemo ™ 마이크로서비스와 함께 배포하여 생성 AI 사용 사례를 사용자 지정하고 평가하며, 사내 애플리케이션에서 검색 증강 생성(RAG)을 지원했습니다.



== 오픈 소스 프레임워크

오픈 소스 기술에 대한 다음 추가 정보는 배포에 따라 관련이 있을 수 있습니다.



=== 랭체인

LangChain은 대규모 언어 모델(LLM)을 기반으로 하는 애플리케이션을 개발하기 위한 오픈 소스 통합 프레임워크입니다. 고객은 Document Loader, VectorStores 및 기타 다양한 패키지와 함께 제공되는 RAG 애플리케이션을 효율적으로 빌드할 수 있으므로 개발자가 복잡한 워크플로를 유연하게 구축할 수 있습니다. 또한 LangSmith로 앱을 검사, 모니터링 및 평가하여 LangServe를 통해 모든 체인을 지속적으로 최적화하고 REST API에 배포할 수 있습니다. LangChain은 RAG 응용 프로그램의 모범 사례를 인코딩하고, RAG 응용 프로그램을 빌드하는 데 필요한 다양한 구성 요소에 대한 표준 인터페이스를 제공합니다.



=== LlamaIndex입니다

LlamaIndex는 사용자 지정 데이터 원본을 LLM(대규모 언어 모델) 기반 응용 프로그램에 연결하기 위한 단순하고 유연한 데이터 프레임워크입니다. 유연한 데이터 커넥터를 통해 API, 데이터베이스, PDF 등에서 데이터를 수집할 수 있습니다. Llama 3 및 GPT-4와 같은 LLM은 대규모 공용 데이터 세트에 대한 사전 교육을 통해 즉시 놀라운 자연어 처리 기능을 제공합니다. 그러나, 그들의 유틸리티는 귀하의 개인 데이터에 대한 액세스 없이 제한됩니다. LlamaIndex는 매우 인기 있는 Python 및 TypeScript 라이브러리를 제공하며 검색 증강(RAG) 기술 분야에서 업계를 선도하고 있습니다.



== NVIDIA Nemo 마이크로서비스

NVIDIA Nemo는 클라우드 및 데이터 센터 전반에 걸쳐 구축할 수 있는 엔터프라이즈급 생성 AI 모델을 구축 및 사용자 지정할 수 있는 엔드 투 엔드 플랫폼입니다. Nemo는 대규모 생성 AI 개발 및 배포 프로세스를 단순화하는 마이크로서비스를 제공하여 조직이 엔터프라이즈 데이터 소스에 LLM을 연결할 수 있도록 합니다. 이 문서를 작성하는 시점에서 Nemo 마이크로서비스는 NVIDIA의 초기 액세스 프로그램을 통해 사용할 수 있습니다.



=== NVIDIA Nemo Inference 마이크로서비스(NIMS)

NVIDIA AI Enterprise의 일부인 NVIDIA NIMS는 AI 기반 엔터프라이즈 애플리케이션을 개발하고 AI 모델을 운영 환경에 구축하기 위한 간소화된 경로를 제공합니다. NIMS는 업계 표준 API, 도메인별 코드, 최적화된 추론 엔진, 엔터프라이즈 런타임을 포함한 컨테이너형 추론 마이크로서비스입니다.



=== NVIDIA Nemo Retriever의 약어입니다

NVIDIA Nemo 프레임워크의 최신 서비스인 NVIDIA Nemo Retriever는 RAG의 포함 및 검색 부분을 최적화하여 정확도와 효율성이 더욱 향상됩니다. NVIDIA Nemo Retriever는 온프레미스 또는 클라우드에 배포할 수 있는 정보 검색 서비스입니다. 이 솔루션은 기업이 엔터프라이즈급 래그 기능을 고객의 맞춤형 운영 AI 애플리케이션에 안전하고 간편하게 통합할 수 있는 경로를 제공합니다.



== NVIDIA Enterprise RAG LLM 연산자

NVIDIA Enterprise Retrieval RAG(Augmented Generation) LLM(Large Language Model) 연산자는 Kubernetes에서 RAG 파이프라인을 실행하는 데 필요한 소프트웨어 구성요소 및 서비스를 가능하게 합니다. NVIDIA Inference Microservice 및 NVIDIA Nemo Retriever Embedding Microservice와 같은 RAG 파이프라인에 대한 주요 구성 요소의 수명 주기를 관리하는 운영자에게 조기에 액세스할 수 있습니다. 자세한 내용은 을 참조하십시오 https://docs.nvidia.com/ai-enterprise/rag-llm-operator/0.4.1/index.html["NVIDIA Enterprise RAG LLM 연산자"^]



== 벡터 데이터베이스



=== PostgreSQL:pgvector입니다

XGBoost와 같은 많은 기존 ML 알고리즘에 대한 기본 바인딩이 있어 SQL로 머신 러닝을 수행하는 것은 PostgreSQL에 새로운 기능이 아닙니다. 최근에는 벡터 유사성 검색을 위한 오픈 소스 확장인 pgvector가 출시됨에 따라 PostgreSQL은 ML 생성 임베딩을 저장 및 검색하는 기능을 갖추고 있습니다. 이 기능은 AI 사용 사례 및 LLM을 사용하는 애플리케이션에 유용합니다.

NVIDIA Enterprise rag LLM 연산자를 통한 검증에서 기본 샘플 파이프라인은 pgvector 데이터베이스를 포드에서 시작합니다. 그런 다음 쿼리 서버가 pgvector 데이터베이스에 연결하여 Embedding을 저장하고 검색합니다. 채팅 봇 웹 애플리케이션 및 쿼리 서버는 마이크로서비스 및 벡터 데이터베이스와 통신하여 사용자 프롬프트에 응답합니다.



=== 밀버스주식회사

MongoDB와 같이 API를 제공하는 다기능 벡터 데이터베이스인 Milvus는 다양한 데이터 유형과 멀티벡터화 같은 기능을 지원하여 데이터 과학 및 머신 러닝에서 널리 사용되고 있습니다. DNN(Deep Neural Networks) 및 ML(Machine Learning) 모델에 의해 생성된 10억 개 이상의 임베디드 벡터를 저장, 인덱싱 및 관리할 수 있는 능력을 갖추고 있습니다. 고객은 Nvidia NIM&Nemo 마이크로서비스 및 Milvus를 벡터 데이터베이스로 사용하여 RAG 애플리케이션을 구축할 수 있습니다. NVIDIA Nemo 컨테이너가 임베디드 생성을 위해 성공적으로 배포되면 Milvus 컨테이너를 배포하여 이러한 임베딩을 저장할 수 있습니다. 벡터 데이터베이스 및 NetApp에 대한 자세한 내용은 를 참조하십시오 https://docs.netapp.com/us-en/netapp-solutions/ai/vector-database-solution-with-netapp.html["레퍼런스 아키텍처 – NetApp를 사용한 벡터 데이터베이스 솔루션"^].



=== Apache Cassandra를 다운로드하십시오

Apache Cassandra ® 는 오픈 소스 NoSQL 데이터베이스로, 확장성이 뛰어난 고가용성 데이터베이스를 제공합니다. 벡터 검색 기능과 함께 제공되며 벡터 데이터 유형 및 벡터 유사성 검색 기능을 지원하며, 특히 LLM 및 사설 RAG 파이프라인이 포함된 AI 애플리케이션에 유용합니다.

NetApp Instaclustr는 클라우드 또는 사내에서 호스팅되는 Apache Cassandra ® 용 완전 관리형 서비스를 제공합니다. NetApp 고객은 이 툴을 사용하여 Apache Cassandra ® 클러스터를 프로비저닝하고 Instaclustr 콘솔 또는 Instaclstr 프로비저닝 API를 통해 C#, Node.js, AWS PrivateLink 및 기타 다양한 옵션을 사용하여 클러스터에 연결할 수 있습니다.

또한, NetApp ONTAP은 Kubernetes에서 실행되는 컨테이너화된 Apache Cassandra 클러스터에 영구 스토리지 공급자 역할을 합니다. NetApp Astra Control은 ONTAP의 데이터 관리 이점을 Apache Cassandra와 같은 데이터가 풍부한 Kubernetes 애플리케이션으로 원활하게 확장합니다. 이에 대한 자세한 내용은 을 참조하십시오 https://cloud.netapp.com/hubfs/SB-4134-0321-DataStax-Cassandra-Guide%20(1).pdf["NetApp Astra Control 및 ONTAP 스토리지를 사용하는 DataStax Enterprise의 애플리케이션 인식 데이터 관리"^]



=== NetApp Instaclustr

Instaclustr는 오픈 소스 기술을 위한 SaaS 플랫폼을 통해 데이터 인프라를 지원함으로써 조직이 규모에 따라 애플리케이션을 제공할 수 있도록 도와줍니다. 의미 있는 이해를 검색 애플리케이션에 포함하려는 Generative AI 개발자는 다양한 옵션을 사용할 수 있습니다. Postgres용 Instaclustr은 pgvector 확장을 지원합니다. OpenSearch용 Instaclustr는 가장 가까운 인접 함수와 함께 입력 쿼리를 기반으로 관련 문서를 검색하는 벡터 검색을 지원합니다. Redis용 Instaclustr는 벡터 데이터를 저장하고 벡터를 검색하며 벡터 검색을 수행할 수 있습니다. 자세한 내용은 를 참조하십시오 https://www.instaclustr.com/platform/["NetApp의 Instaclustr 플랫폼"^]



== NetApp BlueXP

NetApp BlueXP는 NetApp의 모든 스토리지 및 데이터 서비스를 하이브리드 멀티 클라우드 데이터 자산을 구축, 보호 및 관리할 수 있는 단일 툴에 통합합니다. 또한 온프레미스 및 클라우드 환경에서 스토리지 및 데이터 서비스를 위한 통합된 경험을 제공하고 AIOps의 기능을 통해 운영을 간소화하며 오늘날의 클라우드 주도 환경에 필요한 유연한 소비 매개 변수와 통합 보호를 제공합니다.



== NetApp Cloud Insights를 참조하십시오

NetApp Cloud Insights는 전체 인프라에 대한 가시성을 제공하는 클라우드 인프라 모니터링 툴입니다. Cloud Insights를 사용하면 퍼블릭 클라우드 및 프라이빗 데이터 센터를 비롯한 모든 리소스에 대한 모니터링, 문제 해결 및 최적화 등이 가능합니다. Cloud Insights는 수백 개의 수집기를 통해 Kubernetes를 비롯한 이기종 인프라 및 워크로드를 한 곳에서 모든 인프라와 애플리케이션 전체 스택을 한눈에 볼 수 있도록 지원합니다. 자세한 내용은 을 참조하십시오 https://docs.netapp.com/us-en/cloudinsights/index.html["Cloud Insights이 무슨 일을 할 수 있습니까?"^]



== NetApp StorageGRID를 참조하십시오

NetApp StorageGRID는 퍼블릭, 프라이빗 및 하이브리드 멀티 클라우드 환경에서 다양한 사용 사례를 지원하는 소프트웨어 정의 오브젝트 스토리지 제품군입니다. StorageGRID은 Amazon S3 API를 기본적으로 지원하며 자동화된 라이프사이클 관리와 같은 업계 최고의 혁신 기능을 제공하여 비정형 데이터를 장기적으로 비용 효율적으로 저장, 보호 및 보존합니다.



== NetApp 별모양

Spot by NetApp은 AWS, Azure 또는 Google Cloud의 클라우드 인프라를 자동화하고 최적화하여 가장 낮은 비용으로 SLA 기반 가용성 및 성능을 제공합니다. Spot은 머신 러닝과 분석 알고리즘을 사용하여 운영 및 미션 크리티컬 워크로드에 Spot 용량을 활용할 수 있도록 지원합니다. GPU 기반 인스턴스를 실행하는 고객은 Spot의 이점을 누리고 컴퓨팅 비용을 낮출 수 있습니다.



== NetApp ONTAP를 참조하십시오

NetApp의 최신 세대 스토리지 관리 소프트웨어인 ONTAP 9는 기업이 인프라를 현대화하고 클라우드 지원 데이터 센터로 전환할 수 있도록 지원합니다. ONTAP는 업계 최고 수준의 데이터 관리 기능을 활용하여 데이터가 상주하는 위치와 상관없이 단일 툴셋으로 데이터를 관리하고 보호할 수 있습니다. 필요에 따라 에지, 코어, 클라우드 등 어느 위치로도 데이터를 자유롭게 이동할 수 있습니다. ONTAP 9에는 데이터 관리를 단순화하고, 중요 데이터를 더 빨리 처리하고, 보호하며, 하이브리드 클라우드 아키텍처 전체에서 차세대 인프라 기능을 지원하는 다양한 기능이 포함되어 있습니다.



=== 데이터 관리를 단순화하십시오

데이터 관리는 AI 애플리케이션에 적합한 리소스를 사용하고 AI/ML 데이터 세트를 교육할 수 있도록 엔터프라이즈 IT 운영 및 데이터 과학자에게 매우 중요합니다. NetApp 기술에 대한 다음 추가 정보는 이 검증의 범위에 포함되지 않지만, 배포에 따라 달라질 수 있습니다.

ONTAP 데이터 관리 소프트웨어에는 운영을 간소화 및 단순화하고 총 운영 비용을 절감하는 다음과 같은 기능이 있습니다.

* 인라인 데이터 컴팩션 및 확대된 중복제거: 데이터 컴팩션은 스토리지 블록 내부의 낭비되는 공간을 줄이고, 중복제거는 실제 용량을 상당히 늘려줍니다. 이는 로컬에 저장된 데이터와 클라우드로 계층화된 데이터에 적용됩니다.
* 최소, 최대 및 적응형 서비스 품질(AQoS): 세부적인 서비스 품질(QoS) 제어로 고도의 공유 환경에서 중요 애플리케이션의 성능 수준을 유지할 수 있습니다.
* NetApp FabricPool를 참조하십시오. AWS(Amazon Web Services), Azure, NetApp StorageGRID 스토리지 솔루션을 포함한 퍼블릭 클라우드 및 프라이빗 클라우드 스토리지에 콜드 데이터를 자동으로 계층화합니다. FabricPool에 대한 자세한 내용은 를 참조하십시오 https://www.netapp.com/pdf.html?item=/media/17239-tr4598pdf.pdf["TR-4598: FabricPool 모범 사례"^].




=== 데이터 가속화 및 보호

ONTAP는 탁월한 수준의 성능과 데이터 보호를 제공하며 다음과 같은 방법으로 이러한 기능을 확장합니다.

* 성능 및 짧은 지연 시간: ONTAP는 가장 짧은 지연 시간으로 가장 높은 처리량을 제공합니다.
* 데이터 보호: ONTAP는 모든 플랫폼에서 공통 관리를 지원하는 내장 데이터 보호 기능을 제공합니다.
* NVE(NetApp 볼륨 암호화). ONTAP는 온보드 및 외부 키 관리를 모두 지원하는 기본 볼륨 레벨 암호화를 제공합니다.
* 멀티테넌시 및 다단계 인증. ONTAP를 사용하면 인프라 리소스를 최고 수준의 보안으로 공유할 수 있습니다.




=== 미래 지향형 인프라

ONTAP은 다음과 같은 기능을 통해 끊임없이 변화하는 까다로운 비즈니스 요구사항을 충족할 수 있도록 지원합니다.

* 원활한 확장 및 무중단 운영: ONTAP은 운영 중단 없이 기존 컨트롤러 및 스케일아웃 클러스터에 용량을 추가할 수 있도록 지원합니다. 고객은 고비용이 따르는 데이터 마이그레이션이나 운영 중단 없이 NVMe 및 32Gb FC와 같은 최신 기술로 업그레이드할 수 있습니다.
* 클라우드 연결: ONTAP은 주요 클라우드와 연결되는 스토리지 관리 소프트웨어로, 모든 퍼블릭 클라우드에서 소프트웨어 정의 스토리지 및 클라우드 네이티브 인스턴스 옵션이 제공됩니다.
* 새로운 애플리케이션과 통합: ONTAP은 기존 엔터프라이즈 앱을 지원하는 인프라와 동일한 인프라를 사용하여 자율주행 차량, 스마트 시티, Industry 4.0과 같은 차세대 플랫폼 및 애플리케이션을 위한 엔터프라이즈급 데이터 서비스를 제공합니다.




== NetApp ONTAP용 Amazon FSx

Amazon FSx for NetApp ONTAP는 완전 관리형 AWS 서비스로서, NetApp의 인기 ONTAP 파일 시스템을 기반으로 구축되어 매우 안정적이고 확장 가능하며 성능이 우수하며 풍부한 파일 스토리지를 제공합니다. ONTAP용 FSX는 NetApp 파일 시스템의 친숙한 기능, 성능, 기능 및 API 작업을 완벽하게 관리되는 AWS 서비스의 민첩성, 확장성 및 간편성과 결합합니다.



== Azure NetApp Files

Azure NetApp Files는 Azure 네이티브 자사 엔터프라이즈급 고성능 파일 스토리지 서비스입니다. SMB, NFS 및 이중 프로토콜 볼륨을 지원하며 다음과 같은 사용 사례에 사용할 수 있습니다.

* 파일 공유.
* 더 높여 줍니다.
* 데이터베이스를 지원합니다.
* 고성능 컴퓨팅,
* 생성 가능한 AI:




== Google Cloud NetApp 볼륨

Google Cloud NetApp Volumes는 완전 관리형 클라우드 기반 데이터 스토리지 서비스로서, 고급 데이터 관리 기능과 확장성이 뛰어난 성능을 제공합니다. NetApp 호스팅 데이터는 미리 보기 툴킷 참조 아키텍처에서 Google의 Vertex AI 플랫폼에 대한 RAG(검색-증강 생성) 작업에 사용할 수 있습니다.



== NetApp Astra Trident

Astra Trident를 사용하면 ONTAP(AFF, NetApp FAS, Select, 클라우드, NetApp ONTAP용 Amazon FSx), Element 소프트웨어(NetApp HCI, SolidFire), Azure NetApp Files 서비스 및 Google Cloud 기반 Cloud Volumes Service Astra Trident는 Kubernetes와 기본적으로 통합되는 CSI(컨테이너 스토리지 인터페이스) 호환 동적 스토리지 오케스트레이터입니다.



== 쿠버네티스

Kubernetes는 Google에서 원래 설계한 개방형 소스, 분산형 컨테이너 오케스트레이션 플랫폼으로, 현재 CNCF(Cloud Native Computing Foundation)에서 관리하고 있습니다. Kubernetes는 컨테이너화된 애플리케이션의 구축, 관리 및 크기 조정 기능을 자동화할 수 있으며 엔터프라이즈 환경에서 지배적인 컨테이너 오케스트레이션 플랫폼입니다.
