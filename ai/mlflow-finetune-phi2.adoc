---
sidebar: sidebar 
permalink: ai/mlflow-finetune-phi2.html 
keywords: Jupyter Notebook, MLFlow, NetApp DataOps Toolkit, LLM, 
summary: Jupyter Hub에서 MLFlow로 대형 언어 모델을 미세 조정합니다 
---
= Jupyter Hub에서 MLFlow로 대형 언어 모델을 미세 조정합니다
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
이 섹션에서는 Jupyter Hub를 사용하여 MLFlow를 사용하여 LLM(Large Language Model)을 미세 조정하는 단계를 설명합니다.

이 슬라이드의 목적은 RAG(검색 증강 생성)와 같은 고객 사용 사례를 위해 NetApp 스토리지와 NetApp 지능형 데이터 인프라를 통합하는 교육 작업을 보여주는 예입니다.



== 필수 구성 요소

이 섹션에서는 jupyter hub를 사용하여 언어 모델을 미세 조정하는 데 필요한 사전 요구 사항에 대해 간략히 설명합니다. 이를 위해 모델을 훈련하거나 미세 조정하는 데 필요한 관련 라이브러리와 패키지를 이미 설치했다고 가정합니다. 이 예제에 사용된 라이브러리 중 일부는 다음을 포함하지만 이에 국한되지 않습니다. -transformers -peft (parameter Efficient Fine Tuning) -accelerate 이러한 라이브러리는 HuggingFace에 속하는 라이브러리입니다. 추가 라이브러리에는 matplolib, SciPy, Einops 등이 있습니다.

또한 HuggingFace를 통해 기본 모델과 그 무게에 액세스할 수 있다고 가정합니다. 사용 가능한 모델 목록은 에서 https://huggingface.co/models["HuggingFace의 약어입니다"]확인할 수 있습니다.

마지막으로, 적절한 스토리지가 있는 Jupyter Hub 계정에 대한 액세스도 필요합니다. 더 높은 컴퓨팅 요구사항을 위해서는 GPU 서버에 액세스하는 것이 좋습니다.

이 미세 조정 예제는 에서 개발한 노트북 가이드 및 예제 모음으로부터 영감을 https://github.com/brevdev/notebooks["Brevdev 팀"] 받았습니다.



== 데이터 로드 및 실험 설정

쉽게 검색할 수 있도록 모든 데이터(문서 및 텍스트)를 전자 필기장과 동일한 공유 폴더에 저장합니다. Data Processing 및 교육용 문서를 .json 형식으로 변환합니다.

데이터가 처리되면 GPU에 데이터와 함께 모델을 로드할 수 있는 충분한 RAM이 있는지 확인합니다. 이 예에서는 Microsoft의 https://huggingface.co/microsoft/phi-2["파이-2"] 크기 27억 개 매개 변수를 미세 조정하기 위해 16GB RAM이 장착된 NVIDIA Tesla T4 GPU를 사용합니다. 분산 교육 설정을 구축하려는 경우 사용하는 모델과 데이터 양에 따라 더 많은 RAM/추가 GPU가 필요할 수 있습니다.

image:tesla-t4.png["이 예에 사용된 GPU 사양"]

이 예제에서는 https://huggingface.co/docs/diffusers/main/en/training/lora["로라"] 모델이 리소스 제약 조건을 준수하는지 확인하기 위해 을 사용합니다. 컴퓨팅이 제약 조건이 아닌 경우 전체 미세 조정을 수행할 수 있습니다.



== 결과 및 향후 작업

다음 표는 NetApp 솔루션 데이터 세트(내부 솔루션 엔지니어링 블로그/문서)에서 훈련된 PHI-2에 대한 교육 손실 및 해당 검증 손실을 보여줍니다. 관찰한 바와 같이, 시간 경과에 따라 교육 손실과 함께 검증 손실이 감소합니다.

image:phi2-results.png["Phi-2에 대한 교육 손실 및 검증 손실"]

세밀하게 조정된 언어 모델을 평가하는 데 사용되는 몇 가지 샘플 프롬프트는 다음과 같습니다 - * 1. AI 교육 데이터 세트에 NetApp FlexGroup 볼륨을 사용할 때의 이점에 대해 설명하십시오. *

이 프롬프트에 대한 대답은 다음과 같습니다. "NetApp FlexGroup 볼륨은 AI 훈련 데이터 세트에 다음과 같은 여러 가지 이점을 제공합니다. - * 확장성 *: FlexGroup 볼륨을 수평으로 확장하여 AI 훈련에 필요한 대용량 데이터 및 컴퓨팅 리소스를 수용할 수 있습니다. 따라서 조직에서는 리소스 제한에 대한 걱정 없이 대규모 데이터 세트를 기반으로 모델을 훈련할 수 있습니다. - * 데이터 일관성 *: FlexGroup 볼륨은 모든 데이터에 대해 단일 네임스페이스를 제공하여 클러스터의 여러 노드에서 데이터 일관성을 보장합니다. 따라서 여러 노드에서 데이터가 항상 사용 가능하고 일관성을 유지할 수 있습니다. 이는 여러 소스의 데이터에 액세스해야 하는 AI 애플리케이션에 중요합니다. - * 성능 *: FlexGroup 볼륨은 고성능 스토리지에 최적화되어 AI 훈련에 필요한 대규모 데이터 세트를 저장하는 데 적합합니다. 볼륨의 성능 특성에는 짧은 지연 시간, 높은 처리량, 고가용성이 포함되므로 교육 중에 데이터에 빠르고 안정적으로 액세스할 수 있습니다. - * 보안 *: FlexGroup 볼륨은 암호화, 액세스 제어 및 데이터 보호와 같은 기본 제공 보안 기능을 제공하여 중요 데이터를 수명 주기 내내 보호합니다. 이는 개인 정보나 금융 데이터와 같은 민감한 데이터를 처리하는 AI 애플리케이션에 특히 중요합니다. 전반적으로 NetApp FlexGroup 볼륨은 AI 훈련 데이터 세트를 저장 및 관리하기 위한 확장 가능하고 안전한 고성능 솔루션을 제공합니다."

* 2. ONTAP 9는 어떤 장점과 기능을 제공합니까? 특정 인스턴스를 제공하십시오.*

이 프롬프트에 대한 응답은 다음과 같습니다. " ONTAP 9는 다음과 같은 장점과 기능을 제공합니다. - * 고성능 *, 노드와 스토리지 볼륨 간의 데이터 전송을 위해 노드당 최대 1TB/s의 처리량을 제공합니다. - * 고가용성 *, 여러 노드에서 99.999% 가동 시간 및 고가용성 지원 - * 확장성 *, 노드를 추가하거나 각 노드의 디스크 수를 늘려서 수평으로 확장할 수 있는 기능. - * 유연성 * - 워크로드 요구사항에 따라 SSD, HDD 또는 NVMe 드라이브와 같은 다양한 유형의 스토리지 볼륨을 사용할 수 있습니다. - * 보안 *, 암호화, 액세스 제어, 감사 등의 다양한 보안 정책을 구현하여 클러스터의 데이터와 리소스를 보호할 수 있습니다. - 성능을 최적화하고 대량의 데이터를 저장 및 전송하는 비용을 절감하기 위해 * 데이터 중복 제거, 압축 및 복제 * 와 같은 고급 기능을 지원합니다."

이러한 응답을 통해 미세 조정된 모델은 기본 모델에 비해 훈련된 데이터 세트의 컨텍스트가 풍부하고 보다 관련성이 높은 결과를 도출했음을 알 수 있습니다.

이 예제는 적은 양의 컴퓨터 리소스를 사용하는 사용자 정의/독점 데이터에 대한 언어 모델을 교육하는 것이 여전히 가능함을 보여주기 위한 것입니다. 향후 작업에는 훨씬 더 큰 GPU 설정(GPU의 분산 시스템 네트워크)을 활용하여 조직 전체의 데이터에 대한 더 큰 언어 모델(10B 이상의 매개 변수 주문)을 교육하는 것이 포함됩니다.
