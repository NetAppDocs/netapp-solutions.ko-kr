---
sidebar: sidebar 
permalink: ai/osrunai_fractional_gpu_allocation_for_less_demanding_or_interactive_workloads.html 
keywords:  
summary:  
---
= 덜 까다로운 워크로드 또는 대화형 워크로드에 대한 부분 GPU 할당
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ../media/


[role="lead"]
연구자와 개발자가 개발, 고매개 변수 조정 또는 디버깅 단계에서 자신의 모델을 작업할 때 이러한 워크로드는 일반적으로 컴퓨팅 리소스를 적게 사용합니다. 따라서 동일한 GPU를 다른 워크로드에 동시에 할당할 수 있도록 소수점 GPU 및 메모리를 프로비저닝하는 것이 더 효율적입니다. 실행: AI의 오케스트레이션 솔루션은 Kubernetes에서 컨테이너화된 워크로드를 위한 분할 GPU 공유 시스템을 제공합니다. 이 시스템은 CUDA 프로그램을 실행하는 워크로드를 지원하며 추론과 모델 구축과 같은 가벼운 AI 작업에 특히 적합합니다. 소수점 GPU 시스템은 데이터 과학과 AI 엔지니어링 팀에게 단일 GPU에서 동시에 여러 워크로드를 실행할 수 있는 기능을 투명하게 제공합니다. 이를 통해 기업은 컴퓨터 비전, 음성 인식 및 자연어 처리와 같은 더 많은 워크로드를 동일한 하드웨어에서 실행할 수 있으므로 비용이 절감됩니다.

실행: AI의 분할 GPU 시스템은 컨테이너가 자급식 프로세서인 것처럼 사용하고 액세스할 수 있는 자체 메모리 및 컴퓨팅 공간을 사용하여 가상화된 논리 GPU를 효과적으로 생성합니다. 따라서 여러 워크로드가 서로 간섭하지 않고 동일한 GPU의 컨테이너에서 나란히 실행될 수 있습니다. 이 솔루션은 투명하고 단순하며 이식 가능하며 컨테이너 자체를 변경할 필요가 없습니다.

일반적인 UseCase는 동일한 GPU에서 실행되는 작업을 2~8개 볼 수 있으며, 이는 동일한 하드웨어에서 8배 더 많은 작업을 수행할 수 있음을 의미합니다.

다음 그림에서 PROJECT 팀 d에 속한 Frac05 작업에 대해 할당된 GPU 수가 0.50인 것을 알 수 있다. 이는 컨테이너에 사용 가능한 GPU 메모리가 DGX-1 노드의 V100 GPU당 32GB의 절반 인 16,255MB임을 보여 주는 'NVIDIA-SMI' 명령으로 더욱 검증되었습니다.

image:osrunai_image7.png["입력/출력 대화 상자 또는 작성된 내용을 표시하는 그림"]
