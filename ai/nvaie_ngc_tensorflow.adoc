---
sidebar: sidebar 
permalink: ai/nvaie_ngc_tensorflow.html 
keywords: NetApp AI, AI, Artificial Intelligence, ML, Machine Learning, NVIDIA, NVIDIA AI Enterprise, NVAIE, VMware, NGC 
summary: NetApp 및 VMware를 사용하는 NVIDIA AI 엔터프라이즈 - NVIDIA NGC 소프트웨어 활용 - 사용 사례 - TensorFlow 교육 작업 
---
= 사용 사례 - TensorFlow 교육 작업 예
:hardbreaks:
:allow-uri-read: 
:nofooter: 
:icons: font
:linkattrs: 
:imagesdir: ./../media/


[role="lead"]
이 섹션에서는 NVIDIA AI Enterprise 환경 내에서 TensorFlow 교육 작업을 실행하기 위해 수행해야 하는 작업에 대해 설명합니다.



== 필수 구성 요소

이 섹션에 설명된 단계를 수행하기 전에 에 설명된 지침에 따라 게스트 VM 템플릿을 이미 생성했다고 가정합니다 link:nvaie_ngc_setup.html["설정"] 페이지.



== 템플릿에서 게스트 VM을 생성합니다

먼저 이전 섹션에서 생성한 템플릿에서 새 게스트 VM을 생성해야 합니다. 템플릿에서 새 게스트 VM을 생성하려면 VMware vSphere에 로그인하고 템플릿 이름을 마우스 오른쪽 단추로 클릭한 다음 '이 템플릿에서 새 VM...'을 선택하고 마법사를 따릅니다.

image::nvaie_image4.png[nvaie 이미지4]



== 데이터 볼륨 생성 및 마운트

그런 다음, 교육 데이터 세트를 저장할 새 데이터 볼륨을 생성해야 합니다. NetApp DataOps 툴킷을 사용하여 새 데이터 볼륨을 빠르게 생성할 수 있습니다. 다음 예제 명령은 용량이 2TB인 'imagenet'이라는 이름의 볼륨을 생성하는 방법을 보여 줍니다.

....
$ netapp_dataops_cli.py create vol -n imagenet -s 2TB
....
데이터 볼륨을 데이터로 채우기 전에 게스트 VM 내에 마운트해야 합니다. NetApp DataOps 툴킷을 사용하여 데이터 볼륨을 빠르게 마운트할 수 있습니다. 다음 예제 명령은 이전 단계에서 생성한 볼륨의 모팅을 보여 줍니다.

....
$ sudo -E netapp_dataops_cli.py mount vol -n imagenet -m ~/imagenet
....


== 데이터 볼륨을 채웁니다

새 볼륨을 프로비저닝하고 마운트한 후에는 소스 위치에서 교육 데이터 세트를 가져와서 새 볼륨에 배치할 수 있습니다. 일반적으로 이 작업은 S3 또는 Hadoop 데이터 레이크에서 데이터를 가져오는 작업을 수반하며, 경우에 따라 데이터 엔지니어의 도움을 받게 됩니다.



== TensorFlow 교육 작업을 실행합니다

이제 TensorFlow 교육 작업을 실행할 준비가 되었습니다. TensorFlow 교육 작업을 실행하려면 다음 작업을 수행하십시오.

. NVIDIA NGC 엔터프라이즈 TensorFlow 컨테이너 이미지를 가져옵니다.
+
....
$ sudo docker pull nvcr.io/nvaie/tensorflow-2-1:22.05-tf1-nvaie-2.1-py3
....
. NVIDIA NGC 엔터프라이즈 TensorFlow 컨테이너의 인스턴스를 시작합니다. '-v' 옵션을 사용하여 데이터 볼륨을 컨테이너에 연결합니다.
+
....
$ sudo docker run --gpus all -v ~/imagenet:/imagenet -it --rm nvcr.io/nvaie/tensorflow-2-1:22.05-tf1-nvaie-2.1-py3
....
. 컨테이너 내에서 TensorFlow 교육 프로그램을 실행합니다. 다음 예제 명령은 컨테이너 이미지에 포함된 ResNet-50 훈련 프로그램의 예를 보여 줍니다.
+
....
$ python ./nvidia-examples/cnn/resnet.py --layers 50 -b 64 -i 200 -u batch --precision fp16 --data_dir /imagenet/data
....

